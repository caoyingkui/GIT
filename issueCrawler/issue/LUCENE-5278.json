{
    "id": "LUCENE-5278",
    "title": "MockTokenizer throws away the character right after a token even if it is a valid start to a new token",
    "details": {
        "components": [],
        "fix_versions": [
            "4.6",
            "6.0"
        ],
        "affect_versions": "None",
        "priority": "Trivial",
        "labels": "",
        "type": "Bug",
        "resolution": "Fixed",
        "status": "Resolved"
    },
    "description": "MockTokenizer throws away the character right after a token even if it is a valid start to a new token.  You won't see this unless you build a tokenizer that can recognize every character like with new RegExp(\".\") or RegExp(\"...\").\n\nChanging this behaviour seems to break a number of tests.",
    "attachments": {
        "LUCENE-5278.patch": "https://issues.apache.org/jira/secure/attachment/12608061/LUCENE-5278.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2013-10-11T19:31:47+0000",
            "content": "This patch \"fixes\" the behaviour from my perspective but breaks a bunch of other tests. ",
            "author": "Nik Everett",
            "id": "comment-13792979"
        },
        {
            "date": "2013-10-11T19:59:18+0000",
            "content": "I think i understand what you want: it makes sense. The only reason its the way it is today is because this thing historically came from CharTokenizer (see the isTokenChar?).\n\nBut it would be better if you could e.g. make a pattern like ([A-Z]a-z+) and for it to actually break FooBar into Foo, Bar rather than throwout out \"bar\" all together.\n\nI'll dig into this! ",
            "author": "Robert Muir",
            "id": "comment-13792993"
        },
        {
            "date": "2013-10-12T00:48:52+0000",
            "content": "Nice patch Nik!\n\nI think this is ready: i tweaked variable names and rearranged stuff (e.g. i use -1 instead of Integer so we arent boxing and a few other things).\n\nI also added some unit tests.\n\nThe main issues why tests were failing with your original patch:\n\n\treset() needed to clear the buffer variables.\n\tthe state machine needed some particular extra check when emitting a token: e.g. if you make a regex of \"..\", but you send it \"abcde\", the tokens should be \"ab\", \"cd\", but not \"e\". so when we end on a partial match, we have to check that we are in an accept state.\n\tterm-limit-exceeded is a special case (versus last character being in a reject state)\n\n ",
            "author": "Robert Muir",
            "id": "comment-13793181"
        },
        {
            "date": "2013-10-12T01:35:06+0000",
            "content": "added a few more tests to TestMockAnalyzer so all these crazy corner cases are found there and not debugging other tests  ",
            "author": "Robert Muir",
            "id": "comment-13793198"
        },
        {
            "date": "2013-10-12T01:57:01+0000",
            "content": "Commit 1531479 from Robert Muir in branch 'dev/trunk'\n[ https://svn.apache.org/r1531479 ]\n\nLUCENE-5278: remove CharTokenizer brain-damage from MockTokenizer so it works better with custom regular expressions ",
            "author": "ASF subversion and git services",
            "id": "comment-13793205"
        },
        {
            "date": "2013-10-12T01:57:44+0000",
            "content": "I committed this to trunk: I did a lot of testing locally but I want to let Jenkins have its way with it for a few hours before backporting to branch_4x. ",
            "author": "Robert Muir",
            "id": "comment-13793206"
        },
        {
            "date": "2013-10-12T04:30:16+0000",
            "content": "Commit 1531498 from Robert Muir in branch 'dev/branches/branch_4x'\n[ https://svn.apache.org/r1531498 ]\n\nLUCENE-5278: remove CharTokenizer brain-damage from MockTokenizer so it works better with custom regular expressions ",
            "author": "ASF subversion and git services",
            "id": "comment-13793247"
        },
        {
            "date": "2013-10-12T04:31:15+0000",
            "content": "Thanks again Nik! ",
            "author": "Robert Muir",
            "id": "comment-13793248"
        }
    ]
}