{
    "id": "SOLR-6138",
    "title": "Solr ERROR RecoveryStrategy Recovery failed",
    "details": {
        "affect_versions": "4.6,                                            4.7.1",
        "status": "Reopened",
        "fix_versions": [],
        "components": [
            "clients - java"
        ],
        "type": "Bug",
        "priority": "Major",
        "labels": "",
        "resolution": "Unresolved"
    },
    "description": "We want to enrich our search ability by solr.We do an exercise for test that how many cores in one machine solr cores can support.\nWe find we can create more than 2000 cores without datas in one machine.But when we create cores with data ,we just can create about 1000 cores,after more t han 1000 cores,we meet many errors like following I will apend it .If you have meets the same or similar problem,please tell me.\n\nI would be grateful if you could help me.\n\nHear are some errors:\n\n09:43:29 \tWARN \tSolrResourceLoader \tCan't find (or read) directory to add to classloader: /non/existent/dir/yields/warning (resolved as: /non/existent/dir/yields/warning).\n09:43:29 \tWARN \tSolrResourceLoader \tCan't find (or read) directory to add to classloader: /non/existent/dir/yields/warning (resolved as: /non/existent/dir/yields/warning).\n09:43:29 \tWARN \tSolrResourceLoader \tCan't find (or read) directory to add to classloader: /non/existent/dir/yields/warning (resolved as: /non/existent/dir/yields/warning).\n09:43:29 \tWARN \tSolrResourceLoader \tCan't find (or read) directory to add to classloader: /non/existent/dir/yields/warning (resolved as: /non/existent/dir/yields/warning).\n09:43:29 \tWARN \tSolrResourceLoader \tCan't find (or read) directory to add to classloader: /non/existent/dir/yields/warning (resolved as: /non/existent/dir/yields/warning).\n09:43:29 \tWARN \tSolrResourceLoader \tCan't find (or read) directory to add to classloader: /non/existent/dir/yields/warning (resolved as: /non/existent/dir/yields/warning).\n09:43:29 \tWARN \tSolrResourceLoader \tCan't find (or read) directory to add to classloader: /non/existent/dir/yields/warning (resolved as: /non/existent/dir/yields/warning).\n09:43:29 \tWARN \tSolrResourceLoader \tCan't find (or read) directory to add to classloader: /non/existent/dir/yields/warning (resolved as: /non/existent/dir/yields/warning).\n09:43:29 \tWARN \tSolrResourceLoader \tCan't find (or read) directory to add to classloader: /non/existent/dir/yields/warning (resolved as: /non/existent/dir/yields/warning).\n09:43:29 \tWARN \tSolrResourceLoader \tCan't find (or read) directory to add to classloader: /non/existent/dir/yields/warning (resolved as: /non/existent/dir/yields/warning).\n09:43:29 \tWARN \tSolrResourceLoader \tCan't find (or read) directory to add to classloader: /non/existent/dir/yields/warning (resolved as: /non/existent/dir/yields/warning).\n09:43:29 \tWARN \tSolrResourceLoader \tCan't find (or read) directory to add to classloader: /non/existent/dir/yields/warning (resolved as: /non/existent/dir/yields/warning).\n09:43:29 \tWARN \tSolrResourceLoader \tCan't find (or read) directory to add to classloader: /non/existent/dir/yields/warning (resolved as: /non/existent/dir/yields/warning).\n09:46:15 \tERROR \tShardLeaderElectionContext \tThere was a problem trying to register as the leader:org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists for /collections/ctest.test.3521/leaders/shard1\n09:46:15 \tWARN \tElectionContext \tcancelElection did not find election node to remove\n09:46:16 \tWARN \tRecoveryStrategy \tStopping recovery for zkNodeName=core_node1core=ctest.test.3521\n09:46:17 \tERROR \tRecoveryStrategy \tError while trying to recover. core=ctest.test.3521:org.apache.solr.common.SolrException: No registered leader was found,\u200b collection:ctest.test.3521 slice:shard1\n09:46:17 \tERROR \tRecoveryStrategy \tRecovery failed - trying again... (0) core=ctest.test.3521\n09:46:17 \tERROR \tRecoveryStrategy \tRecovery failed - interrupted. core=ctest.test.3521\n09:46:17 \tERROR \tRecoveryStrategy \tRecovery failed - I give up. core=ctest.test.3521\n09:46:18 \tWARN \tRecoveryStrategy \tStopping recovery for zkNodeName=core_node1core=ctest.test.3521\n10:01:58 \tERROR \tSolrCore \torg.apache.solr.common.SolrException: Error handling 'status' action\n10:01:58 \tERROR \tSolrDispatchFilter \tnull:org.apache.solr.common.SolrException: Error handling 'status' action\n10:15:59 \tERROR \tZkController \tError getting leader from zk\n10:15:59 \tERROR \tZkController \tError registering SolrCore:org.apache.solr.common.SolrException: Error getting leader from zk for shard shard1\n10:16:18 \tERROR \tSolrCore \torg.apache.solr.common.SolrException: Error handling 'status' action\n10:16:18 \tERROR \tSolrDispatchFilter \tnull:org.apache.solr.common.SolrException: Error handling 'status' action",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "author": "Shawn Heisey",
            "id": "comment-14018470",
            "date": "2014-06-05T04:47:06+0000",
            "content": "Solr itself does not have any hard limits on the number of cores that you can create, but you are relying on other software than Solr itself.\n\nIn this case, I believe that you are running into a limitation in zookeeper, a dependency for SolrCloud.  Zookeeper has a default max database size of 1MB.  Each new collection puts data into zookeeper, and eventually you're going to run into this database size limit.\n\nSearch the following page for \"jute.maxbuffer\" to find out how to increase the maximum database size in zookeeper:\n\nhttp://zookeeper.apache.org/doc/r3.4.6/zookeeperAdmin.html\n\nI'm going to close this issue, because this is most likely not a problem in Solr.  If it does turn out that there is a bug in Solr that is causing this problem, we can re-open the issue.\n\nPlease direct any followup to the Solr mailing list:\n\nhttp://lucene.apache.org/solr/discussion.html "
        },
        {
            "author": "HuangTongwen",
            "id": "comment-14018751",
            "date": "2014-06-05T12:47:58+0000",
            "content": "Thank you for your replys.I know that it is zookeeper's znode limit.But I tickout the 1MB limit.Then it happened like that.Sometime I create core with the parameter onStartup that I can enlarge cores more than 4000+ cores.Even if I use it than I increase cores.But I don't the loggers in solr board why I reload would happened to some errors,I think that it isn't znode limit.Any other error? "
        },
        {
            "author": "HuangTongwen",
            "id": "comment-14019517",
            "date": "2014-06-06T03:00:51+0000",
            "content": "I am sorry for the first time I decribe that problem is not complete.\nAt this experiment,we  have adjusted the max files numbers that linux can open.we set it 165556 it is very big than the default number.At the same time, we also have changed the znode size limit.We need know that why exception happened like that. Sometime I suspect that it is a problem in solr.\n "
        }
    ]
}