{
    "id": "SOLR-5963",
    "title": "Finalize interface and backport analytics component to 4x",
    "details": {
        "affect_versions": "4.9,                                            6.0",
        "status": "Closed",
        "fix_versions": [
            "5.0",
            "6.0"
        ],
        "components": [],
        "type": "Improvement",
        "priority": "Major",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "Now that we seem to have fixed up the test failures for trunk for the analytics component, we need to solidify the API and back-port it to 4x. For history, see SOLR-5302 and SOLR-5488.\n\nAs far as I know, these are the merges that need to occur to do this (plus any that this JIRA brings up)\n\nsvn merge -c 1543651 https://svn.apache.org/repos/asf/lucene/dev/trunk\nsvn merge -c 1545009 https://svn.apache.org/repos/asf/lucene/dev/trunk\nsvn merge -c 1545053 https://svn.apache.org/repos/asf/lucene/dev/trunk\nsvn merge -c 1545054 https://svn.apache.org/repos/asf/lucene/dev/trunk\nsvn merge -c 1545080 https://svn.apache.org/repos/asf/lucene/dev/trunk\nsvn merge -c 1545143 https://svn.apache.org/repos/asf/lucene/dev/trunk\nsvn merge -c 1545417 https://svn.apache.org/repos/asf/lucene/dev/trunk\nsvn merge -c 1545514 https://svn.apache.org/repos/asf/lucene/dev/trunk\nsvn merge -c 1545650 https://svn.apache.org/repos/asf/lucene/dev/trunk\nsvn merge -c 1546074 https://svn.apache.org/repos/asf/lucene/dev/trunk\nsvn merge -c 1546263 https://svn.apache.org/repos/asf/lucene/dev/trunk\nsvn merge -c 1559770 https://svn.apache.org/repos/asf/lucene/dev/trunk\nsvn merge -c 1583636 https://svn.apache.org/repos/asf/lucene/dev/trunk\n\nThe only remaining thing I think needs to be done is to solidify the interface, see comments from Yonik Seeley on the two JIRAs mentioned, although SOLR-5488 is the most relevant one.\n\nSteven Bower, Houston Putman and Yonik Seeley might be particularly interested here.\n\nI really want to put this to bed, so if we can get agreement on this soon I can make it march.",
    "attachments": {
        "SOLR-5963.patch": "https://issues.apache.org/jira/secure/attachment/12639523/SOLR-5963.patch",
        "SOLR-5963-v2.patch": "https://issues.apache.org/jira/secure/attachment/12673891/SOLR-5963-v2.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Erick Erickson",
            "id": "comment-13964832",
            "date": "2014-04-09T23:57:21+0000",
            "content": "From Yonik Seeley \n\nRemember, this was only committed to trunk not because of test failures (which we didn't know about when it was committed to trunk), but to give time to solidify the API (which is much harder to change once it's \"released\"). After a quick look, there's probably more to do here. The biggest thing that popped out at me was the structure of the response - NamedList in some places that should probably be SimpleOrderedMap. Add \"wt=json&indent=true\" to some sample requests and it's much easier to see.\n "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13964929",
            "date": "2014-04-10T03:13:58+0000",
            "content": "On \"the simplest thing that could possibly work\" theory, since I don't really have a concrete example of what Yonik Seeley is thinking here, I changed all the NamedLists in the analytics code to SimpleOrderedMaps. Which is a subclass of NamedList anyway and.... it all \"just works\". At least all the tests in the analytics code passed and  I do indeed get different output. Is that what you had in mind? "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13965395",
            "date": "2014-04-10T14:29:32+0000",
            "content": "Unless there are objections, I plan on committing this to 4.9 after the 4.8 branch happens so we have maximum time to let it bake in 4x before releasing it into the wild. "
        },
        {
            "author": "Steven Bower",
            "id": "comment-13966095",
            "date": "2014-04-11T01:03:02+0000",
            "content": "Erick Erickson sounds good to me... I was planning on doing about the same thing so thanks for jumping on it.. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13966529",
            "date": "2014-04-11T14:00:52+0000",
            "content": "I changed all the NamedLists in the analytics code to SimpleOrderedMaps. Which is a subclass of NamedList anyway and.... it all \"just works\".\n\nYeah, the XML output should be identical... it's JSON that changes.\nRepresenting things as a Map (JSON Object) is often the most natural mapping... but unfortunately many JSON clients lose ordering.  The only place to use NamedList is when ordering is more important than access-by-key.  Off the top of my head, there probably aren't any such places in the analytics component. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13967190",
            "date": "2014-04-11T22:40:51+0000",
            "content": "Now that the 4.8 branch has been cut, I'm going to commit this over the weekend after I get all of the merges done. We'll still have a chance to change things if we want before 4.9, I'd like to get this into the code base ASAP to let it bake a bit.\n "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13967276",
            "date": "2014-04-12T00:14:48+0000",
            "content": "Hold up here folks ... completely replacing all uses of NamedList with SImpleOrderedMap in the analytics response is definitely not the correct choice \u2013 looking at the docs, there are clearly situations where the order matters. (notably when dealing with facets)\n\nOff the top of my head based on experimenting (and comparing what's on trunk with what's in Erick's patch here in this issue)...\n\n\n\teach of the \"fieldFacets\" children (the per-field structure) needs to be an named list so that \"olap.<request>.fieldfacet.<field>.sortstatistic\" option will still be useful\n\teach of the \"\"rangeFacets\" children (the per-field structure) needs to be a named list so that range buckets will be n the correct order\n\n\n\n... there may be other cases where using a NamedList is important \u2013 those are just the ones that jumped out at me immediately. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13967550",
            "date": "2014-04-12T15:32:17+0000",
            "content": "Chris:\n\nI'm flying a little blind here. Could you cut/paste the URLs you were using so I know what you're talking about?\n\nThanks,\nErick "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13968937",
            "date": "2014-04-14T22:26:59+0000",
            "content": "Erick: I'm pretty sure i'm more blind then you as far as this code \u2013 i just started looking at it today \n\nIn any cases, lst friday i was reading the docs on this feature and playing around with some analytics requests using the example data.  Here's a an example URL that shows what i was talking about as far as the NamedList stuff (note: you have to modify the schema to make \"cat\" use docValues for the facet stuff in the AnalyticsComponent to work) ...\n\nhttp://localhost:8983/solr/select?o.hoss.qf=qfacet&o.hoss.qf.qfacet.query=name:apple&facet.field=cat&indent=true&wt=json&q=popularity:[*%20TO%20*]&facet=true&o.hoss.s.price_count=count%28price%29&fl=id,price,popularity&rows=1&olap=true&o.hoss.rangefacet=price&o.hoss.s.min_price=min%28price%29&o.hoss.s.max_price=max%28price%29&o.hoss.s.stddev_price=stddev%28price%29&o.hoss.rangefacet.price.gap=result%28stddev_price%29&o.hoss.rangefacet.price.start=result%28min_price%29&o.hoss.rangefacet.price.end=result%28max_price%29&o.hoss.fieldfacet.cat.ss=yak&o.hoss.fieldfacet=cat&o.hoss.s.foo=sum%28price%29&o.hoss.s.yak=sum%28popularity%29\n\nWith your existing \"use SimpleOrderedMap\" everywhere, the results include sections like this...\n\n\n...\n      \"fieldFacets\":{\n        \"cat\":{\n          \"electronics\":{\n            \"foo\":2772.3200187683105,\n            \"max_price\":649.99,\n            \"min_price\":11.5,\n            \"price_count\":11,\n            \"stddev_price\":196.77880239587424,\n            \"yak\":63.0},\n          \"graphics card\":{\n            \"foo\":1129.9400024414062,\n            \"max_price\":649.99,\n...\n      \"rangeFacets\":{\n        \"price\":{\n          \"[0.0 TO 539.1075)\":{\n            \"foo\":2402.280040740967,\n            \"max_price\":479.95,\n            \"min_price\":0.0,\n...\n\n\n\n...which means that clients parsing that JSON will wind up with maps for each of those {...} blocks \u2013 losing the ordering of the facet term results (ignoring the \"o.hoss.fieldfacet.cat.ss=yak\" param) and the ranges won't be in order.\n\ni started poking arround into the code and cobbled together this revised patch, which uses NamedLists for those two situations, and makes the corrisponding sections of the results look like this...\n\n\n...\n      \"fieldFacets\":{\n        \"cat\":[\n          \"electronics\",{\n            \"foo\":2772.3200187683105,\n            \"max_price\":649.99,\n            \"min_price\":11.5,\n            \"price_count\":11,\n            \"stddev_price\":196.77880239587424,\n            \"yak\":63.0},\n          \"graphics card\",{\n            \"foo\":1129.9400024414062,\n            \"max_price\":649.99,\n...\n      \"rangeFacets\":{\n        \"price\":[\n          \"[0.0 TO 539.1075)\",{\n            \"foo\":2402.280040740967,\n            \"max_price\":479.95,\n            \"min_price\":0.0,\n...\n\n\n\nBased on my reading of the docs, i think those are the only 2 places where using a NamedList to preserve the order is really important.\n\n\n\nI do however have some other broader concerns about the user API based on my limited experimentation so far...\n\n\n\tinput validation: when trying to build up requests, i ran into several situations where i got NullPointerExceptions, or ArrayIndexOutOfBoundsException, or other confusing error messages that weren't helpful for figuring out what i did wrong because of things like the component assuming certain params will exist if other params exist w/o actaully validating the input.  For example, in this URL when trying to do field facet sorting on a stat that doesn't exist (because of atypo) you get an AIOOBE: http://localhost:8983/solr/select?q=*:*&rows=0&olap=true&o.hoss.fieldfacet=cat&o.hoss.fieldfacet.cat.ss=fooo&o.hoss.s.foo=sum%28price%29\n\terror handling \u2013 while looking into the NamedList thing, i found some code like this which definitely scares me:\n\n      } catch (IOException e) {\n        log.warn(\"Analytics request '\"+areq.getName()+\"' failed\", e);\n        continue;\n      }\n\n\n\tI'm a bit concerned about the \"Statistical Expressions\" syntax that's added here \u2013 for a couple of differnet reasons:\n\t\n\t\t\"Expressions\" is a concept that's already been added to Lucene that means something else, and there's other work in progress in SOLR-4787 to bring that into Solr - i anticipate some terminology confusion.\n\t\tregardless of what we call these expressions, the subtlties of the \"Aggregate Mapping Operations/Expressions\" vs the \"Aggregations\" vs the \"Field Mapping Operations\" seems ripe for a lot of consusion about when/how you can wrap one in the other \u2013 especially since the list of \"Field Mapping Operations\" looks very similar to the list of \"Aggregate Mapping Operations/Expressions\" but is evidently not exactly the same list. (I haven't delved into the code enough to be clear if that's just a doc mistake)  I'm wondering if the syntax shouldn't have some sort of more explicit visual cue to make it clear what's an \"aggregation\" vs what are \"operations\"\n\t\tIn general, the syntax looks just like the valuesource syntax \u2013 even some of the function names are identical \u2013 but it's not the same thing, and those \"functions\" wrk very differently, which is also very confusing.\n\t\t\n\t\t\tperhaps something as simple as changing the \"Aggregations\" to always use uppercase only would help address the above 2 points?\n\t\t\n\t\t\n\t\tonce i finally understood the distinction between \"Field Mapping Operations\" and \"Aggregations\" i now find myself wondering why \"Field Mapping Operations\" exist at all given the large number of ValueSourceParsers available?  Why not just allow \"Aggregations\" to wrap any ValueSources  by delegating to ValueSourceParsers using the existing syntax?\n\t\n\t\n\tDistributed support \u2013 If we focus solely on the API questions for a moment, w/o worrying about the implementation details (because I'm not a math guy and i don't understand the details enough to even pretend i'm a math guy for the purposes of this conversation): From what i understand based on other comments, it sounds like some of these \"Aggregations\" can be efficiently supported in a distributed/sharded setup, but others just plain can't ever be supported because of what's involved in computing them in the aggregate across nodes.  If that's the case, then we need to think about how the component will behave in a distributed setup if you try to use an aggregate that isn't supported.  The last thing we want is silently appear to work but compute nothing \u2013 we want to make sure there is some sort of error message that makes it clear to the user what part of their analytics request is/isn't supported.\n\n\n "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13983987",
            "date": "2014-04-29T04:40:26+0000",
            "content": "Hmmm, there have been several discussions around this, and the question now is whether this should be  back-ported or not.\n\nGiven that the current stats component doesn't supported distributed Solr, one suggestion is to move this to a contrib for the time being and then put distributed statistics in to the main-line code as we can. This may mean there are fewer capabilities. If that's acceptable, I'll start working toward that goal.\n\nSo that would mean:\n1> pull this out of trunk\n2> put this into a contrib on trunk\n3> backport the contrib to 4x. "
        },
        {
            "author": "Gopal Patwa",
            "id": "comment-14050764",
            "date": "2014-07-02T21:53:19+0000",
            "content": "Hi Eric, could you add this patch as contrib to 4.x, so other folks can use it. I tried applying this patch to 4.9 but did not work may be it was created before 4.9 "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-14050833",
            "date": "2014-07-02T22:59:27+0000",
            "content": "Not at this time. This is in considerable flux at the moment, I'm not entirely sure it will be backported or whether we'll instead start over with the pluggable analytics.\n\nApplying the patch won't really help either. You need to merge all the revisions as I've outlined.\n\nBest,\nErick "
        },
        {
            "author": "Houston Putman",
            "id": "comment-14051811",
            "date": "2014-07-03T18:57:03+0000",
            "content": "Hoss Man, sorry I just found this issue. I can address your concern about the statistical expressions.\n\n\n\tI have no issue changing the name of Expressions to something that doesn't conflict with existing lucene/solr stuff. I named it that because that is what they are, mathematical expressions.\n\tThe difference between the three can be confusing when you first look at it, but I think the difference between \"Aggregates\" and the other two are pretty self-explanatory when you start to actually use them. First of all \"Aggregates\" aggregate unspecified amounts of data to a single value (such as median, average, standard deviation, etc.) these are statistics tools. The other two are a way of mapping(transforming/combining) one or more pieces of data into one piece of data (this piece of data may be 0 or 1 dimensional, so a single value or an array), these are regular mathematical tools like add, subtract, multiply, etc. So you can use \"Aggregate Mapping Operations/Expressions\" and \"Field Mapping Operations\" in the exact same way without thinking about it, the only difference between the two is that one maps multiple lists into one list and the other  maps multiple values into one value.\nActually after typing this up I agree that the documentation of the feature could be significantly improved, but I am not sure a syntactical difference between aggregates and the other two are necessary since they don't share much functionality (really just \"sum\" and \"add\"). Also the naming of \"Aggregate Mapping Operations/Expressions\" and \"Field Mapping Operations\" should definitely be changed.\n\tOk, I'm confused about this point. \"Field Mapping Operations\" are ValueSource parsers... I used existing ones and added some of my own.\n\n "
        },
        {
            "author": "Talat UYARER",
            "id": "comment-14165132",
            "date": "2014-10-09T13:46:26+0000",
            "content": "Hi Erick Erickson,\n\nI create a patch for Solr 4.9. Is this enoug for the issue ?  "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-14165186",
            "date": "2014-10-09T14:40:21+0000",
            "content": "Talat:\n\nThis is in flux at the moment, I hope that in the not-too-distant future we backport the analytics component as a contrib rather into the mainline code. So while you can use the patch you created, we'll use another mechanism and (I hope) get this in 5.0.\n\nOnce that's done, it'll be the same code as this though just in a little different place. So whatever you build to use your patch should require minimal work to make work in 5.x.\n\nSorry for the confusion.\nErick "
        },
        {
            "author": "Talat UYARER",
            "id": "comment-14165510",
            "date": "2014-10-09T18:41:02+0000",
            "content": "Erick Erickson,\n\nWhat is other mechanisim ? Is it QueryAnalytics ? Does anyone develop other mechanism ? if you want to help, I can help you.  "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-14165762",
            "date": "2014-10-09T21:20:39+0000",
            "content": "the \"other mechanism\" is just making it a contrib rather than part of the mainline code. Yonik put up a patch to trunk recently here: https://issues.apache.org/jira/browse/SOLR-5302\n\nI haven't looked at that, but the way forward would be to try to apply that patch to the current 5x branch and see if it has any problems and go from there. Any testing you can do would be great!\n\nWarning, though. This might get a bit hairy, so you're warned! "
        },
        {
            "author": "Talat UYARER",
            "id": "comment-14165803",
            "date": "2014-10-09T21:42:36+0000",
            "content": "I used Yori's patch. I backported from trunk to 4.9.1 branch. In my patch Analytics Component  is in contrib folder. Is this enough for the issue ?  "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-14184686",
            "date": "2014-10-26T22:40:48+0000",
            "content": "The analytics component has been moved to a contrib. Also, moving analytics forward needs to work in distributed mode so closing this. "
        },
        {
            "author": "Anshum Gupta",
            "id": "comment-14332629",
            "date": "2015-02-23T05:01:03+0000",
            "content": "Bulk close after 5.0 release. "
        }
    ]
}