{
    "id": "LUCENE-7231",
    "title": "Problem with NGramAnalyzer, PhraseQuery and Highlighter",
    "details": {
        "resolution": "Fixed",
        "affect_versions": "5.4.1",
        "components": [
            "modules/highlighter"
        ],
        "labels": "",
        "fix_versions": [
            "5.5.2",
            "5.6",
            "6.0.1",
            "6.1"
        ],
        "priority": "Major",
        "status": "Closed",
        "type": "Bug"
    },
    "description": "Using the Highlighter with N-GramAnalyzer and PhraseQuery and searching for a substring with length = N yields the following exception:\n\n\njava.lang.IllegalArgumentException: Less than 2 subSpans.size():1\nat org.apache.lucene.search.spans.ConjunctionSpans.<init>(ConjunctionSpans.java:40)\nat org.apache.lucene.search.spans.NearSpansOrdered.<init>(NearSpansOrdered.java:56)\nat org.apache.lucene.search.spans.SpanNearQuery$SpanNearWeight.getSpans(SpanNearQuery.java:232)\nat org.apache.lucene.search.highlight.WeightedSpanTermExtractor.extractWeightedSpanTerms(WeightedSpanTermExtractor.java:292)\nat org.apache.lucene.search.highlight.WeightedSpanTermExtractor.extract(WeightedSpanTermExtractor.java:137)\nat org.apache.lucene.search.highlight.WeightedSpanTermExtractor.getWeightedSpanTerms(WeightedSpanTermExtractor.java:506)\nat org.apache.lucene.search.highlight.QueryScorer.initExtractor(QueryScorer.java:219)\nat org.apache.lucene.search.highlight.QueryScorer.init(QueryScorer.java:187)\nat org.apache.lucene.search.highlight.Highlighter.getBestTextFragments(Highlighter.java:196)\n\n\n\nBelow is a JUnit-Test reproducing this behavior. In case of searching for a string with more than N characters or using NGramPhraseQuery this problem doesn't occur.\nWhy is it that more than 1 subSpans are required?\n\n\npublic class HighlighterTest {\n\n   @Rule\n   public final ExpectedException exception = ExpectedException.none();\n\n   @Test\n   public void testHighlighterWithPhraseQueryThrowsException() throws IOException, InvalidTokenOffsetsException {\n\n       final Analyzer analyzer = new NGramAnalyzer(4);\n       final String fieldName = \"substring\";\n\n       final List<BytesRef> list = new ArrayList<>();\n       list.add(new BytesRef(\"uchu\"));\n       final PhraseQuery query = new PhraseQuery(fieldName, list.toArray(new BytesRef[list.size()]));\n\n       final QueryScorer fragmentScorer = new QueryScorer(query, fieldName);\n       final SimpleHTMLFormatter formatter = new SimpleHTMLFormatter(\"<b>\", \"</b>\");\n\n       exception.expect(IllegalArgumentException.class);\n       exception.expectMessage(\"Less than 2 subSpans.size():1\");\n\n       final Highlighter highlighter = new Highlighter(formatter,TextEncoder.NONE.getEncoder(), fragmentScorer);\n       highlighter.setTextFragmenter(new SimpleFragmenter(100));\n       final String fragment = highlighter.getBestFragment(analyzer, fieldName, \"Buchung\");\n\n       assertEquals(\"B<b>uchu</b>ng\",fragment);\n\n   }\n\npublic final class NGramAnalyzer extends Analyzer {\n\n   private final int minNGram;\n\n   public NGramAnalyzer(final int minNGram) {\n       super();\n       this.minNGram = minNGram;\n   }\n\n   @Override\n   protected TokenStreamComponents createComponents(final String fieldName) {\n       final Tokenizer source = new NGramTokenizer(minNGram, minNGram);\n       return new TokenStreamComponents(source);\n   }\n\n}\n\n}",
    "attachments": {
        "LUCENE-7231.patch": "https://issues.apache.org/jira/secure/attachment/12804392/LUCENE-7231.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "id": "comment-15286414",
            "author": "Alan Woodward",
            "date": "2016-05-17T11:18:03+0000",
            "content": "Here's a patch including your test case and a fix - WeightedSpanTermExtractor needed to check if a PhraseQuery only had one term, and if so rewrite to a SpanTermQuery rather than a SpanNearQuery. "
        },
        {
            "id": "comment-15290713",
            "author": "ASF subversion and git services",
            "date": "2016-05-19T08:49:03+0000",
            "content": "Commit 7793c06a30eb25ee08ee11a57ca696d3da4744b5 in lucene-solr's branch refs/heads/master from Alan Woodward\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=7793c06 ]\n\nLUCENE-7231: WeightedSpanTermExtractor correctly deals with single-term PhraseQuery "
        },
        {
            "id": "comment-15290718",
            "author": "ASF subversion and git services",
            "date": "2016-05-19T08:50:32+0000",
            "content": "Commit 35024d3edc52cb20c7f36860da750cda694a3311 in lucene-solr's branch refs/heads/branch_6x from Alan Woodward\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=35024d3 ]\n\nLUCENE-7231: WeightedSpanTermExtractor correctly deals with single-term PhraseQuery "
        },
        {
            "id": "comment-15290721",
            "author": "Alan Woodward",
            "date": "2016-05-19T08:51:32+0000",
            "content": "Thanks Eva! "
        },
        {
            "id": "comment-15290737",
            "author": "Eva Popenda",
            "date": "2016-05-19T09:01:08+0000",
            "content": "Thank you, Alan, for fixing this! "
        },
        {
            "id": "comment-15292077",
            "author": "Steve Rowe",
            "date": "2016-05-19T20:25:55+0000",
            "content": "Reopening to backport to 6.0.1. "
        },
        {
            "id": "comment-15292080",
            "author": "ASF subversion and git services",
            "date": "2016-05-19T20:26:51+0000",
            "content": "Commit 2457d96e37ba711b9d1ac0e74ed405a9917a0f7d in lucene-solr's branch refs/heads/branch_6_0 from Alan Woodward\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=2457d96 ]\n\nLUCENE-7231: WeightedSpanTermExtractor correctly deals with single-term PhraseQuery "
        },
        {
            "id": "comment-15305386",
            "author": "Steve Rowe",
            "date": "2016-05-28T13:38:30+0000",
            "content": "Bulk close issues included in the 6.0.1 release. "
        },
        {
            "id": "comment-15332678",
            "author": "Steve Rowe",
            "date": "2016-06-15T22:00:00+0000",
            "content": "Reopening to backport to 5.6 and 5.5.2. "
        },
        {
            "id": "comment-15332687",
            "author": "ASF subversion and git services",
            "date": "2016-06-15T22:03:06+0000",
            "content": "Commit 90e823ed37edcce3984296ba6f16654d47f65d64 in lucene-solr's branch refs/heads/branch_5_5 from Alan Woodward\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=90e823e ]\n\nLUCENE-7231: WeightedSpanTermExtractor correctly deals with single-term PhraseQuery "
        },
        {
            "id": "comment-15332688",
            "author": "ASF subversion and git services",
            "date": "2016-06-15T22:03:07+0000",
            "content": "Commit c92703d3875bf8a47ff828d5910f78772e3841af in lucene-solr's branch refs/heads/branch_5x from Alan Woodward\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=c92703d ]\n\nLUCENE-7231: WeightedSpanTermExtractor correctly deals with single-term PhraseQuery "
        },
        {
            "id": "comment-15425192",
            "author": "Thomas Kappler",
            "date": "2016-08-17T19:10:44+0000",
            "content": "The above commits fixed the issue for PhraseQuery, but it still exists for MultiPhraseQuery.\n\nI have a test case and a patch, although they are for 5.5.0 which is what we use. I can update the patch, though. Should I submit a patch against the 5x branch?\n "
        },
        {
            "id": "comment-15426614",
            "author": "David Smiley",
            "date": "2016-08-18T15:12:58+0000",
            "content": "Since this issue is already in a release (multiple in fact) file a new issue please. "
        },
        {
            "id": "comment-15426644",
            "author": "Thomas Kappler",
            "date": "2016-08-18T15:30:08+0000",
            "content": "Thanks David. Filed LUCENE-7417. "
        }
    ]
}