{
    "id": "LUCENE-1314",
    "title": "IndexReader.clone",
    "details": {
        "labels": "",
        "priority": "Minor",
        "components": [
            "core/index"
        ],
        "type": "New Feature",
        "fix_versions": [
            "2.9"
        ],
        "affect_versions": "2.3.1",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "Based on discussion http://www.nabble.com/IndexReader.reopen-issue-td18070256.html.  The problem is reopen returns the same reader if there are no changes, so if docs are deleted from the new reader, they are also reflected in the previous reader which is not always desired behavior.",
    "attachments": {
        "lucene-1314.patch": "https://issues.apache.org/jira/secure/attachment/12384513/lucene-1314.patch",
        "LUCENE-1314.patch": "https://issues.apache.org/jira/secure/attachment/12395766/LUCENE-1314.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2008-06-23T17:13:51+0000",
            "content": "lucene-1314.patch\n\nFirst cut at this, seems to work as desired.  Need to come up with a test case for it.  \n\nDoes anyone know how to turn off Eclipse automatically changing the import statements?  I am not making it reformat but if I edit some code in a file it sees fit to reformat the imports.   ",
            "author": "Jason Rutherglen",
            "id": "comment-12607296"
        },
        {
            "date": "2008-06-24T13:23:44+0000",
            "content": "A package protected field \"boolean openNewFieldsReader = true;\" (defaults to true to mimic previous behavior) should be added to SegmentReader to allow subclasses to determine if they want a new fieldsReader opened everytime a reopen occurs.  The SegmentReader.doClose would need to not close fieldsReader if the openNewFieldsReader was set to false.\n\nThe SegmentReader.reopenSegment method directly instantiates a SegmentReader rather than using IMPL like SegmentReader.get(Directory dir, SegmentInfo si, SegmentInfos sis, boolean closeDir, boolean ownDir, int readBufferSize, boolean  doOpenStores) does.\n\nIn my SegmentReader subclass I am passing a lock and passing a reference to fieldsReader for global locking and a single fieldsReader across all instances.  Otherwise there are too many instances of fieldsReader and file descriptors will be used up.   ",
            "author": "Jason Rutherglen",
            "id": "comment-12607609"
        },
        {
            "date": "2008-06-24T15:38:11+0000",
            "content": "lucene-1314.patch\n\nIncluded the changes mentioned to allow a subclass of SegmentReader to not load fieldsReader on every reopen.  Added the IMPL based instantiation in reopenSegment.  SegmentReader.doClose does not close fieldsReader if openNewFieldsReader is false. ",
            "author": "Jason Rutherglen",
            "id": "comment-12607654"
        },
        {
            "date": "2008-06-24T16:55:48+0000",
            "content": "lucene-1314.patch\n\nAdded SegmentReader protected BitVector cloneDeletedDocs() that allows subclasses to do the cloning.  This will allow for pooling reuse if many reopens occur and many BitVectors are created.   ",
            "author": "Jason Rutherglen",
            "id": "comment-12607681"
        },
        {
            "date": "2008-06-25T05:01:57+0000",
            "content": "At first glance, my opinion was that adding this flag to reopen() is confusing. reopen()'s current behavior is explained well in the documentation, and has a particular use case in mind (checking if the index has changed, and if it has, reopen it). Frankly, I didn't understand why reopen() should (even with the addition of a new parameter) clone or \"copy on write\" the IndexReader when the index hasn't changed.\nIf this capability is needed, wouldn't it have been clearer if IndexReader had some new clone() or copyOnWrite() (in IndexReader's case, a write would actually be a delete...) method that can be called to get a new object that behaves independently from the previous one when it comes to writing (again, a delete)?\nIn your code, you could then do something like\n\nnewIndexReader = indexReader.reopen();\nif(newIndexReader==indexReader)\n  newIndexReader = indexReader.clone(); // copy on write\nelse {\n   oldIndexReader.close(); // most applications won't do this here, but never mind now.\n}\nindexReader = newIndexReader;\n\nI thought that this was a cleaner API, because reopen() isn't complicated with an extra flag that has nothing to do with its intended function, and the new clone() or copyOnWrite() method can also be used in other situations when you want different objects of the same index to handle deletes separately.\n\nBut on second glance, it dawned on me: You can't actually delete on both objects at once, because when you start deleting in one object, it holds a lock and then you can't do deletions in the second object! So I have to admit, the usefulness of of a general clone/copyOnWrite feature for IndexReader is quite limited. My suggestion above can still be the API, but I admit it will hardly be useful in any situation except (the rare situation nowadays of?) a reopen() and later deletes. ",
            "author": "Nadav Har'El",
            "id": "comment-12607857"
        },
        {
            "date": "2008-06-25T10:52:50+0000",
            "content": "In my SegmentReader subclass I am passing a lock and passing a reference to fieldsReader for global locking and a single fieldsReader across all instances. Otherwise there are too many instances of fieldsReader and file descriptors will be used up.\n\nMaybe instead we should just fix access to FieldsReader to be thread safe, either by making FieldsReader itself thread safe, or by doing something similar to what's done for TermVectorsReader (where each thread makes a \"shallow\" clone of the original TermVectorsReader, held in a ThreadLocal instance).  If we do that, then in SegmentReader.doReopen()  we never have to clone FieldsReader. ",
            "author": "Michael McCandless",
            "id": "comment-12607954"
        },
        {
            "date": "2008-06-25T13:39:20+0000",
            "content": "Here is the code of the SegmentReader subclass.  Using the clone terminology would work as well, inside of SegmentReader the clone would most likely reuse SegmentReader.reopenSegment.  The subclass turns off locking by overriding acquireWriteLock and having it do nothing.  I do not know a general fix for the locking issue mentioned \"it holds a lock and then you can't do deletions in the second object\".  Perhaps there is a way using lock less commits.  It is possible to have SegmentReader implement if deletes occur to an earlier IndexReader and a flush is tried it fails, rather than fail in a newer IndexReader like it would now.  This would require keeping track of later IndexReaders which is something Ocean does outside of IndexReader.  \n\nAs far as the FieldsReader, given how many SegmentReaders Ocean creates (up to one per update), a shallow clone threadlocal would still potentially create many file descriptors.  I would rather see a synchronized FieldsReader, or simply use the approach in the code below.  The external lock used seems ok because there is little competition for reading Documents, no more than normal a Lucene application using a single IndexReader loading documents for N results.  \n\n\npublic class OceanSegmentReader extends SegmentReader {\n  protected ReentrantLock fieldsReaderLock;\n  \n  public OceanSegmentReader() {\n    openNewFieldsReader = false;\n  }\n  \n  protected void doInitialize() {\n    fieldsReaderLock = new ReentrantLock();\n  }\n  \n  protected void acquireWriteLock() throws IOException {\n  }\n  \n  protected synchronized DirectoryIndexReader doReopen(SegmentInfos infos, boolean force) throws CorruptIndexException, IOException {\n    OceanSegmentReader segmentReader = (OceanSegmentReader)super.doReopen(infos, force);\n    segmentReader.fieldsReaderLock = fieldsReaderLock;\n    return segmentReader;\n  }\n  \n  /**\n   * @throws CorruptIndexException\n   *           if the index is corrupt\n   * @throws IOException\n   *           if there is a low-level IO error\n   */\n  public synchronized Document document(int n, FieldSelector fieldSelector) throws CorruptIndexException, IOException {\n    ensureOpen();\n    if (isDeleted(n))\n      throw new IllegalArgumentException(\"attempt to access a deleted document\");\n    fieldsReaderLock.lock();\n    try {\n      return getFieldsReader().doc(n, fieldSelector);\n    } finally {\n      fieldsReaderLock.unlock();\n    }\n  }\n}\n\n ",
            "author": "Jason Rutherglen",
            "id": "comment-12608039"
        },
        {
            "date": "2008-06-27T01:34:22+0000",
            "content": "Using the patch and the above subclass of SegmentReader received the following bug.  I am assuming it has something to do with SegmentInfos committing.  Ideally the new clone method of IndexReader will avoid things like reloading SegmentInfos from disk each time.  That will probably slow down the rapid updates too much.\n\n\n1) testSearch(org.apache.lucene.ocean.TestSearch)java.lang.AssertionError: delete count mismatch: info=1 vs BitVector=5\nat org.apache.lucene.index.SegmentReader.loadDeletedDocs(SegmentReader.java:365)\nat org.apache.lucene.index.SegmentReader.initialize(SegmentReader.java:328)\nat org.apache.lucene.index.SegmentReader.get(SegmentReader.java:267)\nat org.apache.lucene.index.SegmentReader.get(SegmentReader.java:235)\nat org.apache.lucene.index.DirectoryIndexReader$1.doBody(DirectoryIndexReader.java:90)\nat org.apache.lucene.index.SegmentInfos$FindSegmentsFile.run(SegmentInfos.java:649)\nat org.apache.lucene.index.DirectoryIndexReader.open(DirectoryIndexReader.java:97)\nat org.apache.lucene.index.IndexReader.open(IndexReader.java:213)\nat org.apache.lucene.index.IndexReader.open(IndexReader.java:209)\n\n ",
            "author": "Jason Rutherglen",
            "id": "comment-12608635"
        },
        {
            "date": "2008-06-29T09:44:46+0000",
            "content": "Using the patch and the above subclass of SegmentReader received the following bug. I am assuming it has something to do with SegmentInfos committing. Ideally the new clone method of IndexReader will avoid things like reloading SegmentInfos from disk each time. That will probably slow down the rapid updates too much.\n\nRight, that exception happens because you are carrying your own deletedDocs in memory to the new SegmentReader without first saving them to the _X_N.del file for that segment.  The new clone() approach definitely should not reload the segments_N file, and thus not call SegmentReader.initialize. ",
            "author": "Michael McCandless",
            "id": "comment-12609071"
        },
        {
            "date": "2008-06-29T09:51:10+0000",
            "content": "It is possible to have SegmentReader implement if deletes occur to an earlier IndexReader and a flush is tried it fails, rather than fail in a newer IndexReader like it would now. This would require keeping track of later IndexReaders which is something Ocean does outside of IndexReader.\n\nI think this is tricky, since SegmentReader doesn't explicitly track whether there is a \"cloned\" reader out there.  As things stand now, there is no such thing as a cloned reader, and so the only way that another SegmentReader is out there is if there have been commits to the index, in which case isCurrent() returns false and the old reader will not allow deletes to be performed.  I suppose we could look at the refCount of the IndexReader: any reader that has been cloned and not yet closed will have a refCount > 1, whereas the last reader returned from a clone() call will have refCount 1.\n\nSo unless we try to track this, when there are N clones out there, any one of them will be allowed to grab the write lock when a change (deletion or setNorm) is attempted, thus preventing all the other clones (and all readers open on previous commits) from making changes. ",
            "author": "Michael McCandless",
            "id": "comment-12609072"
        },
        {
            "date": "2008-06-29T15:17:39+0000",
            "content": "lucene-1314.patch\n\nAdded fieldsReaderLocal to SegmentReader.  reopenSegment passed the fieldsReaderLocal and termVectorsLocal to the new SegmentReader.  In the current version, a new termVectorsLocal is created for each SegmentReader which made reuse of the previously created TermVectorsReaders for a thread unavailable.  The same is implemented for fieldsReaderLocal.  \n\nThe locking needs a default mechanism.  For my own purposes I will likely turn it off, the bug I posted was really the fault of the Ocean code since fixed.  \n\nWould like to be able to optionally have this line run in DirectoryIndexReader in reopen.  Does it need to be run on a clone?\n\nSegmentInfos infos = new SegmentInfos();\ninfos.read(directory, segmentFileName); ",
            "author": "Jason Rutherglen",
            "id": "comment-12609116"
        },
        {
            "date": "2008-07-01T05:10:18+0000",
            "content": "I haven't really been following this issue, but this comment caught my eye...\n\nSo unless we try to track this, when there are N clones out there, any one of them will be allowed to grab the write lock when a change (deletion or setNorm) is attempted, thus preventing all the other clones (and all readers open on previous commits) from making changes.\n\n...and gave me an erie sense of deja vu.  looking back at LUCENE-743, the original approach for reopen was based on cloning and prompted this comment from me...\n\nhttps://issues.apache.org/jira/browse/LUCENE-743?focusedCommentId=12534123#action_12534123\n\n...which led to some interesting discussion about what the semantics of cloning an IndexReader should be (even though ultimately cloning wasn't used).\n ",
            "author": "Hoss Man",
            "id": "comment-12609456"
        },
        {
            "date": "2008-07-02T18:26:04+0000",
            "content": "...which led to some interesting discussion about what the semantics of cloning an IndexReader should be (even though ultimately cloning wasn't used).\n\nIn fact that 2nd point you raised (\"what happens when you clone an IndexReader that has pending changes\") makes me nervous here.  I think I'd prefer that we disallow that (throw an exception when this is attempted).  Ie you can only clone a reader that has no pending changes.\n\nAlso Jason you added set/getWriteLock: how come you couldn't just customize LockFactory for that, instead?  Eg if you want to turn off locking you can just use NoLockFactory.\n\n\nWould like to be able to optionally have this line run in DirectoryIndexReader in reopen. Does it need to be run on a clone?\n\nSegmentInfos infos = new SegmentInfos();\ninfos.read(directory, segmentFileName);\n\nI agree that line should not run on clone(). ",
            "author": "Michael McCandless",
            "id": "comment-12609999"
        },
        {
            "date": "2008-07-02T22:05:54+0000",
            "content": "lucene-1314.patch\n\nSegmentReader.doReopen throws an IOException when deletedDocsDirty or normsDirty is true.  DirectoryIndexReader getLock and setLock removed.  Added isCurrent check in DirectoryIndexReader.doCommit, as per a few comments ago regarding making sure the commit only happens to the latest index. ",
            "author": "Jason Rutherglen",
            "id": "comment-12610065"
        },
        {
            "date": "2008-07-03T11:48:06+0000",
            "content": "I don't think we need to check isCurrent() in doCommit() because since\nthe reader holds the write lock it is necessarily current?\n\nI can't compile with your patch.  It seems like you have changes to\nBitVector.java which did't make it into the patch?  Eg the getBits()\nmethod.\n\nI attached a new version with these changes:\n\n\n\tThrow IllegalStateException if you try to clone a reader that has\n    pending changes.\n\n\n\n\n\tClone the SegmentInfos, instead of just taking a reference, in\n    DirectoryIndexReader\n\n\n\n\n\tChanged \"public abstract Object clone()\" in IndexReader to be a\n    method that throws UnsupportedOperationException instead\n\n\n\n\n\tRenamed a few things; removed some whitespace only diffs.\n\n\n\n\n\tFactored up doReopenOrClone into IndexReader\n\n\n\nOne difference between clone() and reopen() is you force the\ndeletedDocs BitVector to be cloned in SegmentReader during clone(),\nbut not during reopen().  With reopen() we \"declared\" that if you make\nchanges to your reopened reader, it's undefined what happens to your\nold readers.  Ie, it's a \"don't do that\" situation.\n\nBut with clone() the situation is reversed: the whole reason why you\nmake a clone() is to isolate any changes in the new reader from being\nvisible to the old reader.  Given that, I think you also must clone()\nthe norms right?\n\nJason could you add cloning of norms, and add some unit tests, to the\npatch?  Thanks.\n ",
            "author": "Michael McCandless",
            "id": "comment-12610203"
        },
        {
            "date": "2008-07-03T14:53:32+0000",
            "content": "> check isCurrent()\n\nI thought we wanted to check a commit on a clone that the index is current?  Does it need to be in a clone only portion of the code?  Which class is best?\n\n> clone() the norms \n\nWe need to clone norms.  I want to make cloning deletedDocs and norms optional mainly because it is a waste in Ocean to clone norms.  Is the best way to give the option parameters to the clone method (breaking Cloneable)?  An additional option could be readOnly.  Perhaps norms or deletedDocs becomes readOnly if they are ref copied and not cloned.  IndexReader.open and reopen would need a readOnly parameter.  Or should a subclass of SegmentReader handle cloning or refing norms and deletedDocs.\n\nI think it may be easiest to have readOnly be a part of this patch.  I wanted to separate out the FieldsReader synchronization code into a separate patch but then this patch would have been messed up without it (the new FieldsReader per SegmentReader issue).  Readonly may end up being similar.  \n\nThe newlines is another Eclipse thing I haven't figured out yet.   ",
            "author": "Jason Rutherglen",
            "id": "comment-12610244"
        },
        {
            "date": "2008-07-03T15:38:41+0000",
            "content": "I thought we wanted to check a commit on a clone that the index is current? Does it need to be in a clone only portion of the code? Which class is best?\n\nI think checking when a change is first made (and grabbing the write.lock to prevent others) is safer?  Else you could lose changes you had made.  Ie if there are clones out there, the first one that starts making changes prevents any others from doing so.  But I feel like I'm missing something about Ocean: was there some driver for checking on commit instead?\n\nWe need to clone norms. I want to make cloning deletedDocs and norms optional mainly because it is a waste in Ocean to clone norms. Is the best way to give the option parameters to the clone method (breaking Cloneable)? An additional option could be readOnly. Perhaps norms or deletedDocs becomes readOnly if they are ref copied and not cloned. IndexReader.open and reopen would need a readOnly parameter. Or should a subclass of SegmentReader handle cloning or refing norms and deletedDocs.\n\nIt'd be nice if we could do a copy-on-write approach.  This way no copy is made when you first clone, but if you go to make a change, it makes a private copy only at that point.  And you don't have to separately specify a readOnly up front only to find later you didn't pass in the right value.\n\nI think it may be easiest to have readOnly be a part of this patch. I wanted to separate out the FieldsReader synchronization code into a separate patch but then this patch would have been messed up without it (the new FieldsReader per SegmentReader issue). Readonly may end up being similar.\n\nMaybe instead we wait on the readOnly patch until we resolve this one (ie stage them)? ",
            "author": "Michael McCandless",
            "id": "comment-12610260"
        },
        {
            "date": "2008-07-03T18:03:52+0000",
            "content": "There are really only two options here and perhaps this API will work.  \n\n// true makes a copy of the data structure always, while false passes the reference if the data structure is read only or makes a copy if it is writeable. \nIndexReader.getCopy(boolean normsWriteable, boolean deletesWriteable)\nIndexReader.getCopyReadOnly() // defaults to getCopy(false, false)\n\nClone can be removed or default to getCopy(true, true).  The current APIs default to getCopy(true, true).  It is good to make this explicit here so that the deletedDocs or norms cannot be changed later when it is the clear intention of the code.  It is no different than RandomAccessFile(file, \"r\") and RandomAccessFile(file, \"rw\")  \n\nLucene is supposed to be designed for fast reads at the expense of writes, no?  This code in SegmentReader with the deletedDocs and norms synchronization goes against that.  I think it is important to figure out a solution to give users the option of removing synchronization in SegmentReader, users who are willing to give up a little bit in memory (norms or deletedDocs don't use very much anyways).  \n\n> copy-on-write approach\n\nIs the problem with isDeleted now.  The java.util.concurrent.CopyOnWriteArrayList for example uses a volatile list and synchronized update methods.  Which will not work because of JDK1.4.\n\n> driver for checking on commit \n\nYes, it is more of an assertion, it can be performed in Ocean as well.   ",
            "author": "Jason Rutherglen",
            "id": "comment-12610303"
        },
        {
            "date": "2008-07-03T18:55:35+0000",
            "content": "volatile should work on just about all 1.4.1+ JVMs, which I think is the required JVM level for Lucene anyway... ",
            "author": "robert engels",
            "id": "comment-12610318"
        },
        {
            "date": "2008-07-03T19:49:02+0000",
            "content": "Following up on the API comment, there can be a version of the norms or deletedDocs wrapper class for pre JDK1.5 that uses a synchronized accessor as demonstrated http://gee.cs.oswego.edu/dl/classes/EDU/oswego/cs/dl/util/concurrent/CopyOnWriteArrayList.java (works on JDK1.2 and above) and a version for JDK1.5 that uses volatile.  This is only for the writeable norms or deletedDocs anyways, but will yield results for users who continue to use the default API with a writeable IndexReader.  The null check can be synchronized and there can be a global setting that tells the IndexReader to instantiate a new deletedDocs or norms on init.   ",
            "author": "Jason Rutherglen",
            "id": "comment-12610330"
        },
        {
            "date": "2008-07-04T10:04:50+0000",
            "content": "Why would you ever need to make a read-only clone of a writable IndexReader?  In fact, once we have readOnly IndexReaders, why would you ever clone one?  The [precarious] use case that set us down this path (adding clone()) in the first place was to make a clone so that you could make changes to the clone without affecting the original reader.\n\nI think clone() should just clone() and not \"alter\" the readOnly-ness of the original IndexReader?  We could still then under the hood do copy-on-write.  We can just do this ourselves \u2013 keep a boolean isShared in SegmentReader that's true when more than one SegmentReader is referencing the norms/deletedDocs.\n\nI do think we should make IndexReader.open take a readOnly boolean (LUCENE-1030).  In fact, maybe we should go off do that one, first, since it may change our approach to clone?  (Ie swap the order of these two)? ",
            "author": "Michael McCandless",
            "id": "comment-12610510"
        },
        {
            "date": "2008-07-07T13:10:11+0000",
            "content": "lucene-1314.patch\n\nImplemented copy on write for norms and deletedDocs when a cloned SegmentReader is created.  A copy on write ref count is used to insure the correct number of copies are created.  \n\nIncludes a test case. ",
            "author": "Jason Rutherglen",
            "id": "comment-12611148"
        },
        {
            "date": "2008-07-08T12:36:18+0000",
            "content": "Jason, I had some problems with the latest patch.  First, it wouldn't compile, because createIndex was private in TestIndexReaderReopen.\n\nOnce I changed that to protected, I'm seeing this failure in TestStressIndexing2:\n\n    [junit] Testsuite: org.apache.lucene.index.TestStressIndexing2\n    [junit] Tests run: 2, Failures: 2, Errors: 0, Time elapsed: 9.596 sec\n\n    [junit] ------------- Standard Output ---------------\n    [junit] [stored/uncompressed,indexed,termVector,termVectorOffsets,termVectorPosition<f71:??? >, stored/uncompressed,indexed,tokenized,termVector,termVectorOffsets,termVectorPosition<f99:E J H J H F E C I C >, stored/uncompressed,indexed,omitNorms<id:1000085>]\n    [junit] [stored/uncompressed,indexed,termVector,termVectorOffsets,termVectorPosition<f27:???@?p+???l? >, stored/uncompressed,indexed,omitNorms<id:1000000>]\n    [junit] [stored/uncompressed,indexed,omitNorms<id:12>]\n    [junit] [stored/uncompressed,indexed,termVector,termVectorOffsets,termVectorPosition,omitNorms<f64:C >, stored/uncompressed,indexed,termVector,termVectorOffsets,termVectorPosition,omitNorms<f90:1???t?? >, stored/uncompressed,indexed,omitNorms<id:0>]\n    [junit] ------------- ---------------- ---------------\n    [junit] Testcase: testRandom(org.apache.lucene.index.TestStressIndexing2):\tFAILED\n    [junit] expected:<3> but was:<2>\n    [junit] junit.framework.AssertionFailedError: expected:<3> but was:<2>\n    [junit] \tat org.apache.lucene.index.TestStressIndexing2.verifyEquals(TestStressIndexing2.java:336)\n    [junit] \tat org.apache.lucene.index.TestStressIndexing2.verifyEquals(TestStressIndexing2.java:234)\n    [junit] \tat org.apache.lucene.index.TestStressIndexing2.verifyEquals(TestStressIndexing2.java:193)\n    [junit] \tat org.apache.lucene.index.TestStressIndexing2.testRandom(TestStressIndexing2.java:68)\n\n\n    [junit] Testcase: testMultiConfig(org.apache.lucene.index.TestStressIndexing2):\tFAILED\n    [junit] expected:<1> but was:<3>\n    [junit] junit.framework.AssertionFailedError: expected:<1> but was:<3>\n    [junit] \tat org.apache.lucene.index.TestStressIndexing2.verifyEquals(TestStressIndexing2.java:336)\n    [junit] \tat org.apache.lucene.index.TestStressIndexing2.verifyEquals(TestStressIndexing2.java:234)\n    [junit] \tat org.apache.lucene.index.TestStressIndexing2.verifyEquals(TestStressIndexing2.java:193)\n    [junit] \tat org.apache.lucene.index.TestStressIndexing2.testMultiConfig(TestStressIndexing2.java:97)\n\n\nAre you seeing this too? ",
            "author": "Michael McCandless",
            "id": "comment-12611556"
        },
        {
            "date": "2008-07-08T13:54:33+0000",
            "content": "I am seeing the error.  It is not norms because the test does not test norms.  It is either a problem with fieldsreader or deleted docs.   ",
            "author": "Jason Rutherglen",
            "id": "comment-12611585"
        },
        {
            "date": "2008-07-08T17:49:38+0000",
            "content": "lucene-1314.patch\n\ndocStoreOffset is now cloned in FieldsReader.clone() fixing the bug encountered by TestStressIndexing2. ",
            "author": "Jason Rutherglen",
            "id": "comment-12611715"
        },
        {
            "date": "2008-07-08T17:52:14+0000",
            "content": "lucene-1314.patch\n\nSame as previous, with TestIndexReaderClone ",
            "author": "Jason Rutherglen",
            "id": "comment-12611719"
        },
        {
            "date": "2008-07-10T14:11:08+0000",
            "content": "lucene-1314.patch\n\nAdded protected DirectoryIndexReader.allowCloneWithChanges which allows clones with changes to be made.  Added protected IndexReader.decRef(boolean flush) and protected IndexReader.close(boolean flush) which allows subclasses to optionally flush changes. ",
            "author": "Jason Rutherglen",
            "id": "comment-12612504"
        },
        {
            "date": "2008-07-10T14:28:53+0000",
            "content": "Added protected DirectoryIndexReader.allowCloneWithChanges which allows clones with changes to be made.\n\nThis makes me a bit nervous.  What does it \"mean\" to clone an IndexReader that has changes?  Normally Lucene only allows one writer at a time on the index. ",
            "author": "Michael McCandless",
            "id": "comment-12612511"
        },
        {
            "date": "2008-07-10T15:06:36+0000",
            "content": "Because Ocean does not flush to disk with every transaction (deleteDocument then clone the reader) there is a need to allow cloning of readers that have not flushed changes.  Rather than create a workaround, which I did that involves overriding clone and setting hasChanges=false, cloning and then setting hasChanges=true again, this seemed to be cleaner.   ",
            "author": "Jason Rutherglen",
            "id": "comment-12612525"
        },
        {
            "date": "2008-07-12T00:32:11+0000",
            "content": "Because Ocean does not flush to disk with every transaction (deleteDocument then clone the reader) there is a need to allow cloning of readers that have not flushed changes.\n\nBut when you clone a reader with pending changes, is the old reader's write lock revoked?  Meaning it is not allowed to commit (yet, continues to hold the changes it has)?  And the newly cloned reader gets the write lock?  Are further changes allowed against the old reader, or maybe it should become \"frozen\"? ",
            "author": "Michael McCandless",
            "id": "comment-12613025"
        },
        {
            "date": "2008-07-16T14:44:29+0000",
            "content": "lucene-1314.patch\n\nFixed bug in SegmentReader.reopenSegment that caused the ref count of deleted docs and norms to reset after the second clone.  Added test in TestIndexReaderClone to test for this.\n\nAnswering the question from a few comments ago, I don't think this patch needs to wait on IndexReader becoming read only.   ",
            "author": "Jason Rutherglen",
            "id": "comment-12613973"
        },
        {
            "date": "2008-09-15T14:49:44+0000",
            "content": "\nJason I'd like to bring closure on this one; I think it's a good\naddition.\n\nBut the fact that this patch implies it's possible to clone an\nIndexReader that has pending changes makes me nervous.\n\nSo, could you change the patch to not include the\n\"allowCloneWithChanges\" addition to IndexReader?  And, instead factor\nout the current logic in DirectoryIndexReader.reopen that skips\nchecking when there are pending changes or isCurrent() returns true\ninto a new method \"allowReopen()\"?  This way you can subclass and put\nOcean's logic (allowing a reader with pending changes to be cloned)\ninto allowReopen().\n\nThis way Lucene itself does not allow cloning a reader that has\nchanges.  But subclasses (Ocean) can still do so. ",
            "author": "Michael McCandless",
            "id": "comment-12631041"
        },
        {
            "date": "2008-09-16T15:07:51+0000",
            "content": "Looks like something changed such that the test case no longer works for the norms cloning.  Having some problems figuring out what changed as it used to work. ",
            "author": "Jason Rutherglen",
            "id": "comment-12631430"
        },
        {
            "date": "2008-09-17T13:30:55+0000",
            "content": "lucene-1314.patch\n\nThe TestIndexReaderClone sometimes fails on the norms byte comparison.  The TestIndexReaderReopen fails on the ref counting.  I am not sure why yet but will look into it. ",
            "author": "Jason Rutherglen",
            "id": "comment-12631770"
        },
        {
            "date": "2008-09-17T16:44:09+0000",
            "content": "Jason I'm seeing many other tests failing (besides TestIndexReaderReopen).  Are you seeing these too?  EG:\n\n\n    [junit] Testcase: testHangOnClose(org.apache.lucene.index.TestAddIndexesNoOptimize):\tCaused an ERROR\n    [junit] MockRAMDirectory: cannot close: there are still open files: {_0.fdx=13}\n    [junit] java.lang.RuntimeException: MockRAMDirectory: cannot close: there are still open files: {_0.fdx=13}\n    [junit] \tat org.apache.lucene.store.MockRAMDirectory.close(MockRAMDirectory.java:292)\n    [junit] \tat org.apache.lucene.index.TestAddIndexesNoOptimize.testHangOnClose(TestAddIndexesNoOptimize.java:537)\n\n\n\nThe failures all seem to be because *.fdx files are not being closed properly. ",
            "author": "Michael McCandless",
            "id": "comment-12631840"
        },
        {
            "date": "2008-09-17T17:07:55+0000",
            "content": "Hi Michael,\n\nIt used to work this patch.  It was not easy to implement the first time.  I did a merge of the new code and these are the resulting problems.  Do you know what has changed since 2.3.1?  Or around July?  I am surprised at some of the errors as they should be unrelated to how the patch works.  I may need to go ahead and break up the patch into the FieldsReader synchronization optimization (or is this already in trunk?) in order to isolate the issues.  What do you think?\n\nJason ",
            "author": "Jason Rutherglen",
            "id": "comment-12631850"
        },
        {
            "date": "2008-09-17T17:21:47+0000",
            "content": "Yes I am seeing the same error.   ",
            "author": "Jason Rutherglen",
            "id": "comment-12631855"
        },
        {
            "date": "2008-09-17T18:44:52+0000",
            "content": "OK I think you are missing a \"cloneableIndexStream.close()\" in FieldsReader.close.  For me that fixes all the tests failing with *.fdx \"still open\".\n\nBut I still see 5 failures in TestIndexReaderReopen.\n\nI may need to go ahead and break up the patch into the FieldsReader synchronization optimization (or is this already in trunk?) in order to isolate the issues.\n\nI think that's a good idea. ",
            "author": "Michael McCandless",
            "id": "comment-12631873"
        },
        {
            "date": "2008-12-10T18:57:28+0000",
            "content": "The remaining design issue with this patch is the writeLock.  It would seems best to share the writeLock and ref it across instances of clones SegmentReaders.  It is hurting my brain because it would be best to simply have a shared context object that represents all shared data between SegmentReaders but this probably will not work as it would move variables such as deletedDocs, norms, and the writeLock.   ",
            "author": "Jason Rutherglen",
            "id": "comment-12655315"
        },
        {
            "date": "2008-12-10T19:43:23+0000",
            "content": "Seems like 2 solutions to clone and pending updates in SegmentReader:\n\n1) Flush any pending changes on clone\n2) Throw an exception when the original SegmentReader receives new updates (i.e. deleteDocument is called) and on close does not flush the changes.  Flush throws an exception reading \"This segmentreader has pending changes and has been cloned and so cannot accept or flush updates\"  The problem with this one is it could lead to unpredictable behavior in that the user may assume the pending changes are being flushed (on close) and are not.  \n\nPerhaps both can be supported with IndexReader.clone(boolean autoFlush) where the autoFlush=true tells the clone method to flush pending updates (if there are any), and false means keep the pending changes but throw an exception on flush. ",
            "author": "Jason Rutherglen",
            "id": "comment-12655332"
        },
        {
            "date": "2008-12-10T22:19:19+0000",
            "content": "Decided to simply release the lock in SegmentReader when a clone occurs.  If the original segmentreader receives updates (such as deleteDocument) after being cloned then it throws a LockObtainFailedException.   ",
            "author": "Jason Rutherglen",
            "id": "comment-12655386"
        },
        {
            "date": "2008-12-10T23:02:37+0000",
            "content": "LUCENE-1314.patch\n\n\n\tSegmentReader.reopenSegment accepts doClone variable\n\tRef class created for SegmentReader\n\tTestIndexReaderClone focuses on testing SegmentReader\n\tTestIndexReaderClone creates an index, clones and tests the deletedDocs reference counting\n\tDuring a clone of a SegmentReader, the writeLock is released\n\tNorms are not copy on write yet\n\tTestIndexReaderReopen passes\n\n\n\nIf the general method looks ok, norms cloning will be implemented ",
            "author": "Jason Rutherglen",
            "id": "comment-12655403"
        },
        {
            "date": "2008-12-10T23:36:54+0000",
            "content": "LUCENE-1314.patch\n\n\n\tbytes now cloning properly compared to previous patch\n\n ",
            "author": "Jason Rutherglen",
            "id": "comment-12655429"
        },
        {
            "date": "2008-12-12T18:44:01+0000",
            "content": "LUCENE-1314.patch\n\n\n\tAdded TestIndexReaderCloneNorms because cloning the norms is really hard to do implemented as copy on write.  There seem to be many caveats such as whether or not the norms stream is still open?  testNormsRefCounting fails with a corruptedIndexException which I'm investigating.\n\n\n\nI now remember implementing a copy of just the bytes, and only editting them in the Norm object to get around these issues.  Basically on clone, new Norm objects and a Map is created but the byte array of the cloned norm is shared.  On a write, the bytes are cloned.  This gets around needing to deal with the reader norm reference counting used by reopen, though is this a good idea?\n\nI'll try that and see if it works.  Otherwise, suggestions besides hard cloning the norms for each clone? ",
            "author": "Jason Rutherglen",
            "id": "comment-12656109"
        },
        {
            "date": "2008-12-19T02:21:43+0000",
            "content": "LUCENE-1314.patch\n\n\n\tImplemented copying the writeLock reference in DirectorySegmentReader.doReopen to the cloned reader, readonly is set to true, acquireWriteLock throws LockObtainFailedException when readOnly is true\n\tTests try to generate LockObtainFailedException on a cloned reader by trying to update\n\n\n\nTODO:\n\n\tProbably needs more tests from TestIndexReaderReopen such as a multithreading one\n\n ",
            "author": "Jason Rutherglen",
            "id": "comment-12657976"
        },
        {
            "date": "2008-12-22T18:33:06+0000",
            "content": "LUCENE-1314.patch\n\n\n\tAdded TestIndexReaderClone.testParallelReader and testMixedReaders\n\tTest-core Lucene tests pass\n\n\n\nI request assistance in what type of code properly tests multi threading for cloning readers ",
            "author": "Jason Rutherglen",
            "id": "comment-12658617"
        },
        {
            "date": "2008-12-23T16:09:08+0000",
            "content": "\n> I request assistance in what type of code properly tests multi threading for cloning readers\nShouldn't cloning be synchronized, at least the step that transfers the write lock to the cloned reader?\n\nIt should also be synchronized to avoid acquisition of the write lock while the clone is underway.  Ie, only one of those can \"win\".\n\nThe first time a reader with pending changes is cloned, it transfers the write lock to the clone.  If that same reader gets cloned again, that's fine (but no write lock needs transferring again).\n\nBTW can you sync up your patch to the latest trunk?  Or, let me know which revision your patch is based on?  (I'm having trouble applying the patch). ",
            "author": "Michael McCandless",
            "id": "comment-12658863"
        },
        {
            "date": "2008-12-23T16:33:00+0000",
            "content": "LUCENE-1314.patch\n\n\n\tUpdated to work with trunk\n\tCleaned up commented code, removed unused variables\n\tAll tests pass\n\n\n\nMichael M.:\n\"Shouldn't cloning be synchronized, at least the step that transfers the write lock to the cloned reader?\"\n\nThe clone method is synchronized, is there something else that should be synchronized on?  I'm trying to figure out (if it's necessary) the right unit test for the synchronization.   ",
            "author": "Jason Rutherglen",
            "id": "comment-12658876"
        },
        {
            "date": "2008-12-23T18:25:23+0000",
            "content": "\n> The clone method is synchronized, is there something else that should be synchronized on?\nI think that's sufficient. ",
            "author": "Michael McCandless",
            "id": "comment-12658917"
        },
        {
            "date": "2008-12-23T18:39:55+0000",
            "content": "In the case of a reader that is already cloned, and clone is called again, do we want to throw an exception (if so what kind)?  Or perhaps clone should call acquireWriteLock to ensure only the reader with the lock may clone?   ",
            "author": "Jason Rutherglen",
            "id": "comment-12658921"
        },
        {
            "date": "2008-12-23T19:11:08+0000",
            "content": "LUCENE-1314.patch\n\n\n\tDirectoryIndexReader.doReopen acquires the write lock on a clone to ensure\n  only the cloned reader may pass the write lock to the clone reader.\n  This protects against the case where another reader may be trying\n  to clone at the same time.\n\tAll tests pass\n\n ",
            "author": "Jason Rutherglen",
            "id": "comment-12658929"
        },
        {
            "date": "2008-12-26T12:39:43+0000",
            "content": "\nOK I reviewed the patch; some comments:\n\n\n\tWe have clone & reopen methods on *Reader (ParallelReader,\n    MultiReader) that are not synchronized; shouldn't they be\n    synchronized as well?\n\n\n\n\n\tYou are still re-loading segments_N when cloning, which is\n    incorrect (in fact I had fixed this in my patch above but it got\n    lost); you should just clone segmentInfos instead.\n\n\n\n\n\tIn SegmentReader.java we have \"if (doClone) acquireWriteLock();\",\n    which isn't right?  Ie, if this reader does not currently have the\n    write lock (it has no \"local mods\") it should not acquire it?  One\n    should be allowed to clone a stale reader?\n\n\n\n\n\tHave you done any tests to see the cost of the copy-on-write\n    cloning of deleted docs BitVector & norms?  The first new mod to\n    the cloned reader pays that penalty.  Marvin's \"tombstone\"\n    deletions would bring this penalty to near zero, but it's a big\n    change (and should certainly be decoupled from this!).\n\n\n\n\n\tIn IndexReader.clone()'s javadocs can you state that on cloning a\n    reader with pending modifications, the original reader then\n    becomes readOnly (in addition to passing the write lock to the\n    cloned reader)?\n\n\n\n\n\tCan you rename IndexReader.cloneBitVector --> cloneDeletedDocs?\n\n\n\n\n\tWhen you clone the deleted docs (because refCount is > 1) you are\n    first decRef'ing the old one and then making the clone... can you\n    change that so the decRef is done last?  I don't think any actual\n    bug would result from the way it is now, but let's be defensive\n    (don't decRef something until you really are done using it).\n\n\n\n\n\tClass Ref does not need to delcare its private int refCount as\n    volatile; you always access that member from a synchronized\n    context.\n\n\n\n\n\tIn SegmentReader.clone, you incRef the deleteDocsCopyOnWriteRef,\n    but it might be null, right?  Oh I see, it's always init'd to a\n    new Ref() but then you make a new Ref() again on the first\n    delete.  Can you make it null by default?  (Seems like it should\n    be null if deletedDocs is).\n\n\n\n\n\tCan you change Ref() so that it init's its refCount to 1?  This\n    way new Ref() need not immediately call incRef, and a Ref() with\n    refCount 0 is never allowed out into the wild, and you should then\n    add an \"assert refCount > 0\" in incRef as well.\n\n\n\n\n\tIn SegmentReader.doClose() you are failing to call\n    deletedDocsCopyOnWriteRef.decRef(), so you have a refCount leak.\n    Can you create a unit test that 1) opens reader 1, 2) does deletes\n    on reader 1, 3) clones reader 1 --> reader 2, 4) closes reader 1,\n    5) deletes more docs with reader 1, and 6) asserts that the\n    deletedDocs BitVector did not get cloned?  First verify the test\n    fails, then fix the bug...\n\n\n\n\n\tHow should unDeleteAll() work?  EG it seems like you must decRef\n    the Ref, then set it to null?  Can you add some tests for the\n    various permutations of this?\n\n\n\n\n\tSegmentReader.Norm now has two refCounts, and I think both are\n    necessary. One tracks refs to the Norm instance itself and the\n    other tracks refs to the byte[].  Can you add some comments\n    explaining the difference (because it's confusing at first blush)?\n\n\n\n\n\tI think the answer to your question \"// is it necessary to clone\n    everything?\" in SegmentReader.Norm.clone() is \"yes\"; can you\n    make sure you are cloning everything and then remove that comment?\n\n\n\n\n\tIn SegmentReader.doClose() we are also failing to decRef Norm\n    instances (I think this is a pre-existing bug) and the newly added\n    Refs to the byte[]'s as well.  Can you fix both of these?\n\n\n\n\n\tIn SegmentReader.Norm.cloneBytes() don't you need to create a new\n    bytesRef as well, because you are making a private copy at that\n    point?  Oh I see, you do this up in SegmentReader.doSetNorm; can\n    you move it (= making a new bytesRef) down into cloneBytes()?\n    Also, do the decRef of the old Ref last, not first, just like the\n    deletedDocs case.\n\n\n\n\n\tI think you might have an off-by-one error in Norm cloning.  A\n    newly cloned norm seems to share its byte[] with the original put\n    gets a bytesRef with refCount 1?  (Should be refCount 2?).\n\n\n\n\n\tCan you rename deletedDocsCopyOnWriteRef -> deletedDocsRef?\n\n\n\n\n\tCan you add \"new and experimental\" caveats to the package-private\n    APIs you've added (cloneNormBytes, cloneDeletedDocs)?\n\n\n ",
            "author": "Michael McCandless",
            "id": "comment-12659235"
        },
        {
            "date": "2009-01-05T23:05:39+0000",
            "content": "LUCENE-1314.patch\n\nMichael, thanks for reviewing the patch in such detail.  All of your comments have been included in the latest version of the patch.\n\nM.M: In SegmentReader.java we have \"if (doClone) acquireWriteLock();\", which isn't right? Ie, if this reader does not currently have the write lock (it has no \"local mods\") it should not acquire it? One should be allowed to clone a stale reader?\n\nCloning a stale reader is fixed in the patch.  The problem is the user may get into trouble by updating the stale reader which was debated before.  I got the impression insuring the reader being updated was the latest was important.  \n\nM.M.: Have you done any tests to see the cost of the copy-on-write cloning of deleted docs BitVector & norms? The first new mod to the cloned reader pays that penalty. Marvin's \"tombstone\" deletions would bring this penalty to near zero, but it's a big change (and should certainly be decoupled from this!).\n\nThe cost of cloning them meaning the creating a new byte array or some other cost like memory consumption?  I need to reread Marvin's tombstones which at first glance seemed to be an iterative approach to saving deletions that seems like a transaction log.  Correct?\n\nM.M.: SegmentReader.Norm now has two refCounts, and I think both are necessary. One tracks refs to the Norm instance itself and the other tracks refs to the byte[]. Can you add some comments explaining the difference (because it's confusing at first blush)?\n\nByte[] referencing is used because a new norm object needs to be created for each clone, and the byte array is all that is needed for sharing between cloned readers.  The current norm referencing is for sharing between readers whereas the byte[] referencing is for copy on write which is independent of reader references.\n\nM.M.: In SegmentReader.doClose() you are failing to call deletedDocsCopyOnWriteRef.decRef(), so you have a refCount leak.  Can you create a unit test that 1) opens reader 1, 2) does deletes on reader 1, 3) clones reader 1 --> reader 2, 4) closes reader 1, 5) deletes more docs with reader 1, and 6) asserts that the\ndeletedDocs BitVector did not get cloned? First verify the test fails, then fix the bug...\n\nIn regards to #5, the test cannot delete from reader 1 once it's closed.  A method called TestIndexReaderClone.testSegmentReaderCloseReferencing was added to test this closing use case. ",
            "author": "Jason Rutherglen",
            "id": "comment-12660979"
        },
        {
            "date": "2009-01-06T17:27:08+0000",
            "content": "\n\n> The problem is the user may get into trouble by updating the stale reader which was debated before. I got the impression insuring the reader being updated was the latest was important.\n\nBut: when one attempts to change a stale reader, that's caught when\ntrying to acquire the write lock?  (Ie during clone I think you don't\nneed to also check for this).\n\n\n> The cost of cloning them meaning the creating a new byte array\n\nYeah I was thinking CPU cost of creating & copying deleted docs &\nnorms; I was just curious (I don't think we have to measure this\nbefore committing).\n\n\n> I need to reread Marvin's tombstones which at first glance seemed to be an iterative approach to saving deletions that seems like a transaction log. Correct?\n\nSimilar to a transaction log in that the size of what's written is in\nproportion to how many changes (deletions) you made.  But different in\nthat there is no other data structure (ie the tombstones are the\nrepresentation of the deletes) and so the tombstones are used \"live\"\n(whereas transaction log is typically \"played back\" on next startup\nafter a failure).\n\nIf we had tombstones to represent deletes in Lucene then any new\ndeletions would not require any cloning of prior deletions.  Ie there\nwould be no copy-on-write.\n\n\n> M.M.: SegmentReader.Norm now has two refCounts, and I think both are necessary. One tracks refs to the Norm instance itself and the other tracks refs to the byte[]. Can you add some comments explaining the difference (because it's confusing at first blush)?\n> \n> Byte[] referencing is used because a new norm object needs to be created for each clone, and the byte array is all that is needed for sharing between cloned readers. The current norm referencing is for sharing between readers whereas the byte[] referencing is for copy on write which is independent of reader references.\n\nGot it.  Can you put this into the javadocs in the Norm class?\n\n\n> M.M.: In SegmentReader.doClose() you are failing to call deletedDocsCopyOnWriteRef.decRef(), so you have a refCount leak. Can you create a unit test that 1) opens reader 1, 2) does deletes on reader 1, 3) clones reader 1 --> reader 2, 4) closes reader 1, 5) deletes more docs with reader 1, and 6) asserts that the\ndeletedDocs BitVector did not get cloned? First verify the test fails, then fix the bug...\n> \n> In regards to #5, the test cannot delete from reader 1 once it's closed. A method called TestIndexReaderClone.testSegmentReaderCloseReferencing was added to test this closing use case.\n\nWoops \u2013 I meant \"5) deletes more docs with reader 2\".  Test case\nlooks good!  Thanks.\n\nA few more comments:\n\n\n\tCan you update javadocs of IndexReader.reopen to remove the\n    warning about not doing modification operations?  With\n    copy-on-write you are now free to do deletes against the reopened\n    reader with no impact to the reader you had reopened/cloned.\n\n\n\n\n\tWhat is SegmentReader.doDecRef for?  It seems dead?\n\n\n\n\n\tSegmentReader.doUndeleteAll has 4 space indent (should be 2)\n\n\n\n\n\tWe have this in SegmentReader.reopenSegment:\n\nif (deletedDocsRef == null) deletedDocsRef = new Ref();\nelse deletedDocsRef.incRef();\n\n\n   But I think if I clone a reader with no deletes, the clone then\n   [incorrectly] has a deletedDocsRef set?  Can you fix that code to\n   keep the invariant that if deleteDocs is null, so is\n   deletedDocsRef, and v/v?  Can you sprinkle asserts to make sure\n   that invariant always holds?\n\n\n\n\n\tIn SegmentReader.decRef we have \"if (deletedDocsRef != null &&\n    deletedDocsRef.refCount() > 1) deletedDocsRef.decRef();\" \u2013 but,\n    you should not have to check if deletedDocsRef.refCount() > 1?\n    Does something break when you remove that?  (In which case I think\n    we have a refCount bug lurking...)\n\n\n\n\n\tThe norm cloning logic in SegmentReader.reopenSegment needs to be\n    cleaned up... eg we first sweep through each Norm, incRef'ing it,\n    and then make 2nd pass to do full clone.  Really we should have if\n    (doClone) up front and do a single pass?  Also: I think we need\n    that same logic to re-open the singleNormStream for the clone case\n    as well.\n.\n    Hmm, in the non-single-norm stream case I think we also must\n    re-open the norm file, rather than clone it, in Norm.clone().  I\n    think if you 1) open reader 1(do no searching w/ it), 2) clone it\n    --> reader 2, 3) close reader 1, 4) try to do a search against a\n    field that then needs to load norms, you'll hit an\n    AlreadyClosedException, because you had a cloned IndexInput vs a\n    newly reopened one?  Can you add that test case?\n\n\n\n\n\tWhy was this needed:\n\nif (doClone && normsDirty) {\n  normsUpToDate = false;\n}\n\n\n    It seems like leaving normsUpToDate as true should have worked\n    (all the Norm instances are cloned anyway?).\n\n\n\n\n\tIn SegmentReader.doUndeleteAll, can you conditionalize on whether\n    deletedDocs != null?  In general rather than having separate\n    checks for deleteDocs != null and deletedDocsRef != null, I'd\n    prefer to check only deletedDocs != null and add an assert that\n    deleteDocsRef != null, with else clause having assert\n    deletedDocsRef == null.\n\n ",
            "author": "Michael McCandless",
            "id": "comment-12661214"
        },
        {
            "date": "2009-01-07T04:41:43+0000",
            "content": "Everything in the previous post should be working and completed.  TestIndexReaderReopen.testThreadSafety is creating a bug in the deletedDocs referencing which is related to \n\nif (!success) {\n// An exception occured during reopen, we have to decRef the norms\n// that we incRef'ed already and close singleNormsStream and FieldsReader\nclone.decRef();\n}\n\n\nat the bottom of SegmentReader.reopenSegment.  I am finished for the day and posted what is completed otherwise.\n\n> \"Similar to a transaction log in that the size of what's written is in\nproportion to how many changes (deletions) you made. But different in\nthat there is no other data structure (ie the tombstones are the\nrepresentation of the deletes) and so the tombstones are used \"live\"\n(whereas transaction log is typically \"played back\" on next startup\nafter a failure).\n\nIf we had tombstones to represent deletes in Lucene then any new\ndeletions would not require any cloning of prior deletions. Ie there\nwould be no copy-on-write.\"\n\nDefinitely interesting, how do tombstones work with BitVector?\n\nI changed Norm.clone to Norm.cloneNorm because it needs to throw an IOException, the clone interface does not allow exceptions and it's hidden inside of SegmentReader so the naming conventions should not matter.   ",
            "author": "Jason Rutherglen",
            "id": "comment-12661443"
        },
        {
            "date": "2009-01-07T12:04:53+0000",
            "content": "\n> Definitely interesting, how do tombstones work with BitVector?\n\nThey would replace BitVector with an iterator API (eg DocIDSet).  SegmentTermDocs would then AND together the term's postings with the deleted docs postings.  I mocked up a rough test of iteration vs random-access and tentatively found that iteration was a bit faster if %tg deletes was less than 10% or so, but then more costly if it was higher.  I didn't dig much into it though.\n\nOnce Lucene access deletes via iterator, then multiple tombstone streams could be merged during searching.\n\nI'll look at the patch.  Thanks Jason! ",
            "author": "Michael McCandless",
            "id": "comment-12661531"
        },
        {
            "date": "2009-01-08T17:16:01+0000",
            "content": "I executed on Eclipse Mac OS X on a 4 core box (core's significant due to the threads).  I ran TestIndexReaderReopen.testThreadSafety 2 times in debug mode it worked, thought that debug mode wasn't making the bug reproduce so tried just running the test and it passed again.  The 5th time it gave an error in debug mode.  The test case fails consistently when SegmentReader.reopenSegment success == false and decRef is called afterwards in the finally clause.  It seems that calling this decRef on the newly cloned object is causing the assertion error which is possibly related to threading.  Probably because the decRef on the failed clone is decrementing one too many times on a deletedDocsRef used by another reader and causing the following assertion error.  I'm not sure if this is a real bug or an issue that the test case should ignore.  \n\n\njava.lang.AssertionError\n\tat org.apache.lucene.index.SegmentReader$Ref.decRef(SegmentReader.java:104)\n\tat org.apache.lucene.index.SegmentReader.decRef(SegmentReader.java:249)\n\tat org.apache.lucene.index.MultiSegmentReader.doClose(MultiSegmentReader.java:413)\n\tat org.apache.lucene.index.IndexReader.decRef(IndexReader.java:157)\n\tat org.apache.lucene.index.IndexReader.close(IndexReader.java:990)\n\tat org.apache.lucene.index.TestIndexReaderReopen$9.run(TestIndexReaderReopen.java:703)\n\tat org.apache.lucene.index.TestIndexReaderReopen$ReaderThread.run(TestIndexReaderReopen.java:818)\n\n ",
            "author": "Jason Rutherglen",
            "id": "comment-12662043"
        },
        {
            "date": "2009-01-08T21:22:04+0000",
            "content": "LUCENE-1314.patch\n\nAll tests pass.  \n\nIndexReader.close was made non-final to override in SegmentReader.  This is due to the propagation of the method calls to SegmentReader.doClose previously passed through decRef which could be called by IndexReader.decRef or IndexReader.close.  In order to decref the copy on write refs, the close method needs to decrement the references, rather than simply the decRef method.  This caused the bug found in the previous comment where if decRef was called the deletedDocsRef did not need to also be decrefed which was the cause of the ref count assertion failing.  \n\nOccasionally TestIndexReaderReopen.testThreadSafety fails due to an already closed exception.  Trunk however also fails periodically.  Given multi threading of reopen/close is usually unlikely I am not sure it is worth investigating further.\n\nFixed norm byte refs not decrefing on close.\n\nFixed cloneNorm() byteRef being created when there is no byte array, added assertion check.\n\n ",
            "author": "Jason Rutherglen",
            "id": "comment-12662127"
        },
        {
            "date": "2009-01-09T18:41:34+0000",
            "content": "\n> Occasionally TestIndexReaderReopen.testThreadSafety fails due to an already closed exception. Trunk however also fails periodically.\nJason, I don't see this.  I'm running TestIndexReaderReopen via the command line (not through eclipse).  Are you able to see a failure (on trunk) via the command line? ",
            "author": "Michael McCandless",
            "id": "comment-12662465"
        },
        {
            "date": "2009-01-09T18:57:43+0000",
            "content": "I haven't seen this error via the command line, only sporadically in eclipse.  Is there a way with ant to only test one test case?  \nTried:\n\"ant -Dtestcase=org.apache.lucene.index.TestIndexReaderReopen test-core\" which according to the Wiki http://wiki.apache.org/lucene-java/HowToContribute should work. ",
            "author": "Jason Rutherglen",
            "id": "comment-12662472"
        },
        {
            "date": "2009-01-09T19:03:56+0000",
            "content": "\nIs there a way with ant to only test one test case?\nTried:\n\"ant -Dtestcase=org.apache.lucene.index.TestIndexReaderReopen test-core\" which according to the Wiki http://wiki.apache.org/lucene-java/HowToContribute should work. \n\nThe value of the testcase parameter fits in this way **/${testcase}.java in common-build.xml, so in your case it'd be -Dtestcase=TestIndexReaderReopen ",
            "author": "Erik Hatcher",
            "id": "comment-12662475"
        },
        {
            "date": "2009-01-09T19:20:51+0000",
            "content": "That worked Erik.\n\nI executed TestIndexReaderReopen using the LUCENE-1314 patch 8 times via command line and did not see the error.  \n\nThen tried TestIndexReaderReopen in trunk and saw this the first time:\n\n\ncommon.test:\n    [mkdir] Created dir: /Users/jrutherg/dev/lucenetrunk/trunk/build/test\n    [junit] Testsuite: org.apache.lucene.index.TestIndexReaderReopen\n    [junit] this IndexReader is closed)\n    [junit] Tests run: 15, Failures: 1, Errors: 0, Time elapsed: 19.125 sec\n    [junit] \n    [junit] ------------- Standard Output ---------------\n    [junit] java.io.FileNotFoundException: _0_6.del\n    [junit] \tat org.apache.lucene.store.RAMDirectory.openInput(RAMDirectory.java:237)\n    [junit] \tat org.apache.lucene.util.BitVector.<init>(BitVector.java:235)\n    [junit] \tat org.apache.lucene.index.SegmentReader.loadDeletedDocs(SegmentReader.java:412)\n    [junit] \tat org.apache.lucene.index.SegmentReader.reopenSegment(SegmentReader.java:499)\n    [junit] \tat org.apache.lucene.index.MultiSegmentReader.<init>(MultiSegmentReader.java:112)\n    [junit] \tat org.apache.lucene.index.SegmentReader.doReopen(SegmentReader.java:442)\n    [junit] \tat org.apache.lucene.index.DirectoryIndexReader$2.doBody(DirectoryIndexReader.java:153)\n    [junit] \tat org.apache.lucene.index.SegmentInfos$FindSegmentsFile.run(SegmentInfos.java:688)\n    [junit] \tat org.apache.lucene.index.DirectoryIndexReader.reopen(DirectoryIndexReader.java:175)\n    [junit] \tat org.apache.lucene.index.TestIndexReaderReopen$9.run(TestIndexReaderReopen.java:685)\n    [junit] \tat org.apache.lucene.index.TestIndexReaderReopen$ReaderThread.run(TestIndexReaderReopen.java:818)\n    [junit] org.apache.lucene.store.AlreadyClosedException: this IndexReader is closed\n    [junit] \tat org.apache.lucene.index.IndexReader.ensureOpen(IndexReader.java:196)\n    [junit] \tat org.apache.lucene.index.SegmentReader.docFreq(SegmentReader.java:741)\n    [junit] \tat org.apache.lucene.index.MultiSegmentReader.docFreq(MultiSegmentReader.java:378)\n    [junit] \tat org.apache.lucene.search.IndexSearcher.docFreq(IndexSearcher.java:86)\n    [junit] \tat org.apache.lucene.search.Similarity.idf(Similarity.java:481)\n    [junit] \tat org.apache.lucene.search.TermQuery$TermWeight.<init>(TermQuery.java:44)\n    [junit] \tat org.apache.lucene.search.TermQuery.createWeight(TermQuery.java:146)\n    [junit] \tat org.apache.lucene.search.Query.weight(Query.java:95)\n    [junit] \tat org.apache.lucene.search.Searcher.createWeight(Searcher.java:185)\n    [junit] \tat org.apache.lucene.search.Searcher.search(Searcher.java:136)\n    [junit] \tat org.apache.lucene.index.TestIndexReaderReopen$9.run(TestIndexReaderReopen.java:689)\n    [junit] \tat org.apache.lucene.index.TestIndexReaderReopen$ReaderThread.run(TestIndexReaderReopen.java:818)\n    [junit] ------------- ---------------- ---------------\n    [junit] ------------- Standard Error -----------------\n    [junit] java.io.FileNotFoundException: _0_6.del\n    [junit] \tat org.apache.lucene.store.RAMDirectory.openInput(RAMDirectory.java:237)\n    [junit] \tat org.apache.lucene.util.BitVector.<init>(BitVector.java:235)\n    [junit] \tat org.apache.lucene.index.SegmentReader.loadDeletedDocs(SegmentReader.java:412)\n    [junit] \tat org.apache.lucene.index.SegmentReader.reopenSegment(SegmentReader.java:499)\n    [junit] \tat org.apache.lucene.index.MultiSegmentReader.<init>(MultiSegmentReader.java:112)\n    [junit] \tat org.apache.lucene.index.SegmentReader.doReopen(SegmentReader.java:442)\n    [junit] \tat org.apache.lucene.index.DirectoryIndexReader$2.doBody(DirectoryIndexReader.java:153)\n    [junit] \tat org.apache.lucene.index.SegmentInfos$FindSegmentsFile.run(SegmentInfos.java:688)\n    [junit] \tat org.apache.lucene.index.DirectoryIndexReader.reopen(DirectoryIndexReader.java:175)\n    [junit] \tat org.apache.lucene.index.TestIndexReaderReopen$9.run(TestIndexReaderReopen.java:685)\n    [junit] \tat org.apache.lucene.index.TestIndexReaderReopen$ReaderThread.run(TestIndexReaderReopen.java:818)\n    [junit] ------------- ---------------- ---------------\n    [junit] Testcase: testThreadSafety(org.apache.lucene.index.TestIndexReaderReopen):\tFAILED\n    [junit] Error occurred in thread Thread-51:\n    [junit] this IndexReader is closed\n    [junit] junit.framework.AssertionFailedError: Error occurred in thread Thread-51:\n    [junit] this IndexReader is closed\n    [junit] \tat org.apache.lucene.index.TestIndexReaderReopen.testThreadSafety(TestIndexReaderReopen.java:760)\n    [junit] \n    [junit] \n    [junit] Test org.apache.lucene.index.TestIndexReaderReopen FAILED\n\n\n ",
            "author": "Jason Rutherglen",
            "id": "comment-12662485"
        },
        {
            "date": "2009-01-09T21:11:28+0000",
            "content": "Odd, I still can't see it.  Are you sure you have no local mods?  Eg the line number in BitVector.java looks off (but others look OK).\n\nWhat's your full env?  I'm also running on quad core Mac Pro, 10.5.5, with this java:\n\n\nJava(TM) SE Runtime Environment (build 1.6.0_07-b06-153)\nJava HotSpot(TM) 64-Bit Server VM (build 1.6.0_07-b06-57, mixed mode)\n\n ",
            "author": "Michael McCandless",
            "id": "comment-12662519"
        },
        {
            "date": "2009-01-09T22:27:52+0000",
            "content": "Software\n  System Version:\tMac OS X 10.5.6 (9G55)\n  Kernel Version:\tDarwin 9.6.0\n  Boot Volume:\tMacintosh HD\nHardware\nModel Name:\tMac Pro\n  Model Identifier:\tMacPro3,1\n  Processor Name:\tQuad-Core Intel Xeon\n  Processor Speed:\t2.8 GHz\n  Number Of Processors:\t2\n  Total Number Of Cores:\t8\n  L2 Cache (per processor):\t12 MB\n  Memory:\t12 GB\n  Bus Speed:\t1.6 GHz\n  Boot ROM Version:\tMP31.006C.B05\n  SMC Version:\t1.25f4\n  Serial Number:\tG88151P4XYL\n\njava -version\n\njava version \"1.5.0_16\"\nJava(TM) 2 Runtime Environment, Standard Edition (build 1.5.0_16-b06-284)\nJava HotSpot(TM) Client VM (build 1.5.0_16-133, mixed mode, sharing)\n\n\n\nDoes ant execute with -server turned on?  My VM isn't 64bit?   ",
            "author": "Jason Rutherglen",
            "id": "comment-12662545"
        },
        {
            "date": "2009-01-11T22:45:13+0000",
            "content": "\nI started from the last patch and made some fixes to how norms are\nshared (new patch attached).\n\nI also fixed the reopen/clone unit tests to use MockRAMDirectory, to\nverify all open files are closed... which resulted in some interesting\nfailures that are now fixed.\n\nWith this change, we use fewer file descriptions during reopen &\nclone.  Previously, the norms in the new reader opened a new\nIndexInput on reopen or clone; now we share the original one (similar\nto how \"referencedSegmentReader\" works).  This is true for the \"single\nnorm stream\" case too.\n\nIt's now safe to make changes (norms, deletions) on a reopened reader\n(as well as cloned reader); it won't affect the previous reader (a\nprivate copy-on-write is made on the first change).\n\nAll tests pass, except I still can't repro the failure Jason sees on\ntrunk.  I think we're getting close! ",
            "author": "Michael McCandless",
            "id": "comment-12662832"
        },
        {
            "date": "2009-01-12T17:35:41+0000",
            "content": "Fixing the norms bytes loading is good, it seemed incorrect but I\ndidn't want to mess with it as I didn't fully understand it. \n\nI executed TestIndexReaderReopen 7 times and did not see the error. ",
            "author": "Jason Rutherglen",
            "id": "comment-12663023"
        },
        {
            "date": "2009-01-13T16:59:14+0000",
            "content": "I think we should add reopen(boolean readonly) and clone(boolean\nreadonly) as otherwise the only way to obtain a readonly reader is to\ncall IR.open. ",
            "author": "Jason Rutherglen",
            "id": "comment-12663375"
        },
        {
            "date": "2009-01-13T21:43:23+0000",
            "content": "This patch includes the previous patch. All tests pass.\n\n\n\tIndexReader.clone(boolean openReadOnly) method added that returns a\nread only reader.\n\n\n\n\n\tPreviously on a clone, the DirectoryIndexReader.doReopen was\nlooking up the latest segmentinfos file from the directory\nimplementation. This was unnecessary because the current segmentinfos\nis being cloned. In this patch DirectoryIndexReader.clone uses the\nnew doReopenSegmentInfos (which can also be used by LUCENE-1516).\nWhen clone returns a read only reader, the write lock etc is not\nshared. \n\n\n\n\n\tSegmentReader. reopenSegment has a openReadOnly argument.\n\n\n\n\n\tAdded a test case in TestIndexReaderClone checking for read only\nreaders being returned from the method clone openReadOnly=true. \n\n\n\nI decided against having reopen have a read only method because it\ndoes not always return a reader like clone does. If the existing\nreader is not read only and the returned reader is supposed to be\nread only, the current contract of the reopen method would break\nbecause if there are no changes it is supposed to return the existing\nreader. Also returning a read only reader is desired, clone may be\nused. ",
            "author": "Jason Rutherglen",
            "id": "comment-12663485"
        },
        {
            "date": "2009-01-15T21:10:31+0000",
            "content": "Jason I think TestIndexReaderClone.java is missing from your patch? ",
            "author": "Michael McCandless",
            "id": "comment-12664265"
        },
        {
            "date": "2009-01-15T21:27:00+0000",
            "content": "\n> Previously on a clone, the DirectoryIndexReader.doReopen was\n> looking up the latest segmentinfos file from the directory\n> implementation. This was unnecessary because the current segmentinfos\n> is being cloned.\n\nGood!  So now we don't even run the FindSegmentsFile at all during\nclone.\n\n\n> I think we should add reopen(boolean readonly) and clone(boolean\n> readonly) as otherwise the only way to obtain a readonly reader is to\n> call IR.open. \n\nI agree.  It then seems like for realtime search you may want to clone\na readOnly IR to do your searching (for better concurrency), and keep\nthe writable IR for doing further changes.\n\n\n> IndexReader.clone(boolean openReadOnly) method added that returns a\n> read only reader.\n\nIf I have a readOnly reader and I clone with readOnly=false, should\nthat give me a non-readOnly clone?  I think it should?  But I think\ncurrent patch doesn't handle that right?  If so, could you add a test\ncase & fix it?\n\nThen, if I have a non-readOnly reader and I clone it with\nreadOnly=true, it seems like the semantics is to have the original\nreader keep the write lock, ie it's allowed to continue making changes\nif it wants, and the first change after that clone should\ncopy-on-write?  Can you add a test case verifying that?\n\n\n> I decided against having reopen have a read only method because it\n> does not always return a reader like clone does.\n\nOK. ",
            "author": "Michael McCandless",
            "id": "comment-12664271"
        },
        {
            "date": "2009-01-16T03:32:33+0000",
            "content": "All tests pass\n\nChanged DirectoryIndexReader. acquireWriteLock to throw an\nUnsupportedOperationException (rather than a\nLockObtainFailedException) when the reader is readonly because\nTestIndexReader.testReadOnly was failing\n\nAdded test for cloning a writeable reader to read only\n\nCloning a read only reader into a writeable reader throws an\nexception. Added a test case\n\nWhy does DirectoryIndexReader and SegmentReader have a readonly\nvariable?  ",
            "author": "Jason Rutherglen",
            "id": "comment-12664395"
        },
        {
            "date": "2009-01-16T13:14:31+0000",
            "content": "\nChanged DirectoryIndexReader. acquireWriteLock to throw an\nUnsupportedOperationException (rather than a\nLockObtainFailedException) when the reader is readonly because\nTestIndexReader.testReadOnly was failing\n\nWe can't really make that change \u2013 it's technically a change to back compat.  Can we just fix the test that was failing (why was it failing?).\n\n\nCloning a read only reader into a writeable reader throws an\nexception.\n\nWhy not allow this?  (It shouldn't be hard to allow it?)\n\n\nWhy does DirectoryIndexReader and SegmentReader have a readonly\nvariable? \nHmm \u2013 that's no good.  Can you remove SegmentReader's? ",
            "author": "Michael McCandless",
            "id": "comment-12664511"
        },
        {
            "date": "2009-01-16T16:41:36+0000",
            "content": "\n\"Changed DirectoryIndexReader. acquireWriteLock to throw an\nUnsupportedOperationException (rather than a\nLockObtainFailedException) when the reader is readonly because\nTestIndexReader.testReadOnly was failing\"\n\nWe can't really make that change - it's technically a change to back\ncompat. Can we just fix the test that was failing (why was it\nfailing?). \n\nIt's been added in this patch so there isn't a back compat issue. I'm\nnot sure why it wasn't being thrown in previous testing.\nacquireWriteLock in ReadOnly*Reader throws\nUnsupportedOperationException making the patch compatible with\nexisting behavior.\n\n\n\"Cloning a read only reader into a writeable reader throws an\nexception.\"\n\nWhy not allow this? (It shouldn't be hard to allow it?)  \n\nWhile it seem logical, it's not allowed because the read only reader\ndoesn't hold the write lock which it needs to pass on to the\nwriteable reader. \n\nSegmentReader.readOnly variable removed\n\nAll tests pass ",
            "author": "Jason Rutherglen",
            "id": "comment-12664557"
        },
        {
            "date": "2009-01-16T17:09:26+0000",
            "content": "It's been added in this patch so there isn't a back compat issue.\n\nOK, I was confused.  This new exception is thrown if you 1) have a\nnon-readOnly reader1, 2) reopen it with readOnly=false (thus marking\nreader1 as readOnly=true), and 3) try to make a change with the\nnow-readOnly reader.\n\nOK I like throwing UOE.  It's the same as what you get if you open\na readOnly reader and try to make a change.\n\n\nWhile it seem logical, it's not allowed because the read only reader\ndoesn't hold the write lock which it needs to pass on to the\nwriteable reader. \n\nBut that's OK?  Ie, cloning to a non-readOnly reader when it doesn't\nalready have the write lock simply means the new reader is allowed to\nattempt acquiring the write lock (even though it doesn't already have\nthe write lock).\n\nIe \"being non-readOnly\" and \"holding the write lock\" are two separate\nthings.\n\nI can see this being useful if you are an app that doens't often need\nto make changes w/ the reader... so you hold a readOnly reader most of\nthe time, but then when you need to make a change you clone it to\nnon-readOnly clone to make changes.\n\nI also wonder what should happen if you 1) have a non-readOnly\nreader1, but 2) it has no changes pending (does not hold the write\nlock) and 3) you clone it to a non-readOnly clone reader2.  I think\nreader1 should not be marked readOnly this case, because it has no\npending changes.  Ie I think at this point reader1 & reader2 should be\ninterchangeable? ",
            "author": "Michael McCandless",
            "id": "comment-12664568"
        },
        {
            "date": "2009-01-16T19:59:07+0000",
            "content": "Added TestIndexReaderClone.testCloneNoChangesStilReadOnly, changed\nbehavior such that if there are no changes, the original reader is\nnot set to readonly (the previous behavior was to set readonly to\ntrue even if the reader did not have changes). ",
            "author": "Jason Rutherglen",
            "id": "comment-12664652"
        },
        {
            "date": "2009-01-16T20:35:33+0000",
            "content": "Jason I think your last patch is stale?  I don't see the new test case nor the changed logic about setting reader to readOnly on clone. ",
            "author": "Michael McCandless",
            "id": "comment-12664668"
        },
        {
            "date": "2009-01-16T21:56:37+0000",
            "content": "Sorry, here it is. ",
            "author": "Jason Rutherglen",
            "id": "comment-12664697"
        },
        {
            "date": "2009-01-16T22:50:49+0000",
            "content": "I'm seeing this failure:\n\n[junit] Testcase: testCloneWriteToOrig(org.apache.lucene.index.TestIndexReaderClone):\tFAILED\n[junit] deleting from the original should not have worked\n[junit] junit.framework.AssertionFailedError: deleting from the original should not have worked\n[junit] \tat org.apache.lucene.index.TestIndexReaderClone.testCloneWriteToOrig(TestIndexReaderClone.java:53)\n[junit] \n[junit] \n[junit] Test org.apache.lucene.index.TestIndexReaderClone FAILED\n\n\n\nI think that test just needs to be updated based on the new semantics?  Could you also test the reverse (that r2 is also able to do a delete, as long as r1 hasn't).\n\nAnd also this one:\n\n[junit] Testcase: testNormsRefCounting(org.apache.lucene.index.TestIndexReaderCloneNorms):\tFAILED\n[junit] did not hit expected exception\n[junit] junit.framework.AssertionFailedError: did not hit expected exception\n[junit] \tat org.apache.lucene.index.TestIndexReaderCloneNorms.testNormsRefCounting(TestIndexReaderCloneNorms.java:179)\n[junit] \n\n\n\nWhich I think is failing for the same reason (changed semantics).\n\nIt seems like you also now allow non-readOnly reader to clone to a writable one?  Is there a test case for that?\n\nAlso can you make sure you always close MockRAMDir's that you opened (at least one test does not)?  On close it fails if there are still any open files, which is a good test that we are not over-incref'ing somewhere. ",
            "author": "Michael McCandless",
            "id": "comment-12664727"
        },
        {
            "date": "2009-01-16T23:24:36+0000",
            "content": "I was running \"ant test-tag\" which doesn't run all the tests (such as\nthe ones from the patch) so the failures weren't showing up.  Executed ant test-core.\nAnd I always see:\n[junit] Testcase:\nwarning(junit.framework.TestSuite$1):\tFAILED \n[junit] No tests found\nin org.apache.lucene.index.TestDebug \n[junit] junit.framework.AssertionFailedError: No tests found in\norg.apache.lucene.index.TestDebug\n\nTestIndexReaderCloneNorms.testNormsRefCounting changed where the\nexpected exception test is made, trying to write to a reader that's\nbeen cloned, and the clone has been updated\n\nChanged TestIndexReaderClone.testCloneWriteToOrig to test if deleting\nfrom the original reader works (it should because neither one has\nmade updates and acquired the write lock at that stage)\n ",
            "author": "Jason Rutherglen",
            "id": "comment-12664733"
        },
        {
            "date": "2009-01-17T20:30:20+0000",
            "content": "It's best to run \"ant test test-tag\", which tests core, contrib and back compat.\n\n\n[junit] junit.framework.AssertionFailedError: No tests found in\norg.apache.lucene.index.TestDebug \n\nI'm not sure what's up with that... I don't see a TestDebug.java checked in.  Maybe you have a local mod? ",
            "author": "Michael McCandless",
            "id": "comment-12664866"
        },
        {
            "date": "2009-01-18T16:26:42+0000",
            "content": "\nNew patch attached.  All tests pass.  Changes:\n\n\n\tSimplified semantics: if you clone non-readOnly reader1 to\n    non-readOnly reader2, I now simply clear hasChanges & writeLock on\n    reader1 and transfer them to reader2, but do not set readOnly in\n    reader1.  This means reader1 is free to attempt to acquire the\n    write lock if it wants, and it simply fails if it's stale (ie, we\n    just re-use the existing code path to catch this, rather than add\n    a new check), and this way we never have a case where an existing\n    reader \"becomes\" readOnly \u2013 it can only be born readOnly.\n\n\n\n\n\tAdded reopen(readOnly) (what Jason referred to above).  I think\n    the semantics are well defined: it returns a new reader if either\n    the index has changed or readOnly is different.\n\n\n\n\n\tAdded test for \"clone readOnly to non-readOnly\" case, which\n    failed, and fixed various places where we were not respecting\n    \"openReadOnly\" correctly.\n\n\n\n\n\tShare common source (ReadOnlySegmentReader.noWrite) for throwing\n    exception on attempting change to a readOnly reader\n\n\n\n\n\tFixed a sneaky pre-existing bug with reopen (added test case): if\n    you have a non-readOnly reader on a single segment index, then add\n    a segment, then reopen it and try to do a delete w/ new reader, it\n    fails.  This is because we were incorrectly sharing the original\n    SegmentReader instance which still had its own SegmentInfos, so it\n    attempts to double-acquire write lock during a single deleteDocument\n    call.\n\n\n\n\n\tMore tests\n\n ",
            "author": "Michael McCandless",
            "id": "comment-12664976"
        },
        {
            "date": "2009-01-22T19:23:40+0000",
            "content": "Fixed a sneaky pre-existing bug with reopen\n\nMichael, does this affect IndexReader.deleteDocument only? Is using IndexWriter.deleteDocuments fine? ",
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12666256"
        },
        {
            "date": "2009-01-22T22:48:50+0000",
            "content": "Michael, does this affect IndexReader.deleteDocument only? Is using IndexWriter.deleteDocuments fine?\n\nCorrect, it's only attempted changes through the reopened IndexReader that are affected (IndexWriter is fine). ",
            "author": "Michael McCandless",
            "id": "comment-12666334"
        },
        {
            "date": "2009-01-26T21:29:58+0000",
            "content": "OK, new patch.  I think it's ready to commit!  I'll wait a day or\ntwo... changes:\n\n\n\tAllow reopen(readOnly=true) on a reader that has pending changes\n    (added test)\n\n\n\n\n\tAdded CHANGES.txt entry\n\n\n\n\n\tAdded some missing copyrights, fixed javadocs.\n\n\n\n\n\tSmall cleanups, asserts, refactoring\n\n ",
            "author": "Michael McCandless",
            "id": "comment-12667440"
        },
        {
            "date": "2009-01-30T11:13:09+0000",
            "content": "Committed revision 739238.  Thanks Jason! ",
            "author": "Michael McCandless",
            "id": "comment-12668816"
        },
        {
            "date": "2009-01-30T17:09:38+0000",
            "content": "Cool, cheers Mike! ",
            "author": "Jason Rutherglen",
            "id": "comment-12668930"
        },
        {
            "date": "2009-01-30T17:28:53+0000",
            "content": "I'm thinking of implementing a follow on patch that performs pooling\nof the byte arrays used by the norms and deleted docs. Because the\nbyte array length for a segment is always the same, they can be\npooled. \n\nIt is useful because if IR.clone is called repeatedly and written to,\nwith the old readers thrown away, the byte arrays will accumulate as\ngarbage and this could affect the garbage collector. The patch will\nmost likely end up in contrib as it would use ConcurrentHashMap to\navoid synchronization. \n\n ",
            "author": "Jason Rutherglen",
            "id": "comment-12668941"
        },
        {
            "date": "2009-01-30T21:22:30+0000",
            "content": "\nI'm thinking of implementing a follow on patch that performs pooling\nof the byte arrays used by the norms and deleted docs.\nI think this may be premature, or maybe just out of order... I'd much rather see the incremental copy on write solution (which would not be allocating the whole array) explored first, I think? ",
            "author": "Michael McCandless",
            "id": "comment-12669030"
        },
        {
            "date": "2009-02-06T22:42:46+0000",
            "content": "Now that we've got IndexReader.getSequentialSubReaders(), users may\ntry to clone the sub-readers which throws the exception below. I'd\nlike to support cloning individual segment readers because some cases\nrequire cloning on the existing segments, without reloading the new\nsegments. \n\nThe use case is realtime search where the ram index is being flushed\nto disk in the background and we don't need IR.clone to also open the\nnew segments. The old segments could be acquiring deletes as the\nbackground flush to disk is occurring. I suppose I could write a hack\nsuch that a clone is performed on the multireader, then only the old\nsegments are pulled out and deleted from.\n\nAttached is a method TestIndexReaderClone.testCloneSubreaders that\ntests individual segment reader clone.\n\n\njava.lang.NullPointerException\n\tat org.apache.lucene.index.DirectoryIndexReader.clone(DirectoryIndexReader.java:171)\n\tat org.apache.lucene.index.DirectoryIndexReader.clone(DirectoryIndexReader.java:162)\n\tat org.apache.lucene.index.TestIndexReaderClone.testCloneSubreaders(TestIndexReaderClone.java:46)\n\n ",
            "author": "Jason Rutherglen",
            "id": "comment-12671362"
        },
        {
            "date": "2009-02-07T19:29:45+0000",
            "content": "Attached patch.  If the segmentInfos is null (because the SegmentReader is not \"standalone\") we now just clone the segment.  If you call reopen on a non-standalone SegmentReader I throw UnsupportedOperationException.\n\nJason can you test this?  Thanks. ",
            "author": "Michael McCandless",
            "id": "comment-12671511"
        },
        {
            "date": "2009-02-09T18:34:42+0000",
            "content": "Mike, your patch solved the null pointer exception. An item of\nconcern is when deleteDocument is called on the sub-readers, the\nwrite lock is not acquired, and it's not passed from the parent\nMultiSegmentReader. In the new patch I close the subreaders\nindividually, then close the MultiSegmentReader. When opening the\nindex again the SegmentReader can't find the .del file. Perhaps we\njavadoc the parameters of these types of cases or there's a fix.\n\n\njava.io.FileNotFoundException: _b_1.del\n\tat org.apache.lucene.store.MockRAMDirectory.openInput(MockRAMDirectory.java:246)\n\tat org.apache.lucene.util.BitVector.<init>(BitVector.java:209)\n\tat org.apache.lucene.index.SegmentReader.loadDeletedDocs(SegmentReader.java:591)\n\tat org.apache.lucene.index.SegmentReader.initialize(SegmentReader.java:557)\n\tat org.apache.lucene.index.SegmentReader.get(SegmentReader.java:495)\n\tat org.apache.lucene.index.SegmentReader.get(SegmentReader.java:417)\n\tat org.apache.lucene.index.MultiSegmentReader.<init>(MultiSegmentReader.java:55)\n\tat org.apache.lucene.index.DirectoryIndexReader$1.doBody(DirectoryIndexReader.java:112)\n\tat org.apache.lucene.index.SegmentInfos$FindSegmentsFile.run(SegmentInfos.java:688)\n\tat org.apache.lucene.index.DirectoryIndexReader.open(DirectoryIndexReader.java:123)\n\tat org.apache.lucene.index.IndexReader.open(IndexReader.java:316)\n\tat org.apache.lucene.index.IndexReader.open(IndexReader.java:227)\n\tat org.apache.lucene.index.TestIndexReaderClone.testCloneSubreaders(TestIndexReaderClone.java:427)\n\n ",
            "author": "Jason Rutherglen",
            "id": "comment-12671951"
        },
        {
            "date": "2009-02-09T20:07:44+0000",
            "content": "If the SegmentReader is not standalone (does not \"own\" a SegmentInfos,\nand is therefore a sub-reader in a MultiSegmentReader), I think you\nshould not make changes (setNorm, deleteDocument) with it?\n\nIe, you should always use the \"parent\" MultiSegmentReader to make\nchanges.\n\nI'll update the javadocs for getSequentialSubReaders to state this.\n ",
            "author": "Michael McCandless",
            "id": "comment-12671991"
        },
        {
            "date": "2009-02-13T19:30:24+0000",
            "content": "\nIf the SegmentReader is not standalone (does not \"own\" a SegmentInfos,\nand is therefore a sub-reader in a MultiSegmentReader), I think you\nshould not make changes (setNorm, deleteDocument) with it? \n\nFor realtime there is a use case where a Multi*Reader needs to be\ncloned without (re)opening the new segments. This is due to running\nIW.addIndexes in a backbround thread where upon completion a\nconcurrent IR.clone could unintentionally open the new segments.\nOpening the new segments may be undesirable because the transaction\nmay have locked segments and so does not want to delete from the new\nsegments. \n\nOne approach is an IndexReader.cloneNoNew method. Or perhaps\nIR.clone(boolean openReadOnly, boolean openNewSegments) where\nopenNewSegments defaults to true.  ",
            "author": "Jason Rutherglen",
            "id": "comment-12673359"
        },
        {
            "date": "2009-02-13T23:14:11+0000",
            "content": "\nFor realtime there is a use case where a Multi*Reader needs to be\ncloned without (re)opening the new segments.\nI thought that's exactly what clone does (does not open the segments_N)?\n\n\nThis is due to running\nIW.addIndexes in a backbround thread where upon completion a\nconcurrent IR.clone could unintentionally open the new segments.\nIf IW is opened with autoCommit false, then even on completely of addIndexes,\na newly [re-]opened reader won't see the change, until IW commits? ",
            "author": "Michael McCandless",
            "id": "comment-12673415"
        },
        {
            "date": "2009-02-14T01:09:12+0000",
            "content": "\nI thought that's exactly what clone does (does not open the\nsegments_N)? \n\nLUCENE-1516 IW+IR is crowding into my thoughts on realtime and clone\nwhere the segmentinfos is obtained from the IW which gets updated. \n\n\nIf IW is opened with autoCommit false, then even on\ncompletely of addIndexes, a newly [re-]opened reader won't see the\nchange, until IW commits? \n\nPerhaps we need to update the IW.addIndexes javadoc which reads:\n\"This method is transactional in how Exceptions are handled: it does\nnot commit a new segments_N file until all indexes are added. This\nmeans if an Exception occurs (for example disk full), then either no\nindexes will have been added or they all will have been.\"\n\nI wasn't sure if commit is required to see the new indexes. Maybe we\ncan add something like \"When autoCommit=false commit must be called\nto make the new indexes visible to a reader\".  ",
            "author": "Jason Rutherglen",
            "id": "comment-12673442"
        },
        {
            "date": "2009-02-15T10:26:48+0000",
            "content": "\nI wasn't sure if commit is required to see the new indexes. Maybe we\ncan add something like \"When autoCommit=false commit must be called\nto make the new indexes visible to a reader\". \nActually, this is already described in the \"autoCommit=false\" javadocs at the top of IW.  Any & all changes done with IW are not visible to a newly opened IR until commit() is called. ",
            "author": "Michael McCandless",
            "id": "comment-12673590"
        },
        {
            "date": "2009-02-15T10:57:31+0000",
            "content": "Committed revision 744653, to allow cloning of sub-readers. ",
            "author": "Michael McCandless",
            "id": "comment-12673597"
        },
        {
            "date": "2009-02-23T13:14:49+0000",
            "content": "Reopening to remember to add the missing deprecations for 2.9... ",
            "author": "Michael McCandless",
            "id": "comment-12675886"
        },
        {
            "date": "2009-02-23T13:59:18+0000",
            "content": "Duh, wrong issue. ",
            "author": "Michael McCandless",
            "id": "comment-12675899"
        },
        {
            "date": "2009-02-26T19:41:18+0000",
            "content": "Related to LUCENE-1516 I'm seeing a bug.\n\nThe test case in TestIndexReaderClone.testLucene1516Bug recreates the\nbug. Basically a reader is created, incRefed, a clone is made, the\nreader is decRefed, then incRefed again where the\nreader.deletedDocsRef assert > 0 fails. ",
            "author": "Jason Rutherglen",
            "id": "comment-12677120"
        },
        {
            "date": "2009-02-27T00:32:36+0000",
            "content": "Hmm \u2013 good catch!  In fact I think we should not be incRef/decRefing the deletedDocsRef with every incRef/decRef on the SegmentReader... I'll fix. ",
            "author": "Michael McCandless",
            "id": "comment-12677181"
        },
        {
            "date": "2009-02-27T21:04:14+0000",
            "content": "\nAttached patch.  I plan to commit in a day or two.\n\nOK I changed deletedDocRefs to only be inc/decRef'd once for the\nreader, not every time the reader is inc/decRef'd (which was causing\nthe bug you saw).\n\nBut then because of how a reopened SegmentReader references the\noriginal, the deleted docs were being unecessarily copy-on-write'd (on\nclosing the first reader we would fail to decref the deletedDocsRef so\nwhen the 2nd reader did a delete, it would copy).\n\nSo then I added a new coreRef to SegmentReader, instead of the\nreferencedSegmengReader.  I like this approach better because it\nallows the original reader to be closed, without closing the core\nobjects when other readers share them.\n\nIt also simplifies SegmentReader's inc/decRef so that they no longer\nneed to be overridden.\n\nAlso, when cloning the BitVector, I changed it to not copy count over\n\u2013 if a separate thread is changing the deleted docs at the same time,\nthe count could be off.\n\nBack-compat tests don't pass, because TestIndexReaderReopen is\nchecking internal reference counts; I'll commit fixes to tests when I\ncommit. ",
            "author": "Michael McCandless",
            "id": "comment-12677526"
        }
    ]
}