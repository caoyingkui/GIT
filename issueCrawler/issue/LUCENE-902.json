{
    "id": "LUCENE-902",
    "title": "Check on PositionIncrement  with StopFilter.",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [
            "modules/analysis"
        ],
        "type": "Bug",
        "fix_versions": [],
        "affect_versions": "2.2",
        "resolution": "Won't Fix",
        "status": "Closed"
    },
    "description": "PositionIncrement set with Tokenizer is not considered with StopFilter. \n\nWhen PositionIncrement of Token is 1, it is deleted by StopFilter. However, when PositionIncrement of Token following afterwards is 0, it is not deleted. \n\nI think that it is necessary to be deleted. Because it is thought same Token when PositionIncrement is 0.",
    "attachments": {
        "stopfilter20070605.patch": "https://issues.apache.org/jira/secure/attachment/12358920/stopfilter20070605.patch",
        "stopfilter20070608.patch": "https://issues.apache.org/jira/secure/attachment/12359261/stopfilter20070608.patch",
        "stopfilter20070604.patch": "https://issues.apache.org/jira/secure/attachment/12358837/stopfilter20070604.patch",
        "stopfilter.patch": "https://issues.apache.org/jira/secure/attachment/12358695/stopfilter.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2007-06-01T07:50:43+0000",
            "content": "patch attached ",
            "author": "Toru Matsuzawa",
            "id": "comment-12500602"
        },
        {
            "date": "2007-06-01T14:08:51+0000",
            "content": "This patch needs a small unit test showing that the problem exists, and that the provided patch fixes the problem.\n\nAlso, this patch makes the code more confusing - consider, e.g., renaming \"flag\" to something more meaningful. ",
            "author": "Steve Rowe",
            "id": "comment-12500719"
        },
        {
            "date": "2007-06-01T14:39:47+0000",
            "content": "A few points:\n\n\tpositionIncrements can also be >1 (the patch explicitly checks for 1)\n\tjust because a stop word is in the same position as another token does not mean that the other token should be removed\n\tthis patch, as coded, is sensitive to order\n\n ",
            "author": "Yonik Seeley",
            "id": "comment-12500725"
        },
        {
            "date": "2007-06-04T02:05:17+0000",
            "content": "My patch was consideration shortage as shown in the point. \nHowever, I think that processing positionIncrements with StopFilter is necessary.  ",
            "author": "Toru Matsuzawa",
            "id": "comment-12501078"
        },
        {
            "date": "2007-06-04T02:22:52+0000",
            "content": "without a unit test demonstrating an actual problem, i'm having a hard time udnerstanding what exactly the \"bug\" is in this issue.\n\nfrom what i can tell based on the comments and my reading of the patch, Toru is concerned about cumulative positionIncrements of tokens being lost when one of those tokens is a stop word.  (ie: if indexing multiple names of movies in a Document about an actor, and using a positionIncriment of \"10\" between each Field value (ie: movie name), indexing the values \"Dirty Harry\" and \"The Good the bad and the Ugly\" could result in no gap between the tokens \"harry\" and \"good\" since \"the\" is a stop word.\n\nis my understanding of the problem correct?\n\nif so, then i'm not sure how this patch really addresses the problem ... besides the fact that it treats \"1\" as a special case (the problem can come up with any positionIncrement) it doesn't seem to make any allowance for the situation where multiple stop words appear in sequence.\n\ni'm also not clear on why non stop words immediately following stop words (ie: the \"else if\" case) are not returned unless their positionIncriment is 1.\n\n\n ",
            "author": "Hoss Man",
            "id": "comment-12501080"
        },
        {
            "date": "2007-06-04T03:11:23+0000",
            "content": "for stop word only \"is\".\nsample words \"A is B\".\n\nFor instance,When Tokenizer on StopFilter returns the following as a result.\n termText  positionIncrement\n  \"A\"        1\n  \"is\"       1\n  \"are\"      0\n  \"be\"       0\n  \"B\"        1\n\nThe result of StopFilter.\n termText  positionIncrement\n  \"A\"        1\n  \"are\"      0\n  \"be\"       0\n  \"B\"        1\n\n\"A\" and \"are\" and \"be\" become the same positions.\n\nWhen thinking that it will process the result of a Japanese morphological analysis with StopFilter, it becomes a problem. ",
            "author": "Toru Matsuzawa",
            "id": "comment-12501085"
        },
        {
            "date": "2007-06-04T09:27:37+0000",
            "content": "patch and test ",
            "author": "Toru Matsuzawa",
            "id": "comment-12501163"
        },
        {
            "date": "2007-06-04T15:36:43+0000",
            "content": "Hi Toru,\n\nI looked at your patch (though I didn't test it), and I noticed that it uses generics and varargs, both Java 1.5 features.  Lucene core targets Java 1.4, so your patch needs to be rewritten to use only Java 1.4 features.\n\nI think I understand what you're going for (filtering out all tokens at the same position as a stopword), and I think it's a useful addition to Lucene, since the naive \"fix\", i.e. employing a StopFilter in a processing pipeline before a morphological analyzer, will negatively impact the morphological analyzer's performance.  \n\nHowever, this behavior should not be the default - StopFilter's current behavior is well-defined and depended on by lots of people.  I think there are (at least  ) two possible courses of action here:\n\n1. Include a getter/setter for a boolean field controlling whether to filter out tokens at the same position as stopwords (call it, say,  \"removeStopwordCollocates\", where I mean \"collocate\", as a noun, to denote tokens with the same position).  This field would be initialized to false, to preserve existing behavior.\n\n2. Change StopFilter to allow extension (remove the \"final\" in \"public final class StopFilter ...\"), and create a new class extending StopFilter that exhibits the behavior you want.  This could start life in the sandbox.\n\nI like option #1 better - this functionality, were it available, would quite likely be useful to a significat proportion of Lucene's user base (albeit skewed toward non-Lucene-as-black-box users). ",
            "author": "Steve Rowe",
            "id": "comment-12501245"
        },
        {
            "date": "2007-06-05T02:57:27+0000",
            "content": "Hi Steven,\n\nThank you for pointing out the problem.\nThe corrected patch is attached(stopfilter20070605.patch). \n\nI think #1 or #2 is acceptable.  \nHow it is solved is entrusted to the committer. \nI hope it is solved by this problem at the early stage.  ",
            "author": "Toru Matsuzawa",
            "id": "comment-12501435"
        },
        {
            "date": "2007-06-07T04:07:43+0000",
            "content": "A few comments in no particular order...\n\n1) in future patches, could you please use 2 spaces instead of tabs?\n\n2) am i understanding correctly that the primary use case you are trying to address is stop word removal when the stop word has synonyms with a position increment of 0 (the expectation being that the synonyms also be removed) ? ... if so, wouldn't the most efficient thing be to do stop word removal before doing synonym expansion?  (it means having a bigger stop word list - with all the synonyms - but that still seems better to me) ... are there other use cases i'm not understanding? ... i freely admit i don't understand the \"Japanese morphological analysis\" comment.\n\n3) i only glanced over the specifics of removeStopwordCollocatesNext() .. but would promoting BufferedTokenStream from Solr simplify the code (it seems to all be about buffering tokens) ...\nhttp://svn.apache.org/viewvc/lucene/solr/trunk/src/java/org/apache/solr/analysis/BufferedTokenStream.java?view=markup\n\n4) it would be useful if the test case could clarify not only the expected tokens text concatenated together, but also what the expected positions of position increments are for the tokens... i was certainly confused by the title of this issue. ",
            "author": "Hoss Man",
            "id": "comment-12502213"
        },
        {
            "date": "2007-06-08T09:14:09+0000",
            "content": "Hi Hoss,\nThank you your comments.\n\n> 1) in future patches, could you please use 2 spaces instead of tabs?\n\nIt consented.\n\n> 2) am i understanding correctly that the primary use case you are trying to address is\n>  stop word removal when the stop word has synonyms with a position increment of 0 \n> (the expectation being that the synonyms also be removed) ?\n\nYour understanding is correct.\nHowever, a synonym itself might be a stop word. \n\n>  ... if so, wouldn't the most efficient thing be to do stop word removal before doing \n> synonym expansion? (it means having a bigger stop word list - with all the synonyms - \n> but that still seems better to me) ... are there other use cases i'm not understanding? ...\n>  i freely admit i don't understand the \"Japanese morphological analysis\" comment.\n\nIt is not realistic to have a stop word list with all the synonyms \nbecause the morphological engine must understand all the dictionaries to make that list.\n(The engine analyzes texts with such dictionaries.)\n\n> 3) i only glanced over the specifics of removeStopwordCollocatesNext() .. \n> but would promoting BufferedTokenStream from Solr simplify the code\n>  (it seems to all be about buffering tokens) ...\nhttp://svn.apache.org/viewvc/lucene/solr/trunk/src/java/org/apache/solr/analysis/BufferedTokenStream.java?view=markup\n\nI think that it becomes more concise if BufferedTokenStream can be used. \n\n> 4) it would be useful if the test case could clarify not only the expected tokens text \n> concatenated together, but also what the expected positions of position increments are \n> for the tokens... i was certainly confused by the title of this issue.\n\nI agree with you. It would be better to compare them with expected tokens. \nI'm sorry to confuse you with my poor English. ",
            "author": "Toru Matsuzawa",
            "id": "comment-12502731"
        },
        {
            "date": "2009-12-06T20:00:59+0000",
            "content": "This patch is severely out of date - could we get an update? ",
            "author": "Mark Miller",
            "id": "comment-12786687"
        },
        {
            "date": "2011-01-27T10:03:50+0000",
            "content": "There was no update since long time, the patch is outdated and the reasoning behind is questionable (see Yoniks comment). Closing this issue. ",
            "author": "Uwe Schindler",
            "id": "comment-12987471"
        }
    ]
}