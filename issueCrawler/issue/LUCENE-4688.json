{
    "id": "LUCENE-4688",
    "title": "Reuse TermsEnum in BlockTreeTermsReader",
    "details": {
        "components": [
            "core/codecs"
        ],
        "fix_versions": [
            "4.9",
            "6.0"
        ],
        "affect_versions": "4.0,                                            4.1",
        "priority": "Major",
        "labels": "",
        "type": "Improvement",
        "resolution": "Unresolved",
        "status": "Open"
    },
    "description": "Opening a TermsEnum comes with a significant cost at this point if done frequently like primary key lookups or if many segments are present. Currently we don't reuse it at all and create a lot of objects even if the enum is just used for a single seekExact (ie. TermQuery). Stressing the Terms#iterator(reuse) call shows significant gains with reuse...",
    "attachments": {
        "LUCENE-4688.patch": "https://issues.apache.org/jira/secure/attachment/12565130/LUCENE-4688.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2013-01-16T15:37:32+0000",
            "content": "here is an initial patch including my small benchmark that shows a pretty significant impact of reuse. \n\nthe benchmark indexes 2 Million super small docs and checks for each doc if the ID has already been indexed. I use NRT manager to reopen the reader every second. \n\nthe results are pretty significant IMO: \n\nstart benchmark\nrun with reuse\nRun took: 24 seconds with reuse terms enum = [true]\nrun without reuse\nRun took: 34 seconds with reuse terms enum = [false]\n\n\n\nwhile all tests pass with that patch I really wanna ask somebody (mike?  ) with more knowledge about the BlockTreeTermsReader to look at this patch!! \n\nI also run benchmarks with lucene util but didn't see any real gains with this change so far. ",
            "author": "Simon Willnauer",
            "id": "comment-13555123"
        },
        {
            "date": "2013-01-16T15:39:27+0000",
            "content": "Awesome!  I'll look at the patch.\n\nReuse is important w/ BlockTree's TermsEnum ... ",
            "author": "Michael McCandless",
            "id": "comment-13555126"
        },
        {
            "date": "2013-01-16T16:11:59+0000",
            "content": "Can we break this patch up... particularly i think we should look at the multitermquery API as a separate issue from BlockTree's impl. ",
            "author": "Robert Muir",
            "id": "comment-13555164"
        },
        {
            "date": "2013-01-16T16:56:33+0000",
            "content": "I think it's interesting/powerful to enable across-segment reuse: none\nof our other reuse APIs (DocsEnum, D&PEnum) can do that.\n\nBut I'm not sure we should do it: to take full advantage of it\nrequires API changes (like the MTQ.getTermsEnum change) ... we'd have\nto do something similar to Weight/Scorer to share the D/&PEnum across\nsegments.\n\nThe patch itself is spooky: this BlockTree code is hairy, and I'm not\nsure that the reset() isn't going to cause subtle corner-case bugs.\n(Separately: we need to simplify this code: it's unapproachable now).\n\nThe benchmark gain is impressive, but, we are talking about 10 seconds\nover 2M docs right? So 5 micro-seconds (.005 msec) per document?  In a\nmore realistic scenario (indexing more \"normal\" docs) surely this is a\nminor part of the time ...\n\nThe app can always reuse itself per-segment today ... I think reuse is\nrather expert so it's OK to offer that as the way to reuse? ",
            "author": "Michael McCandless",
            "id": "comment-13555201"
        },
        {
            "date": "2013-07-23T18:44:19+0000",
            "content": "Bulk move 4.4 issues to 4.5 and 5.0 ",
            "author": "Steve Rowe",
            "id": "comment-13716912"
        },
        {
            "date": "2014-04-16T12:54:40+0000",
            "content": "Move issue to Lucene 4.9. ",
            "author": "Uwe Schindler",
            "id": "comment-13970835"
        }
    ]
}