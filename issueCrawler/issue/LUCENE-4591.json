{
    "id": "LUCENE-4591",
    "title": "Make StoredFieldsFormat more configurable",
    "details": {
        "components": [
            "core/codecs"
        ],
        "fix_versions": [
            "4.1"
        ],
        "affect_versions": "4.1",
        "priority": "Major",
        "labels": "",
        "type": "Improvement",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "The current StoredFieldsFormat are implemented with the assumption that only one type of StoredfieldsFormat is used by the index.\nWe would like to be able to configure a StoredFieldsFormat per field, similarly to the PostingsFormat.\nThere is a few issues that need to be solved for allowing that:\n1) allowing to configure a segment suffix to the StoredFieldsFormat\n2) implement SPI interface in StoredFieldsFormat \n3) create a PerFieldStoredFieldsFormat\n\nWe are proposing to start first with 1) by modifying the signature of StoredFieldsFormat#fieldsReader and StoredFieldsFormat#fieldsWriter so that they use SegmentReadState and SegmentWriteState instead of the current set of parameters.\n\nLet us know what you think about this idea. If this is of interest, we can contribute with a first path for 1).",
    "attachments": {
        "PerFieldStoredFieldsWriter.java": "https://issues.apache.org/jira/secure/attachment/12560046/PerFieldStoredFieldsWriter.java",
        "PerFieldStoredFieldsFormat.java": "https://issues.apache.org/jira/secure/attachment/12560044/PerFieldStoredFieldsFormat.java",
        "PerFieldStoredFieldsReader.java": "https://issues.apache.org/jira/secure/attachment/12560045/PerFieldStoredFieldsReader.java",
        "LUCENE-4591.patch": "https://issues.apache.org/jira/secure/attachment/12556485/LUCENE-4591.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2012-12-06T13:05:05+0000",
            "content": "Hi Renaud,\n\nMy concern about a per-field StoredFieldsFormat is that it would increase the number of disk seeks required to load all the stored fields of a document (the current default StoredFieldsFormat impl requires only one disk seek to load all the fields of a document). What are you willing to optimize with a per-field StoredFieldsFormat? ",
            "author": "Adrien Grand",
            "id": "comment-13511319"
        },
        {
            "date": "2012-12-06T13:18:21+0000",
            "content": "Hi Adrien, yes I understand the problem. While, it is true that in the extreme case, people could configure a different StoredFieldsFormat for each field, which will lead to a large increase of disk seeks, here we would like to use the CompressingStoredFieldsFormat for all the standard fields, but have a different mechanism for specific fields.\n\nWe would like to store certain fields that requires a different type of data structure than the one currently supported, i.e., a document is not a simple list of fields, but a more complex data structure.\n\nWe could solve the problem by copying and modifying the current CompressingStoredFieldsWriter and CompressingStoredFieldsReader so that it can decide what type of encoding to use based on the field info. However, this is kind of hacky, and we will have to keep in synch our copy with the original implementation. The only way we could find is to have a perfield approach. ",
            "author": "Renaud Delbru",
            "id": "comment-13511335"
        },
        {
            "date": "2012-12-06T13:50:54+0000",
            "content": "We would like to store certain fields that requires a different type of data structure than the one currently supported, i.e., a document is not a simple list of fields, but a more complex data structure.\n\nHow would you do that? As far as I know, the only way to access stored fields is through the StoredFieldVisitor API, which only supports sequences of fields which are necessary numbers, strings or byte arrays.\n\nHowever, this is kind of hacky, and we will have to keep in synch our copy with the original implementation.\n\nI think writing a different StoredFieldsFormat impl would be a better option as you could still require only one disk seek in the worst case. You could reuse some components of CompressingStoredFieldsFormat such as CompressionMode, and maybe we could expose other ones such as CompressingStoredFieldsFormatIndexWriter,Reader (they write/read the stored fields index in a memory-efficient way).\n\nIf you don't care about increasing the number of disk seeks and if you can encode/decode your complex data structure into a small opaque binary blob, maybe DocValues could be an option (Mike and Robert are adding per-field format support to DocValues in LUCENE-4547). ",
            "author": "Adrien Grand",
            "id": "comment-13511352"
        },
        {
            "date": "2012-12-06T14:05:03+0000",
            "content": "I don't think we should implement an SPI unless its really necessary (I've said this before, SPI is heavy-duty stuff and shouldn't be done on a whim).\n\nAs Adrien describes, StoredFieldsFormat does not really make sense per-field.\n\nI don't think we can/should use SegmentWriteState: since IndexWriter streams stored fields directly to the codec, some parameters like FieldInfos are not available at the time this writer is initialized.\n\nBut I think all components should get and respect segment suffixes! ",
            "author": "Robert Muir",
            "id": "comment-13511381"
        },
        {
            "date": "2012-12-06T14:38:09+0000",
            "content": "\nHow would you do that? As far as I know, the only way to access stored fields is through the StoredFieldVisitor API\n\nYes, but we can pass our own implementation of StoredFieldVisitor with our own specific information about what to retrieve.\n\nSo from Adrien and Robert feedback, it looks like you do not really want to see a perfield StoredFieldsFormat mechanism. that's fine and understandable. \nCould we instead try to open/extend the current code base so that we are more free to extend it on our side ? For example, opening CompressingStoredFieldsWriter and CompressingStoredFieldsReader, as well as making them configurable with a segment suffixes ? That would greatly help. ",
            "author": "Renaud Delbru",
            "id": "comment-13511425"
        },
        {
            "date": "2012-12-06T15:08:11+0000",
            "content": "Could we instead try to open/extend the current code base so that we are more free to extend it on our side?\n\nCan you list what you exactly need and/or provide us with a patch? ",
            "author": "Adrien Grand",
            "id": "comment-13511440"
        },
        {
            "date": "2012-12-06T15:54:47+0000",
            "content": "As I said before, In my opinion all (or at least most) codec components should take segment suffixes and respect them.\n\nI actually have a nocommit for this in LUCENE-4547 branch.\n\nI was thinking we could even have a test for this, that writes a segment directly to all the consumers with a suffix and then\nchecks the filenames and so on. ",
            "author": "Robert Muir",
            "id": "comment-13511475"
        },
        {
            "date": "2012-12-06T19:40:27+0000",
            "content": "Given that the task to properly support segment suffixes looks more difficult than expected (until maybe Robert comes with a patch), the remaining solution for us, in order to avoid to copy most of the compressing package, would be to open CompressingStoredFieldsWriter and CompressingStoredFieldsReader, i.e., make them public and non final (see patch). I am not sure that would be acceptable for you, but that would be good for expert-level extension. ",
            "author": "Renaud Delbru",
            "id": "comment-13512043"
        },
        {
            "date": "2012-12-07T17:06:05+0000",
            "content": "Why would you need to make them non-final? ",
            "author": "Adrien Grand",
            "id": "comment-13526544"
        },
        {
            "date": "2012-12-07T17:53:54+0000",
            "content": "To be able to subclass and extend them. If that is not acceptable for you, then the solution left to us is to copy-paste the original code, extend it on our side (and close this issue).  ",
            "author": "Renaud Delbru",
            "id": "comment-13526575"
        },
        {
            "date": "2012-12-08T15:05:51+0000",
            "content": "I had a look at CompressingStoredFieldsWriter and I think that having a different encoding/compression strategy per field would deserve a different StoredFieldsFormat impl (this is a discussion we had in LUCENE-4226, but in that case I think we could open up CompressingStoredFieldsIndexWriter/Reader). However I was thinking that if you don't mind adding one or two extra random seeks, maybe you could reuse it without extending it, like\n\nMyCustomStoredFieldsWriter {\n\n  StoredFieldsWriter defaultSfw; // the default Lucene 4.1 stored fields writer\n\n  writeField(FieldInfo info, StorableField field) {\n    if (isStandard(field)) {\n      defaultSfw.writeField(info, field);\n    } else {\n      // TODO: custom logic writing non-standard fields to another IndexOutput\n    }\n  }\n\n}\n\n\n\nand similarly for the reader\n\n\nMyCustomStoredFieldsReader {\n\n  StoredFieldsReader defaultSfr; // the default Lucene 4.1 stored fields reader\n\n  void visitDocument(int n, StoredFieldVisitor visitor) {\n    // visit standard fields\n    defaultSfr.visitDocument(n, visitor);\n    // TODO then visit specific fields\n  }\n\n}\n\n\n\nWould it work for your use-case? ",
            "author": "Adrien Grand",
            "id": "comment-13527160"
        },
        {
            "date": "2012-12-08T21:09:59+0000",
            "content": "It is a similar approach that we followed (see attached files: PerFieldStoredFieldsFormat, PerFieldStoredFieldsWriter and PerFieldStoredFieldsReader).\nThe issue is that our secondary StoredFieldsReader/Writer we are using is, for the moment, a wrapper around an instance of the CompressingStoredFieldsReader/Writer (using a wrapper approach was another way to extend CompressingStoredFieldsReader/Writer). The wrapper implements our encoding logic, and uses the underlying CompressingStoredFieldsWriter to write our data as a binary block. The problem with this approach is that since we can not configure the segment suffix of the CompressingStoredFieldsWriter, then the two StoredFieldsFormat try to write to files that have identical names.\nSince we are using a CompressingStoredFieldsReader/Writer as underlying mechanism to write the stored fields, why are we not using just one instance to store default lucene fields and our specific fields ? The reasons are: that it was more simple for our first implementation to leverage CompressingStoredFieldsReader/Writer (as a temporary solution); and that we would like to keep things (code and segment files) more isolated from each other.\nAs said previously, we could simply copy-paste the compressing codec on our side to solve the problem, but I thought that maybe by raising the issue, we could have found a more appropriate solution. ",
            "author": "Renaud Delbru",
            "id": "comment-13527261"
        },
        {
            "date": "2012-12-09T13:20:27+0000",
            "content": "Another solution would be to extend the  constructors of CompressingStoredFieldsWriter/Reader to accept a segment suffix as parameter. See new patch attached. And this might also pave the road for Robert's work on making codec components respectful of segment suffix. ",
            "author": "Renaud Delbru",
            "id": "comment-13527450"
        },
        {
            "date": "2012-12-09T23:03:29+0000",
            "content": "Adding constructors to support segment suffixes sounds good! I modified your patch to add lucene.experimental tags and make ant precommit pass. If it is fine with you, I'll commit it soon. ",
            "author": "Adrien Grand",
            "id": "comment-13527647"
        },
        {
            "date": "2012-12-10T11:51:52+0000",
            "content": "That is fine for me. Thanks for your help Adrien. ",
            "author": "Renaud Delbru",
            "id": "comment-13527894"
        },
        {
            "date": "2012-12-10T13:44:08+0000",
            "content": "[trunk commit] Adrien Grand\nhttp://svn.apache.org/viewvc?view=revision&revision=1419449\n\nLUCENE-4591: Make CompressingStoredFields\n{Writer,Reader}\n accept a segment suffix as a constructor parameter.\n ",
            "author": "Commit Tag Bot",
            "id": "comment-13527930"
        },
        {
            "date": "2012-12-10T14:16:08+0000",
            "content": "[branch_4x commit] Adrien Grand\nhttp://svn.apache.org/viewvc?view=revision&revision=1419483\n\nLUCENE-4591: Make CompressingStoredFields\n{Writer,Reader}\n accept a segment suffix as a constructor parameter (merged from r1419449).\n ",
            "author": "Commit Tag Bot",
            "id": "comment-13527950"
        }
    ]
}