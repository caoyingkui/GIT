{
    "id": "LUCENE-2798",
    "title": "Randomize indexed collation key testing",
    "details": {
        "labels": "",
        "priority": "Minor",
        "components": [
            "modules/analysis"
        ],
        "type": "Test",
        "fix_versions": [
            "4.9",
            "6.0"
        ],
        "affect_versions": "3.1,                                            4.0-ALPHA",
        "resolution": "Unresolved",
        "status": "Open"
    },
    "description": "Robert Muir noted on #lucene IRC channel today that Lucene's indexed collation key testing is currently fragile (for example, they had to be revisited when Robert upgraded the ICU dependency in LUCENE-2797 because of Unicode 6.0 collation changes) and coverage is trivial (only 5 locales tested, and no collator options are exercised).  This affects both the JDK implementation in modules/analysis/common/ and the ICU implementation under modules/icu/.\n\nThe key thing to test is that the order of the indexed terms is the same as that provided by the Collator itself.  Instead of the current set of static tests, this could be achieved via indexing randomly generated terms' collation keys (and collator options) and then comparing the index terms' order to the order provided by the Collator over the original terms.\n\nSince different terms may produce the same collation key, however, the order of indexed terms is inherently unstable.  When performing runtime collation, the Collator addresses the sort stability issue by adding a secondary sort over the normalized original terms.  In order to directly compare Collator's sort with Lucene's collation key sort, a secondary sort will need to be applied to Lucene's indexed terms as well. Robert has suggested indexing the original terms in addition to their collation keys, then using a Sort over the original terms as the secondary sort.\n\nAnother complication: Lucene 3.X uses Java's UTF-16 term comparison, and trunk uses UTF-8 order, so the implemented secondary sort will need to respect that.\n\nFrom #lucene:\n\nrmuir__: so i think we have to on 3.x, sort the 'expected list' with Collator.compare, if thats equal, then as a tiebreak use String.compareTo\nrmuir__: and in the index sort on the collated field, followed by the original term\nrmuir__: in 4.x we do the same thing, but dont use String.compareTo as the tiebreak for the expected list\nrmuir__: instead compare codepoints (iterating character.codepointAt, or comparing .getBytes(\"UTF-8\"))",
    "attachments": {
        "LUCENE-2798.patch": "https://issues.apache.org/jira/secure/attachment/12475983/LUCENE-2798.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2010-12-05T12:33:49+0000",
            "content": "Steven, before working too hard on the jdk collation tests, i just had this idea:\n\nAre we sure we shouldn't deprecate the jdk collation functionality (remove in trunk) and only offer ICU?\n\nI was just thinking that the JDK Collator integration is basically a RAM trap due to its aweful keysize, etc:\nhttp://site.icu-project.org/charts/collation-icu4j-sun\n ",
            "author": "Robert Muir",
            "id": "comment-12966933"
        },
        {
            "date": "2010-12-08T17:53:48+0000",
            "content": "\nAre we sure we shouldn't deprecate the jdk collation functionality (remove in trunk) and only offer ICU?\n\nI was just thinking that the JDK Collator integration is basically a RAM trap due to its aweful keysize, etc:\nhttp://site.icu-project.org/charts/collation-icu4j-sun\n\nI don't like this idea, because it removes the choice.\n\nIf there were some way to perform deprecation without eventual removal, I'd be okay with it.  The issue, as I see it, is documentaiton.  Here is an excerpt from the current class-level javadoc for CollationKeyFilter:\n\n\nThe <code>ICUCollationKeyFilter</code> in the icu package of Lucene's contrib area uses ICU4J's Collator, which makes its version available, thus allowing collation to be versioned independently from the JVM.  ICUCollationKeyFilter is also significantly faster and generates significantly shorter keys than CollationKeyFilter.  See http://site.icu-project.org/charts/collation-icu4j-sun for key generation timing and key length comparisons between ICU4J and java.text.Collator over several languages.\n\nSo an attempt is already being made to inform potential victims of the choice they're making - it even links to the same web page you mentioned.\n\nMaybe if we move the JDK variant out of core and into a module, rather than on trunk, it would at least send a message that it's on par with the ICU variant. ",
            "author": "Steve Rowe",
            "id": "comment-12969395"
        },
        {
            "date": "2011-04-11T07:25:45+0000",
            "content": "work in progress: JDK-only Analyzer-only test: TestCollationKeyAnalyzer.testRandomizedCollationKeySort().\n\nThe test succeeds most of the times I run it, but sometimes fails, e.g. for these seeds:\n\n\n\t3253903552510972177:-5236779063463918718\n\t1469913545269555695:-7929666046197505961\n\n\n\nRobert, would you please take a look at the code and see if you can figure out why the test fails? ",
            "author": "Steve Rowe",
            "id": "comment-13018230"
        },
        {
            "date": "2011-04-11T11:08:32+0000",
            "content": "just a glance: \n\nit may be the use of _TestUtil.randomUnicodeString here.\nit is not just avoiding supplementaries, but also avoiding things like U+FFFF\n\nbottom line: there are serious bugs in this stuff, and even my current \"testThreadSafe\" i think is not completely avoiding them (I seem to trigger a OOM from the jre impl every few days)\n\nI've thought about @Ignore'ing our current testThreadSafe for this reason... I don't like dancing around known bugs in a test like this, it makes the test stupid. Somehow this stuff needs to get fixed in ICU/OpenJDK. ",
            "author": "Robert Muir",
            "id": "comment-13018283"
        },
        {
            "date": "2011-04-11T14:02:47+0000",
            "content": "it may be the use of _TestUtil.randomUnicodeString here.\n\nIt may, but the first above-listed seed produces this mismatch (strings are printed out as arrays of codepoints):\n\n\njava.lang.AssertionError: -----------\nIndexed string #45: [141]\n Sorted string #45: [141]\n-----------\nIndexed string #46: [32]\n Sorted string #46: [28, 777]\n-----------\nIndexed string #47: [28, 777]\n Sorted string #47: [32]\n\nCollator strength: SECONDARY  Collator decomposition: CANONICAL_DECOMPOSITION\n\n\n\n#46 and #47 include neither supplementary chars nor problematic BMP chars.\n\nI wrote a test including just [32] and [28,777] as indexed strings, and the same mismatch occurs for random locales, regardless of collator decomposition, and for all collator strengths except PRIMARY. ",
            "author": "Steve Rowe",
            "id": "comment-13018353"
        },
        {
            "date": "2011-04-11T14:16:45+0000",
            "content": "\nI wrote a test including just [32] and [28,777] as indexed strings, and the same mismatch occurs for random locales, regardless of collator decomposition, and for all collator strengths except PRIMARY.\n\nWithout looking too hard (are these hex values?) in your debugging it would be useful to print the sort key as well. Are the sort keys the same?\n\nBut FYI the bugs i found in collation, somehow corrupted the internal state of RuleBasedCollator, so the exact strings you are looking at might simply be a symptom. ",
            "author": "Robert Muir",
            "id": "comment-13018365"
        },
        {
            "date": "2011-04-11T14:49:29+0000",
            "content": "Without looking too hard (are these hex values?) \n\nNo, it's just the output from Arrays.toString(int[]), which outputs decimal.\n\nin your debugging it would be useful to print the sort key as well.\n\nAgreed. Here's the output:\n\n\njava.lang.AssertionError: -----------\nIndexed string #0: [32]\nIndexed collation key: [0, 0, 0, 119, 0, 0]\n Sorted string #0: [28, 777]\nSorted collation key: [0, 0, 0, -101, 0, 0]\n-----------\nIndexed string #1: [28, 777]\nIndexed collation key: [0, 0, 0, -101, 0, 0]\n Sorted string #1: [32]\nSorted collation key: [0, 0, 0, 119, 0, 0]\n\nCollator strength: SECONDARY  Collator decomposition: NO_DECOMPOSITION\n\n(again with the Arrays.toString() for the byte array from the collation keys - obviously not ideal in that they're first converted to signed integers...)\n\nAre the sort keys the same?\n\nNo. ",
            "author": "Steve Rowe",
            "id": "comment-13018374"
        },
        {
            "date": "2011-04-11T15:10:26+0000",
            "content": "also i don't see any check that preflex codec isn't in use for this test?\n ",
            "author": "Robert Muir",
            "id": "comment-13018383"
        },
        {
            "date": "2011-04-11T15:16:59+0000",
            "content": "also i don't see any check that preflex codec isn't in use for this test?\n\nTestCollationKeyAnalyzer.setUp() handles it:\n\n  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    assumeFalse(\"preflex format only supports UTF-8 encoded bytes\", \"PreFlex\".equals(CodecProvider.getDefault().getDefaultFieldCodec()));\n  }\n\n\n\nAnd in practice, the test gets skipped 25% of the time as a result of this. ",
            "author": "Steve Rowe",
            "id": "comment-13018386"
        },
        {
            "date": "2011-04-11T15:19:57+0000",
            "content": "Added two-term collation sort test; added collation key debug printing. ",
            "author": "Steve Rowe",
            "id": "comment-13018388"
        },
        {
            "date": "2013-07-23T18:44:38+0000",
            "content": "Bulk move 4.4 issues to 4.5 and 5.0 ",
            "author": "Steve Rowe",
            "id": "comment-13717008"
        },
        {
            "date": "2014-04-16T12:54:35+0000",
            "content": "Move issue to Lucene 4.9. ",
            "author": "Uwe Schindler",
            "id": "comment-13970808"
        }
    ]
}