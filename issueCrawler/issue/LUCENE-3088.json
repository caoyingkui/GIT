{
    "id": "LUCENE-3088",
    "title": "inconsistency of tokenstream.end() with OffsetLimitTokenFilter and LimitTokenCountFilter",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [],
        "type": "Bug",
        "fix_versions": [],
        "affect_versions": "None",
        "resolution": "Unresolved",
        "status": "Open"
    },
    "description": "In LUCENE-3064, we added some state and checks to MockTokenizer to validate that consumers\nare properly using the tokenstream workflow (described here: http://lucene.apache.org/java/3_0_3/api/core/org/apache/lucene/analysis/TokenStream.html)\n\nOne inconsistency is the following steps:\n4. The consumer calls incrementToken() until it returns false consuming the attributes after each call.\n5. The consumer calls end() so that any end-of-stream operations can be performed.\n\nIn the case of these limitingfilters, end() is called on the Tokenizer before incrementToken() returns false. This is a little strange for a few reasons: one is that the tokenizer might not even be \"ready\" for end(), e.g. it might be coded where end() only works correctly if its entirely consumed. The other problem of course is that the finalOffset, the general use of end(), will most often be wrong in this case, so multi-valued field highlighting will not work.\n\nWe should probably figure out a way to address the inconsistency, some ideas are:\n\n\tfixing the javadocs, perhaps documenting that end() could be called at any time, and accepting the fact that the finalOffset will be wrong.\n\tthe limiting filters could consume the rest of the tokens in a while (incrementToken()) loop to ensure totally proper behavior.\n\tthe limiting filters could do something tricky like override end() so that its not invoked on the Tokenizer in a surprising state. This is still evil but perhaps less evil than calling it \"out of order\".\n\t...",
    "attachments": {},
    "issue_links": {},
    "comments": []
}