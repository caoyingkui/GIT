{
    "id": "SOLR-12523",
    "title": "Confusing error reporting if backup attempted on non-shared FS",
    "details": {
        "labels": "",
        "priority": "Minor",
        "components": [
            "Backup/Restore"
        ],
        "type": "Bug",
        "fix_versions": [
            "7.5",
            "master (8.0)"
        ],
        "affect_versions": "7.3.1",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "So I have a large collection with 4 shards across 2 nodes. When I try to back it up with:\n\n\ncurl \"http://localhost:8984/solr/admin/collections?action=BACKUP&name=sigs&collection=foo_signals&async=5&location=backups\"\n\n\n\n\nI either get:\n\n\n\"5170256188349065\":{\n\n\u00a0 \u00a0 \"responseHeader\":{\n\n\u00a0 \u00a0 \u00a0 \"status\":0,\n\n\u00a0 \u00a0 \u00a0 \"QTime\":0},\n\n\u00a0 \u00a0 \"STATUS\":\"failed\",\n\n\u00a0 \u00a0 \"Response\":\"Failed to backup core=foo_signals_shard1_replica_n2 because org.apache.solr.common.SolrException: Directory to contain snapshots doesn't exist: file:///vol1/cloud84/backups/sigs\"},\n\n\u00a0 \"5170256187999044\":{\n\n\u00a0 \u00a0 \"responseHeader\":{\n\n\u00a0 \u00a0 \u00a0 \"status\":0,\n\n\u00a0 \u00a0 \u00a0 \"QTime\":0},\n\n\u00a0 \u00a0 \"STATUS\":\"failed\",\n\n\u00a0 \u00a0 \"Response\":\"Failed to backup core=foo_signals_shard3_replica_n10 because org.apache.solr.common.SolrException: Directory to contain snapshots doesn't exist: file:///vol1/cloud84/backups/sigs\"},\n\n\n\n\nor if I create the directory, then I get:\n\n\n{\n\n\u00a0 \"responseHeader\":{\n\n\u00a0 \u00a0 \"status\":0,\n\n\u00a0 \u00a0 \"QTime\":2},\n\n\u00a0 \"Operation backup caused exception:\":\"org.apache.solr.common.SolrException:org.apache.solr.common.SolrException: The backup directory already exists: file:///vol1/cloud84/backups/sigs/\",\n\n\u00a0 \"exception\":{\n\n\u00a0 \u00a0 \"msg\":\"The backup directory already exists: file:///vol1/cloud84/backups/sigs/\",\n\n\u00a0 \u00a0 \"rspCode\":400},\n\n\u00a0 \"status\":{\n\n\u00a0 \u00a0 \"state\":\"failed\",\n\n\u00a0 \u00a0 \"msg\":\"found [2] in failed tasks\"}}\n\n\n\n\nI'm thinking this has to do with having 2 cores from the same collection on the same node but I can't get a collection with 1 shard on each node to work either:\n\n\n\"ec2-52-90-245-38.compute-1.amazonaws.com:8984_solr\":\"org.apache.solr.client.solrj.impl.HttpSolrClient$RemoteSolrException:Error from server at http://ec2-52-90-245-38.compute-1.amazonaws.com:8984/solr: Failed to backup core=system_jobs_history_shard2_replica_n6 because org.apache.solr.common.SolrException: Directory to contain snapshots doesn't exist: file:///vol1/cloud84/backups/ugh1\"}\n\n\n\n\nWhat's weird is that\u00a0replica\u00a0(system_jobs_history_shard2_replica_n6) is not even on the\u00a0ec2-52-90-245-38.compute-1.amazonaws.com node! It lives on a different node.",
    "attachments": {
        "SOLR-12523.patch": "https://issues.apache.org/jira/secure/attachment/12929544/SOLR-12523.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2018-06-27T20:39:31+0000",
            "content": "some logs:\n\n\n2018-06-27 20:36:49.739 INFO\u00a0 (qtp853119666-19) [ \u00a0 ] o.a.s.h.a.CollectionsHandler Invoked Collection Action :backup with params name=tim1&action=BACKUP&location=/vol1/backups&collection=foo_signals and sendToOCPQueue=true\n\n\u00a0\n\n2018-06-27 20:36:49.751 ERROR (qtp853119666-18) [ \u00a0 ] o.a.s.h.RequestHandlerBase org.apache.solr.common.SolrException: Failed to backup core=foo_signals_shard2_replica_n4 because org.apache.solr.common.SolrException: Directory to contain snapshots doesn't exist: file:///vol1/backups/tim1\n\n\u00a0\n\n2018-06-27 20:36:49.751 INFO\u00a0 (qtp853119666-18) [ \u00a0 ] o.a.s.s.HttpSolrCall [admin] webapp=null path=/admin/cores params=\\{core=foo_signals_shard2_replica_n4&qt=/admin/cores&name=shard2&action=BACKUPCORE&location=file:///vol1/backups/tim1&wt=javabin&version=2} status=500 QTime=1\n\n\u00a0\n\n2018-06-27 20:36:49.752 ERROR (qtp853119666-18) [ \u00a0 ] o.a.s.s.HttpSolrCall null:org.apache.solr.common.SolrException: Failed to backup core=foo_signals_shard2_replica_n4 because org.apache.solr.common.SolrException: Directory to contain snapshots doesn't exist: file:///vol1/backups/tim1\n\n\u00a0\n\n2018-06-27 20:36:49.754 ERROR (qtp853119666-23) [ \u00a0 ] o.a.s.h.RequestHandlerBase org.apache.solr.common.SolrException: Failed to backup core=foo_signals_shard3_replica_n10 because org.apache.solr.common.SolrException: Directory to contain snapshots doesn't exist: file:///vol1/backups/tim1\n\n\u00a0\n\n2018-06-27 20:36:49.754 INFO\u00a0 (qtp853119666-23) [ \u00a0 ] o.a.s.s.HttpSolrCall [admin] webapp=null path=/admin/cores params=\\{core=foo_signals_shard3_replica_n10&qt=/admin/cores&name=shard3&action=BACKUPCORE&location=file:///vol1/backups/tim1&wt=javabin&version=2} status=500 QTime=0\n\n\u00a0\n\n2018-06-27 20:36:49.754 ERROR (qtp853119666-23) [ \u00a0 ] o.a.s.s.HttpSolrCall null:org.apache.solr.common.SolrException: Failed to backup core=foo_signals_shard3_replica_n10 because org.apache.solr.common.SolrException: Directory to contain snapshots doesn't exist: file:///vol1/backups/tim1\n\n\u00a0\n\n2018-06-27 20:36:49.781 INFO\u00a0 (qtp853119666-19) [ \u00a0 ] o.a.s.s.HttpSolrCall [admin] webapp=null path=/admin/collections params=\\{name=tim1&action=BACKUP&location=/vol1/backups&collection=foo_signals} status=500 QTime=42\n\n\n ",
            "author": "Timothy Potter",
            "id": "comment-16525594"
        },
        {
            "date": "2018-06-27T20:56:34+0000",
            "content": "so sounds like Solr is expecting a shared location across nodes here?\n\n\nSnapShooter snapShooter = new SnapShooter(repository, core, locationUri, name, commitName);\n// validateCreateSnapshot will create parent dirs instead of throw; that choice is dubious.\n// But we want to throw. One reason is that\n// this dir really should, in fact must, already exist here if triggered via a collection backup on a shared\n// file system. Otherwise, perhaps the FS location isn't shared -- we want an error.\nif (!snapShooter.getBackupRepository().exists(snapShooter.getLocation())) {\n throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n \"Directory to contain snapshots doesn't exist: \" + snapShooter.getLocation());\n}\nsnapShooter.validateCreateSnapshot();\nsnapShooter.createSnapshot();\n\n\n ",
            "author": "Timothy Potter",
            "id": "comment-16525603"
        },
        {
            "date": "2018-06-27T21:20:20+0000",
            "content": "Yes, you need a shared file system with the same file path across nodes. The error messages is not very helpful.\n\nThe reference Guide at https://lucene.apache.org/solr/guide/7_4/collections-api.html#backup\u00a0says:\nBacks up Solr collections and associated configurations to a shared filesystem - for example a Network File System.\nWe should probably add a CAUTION box in the refGuide for the shared fs requirement. We should also improve the error messages. Perhaps the BackupCmd\u00a0could do a pre-check before starting the backup by writing a file with random file name into the backup root folder and then ask each node to check for the existence of that file - if it fails we'd abort the backup with some sane error message.\n\nThe error message you quoted above will only be printed in case of an issue with non-shared FS, right? So perhaps a quick fix is to improve that error message and mention the shared FS requirement right there? ",
            "author": "Jan H\u00f8ydahl",
            "id": "comment-16525628"
        },
        {
            "date": "2018-06-27T21:32:11+0000",
            "content": "why does it need a shared filesystem? that's very uncloud like ... I'd use S3 but it's too slow to move these files one-by-one to S3 and SOLR-9958 prevents that from working correctly anyway ... but I've moved on and am just using BACKUPCORE and then using a bulk copy solution to move the files to cloud storage\n\n\u00a0 ",
            "author": "Timothy Potter",
            "id": "comment-16525644"
        },
        {
            "date": "2018-06-27T21:41:26+0000",
            "content": "The backup repository implementations are pluggable, so perhaps it would be possible to make one that can be smart with local storage and then do some post-action in order to move the generated backups for each shard leader somewhere?\n\nOr perhaps an S3BackupRepository which uses local FS as a buffer streams the index folder using ZipOutputStream\u00a0and over to s3. The restore command would do the opposite. ",
            "author": "Jan H\u00f8ydahl",
            "id": "comment-16525654"
        },
        {
            "date": "2018-06-27T22:11:42+0000",
            "content": "Good ideas! I'll try to get the S3AFileSystem working again ... I forget what all the issues are with that besides 9958, then we can iterate from there. ",
            "author": "Timothy Potter",
            "id": "comment-16525669"
        },
        {
            "date": "2018-06-28T08:47:46+0000",
            "content": "Have you seen\u00a0SOLR-9952? It uses HdfsDirectory to write to s3. Also I found\u00a0this\u00a0which seems to allow smart buffering and parallell streaming of data to s3. But I think such effort should continue in SOLR-9952 or new JIRAs. Let's use this one to improve docs and error messages for 7.x. ",
            "author": "Jan H\u00f8ydahl",
            "id": "comment-16526117"
        },
        {
            "date": "2018-06-28T09:01:09+0000",
            "content": "Changed issue title. See attached patch for suggested improvements ",
            "author": "Jan H\u00f8ydahl",
            "id": "comment-16526128"
        },
        {
            "date": "2018-06-28T14:52:18+0000",
            "content": "why does it need a shared filesystem?\n\nCan you explain how you thought or hoped this mechanism worked?  Perhaps you thought of it more as as an in-place snapshot mechanism \u2013 SOLR-9038.  This feature is conceived of a way to back up everything to one place, and that one place needs to accessible to all nodes in the cluster \u2013 hence a shared file system requirement.  It could be interesting if just one node has access to the backup destination and somehow you indicate which node that is.  \n\nAlso FYI Jeff Wartes / Whitepages.com has some cool utilities here: https://github.com/whitepages/solrcloud_manager#cluster-commands \"backupindex\", \"restoreindex\".\n\nThanks Jan for clarifying this issue is about the need for better error messages / documentation. ",
            "author": "David Smiley",
            "id": "comment-16526389"
        },
        {
            "date": "2018-06-28T17:15:20+0000",
            "content": "When I'm working on a cloud platform like EC2 or Google cloud, I don't want to deal with NFS when I have cloud storage like S3. I haven't had much luck in the past with using the Hdfs directory factory with S3 (I'll checkout SOLR-9952), so I figured I would just create the backup using Solr and then move the files out to cloud storage using tools optimized for S3. In the past, I think using an S3 destination for backup worked OK, but RESTORE took forever (all the check summing / sanity checking per file serially vs. concurrently) and given backup is usually part of a disaster recovery strategy, I don't want RESTORE taking hours to restore my index. If I pull that down from cloud storage to the local disks using some tool that's optimized for reading in bulk from S3 (multi-threaded) and then restore from local, it's much faster. So for me, separating the concerns of creating the snapshot for each shard (Solr's job) and moving big files out to cloud storage (Solr needs to do much better in this regard or punt) is what I'm looking for. ",
            "author": "Timothy Potter",
            "id": "comment-16526566"
        },
        {
            "date": "2018-06-29T01:50:40+0000",
            "content": "So for me, separating the concerns of creating the snapshot for each shard (Solr's job) and moving big files out to cloud storage (Solr needs to do much better in this regard or punt) is what I'm looking for.\nTimothy Potter this is the exact use case for which we added snapshots mechanism (Ref:\u00a0SOLR-9038). As part of Cloudera Search, we use this functionality to provide backup and disaster recovery functionality for Solr,\n\nhttps://blog.cloudera.com/blog/2017/05/how-to-backup-and-disaster-recovery-for-apache-solr-part-i/\n\n\u00a0\n\nWhen user creates a snapshot, Solr associates user specified snapshot name with the latest commit point for each core associated with the given collection. Once the snapshot is created, Solr ensures that the files associated with the commit point associated with the snapshot name are not deleted (e.g. as part of optimize operation). It also records the snapshot metadata in Zookeeper and provides access to it via Collections API. Now you are free to use any mechanism to copy these index files to remote location (e.g. in our case we use DistCp - a tool specifically designed for large scale data copy\u00a0which\u00a0also works well with cloud object stores). I agree with your point about slow restore operation. May be we can extend the snapshot API to restore in-place ? e.g. create index.xxx directory automatically and copy the files. Once this is done, we can just switch the index directory on-the-fly (just the way we do at the time of full replication as part of core recovery).\u00a0\n\n\u00a0\n\n\u00a0\n\n\u00a0 ",
            "author": "Hrishikesh Gadre",
            "id": "comment-16527029"
        },
        {
            "date": "2018-06-29T08:20:40+0000",
            "content": "I agree with your point about slow restore operation. May be we can extend the snapshot API to restore in-place\u00a0\nYeah I think providing a way to restore the snapshots in place would be great! ",
            "author": "Varun Thacker",
            "id": "comment-16527310"
        },
        {
            "date": "2018-06-29T11:52:33+0000",
            "content": "Tested the patch, and it passes precommit. Here's the new\u00a0error text from the API when attempting a backup across two nodes that do NOT share the backup drive. The same error will also be logged in the logs on both nodes. Will commit soon.\n\n{\n\"responseHeader\": {\n\"status\": 500, \"QTime\": 135\n}, \"failure\": {\n\"10.5.0.5:8983_solr\": \"org.apache.solr.client.solrj.impl.HttpSolrClient$RemoteSolrException:Error from server at http://10.5.0.5:8983/solr: Failed to backup core=coll2_shard1_replica_n2 because org.apache.solr.common.SolrException: Directory to contain snapshots doesn't exist: file:///back/myback2. Backup folder must already exist. Note also that Backup/Restore of a SolrCloud collection requires a shared file system mounted at the same path on all nodes!\"\n}, \"Operation backup caused exception:\": \"org.apache.solr.common.SolrException:org.apache.solr.common.SolrException: Could not backup all replicas\", \"exception\": {\n\"msg\": \"Could not backup all replicas\", \"rspCode\": 500\n}, \"error\": {\n\"metadata\": [\n\"error-class\", \"org.apache.solr.common.SolrException\", \"root-error-class\", \"org.apache.solr.common.SolrException\"\n], \"msg\": \"Could not backup all replicas\", \"trace\": \"org.apache.solr.common.SolrException: Could not backup all replicas\\n\\tat org.apache.solr.client.solrj.SolrResponse.getException(SolrResponse.java:53)\\n\\tat \n[...snip...]\n}\n}\n\nOne unrelated observation here. Part of the error response says: Could not backup all replicas. While we might call any core a \"replica\", it would perhaps in the context of a collection backup be more precise to say Could not backup all shards? Mark Miller it's your code line \u00a0 ",
            "author": "Jan H\u00f8ydahl",
            "id": "comment-16527505"
        },
        {
            "date": "2018-08-13T09:39:53+0000",
            "content": "Planning to change text \"Could not backup all replicas\" to \"Could not backup all shards\" and then commit. ",
            "author": "Jan H\u00f8ydahl",
            "id": "comment-16578021"
        },
        {
            "date": "2018-08-15T11:49:10+0000",
            "content": "Commit f3339d14c9ff11163dd89b1b03529ef53ee29b49 in lucene-solr's branch refs/heads/master from Jan H\u00f8ydahl\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=f3339d1 ]\n\nSOLR-12523: Improve error reporting and docs regarding Collection backup feature shared-fs requirement ",
            "author": "ASF subversion and git services",
            "id": "comment-16580968"
        },
        {
            "date": "2018-08-15T12:09:04+0000",
            "content": "Commit 806d087adf9ab5f3afd45714686ad3a29e6aa508 in lucene-solr's branch refs/heads/branch_7x from Jan H\u00f8ydahl\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=806d087 ]\n\nSOLR-12523: Improve error reporting and docs regarding Collection backup feature shared-fs requirement\n\n(cherry picked from commit f3339d1) ",
            "author": "ASF subversion and git services",
            "id": "comment-16580988"
        }
    ]
}