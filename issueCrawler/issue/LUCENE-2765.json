{
    "id": "LUCENE-2765",
    "title": "Optimize scanning in DocsEnum",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [],
        "type": "Improvement",
        "fix_versions": [
            "4.9",
            "6.0"
        ],
        "affect_versions": "None",
        "resolution": "Unresolved",
        "status": "Open"
    },
    "description": "Similar to LUCENE-2761:\n\nwhen we call advance(), after skipping it scans, but this can be optimized better than calling nextDoc() like today\n\n\n      // scan for the rest:\n      do {\n        nextDoc();\n      } while (target > doc);\n\n\n\nin particular, the freq can be \"skipVinted\" and the skipDocs (deletedDocs) don't need to be checked during this scanning.",
    "attachments": {
        "LUCENE-2765.patch": "https://issues.apache.org/jira/secure/attachment/12459666/LUCENE-2765.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2010-11-15T22:55:58+0000",
            "content": "Also, another idea like LUCENE-2761 is to specialize the omitTF case here...\n ",
            "author": "Robert Muir",
            "id": "comment-12932247"
        },
        {
            "date": "2010-11-16T00:35:02+0000",
            "content": "here's a patch, maybe can be beautified/optimized further.\n\nneeds benchmarking. ",
            "author": "Robert Muir",
            "id": "comment-12932281"
        },
        {
            "date": "2010-11-16T00:37:52+0000",
            "content": "my mistake, i left an extra check in the code... here's the updated one. ",
            "author": "Robert Muir",
            "id": "comment-12932283"
        },
        {
            "date": "2010-11-16T00:51:47+0000",
            "content": "i ran a quick very rough check, with AND query (3149 results for this query)... \ni didnt benchmark the omitTF case (but it should be better too)\n\nall times in milliseconds\n\n\n    QueryParser qp = new QueryParser(Version.LUCENE_CURRENT, \"body\", new MockAnalyzer());\n    Query query = qp.parse(\"+the +america\");\n    System.out.println(searcher.search(query, 10).totalHits);\n    long ms = System.currentTimeMillis();\n    for (int i = 0; i < 1000; i++) {\n      searcher.search(query, 10);\n    }\n    long ms2 = System.currentTimeMillis();\n    System.out.println(\"time = \" + (ms2 - ms));\n\n\n\n\n\n\nsetup\nrun1\nrun2\nrun3\nrun4\nrun5\nrun6\n\n\ntrunk\n1707\n1706\n1709\n1704\n1704\n1703\n\n\nLUCENE-2765\n1628\n1623\n1641\n1624\n1627\n1628\n\n\n\n\n\nseems worth it to me. ",
            "author": "Robert Muir",
            "id": "comment-12932291"
        },
        {
            "date": "2010-11-17T12:07:14+0000",
            "content": "here is Mike's results on his wikipedia index (multi-segment, 5% deletions) with the patch.\n\n\n\n\nQuery\nQPS base\nQPS spec\nPct diff\n\n\n\"unit state\"\n7.94\n7.84\n-1.3%\n\n\nstate\n36.15\n35.81\n-1.0%\n\n\nspanNear([unit, state], 10, true)\n4.46\n4.42\n-0.9%\n\n\nspanFirst(unit, 5)\n16.51\n16.45\n-0.4%\n\n\nunit state\n10.76\n10.78\n0.1%\n\n\nunit~2.0\n13.83\n14.06 \n1.7%\n\n\nunit~1.0\n14.36\n14.69 \n2.3%\n\n\nuni*\n15.57\n16.02\n2.9%\n\n\nunit*\n27.29\n28.26\n3.5%\n\n\n+unit +state\n11.73\n12.31\n4.9%\n\n\nunited~1.0\n29.01\n30.86\n6.4%\n\n\nun*d\n66.52\n70.99\n6.7%\n\n\nu*d\n21.29\n22.98\n7.9%\n\n\nunited~2.0\n6.48\n7.07\n9.1%\n\n\n+nebraska +state\n169.87\n188.95\n11.2%\n\n\n\n ",
            "author": "Robert Muir",
            "id": "comment-12932920"
        },
        {
            "date": "2013-07-23T18:44:51+0000",
            "content": "Bulk move 4.4 issues to 4.5 and 5.0 ",
            "author": "Steve Rowe",
            "id": "comment-13717078"
        },
        {
            "date": "2014-04-16T12:54:35+0000",
            "content": "Move issue to Lucene 4.9. ",
            "author": "Uwe Schindler",
            "id": "comment-13970809"
        }
    ]
}