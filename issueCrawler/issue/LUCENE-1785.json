{
    "id": "LUCENE-1785",
    "title": "Simple FieldCache merging",
    "details": {
        "labels": "",
        "priority": "Minor",
        "components": [
            "core/search"
        ],
        "type": "Improvement",
        "fix_versions": [
            "4.9",
            "6.0"
        ],
        "affect_versions": "2.4.1",
        "resolution": "Unresolved",
        "status": "Open"
    },
    "description": "We'll merge the field caches in RAM as the SegmentReader's are\nmerged in IndexWriter (the first cut will work in conjunction\nwith IW.getReader). There will be an optional callback to\ndetermine which fields to merge.",
    "attachments": {
        "LUCENE-1785.patch": "https://issues.apache.org/jira/secure/attachment/12426310/LUCENE-1785.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2009-08-06T12:46:06+0000",
            "content": "I think this might have to be 3.1 ... ",
            "author": "Mark Miller",
            "id": "comment-12740033"
        },
        {
            "date": "2009-11-28T01:56:07+0000",
            "content": "This mostly works, not committable. I've noticed we're creating\nmultiple cache keys (i.e. Entry objects), one with the default\nparser, one with a null parser, that point to the same\nunderlying value. \n\nThe field cache merging then tries to merge both of these\nentries into separate objects, causing the field cache sanity\ncheck to fail. I'm guessing I need to find values that are the\nsame for an entry and choose one (the one with a parser?). \n\nNote: This only works when using IW.getReader ",
            "author": "Jason Rutherglen",
            "id": "comment-12783197"
        },
        {
            "date": "2009-11-28T21:38:12+0000",
            "content": "The sanity check is fixed by skipping the entry with a null\nvalue. Removed some of the debugging. I think this patch\nrequires a way to handle merging field caches from segments that\nhave not yet created their field caches. We can generate the new\ncache if we already have at least 75% of the required caches. \n\nAlso we need to handle deletes. ",
            "author": "Jason Rutherglen",
            "id": "comment-12783291"
        },
        {
            "date": "2009-11-28T23:47:12+0000",
            "content": "Deletes in the source readers should be handled correctly.  \n\nWe probably need a unit test that verifies the merged caches are exactly what they should be. ",
            "author": "Jason Rutherglen",
            "id": "comment-12783328"
        },
        {
            "date": "2009-11-29T03:25:47+0000",
            "content": "Cleaned up some more, moved mergeSuccess to mergeMiddle, as otherwise the merge cloned readers had already been released by the time mergeSuccess was reached. ",
            "author": "Jason Rutherglen",
            "id": "comment-12783353"
        },
        {
            "date": "2009-12-14T04:48:58+0000",
            "content": "We probably need to figure out a way to merge string indexes before committing this?  Is there an efficient way to do this? ",
            "author": "Jason Rutherglen",
            "id": "comment-12789985"
        },
        {
            "date": "2009-12-14T09:24:09+0000",
            "content": "Can't we just merge-sort into the merged StringIndex? ",
            "author": "Michael McCandless",
            "id": "comment-12790057"
        },
        {
            "date": "2009-12-14T18:49:39+0000",
            "content": "Can't we just merge-sort into the merged StringIndex? \n\nRight however what's going to be the fastest way to remove terms that are no longer in the index?   ",
            "author": "Jason Rutherglen",
            "id": "comment-12790284"
        },
        {
            "date": "2009-12-14T21:01:23+0000",
            "content": "Hmm good question.  Actually, couldn't we pull a Term(s)Enum from the newly merged segment for that field, and use it to eliminate the non-dead terms? ",
            "author": "Michael McCandless",
            "id": "comment-12790366"
        },
        {
            "date": "2009-12-14T21:06:38+0000",
            "content": "Make that... eliminate the dead terms. ",
            "author": "Michael McCandless",
            "id": "comment-12790369"
        },
        {
            "date": "2009-12-14T21:45:30+0000",
            "content": "couldn't we pull a Term(s)Enum from the newly merged segment for that field\n\nYes, I think this makes the most sense, and won't adversely affect performance because term dictionary file access is sequential. ",
            "author": "Jason Rutherglen",
            "id": "comment-12790391"
        },
        {
            "date": "2013-07-23T18:44:45+0000",
            "content": "Bulk move 4.4 issues to 4.5 and 5.0 ",
            "author": "Steve Rowe",
            "id": "comment-13717048"
        },
        {
            "date": "2014-04-16T12:54:47+0000",
            "content": "Move issue to Lucene 4.9. ",
            "author": "Uwe Schindler",
            "id": "comment-13970881"
        }
    ]
}