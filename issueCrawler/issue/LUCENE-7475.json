{
    "id": "LUCENE-7475",
    "title": "Sparse norms",
    "details": {
        "resolution": "Fixed",
        "affect_versions": "None",
        "components": [],
        "labels": "",
        "fix_versions": [
            "7.0"
        ],
        "priority": "Minor",
        "status": "Resolved",
        "type": "Improvement"
    },
    "description": "Even though norms now have an iterator API, they are still always dense in practice since documents that do not have a value get assigned 0 as a norm value.",
    "attachments": {
        "LUCENE-7475.patch": "https://issues.apache.org/jira/secure/attachment/12831763/LUCENE-7475.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "id": "comment-15549127",
            "author": "Adrien Grand",
            "date": "2016-10-05T15:51:32+0000",
            "content": "Here is a patch that:\n\n\tfixes NormValuesWriter to support sparse norms\n\tadds a new Lucene70NormsFormat that supports sparsity and only encodes norms for documents that have a norm\n\tadds a codecSupportsSparsity method to BaseNormsFormatTestCase so that modern norms formats can get proper testing of the sparse case\n\tfixes SimpleTextNormsFormat to support sparsity\n\tmoves Lucene53NormsFormat to the backward-codecs module\n\n\n\nNotes:\n\n\tthe current patch assigns a norm value of zero to fields that generate no tokens (can happen eg. with the empty string or if all tokens are stop words) and only considers that a document does not have norms if no text field were indexed at all. We could also decide that fields that generate no tokens are considered as missing too, I think both approaches can make sense.\n\tthe new Lucene70NormsFormat is only a first step, it can certainly be improved in further issues\n\n "
        },
        {
            "id": "comment-15549558",
            "author": "Michael McCandless",
            "date": "2016-10-05T18:21:16+0000",
            "content": "Woops, I just pushed a small speedup to the old norms format (Lucene43NormsProducer) to avoid the wrapper class (over dense norms) before seeing this new issue  "
        },
        {
            "id": "comment-15549939",
            "author": "Adrien Grand",
            "date": "2016-10-05T21:03:15+0000",
            "content": "No worries, it's a good change! I was just going to ask whether you would be against making longValue() throw an exception.  "
        },
        {
            "id": "comment-15551420",
            "author": "Adrien Grand",
            "date": "2016-10-06T09:15:43+0000",
            "content": "Rebased patch against Mike's last changes to LUCENE-7407. "
        },
        {
            "id": "comment-15551581",
            "author": "Michael McCandless",
            "date": "2016-10-06T10:33:55+0000",
            "content": "This is a great change.  I would almost call it fixing a \"bug\", in that\nit fixes the norms iteration to never iterate to a document that did\nnot have that field.  Sort of as if we had added docsWithField to\nnorms, in the past.\n\nSo if only 1 doc out of zillions is missing the value, we use the\nsparse form.  We can improve how we encode it on future issues.\n\nAnd of course for very sparse fields, it will be a big win (\"pay for\nwhat you actually use\", like postings and (nearly) stored fields).\n\nI saw some minor things:\n\n\n\tIn Lucene70NormsProducer you can use\n    DocValues.emptyNumeric instead of making your own?\n\n\n\n\n\tYou can let longValue directly throw IOException now, in\n    Lucene70NormsProducer (it's still re-throwing as\n    RuntimeException in a few places).\n\n\n\nThe test improvements are wonderful.\n\n+1 to push! "
        },
        {
            "id": "comment-15551694",
            "author": "Adrien Grand",
            "date": "2016-10-06T11:38:41+0000",
            "content": "We can improve how we encode it on future issues.\n\nYes, we will need to improve the format indeed. The current  sparse format uses a bitset to store docs with norms, so it is still wasteful in the very sparse case: if less than 1/32 docs have a values even storing the full 4-byte doc ids would be more efficent. On the other hand, if the norms are almost dense, there will be a performance hit so we might want to keep the dense encoding above a certain threshold of documents that have a value.\n\nThanks for having a look. I'll address your comments and push. "
        },
        {
            "id": "comment-15551763",
            "author": "ASF subversion and git services",
            "date": "2016-10-06T12:08:00+0000",
            "content": "Commit 9128bdbaf547429667740cdc95370c7c606f83fc in lucene-solr's branch refs/heads/master from Adrien Grand\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=9128bdb ]\n\nLUCENE-7475: Make norms sparse. "
        },
        {
            "id": "comment-15552684",
            "author": "ASF subversion and git services",
            "date": "2016-10-06T18:05:37+0000",
            "content": "Commit e1370d2c2060463da8baffa19719249db1aa1a7d in lucene-solr's branch refs/heads/master from Adrien Grand\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=e1370d2 ]\n\nLUCENE-7475: Make Lucene70NormsFormat's SparseDISI use the slice API rather than RandomAccessSlice. "
        },
        {
            "id": "comment-15607866",
            "author": "ASF subversion and git services",
            "date": "2016-10-26T08:40:20+0000",
            "content": "Commit 5394d29fca8546936dc8227f23c6561d6b386832 in lucene-solr's branch refs/heads/master from Adrien Grand\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=5394d29 ]\n\nLUCENE-7475: Remove one layer of abstraction in the Lucene70 norms impl. "
        }
    ]
}