{
    "id": "SOLR-5092",
    "title": "Send shard request to multiple replicas",
    "details": {
        "affect_versions": "4.4",
        "status": "Closed",
        "fix_versions": [],
        "components": [
            "clients - java",
            "SolrCloud"
        ],
        "type": "Improvement",
        "priority": "Minor",
        "labels": "",
        "resolution": "Duplicate"
    },
    "description": "We have a case on a SolrCloud cluster. Queries takes too much QTime, due to a randomly slow shard request. In a noticeable part of queries, the slowest shard consumes more than 4 times qtime than the average.\n\nOf course, deep inspection of the performance factor should be made on the specific environment.\n\nBut, there is one more idea:\n\nIf shard request will be sent to all of the replicas of each shard, the probability of all the replicas of the same shard to be the slowest is very small. Obviously cluster works harder, but on a (very) low qps, it might be OK.",
    "attachments": {
        "SOLR-5092.patch": "https://issues.apache.org/jira/secure/attachment/12595037/SOLR-5092.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Isaac Hebsh",
            "id": "comment-13724376",
            "date": "2013-07-30T20:39:34+0000",
            "content": "Submitting initial patch.\nAs Erick Erickson suggested on mailing list, changes are only in solrj, so nothing should be changed in core.\n\nThis change should be very easy. Just move the single HTTP request into CompletionService \n\nBut, the most complicated thing in this patch, is to preserve the original exception handling. There are some exceptions which are considered as temporary, while other exceptions are fatal. Moreover, we want to preserve the zombie list maintenance as is. "
        },
        {
            "author": "Isaac Hebsh",
            "id": "comment-13724396",
            "date": "2013-07-30T20:46:11+0000",
            "content": "Question:\nin HttpShardHandler, I can find the next comment:\n\n// maps \"localhost:8983|localhost:7574\" to a shuffled List(\"http://localhost:8983\",\"http://localhost:7574\")\n// This is primarily to keep track of what order we should use to query the replicas of a shard\n// so that we use the same replica for all phases of a distributed request.\nshardToURLs = new HashMap<String,List<String>>();\n\n\n\nwhy is the replica-consistency is so important? what would happen if one phase of a distributed request will get a response from replica1 and another phase will get a response from replica2?\nI think this situation might happen in the current state, if one replica stops to response during the distributed process. "
        },
        {
            "author": "Ryan Ernst",
            "id": "comment-13724581",
            "date": "2013-07-30T23:16:28+0000",
            "content": "I think this is a dup of SOLR-4449?\n\n\nwhy is the replica-consistency is so important? what would happen if one phase of a distributed request will get a response from replica1 and another phase will get a response from replica2?\n\nReplica consistency is important because multi phase search in solr depends on things like the filter cache being filled and not rerunning the entire search on subsequent requests.\n\n\nIf shard request will be sent to all of the replicas of each shard\nThat is kind of scary (loading the entire fleet with the same query kind of negates some of the benefit of replicas). I would rather do it like SOLR-4449 and have it configurable. "
        },
        {
            "author": "Isaac Hebsh",
            "id": "comment-13725509",
            "date": "2013-07-31T18:02:00+0000",
            "content": "Hi Ryan, you're absolutely right. SOLR-4449 exactly addresses my issue. if repFactor is 2, we suggest the same solution.. \n\nOn the other hand, I didn't understand your response about the case when distributedProcess might address different replicas on different phases, if one replica stop responding. "
        }
    ]
}