{
    "id": "SOLR-10229",
    "title": "See what it would take to shift many of our one-off schemas used for testing to managed schema and construct them as part of the tests",
    "details": {
        "labels": "",
        "priority": "Minor",
        "components": [],
        "type": "Improvement",
        "fix_versions": [],
        "affect_versions": "None",
        "resolution": "Unresolved",
        "status": "Open"
    },
    "description": "The test schema files are intimidating. There are about a zillion of them, and making a change in any of them risks breaking some other test. That leaves people three choices:\n\n1> add what they need to some existing schema. Which makes schemas bigger and bigger and bigger.\n\n2> create a new schema file, adding to the proliferation thereof.\n\n3> Look through all the existing tests to see if they have something that works.\n\nThe recent work on LUCENE-7705 is a case in point. We're adding a maxLen parameter to some tokenizers. Putting those parameters into any of the existing schemas, especially to test < 255 char tokens is virtually guaranteed to break other tests, so the only safe thing to do is make another schema file. Adding to the multiplication of files.\n\nAs part of SOLR-5260 I tried creating the schema on the fly rather than creating a new static schema file and it's not hard. WDYT about making this into some better thought-out utility? \n\nAt present, this is pretty fuzzy, I wanted to get some reactions before putting much effort into it. I expect that the utility methods would eventually get a bunch of canned types. It's reasonably straightforward for primitive types, if lengthy. But when you get into solr.TextField-based types it gets less straight-forward.\n\nWe could manage to just move the \"intimidation\" from the plethora of schema files to a zillion fieldTypes in the utility to choose from...\n\nAlso, forcing every test to define the fields up-front is arguably less convenient than just having some canned schemas we can use. And erroneous schemas to test failure modes are probably not very good fits for any such framework.\n\nSteve Rowe and Chris Hostetter (Unused) in particular might have something to say.",
    "attachments": {
        "SOLR-10229-straw-man.patch": "https://issues.apache.org/jira/secure/attachment/12875571/SOLR-10229-straw-man.patch",
        "SOLR-10229.patch": "https://issues.apache.org/jira/secure/attachment/12861490/SOLR-10229.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2017-03-05T23:10:54+0000",
            "content": "Could we have a master schema and then create a new one from it by passing types/fields needed by name? That way all the definitions are centralized, but only the used ones are pulled in.\n\nJust a random thought, really. I still need to dig into the tests deeper. ",
            "author": "Alexandre Rafalovitch",
            "id": "comment-15896593"
        },
        {
            "date": "2017-03-06T05:25:23+0000",
            "content": "I whole heartedly agree that tests should try to avoid creating config files, and that the advent of managed schema and other APIs now allows us to do that whereas in the past it wasn't.  Noble Paul and I were talking about this a couple weeks ago.  I've got a technique for it in the patch here SOLR-10117  I very briefly just examined SOLR-5260 which you just referenced but I don't think the identical technique applies to many tests that don't care about SolrCloud (thus needn't have the overhead of a test using SolrCloud via SolrCloudTestCase).\n\nWDYT about making this into some better thought-out utility?\n\nYes; It should be made easier \u2013 not that it's hard but it took some time for me to figure out how to do it without copying/writing new configs to disk (something I want to avoid).  I'm curious what you think of the test in SOLR-10117. ",
            "author": "David Smiley",
            "id": "comment-15896759"
        },
        {
            "date": "2017-03-06T06:20:25+0000",
            "content": "First the managed schema stuff doesn't require SolrCloud, right? SOLR-5260 the process method just takes a SolrClient even though it's passed a CloudSolrClient. IIUC anyway.\n\nre: SOLR-10117: I find that pretty hard to follow frankly. For any test that had a bunch of fields to be added the setup code wold get humongous. I was hoping to hide all that away in a utility class and have users be able to do something in @BeforeClass like\n\nload minimal managed schema (this is just fields)\naddToSchema(canned_type1, name1, prop1, val1, prop2, val2.....)\naddToSchema(canned_type2, name2, prop11, val11, prop22, val22.....)\n.\n.\n.\nupdateSchema(SolrClient...)\n\nNote that prop1, val1 and the like override the defaults for canned_type1 etc.\n\nthat ought to work for both cloud and stand-alone...\n\nThe problem I ran into when I was faking this earlier today is that fieldTypes aren't simple. While I haven't put much thought into it yet, the simple thing we're trying to do for LUCENE-7055 is a case in point. I want a fieldType with a new parameter set on several tokenizers. That, of course, is solved by the technique in SOLR-10117, but to force every test to define it's own fieldTypes when a vast majority are common seems like a bad tradeoff. OTOH, to pre-define a boatload of fieldTypes in some utility makes that utility at least as hard to follow as a huge schema file.\n\nSo I'm a little stuck on how to balance of making writing tests really painful and reducing the necessity to create yet another schema file. Maybe there's no good compromise... ",
            "author": "Erick Erickson",
            "id": "comment-15896786"
        },
        {
            "date": "2017-03-13T16:26:01+0000",
            "content": "Amrit and I were chatting offline. Using the managed-schema API to create fieldTypes inline is certainly possible, but I find it's code that's very hard to understand at a glance. And the goal here is to provide something that's not hard to write, especially if you're new.\n\nAny interface that allows us to add fieldTypes immediately gets complex since fieldTypes are much more complex structurally than fields.\n\nSo what do you think about providing a \"translator\" method that would take the XML definition (static string in the test case if needed) and transforms it into a managed schema definition and submits it? You'd have something like (yeah, the internal double quotes are not escaped):\n\nstatic String newField = \"<fieldType name=\"lowercase\" class=\"solr.TextField\" positionIncrementGap=\"100\">\n    <analyzer>\n      <tokenizer class=\"solr.KeywordTokenizerFactory\"/>\n      <filter class=\"solr.LowerCaseFilterFactory\"/>\n    </analyzer>\n  </fieldType>\";\n\nthen somewhere\n\nFieldUtility.addFieldType(newField)\n\n\nthe string could have multiple entries possibly. I'd find this much easier to understand than the raw addSchema code.\n\nSo that leaves us with a \"regular\" schema file with a series of pre-defined base types. I'm thinking the primitive types, int, tint, string, date, boolean and the like. Also it'd have a few \"common\" text-based field types. One challenge would be to keep the text-based types from sprawling in the \"one base schema\". We'd still also have all the bad-schema files I'd guess, and a maybe the minimal version(s). For the rest we could remove them and put special fieldTypes into the respective test files.\n\nMostly throwing this out there for discussion. I agree it's an extra step to have a parser to take the string and turn it into the addSchema commands but it's also much more friendly to scanning someone else's code. ",
            "author": "Erick Erickson",
            "id": "comment-15907767"
        },
        {
            "date": "2017-03-13T16:41:54+0000",
            "content": "What about a master schema of all field type definitions loaded by test framework setup and then using Config API to copy the definition by name? That way there is no need for any translator and people creating new tests will have more exposure to other types already defined.  ",
            "author": "Alexandre Rafalovitch",
            "id": "comment-15907792"
        },
        {
            "date": "2017-03-13T17:15:04+0000",
            "content": "Alexandre:\n\nThis is why I throw things out for discussion, because other people almost always have a better idea  \n\nWhat I like about this is that we load/parse this monster file once when the test run starts rather than for each test. Each test (suite?) then makes any changes necessary in line. I don't particularly care if that file is a \"kitchen sink\" in this scenario.\n\nThat said, I don't want to force every test to define the schema in the test code. So there'd still be a handful of pre-defined schema files that people could use as-is, the 80-20 rule here, if your test is happy with the (relatively) small schema, just use that.  ",
            "author": "Erick Erickson",
            "id": "comment-15907881"
        },
        {
            "date": "2017-03-13T18:28:24+0000",
            "content": "Actually, I was not suggesting using kitchen sink as the actual live schema, just as a source to copy from. Running the tests on the mother scheme may make tests too complicated to review. Having explicit list of definitions, even if copied, would be a good idea in my mind.\n\nAnd to simplify, it may be useful to say something like \"copyFieldAndDefinition\", so if you pull in the \"id\" field, it all pulls the necessary definitions too. Which probably still means some bridging/assistance code after all. ",
            "author": "Alexandre Rafalovitch",
            "id": "comment-15922677"
        },
        {
            "date": "2017-03-13T18:42:42+0000",
            "content": "bq: Actually, I was not suggesting using kitchen sink as the actual live schema, just as a source to copy from\n\nUnderstood, I wasn't suggesting that either. The \"mother schema\" would be loaded by the test framework exactly once before running any tests. Individual tests could choose to add definitions from that  schema as necessary.\n\nThere would be \"basic schema(s)\" available for use as-is, but not very many.\n\nTests that needed one-off additions would have the \"mother schema\" as a resource to add any custom stuff. ",
            "author": "Erick Erickson",
            "id": "comment-15922704"
        },
        {
            "date": "2017-03-14T17:24:13+0000",
            "content": "Assigned to myself, but Amrit is going to do the heavy lifting. ",
            "author": "Erick Erickson",
            "id": "comment-15924619"
        },
        {
            "date": "2017-03-14T19:54:08+0000",
            "content": "I'm really looking forward to where this is going.  One potential consideration before investing further in the XML syntax/schema is to deliberately not add such conveniences and instead just do for the JSON syntax.  If we are supposed to migrate to JSON then this is a moment where we can make a deliberate decision. ",
            "author": "David Smiley",
            "id": "comment-15924886"
        },
        {
            "date": "2017-03-14T23:51:13+0000",
            "content": "I have no objection. And you're right that if we're going to go to JSON eventually anyway we might as well start now. For the purposes of this JIRA I don't see any roadblocks. ",
            "author": "Erick Erickson",
            "id": "comment-15925275"
        },
        {
            "date": "2017-03-16T09:02:21+0000",
            "content": "Thank you Erick for the opportunity,\n\nHere are the key points on which we are designing the framework:\n\n1. We will have a \"mother\"/\"master\" schema, which can be imported by the individual tests and can add/modify fieldTypes and field definitions through custom code.\n\n2. A set of schema files with limited features/definitions will be available other than \"mother\", basic ones, one or two can be complex, we can discuss that later.\n\n3. Provide reasonable and understable pref-defined functions to add/modify fieldTypes and field (custom code):\nErick suggested something like:\n\nstatic String newFieldType = \"<fieldType name=\"lowercase\" class=\"solr.TextField\" positionIncrementGap=\"100\">\n    <analyzer>\n      <tokenizer class=\"solr.KeywordTokenizerFactory\"/>\n      <filter class=\"solr.LowerCaseFilterFactory\"/>\n    </analyzer>\n  </fieldType>\";\n\n\nand then have a utility method like:\n\nUtility.addFieldType(newFieldType);\n\n\n\nIt is human readable for the coders and it will require a straightforward string parsing and invoke relevant methods for the schema.\n\nDavid mentioned to avoid XML syntax/schema and build in JSON, does that mean the entire managed-schema will transformed in JSON format or we are just discussing the intake parameter for utility methods for the framework?\n\nI will start working on framework first, before we discuss what to or not to include in our mother and other basic schemas. ",
            "author": "Amrit Sarkar",
            "id": "comment-15927692"
        },
        {
            "date": "2017-03-16T11:09:09+0000",
            "content": "I thought what I said and what Eric agreed was:\n\nIndividual tests could choose to add definitions from that schema as necessary.\n\nSo, the mother is not used in the tests directly. A new minimal schema is constructed by copying the definitions from the mother. That way, if there are any issues, the debug dumps the smallest schema generated.\n\nRegarding JSON migration, I am assuming the suggestion is to use the JSON notation from the Schema API. Because, for schema, the storage format is for now still XML. For solrconfig.xml though, we do have most of additional stuff representable as JSON with configoverlay.json ",
            "author": "Alexandre Rafalovitch",
            "id": "comment-15927847"
        },
        {
            "date": "2017-03-16T11:43:09+0000",
            "content": "Alexandre,\n\nThank you for correcting both the points out, Sorry I mixed two different conversations (online-offline) altogether. Rephrasing again:\n\n1. A \"mother\" schema, with most common field and fieldType definitions, will be loaded/parsed in the test framework once, non-dependent on any individual tests.\n2. The individual tests then can pull relevant/required field and fieldType definitions from mother schema already parsed content and post them to its own miniature schema for tests via Schema API. The utility method can be named as \"copyFieldAndDefinition\" as suggested above.\n3. For custom field and fieldType, which are not available in the mother schema, utility methods in framework to pass them onto Schema API.\n4. Apart from the above, Global Similarity and Default Query Operator will be configurable, defaults will be provided.\n\nAll the endpoints of framework will take JSON format parameters. Anything am I missing out or understanding wrong? ",
            "author": "Amrit Sarkar",
            "id": "comment-15927875"
        },
        {
            "date": "2017-03-16T14:05:13+0000",
            "content": "Sounds good. You will also hit uniqueKey definitions, field type definitions without associated fields and possibly other issues. Other things, like per-field similarity (IIRC) and custom attributes would probably only show up if you are converting those - more specialized - tests. ",
            "author": "Alexandre Rafalovitch",
            "id": "comment-15928106"
        },
        {
            "date": "2017-03-16T15:00:17+0000",
            "content": "Sounds like what I was thinking too. I really don't want to go overboard with this, forcing every test to define a complete schema would be burdensome, and this approach doesn't do that.\n\nOTOH, it makes adding two unique field types to some really basic schema much easier and less confusing than adding a new schema.\n\nSo my notion was once the framework is in place we'll pick some schema file from the current list and eliminate it by using the new framework. Along the way we'll enhance the framework as necessary/practical. ",
            "author": "Erick Erickson",
            "id": "comment-15928217"
        },
        {
            "date": "2017-03-22T22:09:36+0000",
            "content": "random 2cents observation:\n\nif we're going to go to the trouble of trying to change/cleanup how most tests use/depend on their schema (or a new unified test schema w/additions) then it would be nice to also move towards more of a \"declarative\" model of what th test needs and let the scaffolding assume any field/fieldtype properties the test doesn't declare can be randomized.\n\nfor example: a test should be able to declare that it needs a field named do_something_with_this_field that is an \"integer\" and has \"docValues=true\" but other unspecified things (like whether it's a points based int field or a trie based int field, or whether it's stored or indexed) should be left to the helper method to randomize.\n\nthis should, in theory, help us find bugs that currently fall through the cracks because people don't realize their code has implict dependencies on certain field/type atttributes.\n\ncontinuing our previous example: someone might today write theat test to use a do_something_with_this_field_i field name so they can leverage an existing *_i dynamic field because they know they want something \"integer\" based, w/o considering the possibility that maybe the only reason their code works is because that dynamicField has docValues=true AND is stored=true. ",
            "author": "Hoss Man",
            "id": "comment-15937252"
        },
        {
            "date": "2017-03-23T00:01:24+0000",
            "content": "gimmeAField.builder().withName(\"ohmy\").withType(\"int\").withAttribute(\"stored\", \"true\").build()?\n\nand anything not specified by withAttribute is randomizable? Wordy, but understandable. ",
            "author": "Erick Erickson",
            "id": "comment-15937420"
        },
        {
            "date": "2017-03-23T02:56:22+0000",
            "content": "if we're going to go to the trouble of trying to change/cleanup how most tests use/depend on their schema (or a new unified test schema w/additions) then it would be nice to also move towards more of a \"declarative\" model of what th test needs and let the scaffolding assume any field/fieldtype properties the test doesn't declare can be randomized.\n\n+1 fantastic ",
            "author": "David Smiley",
            "id": "comment-15937602"
        },
        {
            "date": "2017-03-31T19:10:09+0000",
            "content": "Uploaded the first draft, SOLR-10229.patch, (working) for review, suggestions and clearing doubts.\n\n1. A \"mother\" schema, with most common field and fieldType definitions, will be loaded/parsed in the test framework once, non-dependent on any individual tests.\n\nLoaded mother schema using ManagedSchemaFactory::create in framework creation, independent of any test suite. I had to hardcode the solr.home system property so that it can pick the default solrconfig.xml and mother-schema, suggestion on this will be appreciated. There must be a better way to do it.\n\n2. The individual tests then can pull relevant/required field and fieldType definitions from mother schema already parsed content and post them to its own miniature schema for tests via Schema API. The utility method can be named as \"copyFieldAndDefinition\" as suggested above.\n\naddField(String... fields) and addFieldTypes(String... fieldTypes) will do the desired. Fetch the managed-schema from the current core and add components to it accordingly.\n\n3. For custom field and fieldType, which are not available in the mother schema, utility methods in framework to pass them onto Schema API.\n\nOn Hoss suggestions, declarative builder methods are written which will add a new field or fieldType. Did not verified how the analysers will be specified for a specific fieldType, need to test that part and will update.\n\nAs we are fetching the managedIndexSchema from the current core, this framework will not support Classic schema. I am assuming going forward as we are encouraging users to use managed-schema in place of classic, this approach is correct.\n\nMade some progress on other features not listed in the patch, will update them very soon. ",
            "author": "Amrit Sarkar",
            "id": "comment-15951507"
        },
        {
            "date": "2017-03-31T23:53:48+0000",
            "content": "A very minor nit, I'd drop the 's' on \"withAttributes\", i.e. \"withAttribute\" since we're only setting one at a time for all we're chaining them together.\n\nI don't think you need to set solr.solr.home, and I'm pretty sure setting it to the sub-directory will cause Bad Things To Happen. I think that something like this should work if you create a \"mother_configset/conf/managed-schema\" & etc in solr/core/src/test-files/solr/configsets:\nTEST_PATH().resolve(\"configsets\").resolve(\"mother_configset\").resolve(\"conf\").resolve(\"managed-schema\").\n\nOn second thought, I'd probably rather not make a new configset as the whole point here is NOT to load this up per test. So just putting a single file along with the other files something like:\nTEST_PATH().resolve(\"collection1\").resolve(\"conf\").resolve(\"mother-schema\") might be preferable. Actually I think I like putting it here rather than a new configset, but that's not a strong preference.\n\nAlthough we may want to name it something more descriptive, maybe template-schema or something.... schema-to-use-for-creating-fields-on-the-fly is a little too long though.\n\nIt looks like you're thinking to have test classes subclass this. Could it be instantiated as a static member of SolrTestCaseJ4 somehow? I think that's less confusing and all current tests would immediately have access. The only thing I see on a quick glance that really requires SolrTestCaseJ4 is h.getCore(), so that would probably mean we need to pass the core in to the methods that need it.\n\nThis last is pretty certain to be something we want to do or similar. Using h.getCore() doesn't accommodate having different cores with different schemas in the same test.\n\nI doubt we should persist any changes. Tests should fail if we try since there's code in place to prevent changing any source files and unless we copied the managed schema being loaded to a temp directory, persisting should fail. In this case whatever schema the test loaded should be considered a \"source file\".\n\nI like where this is going, it'll be exciting to get it in place. ",
            "author": "Erick Erickson",
            "id": "comment-15951825"
        },
        {
            "date": "2017-04-01T16:42:48+0000",
            "content": "\nThank you for the correction and the suggestions.\n\nIt looks like you're thinking to have test classes subclass this. Could it be instantiated as a static member of SolrTestCaseJ4 somehow? I think that's less confusing and all current tests would immediately have access. The only thing I see on a quick glance that really requires SolrTestCaseJ4 is h.getCore(), so that would probably mean we need to pass the core in to the methods that need it.\n\nIf you look closely at the public methods exposed to be used, all are static and h.getCore each time will fetch the current test-suites core and its schema, which is correct, no? Developers will directly access these methods without inheriting or creating framework object. \n\nUsing h.getCore() doesn't accommodate having different cores with different schemas in the same test.\n\nNot very much aware of above, different cores with different schemas in the same test in our test-suites. Are there such use cases? I will look for them.\n\nI doubt we should persist any changes.\n\nMakes sense. I will do repetitive forced testing for two or more test suites simultaneously and observe what's happening.\n\nMaking necessary changes on the already and completing the rest, will update soon.\n\n ",
            "author": "Amrit Sarkar",
            "id": "comment-15952298"
        },
        {
            "date": "2017-04-01T17:40:57+0000",
            "content": "bq: If you look closely at the public methods exposed to be used, all are static and h.getCore each time will fetch the current test-suites core and its schema, which is correct, no\n\nh.getCore() is overly restrictive and doesn't support having more than one core open and modifying the schema. The problem is it fetches the test core which is limiting. It's convenient for writing tests that only operate on a single core. For more complex situations it's quite restrictive.\n\nTake a look at, for instance, TestLazyCores. It has to do some fancy dancing, but it opens multiple cores so it has to bypass h.getCore() completely. Admittedly they all use the same schema, but that doesn't matter since if I wanted each of those cores to have new field definitions I couldn't use h.getCore(), even implicitly. Even if all the new field definitions were the same.\n\nbq: ...different cores with different schemas in the same test in our test-suites... Are there such use cases? \n\nNot that I know of offhand, but that doesn't mean anything really, there's a lot of test code . It's unnecessarily restrictive to confine ourselves into that paradigm though. And as above, using h.getCore() doesn't allow modifying schemas for more than one core in any given test.\n\nbq:  I will do repetitive forced testing for two or more test suites simultaneously and observe what's happening.\n\nThis isn't quite the issue. If we try to persist anything to the \"source tree\", which includes all the config files in this case, the test framework should throw an exception. I'm not worried about multiple cores making modifications to the on-disk files, no mods should be allowed unless the configs are in a temp dir. You'll see lots of code like (again from TestLazyCores since I know that code):\n\n    solrHomeDirectory = createTempDir().toFile();\n    File coreRoot = new File(solrHomeDirectory, coreName);\n    copyMinConf(coreRoot, \"name=\" + coreName);\n\nso having the temp dir (which is automagically cleaned up by the test harness) is required to change anything on-disk and just to use this new approach shouldn't require creating a tmp dir and copying stuff to it. ",
            "author": "Erick Erickson",
            "id": "comment-15952316"
        },
        {
            "date": "2017-04-08T08:55:50+0000",
            "content": "Updated Patch:\n\nIncorporated the framework to TestMaxTokenLenTokenizer.java for LUCENE-7705.\n\nPoints to be noted, add fieldType on the fly looks like this:\n\n    framework.createNewFieldType().withName(\"keywordType\").\n        withClassName(\"solr.TextField\").\n        withAttribute(\"positionIncrementGap\", \"100\").\n        withAttribute(\"analyzer\", map(\"tokenizer\", map(\"class\", \"solr.KeywordTokenizerFactory\", \"maxTokenLen\", \"3\"))).\n        build(h.getCore());\n\n\n\nNested maps for the respective attributes of the analyser components.\n\nThe framework is working as expected. I am able to load the mother-schema as well. Seeking feedback on this for improvements.\n\nTo do:\n\n1. addCopyFields (both from mother-schema and on the fly)\n2. addDynamicFields (both from mother-schema and on the fly)\n3. Global Similarity\n4. UniqueKey definitions\n5. Default Query Operator\n... more to follow ",
            "author": "Amrit Sarkar",
            "id": "comment-15961746"
        },
        {
            "date": "2017-04-08T10:01:57+0000",
            "content": "addCopyFields and addDynamicFields are added.\n\nFollowing are not allowed to set from ManagedIndexSchema API :\n1. Global Similarity\n2. UniqueKey definitions\n3. Default Query Operator\n\nWhat to do with them? ",
            "author": "Amrit Sarkar",
            "id": "comment-15961756"
        },
        {
            "date": "2017-04-12T05:29:15+0000",
            "content": "This looks really interesting. I'll look some more tomorrow, but some of nits and a significant question or two:\n\nnit1:  The default managed-schema used by solrconfig-managed-schema.xml is actually very small. So since the first schema or two will be used as a template,  let's not introduce the property with System.setProperty(\"managed.schema.resourceName\", \"schema-tiny.xml\") and just use solrconfig-managed-schema.xml and managed-schema in initCore\n\nnit2: positionIncrementGap is mostly useful when you have mulitValued fields and are testing phrase queries that don't cross that gap so setting them here is probably unnecessary. Since this will be the first place others look to see how to use this capability let's nuke those.\n\nnit3: mother-schema has <defaultSearchField>, which is deprecated.\n\nnit4: Do the <copyField> directives in mother-schema make sense?\n\n\nSignificant question 1:\n\nI'm a little uncomfortable with the build(h.getCore) method being called for every field type addition and every field addition. I'm not sure how much work that entails, will we be reloading the schema again and again? Perhaps Use account \"steve_rowe\" instead or Hoss Man can weigh in (or I'll look more in the morning). WDYT about this kind of pattern?\n\nList<FieldType> listBlah.\nlistBlah.add(framework.createNewFieldType(blah blah blah).build);\nlistBlah.add(framework.createNewFieldType(blah blah blah).build);\nframework.addFieldTypes(listBlah)\n\nDitto for Fields.... As I said, I really don't know whether this'll be more efficient or not, think of this as a marker to make sure we answer before diving in totally.\n\nSignificant question 2:\n\nThis patch contains LUCENE-7705. I briefly experimented with taking out the 7705 bits and it seems pretty easy. Yet that's the driver for this functionality. WDYT about splitting the 7705 bits out (we'll have to commit this one before 7705) and adding this patch with other examples? I'm thinking of removing a couple of the current schema files and replacing them with this mechanism. I'd be happy to volunteer to do that part of the patch as I'd like to get some hands-on experience with this approach. There are some docValues schemas that are only used in one or two places that are likely candidates. I think the sweet spot for this mechanism is exactly those places where there are just a few tests that use a particular schema.\n\nAlong the way, by replacing the uses of at least two uses of a schema we can also make certain some test harness trickery isn't causing us to reload the mother-schema for every test suite...\n\nI suppose that replacing some of the other schemas is probably not as bad as I expect as a number of them use, say, schema.xml but only really use a few fields out of it and we can just add existing fields from the mother schema with a couple of lines.\n\nAnyway, great work, I think this is very close! ",
            "author": "Erick Erickson",
            "id": "comment-15965400"
        },
        {
            "date": "2017-04-13T16:18:48+0000",
            "content": "Thank you Erick for the detailed feedback,\n\nI have rectified the first three nits you mentioned and will upload new patch soon.\n\nnit4: Do the <copyField> directives in mother-schema make sense?\nI know and was skeptical adding the feature but there is no harm providing the feature considering it is not taking that much code space in the framework. I can remove this if it is insignificant.\n\nI'm a little uncomfortable with the build(h.getCore) method being called for every field type addition and every field addition. I'm not sure how much work that entails, will we be reloading the schema again and again? Perhaps Use account \"steve_rowe\" instead or Hoss Man can weigh in (or I'll look more in the morning). WDYT about this kind of pattern?\n\nWe are not reloading the schema, but adding a new field to the list in present schema already available to core. It is atomic and doesn't require reloading. core.setLatestSchema(newSchema) is setting at the core level before informing the core regarding the SimilarityFactory, which doesn't concern with what we are doing here. More insights on this will be better.\n\nDitto for Fields.... As I said, I really don't know whether this'll be more efficient or not, think of this as a marker to make sure we answer before diving in totally.\n\nThis is good I suppose, passing SolrCore again and again doesn't seem really good way and wrapping it in a list and passing it once seems good. Also unsetting and resetting of schema will be saved. I will add that. Though I didn't modify the TestMaxTokenLenTokenizer at this moment with factory.addNewFields(...) and factory.addNewFieldTypes(...) and post that patch on LUCENE-7705 for your feedback and changes.\n\nWDYT about splitting the 7705 bits out (we'll have to commit this one before 7705) and adding this patch with other examples?\n\nI added that to have your feedback on how it will show up in an actual test suite. I will remove it.\n\nAlong the way, by replacing the uses of at least two uses of a schema we can also make certain some test harness trickery isn't causing us to reload the mother-schema for every test suite...\n\nUnless and until, it forces TestSchemaFrameworkFactory object already created to get destroyed, we are good!\n\nI will post respective patches on the two jiras shortly. \n ",
            "author": "Amrit Sarkar",
            "id": "comment-15967813"
        },
        {
            "date": "2017-04-13T18:01:52+0000",
            "content": "Updates patch: SOLR-10229.patch\n\n1. framework.addNewFields(...) and framework.addNewFieldTypes(...)\n2. Removed <defaultSearchField> from mother-schema ",
            "author": "Amrit Sarkar",
            "id": "comment-15967969"
        },
        {
            "date": "2017-07-04T05:22:06+0000",
            "content": "Here's a straw-man re-working of Amrit's patch. It's got nocommits, lacks javadocs etc. I wanted to see what people thought.\n\nIn order to be used, I think it's imperative that this be easy. It must not be harder (much) to use than just adding a bunch of new stuff to a new schema file.\n\nSo the basic pattern here to specify the fields that you need is:\n\n\n    SchemaFrameworkFactory.SchemaFramework fac = SchemaFrameworkFactory.getFramework();\n    initCore(\"solrconfig-id-and-version-fields-only.xml\", \"schema-id-and-version-fields-only.xml\");\n\n    fac.addFieldTypesFromMother(h.getCore(), \"whitespace\", \"tint\", \"tints\", \"tfloat\", \"tfloats\",\n        \"tlong\", \"tlongs\", \"tdouble\", \"tdoubles\",\n        \"text_mock\");\n    fac.addFields(h.getCore(), new String[][] {\n        {\"name\", \"f_ti\", \"type\", \"tint\", \"indexed\", \"true\"},\n        {\"name\", \"f_tis\", \"type\", \"tints\", \"indexed\", \"true\"},\n        {\"name\", \"f_tf\", \"type\", \"tfloat\", \"indexed\", \"true\"},\n        {\"name\", \"f_tfs\", \"type\", \"tfloats\", \"indexed\", \"true\"},\n        {\"name\", \"f_tl\", \"type\", \"tlong\", \"indexed\", \"true\"},\n        {\"name\", \"f_tls\", \"type\", \"tlongs\", \"indexed\", \"true\"},\n        {\"name\", \"f_td\", \"type\", \"tdouble\", \"indexed\", \"true\", \"docValues\",Boolean.toString(Boolean.getBoolean(NUMERIC_DOCVALUES_SYSPROP))},\n        {\"name\", \"f_tds\", \"type\", \"tdoubles\", \"indexed\", \"true\"},\n        {\"name\", \"*_s\", \"type\", \"string\", \"indexed\", \"true\"},\n        {\"name\", \"*_ws\", \"type\", \"whitespace\", \"indexed\", \"true\"},\n        {\"name\", \"*_ss\", \"type\", \"string\", \"indexed\", \"true\", \"multiValued\", \"true\"},\n        {\"name\", \"*_t\", \"type\", \"text_mock\", \"indexed\", \"true\"},\n        {\"name\", \"val_i\", \"type\", \"tint\", \"indexed\", \"true\"}\n    });\n\n\n\nAt this point I'm more interested in what people think of the two tests I've re-worked to use this mechanism. From the perspective of writing tests, does this seem easy to grasp? How could it be easier? And the NUMERIC_DOCVALUES_SYSPROP took me a while to figure out. I picked that test at random and it turned out to be trickier than I thought.\n\nSome notes (and this is a work in progress):\n\n\n\tSiiiigggghhhh. To reduce the number of config files I had to add some. Eventually others will go away but for the nonce... How much do we want to cut down on the new solrconfig file? The spellcheck stuff is still in there for instance. It's a copy of solrconfig.xml with managed schema in it.\n\n\n\n\n\tWe could do something very similar with solrconfig I should think, but one thing at a time.\n\n\n\n\n\tUse the pre-existing fieldTypes in the schema-mother.xml file if at all possible. If you think the particular ones you're adding will be generally useful, just add them to schema-mother.xml. Eventually the schema-mother.xml will be quite big. However, it's only loaded once.\n\t\n\t\tthe SchemaFrameworkFactory has a pass-through for defining new field types to the managed schema code. I haven't tried it yet though. I don't see a way to make adding new fieldTypes easy, so I don't see a benefit in adding another layer. Suggestions for how to make adding a field type simply are very welcome.\n\t\n\t\n\n\n\n\n\tYou can redefine the id field as above if you want to change it to a different type for some specific reason. Currently it's a string.\n\n\n\n\n\tThere are the beginnings of randomizing unspecified field options for a few options at present. This could be made more sophisticated.\n\t\n\t\tMake stored/dv (when unspecified) be one or the other or both?\n\t\tThis means that if you don't specify, say, DV but rely on them your tests will pass sometimes and fail others. So far I've gotten pretty good error messages when that happens and it just requires that you add the option you need when you add the field.\n\t\n\t\n\n\n\n\n\tWhen making changes to the schema and config files, I sometimes have to rebuild IntelliJ (ant clean-idea idea). Haven't tracked down why yet.\n\n\n\n\n\tHaven't approached making this work with SolrCloud tests. One step at a time. DistributedQueryElevationComponentTest fails for instance with \"undefined field\".\n\n\n\n\n\tThere are id-and-version-only configs (solrconfig and schema) that are meant to be used in tandem. The critical bit is that you need to have the schema be defined as a managed resource.\n\t\n\t\tIt's a little awkward that the id-and-version-only schema has a \"string\" and \"long\" type. But we need to load the file to change the file and I don't see a way to add a <uniqueKey> via the managed schema code. I'm not sure we want to force every test to define these anyway. It does take a little getting used to before you realize you do not have to add \"string\" and \"long\" as types in your test. Live with it.\n\t\n\t\n\n\n\n\n\tWe'd better not persist configs. I did have a couple of instances where my schema-mother.xml was renamed to schema-mother.xml.bak but that went away with I got the loading straightened out.\n\n\n\n\n\tI'm not sure what I think about the \"mother\" bits. Anyone have a better name?\n\n\n\n\n\tI do like how this approach couples the field definitions with the test. The randomizing will also help catch hidden assumptions. So far it isn't onerous to add the fields for a test one needs.\n\n\n\n\n\tPerhaps we should do some variant of \"hungarian notation\" for the fieldTypes in schema-mother.xml? There should be a way to quickly find out what field types are available without having to look at every single one. A field of \"name\" for instance doesn't tell us anything about it. We already use things like _s _ss for string and string-multivalued for instance.\n\n\n\nI want to emphasize that this is a WIP. We wanted to get this to the point of being able to see what it looked like in a couple of tests and invite comments, so fire away. I'm particularly looking at whether people think the approach makes sense or if there are alternate ways we could approach it that are better.\n\n ",
            "author": "Erick Erickson",
            "id": "comment-16073116"
        },
        {
            "date": "2017-07-10T16:43:06+0000",
            "content": "No comments so everything's just fine, right?\n\nDavid SmileyAmrit SarkarAlexandre RafalovitchChris Hostetter (Unused)\nAny comments or should we just carry this forward? ",
            "author": "Erick Erickson",
            "id": "comment-16080622"
        },
        {
            "date": "2017-07-10T17:08:50+0000",
            "content": "I haven't done more then just skim the patch, but I would strongly advise against any attempt to make more tests leverage ManagedIndexSchema (and adding fields as needed in setup) unless/until both SOLR-11034 & SOLR-11035 get fixed.  The combination of the two are essentially a guaranteed recipe for confusing (non-reproducible seed) failures like SOLR-10562 and SOLR-9843. ",
            "author": "Hoss Man",
            "id": "comment-16080664"
        },
        {
            "date": "2017-07-10T17:26:42+0000",
            "content": "Chris Hostetter (Unused) Agreed, we won't check it in until those JIRAs are fixed.\n\nAt this point, I'm more looking at whether this approach seems useful in form before polishing it. Do you find the code snippet above something you'd actually use when writing tests? Or are there better approaches from a test writer's perspective? ",
            "author": "Erick Erickson",
            "id": "comment-16080697"
        },
        {
            "date": "2017-07-21T10:03:39+0000",
            "content": "Though I have limited exposure of writing tests in Lucene / Solr project, I really liked the new simple framework. It saves lot of time and is modular for each test method of test case, making it meaningful. You don't have to scrape through entire schema to see attributes of particular field-name / field-type used in a test method. ",
            "author": "Amrit Sarkar",
            "id": "comment-16096085"
        },
        {
            "date": "2017-07-23T17:58:15+0000",
            "content": "I think this is getting near final form, pending resolution of blockers. It's time to render an opinion of whether this approach has legs because I'll check it in when the blockers are resolved.\n\nThere are three cases to deal with (so far)\n1> stand-alone, single cores\n2> non-cloud, distributed\n3> Cloud mode\n\nThis patch has an example of each converted to use the schema framework.\n\nWARNING: When people start using this there'll be, I predict, a lot of Jenkins errors. Every test I've converted has has some assumptions that, due to randomization, may succeed for a while. Example:\n\nDistributedQueryElevationTest:\n\nsorted on int_i and examined the responses for the text fields. Unless and until one explicitly defined int_i as multiValued=\"false\" and the text fields as stored=\"true\" this would intermittently fail. It may be wise to beast tests as they are converted... or at least run them multiple times. The test-nocompile is very helpful for that... This may be particularly interesting with docValues and stored/not stored.\n\nI think this is a +1 though as the coupling of the assumptions with the tests is much easier to track.\n\nI'm not quite sure what to do with points .vs. numerics yet. We ought to be able to randomize the /t/p* primitives, although we may need to override some of that for testing specific cases. Sysprop? Prefix on addTypes (e.g. ^tint means \"must be a tint\")? ",
            "author": "Erick Erickson",
            "id": "comment-16097730"
        },
        {
            "date": "2017-07-24T02:42:20+0000",
            "content": "This is clearly a major step forward; thanks Erick & Amrit!\n\nSome questions/observations:\n\n\tI take it reducing test solrconfig.xml files is out of scope of this issue?\n\tThe latest patch seems to be a patch to be applied on top of a previous version of the patch, which is very difficult to consume with fresh eyes.  Can a fresh all-inclusive patch please be attached?\n\tin solrconfig-id-version.xml: why change df from text field to id?\n\tRE copying field types from uber: how are resources like synonyms.txt handled?  I suspect it \"just works\" because all these configs are actually in the same dir and thus is kinda the same config?\n\n ",
            "author": "David Smiley",
            "id": "comment-16097890"
        },
        {
            "date": "2017-07-24T18:06:13+0000",
            "content": "bq: I take it reducing test solrconfig.xml files is out of scope of this issue?\nYep. Although I'm working out a couple of interesting bits, e.g. a sys var to turn on and off update logs.\n\nbq: The latest patch seems to be a patch to be applied on top of a previous version of the patch, which is very difficult to consume with fresh eyes. Can a fresh all-inclusive patch please be attached?\nAttached, I'll master Git yet.\n\nbq: in solrconfig-id-version.xml: why change df from text field to id?\nJust to have a field there that is always present. I think core startup failed if there was no actual definition for the df field. May not have been necessary.\n\nbq: RE copying field types from uber: how are resources like synonyms.txt handled? I suspect it \"just works\" because all these configs are actually in the same dir and thus is kinda the same config?\nHasn't been thought through frankly. But so far you're right, it \"just works\" because all the files are in the source tree. Yet another thing to clean up as people start to use this. ",
            "author": "Erick Erickson",
            "id": "comment-16098916"
        },
        {
            "date": "2017-07-24T20:04:47+0000",
            "content": "Does it make sense to use the SolrJ APIs to change the schema instead? ",
            "author": "Erick Erickson",
            "id": "comment-16099057"
        },
        {
            "date": "2017-07-25T03:21:00+0000",
            "content": "Does it make sense to use the SolrJ APIs to change the schema instead?\n\nWell this framework here randomizes the settings that aren't explicit, and I imagine that might be hard to do with SolrJ schema API?  Can you still use SolrJ schema API if a test writer wanted to?\n\nRE setting \"df\" to \"id\" in solrconfig-id-version.xml: please don't do that; leave it off entirely.  If a test fundamentally requires the default field bet set, it ought to set it.  If it leads to errors then this is a good thing as whatever query caused it was ambiguous and they should be fixed.  Setting \"df\" in solrconfig can be problematic since it effects the entire query in ways that might be unanticipated since the Lucene query parser is activated via many Solr features (e.g. facet.query etc.).  This conceals bugs or makes errors take longer to troubleshoot (some head scratching moments as to why a query isn't working but doesn't error).  In my perfect world (that this isn't), \"df\" would only be a local-param, and all params would be considered a local-param to 'q' for convenience. ",
            "author": "David Smiley",
            "id": "comment-16099432"
        }
    ]
}