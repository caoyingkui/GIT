{
    "id": "LUCENE-7474",
    "title": "Improve doc values writers",
    "details": {
        "resolution": "Fixed",
        "affect_versions": "None",
        "components": [],
        "labels": "",
        "fix_versions": [
            "7.0"
        ],
        "priority": "Minor",
        "status": "Resolved",
        "type": "Improvement"
    },
    "description": "One of the goals of the new iterator-based API is to better handle sparse data. However, the current doc values writers still use a dense representation, and some of them perform naive linear scans in the nextDoc implementation.",
    "attachments": {
        "LUCENE-7474.patch": "https://issues.apache.org/jira/secure/attachment/12831555/LUCENE-7474.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "id": "comment-15545644",
            "author": "Adrien Grand",
            "date": "2016-10-04T15:21:27+0000",
            "content": "Here is a patch. Writers now only store actual values (not placeholders for documents that do not have a value) and documents that have a value for the field are encoded using a FixedBitSet. While this is still technically linear, this should be significantly faster in the sparse case since many documents can be skipped at once. "
        },
        {
            "id": "comment-15545780",
            "author": "Michael McCandless",
            "date": "2016-10-04T15:42:50+0000",
            "content": "+1, wonderful. "
        },
        {
            "id": "comment-15545988",
            "author": "ASF subversion and git services",
            "date": "2016-10-04T17:06:50+0000",
            "content": "Commit d50cf97617c88ec75fd8f4482003623db08e625e in lucene-solr's branch refs/heads/master from Adrien Grand\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=d50cf97 ]\n\nLUCENE-7474: Doc values writers should have a sparse encoding. "
        },
        {
            "id": "comment-15548058",
            "author": "Otis Gospodnetic",
            "date": "2016-10-05T08:26:03+0000",
            "content": "yoooohooo! \nDo the nightly builds have any tests that will exercise these new writers, the new 7.0 Codec, etc., so one can see how much speed this change gains? "
        },
        {
            "id": "comment-15548127",
            "author": "Adrien Grand",
            "date": "2016-10-05T09:02:54+0000",
            "content": "All our benchmarks use dense data I think. The good news is that these changes did not seem to slow down indexing in the dense case if I look at http://people.apache.org/~mikemccand/geobench.html#index-times or http://people.apache.org/~mikemccand/lucenebench/indexing.html, or at least the slow down is small enough so that nothing is noticeable if there are points or terms indexed too. However regarding search, this change is almost certainly going to make things slower (see eg. http://people.apache.org/~mikemccand/lucenebench/Term.html), I think we need to be careful about keeping the slowdown contained. "
        },
        {
            "id": "comment-15564060",
            "author": "Otis Gospodnetic",
            "date": "2016-10-11T01:01:10+0000",
            "content": "I was wondering how one could compare Lucene indexing (and searching) performance before and after this change.  Is there a way to add a sparse dataset for the nightly benchmark and use it for both trunk and 6.x branch, so one can see the performance difference of Lucene 6.x with sparse data vs. Lucene 7.x with sparse data? "
        },
        {
            "id": "comment-15565052",
            "author": "Michael McCandless",
            "date": "2016-10-11T09:54:04+0000",
            "content": "A sparse set in the nightly benchmarks is an interesting idea.  Do you have a data set in mind?\n\nAt some point I'll write up a blog post summarizing the change and I can also try to do a before (6.x) / after (upcoming 7.0) one-time performance test for that. "
        }
    ]
}