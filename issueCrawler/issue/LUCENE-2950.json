{
    "id": "LUCENE-2950",
    "title": "Modules under top-level modules/ directory should be included in lucene's build targets, e.g. 'package-tgz', 'package-tgz-src', and 'javadocs'",
    "details": {
        "labels": "",
        "priority": "Blocker",
        "components": [
            "general/build"
        ],
        "type": "Bug",
        "fix_versions": [
            "4.0-ALPHA"
        ],
        "affect_versions": "4.0-ALPHA",
        "resolution": "Duplicate",
        "status": "Closed"
    },
    "description": "Lucene's top level modules/ directory is not included in the binary or source release distribution Ant targets package-tgz and package-tgz-src, or in javadocs, in lucene/build.xml.  (However, these targets do include Lucene contribs.)\n\nThis issue is visible via the nightly Jenkins (formerly Hudson) job named \"Lucene-trunk\", which publishes binary and source artifacts, using package-tgz and package-tgz-src, as well as javadocs using the javadocs target, all run from the top-level lucene/ directory.",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "date": "2011-03-04T17:11:21+0000",
            "content": "this is a big problem, the source.tgz artifact that is produced will not even compile because unfortunately some contribs depend on /modules.\n\nideally we could remove these dependencies though. ",
            "author": "Robert Muir",
            "id": "comment-13002718"
        },
        {
            "date": "2011-03-08T20:29:03+0000",
            "content": "ideally we could remove these dependencies though.\n\nHow would this work?  E.g. many contribs depend on the common-analyzers module.  Removing this dependency would almost certainly make the contribs non-functional.\n\nMaybe you mean, we should move contribs with modules/ dependencies into modules/? ",
            "author": "Steve Rowe",
            "id": "comment-13004188"
        },
        {
            "date": "2011-03-08T20:49:14+0000",
            "content": "How would this work? E.g. many contribs depend on the common-analyzers module. Removing this dependency would almost certainly make the contribs non-functional.\n\nThe dependency is mostly bogus. Here is the contribs in question:\n\n\tant\n\tdemo\n\tlucli\n\tmisc\n\tspellchecker\n\tswing\n\twordnet\n\n\n\nFor example the ant IndexTask only depends on this so it can make this hashmap:\n\n    static {\n      analyzerLookup.put(\"simple\", SimpleAnalyzer.class.getName());\n      analyzerLookup.put(\"standard\", StandardAnalyzer.class.getName());\n      analyzerLookup.put(\"stop\", StopAnalyzer.class.getName());\n      analyzerLookup.put(\"whitespace\", WhitespaceAnalyzer.class.getName());\n    }\n\n\n\nI think we could remove this, e.g. it already has reflection code to build the analyzer, if you supply \"Xyz\" why not just look for XyzAnalyzer as a fallback?\n\nThe lucli code has 'StandardAnalyzer' as a default: I think its best to not have a default analyzer at all. I would have fixed this already: but this contrib module has no tests! This makes it hard to want to get in there and clean up.\n\nThe misc code mostly supplies an Analyzer inside embedded tools that don't actually analyze anything. We could add a pkg-private NullAnalyzer that throws UOE on its tokenStream() <-- especially as they shouldnt be analyzing anything, so its reasonable to do?\n\nThe spellchecker code has a hardcoded WhitespaceAnalyzer... why is this? Seems like the whole spellchecking n-gramming is wrong anyway. Spellchecker uses a special form of n-gramming that depends upon the word length. Currently it does this in java code and indexes with WhitespaceAnalyzer (creating a lot of garbage in the process, e.g. lots of Field objects), but it seems this could all be cleaned up so that the spellchecker uses its own SpellCheckNgramAnalyzer, for better performance to boot.\n\nThe swing code defaults to a whitespaceanalyzer... in my opinion again its best to not have a default analyzer and make the user somehow specify one.\n\nThe wordnet code uses StandardAnalyzer for indexing the wordnet database. It also includes a very limited SynonymTokenFilter. In my opinion, now that we merged the SynonymTokenizer from solr that supports multi-word synonyms etc (which this wordnet module DOES NOT!), we should nuke this whole thing. \n\nInstead, we should make the synonym-loading process more flexible, so that one can produce the SynonymMap from various formats (such as the existing Solr format, a relational database, wordnet's format, or openoffice thesaurus format, among others). We could have parsers for these various formats. This would allow us to have a much more powerful synonym capability, that works nicely regardless of format. We could then look at other improvements, such as allowing SynonymFilter to use a more ram-conscious datastructure for its Synonym mappings (e.g. FST), and everyone would see the benefits.\nSo hopefully this entire contrib could be deprecated.\n ",
            "author": "Robert Muir",
            "id": "comment-13004205"
        },
        {
            "date": "2011-06-28T01:48:41+0000",
            "content": "just following up: the only thing in lucene reaching back into modules right now is contrib/demo... ",
            "author": "Robert Muir",
            "id": "comment-13056245"
        },
        {
            "date": "2011-06-28T02:41:03+0000",
            "content": "The xml-query-parser demo also reaches back to StandardAnalyzer.  Does this get included in the packaging? ",
            "author": "Chris Male",
            "id": "comment-13056259"
        },
        {
            "date": "2011-10-07T19:39:30+0000",
            "content": "This is related to LUCENE-2999 (or a subset of it) ",
            "author": "Robert Muir",
            "id": "comment-13123114"
        },
        {
            "date": "2012-01-17T21:18:06+0000",
            "content": "this is a duplicate of LUCENE-2999 right? ",
            "author": "Simon Willnauer",
            "id": "comment-13188004"
        },
        {
            "date": "2012-01-17T21:26:22+0000",
            "content": "this is a duplicate of LUCENE-2999 right?\n\nvice-versa, but yes. ",
            "author": "Steve Rowe",
            "id": "comment-13188016"
        },
        {
            "date": "2012-01-17T21:26:25+0000",
            "content": "Out of that huge list, the only contrib still reaching back into /modules is contrib/demo.  ",
            "author": "Robert Muir",
            "id": "comment-13188017"
        },
        {
            "date": "2012-02-12T19:36:20+0000",
            "content": "Out of that huge list, the only contrib still reaching back into /modules is contrib/demo.\n\nMaybe lucene/contrib/demo/ should be moved to modules/demo/?\n\nAlso, the javadocs-all target in lucene/build.xml depends on modules modules/queryparser/, modules/analysis/common/, and modules/queries/. ",
            "author": "Steve Rowe",
            "id": "comment-13206492"
        },
        {
            "date": "2012-02-13T14:36:15+0000",
            "content": "\nMaybe lucene/contrib/demo/ should be moved to modules/demo/?\n\nI don't remember which issue the discussions were on, but somewhere we discussed improving the way we do this,\nsuch that we have something like an 'examples' module, which could have various examples showing how to use lucene/solr,\nincluding modules (e.g. faceting). \n\nI think its nice to have little examples in javadocs, but at the same time it would be really nice to have\nmore fleshed-out examples which can span across different use-cases, for example faceting and grouping combined or whatever.\n\nAs a real module of course we enforce we don't break these (unlike javadocs examples: which really i think should not\ngrow too large but just be easy demonstrations of the basics), and we can even have tests that they are also\nexample-ing correctly (the demo stuff does have some tests).\n\nSo my first idea would be a top-level examples/... in fact I don't even think it should be rooted underneath modules/.\nExamples are for new users and they shouldn't have to dig around to find them. ",
            "author": "Robert Muir",
            "id": "comment-13206905"
        },
        {
            "date": "2012-02-13T15:49:36+0000",
            "content": "Interesting - I assume, though, that solr/example/ would stay where it is?\n\nI like the idea of continuously testing examples.\n\nI don't remember which issue the discussions were on, but somewhere we discussed improving the way we do this, such that we have something like an 'examples' module, which could have various examples showing how to use lucene/solr, including modules (e.g. faceting).\n\nI think you're thinking of LUCENE-3550. ",
            "author": "Steve Rowe",
            "id": "comment-13206947"
        },
        {
            "date": "2012-02-13T16:06:04+0000",
            "content": "\nI think you're thinking of LUCENE-3550.\n\nThat's the one, though it does seem to hint at examples being within each module.\n\nI am proposing instead that we have examples that can show how the different parts and pieces work together,\n\"big picture\", which I think is important as 4.0 is already a more modular architecture than 3.x\n\n\nInteresting - I assume, though, that solr/example/ would stay where it is?\n\nI have no opinion for now. I'd say leave it for the time being, there is already lots of documentation\nand stuff about how to use this in the place where it is now. I also think this is less of an 'example'\nand more of a 'defaults'... whenever I say this people argue with me, but lets face reality \n\nBut from the lucene side, as mentioned on LUCENE-3550, lots of APIs have changed, things have been modularized\nand refactored and moved around, and when lucene 4.x comes out (unless people are working really hard in secret\non this and I don't know about it), we won't have any \"lucene in action\" book for 4.x (to my knowledge) to shove \nthe responsibility onto... I sorta feel thats how users have dealt with this lack of documentation in the past.\n\nExamples are like the least-maintained part of lucene, so I dont have any solutions for 'hey how do we get people\nexcited about writing some nice clean examples', but it would be good to at least set things up so people can\ndo this easily without refactoring the build system. ",
            "author": "Robert Muir",
            "id": "comment-13206953"
        },
        {
            "date": "2012-04-19T06:12:31+0000",
            "content": "Fixed in LUCENE-3965 ",
            "author": "Robert Muir",
            "id": "comment-13257285"
        }
    ]
}