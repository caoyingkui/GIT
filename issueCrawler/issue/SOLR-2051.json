{
    "id": "SOLR-2051",
    "title": "analysis.jsp is incorrect for protWords etc",
    "details": {
        "affect_versions": "3.1,                                            4.0-ALPHA",
        "status": "Resolved",
        "fix_versions": [],
        "components": [
            "Admin UI"
        ],
        "type": "Bug",
        "priority": "Major",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "Analysis.jsp gives the incorrect results if you use \"protwords.txt\" or \"stemdict.txt\" or the like.\n\nThis is because this is now implemented with KeywordAttribute (so you can easily override any stemmer etc).\n\nFor example, if your schema had \"foobars\" in protwords.txt, analysis.jsp would show it being stemmed to \"foobar\", even though this doesnt actually happen.\n\nThe problem is that this jsp is downconverting the entire tokenstream to Token in between processing, so it silently discards KeywordAttribute and you get the wrong result.\n\nNote: this issue isnt about displaying other attributes such as KeywordAttribute (which would be a new feature). Its about not throwing them away so that the analysis actually represents what happens.",
    "attachments": {
        "dynamic-AttributeSource.patch": "https://issues.apache.org/jira/secure/attachment/12452274/dynamic-AttributeSource.patch",
        "SOLR-2051.patch": "https://issues.apache.org/jira/secure/attachment/12452197/SOLR-2051.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Robert Muir",
            "id": "comment-12899023",
            "date": "2010-08-16T18:36:44+0000",
            "content": "attached is a patch that uses AttributeSource.copyTo to preserve any custom attributes that might be in the stream.\n\nadditionally i added some logic for non-stringable terms (it will just print the bytes in hex) "
        },
        {
            "author": "Robert Muir",
            "id": "comment-12899028",
            "date": "2010-08-16T18:42:34+0000",
            "content": "you can reproduce this easily / verify it is now correct by going to the analysis.jsp, turning on verbose output, and entering \"dontstems\" for field type \"text\", as its already in the protwords.txt\n\nwithout the patch you will see it being stemmed. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-12899100",
            "date": "2010-08-16T21:26:30+0000",
            "content": "here is a slightly improved patch, but still this jsp file is scary.\n\ni wonder if we can use tee/sinks to do this cleaner? "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12899109",
            "date": "2010-08-16T21:45:02+0000",
            "content": "Ah, yeah, good catch!\n\ni wonder if we can use tee/sinks to do this cleaner?\n\nInsert a tap after each filter?  Yeah, might be safer by more closely emulating how the analysis actually works.\nFor example, if someone develops some whacky filters that rely on thread locals to pass info or something.\n\nSince it looks like you've fixed it already, I'd just commit that though. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-12899115",
            "date": "2010-08-16T21:56:05+0000",
            "content": "\nInsert a tap after each filter? Yeah, might be safer by more closely emulating how the analysis actually works.\nFor example, if someone develops some whacky filters that rely on thread locals to pass info or something.\n\nSince it looks like you've fixed it already, I'd just commit that though.\n\nWell, Uwe suggested CachingTokenFilter as one idea, we could keep the same overall flow. \n\nA 'printing tap' after each filter seems even better though... lemme try it and worse case we have this as the fix for now. "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-12899133",
            "date": "2010-08-16T22:14:55+0000",
            "content": "After a discussion with Robert, I also think that a Tap would be an elegant and less intrusive aproach (from the TokenStreams point of view). The Whole thing would simply create the Tokenizer, wrap the tap-filter around then add the next filter in chain, again add the tap again, and so on.\n\nThe filter simply calls input.increametToken() and then prints the current attributes. It can also hold a local \"pos\" field that is updated with positionIncrement to do formatting right. The code to resort tokens when negative position increments occur is useless, as Lucene no longer allows negative position increments (from what I know). The whole JSP would use no caching lists of tokens, no iterators, no array copy, no copyTo(). It just builds a tokenstream and consumes it. The Tap filter can also be added around the generic (non TokenizerChain Lucene Analyzer). The main code would simply do \"while (ts.incrementToken())\" - nothing more. All printout is done in the filters added between each chain step (or after the generic lucene analyzer). "
        },
        {
            "author": "Robert Muir",
            "id": "comment-12899178",
            "date": "2010-08-16T23:16:27+0000",
            "content": "ok, i had a look at reworking this as we discussed, but its more complicated\ndue to \"highlight matches\" etc.\n\nSo for now, heres the bugfix (same as before except it creates the fake tokenstream with the same factory as what the filter uses)\n\ni'll commit this and we should open another issue for reworking this, and probably printing all attributes when we do that. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-12899183",
            "date": "2010-08-16T23:25:52+0000",
            "content": "Committed revision 986158, 986160 "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-12899358",
            "date": "2010-08-17T09:36:12+0000",
            "content": "For performance reasons, I would move\n\n\nfinal AttributeSource token = iter.next();\nIterator<Class<? extends Attribute>> atts = token.getAttributeClassesIterator();\nwhile (atts.hasNext()) this.addAttribute(atts.next());\n\n\n\nto the ctor of the helper tokenstream. This is the same how TeeSink and all other tokenstreams work. Adding attributes later in the tokenstreams incrementToken() is not allowed, so you can be sure that after the original tokenstreams ctor was executed all attributes are available. Doing this on each incrementToken is the same like if indexer would do this on each incrementToken call. "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-12899363",
            "date": "2010-08-17T10:08:05+0000",
            "content": "Ah, I understand the problem. So ignore my last message: The printTokens method adds attributes that may not exist to the cloned AttributeSources. After that copyTo to the original stream does not work.\n\nJust an idea: Would it make sense, to let copyTo() automatically add missing target attributes? copyTo() is new in 3.x and trunk, so we can still change how it works. "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-12899367",
            "date": "2010-08-17T10:28:02+0000",
            "content": "Here the more dynamic AS, that adds missing attribute impls on restoreState() and copyTo(). This is just an idea, the AS test does not pass, as it checks for the exception previously thrown.\n\nI changed analysis.jsp to use this. Sorry for formatting changes, but my editor fixed the tabs.\n\nI am not sure, if this is good, as it may add tokenstreams attributes after the ctor which is discouraged and can lead to unexspected behaviour on the consumer, especially if factories dont match correct between source and target (in both cases, copyTo and restoreState). Ideally on copyTo(), the AS should check that AF is identical. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-12899415",
            "date": "2010-08-17T14:15:43+0000",
            "content": "Just an idea: Would it make sense, to let copyTo() automatically add missing target attributes\n\nNot sure, this wouldn't help the typical buffering case like SynonymFilter? I think this analysis.jsp\nthat crosses the tokenstreams is an extremely special case. "
        }
    ]
}