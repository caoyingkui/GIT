{
    "id": "SOLR-5232",
    "title": "SolrCloud should distribute updates via streaming rather than buffering.",
    "details": {
        "affect_versions": "None",
        "status": "Resolved",
        "fix_versions": [
            "4.6",
            "6.0"
        ],
        "components": [
            "SolrCloud"
        ],
        "type": "Improvement",
        "priority": "Critical",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "The current approach was never the best for SolrCloud - it was designed for a pre SolrCloud Solr - it also uses too many connections and threads - nailing that down is likely wasted effort when we should really move away from explicitly buffering docs and sending small batches per thread as we have been doing.",
    "attachments": {
        "SOLR-5232.patch": "https://issues.apache.org/jira/secure/attachment/12602540/SOLR-5232.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Mark Miller",
            "id": "comment-13764055",
            "date": "2013-09-11T06:38:59+0000",
            "content": "I hacked together an initial patch that uses a ConcurrentSolrServer per url with 1 thread and a queue of 10. I originally played around with sharing them across update requests as a static, but it ends up being difficult to wait until you know the updates are accepted, so I abandoned that. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13764074",
            "date": "2013-09-11T07:22:32+0000",
            "content": "Another quick pass - biggest change is sharing thread executor across requests to reduce the need to spin up new threads. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13764215",
            "date": "2013-09-11T11:22:41+0000",
            "content": "Mark:\n\nJust so it's recorded, there has been anecdotal evidence that the batch size of 10 we were using is a bottleneck, but there were reasons to not bump it up. Do you expect streaming to alter the throughput here? "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13764351",
            "date": "2013-09-11T14:26:42+0000",
            "content": "there has been anecdotal evidence that the batch size of 10 we were using is a bottleneck\n\nbatch size != queue size... and it's not even clear the queue does anything unless one is somehow producing documents in a very bursty fashion.\nStreaming rather than buffering is definitely the way to go. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13764371",
            "date": "2013-09-11T14:45:01+0000",
            "content": "This patch adds back in the retry on forwarding to leader logic (had hacked it out initially) and a new simple test for retries. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13764444",
            "date": "2013-09-11T16:10:31+0000",
            "content": "bq: batch size != queue size\n\nI wasn't confusing the two, they just happen to be the same numbers. What I'm after here is something on record as to whether we expect the anecdotal evidence of faster indexing by increasing batch size to be affected by streaming, making changing the batch size question less relevant.\n\nI suppose with Joel's/Mark's changes to CloudSolrServer, much of the question goes away anyway, and this JIRA will then primarily affect the leader forwarding the updates to the followers.\n\nOf course all bets are off if a user directly uses SUSS. Seems like a \"best practice\" is use CloudSolrServer and if you really insist on NOT using it, then this JIRA will keep you from deadlock. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13764484",
            "date": "2013-09-11T16:58:47+0000",
            "content": "All SolrJ clients and non SolrJ clients should fall under 'best practice' depending on your use case and desires. Using the new routing in CloudSolrServer is a possible workaround for issues that should be addressed, not worked around. Also, routing removes forwarding to leaders - you still send documents to replicas - that is still reliant on the buffer. CloudSolrServer can run also be used in a manner that does not route as an aside.\n\nmaking changing the batch size question less relevant.\n\nAs the comments on the batch size issue indicate, changing the size is not an option we are willing to go with.\n\nAs far as speed comparisons, someone would have to do some benchmarks to know how the new strategy holds up - it's just clearly where we have always needed to get to eventually.\n\nThere is no similar buffer size to consider here. "
        },
        {
            "author": "Otis Gospodnetic",
            "id": "comment-13764634",
            "date": "2013-09-11T19:06:38+0000",
            "content": "Mark Miller does that mean we can close SOLR-4956 as Won't Fix? "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13764638",
            "date": "2013-09-11T19:09:57+0000",
            "content": "Or resolve it as fixed by this if you wanted to track the issue as the performance problem. I'm fine with either approach.\n\nWe still have to look at thread count usage with the this though - and do some general checks. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13779970",
            "date": "2013-09-27T14:19:16+0000",
            "content": "This patch takes care of the nocommits in the previous patch. I'll commit shortly. "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-13780008",
            "date": "2013-09-27T15:13:18+0000",
            "content": "fyi, ShardSplitTest is much slower with this patch e.g. \n\nant -Dtests.seed=8FEFBE4A48F65343 -Dtestcase=ShardSplitTest clean test-core\n\nWithout patch: Total time: 1 minute 48 seconds\nWith patch: Total time: 4 minutes 25 seconds "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13780026",
            "date": "2013-09-27T15:45:46+0000",
            "content": "Hmm, lost in the noise for me because 205.66ms (that test's runtime for me) doesn't increase the total run time with tests.jvms=8.\n\nI'll dig into it. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13781419",
            "date": "2013-09-29T15:59:16+0000",
            "content": "Here is a patch with some improvements.\n\nI still have not gotten to the root cause of the SplitShardTest slowdown. Still digging around. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13799533",
            "date": "2013-10-18T21:27:33+0000",
            "content": "This patch address a performance issue when you were sending few docs per request to replicas (1 replica per request was really bad).\n\nThis was because each request runner would wait 250ms when the queue was empty just in case something came along. That was huge.\n\nThis patch waits for 0ms, which removes the issue for the few updates per request case and should not hurt the bulk docs per request case noticeably because we are using a queue of 100 anyway. "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-13799578",
            "date": "2013-10-18T22:10:55+0000",
            "content": "Commit 1533649 from Mark Miller in branch 'dev/trunk'\n[ https://svn.apache.org/r1533649 ]\n\nSOLR-5216: Document updates to SolrCloud can cause a distributed deadlock.\nSOLR-5232: SolrCloud should distribute updates via streaming rather than buffering. "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-13799586",
            "date": "2013-10-18T22:15:37+0000",
            "content": "Commit 1533652 from Mark Miller in branch 'dev/branches/branch_4x'\n[ https://svn.apache.org/r1533652 ]\n\nSOLR-5216: Document updates to SolrCloud can cause a distributed deadlock.\nSOLR-5232: SolrCloud should distribute updates via streaming rather than buffering. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13799757",
            "date": "2013-10-19T03:33:33+0000",
            "content": "I look forward to any further review or testing from interested parties. Resolving this for now. Let me know what you find. "
        },
        {
            "author": "Chris Geeringh",
            "id": "comment-13799951",
            "date": "2013-10-19T17:20:58+0000",
            "content": "Mark, I have my servers updated, however is it necessary to update solrj in my indexing client? I'm not seeing the maven jar in the repository relating to build #443. "
        },
        {
            "author": "Chris Geeringh",
            "id": "comment-13800039",
            "date": "2013-10-19T23:55:49+0000",
            "content": "This patch hasnt resolved the issue. 1.3 mill docs inserted and deadlock/no updates being accepted.\n\nI ran netstat on the servers, each of them have between 80-100 connections between each other in CLOSE_WAIT belonging to tomcat (only solr deployed) "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13800043",
            "date": "2013-10-20T00:10:25+0000",
            "content": "That means you were not liking seeing the same semaphore distrib lock that SOLR-5216 is about (that semaphore no longer exists) and there is something else going on with your setup. "
        },
        {
            "author": "Chris Geeringh",
            "id": "comment-13800045",
            "date": "2013-10-20T00:17:41+0000",
            "content": "OK, well as long as we're narrowing down the potential problem. The connections reported by netstat were all between the servers (not between the servers and my indexing client on different machine) "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13800051",
            "date": "2013-10-20T00:41:44+0000",
            "content": "I think we will know a lot more as people start reporting in on their results now. "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-13811813",
            "date": "2013-11-02T00:47:04+0000",
            "content": "Commit 1538112 from Mark Miller in branch 'dev/trunk'\n[ https://svn.apache.org/r1538112 ]\n\nSOLR-5232: fix retry logic "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-13811814",
            "date": "2013-11-02T00:47:52+0000",
            "content": "Commit 1538113 from Mark Miller in branch 'dev/branches/branch_4x'\n[ https://svn.apache.org/r1538113 ]\n\nSOLR-5232: fix retry logic "
        },
        {
            "author": "Jessica Cheng Mallet",
            "id": "comment-13941957",
            "date": "2014-03-20T16:59:02+0000",
            "content": "Just curious--has anyone gotten a chance to run with both before and after this change to see if the throughput is improved? "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13944459",
            "date": "2014-03-23T16:17:35+0000",
            "content": "I did some tests before and after with the Lucene benchmark for Solr integration patch I have - I don't recall the exact numbers, but it was a pretty decent improvement for batching or streaming cases. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13955931",
            "date": "2014-04-01T00:22:18+0000",
            "content": "I do think the per request time may have gone up a bit (and we might be able to improve that), but with a tradeoff that batch or streaming updates are much, much faster. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-14002020",
            "date": "2014-05-19T17:24:45+0000",
            "content": "Some more real world experience - the old system of internally sending around batches of 10 docs was horribly inefficient and a major performance limiter. The only way this might not be the case was if you were using client side hashing and no replicas. Batching with multiple threads is the key to performance with SolrCloud and the internal batch by 10 would just decimate the performance no matter the size the user batched - even with no replicas and just internal forwarding. This change unlocked that performance bottleneck and is at least many times faster in some cases. "
        }
    ]
}