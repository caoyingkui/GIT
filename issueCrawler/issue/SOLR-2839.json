{
    "id": "SOLR-2839",
    "title": "add alternative language detection impl",
    "details": {
        "affect_versions": "None",
        "status": "Closed",
        "fix_versions": [
            "3.5",
            "4.0-ALPHA"
        ],
        "components": [],
        "type": "Improvement",
        "priority": "Major",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "based on http://code.google.com/p/language-detection (apache license), supports 53 languages.",
    "attachments": {
        "SOLR-2839.patch": "https://issues.apache.org/jira/secure/attachment/12499190/SOLR-2839.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Robert Muir",
            "id": "comment-13128322",
            "date": "2011-10-16T02:00:48+0000",
            "content": "patch, needs the language detection jar and its deps from revision 111 of language-detection (in the lib folder), and the profiles files (into the resources folder) "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13128324",
            "date": "2011-10-16T02:04:55+0000",
            "content": "this is just for reviewing, there are a lot of svn moves etc (so i doubt you can easily apply it) "
        },
        {
            "author": "Koji Sekiguchi",
            "id": "comment-13128328",
            "date": "2011-10-16T02:30:01+0000",
            "content": "based on http://code.google.com/p/language-detection (apache license), supports 53 languages.\n\nI've seen that, too. +1. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13128335",
            "date": "2011-10-16T03:14:38+0000",
            "content": "ok, i'd like to add this basic implementation first.\n\nlater, we should add support for some advanced parameters and refactoring:\n\n\twhitelisting should not happen in the base class as a post-filter (though this is fine as a default implementation), but subclasses should override i think. For this detector, it could improve performance.\n\tfor this detector whitelist should support priors too (e.g. en=0.5, fr=0.1).\n\twe should add support for configuring smoothing parameter and maxTextLength (and, the base class's concat should respect that too).\n\tboth this implementation and the tika implementation are copying objects across lists of language information, i think this is not very efficient to do per-document. So I think we should change the API from List<DetectedLanguage> detectLanguage() to Iterable<DetectedLanguage> detectLanguage. It seems in general it just wants the first one anyway.\n\n "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-13128407",
            "date": "2011-10-16T14:21:43+0000",
            "content": "Cool. The reasoning behind a list of detected languages was that a more advanced detector could go sentence by sentence and tag multi lingual documents correctly. FAST had that capability.\n\nHow does this impl compare with the Tika one for short texts? And wouldn't it make more sense to add this on the Tika level letting the detection method be configurable? Then all Tika users would benefit from it. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13128409",
            "date": "2011-10-16T14:27:54+0000",
            "content": "\nHow does this impl compare with the Tika one for short texts? And wouldn't it make more sense to add this on the Tika level letting the detection method be configurable? Then all Tika users would benefit from it.\n\nI have no idea, probably not that great? But i didnt compare to tika.\nregarding short texts: http://shuyo.wordpress.com/2011/09/29/langdetect-is-updatedadded-profiles-of-estonian-lithuanian-latvian-slovene-and-so-on/\n\n\nAnd wouldn't it make more sense to add this on the Tika level letting the detection method be configurable? Then all Tika users would benefit from it.\n\nIf someone wants to do this, then we can remove this implementation at that time. But for lucene/solr, I am able to commit to this project, and I think that its important for langid to be pluggable to different implementations.\n\nFor example, maybe someone ports google's detector (http://src.chromium.org/viewvc/chrome/trunk/src/third_party/cld/) to java and we expose that too, which might be interesting for short texts. "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-13128414",
            "date": "2011-10-16T14:47:31+0000",
            "content": "Sure, it's way better to get stuff done than debate on details  Great work. Stuff can \"bubble down\" to Tika later just has stuff has bubbled down from Solr to Lucene.. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13128416",
            "date": "2011-10-16T14:51:37+0000",
            "content": "Its not really the same in my opinion. Anyone can commit to both lucene and solr so we can always put things in the correct place. "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-13128475",
            "date": "2011-10-16T18:13:08+0000",
            "content": "I meant to compare with the situation before the Solr+Lucene merge. It takes a whole lot longer time to wait for a dependency to get released before you can consume it, so then it's ok to add it higher up as a first step. "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-13157852",
            "date": "2011-11-27T12:36:05+0000",
            "content": "Bulk close after 3.5 is released "
        }
    ]
}