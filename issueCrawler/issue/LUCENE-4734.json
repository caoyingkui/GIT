{
    "id": "LUCENE-4734",
    "title": "FastVectorHighlighter Overlapping Proximity Queries Do Not Highlight",
    "details": {
        "components": [
            "modules/highlighter"
        ],
        "fix_versions": [
            "4.9",
            "6.0"
        ],
        "affect_versions": "4.0,                                            4.1,                                            6.0",
        "priority": "Major",
        "labels": "",
        "type": "Bug",
        "resolution": "Unresolved",
        "status": "Reopened"
    },
    "description": "If a proximity phrase query overlaps with any other query term it will not be highlighted.\n\nExample Text:  A B C D E F G\n\nExample Queries: \n\n\"B E\"~10 D\n(D will be highlighted instead of \"B C D E\")\n\n\"B E\"~10 \"C F\"~10\n(nothing will be highlighted)\n\n\nThis can be traced to the FieldPhraseList constructor's inner while loop. From the first example query, the first TermInfo popped off the stack will be \"B\". The second TermInfo will be \"D\" which will not be found in the submap for \"B E\"~10 and will trigger a failed match.",
    "attachments": {
        "lucene-4734.patch": "https://issues.apache.org/jira/secure/attachment/12572342/lucene-4734.patch",
        "LUCENE-4734.patch": "https://issues.apache.org/jira/secure/attachment/12592958/LUCENE-4734.patch",
        "LUCENE-4734-2.patch": "https://issues.apache.org/jira/secure/attachment/12593486/LUCENE-4734-2.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2013-01-29T23:34:48+0000",
            "content": "Added a patch with two test cases that reproduce the issue ",
            "author": "Ryan Lauck",
            "id": "comment-13565967"
        },
        {
            "date": "2013-01-31T05:38:25+0000",
            "content": "Tricky problem! I created a patch and modified my test cases (deleted the old test case patch).\n\nI'd appreciate any feedback, my solution seems durable and passes all highlighter test cases but I took a slightly different approach to finding the longest matching phrase.\n\nAlso a bonus idea!\nThe current addIfNoOverlap method assumes that we would never want overlapping highlights and throws them out. A better approach might be to allow the user to provide a delegate that can add/modify overlapping WeightedPhraseInfo, some possible implementations could be:\n\n\n\tfirst only - current behavior\n\tmerge - creates a single WPI that covers all overlaps\n\tsplit - gives priority to the first/existing WPI and add whatever is left overlaps\n\tlongest - gives priority to the longest WPI and drop any overlaps\n\tinclude all - this use case solves my need to return only the offsets of all highlights in a document and perform the highlighting and overlap handling myself at a later stage.\n\n ",
            "author": "Ryan Lauck",
            "id": "comment-13567380"
        },
        {
            "date": "2013-01-31T17:12:17+0000",
            "content": "I hope I'm not stepping on any toes here, but I realized my patch is similar to some of the work done in LUCENE-4118. My patch also solves the bug where repeated terms in a proximity query cause highlight matching to fail.\n\nI also took a different approach to handling reverse order matching on slop queries so that this patch could be a complete alternative to LUCENE-4118. I modified QueryPhraseMap.add to detect PhraseQuerys with slop and create a second mapping for the phrase terms in reverse order - this way no other code needs to change to handle proximity phrase terms appearing in reverse order.\n\nI added two simple test cases for both reverse ordering and repeated terms. ",
            "author": "Ryan Lauck",
            "id": "comment-13567818"
        },
        {
            "date": "2013-03-06T16:34:11+0000",
            "content": "Store the max possible slop on the QueryPhraseMap rather than the entire FieldQuery. This limits unnecessary matching when a PhraseQuery with a large slop is combined with other PhraseQuerys.\n\nAlso, I added a fragment of slop recalculation code from WeightedSpanTermExtractor that handles PhraseQuerys with position gaps. The most common way this is encountered is by searching a phrase that contains stop words while using an analyzer that filters them.\n\nAlso cleaned up the test cases a little, and added a few comments.  ",
            "author": "Ryan Lauck",
            "id": "comment-13594842"
        },
        {
            "date": "2013-07-18T10:56:39+0000",
            "content": "Ryan, I iterated over your patch in order to be able to handle a few more queries, specifically phrase queries that contain gaps or have several terms at the same position.\n\nIt is very hard to handle all possibilities without making the highlighting complexity explode. I'm looking forward to LUCENE-2878 so that highlighting can be more efficient and doesn't need to duplicate the query interpretation logic anymore. ",
            "author": "Adrien Grand",
            "id": "comment-13712217"
        },
        {
            "date": "2013-07-18T15:55:07+0000",
            "content": "Thanks Adrien!\n\nI agree about LUCENE-2878. I came to the same conclusion before finding that someone had already done most of the work that the ideal scenario is to (optionally) pull postings or term vectors in addition to payloads while scoring and expose them for highlighting. I'm looking forward to that patch too!\n\nAn idea I began working on but haven't polished enough to submit a patch for:\n\nUsers of the API could access raw highlight metadata (offsets and positions) and could additionally process to merge/filter/ignore overlapping highlights - one flaw I've had to work around in existing highlighters is that when highlights overlap they either merge them or toss all but the first encountered. We perform the highlighting manually in our system and hope to one day allow end users to toggle which terms are highlighted without having to make round-trips to the server to modify the search criteria and rerun the highlighter. With raw offset data this is trivial and merging/discarding overlaps can be handled in client-side code. There are additional advantages too such as being able to highlight find-in-page or search-within-search results and only having to transfer new offset metadata rather than the entire text over the wire (we have some very big 100MB+ documents). ",
            "author": "Ryan Lauck",
            "id": "comment-13712427"
        },
        {
            "date": "2013-07-19T09:18:38+0000",
            "content": "Hey Ryan, I think the use-case you are describing will be possible. However this will require some care because offsets computed by Lucene's analysis API are offsets for UTF16-encoded content (Java's internal encoding). So if your client code' programming language has a different internal encoding, you will need to perform conversions (this is not a fundamental problem, just something to be aware of in order not to get bad surprises). ",
            "author": "Adrien Grand",
            "id": "comment-13713480"
        },
        {
            "date": "2013-07-19T12:52:40+0000",
            "content": "Commit 1504862 from Adrien Grand in branch 'dev/trunk'\n[ https://svn.apache.org/r1504862 ]\n\nLUCENE-4734: Add FastVectorHighlighter support for proximity queries and phrase queries with gaps or overlapping terms. ",
            "author": "ASF subversion and git services",
            "id": "comment-13713619"
        },
        {
            "date": "2013-07-19T12:55:15+0000",
            "content": "Commit 1504863 from Adrien Grand in branch 'dev/branches/branch_4x'\n[ https://svn.apache.org/r1504863 ]\n\nLUCENE-4734: Add FastVectorHighlighter support for proximity queries and phrase queries with gaps or overlapping terms. ",
            "author": "ASF subversion and git services",
            "id": "comment-13713620"
        },
        {
            "date": "2013-07-22T11:06:36+0000",
            "content": "The approach I used can be memory-intensive when there are many positions that have several terms, here is a fix. ",
            "author": "Adrien Grand",
            "id": "comment-13715110"
        },
        {
            "date": "2013-07-22T16:59:09+0000",
            "content": "Commit 1505731 from Adrien Grand in branch 'dev/trunk'\n[ https://svn.apache.org/r1505731 ]\n\nLUCENE-4734: Better memory efficiency. ",
            "author": "ASF subversion and git services",
            "id": "comment-13715361"
        },
        {
            "date": "2013-07-22T17:01:38+0000",
            "content": "Commit 1505732 from Adrien Grand in branch 'dev/branches/branch_4x'\n[ https://svn.apache.org/r1505732 ]\n\nLUCENE-4734: Better memory efficiency. ",
            "author": "ASF subversion and git services",
            "id": "comment-13715364"
        },
        {
            "date": "2013-07-22T17:48:24+0000",
            "content": "I'm curious what you think about the comment I had in my original patch before calling addIfNoOverlap. It seems wasteful to traverse the phrase candidate list from the beginning every iteration to search for overlaps, and also prevents gathering the raw highlights as mentioned in my previous comment. What do you think about waiting until all phrase candidates are gathered to optionally filter overlaps? ",
            "author": "Ryan Lauck",
            "id": "comment-13715444"
        },
        {
            "date": "2013-07-22T18:01:42+0000",
            "content": "I agree this seems wasteful. Maybe we could open an issue about it? ",
            "author": "Adrien Grand",
            "id": "comment-13715461"
        },
        {
            "date": "2013-07-23T18:44:44+0000",
            "content": "Bulk move 4.4 issues to 4.5 and 5.0 ",
            "author": "Steve Rowe",
            "id": "comment-13717041"
        },
        {
            "date": "2013-08-16T00:41:41+0000",
            "content": "Looking at some highlighter code, I see this constructor in org.apache.lucene.search.vectorhighlight.FieldPhraseList.java of branch_4x:\n\n\n/**\n * a constructor.\n * \n * @param fieldTermStack FieldTermStack object\n * @param fieldQuery FieldQuery object\n * @param phraseLimit maximum size of phraseList\n */\npublic FieldPhraseList( FieldTermStack fieldTermStack, FieldQuery fieldQuery, int phraseLimit ){\n  final String field = fieldTermStack.getFieldName();\n\n  QueryPhraseMap qpm = fieldQuery.getRootMap(field);\n  if (qpm != null) {\n    LinkedList<TermInfo> phraseCandidate = new LinkedList<TermInfo>();\n    extractPhrases(fieldTermStack.termList, qpm, phraseCandidate, 0);\n    assert phraseCandidate.size() == 0;\n  }\n}\n\n\n\nClearly phraseLimit is no longer used. Is it being deprecated, or is this simply work in progress that will use it again eventually?\n\nThis parameter is passed over several layers of code, ultimately it is set up in Solr using the hl.phraseLimit parameter.\n\nSeems like a \"dead parameter\" that should be cleaned up now or deprecated for future cleanup, but I can't say that I have been able to follow all of the work that has transpired in the highlighters.\n\nThe change occurred in Revision 1505732 (related to this Jira.) Before then, this parameter was used.\n\nComments? Or should this be a separate Jira issue? ",
            "author": "Jack Krupansky",
            "id": "comment-13741735"
        },
        {
            "date": "2013-09-05T16:29:00+0000",
            "content": "I've encountered several issues recently because of this patch I committed and I am considering reverting it. The issue is that it makes the runtime of FastVectorHighlighter very bad and this just doesn't work when the text to highlight has lots of occurrences of the query terms.\n\nI spent time trying to improve it but I couldn't find a way to make it work nicely. I wouldn't feel good to have a release of Lucene out with this patch in it so I will revert the patch tomorrow if there is no objection. ",
            "author": "Adrien Grand",
            "id": "comment-13759203"
        },
        {
            "date": "2013-09-05T19:41:21+0000",
            "content": "I did some performance testing of my original patch so I'd be happy to take a look at yours as well and see if I can come up with anything to help. Another idea I explored but never submitted was to build a finite state automata out of the query terms (each term is a state) and use that to highlight. Benchmarks were unstable but it seemed like a workable solution for complex queries. \n\nThe real question is: does it make more sense to invest time in LUCENE-2878 rather than further complicating FVH? FVH works great for simple phrase and single term queries but it has so many corner cases... ",
            "author": "Ryan Lauck",
            "id": "comment-13759359"
        },
        {
            "date": "2013-09-05T19:48:57+0000",
            "content": "The real question is: does it make more sense to invest time in LUCENE-2878 rather than further complicating FVH? FVH works great for simple phrase and single term queries but it has so many corner cases...\n\nThis is my feeling too. ",
            "author": "Adrien Grand",
            "id": "comment-13759365"
        },
        {
            "date": "2013-09-06T09:22:16+0000",
            "content": "The real question is: does it make more sense to invest time in LUCENE-2878 rather than further complicating FVH? FVH works great for simple phrase and single term queries but it has so many corner cases..\n\n+1 lets do it\n\n+1 to revert the change! ",
            "author": "Simon Willnauer",
            "id": "comment-13760081"
        },
        {
            "date": "2013-09-06T10:52:49+0000",
            "content": "Commit 1520536 from Adrien Grand in branch 'dev/trunk'\n[ https://svn.apache.org/r1520536 ]\n\nRevert LUCENE-4734. ",
            "author": "ASF subversion and git services",
            "id": "comment-13760118"
        },
        {
            "date": "2013-09-06T11:20:29+0000",
            "content": "Commit 1520544 from Adrien Grand in branch 'dev/branches/branch_4x'\n[ https://svn.apache.org/r1520544 ]\n\nRevert LUCENE-4734. ",
            "author": "ASF subversion and git services",
            "id": "comment-13760138"
        },
        {
            "date": "2014-04-16T12:54:27+0000",
            "content": "Move issue to Lucene 4.9. ",
            "author": "Uwe Schindler",
            "id": "comment-13970758"
        }
    ]
}