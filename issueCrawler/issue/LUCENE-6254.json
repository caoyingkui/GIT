{
    "id": "LUCENE-6254",
    "title": "Dictionary-based lemmatizer",
    "details": {
        "resolution": "Unresolved",
        "affect_versions": "None",
        "components": [
            "modules/analysis"
        ],
        "labels": "",
        "fix_versions": [
            "5.0"
        ],
        "priority": "Major",
        "status": "Open",
        "type": "New Feature"
    },
    "description": "The only way to achieve lemmatization today is to use the SynonymFilterFactory. The available stemmers are also inaccurate since they are only following simplistic rules.\n\nA dictionary-based lemmatizer will be more precise because it has the opportunity to know the part of speech. Thus it provides a more precise method to stem words compared to other dictionary-based stemmers such as Hunspell.\n\nThis is my effort to develop such a lemmatizer for Apache Lucene. The documentation is temporarily placed here:\nhttp://folk.uio.no/erlendfg/solr/lemmatizer.html",
    "attachments": {
        "LUCENE-6254.patch": "https://issues.apache.org/jira/secure/attachment/12699452/LUCENE-6254.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "id": "comment-14325665",
            "author": "Dawid Weiss",
            "date": "2015-02-18T09:58:24+0000",
            "content": "There actually is a dictionary-driven lemmatization engine in Lucene (for Polish). You could simply compile a dictionary for morfologik-stemming and reuse the same code.\n\nIn fact, this is how folks at the https://www.languagetool.org/ are using it (and they have support for multiple languages). "
        },
        {
            "id": "comment-14325668",
            "author": "Erlend Gar\u00e5sen",
            "date": "2015-02-18T10:01:47+0000",
            "content": "My patch including the lemmatizer and tests. "
        },
        {
            "id": "comment-14325669",
            "author": "Erlend Gar\u00e5sen",
            "date": "2015-02-18T10:04:25+0000",
            "content": "Thanks, I will take a look at it. The lemmatizer I have written will be used at University of Oslo, so this was my contribution back to Apache. "
        },
        {
            "id": "comment-14325674",
            "author": "Dawid Weiss",
            "date": "2015-02-18T10:08:38+0000",
            "content": "Lemmatisation is a tricky thing, especially for highly inflectional languages. There are technical issues (the dictionaries can get quite big; that's why morfologik-stemming uses an automaton to encode it efficiently) and non-technical issues (lemmatisation is typically combined with morfphological analysis to resolve disambiguities, otherwise it's not clear which lemma to pick for ambiguous surface forms). "
        },
        {
            "id": "comment-14325688",
            "author": "Erlend Gar\u00e5sen",
            "date": "2015-02-18T10:30:42+0000",
            "content": "This lemmatizer can do POS-tagging if it's enabled (and that the dictionary has information about word-classes). Ambiguous forms can either be indexed or reduced to one lemma. depending on how it is configured.\n\nWe have tested this lemmatizer by indexing 200,000 larger texts with a dictionary containing 700,000 entries. It does not take any longer time compared to one of the other available stemmers such as Hunspell.\n\nI guess morphological analysis will be more time-consuming and require more memory at index time? "
        },
        {
            "id": "comment-14325732",
            "author": "Dawid Weiss",
            "date": "2015-02-18T11:29:27+0000",
            "content": "> Ambiguous forms can either be indexed or reduced to one lemma.\n\nSure, there's some sort of workaround for everything  I'm not saying your contribution is bad or anything, I just said in general it's a tricky problem. The Polish dictionary in morfologik-stemming has 4,800,433 entries. That's 300mb of raw UTF8 where PoSs are highly ambiguous; most of it looks like this:\n\nwraca\u0142yby wraca\u0107 verb:pot:pl:m2.m3.f.n1.n2.p2.p3:ter:imperf:nonrefl+verb:pot:pl:m2.m3.f.n1.n2.p2.p3:ter:imperf:refl.nonrefl\n\n\n\nThe PoS tag is a Cartesian product of all the alternatives separated by dots... "
        }
    ]
}