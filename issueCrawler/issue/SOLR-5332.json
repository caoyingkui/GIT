{
    "id": "SOLR-5332",
    "title": "Add \"preserve original\" setting to the EdgeNGramFilterFactory",
    "details": {
        "affect_versions": "4.4,                                            4.5,                                            4.5.1,                                            4.6",
        "status": "Closed",
        "fix_versions": [],
        "components": [],
        "type": "Wish",
        "priority": "Major",
        "labels": "",
        "resolution": "Implemented"
    },
    "description": "Hi, as described here: http://lucene.472066.n3.nabble.com/Help-to-figure-out-why-query-does-not-match-td4086967.html the problem is in that if you have these 2 strings to index:\n1. facebook.com/someuser.1\n2. facebook.com/someveryandverylongusername\nand the edge ngram filter factory with min and max gram size settings 2 and 25, search requests for these urls will fail.\n\nBut search requests for:\n1. facebook.com/someuser\n2. facebook.com/someveryandverylonguserna\nwill work properly.\n\nIt's because first url has \"1\" at the end, which is lover than the allowed min gram size. In the second url the user name is longer than the max gram size (27 characters).\n\nWould be good to have a \"preserve original\" option, that will add the original string to the index if it does not fit the allowed gram size, so that \"1\" and \"someveryandverylongusername\" tokens will also be added to the index.\n\nBest,\nAlex",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "author": "Furkan KAMACI",
            "id": "comment-13818593",
            "date": "2013-11-10T22:42:37+0000",
            "content": "I've added preserveOriginal capability to EdgeNGramFilterFactory and attached a patch to SOLR-5152. I want to make clear something about the problem that is pointed at this issue. The schema that is described at here: http://lucene.472066.n3.nabble.com/Help-to-figure-out-why-query-does-not-match-td4086967.html uses LowerCaseFilterFactory before EdgeNGramFilterFactory. There is an explanation about it: http://wiki.apache.org/solr/AnalyzersTokenizersTokenFilters#solr.LowerCaseTokenizerFactory and says that: \"Creates tokens by lowercasing all letters and dropping non-letters.\" So non-letters will be dropped \"before\" tokens are retrieved by EdgeNGramFilterFactory. \n\nMy patch preserves original token if preserveOriginal is set to true and token length is less than minGramSize or greater than maxGramSize. "
        },
        {
            "author": "Furkan KAMACI",
            "id": "comment-13818596",
            "date": "2013-11-10T22:43:34+0000",
            "content": "This issue can be marked as duplicated because of that issue: https://issues.apache.org/jira/browse/SOLR-5152 "
        },
        {
            "author": "Furkan KAMACI",
            "id": "comment-13833582",
            "date": "2013-11-27T08:43:13+0000",
            "content": "Alexander S. if you change the Fix Version/s to the next release this issue can be regarded. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13833811",
            "date": "2013-11-27T13:50:27+0000",
            "content": "Why not just use another field? Its the same cost either way as this setting: except it works today and we dont have to maintain it.\n\nAdditionally you maintain more control: you can control boosting etc across the different fields "
        },
        {
            "author": "James Dyer",
            "id": "comment-13834074",
            "date": "2013-11-27T19:41:40+0000",
            "content": "We have a use case where we use a modified version of EdgeNGramFilter to \"preserve the original\".  The field we used this on is multi-valued.  We change all user queries against the field to phrases with slop to prevent partial matches across values.  But our users also want to be able to enter sub-strings on this field.  (Because all queries are phrase queries, wildcards are not an option.)  So had this functionality existed we would have been spared of having to implement it ourselves.  (I didn't contribute the code because I couldn't imagine it had broad applicability.  But it seems that with this issue, at least a few others out there have cases for it as well) "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13834135",
            "date": "2013-11-27T20:54:19+0000",
            "content": "James but the issue is still the same. There is no savings of doing this in the same field!\n\nSo to me its more clear to query on foo_exact:whatever if you want an exact match versus doing it in a roundabout way with a sloppy phrase query. "
        },
        {
            "author": "James Dyer",
            "id": "comment-13834141",
            "date": "2013-11-27T21:01:46+0000",
            "content": "there is if a user enters 2 keywords, the one matches an edgengram and the other matches an original keyword.  Our case involves book contributors.  If a book has 2 contributors, John Smith & Edward Jones, we want the user to get a result if they query \"edward jones\" or \"e jones\" or \"ed jones\", but not \"edward smith\" nor \"e smith\", etc.  The only solution I could come up with involved with a combination of edge n-grams and the original keywords in the same field.  I think there are valid usecases for this, perhaps not very many. "
        },
        {
            "author": "Furkan KAMACI",
            "id": "comment-13834223",
            "date": "2013-11-27T22:12:05+0000",
            "content": "Actually there is same situation at WordDelimiterFilterFactory. It splits words into new ones but still has a preserveOriginal capability too. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13834285",
            "date": "2013-11-27T23:00:28+0000",
            "content": "Just because WordDelimiterFilter has an option doesnt mean other filters should have it, its hardly a model citizen. Probably even more reason to really think about what is happening and question if its the right thing to do.\n\nFor the use case described in the issue, a separate field suffices and is likely more flexible and just as efficient. \n\nI admit i dont fully understand what James is doing. \n\nI'm just saying I dont think our filters need options like \"preserve\" or \"inject\" because I see generally no value versus just using another field: its typically just users who dont understand that the underlying cost in an inverted index is the same. "
        },
        {
            "author": "Furkan KAMACI",
            "id": "comment-13834318",
            "date": "2013-11-27T23:20:02+0000",
            "content": "I just gave an example use case of that option. I mean that: EdgeNGram may have that option or this option may be removed from WordDelimiter too it depends on whichever is a good choice. Of course it does not mean that if WordDelimiter has that option others should have too. However they have similar use cases and WordDelimiter one has that option. \n\nOn the other hand this issue is a duplicate of another one as I mentioned at my comment. This issue has some problems at description section as I mentioned too so we should not directly care about it as a use case. I implemented a wish for community because some people needs and wants it (I do not use it at my current application/s). It is up to us to decide using it or not. "
        },
        {
            "author": "Simon Endele",
            "id": "comment-14343414",
            "date": "2015-03-02T17:24:46+0000",
            "content": "+1 for this feature.\nWe use the EdgeNGramFilterFactory on a tokenized field (in order to implement a \"prefix search\" on index time) with minGramSize=\"3\".\nUnfortunately we observed that tokens with length 1 or 2 are actually deleted, unexpectedly from our point of view.\n\nUsing a second field (though complicated IMHO) would address query-issues, but it gets awkward when it comes to highlighting or phrase searches.\nFor instance when searching for \"us rep\"\n\n\tthe field with EdgeNGramFilterFactory highlights \"rep\" in \"representative\", but not \"US\" as this token has been removed,\n\tthe field without EdgeNGramFilterFactory highlights \"US\", but not \"representative\" as it has no prefixes indexed.\n\n\n\nBringing these highlightings together in one string is a quite complex task.\nNot speaking of a phrase search, which does not work at all for the example above.\n\nWe use minGramSize=\"3\" to reduce collisions of prefixes and abbreviations (like \"US\" and \"usage\") and reduce the index size.\nI admit, this does not prevent all collisions (e.g. \"USA\" still collides with \"usage\"), but it's a compromise.\n\nNevertheless, minGramSize is a nice feature of EdgeNGramFilterFactory, but it lacks a \"preserveOriginal\" flag IMO. "
        },
        {
            "author": "Furkan KAMACI",
            "id": "comment-14345260",
            "date": "2015-03-03T16:14:56+0000",
            "content": "Simon Endele You can check my patch at SOLR-5152. I've applied a patch there and this issue become a duplicate. "
        },
        {
            "author": "Thomas W\u00f6ckinger",
            "id": "comment-16423817",
            "date": "2018-04-03T10:24:29+0000",
            "content": "So what can be done to get this into the main line? "
        },
        {
            "author": "Ingomar Wesp",
            "id": "comment-16510060",
            "date": "2018-06-12T19:15:13+0000",
            "content": "Given that\u00a0LUCENE-7960\u00a0has been closed, I think this issue can be marked as fixed, too. "
        },
        {
            "author": "Alexandre Rafalovitch",
            "id": "comment-16566853",
            "date": "2018-08-02T14:09:36+0000",
            "content": "It seems most of this has been implemented in other, already referenced issues. It is not clear what is left to do here.\u00a0\n\nI suggest a new issue is opened with latest needs, if any still exist in the current Solr version. "
        }
    ]
}