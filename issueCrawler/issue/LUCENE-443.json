{
    "id": "LUCENE-443",
    "title": "ConjunctionScorer tune-up",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [
            "core/search"
        ],
        "type": "Bug",
        "fix_versions": [
            "2.1"
        ],
        "affect_versions": "1.9",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "I just recently ran a load test on the latest code from lucene , which is using a new BooleanScore and noticed the ConjunctionScorer was crunching through objects , especially while sorting as part of the skipTo call. It turns a linked list into an array, sorts the array, then converts the array back to a linked list for further processing by the scoring engines below.\n\n'm not sure if anyone else is experiencing this as I have a very large index (> 4 million items) and I am issuing some heavily nested queries\n\nAnyway, I decide to change the link list into an array and use a first and last marker to \"simulate\" a linked list.\n\nThis scaled much better during my load test as the java gargbage collector was less - umm - virulent",
    "attachments": {
        "ConjunctionScorer.java": "https://issues.apache.org/jira/secure/attachment/12314671/ConjunctionScorer.java",
        "Conjunction20060921.patch": "https://issues.apache.org/jira/secure/attachment/12341256/Conjunction20060921.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2005-10-02T14:32:05+0000",
            "content": "Updated a version of the ConjunctionScorer which uses an array rather than a linked list.\nThe first(), last()  and doc() method calls should probably be in-lined - maybe. ",
            "author": "Abdul Chaudhry",
            "id": "comment-12331065"
        },
        {
            "date": "2005-10-03T00:08:08+0000",
            "content": "I like performance, so I'm all for this.\nOne thing about the code: it has a few probably\nsuperfluous casts to (Scorer) from Scorer array elements.\n\nRegards,\nPaul Elschot ",
            "author": "Paul Elschot",
            "id": "comment-12331081"
        },
        {
            "date": "2005-10-03T04:22:07+0000",
            "content": "Simplified version, removed most casts, inlined first() and last().\nPasses all tests here.\n\nRegards,\nPaul Elschot ",
            "author": "Paul Elschot",
            "id": "comment-12331098"
        },
        {
            "date": "2005-10-04T07:40:45+0000",
            "content": "Thanks Paul,  re-ran load tests here, everything looks good and it looks easier to read as well.\nI also checked Arrays.sort, it's a merge sort - guaranteed nlogn.\nThis all looks squeaky clean.\nCheers,\n\u2013 Abdul ",
            "author": "Abdul Chaudhry",
            "id": "comment-12331227"
        },
        {
            "date": "2005-10-11T03:15:31+0000",
            "content": "The score() method can be simplified to use only the 'i' index. There is no need\nto offset the index into the scorers with the 'pos' variable, because all scorers match.\n\nRegards,\nPaul Elschot ",
            "author": "Paul Elschot",
            "id": "comment-12331735"
        },
        {
            "date": "2005-10-11T15:36:07+0000",
            "content": "ok, this makes sense as the scoring engine runs something like this\n\nwhile (scorer.next()) {\n  int doc = scorer.doc();\n  float scorer = scorer.score();\n  collector.collect(doc, score);\n}\n\nThat is, next() will have ordered everything, so that by the time we call the scorer.score() method , everything should be in-order.\n\nThanks, ill give that a go.\n\nThe impression I have with lucene, and correct me if Im wrong, is that complex queries with many terms and clauses have their bottleneck in terms of performance in the ordering phase, that is scorer.next() requires everything to be in-document order and all the scorer sub-engines must comply. Collection is a moot point as you probably have small numbers of hits. However, on the other end of the scale, for queries with one or two terms that have a very high frequency the bottleneck is really in collection, that is the priority queue in collector.collect(),\nEssentially this is a sorting issue, somewhat masked and manipulated at various stages.\nThis looks to me like lucene needs a \"Query Plan\".  ",
            "author": "Abdul Chaudhry",
            "id": "comment-12331775"
        },
        {
            "date": "2005-10-11T16:44:08+0000",
            "content": "Once the ConjunctionScorer matches the order of the subqueries/subscorers does not matter\nbecause they all match and a sum score needs to be formed.\n\nScorer.next() can only tolerate documents not to be in order at top level, where hit collection is done.\nAt lower levels in nested scorers, Lucene works a document at a time, and there Scorer.skipTo(docNr)\nrequires that all document numbers are in order. Such skipping is needed for conjunctions.\nSince the score value of a document for a query depends on the score value of the subqueries,\nat some point the association on a single document must be done.\nFor conjunctions, skipTo() is used, but for disjunctions this association is done by\na priority queue in the trunk, and a distribution like method in 1.4.3. This distribution method works\nsomewhat loosely on document order, and is therefore incompatible with skipping.\n\nRegards,\nPaul Elschot ",
            "author": "Paul Elschot",
            "id": "comment-12331778"
        },
        {
            "date": "2005-12-28T04:48:25+0000",
            "content": "It seems like more cruft could be removed if support for incremental adding of subscorers was removed.\nIs there a reason we can't simplify things and just pass Collection<Scorer> in the constructor?\n ",
            "author": "Yonik Seeley",
            "id": "comment-12361284"
        },
        {
            "date": "2006-09-21T01:09:48+0000",
            "content": "Yonik, Paul, do either of you know the status on this one?  From the looks of it, it hasn't been implemented.  It also has the highest number of votes in JIRA, so I thought I would take a look at it.  One downside is it is not in patch form, but it also doesn't look to hard to extract the changes, either.\n\nOne issue I have with these performance issues is that we don't have a reliable benchmarking suite.  I am not a lawyer, but might we be able to use something like http://trec.nist.gov/data/reuters/reuters.html to build a sample benchmark suite?  This corpus, plus 100 or so queries could work nicely.  Of course, we would have to figure out some way for those interested to get their hands on the data.  What do others do for benchmarking? ",
            "author": "Grant Ingersoll",
            "id": "comment-12436414"
        },
        {
            "date": "2006-09-21T07:17:07+0000",
            "content": "Iirc the orginal performance problem was caused by creation of objects in the tight loop\ndoing skipTo() on al  the scorers.\n\nThis patch is against current trunk and based on the earlier posted versions of ConjunctionScorer.\nwhich was based (by the first poster) on an existing ConjunctionScorer with an ASL notice,\nwhich is why I could grant the licence to ASF. ",
            "author": "Paul Elschot",
            "id": "comment-12436452"
        },
        {
            "date": "2006-09-21T07:20:21+0000",
            "content": "I just overlooked the grant by Abdul to the ASF. ",
            "author": "Paul Elschot",
            "id": "comment-12436453"
        },
        {
            "date": "2006-10-17T20:51:03+0000",
            "content": "Thanks!  I just committed this. ",
            "author": "Yonik Seeley",
            "id": "comment-12443064"
        },
        {
            "date": "2007-02-27T18:10:32+0000",
            "content": "Closing all issues that were resolved for 2.1. ",
            "author": "Michael McCandless",
            "id": "comment-12476256"
        }
    ]
}