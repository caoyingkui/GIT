{
    "id": "SOLR-3231",
    "title": "Add the ability to KStemmer to preserve the original token when stemming",
    "details": {
        "affect_versions": "None",
        "status": "Closed",
        "fix_versions": [
            "4.3",
            "6.0"
        ],
        "components": [
            "Schema and Analysis"
        ],
        "type": "Improvement",
        "priority": "Major",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "While using the PorterStemmer, I found that there were often times that it was far to aggressive in it's stemming.  In my particular case it is unrealistic to provide a protected word list which captures all possible words which should not be stemmed.  To avoid this I proposed a solution whereby we store the original token as well as the stemmed token so exact searches would always work.  Based on discussions on the mailing list Ahmet Arslan, I believe the attached patch to KStemmer provides the desired capabilities through a configuration parameter.  This largely is a copy of the org.apache.lucene.wordnet.SynonymTokenFilter.",
    "attachments": {
        "KStemFilter.patch": "https://issues.apache.org/jira/secure/attachment/12517874/KStemFilter.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Ryan McKinley",
            "id": "comment-13227257",
            "date": "2012-03-11T22:28:49+0000",
            "content": "If I understand the patch, this patch just sets the tokenType attribute to \"STEM\" right?\n "
        },
        {
            "author": "Jamie Johnson",
            "id": "comment-13227484",
            "date": "2012-03-12T13:01:32+0000",
            "content": "this should (unless I messed it up which is possible) also produce a token for the original term.  For instance if the term was \"bricks\" it should produce tokens for \"bricks\" and \"brick\".  If that's not the case please let me know.\n\nTestKStemFilterFactory.java\npackage org.apache.solr.analysis;\n\nimport java.io.Reader;\nimport java.io.StringReader;\n\nimport org.apache.lucene.analysis.MockTokenizer;\nimport org.apache.lucene.analysis.TokenStream;\nimport org.apache.lucene.analysis.tokenattributes.CharTermAttribute;\n\n/**\n * Licensed to the Apache Software Foundation (ASF) under one or more\n * contributor license agreements.  See the NOTICE file distributed with\n * this work for additional information regarding copyright ownership.\n * The ASF licenses this file to You under the Apache License, Version 2.0\n * (the \"License\"); you may not use this file except in compliance with\n * the License.  You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n/**\n * Simple tests to ensure the kstem filter factory is working.\n */\npublic class TestKStemFilterFactory extends BaseTokenTestCase {\n  public void testStemming() throws Exception {\n    Reader reader = new StringReader(\"bricks\");\n    KStemFilterFactory factory = new KStemFilterFactory();\n    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));\n    assertTokenStreamContents(stream, new String[] { \"bricks\", \"brick\" }, new int[]{1, 0});\n    \n  }\n}\n\n\n \n\nThat is what this tests right? "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13238557",
            "date": "2012-03-26T16:56:51+0000",
            "content": "I don't think we should approach the problem this way: this is the \nsame discussion as LUCENE-3415 "
        },
        {
            "author": "Jamie Johnson",
            "id": "comment-13238564",
            "date": "2012-03-26T17:08:22+0000",
            "content": "Thanks Robert.  I just read LUCENE-3415 and understand the approach.  My biggest issue is I don't like having to create a separate field to do an exact search, this of course is based on the fact that I was burned by this so perhaps I am biased.  It feels like the right thing to do from a user of the API would be to do the least destructive thing, but again I have a specific use case in mind and am not considering all other implications. "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-13653874",
            "date": "2013-05-10T10:33:15+0000",
            "content": "Closed after release. "
        }
    ]
}