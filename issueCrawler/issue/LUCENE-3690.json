{
    "id": "LUCENE-3690",
    "title": "JFlex-based HTMLStripCharFilter replacement",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [
            "modules/analysis"
        ],
        "type": "New Feature",
        "fix_versions": [
            "3.6",
            "4.0-ALPHA"
        ],
        "affect_versions": "3.5,                                            4.0-ALPHA",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "A JFlex-based HTMLStripCharFilter replacement would be more performant and easier to understand and maintain.",
    "attachments": {
        "HTMLStripCharFilterWarcTest.java": "https://issues.apache.org/jira/secure/attachment/12510688/HTMLStripCharFilterWarcTest.java",
        "jenkins_test.patch": "https://issues.apache.org/jira/secure/attachment/12511433/jenkins_test.patch",
        "BaselineWarcTest.java": "https://issues.apache.org/jira/secure/attachment/12510686/BaselineWarcTest.java",
        "LUCENE-3690-handle-utf16-surrogates.patch": "https://issues.apache.org/jira/secure/attachment/12511477/LUCENE-3690-handle-utf16-surrogates.patch",
        "JFlexHTMLStripCharFilterWarcTest.java": "https://issues.apache.org/jira/secure/attachment/12510687/JFlexHTMLStripCharFilterWarcTest.java",
        "LUCENE-3690.patch": "https://issues.apache.org/jira/secure/attachment/12510313/LUCENE-3690.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2012-01-12T05:40:03+0000",
            "content": "Patch implementing the idea.\n\nThis patch just creates a new class named JFlexHTMLStripCharFilter.  All of the HTMLStripCharFilterTest tests are copied over to JFlexHTMLStripCharFilterTest; Robert's random test is un-@Ignore'd, and several more tests are added. ",
            "author": "Steve Rowe",
            "id": "comment-13184740"
        },
        {
            "date": "2012-01-12T06:04:30+0000",
            "content": "Left to do:\n\n\n\tAccept supplementary characters in HTML tag names.\n\tRecognize uppercase character entity variants for \"quot\", \"copy\", \"gt\", \"lt\", \"reg\", and \"amp\" (from Dawid Weiss's SOLR-882 patch)\n\tRename current HTMLStripCharFilter to ClassicHTMLStripCharFilter\n\tRename JFlexStripCharFilter to HTMLStripCharFilterImpl\n\tMake a back-compat-enabling wrapper class (like StandardTokenizer) that will use ClassicHTMLStripCharFilter for Version.LUCENE_35 and earlier, and HTMLStripCharFilterImpl otherwise.\n\n\n\nThis would be the first back-compat enabled CharFilter.  Should the existing HTMLStripCharFilter instead vanish off the face of the earth? ",
            "author": "Steve Rowe",
            "id": "comment-13184745"
        },
        {
            "date": "2012-01-12T06:08:23+0000",
            "content": "This JFlex-based HTMLStripCharFilter replacement will fix LUCENE-2208. ",
            "author": "Steve Rowe",
            "id": "comment-13184746"
        },
        {
            "date": "2012-01-12T06:14:00+0000",
            "content": "One other thing left to do: I added javadocs to BaseCharFilter.addOffCorrectMap(), but I think they should be moved to the package javadocs for o.a.l.analysis.charfilter, and maybe add some examples.  (This package has basically zero documentation currently.) ",
            "author": "Steve Rowe",
            "id": "comment-13184749"
        },
        {
            "date": "2012-01-12T07:00:17+0000",
            "content": "Added a <![CDATA[...]]> section test, and fixed the CDATA section handling. ",
            "author": "Steve Rowe",
            "id": "comment-13184773"
        },
        {
            "date": "2012-01-12T12:30:03+0000",
            "content": "\nRobert's random test is un-@Ignore'd\n\n+1!\n ",
            "author": "Robert Muir",
            "id": "comment-13184889"
        },
        {
            "date": "2012-01-12T12:37:10+0000",
            "content": "Any idea how quickly this will be rolled into a new version? ",
            "author": "Brian Meidell",
            "id": "comment-13184890"
        },
        {
            "date": "2012-01-12T12:45:15+0000",
            "content": "\nThis would be the first back-compat enabled CharFilter. Should the existing HTMLStripCharFilter instead vanish off the face of the earth?\n\nWhat would be the motivation? Are there some features of the previous one that don't make sense in this implementation?\nI don't think fixing offsets bugs like LUCENE-2208 counts as breaking index backwards compat, because it won't change search results.\nIt will just prevent highlighters from throwing exceptions.\n\n(LUCENE-3642 and LUCENE-3668 fixed lots of offset bugs already, we didn't spend time on any back compat). ",
            "author": "Robert Muir",
            "id": "comment-13184904"
        },
        {
            "date": "2012-01-12T12:47:12+0000",
            "content": "Also I don't know how Version etc would work here, since the old HtmlStripCharFilter was never part of lucene.\n\nfrom lucene's perspective, its a new feature. ",
            "author": "Robert Muir",
            "id": "comment-13184914"
        },
        {
            "date": "2012-01-12T13:55:51+0000",
            "content": "Here's another to-do, from comment-12625835 in SOLR-42: handle MS-Word-generated broken processing instructions <? ... /> (instead of <? ... ?>. ",
            "author": "Steve Rowe",
            "id": "comment-13184969"
        },
        {
            "date": "2012-01-12T14:19:07+0000",
            "content": "\nThis would be the first back-compat enabled CharFilter.\n\nWhat would be the motivation?\n\nThere are differences in the behavior, but I guess all of these could be characterized as bug fixes:\n\n\n\tSupplementary characters in tags will be recognized.  The old version doesn't do this.\n\tCDATA sections are recognized.  The old version doesn't; people have requested this, e.g. http://www.lucidimagination.com/search/document/48fcd906e39764ec#48fcd906e39764ec)\n\tNo space is substituted for inline tags (e.g. <b>, <i>, <span>).  The old version substitutes spaces for all tags; people have complained e.g. on SOLR-1343\n\tBroken MS-Word-generated processing instructions <? ... /> will be handled.\n\tUppercase character entities \"quot\", \"copy\", \"gt\", \"lt\", \"reg\", and \"amp\" will be recognized (from Dawid Weiss's SOLR-882 patch); the old version doesn't do this.\n\n\n\nAre there some features of the previous one that don't make sense in this implementation?\n\nNo, not as far as I can tell.  I think all features of the previous one are included.\n\nAlso I don't know how Version etc would work here, since the old HtmlStripCharFilter was never part of lucene.  from lucene's perspective, its a new feature.\n\nGood point.  Should I make it a new Lucene feature on 3.X?  That is, should I remove Solr's HTMLStripCharFilter and have it refer to a new Lucene HTMLStripCharFilter? ",
            "author": "Steve Rowe",
            "id": "comment-13184983"
        },
        {
            "date": "2012-01-12T14:24:03+0000",
            "content": "AFAICT, SOLR-2891 will be fixed by this implementation. ",
            "author": "Steve Rowe",
            "id": "comment-13184985"
        },
        {
            "date": "2012-01-12T14:24:37+0000",
            "content": "\nThere are differences in the behavior, but I guess all of these could be characterized as bug fixes:\n\nThis sounds awesome!\n\n\nGood point. Should I make it a new Lucene feature on 3.X? That is, should I remove Solr's HTMLStripCharFilter and have it refer to a new Lucene HTMLStripCharFilter?\n\nI think so.\n\nIf you want to, you can make it package-private + deprecated inside o.a.solr.analysis. The Solr factory could respect\nthe luceneMatchVersion parameter for backwards compatibility, and instantiate the old version in that case.\n\nSo you would then move the old charfilter from modules/analysis to the same place in trunk, too... its purely a solr\nback-compat issue. For lucene users its just a new feature and they don't see any of this.\n\nThis is what we did with Synonyms. ",
            "author": "Robert Muir",
            "id": "comment-13184986"
        },
        {
            "date": "2012-01-13T19:04:11+0000",
            "content": "This patch contains a feature-complete version.  Changes from the previous patch:\n\n\n\tNow substituting newlines instead of spaces for block-level elements; this corresponds more closely to on-screen layout, enables sentence segmentation, and doesn't change offsets.\n\tSupplementary characters are now accepted in tags.\n\tSwitched accepted tag names from [:XID_Start:] and [:XID_Continue:] Unicode properties to the more relaxed [:ID_Start:] and [:ID_Continue:] properties, in order to broaden the range of recognizable input.  (The improved security afforded by the XID_* properties is irrelevant to what a CharFilter does.)\n\tUppercase character entity variants for \"quot\", \"copy\", \"gt\", \"lt\", \"reg\", and \"amp\" (from Dawid Weiss's SOLR-882 patch) are now accepted.\n\tMS-Word-generated broken processing instructions (<? ... /> instead of <? ... ?>) are now accepted.\n\tAdded several tests, including parsing a full MS-Word-2010-generated HTML file.\n\n\n\nLeft to do:\n\n\n\tMove javadocs from BaseCharFilter.addOffCorrectMap() to o.a.l.analysis.charfilter package level javadoc file.\n\tRename the existing HTMLStripCharFilter to ClassicHTMLStripCharFilter; move it to Solr o.a.s.analysis package; deprecate it; and make it package private.\n\tRename JFlexHTMLStripCharFilter to HTMLStripCharFilter.\n\tEnable Solr back-compat (but not Lucene back-compat, since HTMLStripCharFilter has never been released as part of Lucene) by making HTMLStripCharFilterFactory instantiate ClassicHTMLStripCharFilter if the luceneMatchVersion parameter is LUCENE_35 or earlier, and otherwise instantiate the new HTMLStripCharFilter.\n\n ",
            "author": "Steve Rowe",
            "id": "comment-13185759"
        },
        {
            "date": "2012-01-13T19:18:54+0000",
            "content": "Forgot to mention two more change in the latest patch from the previous version: \n\n7. The generated scanner's parse method now returns the next available character if one is available; this simplifies/clarifies the processing flow. (Previously the parse method returned an enum indicating whether to copy a char directly from the input buffer \u2013 OutputSource.DIRECT \u2013 or from another location \u2013 OutputSource.INDIRECT \u2013 the read() method would then have to go fetch the next character from the given source.)\n8. Renamed the generated scanner's parse method from the default yylex() to nextChar(). ",
            "author": "Steve Rowe",
            "id": "comment-13185771"
        },
        {
            "date": "2012-01-13T19:35:06+0000",
            "content": "I don't think fixing offsets bugs like LUCENE-2208 counts as breaking index backwards compat, because it won't change search results.\nIt will just prevent highlighters from throwing exceptions.\n\nFWIW: If i understand the issue correctly, then the one risk i can imagine here is that people don't reindex, and get the new behavior for new docs, so they'll get diff behavior are query time depending on when the doc is re-indexed.  that seems significant enough to definitely warrant the luceneMatchVersion toggle sarowe has on his todo list \u2013 which seems fairly straight forward.\n\nThe only concern i really have is...\n\nA JFlex-based HTMLStripCharFilter replacement would be more performant...\n\n..before deprecating \"ClassicHTMLStripCharFilter\" we should actually test that the Jlex version is faster ... because if it winds up being noticible slower in some cases, some people may prefer the the \"classic\" mode to the JFlex mode if the \"warts\" of the existing one don't affect them \u2013 in which case i might almost suggest actually using multiple factories in solr instead of making it versionMatch dependent.  \n\n(fingers crossed it's a non-issue) ",
            "author": "Hoss Man",
            "id": "comment-13185789"
        },
        {
            "date": "2012-01-13T19:41:32+0000",
            "content": "Let's be conservative and keep around HTMLStripCharFilter, and name this one something else?\nThe original was meant to handle all sorts of bad, partial, and weird input.\nOr are we really confident that this implementation handles everything the current one does? ",
            "author": "Yonik Seeley",
            "id": "comment-13185793"
        },
        {
            "date": "2012-01-13T19:44:43+0000",
            "content": "\nLet's be conservative and keep around HTMLStripCharFilter, and name this one something else?\nThe original was meant to handle all sorts of bad, partial, and weird input.\n\nI call bullshit. It fails on all kinds of bad/partial/and weird input.\n\nIn fact ill go remove my @Ignore now. Lets see if anyone can fix the bugs in it. That should settle this. ",
            "author": "Robert Muir",
            "id": "comment-13185795"
        },
        {
            "date": "2012-01-13T19:47:26+0000",
            "content": "are we really confident that this implementation handles everything the current one does?\n\nYes, this implementation's bad/partial/weird HTML handling capabilities are a superset of the current implementation.  The tests for the new implementation are a superset of the old implementation's tests.\n\nI welcome more examples of junk HTML to add to the tests  ",
            "author": "Steve Rowe",
            "id": "comment-13185796"
        },
        {
            "date": "2012-01-13T19:50:30+0000",
            "content": "\nThe only concern i really have is...\n\nA JFlex-based HTMLStripCharFilter replacement would be more performant...\n\n..before deprecating \"ClassicHTMLStripCharFilter\" we should actually test that the Jlex version is faster ... \n\n+1.  I'll do this before committing anything. ",
            "author": "Steve Rowe",
            "id": "comment-13185797"
        },
        {
            "date": "2012-01-13T19:52:35+0000",
            "content": "I welcome more examples of junk HTML to add to the tests \n\nJulien Nioche (Nutch) may have access to realistic large HTML crawls... there's nothing wilder and weirder than real-life HTML  ",
            "author": "Dawid Weiss",
            "id": "comment-13185799"
        },
        {
            "date": "2012-01-13T20:06:25+0000",
            "content": "+1.  I'll do this before committing anything.\n\ni wouldn't be shy about committing the new impl + tests, i would just wait to change the solr factory default behavior until we prove the perf is as good as the existing one in some common cases, and if it's not, then re-evaluate the names of the classes.\n\nand by common cases i'm thinking...\n\n\n\tsome test docs using typical wellformed html markup\n\tsome test docs using malformed markup that require backtracking\n\tsome test docs that contain almost no HTML at all (this is the one that i have a hunch may be a big differentiator \u2013 i've seen lots of people who use the HTML stripper not becuase they expect HTML, but because they want to be sure it doesn't get indexed if some stray html encoding sneaks into their data)\n\n ",
            "author": "Hoss Man",
            "id": "comment-13185810"
        },
        {
            "date": "2012-01-13T20:07:26+0000",
            "content": "The tests for the new implementation are a superset of the old implementation's tests.\n\nUnfortunately I'm not sure how much of a story the tests tell (and yes, that would be my fault \nMy memory is rusty, but back in '05 when I coded this thing, I threw a lot stuff we had lying around CNET at it, and also a lot of stuff downloaded from the web (which I couldn't just copy-n-paste into a unit test obviously).  I had a heck of a time handling all the weird stuff that could appear inside script tags, for example, and I don't think I see much of a test for that (again... my fault.)\n\nI welcome more examples of junk HTML to add to the tests\n\nNot saying the new one isn't great (and matching a lot of crap from the old one is quite an achievement).\nOne can be sure that the current implementation doesn't always do the right thing, but unfortunately \"right\" isn't well defined here considering the domain.\nThe cost to keeping around the current version for a little while seems minimal. ",
            "author": "Yonik Seeley",
            "id": "comment-13185811"
        },
        {
            "date": "2012-01-13T20:34:55+0000",
            "content": "I had a heck of a time handling all the weird stuff that could appear inside script tags, for example, and I don't think I see much of a test for that (again... my fault.)\n\nI added tests with the following snippets:\n\n\none<script><!-- <!--#config comment=\"<!-- \\\"comment\\\"-->\"--> --></script>two\n\n=> 'one\ntwo'\n\n\n\none<script attr= bare><!-- action('<!-- comment -->', \"\\\"-->\\\"\"); --></script>two\n\n=> 'one\ntwo'\n\n\n\nhello<script><!-- f('<!--internal--></script>'); --></script>\n\n=> 'hello\n'\n\n\n\nOne can be sure that the current implementation doesn't always do the right thing, but unfortunately \"right\" isn't well defined here considering the domain.\n\nI agree - the \"right\" thing IMHO is: get as much content from as varied a range of sources as possible, and never ever allow the input to bork processing.\n\nThe cost to keeping around the current version for a little while seems minimal.\n\nMy proposal would do this, though under a different name, and requiring a luceneMatchVersion of 3.5 or earlier for the factory to use it.  Do you object to this?  \n\nI have two issues with not switching over now:\n\n\n\tIt's a chicken and egg problem: how will people know if there is a problem with the new implementation if they don't use it?\n\tThe current version has several long standing bugs that nobody has fixed.  I personally wouldn't attempt it with the current implementation: it's difficult to understand.  This is one of my main motivations for making this new version: when people find issues, fixing them should be much easier with the new implementation.\n\n ",
            "author": "Steve Rowe",
            "id": "comment-13185831"
        },
        {
            "date": "2012-01-13T21:10:00+0000",
            "content": "From #lucene-dev IRC:\n\n\nyonik_:\tsarowe: if we change the name of the current html strip stuff, it seems like doing anything with luceneMatchVersion isn't needed (or overkill?)\n\nsarowe:\tbut then people will need to take action to use the (non-broken) new impl\n        me no likey\n\nyonik_:\tbut if the name is changed, they won't use it by accident\n\nsarowe:\toh, you mean: don't even attempt back-compat - just provide the ability to use the previous implementation\n\nyonik_:\tyeah\n\nsarowe:\tvia a new/different name\n        I'm definitely okay with that ",
            "author": "Steve Rowe",
            "id": "comment-13185855"
        },
        {
            "date": "2012-01-13T22:09:08+0000",
            "content": "In fact ill go remove my @Ignore now. Lets see if anyone can fix the bugs in it. That should settle this.\n\nI see you've done this.  Purposely breaking the build really isn't necessary to make a point about a known bug. ",
            "author": "Yonik Seeley",
            "id": "comment-13185904"
        },
        {
            "date": "2012-01-13T22:22:04+0000",
            "content": "sarowe: oh, you mean: don't even attempt back-compat - just provide the ability to use the previous implementation\n\nright, this is what we did with DateField a while back, note the CHANGES.txt entry on r658003.  now that we have luceneMatchVersion though i kind of go back and forth on when to use it to pick an impl vs when to do stuff like this. dealers choice...\n\nhttps://svn.apache.org/viewvc?view=revision&revision=658003 ",
            "author": "Hoss Man",
            "id": "comment-13185917"
        },
        {
            "date": "2012-01-14T00:04:51+0000",
            "content": "some test docs using malformed markup that require backtracking\n\nI set up a quick test for this in both of the test classes using output from the synthetic broken HTML generator o.a.l.util._TestUtil.randomHtmlishString() and ran 100K iterations of it - here's the HTMLStripCharFilterTest version:\n\n\n  public void testRandomBrokenHTML() throws Exception {\n    int maxNumElements = 10000;\n    String text = _TestUtil.randomHtmlishString(random, maxNumElements);\n    Reader reader\n        = new HTMLStripCharFilter(CharReader.get(new StringReader(text)));\n    while (reader.read() != -1);\n  }\n\n\n\nBest/worst of 5 (as reported by Ant for the individual test, rather than for the entire Ant invocation):\n\n\n\tHTMLStripCharFilter: best: 73.4 sec, worst: 76.5 sec\n\tJFlexHTMLStripCharFilter: best: 73.5 sec, worst: 76.0 sec\n\n\n\nI'm going to increase the evilness of _TestUtil.randomHtmlishString() and re-run to see if the numbers shift. ",
            "author": "Steve Rowe",
            "id": "comment-13186005"
        },
        {
            "date": "2012-01-14T07:10:31+0000",
            "content": "I'm going to increase the evilness of _TestUtil.randomHtmlishString() and re-run to see if the numbers shift.\n\nI did this, and it uncovered a bug in handling of Server Side Includes in JFlexHTMLStripCharFilter - hooray for evil tests.\n\nThe timings, this time for 10K iterations:\n\n\n\tHTMLStripCharFilter: best: 48.6 sec, worst: 49.7 sec\n\tJFlexHTMLStripCharFilter: best: 15.5 sec, worst: 17.3 sec\n\n ",
            "author": "Steve Rowe",
            "id": "comment-13186123"
        },
        {
            "date": "2012-01-14T07:24:42+0000",
            "content": "some test docs that contain almost no HTML at all\n\nI used the following to test the zero-markup case in both test classes (the JFlexHTMLStripCharFilter version is given below):\n\n\n  public void testRandomText() throws Exception {\n    StringBuilder text = new StringBuilder();\n    int minNumWords = 10;\n    int maxNumWords = 10000;\n    int minWordLength = 3;\n    int maxWordLength = 20;\n    int numWords = _TestUtil.nextInt(random, minNumWords, maxNumWords);\n    switch (_TestUtil.nextInt(random, 0, 4)) {\n      case 0: {\n        for (int wordNum = 0 ; wordNum < numWords ; ++wordNum) {\n          text.append(_TestUtil.randomUnicodeString(random, maxWordLength));\n          text.append(' ');\n        }\n        break;\n      }\n      case 1: {\n        for (int wordNum = 0 ; wordNum < numWords ; ++wordNum) {\n          text.append(_TestUtil.randomRealisticUnicodeString\n              (random, minWordLength, maxWordLength));\n          text.append(' ');\n        }\n        break;\n      }\n      default: { // ASCII 50% of the time\n        for (int wordNum = 0 ; wordNum < numWords ; ++wordNum) {\n          text.append(_TestUtil.randomSimpleString(random));\n          text.append(' ');\n        }\n      }\n    }\n    Reader reader = new JFlexHTMLStripCharFilter\n        (CharReader.get(new StringReader(text.toString())));\n    while (reader.read() != -1);\n  }\n\n\n\nThe results for 10K iterations (best/worst of 5):\n\n\n\tHTMLStripCharFilter: best: 23.7 sec, worst: 24.8 sec\n\tJFlexHTMLStripCharFilter: best: 22.0 sec, worst: 24.7 sec\n\n\n ",
            "author": "Steve Rowe",
            "id": "comment-13186127"
        },
        {
            "date": "2012-01-16T09:45:45+0000",
            "content": "some test docs using typical wellformed html markup\n\nI have access to ClueWeb09.  For performance testing I used the first WARC file for the English and Chinese languages (en0000/00.warc.gz and zh0000/00.warc.gz), each of which when uncompressed contains about 1GB of text (including a small amount of non-HTML metadata: WARC information and HTTP headers).  The English WARC contains about 35,000 documents from about 2,100 unique domains.  The Chinese WARC contains about 33,000 documents from about 550 unique domains.\n\nI compared JFlexHTMLStripCharFilter's output with that of HTMLStripCharFilter for several hundred documents.  In the course of this comparison, I found several problems with the JFlex implementation (e.g. no <STYLE> tag handling; no MS conditional tag handling, e.g. <![if ! IE]>; and some problems handling creative attribute values), which the attached patch fixes.  I re-ran the text-only and malformed HTML performance tests on the final implementation, and the numbers aren't significantly different from those prior to these fixes.  The new patch also contains the more-evil _TestUtils.randomHtmlishString();  shifts the CharFilter javadocs from BaseCharFilter.addOffCorrectMapping() to package.html; and adds several more tests to JFlexHTMLStripCharFilterTest.java.\n\nI have attached the three classes I used to test performance over the ClueWeb09 subset.  BaselineWarcTest.java uses the WarcRecord class supplied with the ClueWeb09 collection to read the compressed WARC files; looks for a declared charset first in each document's content in the Content-Type <meta> tag, and then in the HTTP header; feeds this charset, if any, to the ICU4J charset detector, which instantiates a Reader using the detected charset; and then read()'s all content.  The other two classes add the respective CharFilter on top of BaselineWarcTest's functionality.\n\nThe performance numbers (best of 5 trials):\n\n\n\n\nLanguage\nBaseline\nClassic\nJFlex\n\n\nEnglish\n156s\n179s\n171s\n\n\nChinese\n155s\n180s\n172s\n\n\n\n\n\nExcluding charset detection and I/O (measured by BaselineWarcTest), JFlexHTMLStripCharFilter appears to improve on HTMLStripCharFilter's throughput by about 50% in both languages.\n\nI found a few problems with HTMLStripCharFilter:\n\n\n\tThe following exception was thrown for six of the English documents:\n\njava.io.IOException: Mark invalid\n        at java.io.BufferedReader.reset(BufferedReader.java:485)\n        at org.apache.lucene.analysis.CharReader.reset(CharReader.java:69)\n        at org.apache.lucene.analysis.charfilter.HTMLStripCharFilter.restoreState(HTMLStripCharFilter.java:171)\n        at org.apache.lucene.analysis.charfilter.HTMLStripCharFilter.read(HTMLStripCharFilter.java:734)\n        at HTMLStripCharFilterWarcTest.main(HTMLStripCharFilterWarcTest.java:86)\n\n\n\t&apos; is not decoded.\n\tContent between some <script> tags is not stripped out.\n\tUnbalanced quotation marks in opening tags cause the tag to not be stripped out.\n\n\n\nLeft to do:\n\n\n\tRename HTMLStripCharFilter to ClassicHTMLStripCharFilter; move it to Solr o.a.s.analysis package; deprecate it; and create a new Solr Factory for it.\n\tRename JFlexHTMLStripCharFilter to HTMLStripCharFilter.\n\tCommit to trunk\n\tBackport and commit to branch_3x.\n\n ",
            "author": "Steve Rowe",
            "id": "comment-13186818"
        },
        {
            "date": "2012-01-16T23:27:15+0000",
            "content": "+1 ... to everything. ",
            "author": "Hoss Man",
            "id": "comment-13187301"
        },
        {
            "date": "2012-01-22T02:56:06+0000",
            "content": "AFAICT, SOLR-2891 will be fixed by this implementation.\n\nI misspoke, having misread that issue - despite the reference to HTMLStripCharFilter in the most recent comment on the issue, SOLR-2891 is not about HTMLStripCharFilter. ",
            "author": "Steve Rowe",
            "id": "comment-13190588"
        },
        {
            "date": "2012-01-22T05:17:32+0000",
            "content": "Here is the final patch.\n\n\nsarowe: oh, you mean: don't even attempt back-compat - just provide the ability to use the previous implementation\n\nright, this is what we did with DateField a while back, note the CHANGES.txt entry on r658003. now that we have luceneMatchVersion though i kind of go back and forth on when to use it to pick an impl vs when to do stuff like this. dealers choice...\n\nhttps://svn.apache.org/viewvc?view=revision&revision=658003\n\nI took the same approach - here are the changes from the previous version of the patch:\n\n\n\tThe previous HTMLStripCharFilter implementation is moved to Solr, renamed to LegacyHTMLStripCharFilter, and deprecated, and a Factory is added for it.\n\tJFlexHTMLStripCharFilter is renamed to HTMLStripCharFilter.\n\tSupport for HTMLStripCharFilter's \"escapedTags\" functionality is added to HTMLStripCharFilterFactory.\n\tAdded TestHTMLStripCharFilterFactory.\n\tSolr and Lucene CHANGES.txt entries are added.\n\n\n\nRun the following svn copy script before applying the patch:\n\n\nsvn cp modules/analysis/common/src/java/org/apache/lucene/analysis/charfilter/HTMLStripCharFilter.java solr/core/src/java/org/apache/solr/analysis/LegacyHTMLStripCharFilter.java\nsvn cp modules/analysis/common/src/test/org/apache/lucene/analysis/charfilter/htmlStripReaderTest.html solr/core/src/test/org/apache/solr/analysis/\nsvn cp modules/analysis/common/src/test/org/apache/lucene/analysis/charfilter/HTMLStripCharFilterTest.java solr/core/src/test/org/apache/solr/analysis/LegacyHTMLStripCharFilterTest.java\nsvn cp solr/core/src/java/org/apache/solr/analysis/HTMLStripCharFilterFactory.java solr/core/src/java/org/apache/solr/analysis/LegacyHTMLStripCharFilterFactory.java\n\n\n\nI plan to commit to trunk shortly, then backport and commit to branch_3x. ",
            "author": "Steve Rowe",
            "id": "comment-13190609"
        },
        {
            "date": "2012-01-22T15:57:40+0000",
            "content": "Here's a standalone testcase for the fail from jenkins ",
            "author": "Robert Muir",
            "id": "comment-13190701"
        },
        {
            "date": "2012-01-22T16:11:18+0000",
            "content": "By the way: \"expected\" in that test is wrong. its just the same input string to trigger the assert in MockTokenizer... ",
            "author": "Robert Muir",
            "id": "comment-13190704"
        },
        {
            "date": "2012-01-23T07:30:12+0000",
            "content": "Patch (excluding the re-generated .java scanner) that addresses the unpaired surrogate numeric character entity failures uncovered by random testing, by outputting REPLACEMENT CHARACTER U+FFFD, and adds the ability to interpret properly paired UTF-16 surrogates as an above-BMP codepoint.  Added tests to cover all four combinations of hex & decimal surrogate numeric character entities in surrogate pairs.\n\nAlso added @SuppressWarnings(\"fallthrough\") to the JFlex-generated scanner class, so that the 40+ warnings about switch case fall-throughs don't clutter the output.\n\nEdit: committing to trunk shortly. ",
            "author": "Steve Rowe",
            "id": "comment-13190908"
        },
        {
            "date": "2012-01-23T07:43:55+0000",
            "content": "Committed the fixed UTF-16 numeric character reference surrogates handling to trunk in r1234687. ",
            "author": "Steve Rowe",
            "id": "comment-13190911"
        },
        {
            "date": "2012-01-23T07:46:21+0000",
            "content": "Thanks Robert for your help diagnosing and fixing the surrogates problem! ",
            "author": "Steve Rowe",
            "id": "comment-13190913"
        },
        {
            "date": "2012-01-24T15:53:46+0000",
            "content": "Backported to branch_3x. ",
            "author": "Steve Rowe",
            "id": "comment-13192223"
        }
    ]
}