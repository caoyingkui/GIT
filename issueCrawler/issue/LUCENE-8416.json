{
    "id": "LUCENE-8416",
    "title": "Add tokenized version of o.o. to Stempel stopwords",
    "details": {
        "components": [
            "modules/analysis"
        ],
        "status": "Open",
        "resolution": "Unresolved",
        "fix_versions": [],
        "affect_versions": "None",
        "labels": "",
        "priority": "Trivial",
        "type": "Improvement"
    },
    "description": "The Stempel stopword list ( lucene-solr/lucene/analysis/stempel/src/resources/org/apache/lucene/analysis/pl/stopwords.txt\u00a0) contains \"o.o.\" which is a good stopword (it's part of the abbreviation for \"limited liability company\", which is \"sp. z o.o.\". However, the standard tokenizer changes \"o.o.\" to \"o.o\" so the stopword filter has no effect.\n\nAdd \"o.o\" to the stopword list. (It's probably okay to leave \"o.o.\" in the list, though, in case a different tokenizer is used.)",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "id": "comment-16611862",
            "author": "Peter Cseh",
            "content": "I've created a PR for this. I could not find any tests that should be changed after this. ",
            "date": "2018-09-12T09:59:03+0000"
        }
    ]
}