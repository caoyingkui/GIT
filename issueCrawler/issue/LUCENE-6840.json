{
    "id": "LUCENE-6840",
    "title": "Put ord indexes of doc values on disk",
    "details": {
        "resolution": "Fixed",
        "affect_versions": "None",
        "components": [],
        "labels": "",
        "fix_versions": [
            "5.4",
            "6.0"
        ],
        "priority": "Minor",
        "status": "Closed",
        "type": "Improvement"
    },
    "description": "Currently we still load monotonic blocks into memory to map doc ids to an offset on disk. Since these data structures are usually consumed sequentially I would like to investigate putting them to disk.",
    "attachments": {
        "LUCENE-6840.patch": "https://issues.apache.org/jira/secure/attachment/12766799/LUCENE-6840.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "id": "comment-14958946",
            "author": "Adrien Grand",
            "date": "2015-10-15T13:59:15+0000",
            "content": "Here is a patch that should improve memory usage for:\n\n\tvariable-length binary fields\n\tmulti-valued sorted numeric fields\n\tmulti-valued sorted set fields\n\n\n\nOn the other hand, the BINARY_PREFIX_COMPRESSED format still uses MononicBlockPackedReader/Writer.\n\nI wrote the patch by changing Lucene50DocValuesFormat to make it easier to review, but when it's ready I plan to make it a whole new format (with new Lucene54Codec, etc.).\n\nCompared to previously, only per-block metadata is kept around in memory, data is written to disk using the DirectWriter/slice APIs. Out of curiosity I tried to write all entries of my /usr/share/dict/words file into a binary dv field to see how it compares to trunk:\n\n\ntrunk\n  .dvd: 992334 bytes\n  .dvm 128 bytes\n  memory usage 153124 bytes\npatch\n  .dvd 1038100 bytes\n  .dvm 165 bytes\n  memory usage 232 bytes\n\n\n\nOne important thing is that I had to introduce some per-thread memory usage: each thread needs to have its own array of DirectReader instances (one per block). This is why I raised the block size from 16K to 64K in order to have fewer blocks. Maybe this would need to be even more increased (but this would also hurt compression a bit). In the worst case that someone has a segment with 2B documents, there would be 32k blocks of 64k values so each thread would need about 1.2MB of memory. In my opinion it's ok since apps should query their Lucene indices from a reasonable number of threads, and it would probably still be much better than today since even requiring a single bit of memory per document (with today's MonotonicBlockPackedReader) would use 256MB of memory. "
        },
        {
            "id": "comment-14960514",
            "author": "Adrien Grand",
            "date": "2015-10-16T11:04:22+0000",
            "content": "I did a quick benchmark with the geonames dataset (10740477 documents), with only two doc values fields:\n\n\tname as a binary dv field\n\talternatenames as a sorted set dv field\n\n\n\nThen I measured disk/memory usage and tried to sort on both fields (using SortedSetSelector.Type.MIN for the multi-valued field) with a MatchAllDocsQuery:\n\n\n\n\nbranch\nindex size(MB)\nmemory usage(MB)\ntime to sort on \"name\" (ms)\ntime to sort on \"alternatenames\" (ms)\n\n\ntrunk\n311\n33.1\n4750\n3570\n\n\npatch\n319 (+2%)\n1.4 (-96%)\n5390 (+13%)\n4000 (+12%)\n\n\n\n\n\nMaybe there are things we can optimize with the patch, but even with these numbers I think this patch has a better trade-off: I am not very happy that the current format takes more than 3 bytes of memory per document for only two doc values fields. "
        },
        {
            "id": "comment-14963261",
            "author": "Adrien Grand",
            "date": "2015-10-19T12:57:11+0000",
            "content": "Here is a new patch that folds the ability to read after a given offset into DirectReader directly, so that we don't have to introduce a new implementation of RandomAccessInput, which seemed to confuse hotspot a bit.\n\n\n\n\nbranch\nindex size(MB)\nmemory usage(MB)\ntime to sort on \"name\" (ms)\ntime to sort on \"alternatenames\" (ms)\n\n\ntrunk\n311\n33.1\n4780\n3580\n\n\npatch\n319 (+2%)\n1.4 (-96%)\n4960 (+4%)\n3790 (+6%)\n\n\n\n "
        },
        {
            "id": "comment-14976799",
            "author": "Adrien Grand",
            "date": "2015-10-27T17:32:02+0000",
            "content": "Here is a patch that makes this a new DocValuesFormat, with a new associated Codec and moves Lucene53Codec and Lucene50DocValuesFormat to lucene/backward-codecs. I would like to commit soon if there are no objections. "
        },
        {
            "id": "comment-14976919",
            "author": "Robert Muir",
            "date": "2015-10-27T18:33:47+0000",
            "content": "Can we add back a helper like this to DirectReader? I think it helps the api for the general case, where an offset from a slice is kinda silly (but i get where it helps for this case).\n\n\npublic static LongValues getInstance(RandomAccessInput slice, int bitsPerValue) {\n  return getInstance(slice, bitsPerValue, 0);\n}\n\n\n\nthanks for adding the offset tests to directreader tests.\n\nShould we move LongValues.EMPTY to DirectMonotonicReader since its the only one using it right now?\n "
        },
        {
            "id": "comment-14976967",
            "author": "Adrien Grand",
            "date": "2015-10-27T18:58:23+0000",
            "content": "Here is an updated patch that should address your comments. Thank you for the review, I'll commit soon. "
        },
        {
            "id": "comment-14977041",
            "author": "ASF subversion and git services",
            "date": "2015-10-27T19:49:48+0000",
            "content": "Commit 1710876 from Adrien Grand in branch 'dev/trunk'\n[ https://svn.apache.org/r1710876 ]\n\nLUCENE-6840: Put ord indexes on disk. "
        },
        {
            "id": "comment-14977107",
            "author": "ASF subversion and git services",
            "date": "2015-10-27T20:32:29+0000",
            "content": "Commit 1710880 from Adrien Grand in branch 'dev/branches/branch_5x'\n[ https://svn.apache.org/r1710880 ]\n\nLUCENE-6840: Put ord indexes on disk. "
        }
    ]
}