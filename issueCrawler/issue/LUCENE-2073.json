{
    "id": "LUCENE-2073",
    "title": "Document issues involved in building your index with one jdk version and then searching/updating with another",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [
            "core/index"
        ],
        "type": "Task",
        "fix_versions": [
            "4.9",
            "6.0"
        ],
        "affect_versions": "None",
        "resolution": "Unresolved",
        "status": "Open"
    },
    "description": "I think this needs to go in something of a permenant spot - this isn't a one time release type issues - its going to present over multiple release.\n\n\nIf there is nothing we can do here, then we just have to do the best we can -\nsuch as a prominent notice alerting that if you transition JVM's between building and searching the index and you are using or doing X, things will break.\n\nWe should put this in a spot that is always pretty visible - perhaps even a new readme file titlted something like IndexBackwardCompatibility or something, to which we can add other tips and gotchyas as they come up. Or MaintainingIndicesAcrossVersions, or FancyWhateverGetsYourAttentionAboutUpgradingStuff. Or a permanent entry/sticky entry at the top of Changes.",
    "attachments": {
        "stdAnalyzerTest.java": "https://issues.apache.org/jira/secure/attachment/12425246/stdAnalyzerTest.java",
        "LUCENE-2073.patch": "https://issues.apache.org/jira/secure/attachment/12425228/LUCENE-2073.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2009-11-16T21:16:42+0000",
            "content": "Mark, I agree, there are two issues I know of:\n\n\n\tusing a new java version can change unicode version, which changes character properties, which makes things tokenize differently.\n\tusing a different default locale can change at least some things in contrib, for example PatternAnalyzer uses a Locale-based toLowerCase() method, which will break if default locale is different between index and search.\n\n\n\n... <other things you can think of> ",
            "author": "Robert Muir",
            "id": "comment-12778547"
        },
        {
            "date": "2009-11-17T10:44:56+0000",
            "content": "How about adding a general note into some JRE_VERSION_MIGRATION.txt on each release, also add this to the non-version specific site docs?\nThe first version that would contain it in the distribution would be 3.0, but it should be noted on the site-docs, that this affects all versions. Something like \"whenever you change JRE major versions 1.4 -> 1.5 -> 1.6 -> 1.7 you may have to reindex, because the underlying VM's Unicode version could have changed in a way, affecting your tokenizers.\" ",
            "author": "Uwe Schindler",
            "id": "comment-12778815"
        },
        {
            "date": "2009-11-17T13:22:42+0000",
            "content": "Sounds good to me. ",
            "author": "Mark Miller",
            "id": "comment-12778862"
        },
        {
            "date": "2009-11-17T13:43:15+0000",
            "content": "Which components are affected by this?  I think just Analyzers and query\nparsers, yes?\n\nIf that's true, my inclination would be to add a note to the javadocs for each\nsuch class. In every case, it's theoretically possible to build alternative\nimplementations which are unaffected by upgrading the JVM.  \n\nThis isn't a fundamental problem with the Lucene architecture; it's an\nartifact of the way certain classes are implemented.  Outside of the affected\ncomponents, Lucene doesn't get down and dirty with Unicode properties and\nother fast-moving stuff \u2013 it's just dealing in UTF-8 bytes, Java strings,\netc.  Those things can change (Modified UTF-8, shudder), but they move on a\nslower timescale.\n\nArguably, Analyzer subclasses shouldn't be in core for reasons like this.\nPerhaps there could be an \"ICUAnalysis\" package which depends on ICU4J, so\nthat Unicode-related index incompatibilites occur when you upgrade your\nUnicode library.  Though most people would probably choose to use the\nsmaller-footprint, zero-dependency \"JVMAnalysis\" package, where reindexing\nwould be required after a JVM upgrade.\n\nThe software certifiers wouldn't like that, and I'm not seriously advocating\nsuch a disruptive change (yet), but I just wanted to illustrate that this is a\ncontained problem.\n ",
            "author": "Marvin Humphrey",
            "id": "comment-12778875"
        },
        {
            "date": "2009-11-17T13:49:17+0000",
            "content": " If that's true, my inclination would be to add a note to the javadocs for each\nsuch class. In every case, it's theoretically possible to build alternative\nimplementations which are unaffected by upgrading the JVM. \n\nI think thats a good idea, but I'd still like the top level warning as well - I think it should be specific in explaining the problem, and not claim that it exists for everything - Robert has already laid out a couple specific examples we can mention. The problem with the javadoc approach only is that its very easy to miss - I think its a good place to lay out the details for that particular class - but it would still be great to have a visible top level warning so that users know to be careful of this. ",
            "author": "Mark Miller",
            "id": "comment-12778880"
        },
        {
            "date": "2009-11-17T13:51:35+0000",
            "content": "Which components are affected by this? I think just Analyzers and query parsers, yes? \n\nI think just tokenstreams / analyzers.\n\nThis isn't a fundamental problem with the Lucene architecture; it's an artifact of the way certain classes are implemented.\n\nyes, you are exactly right. StandardTokenizer does not have this problem. its behavior is independent of the users JVM, although dependent on the JVM of the developer who last re-ran jflex \n\nPerhaps there could be an \"ICUAnalysis\" package which depends on ICU4J\n\nyeah, this is what I think most of us who need unicode support do anyway. so i tried to start a good impl of this in LUCENE-1488.\neven if you do not care about unicode support, maybe you care that things like .isWhiteSpace() are faster than in the jdk:\nhttp://site.icu-project.org/home/why-use-icu4j (see under Performance section).\n ",
            "author": "Robert Muir",
            "id": "comment-12778882"
        },
        {
            "date": "2009-11-17T14:05:02+0000",
            "content": "Hello, whereever we put this text (i do not care), I thought the following would be a start.\n\nplease help me make it easier to digest/understand\n\n\nIf possible, use the same major JVM version at both index and search time.\nDifferent JVM versions may implement different versions of the Unicode Standard, which will change the way Lucene treats your text.\nFor example, under Java 1.4, LetterTokenizer will split around the character U+02C6, but under Java 5 it will not.\nThis is because Java 1.4 implements Unicode 3, but Java 5 implements Unicode 4.\n\n ",
            "author": "Robert Muir",
            "id": "comment-12778886"
        },
        {
            "date": "2009-11-17T14:12:40+0000",
            "content": "I guess that warning still isnt good enough. if you bump jvm version you should reindex older data too, and not just add new documents to it... ",
            "author": "Robert Muir",
            "id": "comment-12778890"
        },
        {
            "date": "2009-11-17T15:47:50+0000",
            "content": "i tried to improve the wording a bit. ",
            "author": "Robert Muir",
            "id": "comment-12778948"
        },
        {
            "date": "2009-11-17T16:02:55+0000",
            "content": "ok, i think this one is better.\nFor convenience, I list which JRE versions correspond to which unicode versions.\n\nBecause I think that for example, if someone goes from Java 5 to Java 6, they should not worry about this. ",
            "author": "Robert Muir",
            "id": "comment-12778955"
        },
        {
            "date": "2009-11-17T17:25:05+0000",
            "content": "I like this:\n\n> some parts of Lucene\n\n... but I still think the message is a little too aggressive.  There are a lot\nof people just using ye olde StandardAnalyzer, and they don't need to reindex.\nWe don't need to spread our own FUD. \n\nCan we change it to say \"Analyzers\", and then refer people to the docs for\ntheir specific Analyzer?  Alternatively, should that notification just contain\na complete list of the affected classes? ",
            "author": "Marvin Humphrey",
            "id": "comment-12778998"
        },
        {
            "date": "2009-11-17T17:29:00+0000",
            "content": "Hi Marvin, thanks for reviewing it.\n\n\n... but I still think the message is a little too aggressive. There are a lot\nof people just using ye olde StandardAnalyzer, and they don't need to reindex.\nWe don't need to spread our own FUD. \n\nare you sure? StandardAnalyzer uses LowerCaseFilter, i did not check to see if any casing properties have changed.\n\n\nCan we change it to say \"Analyzers\", and then refer people to the docs for\ntheir specific Analyzer? Alternatively, should that notification just contain\na complete list of the affected classes?\nBasically I am trying to be ambiguous, because I'm not sure what all is affected without doing some significant analysis!\nI will do this, if its the right thing though. ",
            "author": "Robert Muir",
            "id": "comment-12778999"
        },
        {
            "date": "2009-11-17T17:29:05+0000",
            "content": "Agreed - we don't want to cause those that don't need to to reindex just to try and be safe. ",
            "author": "Mark Miller",
            "id": "comment-12779000"
        },
        {
            "date": "2009-11-17T17:36:02+0000",
            "content": "Mark, but here is the crux of the issue:\n\nWhile i think casing property is normative and should not change, new characters can be introduced with new casing properties.\nThis of course should not affect Simple/StopAnalyzer, but may affect StandardAnalyzer.\n\nThe reason is that StandardTokenizer contains hardcoded (sometimes oversized) ranges that may include some characters that were previously unassigned in Unicode 3.\nIf they are assigned in Unicode 4, with a casing property, then this means for lucene, they were indexed in uppercase in 1.4 but lowercase in 1.5... i hope this makes sense. ",
            "author": "Robert Muir",
            "id": "comment-12779004"
        },
        {
            "date": "2009-11-17T17:41:26+0000",
            "content": "> are you sure? StandardAnalyzer uses LowerCaseFilter,\n\nNo, I'm not sure.    I was confusing StandardAnalyzer and StandardTokenizer.\n\nI still think that there are a lot of people who don't need to reindex,\nbecause, for example, their entire corpus is limited to Latin-1 code points. \n\nConversely, the people most likely to be affected are the people most likely\nto be on the lookout for this kind of think.  I think it's important to\nreach this group, without unduly alarming those who don't really need to\nreindex.  Reindexing is a huge pain for some installations. ",
            "author": "Marvin Humphrey",
            "id": "comment-12779006"
        },
        {
            "date": "2009-11-17T17:45:43+0000",
            "content": "Okay, fair enough - in the end I do think we want to err on the side of caution - losing terms/docs in the index can be disastrous for some. Can we contain the statement at all though? What if you are just working with essentially ascii text? Basic English chars? That type of thing ... perhaps saying something to the effect of, in many/some cases, a user might not be affected, but if you need to be sure, you must reindex? ",
            "author": "Mark Miller",
            "id": "comment-12779010"
        },
        {
            "date": "2009-11-17T17:47:37+0000",
            "content": "I am pretty sure StandardAnalyzer is ok actually now.\nThe only time it uses hardcoded ranges is for the CJK definition:\nand the following UnicodeSet is the empty set (0 codepoints):\n\n\n[[\\u3100-\\u312f\\u3040-\\u309F\\u30A0-\\u30FF\\u31F0-\\u31FF\\u3300-\\u337f\\u3400-\\u4dbf\\u4e00-\\u9fff\\uf900-\\ufaff\\uff65-\\uff9f]&[:Case_Sensitive=True:]]\n\n\n\nWikipediaTokenizer, probably not ok  ",
            "author": "Robert Muir",
            "id": "comment-12779011"
        },
        {
            "date": "2009-11-17T17:52:05+0000",
            "content": "Mark good point, if you are using \"Basic Latin\" as exists on your keyboard, you might be ok.\n\nOf course, one never knows, I feel like i remember Microsoft Word creating strange hyphens and smart quotes automatically... \n\nI'd love to contain it, if you have some suggested verbage lets put it in there. ",
            "author": "Robert Muir",
            "id": "comment-12779012"
        },
        {
            "date": "2009-11-17T17:54:24+0000",
            "content": "> I am pretty sure StandardAnalyzer is ok actually now.\n\nGood news!  Thanks for performing that analysis. ",
            "author": "Marvin Humphrey",
            "id": "comment-12779015"
        },
        {
            "date": "2009-11-17T18:01:05+0000",
            "content": "if you are using \"Basic Latin\" as exists on your keyboard, you might be ok.\n\nHeh - well if thats the strongest you would say that, sounds like its not very containable. Perhaps we just put that?\n\n\nedit\n\nYes, word def uses a couple funky things by default with hyphens and quotes - ran into that before. But I think its somewhat up to you to know that. If you are getting your text from another application, than you don't likely properly know you have latin1 stuff. But some people will know - in the newspaper biz, we use pre processing filters to map anything outside of latin1 to latin1 - else remove it. If you don't know your source text well enough, then yes, all bets are off. ",
            "author": "Mark Miller",
            "id": "comment-12779018"
        },
        {
            "date": "2009-11-17T18:04:27+0000",
            "content": "\n> I am pretty sure StandardAnalyzer is ok actually now.\n\nGood news! Thanks for performing that analysis.\n\nDoh! this case pair stability policy was not introduced until 5.0, so to validate, i must do further analysis\nref: \"unicode back compat policy\": http://www.unicode.org/policies/stability_policy.html ",
            "author": "Robert Muir",
            "id": "comment-12779020"
        },
        {
            "date": "2009-11-17T18:05:45+0000",
            "content": "Of course, one never knows, I feel like i remember Microsoft Word creating strange hyphens and smart quotes automatically... \n\nIt is the same strange soft hyphen we talked about before... Normally you should simply remove it during indexing using a CharFilter (I do this when indexing word documents and so on). ",
            "author": "Uwe Schindler",
            "id": "comment-12779023"
        },
        {
            "date": "2009-11-17T18:30:02+0000",
            "content": "Hi, I completely validated. StandardAnalyzer is ok. none of the casing changed for any previous [:letter:] characters from Unicode 3 in Unicode 4.\n\nI'll work on adding more explanation\n ",
            "author": "Robert Muir",
            "id": "comment-12779030"
        },
        {
            "date": "2009-11-17T18:41:40+0000",
            "content": "very happy to add new verbage here mentioning that StandardAnalyzer is ok. ",
            "author": "Robert Muir",
            "id": "comment-12779035"
        },
        {
            "date": "2009-11-17T18:48:10+0000",
            "content": "the crappy test script i wrote to confirm the lowercasing behavior.\nmaybe we need it again if we go to java 1.7 in this decade, or maybe i screwed something up  ",
            "author": "Robert Muir",
            "id": "comment-12779038"
        },
        {
            "date": "2009-11-17T18:55:28+0000",
            "content": "Text looks good, maybe we should still add the \"basic latin as on your keyboard\". ",
            "author": "Uwe Schindler",
            "id": "comment-12779043"
        },
        {
            "date": "2009-11-17T19:03:53+0000",
            "content": "Uwe, ok, I am currently trying to come up with a way to word this.\n\nUnknowns like the soft hyphen thing and other things word processors, etc might do make me really cautious to say something like this...\nI don't want someone to unnecessarily reindex, but on the other hand, I don't want to see bug report or whatever either. ",
            "author": "Robert Muir",
            "id": "comment-12779049"
        },
        {
            "date": "2009-11-17T19:14:37+0000",
            "content": "i added the following:\n\nIn general, whether or not you need to re-index largely depends upon the data that\nyou are searching, and what was changed in any given Unicode version. For example,\nif you are completely sure that your content is limited to the \"Basic Latin\" range\nof Unicode, you can safely ignore this. ",
            "author": "Robert Muir",
            "id": "comment-12779056"
        },
        {
            "date": "2009-11-17T19:38:48+0000",
            "content": "guys I would like to commit this file soon, let me know if you see any issues with it.\n\nI think this additional verbage i added about \"basic latin\" is safe, the only properties that have changed even up to unicode 5.1 are minor changes to bidirectional properties.\nThis only affects rendering/layout. ",
            "author": "Robert Muir",
            "id": "comment-12779078"
        },
        {
            "date": "2009-11-17T19:52:45+0000",
            "content": "+1, ok ",
            "author": "Uwe Schindler",
            "id": "comment-12779083"
        },
        {
            "date": "2009-11-17T19:56:40+0000",
            "content": "Looks great! +1 ",
            "author": "Mark Miller",
            "id": "comment-12779086"
        },
        {
            "date": "2009-11-17T20:09:09+0000",
            "content": "Committed revision 881466.\n\nshould we keep the issue open Mark, or close it?\nI think we will potentially have some specialized problems in 3.1 also... (due to fixing unicode 4/suppl characters) ",
            "author": "Robert Muir",
            "id": "comment-12779094"
        },
        {
            "date": "2009-11-17T20:13:24+0000",
            "content": "Okay - popped it to 3.1 to ensure we look at this again. ",
            "author": "Mark Miller",
            "id": "comment-12779096"
        },
        {
            "date": "2009-11-17T20:17:57+0000",
            "content": "Cool, we can do something similar in 3.1 \n\nWhile it seems crazy, like these issues affect no one, someone told me today about relying upon broken unicode 4 behavior in lucene for chinese tokenization....! ",
            "author": "Robert Muir",
            "id": "comment-12779098"
        },
        {
            "date": "2012-06-08T23:49:30+0000",
            "content": "rmuir already wrote a doc on this back in 2009, not sure why it was the jira was left open.\n\nrmuir: can you resolve if you think we're good here, or update with what you think is still needed otherwise? ",
            "author": "Hoss Man",
            "id": "comment-13292101"
        },
        {
            "date": "2012-07-11T23:03:44+0000",
            "content": "bulk cleanup of 4.0-ALPHA / 4.0 Jira versioning. all bulk edited issues have hoss20120711-bulk-40-change in a comment ",
            "author": "Hoss Man",
            "id": "comment-13412294"
        },
        {
            "date": "2012-08-07T03:41:18+0000",
            "content": "rmuir20120906-bulk-40-change ",
            "author": "Robert Muir",
            "id": "comment-13429693"
        },
        {
            "date": "2013-01-15T20:11:46+0000",
            "content": "AFAICT, lucene/JRE_VERION_MIGRATION.txt doesn't need any modifications for the 4.1 release. ",
            "author": "Steve Rowe",
            "id": "comment-13554263"
        },
        {
            "date": "2013-07-23T18:44:33+0000",
            "content": "Bulk move 4.4 issues to 4.5 and 5.0 ",
            "author": "Steve Rowe",
            "id": "comment-13716987"
        },
        {
            "date": "2014-04-16T12:54:50+0000",
            "content": "Move issue to Lucene 4.9. ",
            "author": "Uwe Schindler",
            "id": "comment-13970897"
        }
    ]
}