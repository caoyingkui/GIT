{
    "id": "LUCENE-2019",
    "title": "map unicode process-internal codepoints to replacement character",
    "details": {
        "labels": "",
        "priority": "Minor",
        "components": [
            "core/index"
        ],
        "type": "Improvement",
        "fix_versions": [],
        "affect_versions": "None",
        "resolution": "Unresolved",
        "status": "Reopened"
    },
    "description": "A spinoff from LUCENE-2016.\n\nThere are several process-internal codepoints in unicode, we should not store these in the index.\nInstead they should be mapped to replacement character (U+FFFD), so they can be used process-internally.\n\nAn example of this is how Lucene Java currently uses U+FFFF process-internally, it can't be in the index or will cause problems.",
    "attachments": {
        "LUCENE-2019.patch": "https://issues.apache.org/jira/secure/attachment/12423624/LUCENE-2019.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2009-10-29T18:37:03+0000",
            "content": "easiest way to get the complete list: http://unicode.org/cldr/utility/list-unicodeset.jsp?a=%5B:Noncharacter_Code_Point=True:%5D ",
            "author": "Robert Muir",
            "id": "comment-12771541"
        },
        {
            "date": "2009-10-29T21:18:23+0000",
            "content": "I think this code won't be so intrusive or hairy.\nHere is the list in surrogate pair representation.\nNote that for the > BMP points, the trail surrogate is always U+DFFE or U+DFFF\n\nBMP points:\n\n\\uFDD0-\\uFDEF\n\\uFFFE\n\\uFFFF <-- already handled\n\n\n\n> BMP points:\n\n\\uD83F\\uDFFE\n\\uD83F\\uDFFF\n\\uD87F\\uDFFE\n\\uD87F\\uDFFF\n\\uD8BF\\uDFFE\n\\uD8BF\\uDFFF\n\\uD8FF\\uDFFE\n\\uD8FF\\uDFFF\n\\uD93F\\uDFFE\n\\uD93F\\uDFFF\n\\uD97F\\uDFFE\n\\uD97F\\uDFFF\n\\uD9BF\\uDFFE\n\\uD9BF\\uDFFF\n\\uD9FF\\uDFFE\n\\uD9FF\\uDFFF\n\\uDA3F\\uDFFE\n\\uDA3F\\uDFFF\n\\uDA7F\\uDFFE\n\\uDA7F\\uDFFF\n\\uDABF\\uDFFE\n\\uDABF\\uDFFF\n\\uDAFF\\uDFFE\n\\uDAFF\\uDFFF\n\\uDB3F\\uDFFE\n\\uDB3F\\uDFFF\n\\uDB7F\\uDFFE\n\\uDB7F\\uDFFF\n\\uDBBF\\uDFFE\n\\uDBBF\\uDFFF\n\\uDBFF\\uDFFE\n\\uDBFF\\uDFFF\n\n ",
            "author": "Robert Muir",
            "id": "comment-12771623"
        },
        {
            "date": "2009-10-29T21:35:49+0000",
            "content": "here is a prototype patch.\nbecause U+DFFE and U+DFFF are process-internal for all planes, the surrogate case is easy (just treat these process-internal points in the unpaired surrogates codepath)\n\nfor the additional bmp chars, they happen to be > UNI_SUR_HIGH_START, so again it shouldnt be in the main branch.\n\nMike, if you have a moment maybe check this out, if its ok ill fix formatting and add tests. ",
            "author": "Robert Muir",
            "id": "comment-12771633"
        },
        {
            "date": "2009-10-30T21:37:22+0000",
            "content": "The patch looks good, and is non-intrusive, but I think we need to somehow answer the larger question about whether Lucene should in fact be in the business of replacing all \"invalid for interchange\" characters.  Really it comes down to the semantics question of whether Lucene is in fact \"process internal\" to an application (or, whether we want to allow applications to treat Lucene that way). ",
            "author": "Michael McCandless",
            "id": "comment-12772104"
        },
        {
            "date": "2009-10-30T21:46:55+0000",
            "content": "Michael, well if we go by the unicode standard:\nSection 3.2\n\nC2 A process shall not interpret a noncharacter code point as an abstract character.\n\u2022 The noncharacter code points may be used internally, such as for sentinel values\nor delimiters, but should not be exchanged publicly.\n\nThis makes me think they should not be in terms, but i'll take anyone's interpretation.\nif people disagree, just cancel the issue as not fix. i don't think this approach will hurt performance. ",
            "author": "Robert Muir",
            "id": "comment-12772110"
        },
        {
            "date": "2009-10-30T22:06:08+0000",
            "content": "Lucene indexes can be used both process-internally and across processes (e.g. Solr).\n\nThis patch enforces the Lucene-index-as-process-external view, and excludes the possiblity that a Lucene index is used process-internally.\n\nSince Lucene itself uses U+FFFF internally, no clients can use it for their own purposes.  This patch rationalizes handling of internal-use-only characters, such that Lucene's behavior is made consistent for all of them.\n\nInstituting this consistency precludes Lucene-index-as-process-internal use cases.  I would argue that the price of consistency is in this case too high.\n\nMy vote: document the crap out of the U+FFFF Lucene-internal-use character and drop this patch.\n\nIf people want to use internal-use-only characters in Lucene indexes, as long as Lucene doesn't reserve them for its own use, why stop them? ",
            "author": "Steve Rowe",
            "id": "comment-12772118"
        },
        {
            "date": "2009-10-30T22:09:46+0000",
            "content": "If people want to use internal-use-only characters in Lucene indexes, as long as Lucene doesn't reserve them for its own use, why stop them?\n\n+1 ",
            "author": "Yonik Seeley",
            "id": "comment-12772120"
        },
        {
            "date": "2009-10-30T22:11:35+0000",
            "content": "Steven, the only reason I might disagree is that a Lucene Index is supposed to be portable across different languages other than Lucene Java.\n\nin my opinion, if you are to store process-internal codepoints as abstract characters in terms, then you should not claim that Lucene indexes are in any Unicode format,\nbecause then they violate the standard.\n\nBy not storing them in terms, then you are free to use them as delimiters, or other purposes. right now U+FFFF is used as a delimiter, but who knows, maybe someday you might need more? ",
            "author": "Robert Muir",
            "id": "comment-12772121"
        },
        {
            "date": "2009-10-30T22:20:50+0000",
            "content": "If someone purposefully hands lucene internal-use-only characters, doesn't that imply they are using lucene in a process-internal manner? ",
            "author": "Yonik Seeley",
            "id": "comment-12772125"
        },
        {
            "date": "2009-10-30T22:24:57+0000",
            "content": "Yonik, no. this is how i see it.\n\nprocess-internal means just that, internal to processing. \nSo if I want to use U+FDDF in some lucene process, say as a syllable delimiter or something like that, i should not have to worry about it being stored in a portable index as an abstract character (inside some term text)\n\nagain this is my interpretation, so if you guys disagree, please mark the issue as not fix, but i enjoy the discussion.\n\n<edit addition>\n\nhere is an example use case, perhaps i want to make a Query that needs to do some fuzzy matching or something crazy for a difficult language.\ni should be able to internally use any of these process-internal codepoints as delimiters in my processing (process-internal)\nwithout worrying that they will be in the Term text from TermEnum.  ",
            "author": "Robert Muir",
            "id": "comment-12772128"
        },
        {
            "date": "2009-10-30T22:32:24+0000",
            "content": "Steven, the only reason I might disagree is that a Lucene Index is supposed to be portable across different languages other than Lucene Java.\n\nRight, but not all Lucene indexes in-the-wild are accessed from more than one language.  The vast majority of Lucene index uses, I'd venture to guess, are single-language, single-process uses.\n\nin my opinion, if you are to store process-internal codepoints as abstract characters in terms, then you should not claim that Lucene indexes are in any Unicode format, because then they violate the standard.\n\nI strongly disagree with the assumption that interchange and serialization are synonymous.\n\nBy not storing them in terms, then you are free to use them as delimiters, or other purposes. right now U+FFFF is used as a delimiter, but who knows, maybe someday you might need more?\n\nI actually agree with this argument.  What if Lucene needs more process-internal characters?  I don't have any way of gauging the probability that it will in the future (other than the last eight years of history, during which only one was deemed necessary).  But what does Mike M. say? \"Design for now\" or something like that? ",
            "author": "Steve Rowe",
            "id": "comment-12772133"
        },
        {
            "date": "2009-10-30T22:35:02+0000",
            "content": "I strongly disagree with the assumption that interchange and serialization are synonymous.\n\nActually I won't argue with you too much about this. i only care about lucene-java.\n\nI actually agree with this argument. What if Lucene needs more process-internal characters? I don't have any way of gauging the probability that it will in the future (other than the last eight years of history, during which only one was deemed necessary). But what does Mike M. say? \"Design for now\" or something like that?\n\nright, the point is that in my processing as a user, i might need to have delimiters or whatever.\ni should not have to worry about lucene treating them as an abstract character because the unicode standard says it should not.\nso for example, if i create a MultiTermQuery, i should be able to use U+FFFE and U+FFFF both internally, perhaps to delimit things for different reasons, without any concern that they are stored in term text.\nby storing them in term text, by definition they are being treated as abstract character. ",
            "author": "Robert Muir",
            "id": "comment-12772135"
        },
        {
            "date": "2009-10-30T22:38:14+0000",
            "content": "Here's a process-internal use-case (as I understand the meaning):\nUser hands me two tokens. I catenate and separate them with an internal-use char, then index.\nLater, I get this term somehow from lucene, split on my internal-use char and hand back to the user.\nIf lucene converts internal-use chars, this becomes impossible.\n\nWhat's the use-case for handing lucene internal-use characters and not wanting it preserved?  Couldn't you always use your internal-use characters, and then convert or remove them before handing to lucene? ",
            "author": "Yonik Seeley",
            "id": "comment-12772138"
        },
        {
            "date": "2009-10-30T22:42:59+0000",
            "content": "Yonik, i argue in your process-internal usecase, that its in fact process-external.\n\nin this case of concatenation you should instead use a control character, or something more suitable for this purpose.\nfor example, you could use \"information separator\" controls 001C-001F, and this is especially more nice than if you were to use U+FFFE, say for this purpose.\nsome other process could recognize that you were separating information, rather than just using a noncharacter for process-internal use.\n\nprocess-internal is somethign that won't be stored or interchanged in any way (internal to the process) ",
            "author": "Robert Muir",
            "id": "comment-12772142"
        },
        {
            "date": "2009-10-30T22:46:45+0000",
            "content": "process-internal is somethign that won't be stored or interchanged in any way (internal to the process)\nAnd if I'm indexing to a RAM directory?  The point is, the private-use char is never seen external to the process (which includes both Lucene and it's index). ",
            "author": "Yonik Seeley",
            "id": "comment-12772146"
        },
        {
            "date": "2009-10-30T22:48:43+0000",
            "content": "And if I'm indexing to a RAM directory? The point is, the private-use char is never seen external to the process (which includes both Lucene and it's index).\n\nwhoah, lets not confuse private-use characters with non-characters. there is a huge difference!!!!\n\n<edit addition>\n\nI see private-use characters as available to the end user, i.e. someone like DM Smith trying to index Myanmar encoded in private-use chars (he mentioned this before).\nThese are available for his use.\n\ncontrol characters are available for your use to concatenate or do strange things.\n\nprocess-internal (non-characters) should not be stored and are available for processing, without concern that they will be treated as an abstract character. ",
            "author": "Robert Muir",
            "id": "comment-12772147"
        },
        {
            "date": "2009-10-30T22:56:53+0000",
            "content": "process-internal is somethign that won't be stored or interchanged in any way (internal to the process)\n\nRight, this is the crux of the disagreement: you think storage (with the exception of in-memory usage) means interchange.  I and Yonik think that storage does not necessarily mean interchange.\n\nSection 16.7 (Noncharacters) of the Unicode 5.0.0 standand (the latest version for which an electronic version of this chapter is available), says:\n\n\nNoncharacters are code points that are permanently reserved in the Unicode Standard for internal use. They are forbidden for use in open interchange of Unicode text data. See Section 3.4, Characters and Encoding, for the formal definition of noncharacters and conformance requirements related to their use.\n\nThe Unicode Standard sets aside 66 noncharacter code points. The last two code points of each plane are noncharacters: U+FFFE and U+FFFF on the BMP, U+1FFFE and U+1FFFF on Plane 1, and so on, up to U+10FFFE and U+10FFFF on Plane 16, for a total of 34 code points. In addition, there is a contiguous range of another 32 noncharacter code points in the BMP: U+FDD0..U+FDEF. For historical reasons, the range U+FDD0..U+FDEF is contained within the Arabic Presentation Forms-A block, but those noncharacters are not \"Arabic noncharacters\" or \"right-to-left noncharacters,\" and are not distinguished in any other way from the other noncharacters, except in their code point values.\n\nApplications are free to use any of these noncharacter code points internally but should never attempt to exchange them. If a noncharacter is received in open interchange, an application is not required to interpret it in any way. It is good practice, however, to recognize it as a noncharacter and to take appropriate action, such as removing it from the text. Note that Unicode conformance freely allows the removal of these characters. (See conformance clause C7 in Section 3.2, Conformance Requirements.)\n\nIn effect, noncharacters can be thought of as application-internal private-use code points. Unlike the private-use characters discussed in Section 16.5, Private-Use Characters, which are assigned characters and which are intended for use in open interchange, subject to interpretation by private agreement, noncharacters are permanently reserved (unassigned) and have no interpretation whatsoever outside of their possible application-internal private uses.\n\nU+FFFF and U+10FFFF.  These two noncharacter code points have the attribute of being associated with the largest code unit values for particular Unicode encoding forms. In UTF-16, U+FFFF is associated with the largest 16-bit code unit value, FFFF16. U+10FFFF is associated with the largest legal UTF-32 32-bit code unit value, 10FFFF16. This attribute renders these two noncharacter code points useful for internal purposes as sentinels. For example, they might be used to indicate the end of a list, to represent a value in an index guaranteed to be higher than any valid character value, and so on.\n\n(I left out the last part about U+FFFE.)\n\nAgain, the crux of the matter is the definition of \"open interchange\". ",
            "author": "Steve Rowe",
            "id": "comment-12772151"
        },
        {
            "date": "2009-10-30T22:59:03+0000",
            "content": "Steven, I argue that your quote from the standard agrees with this issue more than it disagrees.\n\nagain, its up for interpretation though  ",
            "author": "Robert Muir",
            "id": "comment-12772153"
        },
        {
            "date": "2009-10-30T23:04:02+0000",
            "content": "i guess the final thing I will say, is the inconsistency of treating U+FFFF special, without being consistent and treating the entire category (noncharacter) the same way.\n\nThis is what lead to the index corruption bug in the first place after all, if you look at it from a unicode perspective and not from a java perspective.  ",
            "author": "Robert Muir",
            "id": "comment-12772154"
        },
        {
            "date": "2009-10-30T23:16:21+0000",
            "content": "Lucene is not an application.\n\nAgain, quoting from section 16.7 (emphasis mine):\n\nApplications are free to use any of these noncharacter code points internally but should never attempt to exchange them.\n\nThe forbidden operation is exchanging non-characters across the application boundary.  \n\nAsking Lucene to store non-characters for you is not a violation of the Unicode standard.  Lucene agreeing to do so is not a violation of the Unicode standard.\n\nIf a Lucene user later uses a Lucene index to exchange data (of whatever form) across the application boundary, that's on the user, not on Lucene.\n\n(I'll skip the Lucene-as-a-weapon metaphor.  You can thank me later.) ",
            "author": "Steve Rowe",
            "id": "comment-12772164"
        },
        {
            "date": "2009-10-30T23:19:51+0000",
            "content": "Steven, yes you are arguing the interchange part.\n\nI am arguing the treatment of a noncharacter as an abstract character.\nIf a lucene index stores a noncharacter as if it were any other character (i.e. within a Term), then its treated as an abstract character.\n\nif you disagree with this patch, then you should also disagree with treating U+FFFF special! \nI don't see how in the world U+FFFF is different than any other codepoint in the noncharacter category in this regard! ",
            "author": "Robert Muir",
            "id": "comment-12772170"
        },
        {
            "date": "2009-10-30T23:29:29+0000",
            "content": "if you disagree with this patch, then you should also disagree with treating U+FFFF special! \n\nQuoting myself from an earlier comment on this issue (apoligies):\n\nInstituting this consistency precludes Lucene-index-as-process-internal use cases. I would argue that the price of consistency is in this case too high.\n\nSo you think that enforcing consistency is worth the cost of disallowing some usages, and I don't. ",
            "author": "Steve Rowe",
            "id": "comment-12772174"
        },
        {
            "date": "2009-10-30T23:37:19+0000",
            "content": "So you think that enforcing consistency is worth the cost of disallowing some usages, and I don't.\n\nno, i think this a myth. I think this is the original bug that caused index corruption\n\n\tlucene used a noncharacter (happened to be U+FFFF) process-internally\n\tlucene also treated this noncharacter as an abstract character (it later got truncated by some encoding routine, but basically it didn't correctly handle this case)\n\n\n\nby disallowing all noncharacters as term text, lucene is more free to use them as delimiters, and sentinel values, and such, as specified in chapter 3 of the standard.\n\nright now you only have one you treat correctly, and thats U+FFFF.\n\n<edit>\n\nSteven, by the way, I think something i havent been able to communicate properly, is that I feel very strongly that storing noncharacters in term text where they are treated as abstract characters, is very different than using them as sentinel values / delimiters / etc in the index format, I think this is ok and is what they are for.\n\nbut term text is different, search engines index human language and by putting noncharacters in term text you are treating them as abstract characters. ",
            "author": "Robert Muir",
            "id": "comment-12772180"
        },
        {
            "date": "2009-10-30T23:52:58+0000",
            "content": "by disallowing all noncharacters as term text, lucene is more free to use them as delimiters, and sentinel values, and such, as specified in chapter 3 of the standard.\n\nLucene is more free, but Lucene's users are not.  Quite the contrary.\n\nIMHO, Lucene's users (applications that incorporate the Lucene library) should be able to use Unicode data in ways that the standard allows (\"Applications are free to use any of these noncharacter code points internally\").\n\nU+FFFF was chosen for Lucene-internal use for reasons very similar to those you're bringing up, Robert: something like \"who would ever want to use non-characters in an index?\"  However, this choice does not obligate Lucene to take the same action for all other non-characters.\n\nI think the fix here is documentation, not proscription. ",
            "author": "Steve Rowe",
            "id": "comment-12772184"
        },
        {
            "date": "2009-10-31T02:32:18+0000",
            "content": "\nSteven, by the way, I think something i havent been able to communicate properly, is that I feel very strongly that storing noncharacters in term text where they are treated as abstract characters, is very different than using them as sentinel values / delimiters / etc in the index format, I think this is ok and is what they are for.\n\nbut term text is different, search engines index human language and by putting noncharacters in term text you are treating them as abstract characters.\n\nRobert, you are a proponent of the (ICU)CollationKeyFilter functionality, which uses IndexableBinaryStringTools to store arbitrary binary data in a Lucene index.  These filters store non-human-readable terms in the index.  I can think of several other examples of using Lucene indexes to store non-human-language terms.\n\nCharacter data, in addition to representing characters, is data.  Bits.  I would argue that you always need context to figure out what bits represent. ",
            "author": "Steve Rowe",
            "id": "comment-12772211"
        },
        {
            "date": "2009-10-31T02:50:46+0000",
            "content": "Robert, you are a proponent of the (ICU)CollationKeyFilter functionality, which uses IndexableBinaryStringTools to store arbitrary binary data in a Lucene index.\n\nI'm actually only a fan of the idea of using unicode collation for searching and sorting.\nas a default, binary comparison for most languages is absolute madness.\n\nI'm not so much a fan of how it encodes this data binary data into what people expect to be a character field, but I understand the limitations and don't blame the implementation \nand this implementation never uses any of the characters in question, although thats not really relevant. ",
            "author": "Robert Muir",
            "id": "comment-12772214"
        },
        {
            "date": "2009-10-31T02:55:26+0000",
            "content": "... the same with trie (numeric) fields ... ",
            "author": "Uwe Schindler",
            "id": "comment-12772215"
        },
        {
            "date": "2009-10-31T12:57:06+0000",
            "content": "if you disagree with this patch, then you should also disagree with treating U+FFFF special! I don't see how in the world U+FFFF is different than any other codepoint in the noncharacter category in this regard!\nYes! The best treatment a library can offer to your data if you're not explicitly requesting transformation is transparently passing it in and out.\nIf Lucene had cleanly separated text/binary data API, it would be okay to mangle text input. But now such mangling just messes up other people's attempts of building said type-safe API on top of Lucene. ",
            "author": "Earwin Burrfoot",
            "id": "comment-12772246"
        },
        {
            "date": "2009-10-31T13:04:58+0000",
            "content": "Earwin, it won't mess with anyones attempt if they use IndexableBinaryStringTools.\n\nif instead, they write some routine that generates invalid unicode, well, I think they get what they deserve. ",
            "author": "Robert Muir",
            "id": "comment-12772247"
        },
        {
            "date": "2013-11-30T12:42:25+0000",
            "content": "2013 Old JIRA cleanup ",
            "author": "Erick Erickson",
            "id": "comment-13835674"
        }
    ]
}