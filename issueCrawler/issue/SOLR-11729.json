{
    "id": "SOLR-11729",
    "title": "Increase default overrequest ratio/count in json.facet to match existing defaults for facet.overrequest.ratio & facet.overrequest.count ?",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [],
        "type": "Improvement",
        "fix_versions": [],
        "affect_versions": "None",
        "resolution": "Invalid",
        "status": "Closed"
    },
    "description": "When FacetComponent first got support for distributed search, the default \"effective shard limit\" done on shards followed the formula...\n\n\nlimit = (int)(dff.initialLimit * 1.5) + 10;\n\n\n\n...over time, this became configurable with the introduction of some expert level tuning options: facet.overrequest.ratio & facet.overrequest.count \u2013 but the defaults (and basic formula) remain the same to this day...\n\n\n      this.overrequestRatio\n        = params.getFieldDouble(field, FacetParams.FACET_OVERREQUEST_RATIO, 1.5);\n      this.overrequestCount \n        = params.getFieldInt(field, FacetParams.FACET_OVERREQUEST_COUNT, 10);\n...\n  private int doOverRequestMath(int limit, double ratio, int count) {\n    // NOTE: normally, \"1.0F < ratio\"\n    //\n    // if the user chooses a ratio < 1, we allow it and don't \"bottom out\" at\n    // the original limit until *after* we've also added the count.\n    int adjustedLimit = (int) (limit * ratio) + count;\n    return Math.max(limit, adjustedLimit);\n  }\n\n\n\nHowever...\n\n\nWhen json.facet multi-shard refinement was added, the code was written slightly diff:\n\n\n\tthere is an explicit overrequest:N (count) option\n\tif -1 == overrequest (which is the default) then an \"effective shard limit\" is computed using the same basic formula as in FacetComponet \u2013 but the constants are different...\n\t\n\t\teffectiveLimit = (long) (effectiveLimit * 1.1 + 4);\n\t\n\t\n\tFor any (non \"-1\") user specified overrequest value, it's added verbatim to the limit (which may have been user specified, or may just be the default)\n\t\n\t\teffectiveLimit += freq.overrequest;\n\t\n\t\n\n\n\n\nGiven the design of the json.facet syntax, I can understand why the code path for an \"advanced\" user specified overrequest:N option avoids using any (implicit) ratio calculation and just does the straight addition of limit += overrequest.\n\nWhat I'm not clear on is the choice of the constants 1.1 and 4 in the common (default) case, and why those differ from the historically used 1.5 and 10.\n\n\n\nIt may seem like a small thing to worry about, but it can/will cause odd inconsistencies when people try to migrate simple facet.field=foo (or facet.pivot=foo,bar) queries to json.facet \u2013 I have also seen it give people attempting these types of migrations the (mistaken) impression that discrepancies they are seeing are because refine:true is not be working.\n\nFor this reason, I propose we change the (default) overrequest:-1 behavior to use the same constants as the equivilent FacetComponent code...\n\n\nif (fcontext.isShard()) {\n  if (freq.overrequest == -1) {\n    // add over-request if this is a shard request and if we have a small offset (large offsets will already be gathering many more buckets than needed)\n    if (freq.offset < 10) {\n      effectiveLimit = (long) (effectiveLimit * 1.5 + 10);\n    }\n    ...",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "date": "2017-12-06T18:29:58+0000",
            "content": "Yonik Seeley: do you remember if there was the an explicit reason you choose those lower constants in the json.facet code? ",
            "author": "Hoss Man",
            "id": "comment-16280631"
        },
        {
            "date": "2017-12-06T21:51:52+0000",
            "content": "(fixed stupid 6 => 10 typo in description ... had 6 on the brain because it's the limit value used in a test i was looking at) ",
            "author": "Hoss Man",
            "id": "comment-16280978"
        },
        {
            "date": "2017-12-07T02:08:31+0000",
            "content": "Yonik Seeley: do you remember if there was the an explicit reason you choose those lower constants in the json.facet code?\n\nBoth sets of numbers were rather shots in the dark.  Two thoughts I had while lowering them:\n\n\tI had seen people suffering performance problems with really big limits... a 50% overrequest can be overkill\n\tThe cost of overrequest can now be much greater (due to nested facets & stats)\n\n\n\nIt may seem like a small thing to worry about, but it can/will cause odd inconsistencies when people try to migrate\n\nAligning over-request limits still wouldn't prevent some differences... the refinement algorithm is currently different.\nIt seems like there are many logical ways to refine results - I originally thought about using refine:simple because I imagined we would have other implementations in the future.\nAnyway, this one is the simplest one to think about and implement: the top buckets to return for all facets are determined in the first phase.  The second phase only gets contributions from other shards for those buckets.\n\nAnyway... back to what the default amount of overrequest should be: I don't really have a strong opinion.\n\n ",
            "author": "Yonik Seeley",
            "id": "comment-16281243"
        },
        {
            "date": "2017-12-07T18:25:04+0000",
            "content": "Aligning over-request limits still wouldn't prevent some differences... the refinement algorithm is currently different.\n\nYeah, I hadn't realized how diff the algos are (linking SOLR-11733).\n\nIn light of which, I'm not sure if it makes any sense to even remotely worry about making the default overrequesting consistent. ",
            "author": "Hoss Man",
            "id": "comment-16282268"
        },
        {
            "date": "2017-12-07T18:27:23+0000",
            "content": "Resolving Invalid since the basic premise i was operating under for assuming these defaults should be the same is flawed.\n\n(It may make sense to change/increase the default overrequesting in json.facet, but that should be considered on it's own merrits, based on the refinement algo used \u2013 not because of any question of equivilence with facet.field) ",
            "author": "Hoss Man",
            "id": "comment-16282272"
        }
    ]
}