{
    "id": "SOLR-2438",
    "title": "Case Insensitive Search for Wildcard Queries",
    "details": {
        "affect_versions": "None",
        "status": "Closed",
        "fix_versions": [
            "3.6",
            "4.0-ALPHA"
        ],
        "components": [],
        "type": "Improvement",
        "priority": "Major",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "This patch adds support to allow case-insensitive queries on wildcard searches for configured TextField field types.\n\nThis patch extends the excellent work done Yonik and Michael in SOLR-219.\nThe approach here is different enough (imho) to warrant a separate JIRA issue.",
    "attachments": {
        "SOLR-2438.patch": "https://issues.apache.org/jira/secure/attachment/12474420/SOLR-2438.patch",
        "SOLR-2438-3x.patch": "https://issues.apache.org/jira/secure/attachment/12504780/SOLR-2438-3x.patch",
        "SOLR-2438_3x.patch": "https://issues.apache.org/jira/secure/attachment/12505143/SOLR-2438_3x.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Peter Sturge",
            "id": "comment-13010251",
            "date": "2011-03-23T17:42:28+0000",
            "content": "Attached patch file "
        },
        {
            "author": "Peter Sturge",
            "id": "comment-13010268",
            "date": "2011-03-23T18:10:13+0000",
            "content": "If you're like me, you may have often wondered why MyTerm, myterm, myter* and MyTer* can return different, and sometimes empty results.\nThis patch addresses this for wildcard queries by adding an attribute to relevant solr.TextField entries in schema.xml.\nThe new attribute is called:  ignoreCaseForWildcards\n\nExample entry in schema.xml:\nschema.xml [excerpt]\n<fieldType name=\"text_lcws\" class=\"solr.TextField\" positionIncrementGap=\"100\" ignoreCaseForWildcards=\"true\">\n  <analyzer type=\"index\">\n    <tokenizer class=\"solr.WhitespaceTokenizerFactory\"/>\n    <filter class=\"solr.LowerCaseFilterFactory\"/>\n  </analyzer>\n  <analyzer type=\"query\">\n      <tokenizer class=\"solr.WhitespaceTokenizerFactory\"/>\n      <filter class=\"solr.LowerCaseFilterFactory\"/>\n      <filter class=\"solr.SynonymFilterFactory\" synonyms=\"synonyms.txt\" ignoreCase=\"true\" expand=\"true\"/>\n  </analyzer>\n</fieldType>\n\n\n\nIt's worth noting that this will lower-case text for ALL terms that match the field type - including synonyms and stemmers.\n\nFor backward compatibility, the default behaviour is as before - i.e. a case sensitive wildcard search (ignoreCaseForWildcards=false).\n\nThe patch was created against the lucene_solr_3_1 branch. I've not applied it yet on trunk.\n\n[caveat emptor] I freely admit I'm no schema expert, so commiters and community members may see use cases where this approach could pose problems. I'm all for feedback to enhance the functionality...\n\nThe hope here is to re-ignite enthusiasm for case-insensitive wildcard searches in Solr - in line with the 'it just works' Solr philosophy.\n\nEnjoy! "
        },
        {
            "author": "David Smiley",
            "id": "comment-13016464",
            "date": "2011-04-06T17:54:56+0000",
            "content": "Nice Peter. So why did you create another JIRA issue instead of putting your patch on SOLR-219?  This is yet another issue and there is already a quasi-community of commenters (including me) on that other issue). "
        },
        {
            "author": "Peter Sturge",
            "id": "comment-13016770",
            "date": "2011-04-07T08:50:48+0000",
            "content": "As I mentioned above, the approach is a little bit different from SOLR-219, and its scope is [perhaps] more targeted at case-insensitive wildcards only.\n\nIt's also a completely self-contained patch. I've found that when a JIRA issue contains lots of (>1) 'non-evolutionary' patches, it becomes difficult to know which patch is which.\nI agree that a new issue means commenters of 219 would need to look at this issue. I've added a link on SOLR-219 to relate it to this issue so it's easier to track.\nHope this helps clarify. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13147657",
            "date": "2011-11-10T13:07:28+0000",
            "content": "I'd like to nudge this one forward, this has always bugged me and we spend a lot of time on the user's lists etc. explaining this. Plus, this is a nice simple patch that I can understand .\n\nSo, I've assigned it to myself and I'd like to carry it to resolution, and for that I'd like any comments. As far as SOLR-219 is concerned, this seems like a more targeted fix as Peter mentioned. Does the 80/20 rule apply here? Can we consider this a step towards a full resolution but \"good enough for now\"? Or would introducing a parameter into the schema file be harder to undo later?\n\nThis approach seems to put the whole question squarely on the user to determine if she wants to, while keeping current behavior unless she takes explicit action which I think is a good thing. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13147675",
            "date": "2011-11-10T13:28:39+0000",
            "content": "I don't think we should use the default locale.\n\nWhy not add an optional analysis chain for multitermqueries like SOLR-219?\n\notherwise you do this, and then someone opens an issue about how accents arent being folded like their analyzer eihter. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13147735",
            "date": "2011-11-10T14:59:26+0000",
            "content": "Why not add an optional analysis chain\n\n\nsomeone opens an issue about how accents arent being folded like their analyzer either.\n\nGood point.\nWhile an optional analysis chain to be used for prefix queries, etc, would be powerful in some ways, it's not very user friendly and makes the schema harder to read if we add it for all our fields.  We should be able to figure out the right thing to do in pretty much all cases when our filters are used (i.e. some filters should be run on a prefix and some shouldn't). "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13147745",
            "date": "2011-11-10T15:10:00+0000",
            "content": "\nWhile an optional analysis chain to be used for prefix queries, etc, would be powerful in some ways, it's not very user friendly and makes the schema harder to read if we add it for all our fields. We should be able to figure out the right thing to do in pretty much all cases when our filters are used (i.e. some filters should be run on a prefix and some shouldn't).\n\nI agree with this actually... but it kinda sucks from the plugin perspective.\n\nCan we have both? E.g. we have a pluggable chain, you can declare your own, but the default is 'AutoAnalyzerFactory' or something like that, which is a factory that deduces it from the query chain (e.g. for this i would say look for accent-folding and lowercase and declare success, if you want anything else go configure your own chain).\n\nThen the schema file wouldn't be messy either. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13147767",
            "date": "2011-11-10T15:28:34+0000",
            "content": "I was thinking about trying to explain another type of analyzer a-la SOLR-219. And maybe a fourth type if SOLR-2477 were implemented. And it was giving me a headache, especially when that would require the users to understand what is arguably an expert option before they could handle the 80% case...\n\nSo what about making this bug deal with the accents and case folding as Robert suggests and leave the pluggable stuff for 219 if anyone wants to take it on? And if we do it that way, should we make the user specify a per-field flag (suggestions welcome) or really make this the default and change the current behavior? This latter seems like a bad idea for 3.x, but possibly make the default to auto-detect in trunk? "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13147769",
            "date": "2011-11-10T15:30:59+0000",
            "content": "We can change the default just by respecting a version bump (if its < 3.5, we do nothing, and old configs still did what they did before) "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13147774",
            "date": "2011-11-10T15:40:36+0000",
            "content": "Can we have both?\n\nYeah, that sounds like the best option. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13147780",
            "date": "2011-11-10T15:43:16+0000",
            "content": "bq: We can change the default just by respecting a version bump (if its < 3.5, we do nothing, and old configs still did what they did before)\n\nBut from a user's perspective, they install 3.5 and the behavior changes. I'm willing to do it the way you suggest but it makes me nervous to do unilaterally. "
        },
        {
            "author": "David Smiley",
            "id": "comment-13147782",
            "date": "2011-11-10T15:44:08+0000",
            "content": "I really like the idea of automatically deducing the proper analysis steps by default (if the schema is >= 3.5), and having the option to specify an explicit analysis chain too. FYI there is similar analyzer detection that goes on for handling of ReverseWildcardFilterFactory with wildcards, and also in ExtendedDismax for detecting stop words. It's good to see committers have interest in this again, finally. If there's something I can do to help then let me know. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13147784",
            "date": "2011-11-10T15:46:06+0000",
            "content": "\nBut from a user's perspective, they install 3.5 and the behavior changes. I'm willing to do it the way you suggest but it makes me nervous to do unilaterally.\n\nit doesn't ? because their old configuration file doesnt have matchVersion=3.5 "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13150158",
            "date": "2011-11-15T01:45:10+0000",
            "content": "This is not at all ready for prime-time but I'm inviting comments on the approach. It turns out that all the hard work has already been done, see QueryParserBase. The attached patch is almost all tests... \n\nBut I greatly fear that I'm grossly misusing \nQueryParserBase.lowercaseExpandedTerms, which looks like it's for parameters on the query line? Where did that come from anyway? Or what the heck is it supposed to be used for, anyone know? \n\nA couple of thing make me nervous about this approach. It depends in a pretty hard-coded way on detecting LowerCaseFilterFactory and LowerCaseTokenizerFactory, if anyone adds anything else in there it'll have to be re-coded. Is there a better way? It almost seems like a flag on the <field> definition as Peter suggested is a more robust way of going about things.\n\nAnyway, I'm getting way past the point of diminishing returns tonight, so I thought I'd at least throw this out for comment.\n\nIgnore everything with the ASCIIFoldingFilterFactory, I detect it but don't do anything with it yet.\n\nAnd I can't seem to make the reversed test work, even without the casing switch. Which means I should put it down for the evening, I'm obviously fried. Anybody feeling kind can uncomment the line that starts:\n\n// make me work\n\nand get the test class to work. It's probably trivial but I'm not seeing it. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13150207",
            "date": "2011-11-15T02:52:41+0000",
            "content": "QueryParserBase.lowercaseExpandedTerms[...] Where did that come from anyway?\n\nLegacy.  Solr has never used it.\n\nIt almost seems like a flag on the <field> definition as Peter suggested is a more robust way of going about things.\n\nSince there's normally only one right way, making it configurable (from the users point of view) isn't optimal.\nThat could be the job of the factory though!\n\nWe could add flags to the factory to say \"this filter should be run for prefix queries, etc\", or a method to return that meta-data.\nThen an analyzer could be built that only included the right filters for the type query (prefix, wildcard, etc).\n\nAnother related alternative is to have the factory actually do the processing on the term.  Something like\n\n\npublic enum QueryType { PREFIX, WILDCARD, ... }\n\npublic String LowerCaseFilterFactory.processQueryTerm(String queryTerm, QueryType queryType) {\n  return queryTerm.toLowerCase(Locale.US);  // Uhhh, what locale returns the same values as Character.toLowerCase()?  \n}\n\n "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13150945",
            "date": "2011-11-16T01:01:24+0000",
            "content": "Here's a rough cut at what I think Yonik might have been talking about, comments?\n\nI haven't done a thing about efficiency here, just seeing if the new method in the FilterFactories (processQueryTerm) makes sense to y'all.\n\nOne thing I'm not clear on: Would it make more sense to just instantiate a new instance of the filter and run each term through it rather than steal bits from the underlying Filters (see ASCIIFoldingFilterFactory and LowercaseFilterFactory for example). I just hate duplicated code but I'm not sure how efficient creating a new filter and running the token through would be for each and every token. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13150996",
            "date": "2011-11-16T03:29:47+0000",
            "content": "\nI just hate duplicated code but I'm not sure how efficient creating a new filter and running the token through would be for each and every token.\n\nWhich is why it should be a real chain, not code-dup or conflation of tokenfilterfactories with being also queryparserfactories.\n\nThe Analyzer etc takes care of all this reuse stuff already: the only issue people have with a chain is they want an 'auto' one by default... thats separate... thats CONFIGURATION "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13152527",
            "date": "2011-11-18T00:56:28+0000",
            "content": "OK, this isn't nearly finished yet, but I wanted to run it by folks to see if the approach is what, particularly, Robert and Yonik have in mind.\n\nI'm assuming that the flex stuff is out of scope for this JIRA, right?\n\nDon't waste your time on details just yet, only the general approach.\n\nI'm thinking of allowing a flag to the fields to disable this functionality but make this the default, thoughts?\n\nHaven't even thought about back-porting to 3x, but it looks do-able on a quick glance. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13152545",
            "date": "2011-11-18T01:05:37+0000",
            "content": "This is totally the general approach I wanted to see here!\n\nSo then we are only left with the two configuration cases to think about:\n1. we have the backwards case where no chain is specified, and we want to provide the behavior of today. I think the simplest solution is to just use set the analyzer to keywordanalyzer for that? This might simplify logic as then this 'analyzer' for the field is never non-null, and QP just always analyzes these queries.\n2. we have the 'auto' case where no chain is specified, and we want to do the right thing automatically. so in that situation I think we always build a chain based off of the users CharFilter setup + keywordtokenizer + lowercasefilter (if lowercasetokenizer/filter is in use) + asciifoldingfilter (if its in use). anything more complicated and someone just declares their own chain. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13153122",
            "date": "2011-11-18T21:05:16+0000",
            "content": "Yonik says that .../queryparser/classic/QueryParserBase.lowercaseExpandedTerms is something that was never used (but I do see test cases for it). Should I remove the variable, the getter/setter and all that kinda stuff? Are there any back compat issues (this is a public method after all).....\n\nI can easily be argued out of taking this out. This JIRA is about Solr, I'm not sure messing around in the classic query parser is appropriate when it's not germane to the JIRA... "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13153176",
            "date": "2011-11-18T22:17:14+0000",
            "content": "\nYonik says that .../queryparser/classic/QueryParserBase.lowercaseExpandedTerms is something that was never used (but I do see test cases for it).\n\nIts not used by solr, but its 'on' by default for lucene. \n\nI would say leave it be to make it easier to get this issue resolved for now? "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13153180",
            "date": "2011-11-18T22:21:29+0000",
            "content": "Its not used by solr, but its 'on' by default for lucene.\n\nYep.\n\nI would say leave it be to make it easier to get this issue resolved for now?\n\n+1 "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13153863",
            "date": "2011-11-20T20:28:42+0000",
            "content": "I think this patch is ready for scrutiny. Tests run successfully.\n\nI have yet to do several things:\n1> update README\n2> add an example to example/schema.xml\n3> this is going to take a writeup on the Wiki I think, explaining that there's another (optional) section to a <fieldType>. Any suggestions where that should go?\n\nOriginally, I'd hoped to back-port it to 3.5, but the more I look at it the more I'd like it to bake a while before being officially released and target 3.6 instead for the back-port. Can one back-port something like this after the first RC is cut or is it better to wait until after the release? I can always commit this to trunk and open another JIRA to backport after 3.5 is released. "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-13153871",
            "date": "2011-11-20T20:57:19+0000",
            "content": "Hi Erick, once the 3.5 release is branched off, you are free to commit it tot he 3.x branch. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13154161",
            "date": "2011-11-21T13:24:10+0000",
            "content": "3.5 is branched. But just my opinion: we should never worry about this stuff.\n\nI don't think we should ever freeze trunk or our stable branch.\n\nIf someone is working on a release candidate and hasn't branched, they can always branch\nfrom a specific revision that they were working with before.\n\nBy the way Erick: nice work on the patch. I just took a quick glance (didn't test it),\nbut only have one question.\n\nIf the backwards compatibility path is to have legacyMultiTerm, can't we just control\nits default based upon the schema version (and bump that?). It seems awkward to have\n2 booleans that control the backwards: both legacyMultiTerm and luceneMatchVersion.\n\nI guess at the end of the day I think the schema variable you added is a better approach,\nbecause its not really a behavior of the lucene queryparser that changed, but a change\nto the schema. "
        },
        {
            "author": "Simon Willnauer",
            "id": "comment-13154173",
            "date": "2011-11-21T13:31:34+0000",
            "content": "3.5 is branched. But just my opinion: we should never worry about this stuff.\n\n+1  "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13154210",
            "date": "2011-11-21T14:41:48+0000",
            "content": "bq: I guess at the end of the day I think the schema variable you added is a better approach\n\nI was just thinking about this since someone on the user's list asked \"can this be applied to 3.4\" and couldn't make that all work without headaches, precisely because there were two variables to contend with. Alright, I'll make matchVersion determine the default value of legacyMultiTerm, which should allow this patch to be applied to pre 3.6 code lines at the user's risk.\n\nbq: 3.5 is branched. But just my opinion: we should never worry about this stuff.\n\nRight, if it had been more than a couple of days it'd have been another story, but I ran into a few surprises when running tests, so delaying for a couple of days to insure no chance of screwing up seemed prudent... thanks. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13154730",
            "date": "2011-11-21T23:37:09+0000",
            "content": "OK, this patch does a better job with the matchVersion as per Muir. If nobody objects I'll commit it this week, probably not before Wednesday though. Then I should be able to do the backport to 3.6 shortly thereafter.\n\nI still have to run all the tests yet again, but I don't really expect much of a problem.\n\nShould SOLR 218, 219 and 757 all be closed as part of 2438? "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13155310",
            "date": "2011-11-22T18:06:25+0000",
            "content": "Here's what the 3x version would look like if anyone's interested. There's some refactoring that was done between 3.x and 4.0 that made reconciling these a bit of a pain. \n\nStill need to modify the CHANGES files.\n\nI'll commit these tomorrow sometime if nobody objects. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13157222",
            "date": "2011-11-25T16:22:27+0000",
            "content": "Let's iterate on this in trunk a while before we backport to 3x.\nIt's always good when we can avoid configuration, and I think that's the case here.\n\nFirst of all, the name \"legacyMultiTerm\" just begs the question \"with respect to what?\".\nSecond, things would only be non-back compatible if someone were using things incorrectly (i.e. a query of myfield:Foo when myfield contains a lowecase filter).  It really doesn't seem like we need a \"legacyMultiTerm\" flag or a lucene match version for this.\n\nI'll work up a patch to make the analysis a bit more flexible too.\n "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13157251",
            "date": "2011-11-25T17:17:37+0000",
            "content": "Too late, I checked all this in before I saw your comment, including into 3.6.\n\nYeah, legacyMultiTerm is awkward, and I'm pretty confused by the lucene match version, so anything you want to do there is welcome. what I was trying for was the capability to \n1> keep from changing the behavior on someone installing over an older 3.x version\n2> allow them to keep the old behavior if necessary. I admit I have a hard time \n   coming up with a use-case here, but at least it does allow them to sidestep\n   the whole process if someone counts on the old behavior.\n\nAt root I'm uncomfortable deciding for them what's best without a way of having the user say \"no, you dolt, you didn't anticipate my use case!\".\n\nAnyway, I opened up SOLR-2918 "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13157252",
            "date": "2011-11-25T17:19:39+0000",
            "content": "Patches as of the commit "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13157253",
            "date": "2011-11-25T17:20:48+0000",
            "content": "Trunk - r1206229\n3.6   - r1206258\n\nNote, Yonik has some improvements in mind, see: SOLR-2918 "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13157259",
            "date": "2011-11-25T17:36:01+0000",
            "content": "I closed SOLR-219 and SOLR-757 as part of this issue. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13157297",
            "date": "2011-11-25T20:35:50+0000",
            "content": "I'm looking at TestFoldingMultitermQuery, and as far as I can tell there only seem to be tests for positive matches.\nFor example, there are tests that myfield:A*  match \"abacus\" on a case insensitive field, but there are no tests that ensure that it doesn't match on a case sensitive field?\n\nIt was especially confusing since there are comments like:\n\n// test the wildcard queries find only one doc  where the query is uppercased and/or accented.\n\n\nThat suggest that case sensitivity is also being tested (because of the \"only one\" phrase), but that's not the case.  It seems like it should really say\n\n// test the wildcard queries find the doc even when the query is uppercased and/or accented.\n\n\n\nThis patch also introduced a bug that causes regex queries to be lowercased when they shouldn't be.  I've fixed it in my local copy. "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-13157318",
            "date": "2011-11-25T22:18:55+0000",
            "content": "I fixed the example schema in 3.x (which contained a merge error: double field definition). The 3.x code also used Arrays.copyOfRange() that is not available in Java 5. Both errors should have been detected when running tests before committing. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13157329",
            "date": "2011-11-25T23:12:52+0000",
            "content": "I see a couple of other issues:\n\n\thardcoded use of WhitespaceTokenizerFactory will break any fields that allow embedded whitespace (KeywordTokenizerFactory, etc)\n\tLowercaseTokenizerFactory won't be detected as producing lowercase tokens\n\tNo CharFilters are run (i.e. things like MappingCharFilter that chan change chars)\n\n\n\nI'll take a crack at addressing these. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13157331",
            "date": "2011-11-25T23:19:46+0000",
            "content": "Seems like unless you specifically ask, the automagic mode should use keywordtokenizer?\n\nI think the relevant code for analyzing the terms will get throw an exception if the tokenizer produces more than 1 term from a wildcard or other MTQ...  "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13157332",
            "date": "2011-11-25T23:21:06+0000",
            "content": "And supporting other tokenizers by default would be hellaciousanyway, since you possibly have syntax in the text... "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13157336",
            "date": "2011-11-25T23:38:28+0000",
            "content": "Thanks, Uwe. I not only ran my new tests in IntelliJ, but I also checked out the code after committing and ran the entire test suite. Then, looking at my stored results again after your note just now I saw that I'd managed to blow right past the error in schema.xml. Siiiggghhhhh. It wasn't in my test cases so I guess I'd just stopped looking by then....My apologies, that shouldn't happen again... "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13157560",
            "date": "2011-11-26T17:41:25+0000",
            "content": "Here's a patch with quite a few changes:\n\n\tfixed cases that were lowercasing the terms when they shouldn't be\n\tmoved the multiTermAnalyzer methods up to TextField.  This strategy isn't general enough to be used by other field types (think prefix query on a numeric field, etc)\n\tadded an interface, MultiTermAwareComponent, that can allow a factory to return another factory (or itself)\n\tremoved legacy_multiTerm... if someone wants that, they can directly configure a keyword tokenizer.\n\tmade TextField.getRangeQuery() fully functional\n\tuse KeywordTokenizer by default in the MultiTermAnalyzer\n\tremoved from the example schema... this should work for 99% of people and only expert users should care (and it could confuse new users about when they need to define a custom multiTermAnalyzer)\n\tother minor improvements such as not looking up the fieldType twice all the time in SolrQueryParser\n\tSOLR-1982 related - don't introspect all fieldTypes for every query parser instantiation... do it per-field only as required.  Also, don't allow wildcard behavior of one field affect another.\n\tadded some new tests to catch certain cases, fixed some other test cases.  A few more tests might be desirable.\n\n "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13157569",
            "date": "2011-11-26T18:04:18+0000",
            "content": "Yonik:\n\nSplendid. It's amazing what happens when someone who really understands the code does the work! I took a quick glance over it, I'll be able to look more this evening...\n\nSo what's next, should I carry it forward from here or are you going to commit the patch? And what about 3x? "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13157573",
            "date": "2011-11-26T18:21:43+0000",
            "content": "So what's next, should I carry it forward from here \n\nGo for it! "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13157941",
            "date": "2011-11-27T17:38:37+0000",
            "content": "Improved version of this issue. If you want to apply this patch to the source from before 25-Nov, you probably have to apply the patch dated 25-Nov first, both for trunk and 3.6 "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13158084",
            "date": "2011-11-27T23:25:45+0000",
            "content": "backport MultiTermAware version of this patch to 3.6. Again, before applying this patch you probably need to apply the 3x patch from 25-Nov. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13176654",
            "date": "2011-12-28T14:14:42+0000",
            "content": "Hmmm, it's clear that reading this patch is confusing. See the writeup at: http://wiki.apache.org/solr/MultitermQueryAnalysis "
        },
        {
            "author": "Michael McCandless",
            "id": "comment-13180708",
            "date": "2012-01-05T19:03:25+0000",
            "content": "Hmm, working on LUCENE-995, where I had to regen QueryParser.java from QueryParser.jj on 3.x... I noticed that when this issue was committed (well, rev 1206258, up above), that QueryParser.java was changed yet QueryParser.jj was not...\n\nI'll fix that.\n\nBut even more spooky, all tests passed with that loss:\n\n-  protected String analyzeMultitermTerm(String field, String part, Analyzer analyzerIn) {\n-    TokenStream source;\n-\n-    if (analyzerIn == null) analyzerIn = analyzer;\n-\n-    try {\n-      source = analyzerIn.tokenStream(field, new StringReader(part));\n-      source.reset();\n-    } catch (IOException e) {\n-      throw new RuntimeException(\"Unable to initialize TokenStream to analyze multiTerm term: \" + part, e);\n-    }\n-\n-    CharTermAttribute termAtt = source.getAttribute(CharTermAttribute.class);\n-    String termRet = \"\";\n-\n-    try {\n-      if (!source.incrementToken())\n-        throw new IllegalArgumentException(\"analyzer returned no terms for multiTerm term: \" + part);\n-      termRet = termAtt.toString();\n-      if (source.incrementToken())\n-        throw new IllegalArgumentException(\"analyzer returned too many terms for multiTerm term: \" + part);\n-    } catch (IOException e) {\n-      throw new RuntimeException(\"error analyzing range part: \" + part, e);\n-    }\n-\n-    try {\n-      source.end();\n-      source.close();\n-    } catch (IOException e) {\n-      throw new RuntimeException(\"Unable to end & close TokenStream after analyzing multiTerm term: \" + part, e);\n-    }\n-\n-    return termRet;\n-  }\n-\n\n\n\nDo we have no test coverage for this method?  Should this method be removed...?  I'm confused. "
        },
        {
            "author": "Michael McCandless",
            "id": "comment-13180710",
            "date": "2012-01-05T19:04:02+0000",
            "content": "Reopening so we can figure out whether the backport was correct... we should at least see a test fail when that method is removed I think? "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13180850",
            "date": "2012-01-05T21:27:37+0000",
            "content": "Yikes!\n\nHow did you \"remove the method\"? Comment it out and comment out the call to it or something else? I'll need to do whatever you did to reproduce it.\n\nAnd do you expect that this would also be an issue for trunk? As I remember, the two implementations are pretty similar so I'd at least be suspicious there too.\n\nI'm not very familiar (ok, not at all) with the parser generation step, so there may be a few more questions along the way.\n\nI should be able to take a quick look tonight sometime... "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13180856",
            "date": "2012-01-05T21:39:03+0000",
            "content": "And do you expect that this would also be an issue for trunk?\n\nNope.  For trunk, I previously refactored everything I could out of QueryParser.jj into QueryParserBase.java (and hence the trunk patch only needed to modified that file). "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13181061",
            "date": "2012-01-06T02:51:22+0000",
            "content": "OK, spooky is a kinder way to describe this than some I can think of. The method in lucene...QueryParser was simply dead code, I suspect I managed to put it there through the magic of modern IDEs. And hey, it compiles. Since this solution is a purely Solr construct in the first place, it has no business being in the lucene package at all.\n\nThere's an identical method in solr...TextField that is the code actually used, so somehow I managed to put the same code in two places. Simply removing the code from lucene...QueryParser is the right thing to do here I think, all the tests pass when I did this manually.\n\nAnd, as Yonik says, there's nothing similar in trunk.\n\nSo if I remember the patterns from lex and yacc, there's really nothing for me to do except close this JIRA, right? Mike can freely check in the newly generated QueryParser.java and I can remember to actually read the header that says things about this being a generated file that shouldn't be changed....  \n\nAgree? Disagree?\n\nNice catch Mike! "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13182238",
            "date": "2012-01-08T16:07:57+0000",
            "content": "Michael:\n\nCan we close this? Or is there something I need to do here? "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13182703",
            "date": "2012-01-09T18:50:10+0000",
            "content": "Removed methods inadvertently put in lucene...QueryParser.java/jj\n\nThanks Mike for pointing this out!\n\n3x only, r: 1229291 "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13182704",
            "date": "2012-01-09T18:51:06+0000",
            "content": "Removed dead code inadvertently put in 3x QueryParser.java. No functional changes, no patch. "
        },
        {
            "author": "Duto",
            "id": "comment-13219939",
            "date": "2012-03-01T09:21:34+0000",
            "content": "I try it yesterday the 3.6-SNAPSHOT and I remark something strange :\n\n\n\n\nraw query\nparsed query\ncomment\n\n\nname:L\u00e9CTROD*\nname:lectrod*\nfill good\n\n\nname:*L\u00e9CTROD\nname:lectrod\n that remove the wildcard !!! \n\n\nname:*L\u00e9CTROD*\nname:lectrod\n that remove all wildcards !!! \n\n\n\n\n\nI would like to know if it's normal that if the wildcard is on the first position on the raw query, the wildcard is remove on the parsed query ?\n\nschema.xml\n<types>\n\t<fieldtype name=\"text_fr\" class=\"solr.TextField\">\n\t\t<analyzer type=\"index\">\n\t\t\t<tokenizer class=\"solr.StandardTokenizerFactory\"/>\n\t\t\t<filter class=\"solr.StandardFilterFactory\"/>\n\t\t\t<filter class=\"solr.ASCIIFoldingFilterFactory\"/>\n\t\t\t<filter class=\"solr.LowerCaseFilterFactory\"/>\n\t\t</analyzer>\n\t\t<analyzer type=\"query\">\n\t\t\t<tokenizer class=\"solr.StandardTokenizerFactory\"/>\n\t\t\t<filter class=\"solr.StandardFilterFactory\"/>\n\t\t\t<filter class=\"solr.ASCIIFoldingFilterFactory\"/>\n\t\t\t<filter class=\"solr.LowerCaseFilterFactory\"/>\n\t\t</analyzer>\n\t\t<analyzer type=\"multiterm\">\n\t\t\t<tokenizer class=\"solr.StandardTokenizerFactory\" />\n\t\t\t<filter class=\"solr.StandardFilterFactory\"/>\n\t\t\t<filter class=\"solr.ASCIIFoldingFilterFactory\"/>\n\t\t\t<filter class=\"solr.LowerCaseFilterFactory\"/>\n\t\t</analyzer>\n\t</fieldtype>\n</types>\n\n<fields>\n\t<field name=\"name\" type=\"text_fr\" indexed=\"true\" stored=\"true\" multiValued=\"true\"/>\n</fields>\n\n\n\n\nDuto\n "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13220014",
            "date": "2012-03-01T13:09:40+0000",
            "content": "Duto:\n\nA couple of things. First, in the future could you post this kind of usage question to the users list? See: http://lucene.apache.org/solr/discussion.html. No big deal, but that way more people see the discussion and benefit.\n\nBut to your question:\nHave you enabled leading wildcard? See the ReversedWildcardFilterFactory. Leading wildcards need some special handling because in the simple case, finding them means you have to examine every term in the field and can be very expensive.\n\nSecond, you could get away with just using one analyzer since they're all the same, as\n<analyzer>\n.\n.\n.\n</analyzer>\n\nif no 'type=...' is specified, then the index and query and multiterm chains are use the analyzer definition.\n\nI doubt this issue is related to this JIRA, I think it's just the normal leading wildcard issues.\n\nHere's a discussion of this in some detail if you haven't seen it yet:\nhttp://www.lucidimagination.com/blog/2011/11/29/whats-with-lowercasing-wildcard-multiterm-queries-in-solr/\n\n\nErick "
        },
        {
            "author": "Karsten R.",
            "id": "comment-13502816",
            "date": "2012-11-22T15:16:37+0000",
            "content": "Hi Erick,\n\nin your commit Revision 1206767 (2011-11-27) there is a change in\norg.apache.solr.search.SolrQueryParser#getReversedWildcardFilterFactory(FieldType)\nBefore this commit the Map leadingWildcards was important, after this the Map leadingWildcards is only a cache. A cache, which is never used:\n\nReversedWildcardFilterFactory fac = leadingWildcards.get(fieldType);\nif (fac == null && leadingWildcards.containsKey(fac)) {\n   return fac;\n}\n\n\nIf we want to use this cache it should be\n\nReversedWildcardFilterFactory fac = leadingWildcards.get(fieldType);\nif (fac != null || leadingWildcards.containsKey(fieldType)) {\n   return fac;\n}\n\n\n\nbest regards\n  Karsten\n "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13502821",
            "date": "2012-11-22T15:36:34+0000",
            "content": "Thanks Karsten, I'll fold that change into my patch for SOLR-4093 "
        }
    ]
}