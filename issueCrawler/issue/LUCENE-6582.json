{
    "id": "LUCENE-6582",
    "title": "SynonymFilter should generate a correct (or, at least, better) graph",
    "details": {
        "resolution": "Duplicate",
        "affect_versions": "None",
        "components": [],
        "labels": "",
        "fix_versions": [],
        "priority": "Major",
        "status": "Resolved",
        "type": "Bug"
    },
    "description": "Some time ago, I had a problem with synonyms and phrase type queries (actually, it was elasticsearch and I was using a match query with multiple terms and the \"and\" operator, as better explained here: https://github.com/elastic/elasticsearch/issues/10394).\n\nThat issue led to some work on Lucene: LUCENE-6400 (where I helped a little with tests) and  LUCENE-6401. This issue is also related to LUCENE-3843.\n\nStarting from the discussion on LUCENE-6400, I'm attempting to implement a solution. Here is a patch with a first step - the implementation to fix \"SynFilter to be able to 'make positions'\" (as was mentioned on the issue). In this way, the synonym filter generates a correct (or, at least, better) graph.\n\nAs the synonym matching is greedy, I only had to worry about fixing the position length of the rules of the current match, no future or past synonyms would \"span\" over this match (please correct me if I'm wrong!). It did require more buffering, twice as much.\n\nThe new behavior I added is not active by default, a new parameter has to be passed in a new constructor for SynonymFilter. The changes I made do change the token stream generated by the synonym filter, and I thought it would be better to let that be a voluntary decision for now.\n\nI did some refactoring on the code, but mostly on what I had to change for may implementation, so that the patch was not too hard to read. I created specific unit tests for the new implementation (TestMultiWordSynonymFilter) that should show how things will be with the new behavior.",
    "attachments": {
        "before.png": "https://issues.apache.org/jira/secure/attachment/12740491/before.png",
        "after.png": "https://issues.apache.org/jira/secure/attachment/12740492/after.png",
        "LUCENE-6582.patch": "https://issues.apache.org/jira/secure/attachment/12740367/LUCENE-6582.patch",
        "after2.png": "https://issues.apache.org/jira/secure/attachment/12740558/after2.png",
        "after3.png": "https://issues.apache.org/jira/secure/attachment/12740911/after3.png"
    },
    "issue_links": {},
    "comments": [
        {
            "id": "comment-14591666",
            "author": "Ian Ribas",
            "date": "2015-06-18T11:31:28+0000",
            "content": "The patch with the initial work. "
        },
        {
            "id": "comment-14592430",
            "author": "Michael McCandless",
            "date": "2015-06-18T20:13:22+0000",
            "content": "I will dig more into this patch, it is a nice (big!) change, but this TODO caught my eye:\n\n\n    // TODO: Problems: In the substitution below, how to identify that the terms \"united\" \"states\" \"of\" \"america\"\n    // are actually a phrase and not individual synonyms of \"usa\"? And how to differentiate that phrase from the\n    // phrase \"u\" \"s\" \"a\"? We can do that adding position lengths ...\n\n\n\nOne approach could be to use TokenStreamToAutomaton, then enumerate all finite strings from the resulting automaton, and assert it's as expected?  I.e. that things did not get unexpectedly \"sausaged\"? "
        },
        {
            "id": "comment-14592498",
            "author": "Michael McCandless",
            "date": "2015-06-18T21:01:54+0000",
            "content": "Example images. "
        },
        {
            "id": "comment-14592501",
            "author": "Michael McCandless",
            "date": "2015-06-18T21:03:24+0000",
            "content": "Just to confirm the scope of this change, if I have these synonyms:\n\n\n  wtf --> what the fudge\n  wtf --> wow that's funny\n\n\n\nAnd then I'm tokenizing this:\n\n\n  wtf happened\n\n\n\nBefore this change (today) I get this crazy sausage incorrectly\nmatching phrases like \"wtf the fudge\" and \"wow happened funny\":\n\n\n\nBut after this change, the expanded synonyms become separate paths in\nthe graph right?  So it will look like this?:\n\n\n\nMatching exactly the right phrases?  Note that absolute position\nnumbers become somewhat meaningless now ... they are really \"node\nIDs\".\n\nSome small things I noticed:\n\n\n       originalInputIdx = -10;\n\n\n\nWhy -10?\n\nCan we just add the new test cases into the existing (tiny)\nTestMultiWordSynonyms.java?\n\nRelated: LUCENE-5012 is an effort to make such \"graph consuming and\nproducing token streams\" easier ... but that's a major change to the\nTokenStream API.\n\nIn the case where a given input token matches no rules in the FST, are\nwe still able to pass that through to the output without buffering\n(calling capture())? "
        },
        {
            "id": "comment-14592848",
            "author": "Ian Ribas",
            "date": "2015-06-19T01:32:59+0000",
            "content": "This comment was written early in my attempts and I'm afraid I didn't review it later. In the final solution, it is much clearer that the longer terms are not individual synonyms of the shorter terms, specially since the longest version is what appears first on the output. I'll have to change the comment, and take away the TODO (it was a marker for things to remember to ask when submitting).\n\nI don't think things will get \"sausaged\", but I'll look into TokenStreamToAutomaton to see if I can understand it enough to use it.\n\nWhat might still happen is that a phrase \"u s of america\" would match, as is implied on the second question on the comment above, which is a lesser problem but still kind of wrong. More on that below. "
        },
        {
            "id": "comment-14592875",
            "author": "Ian Ribas",
            "date": "2015-06-19T01:59:46+0000",
            "content": "Another example image. "
        },
        {
            "id": "comment-14592896",
            "author": "Ian Ribas",
            "date": "2015-06-19T02:28:41+0000",
            "content": "> But after this change, the expanded synonyms become separate paths in\n> the graph right? So it will look like this?\n> Matching exactly the right phrases? \n\nActually, I think it looks more like this:\n\n\n\nThat means that \"wtf the fudge\" and \"wow happened funny\" will no longer match, but \"wow the fudge\" would.\n\nThe absolute positions still have meaning. I couldn't figure out how to clearly separate the two phrases from the rules (as was mentioned on the TODO comment above) using the token attributes. They will be stacked in the same order on each position, but that doesn't seem to be enough to make things unambiguous. Specially since with rules like:\n\n\npass, ticket\ncheap, unexpensive\n\n\n\nand tokenizing:\n\n\ncheap pass\n\n\n\nI would expect to mach all the resulting combinations: \"cheap pass\", \"unexpensive pass\", \"cheap ticket\" and \"unexpensive ticket\". And there is no difference in the representation of the tokens \"unexpensive\" as a synonym for \"cheap\" from \"wow\" as a synonym for \"what\" on the previous rules, using the attributes.\n\n> Why -10?\n\nI was unsure if -1 as an invalid value was clear enough and ended up using -10. It could probably just be -1. I'll check.\n\n> Can we just add the new test cases into the existing (tiny) TestMultiWordSynonyms.java?\n\nProbably. Since all tests in the new file use the new constructor to force the new behavior, and TestMultiWordSynonyms tests the old behavior, I didn'tt want to mix things. But I'll just join them, with a comment on the test to make it clear its the old behavior.\n\n> In the case where a given input token matches no rules in the FST, are\n> we still able to pass that through to the output without buffering\n> (calling capture())?\n\nI didn't test this specifically, but would think yes. The new behavior only handles matches differently, I didn't have to do any extra buffering before the match, nor did I change anything on the matching part of the code. The extra buffering is needed only when there was already buffering (lookahead for a partial match) and the synonym was longer than the match. "
        },
        {
            "id": "comment-14593966",
            "author": "Ian Ribas",
            "date": "2015-06-19T21:07:05+0000",
            "content": "New patch with minor fixes: changed -10 to -1 (it was a leftover that I had overlooked, sorry for that).Changed the comment on the TODO, making it clearer what the problem is: output is still a sausage for multiple multi term synonyms.\n\nUnfortunately, I could not merge the tests into a single file because they have different base classes and the new tests depend on asserts on the base class. "
        },
        {
            "id": "comment-14595017",
            "author": "Michael McCandless",
            "date": "2015-06-21T10:49:44+0000",
            "content": "changed -10 to -1\n\nThank you!\n\nUnfortunately, I could not merge the tests into a single file because they have different base classes and the new tests depend on asserts on the base class.\n\nUgh, OK, thanks for trying.  It's fine to leave it separate...\n\nThe absolute positions still have meaning.\n\nOK but with this change we have now created new nodes (something SynFilter does not do today), because wtf now has posLen=3.  This is great (necessary!) for SynFilter to be correct...\n\nAnd there is no difference in the representation of the tokens \"unexpensive\" as a synonym for \"cheap\" from \"wow\" as a synonym for \"what\" on the previous rules, using the attributes.\n\nWell, it is entirely possible for PosInc/PosLenAtt to express the correct graph, it's just hairy to implement, but I think your patch is part way there (it creates new positions!).\n\nE.g. here's a sequence of tokens that would be the fully correct graph output for the wtf example:\n\n\n\n\ntoken\nposInc\nposLen\n\n\nwtf\n1\n5\n\n\nwhat\n0\n1\n\n\nwow\n0\n3\n\n\nthe\n1\n1\n\n\nfudge\n1\n3\n\n\nthat's\n1\n1\n\n\nfunny\n1\n1\n\n\nhappened\n1\n1\n\n\n\n\n\nIt corresponds to this graph:\n\n\n\nThe token posInc/posLen is just a \"rote\" serialization of the arcs of the graph based on how the states are numbered, and other numberings would be possible resulting in different token outputs because there is inherent ambiguity in how you serialize a graph.  I think the only constraints are that 1) all arcs leaving a given state must be serialized one after another (exactly like Lucene's Automaton class!), 2) an arc from node X must go to another node > X (i.e., arcs cannot go to an earlier numbered node). "
        },
        {
            "id": "comment-14596318",
            "author": "Ian Ribas",
            "date": "2015-06-22T17:47:53+0000",
            "content": "I really hadn't thought of using position lengths as \"references\", like this! For some reason I could only think of position length spanning over terms on the \"base\" stream, not creating independent branches. And so I was stuck in thinking  how to represent the graph correctly once I saw that my implementation was still a \"sausage\" on the overlapping phrases.\n\nI will try to implement this solution and see how far I can get.\n\nOne problem that I see is that I'll need more buffering as now the future output is no longer the size of the longest synonym but the added sizes of all synonyms that are phrases (each minus one). Getting this number at the beginning might require a change on the synonym parser...\n\nOne other doubt I have is how this affects the indexer. I imagine it saves position lengths on the index too, so this shouldn't be a problem, right?\n\nThanks very much for such clear guidelines! "
        },
        {
            "id": "comment-14596490",
            "author": "Michael McCandless",
            "date": "2015-06-22T19:20:48+0000",
            "content": "I really hadn't thought of using position lengths as \"references\", like this!\n\nIt's hard to think about   But it \"just\" means the positions become node IDs, and you must number the nodes \"properly\" (so that any token always goes from node X to Y where Y > X).\n\nOne problem that I see is that I'll need more buffering \n\nI think that's fine, I think better correctness trumps the added buffering cost.\n\nOne other doubt I have is how this affects the indexer. I imagine it saves position lengths on the index too, so this shouldn't be a problem, right?\n\nThe index does NOT record position length today... I think if we fix syn filter here to produce the correct graph, we should also insert a \"sausagizer\" phase that turns this graph back into a sausage for indexing?  (So that \"what the fudge\" and \"wow that's funny\" will in fact match a document that had \"wtf\").\n\nHowever, if you apply syn filter at search time, we could fix query parsers to possibly \"do the right thing\" here, e.g. translating this graph into a union of phrase queries, or using TermAutomatonQuery (in sandbox still), or something ... "
        },
        {
            "id": "comment-14596772",
            "author": "Ian Ribas",
            "date": "2015-06-22T22:29:06+0000",
            "content": "Ok, I think I have an idea on how to do this, but it will definitely need some thinking, so it will probably take a while.\n\nI think that's fine, I think better correctness trumps the added buffering cost.\n\nI completely agree.\n\nI think if we fix syn filter here to produce the correct graph, we should also insert a \"sausagizer\" phase that turns this graph back into a sausage for indexing?\n\nI think Robert also commented something on these lines in his answer to my email. I think I understand the general idea of what that means, but I would certainly appreciate some guidance, when the time comes. I'll focus on producing a correct graph first.\n\nThis also means that maybe I'll need changes on the test validations, since we might run into conditions that are considered wrong now. Specially regarding offsets (start and end) and their relation to position lengths. But I'll see what I can do about that too.\n\nHowever, if you apply syn filter at search time, we could fix query parsers to possibly \"do the right thing\" here\n\nI was planning taking a shot at that too, once this part is finished. To make the solution more complete. And, again, I'll certainly appreciate ideas when the time comes. "
        },
        {
            "id": "comment-14596804",
            "author": "Robert Muir",
            "date": "2015-06-22T22:56:35+0000",
            "content": "Can we consider mike's \"crazy graph\" as a second step? I don't know, it just seems like the current patch might be an easier-to-digest improvement. Then again I get totally lost in the synonymfilter \n\nThere is a lot still to do after even this first step before users get real improvements, for instance fixing querybuilder for the boolean case (hopefully easier now), and improving stuff like sandbox/TermAutomatonQuery (maybe?) for the positional case, and so on.\n\nIf we spend the work on a hypercorrect graph for synonymfilter I'm just afraid of things getting lost, queryparser can't make use of it because posinc/poslen semantics become too confusing, analysis is hard to reason about because posinc/poslen semantics are too confusing, more performance tradeoffs (like graph re-sausaging at index time), ... "
        },
        {
            "id": "comment-14597359",
            "author": "Michael McCandless",
            "date": "2015-06-23T08:50:27+0000",
            "content": "I agree Robert Muir, we can do the \"correct graph\" as a follow-on issue; this one is already a good step towards that.\n\nI'll look more closely at this patch.\n\nI can also help with \"phase 2\" ... e.g. maybe build the re-sausagizer filter.  I do think \"phase 2\" may result in a simpler syn filter implementation ... some of the complexity in the current one is because it's being forced to sausagify at the same time as producing synonyms, so if we can more cleanly split out those two functions maybe we get simpler code ... not sure. "
        },
        {
            "id": "comment-14597570",
            "author": "Ian Ribas",
            "date": "2015-06-23T12:22:58+0000",
            "content": "I'll be glad to help either way. I trust whatever priority you both decide.Where should I start looking for the next step? QueryBuilder? \n\nsome of the complexity in the current one is because it's being forced to sausagify at the same time as producing synonyms, so if we can more cleanly split out those two functions maybe we get simpler code \n\nVery good point! It does depend, though, on how the graph is represented, of course. I'll try to keep this in mind when working on the \"correct graph\" (now or later). "
        },
        {
            "id": "comment-14609117",
            "author": "Ian Ribas",
            "date": "2015-06-30T21:33:45+0000",
            "content": "Added one test with automaton (following Michael McCandless's first comment) to clearly show sausagization. "
        },
        {
            "id": "comment-14611746",
            "author": "Michael McCandless",
            "date": "2015-07-02T10:09:34+0000",
            "content": "Thanks Ian Ribas!\n\nI've opened LUCENE-6638 to create a \"graph flattener\" TokenFilter, and it seems to work well ... I'm going to now try to simplify SynFilter by removing the hairy graph flattening it must do today, and have it create correct graph outputs.  I think with the combination of these two we can then have 100% accurate synonym graphs for accurate query-time searches, but also have the \"sausagized\" version that indexing needs to \"match\" the graph corruption we do today. "
        },
        {
            "id": "comment-14618511",
            "author": "Michael McCandless",
            "date": "2015-07-08T12:27:43+0000",
            "content": "I'm going to now try to simplify SynFilter by removing the hairy graph flattening it must do today\n\nI opened LUCENE-6664 for this... it seems to work! "
        },
        {
            "id": "comment-15794770",
            "author": "Michael McCandless",
            "date": "2017-01-03T10:52:31+0000",
            "content": "This has been fixed with the addition of SynonymGraphFilter in LUCENE-6664. "
        }
    ]
}