{
    "id": "SOLR-6637",
    "title": "Solr should have a way to restore a core",
    "details": {
        "components": [],
        "type": "Improvement",
        "labels": "",
        "fix_versions": [
            "5.2",
            "6.0"
        ],
        "affect_versions": "None",
        "status": "Closed",
        "resolution": "Fixed",
        "priority": "Major"
    },
    "description": "We have a core backup command which backs up the index. We should have a restore command too. \n\nThis would restore any named snapshots created by the replication handlers backup command.\n\nWhile working on this patch right now I realized that during backup we only backup the index. Should we backup the conf files also? Any thoughts? I could separate Jira for this.",
    "attachments": {
        "SOLR-6637.patch": "https://issues.apache.org/jira/secure/attachment/12676305/SOLR-6637.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2014-10-22T11:44:42+0000",
            "author": "Varun Thacker",
            "content": "Patch which adds functionality to restore a core. I am starting to work on a test case.\n\nIn parallel I am also working to provide a patch for SOLR-5750. ",
            "id": "comment-14179824"
        },
        {
            "date": "2014-11-01T16:17:35+0000",
            "author": "Varun Thacker",
            "content": "Patch with a working test case.\n\nWe need to discuss the scenario where we hit an exception while restoring. i.e We copy all segment files from the backup location to the index location overwriting any segment files with the same name. Now while copying if we hit an exception then the index can get corrupt. \n\nIs there any way to deal with it or do we just need to document this scenario. ",
            "id": "comment-14193256"
        },
        {
            "date": "2014-11-01T16:27:02+0000",
            "author": "Noble Paul",
            "content": "can you just give  a quick writeup on the steps done by this operation ",
            "id": "comment-14193263"
        },
        {
            "date": "2014-11-01T16:40:52+0000",
            "author": "Varun Thacker",
            "content": "Sure.\n\n1. We can issue only one restore command for a core.\n2. If the \"location\" is not provided in the query string then we default it to core.getDataDir() . We do the same while taking backups hence this behaviour instead of making it mandatory.\n\nIn RestoreCore we do the following - \n1. Close the current index writer\n2. Copy over all files from the backup location to the current index directory. \n3. Remove any files in the current directory which does not belong to the segment .( Hmm.. this might not work when there are multiple segments ) Maybe instead of using \n\n\nSegmentInfos.readCommit(dir, segmentFileName)\n\n\n\nwe just need to do something simple i.e just keep track of what files were before and what files are currently present and remove the unwanted. I will check if this needs to be fixed.\n\n4. Open a new writer and searcher against the index before we return restore success.\n\n\nWe track the status of the restore with a \"restorestatus\" API. This checks if the future is finished executing or not. ",
            "id": "comment-14193266"
        },
        {
            "date": "2014-11-03T08:30:04+0000",
            "author": "Varun Thacker",
            "content": "Updated patch. Improved the test case and fixed the bugs that it uncovered.\n\nStill fighting one issue - I keep getting this error when the index directory tries to close all the resources. Trying to figure out what is the underlying problem.\n\n\nMockDirectoryWrapper: cannot close: there are still open files: {_0.cfs=1, _1.cfs=1}\n\n ",
            "id": "comment-14194356"
        },
        {
            "date": "2014-11-03T11:12:29+0000",
            "author": "Varun Thacker",
            "content": "MockDirectoryWrapper: cannot close: there are still open files: {_0.cfs=1, _1.cfs=1}\n\nPatch which fixes this. Looks like we can't use the try with resource block to get indexDir from the directoryFactory as we need to call release() instead of closing it. ",
            "id": "comment-14194444"
        },
        {
            "date": "2014-11-03T13:13:27+0000",
            "author": "David Smiley",
            "content": "FYI I already created an issue in JIRA for this: https://issues.apache.org/jira/browse/SOLR-4545 ",
            "id": "comment-14194516"
        },
        {
            "date": "2014-11-03T13:25:25+0000",
            "author": "Varun Thacker",
            "content": "David Smiley I had not seen that issue previously. Should we move the work there ? \n\nA proposed \"restore\" command to the replication handler should allow specifying a directory, or an \"as-of\" date; otherwise you'd get the most recent snapshot.\n\nMy approach here has been to allow restoring named snapshots ( SOLR-5340 ) only. We can add functionality that says that if the \"name\" is not provided then we restore the most recent snapshot.  ",
            "id": "comment-14194522"
        },
        {
            "date": "2014-11-03T14:11:12+0000",
            "author": "Noble Paul",
            "content": "Varun Thacker Can I not restore the data to another core? \n\nIf the \"location\" is not provided in the query string then we default it to core.getDataDir()\n\nwhat is the usecase for restoring from the dataDir itself?\n\nRemove any files in the current directory which does not belong to the segment .\n\nDON'T DO THIS\n\nThere is a mechanism using for loading the index from another directory in the same core. ",
            "id": "comment-14194555"
        },
        {
            "date": "2014-11-03T14:19:06+0000",
            "author": "Varun Thacker",
            "content": "what is the usecase for restoring from the dataDir itself?\n\nWhat I meant here was - if location param is not provided it would see if the backup index is present under dataDir/backupName .\n\nRemove any files in the current directory which does not belong to the segment .\n\nThis is what I do here - Once all the files from the backup location have been successfully copied over the current index, there might be extra segment files from the current index lying around. It gets cleaned up in cleanupOldIndexFiles() where we take the name of the segment file from the backup index and see which files are extra. We then remove these extra segment files. ",
            "id": "comment-14194563"
        },
        {
            "date": "2014-11-03T15:13:26+0000",
            "author": "David Smiley",
            "content": "David Smiley I had not seen that issue previously. Should we move the work there ?\n\nNo, it's too late now.  Next time please search for an existing issue.  SOLR-4545 can be closed as a duplicate so long as you can restore a snapshot without being required to specify its name.  A timestamp would be nice. ",
            "id": "comment-14194608"
        },
        {
            "date": "2014-11-04T07:03:18+0000",
            "author": "Varun Thacker",
            "content": "New patch.\n\nSOLR-4545 can be closed as a duplicate so long as you can restore a snapshot without being required to specify its name. A timestamp would be nice.\n\nDone. How it works is if the backup name is provided it restores the named snapshot. Otherwise it looks in the backup directory for the oldest timestamp backup and restores that.\n\nAdditionally the patch improves the test and shuts down the executor service correctly. ",
            "id": "comment-14195816"
        },
        {
            "date": "2014-11-05T20:53:54+0000",
            "author": "Shalin Shekhar Mangar",
            "content": "Thanks for the patch Varun.\n\nA few comments on the patch and the feature in general:\n\n\tThe usage of restoreLock is wrong. If you issue a second restore then you'll get a IllegalMonitorStateException. The thread which acquires the lock must be the one which releases it. So just calling unlock from another request thread won't work. The RestoreCore thread must be the one to acquire and release the lock (in a finally clause)\n\tYou should cancel the future interruptibly in the close hook. Just executor service's awaitTermination is not enough.\n\tThere are no guarantees here that the previous backup was actually complete before you start restoring it. This might need another issue to fix the snapshoot command itself.\n\tIf restoreFuture is null (no restore has ever been requested), the restore status will return \"in progress\".\n\tConsidering that a restore is a full replace of the older index, we can just use the same index.properties method that SnapPuller uses to ask SolrCore to reload with a new index directory. That would eliminate the copying around files to the index directory.\n\tThere should be an option to not copy files from the source location at all and instead to just use it directly as the new index directory.\n\tWe should be able to rollback to original state (old directory) if the new index fails integrity checks.\n\n\n\nWe need tests for all these scenarios. I'd also like to see more code being refactored and shared between Snapshoot, Snappuller and RestoreCore. ",
            "id": "comment-14199069"
        },
        {
            "date": "2014-11-06T14:25:58+0000",
            "author": "Noble Paul",
            "content": "I believe having a new class RestoreCore for this small functionality is overkill. It can be made part of SnapPuller. If you refactor a bit , both snappull and restore will have a lot of commonalities ",
            "id": "comment-14200216"
        },
        {
            "date": "2014-11-12T18:40:45+0000",
            "author": "Greg Solovyev",
            "content": "I have been looking for this functionality, but with a slight twist where index files for the core need to be shipped over the network rather than provided on storage local to the Solr instance where the core is being restored. I have an implementation of CoreRestoreHandler that takes index files over HTTP as ContentStreams. Should I submit it to this ticket as a patch? ",
            "id": "comment-14208425"
        },
        {
            "date": "2014-11-12T18:53:40+0000",
            "author": "Noble Paul",
            "content": "Please post the patch anyway\n\n ",
            "id": "comment-14208458"
        },
        {
            "date": "2015-02-07T08:31:36+0000",
            "author": "Varun Thacker",
            "content": "Thanks Shalin for the review! I'm sorry it took this long for me to resume working on this.\n\nUpdated patch.\n\nThe usage of restoreLock is wrong. If you issue a second restore then you'll get a IllegalMonitorStateException. The thread which acquires the lock must be the one which releases it.So just calling unlock from another request thread won't work. The RestoreCore thread must be the one to acquire and release the lock (in a finally clause)\n\nThe restore lock is acquired and unlocked by the RestoreCore thread.\n\nYou should cancel the future interruptibly in the close hook. Just executor service's awaitTermination is not enough.\n\nChanged it to ExecutorUtil.shutdownNowAndAwaitTermination(restoreExecutor);\n\nIf restoreFuture is null (no restore has ever been requested), the restore status will return \"in progress\".\n\nFixed.\n\nConsidering that a restore is a full replace of the older index, we can just use the same index.properties method that SnapPuller uses to ask SolrCore to reload with a new index directory. That would eliminate the copying around files to the index directory.\n\nFiles a copied over to a new restore directory and the using the index.properties method we switch the writer/searcher to this directory. If the same backed up segment files is present in the current index directory then that is used as the source for copying. \n\nWe should be able to rollback to original state (old directory) if the new index fails integrity checks.\nIt rolls back to the original index if we are uable to open the restored index. \n\n\n\nSpent a few hours further refactoring SnapPuller so that RestoreCore could use the index diff copying logic in there. But then I realized that SnapPuller always assumes that the source it's fetching from is always ahead of it's current state ( so we don't need to do cleanups if copying into the same directory fails). This would always not be the case when Restoring a core so decided not to go down that path.\n\nTests passed and precommit passes after this svn propset svn:eol-style native ./solr/core/src/java/org/apache/solr/handler/OldBackupDirectory.java ./solr/core/src/java/org/apache/solr/handler/ReplicationUtils.java ./solr/core/src/java/org/apache/solr/handler/RestoreCore.java\n\nWe'll need a slightly different patch for 5x which takes back-compat into consideration while restoring of files in RestoreCore.doRestore() ",
            "id": "comment-14310614"
        },
        {
            "date": "2015-02-09T12:47:24+0000",
            "author": "Varun Thacker",
            "content": "Updated patch.\n\n\n\tMoved all the tests into a separate class TestRestoreCore\n\tUses lucene checksums to to verify if a segment file is same when preferring the local copy.\n\n ",
            "id": "comment-14312186"
        },
        {
            "date": "2015-03-24T13:27:16+0000",
            "author": "Varun Thacker",
            "content": "Updated the patch to trunk ",
            "id": "comment-14377833"
        },
        {
            "date": "2015-03-31T12:49:12+0000",
            "author": "Noble Paul",
            "content": "I have removed the reentrant lock and  the synchronized is good enough . Please take a look ",
            "id": "comment-14388473"
        },
        {
            "date": "2015-04-01T16:37:04+0000",
            "author": "Varun Thacker",
            "content": "Patch which folds in Noble's changes. I think its ready.\n\nIf there are no objections I will commit this to trunk tomorrow and wait a few days before backporting to branch_5x. \n\nAlso the patch would be slightly different on branch_5x as lucene checksums are not guaranteed to exist since there can be pre 4.8 segments ",
            "id": "comment-14390949"
        },
        {
            "date": "2015-04-03T09:46:56+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1671022 from Varun Thacker in branch 'dev/trunk'\n[ https://svn.apache.org/r1671022 ]\n\nSOLR-6637: Solr should have a way to restore a core ",
            "id": "comment-14394256"
        },
        {
            "date": "2015-04-05T14:59:04+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1671400 from Varun Thacker in branch 'dev/trunk'\n[ https://svn.apache.org/r1671400 ]\n\nSOLR-6637: Better error handling when retrieving checksums (Fixes Policeman Jenkins Failure #2134) ",
            "id": "comment-14396266"
        },
        {
            "date": "2015-04-07T19:01:22+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1671919 from Varun Thacker in branch 'dev/branches/branch_5x'\n[ https://svn.apache.org/r1671919 ]\n\nSOLR-6637: Solr should have a way to restore a core (merged from trunk r1671022 r1671400) ",
            "id": "comment-14483809"
        },
        {
            "date": "2015-04-07T19:03:15+0000",
            "author": "Varun Thacker",
            "content": "Thanks everybody! ",
            "id": "comment-14483816"
        },
        {
            "date": "2015-04-08T14:52:39+0000",
            "author": "Mark Miller",
            "content": "Looks like this issue caused SOLR-7364.\n\nYou can't assume a local filesystem when dealing with paths. ",
            "id": "comment-14485335"
        },
        {
            "date": "2015-04-09T06:47:52+0000",
            "author": "Varun Thacker",
            "content": "Oh that looks like my mistake. Sorry about that.\n\nWe need to change this tmpIndex = Paths.get(solrCore.getDataDir(), tmpIdxDirName).toString(); to Paths.get(solrCore.getDataDir()).resolve(tmpIdxDirName).toString();\n\nThere were two more places which need to be corrected. I'll fix them. ",
            "id": "comment-14486843"
        },
        {
            "date": "2015-04-09T10:45:20+0000",
            "author": "Mark Miller",
            "content": "What's the motivation for using Path at all? This doesn't seem right as it's a local filesystem thing? How do we know that is going to work with any DirectoryFactory impl? ",
            "id": "comment-14487137"
        },
        {
            "date": "2015-04-09T12:54:24+0000",
            "author": "Varun Thacker",
            "content": "How do we know that is going to work with any DirectoryFactory impl?\n\nYou're right. It should stay the way it was originally - tmpIndex = solrCore.getDataDir() + tmpIdxDirName; - The HDFS tests rightly fail otherwise.\n\nAlso this got me thinking that backups or restores won't work when using HDFSDir since we write out the backup index using SimpleFSDirectory. I will test it out and create another Jira for it.\n\nShould we add HDFSDir to the list of directories in LuceneTestCase? \n ",
            "id": "comment-14487316"
        },
        {
            "date": "2015-04-10T11:52:45+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1672620 from Varun Thacker in branch 'dev/trunk'\n[ https://svn.apache.org/r1672620 ]\n\nSOLR-6637: can't assume a local filesystem when dealing with paths ",
            "id": "comment-14489481"
        },
        {
            "date": "2015-04-10T13:07:51+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1672641 from Varun Thacker in branch 'dev/branches/branch_5x'\n[ https://svn.apache.org/r1672641 ]\n\nSOLR-6637: can't assume a local filesystem when dealing with paths (merged from trunk r1672620) ",
            "id": "comment-14489571"
        },
        {
            "date": "2015-04-10T13:09:55+0000",
            "author": "Varun Thacker",
            "content": "Resolving this issue. Fixed the broken Path calls. We can tackle backup/restore working correctly on HDFS here SOLR-7374 ",
            "id": "comment-14489589"
        },
        {
            "date": "2015-04-13T15:34:33+0000",
            "author": "Varun Thacker",
            "content": "Need to fix the CHANGES entry. ",
            "id": "comment-14492521"
        },
        {
            "date": "2015-04-14T13:15:50+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1673420 from Varun Thacker in branch 'dev/trunk'\n[ https://svn.apache.org/r1673420 ]\n\nSOLR-6637: improve CHANGES entry + fix wrong usage of path in snapshooter ",
            "id": "comment-14494104"
        },
        {
            "date": "2015-04-14T13:33:10+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1673423 from Varun Thacker in branch 'dev/branches/branch_5x'\n[ https://svn.apache.org/r1673423 ]\n\nSOLR-6637: improve CHANGES entry + fix wrong usage of path in snapshooter (merged from trunk r1673420) ",
            "id": "comment-14494117"
        },
        {
            "date": "2015-04-14T13:33:43+0000",
            "author": "Varun Thacker",
            "content": "Sample Restore API Usage - \nhttp://localhost:8983/solr/techproducts/replication?command=restore&name=backup_name\n\nParameters for the api -\nlocation - The location where the backup index. If not specified it looks for backups in Solr's data directory.\nname - The name of the backed up index snapshot to be restored. If the name is not provided it looks for backups with snapshot.<timestamp> format in the location directory. It picks the latest timestamp backup in that case.\n\nYou can check the status of the operation with the following call -\nhttp://localhost:8983/solr/techproducts/replication?command=restorestatus\n\nSample output for the restore API -\n\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<response>\n   <lst name=\"responseHeader\">\n      <int name=\"status\">0</int>\n      <int name=\"QTime\">0</int>\n   </lst>\n   <lst name=\"restorestatus\">\n      <str name=\"snapshotName\">snapshot.ab</str>\n      <str name=\"status\">success</str>\n   </lst>\n</response>\n\n\n\nThe status value can be \"In Progress\" , \"success\" or \"failed\". If it failed then an \"exception\" will also be sent in the response. ",
            "id": "comment-14494119"
        },
        {
            "date": "2015-04-14T13:35:23+0000",
            "author": "Varun Thacker",
            "content": "Improved the CHANGES entry, added API examples. The Ref Guide will also be updated after the 5.1 Ref Guide release. ",
            "id": "comment-14494120"
        },
        {
            "date": "2015-05-14T23:51:23+0000",
            "author": "Greg Solovyev",
            "content": "Would it make sense to add an ability to upload index files to target Solr instance via HTTP using ContentStreams or is it a bad idea for any reason? ",
            "id": "comment-14544636"
        },
        {
            "date": "2015-05-19T18:27:35+0000",
            "author": "Greg Solovyev",
            "content": "Posted my patch to this subtask: https://issues.apache.org/jira/browse/SOLR-7567 ",
            "id": "comment-14550955"
        },
        {
            "date": "2015-06-15T21:44:15+0000",
            "author": "Anshum Gupta",
            "content": "Bulk close for 5.2.0. ",
            "id": "comment-14586902"
        },
        {
            "date": "2016-04-14T17:41:18+0000",
            "author": "David Smiley",
            "content": "While working on SOLR-5750 (Collection level backup/restore), I read the code for RestoreCore and I'm confused why the \"prefer local copy\" logic is expressly avoided for these file extensions: .si, .liv, and the segments_.  Why these files?  It seems arbitrary and there are no comments saying why.  Do you know Varun Thacker? ",
            "id": "comment-15241575"
        },
        {
            "date": "2016-05-02T04:20:19+0000",
            "author": "Varun Thacker",
            "content": "Hi David,\n\nThe idea came when we were working on issues are replication causing index corruption : Here is a related Jira comment : https://issues.apache.org/jira/browse/SOLR-6920?focusedCommentId=14309370&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14309370\n\nThe actual impl. is in {[IndexFetcher#filesToAlwaysDownloadIfNoChecksums}} . Maybe we could reuse that method ? ",
            "id": "comment-15266100"
        },
        {
            "date": "2016-05-02T04:31:35+0000",
            "author": "David Smiley",
            "content": "Maybe we could reuse that method?\n\n+1 Most definitely.  The change to re-use this method is minor enough that I'll just slide it into SOLR-5750. ",
            "id": "comment-15266104"
        },
        {
            "date": "2016-05-13T17:47:00+0000",
            "author": "Hrishikesh Gadre",
            "content": "Varun Thacker Shalin Shekhar Mangar\n\nPlease take a look at this code snippet,\n\nhttps://github.com/apache/lucene-solr/blob/4193e60b9fc1ff12df2267778213ae3b0f04fb84/solr/core/src/java/org/apache/solr/handler/IndexFetcher.java#L605-L617\n\nIs there a specific reason why we have used \"SegmentInfos.readCommit(...)\" method instead of just using \"commit.getFileNames()\" ? It seems equivalent as per my code understanding but not sure if I have missed anything... ",
            "id": "comment-15282912"
        },
        {
            "date": "2016-05-14T08:04:37+0000",
            "author": "Shalin Shekhar Mangar",
            "content": "Is there a specific reason why we have used \"SegmentInfos.readCommit(...)\" method instead of just using \"commit.getFileNames()\" ? It seems equivalent as per my code understanding but not sure if I have missed anything...\n\nI am not sure. Does commit.getFileNames() return the live files as well? ",
            "id": "comment-15283476"
        }
    ]
}