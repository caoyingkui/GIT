{
    "id": "SOLR-743",
    "title": "Update the bitset usage in Schema to enums",
    "details": {
        "affect_versions": "None",
        "status": "Closed",
        "fix_versions": [
            "1.4"
        ],
        "components": [],
        "type": "Improvement",
        "priority": "Minor",
        "labels": "",
        "resolution": "Invalid"
    },
    "description": "For all of the reasons given by smarter people than I (specifically, Effective Java), and because its just easier to follow.",
    "attachments": {
        "SOLR-743.patch": "https://issues.apache.org/jira/secure/attachment/12389234/SOLR-743.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Yonik Seeley",
            "id": "comment-12627220",
            "date": "2008-08-30T17:01:51+0000",
            "content": "I worked hard to keep some of this code fast... I'd hate to see it slowed down in the name of type-safety (esp in code that Solr users don't have to interface with). "
        },
        {
            "author": "Mark Miller",
            "id": "comment-12627253",
            "date": "2008-08-30T21:03:01+0000",
            "content": "enums are shorter, clearer, and safer. if under 64 options, they are represented by a long and set operations are done with bitwise arithmetic, so while its going to be a bit slower, if its measurable I'd be pretty surprised (though I guess I'll be happy to measure). Some programmers still cling to bitsets, but I buy Josh Blochs arguments that the bitset is better left behind in favor of the enum - its just better code. I'll go with whatever the community wants though - this patch just presents an option.\n\n\n\tMark\n\n "
        },
        {
            "author": "Mark Miller",
            "id": "comment-12627260",
            "date": "2008-08-30T23:28:31+0000",
            "content": "Had a bit of debug in one of those classes. Also went through to make sure everything was still being done with bit twiddling. I can't imagine any speed loss with this  wouldn't be worth the clearer more maintainable code (though i should still try and work around calling ordinal() in there). "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12627468",
            "date": "2008-09-01T14:18:46+0000",
            "content": "Neither patch will apply cleanly for some reason.... anyone else? "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12627476",
            "date": "2008-09-01T14:55:20+0000",
            "content": "they are represented by a long and set operations are done with bitwise arithmetic\n\nInternally, it's done with bitwise arithmetic...  but there is a lot of surrounding/supporting code that will take much longer to execute.\n\nI buy Josh Blochs arguments that the bitset is better left behind in favor of the enum\n\nAs a general rule, perhaps, but advice like this has to be taken in the context of the broad java dev world.  The majority of Java developers out there are building specific biz apps that one can either say meet or don't meet performance targets.  If those targets aren't met, then they can profile and find the problem spot.  Library and framework developers are a bit different IMO and the complexity / performance tradeoff shifts.  I bet you won't see any of the internal native bitvectors in the Java class libraries switching to EnumSet. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12627477",
            "date": "2008-09-01T15:03:10+0000",
            "content": "OK, some performance results:\nSetup: P4, WinXP, Java6 -server\n\nTest: loop over all dynamic fields in the test schema, creating a new SchemaField from a prototype (as is done for each dynamic field accessed) and then test all it's properties (done for each field indexed).\n\nsolr trunk: 10391ms\nthis patch: 110891ms\n\nTest: loop over all dynamic fields in the test schema and test all it's properties.\n\nsolr trunk: 6656ms\nthis patch: 17531ms "
        },
        {
            "author": "Mark Miller",
            "id": "comment-12627503",
            "date": "2008-09-01T16:54:46+0000",
            "content": "Okay, I'm surprised at the results, but I suppose they are what they  \nare. The onus should really be on me to prove the patch rather than  \nyou to disprove it, but thanks for saving me the time \n\nStill, I'm looking further at how I am doing it, it seems odd it would  \nbe that much slower.  Method calls and a long shouldn't cost so much.  \nIf it is really that much slower, I switch my claim that I buy joshs  \nargument (which is not laid out as general advice). If it's that much  \nslower, he is wrong.\n\n\n\tMark\n\n\n\n\nOn Sep 1, 2008, at 11:04 AM, \"Yonik Seeley (JIRA)\" <jira@apache.org>  \n "
        },
        {
            "author": "Mark Miller",
            "id": "comment-12627551",
            "date": "2008-09-01T23:48:51+0000",
            "content": "Any chance on sharing the test code used for that ? "
        },
        {
            "author": "Mark Miller",
            "id": "comment-12627552",
            "date": "2008-09-01T23:55:31+0000",
            "content": "As a general rule, perhaps, but advice like this has to be taken in the context of the broad java dev world. The majority of Java developers out there are building specific biz apps that one can either say meet or don't meet performance targets. If those targets aren't met, then they can profile and find the problem spot. Library and framework developers are a bit different IMO and the complexity / performance tradeoff shifts. I bet you won't see any of the internal native bitvectors in the Java class libraries switching to EnumSet.\n\nHis advice, from my read, is that the performance penalty is small enough so that you can clearly say, there is no reason to use the bitset. Thats how I read it anyway. The performance measurements you gave refute that - if those numbers are accurate, at most, you can say, in general use enum, for performance spots you still should be looking at bitsets. Bloch says, drop the bitset, the performance loss is easily outweighed unqualified. With those losses, I easily agree with you that the performance loss is not outweighed (not even close?) - in addition, we are not doing something special - we are doing a classic case, with classic code. Thats why I still suspect maybe i have missed somewhere that is not doing bits, though I was pretty thorough in my check... "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12627684",
            "date": "2008-09-02T13:59:03+0000",
            "content": "Any chance on sharing the test code used for that ? \n\nI checked it in for future reference.... it's commented out in BasicFunctionalityTest.\n\n\n  public void testFieldPerf() {\n    IndexSchema schema = h.getCore().getSchema();\n    SchemaField[] fields = schema.getDynamicFieldPrototypes();\n    boolean createNew = false;\n\n    long start = System.currentTimeMillis();\n    int ret = 0;\n    for (int i=0; i<10000000; i++) {\n      for (SchemaField f : fields) {\n        if (createNew) f = new SchemaField(f, \"fakename\");\n        if (f.indexed()) ret += 1;\n        if (f.isCompressed()) ret += 2;\n        if (f.isRequired()) ret += 3;\n        if (f.multiValued()) ret += 4;\n        if (f.omitNorms()) ret += 5;\n        if (f.sortMissingFirst()) ret += 6;\n        if (f.sortMissingLast())ret += 7;\n        if (f.stored()) ret += 8;\n        if (f.storeTermOffsets()) ret += 9;\n        if (f.storeTermPositions()) ret += 10;\n        if (f.storeTermVector()) ret += 11;\n      }\n    }\n    long end = System.currentTimeMillis();\n    System.out.println(\"ret=\" + ret + \" time=\"+ (end-start));\n\n\n\nA native bitwise-and + check for non-zero is a single cycle instruction (TEST in x86).  Consider everything else that needs to be done for EnumSet.contains()\n\n\tpossible null check on the EnumSet instance, method call, then null check on the param\n\tgetClass() and compare to check to see that the enum being checked for is of the right class (COLOR and not SUIT, etc)\n\tcast to Enum type, get the ordinal value, do a shift by that value, then do the bitwise-and.\n\n\n "
        },
        {
            "author": "Mark Miller",
            "id": "comment-12628325",
            "date": "2008-09-04T12:37:42+0000",
            "content": "I still have interest in going over this myself, but as far as solr is concerned, I suppose I'll trust the words of the Father. "
        },
        {
            "author": "David Smiley",
            "id": "comment-12629147",
            "date": "2008-09-08T13:02:13+0000",
            "content": "Although it is slower (which doesn't surprise me), does it really matter?\nI think it's a shame to still use the ancient techniques of an int bitset.  I've been cringing as I look over this code lately.  Since the code is already written and it is admittedly faster... there isn't a strong motivation to switch it.  But if it hadn't been written yet, I would be hard put to use an int bitset unless I knew an EnumSet would be a bottleneck (and I wouldn't). "
        },
        {
            "author": "Mark Miller",
            "id": "comment-12629160",
            "date": "2008-09-08T13:39:21+0000",
            "content": "Although it is slower (which doesn't surprise me), does it really matter?\n\nRight...of course its going to be slower, but my guess was that it was slower in a way that compiler/hotspot optimizations, nature of the code, etc, would make the difference not really matter (its what effective java seemed to indicate, and since he wrote the code..). \n\nBut the results yonik posted...if thats the slowdown, I don't see moving as an option...and if we were using enums I'd vote for a switch to bitset. Seems like quite a difference to me (though I still havn't had time to educate myself with the test code used).\n "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12775526",
            "date": "2009-11-10T15:51:47+0000",
            "content": "Bulk close for Solr 1.4 "
        }
    ]
}