{
    "id": "SOLR-12259",
    "title": "Robustly upgrade indexes",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [],
        "type": "Improvement",
        "fix_versions": [],
        "affect_versions": "None",
        "resolution": "Unresolved",
        "status": "Open"
    },
    "description": "The general problem statement is that the current upgrade path is trappy and cumbersome.  It would be a great help \"in the field\" to make the upgrade process less painful.\n\nAdditionally one of the most common things users want to do is enable docValues, but currently they often have to re-index.\n\nIssues:\n\n1> if I upgrade from 5x to 6x and then 7x, theres no guarantee that when I go to 7x all the segments have been rewritten in 6x format. Say I have a segment at max size that has no deletions. It'll never be rewritten until it has deleted docs. And perhaps 50% deleted docs currently.\n\n2> IndexUpgraderTool explicitly does a forcemerge to 1 segment, which is bad.\n\n3> in a large distributed system, running IndexUpgraderTool on all the nodes is cumbersome even if <2> is acceptable.\n\n4> Users who realize specifying docValues on a field would be A Good Thing have to re-index. We have UninvertDocValuesMergePolicyFactory. Wouldn't it be nice to be able to have this done all at once without forceMerging to one segment.\n\nProposal:\n\nSomehow avoid the above. Currently LUCENE-7976 is a start in that direction. It will make TMP respect max segments size so can avoid forceMerges that result in one segment. What it does not do is rewrite segments with zero (or a small percentage) deleted documents.\n\nSo it  doesn't seem like a huge stretch to be able to specify to TMP the option to rewrite segments that have no deleted documents. Perhaps a new parameter to optimize?\n\nThis would likely require another change to TMP or whatever.\n\nSo upgrading to a new solr would look like\n1> install the new Solr\n2> execute \"http://node:port/solr/collection_or_core/update?optimize=true&upgradeAllSegments=true\"\n\nWhat's not clear to me is whether we'd require UninvertDocValuesMergePolicyFactory to be specified and wrap TMP or not.\n\nAnyway, let's discuss. I'll create yet another LUCENE JIRA for TMP do rewrite all segments that I'll link.\n\nI'll also link several other JIRAs in here, they're coalescing.",
    "attachments": {
        "SOLR-12259.patch": "https://issues.apache.org/jira/secure/attachment/12946637/SOLR-12259.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2018-04-22T16:02:43+0000",
            "content": "I should stress that this JIRA will address a subset of the upgrade issues.  For most schema changes and the like, the information you'd need to \"fix\" things just isn't available. For instance, let's say you index without term positions and then decide you need to support phrase queries. The information is just gone, there's no way Solr, Lucene or an Act of Congress can get it back without reindexing from the source. Ditto \"oops, we shouldn't have included that word in our stopwords\". \"I need to include term vectors\" etc.\n\nThe idea here is to support what we can now. So far there are two things:\n1> rewrite into the current format\n2> add DocValues=true to a field.\n\nUpgradeIndexMergePolicyFactory and UninvertDocValuesMergePolicyFactory seem like the building blocks here.\n\nBrainstorming here, all ideas welcome! ",
            "author": "Erick Erickson",
            "id": "comment-16447276"
        },
        {
            "date": "2018-10-12T18:21:15+0000",
            "content": "The more I think about this, the less I like overriding optimize. The intent here is that for certain situations it's beneficial to rewrite all segments, but they are special-purpose/expert.\n\nWhat do people think about just a new command that doesn't have all the baggage that optimize has? Something like:\n\nblahblahblah/update?rewriteIndex=true\n\nor similar. I want to avoid upgradeIndex since it has the flavor of allowing X->X+1->X+2 without re-indexing. ",
            "author": "Erick Erickson",
            "id": "comment-16648265"
        },
        {
            "date": "2018-10-19T14:17:59+0000",
            "content": "I like the proposal in your last comment here \u2013 a new \"rewriteIndex=true\" and not conflate this with \"optimize\".  I'm not sure it should be some parameter since it's so rare to do this and it's not something you'd do on the fly.  It seems to me it's logically some admin operation.  Heck, perhaps, optimize ought to be an admin operation too  ",
            "author": "David Smiley",
            "id": "comment-16656849"
        },
        {
            "date": "2018-10-19T16:06:03+0000",
            "content": "Thanks for opening this Jira Erick, upgrading is a major issue for us too. \n+1 for not mixing things with the optimize command. I think that one has a different objective (regardless of if in fact re-writes segments). How do you feel about making a new Request Handler instead, that we could include in the solrconfig (or implicit, like /update), that way we don\u2019t pollute the UpdateHandler with upgrading logic and don\u2019t mix the APIs with different kinds of parameters that this handler could accept. Something like:\n\n/solr/collection_or_core/upgrade\n\nIn this endpoint we could include logic for upgrading Lucene/Solr versions (now maybe only upgrading the index, but maybe more things in the future, things like \u201cMIGRATESTATEFORMAT\u201d collection API could belong here too). I\u2019m also thinking this endpoint could provide information regarding upgrades (in a sort of dry-run option), like:\n\n/solr/collection_or_core/upgrade?action=status\nAnd return something like (this is just a random example):\n\nindex:\n\u00a0\u00a0\u00a0 creationVersion:Lucene 6.3\n\u00a0\u00a0\u00a0 codecVersion:Lucene 6.1\n    segment versions:[...]\n    canUpgrade: YES\nSolr:\n    runningVersions: [7.3,6.3] \n    clusterStateFormat: legacy\n...\n\n\n\nThen the user could do a: /solr/collection_or_core/upgrade?action=upgradeIndex or something like that to start an upgrade in the index, Solr would then check whatever it can to see if the upgrade is possible, do core/collections calls, or whatever it needs to do to upgrade. ",
            "author": "Tom\u00e1s Fern\u00e1ndez L\u00f6bbe",
            "id": "comment-16657001"
        },
        {
            "date": "2018-10-24T00:54:09+0000",
            "content": "I was thinking about\u00a0 this on the way back from Activate. One of the issues we'll have is the fact that it'd be a mess to support arbitrary upgrade paths for all the reasons in LUCENE-7976. Doing \"whatever it can\" is so fraught.\n\nTHIS IS A STRAW MAN PROPOSAL. Feel free to shoot holes in it.....\n\nIn essence, this could be thought of as using custom merge policies do \"do the right thing\", where the \"right thing\" varied (and will continue to vary going forward).\n\nHere's what I came up with as design goals:\n > transform all segments in an core.\n > can upgrade collections/cores individually even if collections shared a configset\n > extensible in future\n > can deal with \"safe\" X+2 upgrades if there ever are any.\n > should not require restarting Solr\n > should not require special solrconfig.xml\u00a0changes\n > may require enabling the new end-point. Possibly a new config API? Maybe require a config API call to enable/disable?\n\nWhat I have in mind is a new request handler that\u00a0\n\n> locks the index for updates until done. I'm not horribly comfortable with this but it would circumvent a world of problems.\n > applied a (possibly custom) merge policy that would implement what's desired\u00a0on all segments without merging. This is essentially a \"singleton merge\" on each segment regardless of its state. We could, of course, skip segments that didn't require the transformation. This is somewhat along the lines of UninvertDocValuesMergePolicyFactory\n> A prime candidate we would supply would be upgrade to docValues fields.\n\nNote that the merge policy in effect at the client would not be changed at all.  Say I was running TMP. This would come in completely around the end and not change that at all. We'd probably have to supply a new merge policy to be used by this end-point.\n\nThe reason I don't want to merge segments is that it would get weird having to make the different merge policies do the right thing, NoMergePolicy is particularly problematic \n\nThe simple case here would require a full rewrite of all segments for each transformation, which is a drawback. OTOH, until we have examples of multiple transformations we want to happen, maybe we can go with it for now.\n\nConceivably this could be used for special-purpose upgraded with limited scope that could do the X->X+2 upgrade. I have no concrete examples of what would be safe and I certainly don't want to distribute any such thing as part of Solr. Having the mechanism in place could allow users to make their own (at their own risk). Or call Uwe...\n\nComments? ",
            "author": "Erick Erickson",
            "id": "comment-16661538"
        },
        {
            "date": "2018-10-24T12:52:40+0000",
            "content": "You refer to upgrading to version X+2 but isn't only X+1 supported?  I forget.\n\nIt's not clear we need to do any special locking; I think that would make things more complicated because merging is already handled concurrently within Lucene.  I imagine that to support this, we'd have a delegating MergePolicy that is able to, when told, not delegate to the true MP and instead do something different.  Something along those lines any way.  The alternative would be closing the current IndexWriter and re-opening a new one with the upgrading MP while the upgrade is in progress... but that seems very difficult or near impossible to coordinate with the rest of Solr's internals that may already be in the middle of indexing. ",
            "author": "David Smiley",
            "id": "comment-16662251"
        },
        {
            "date": "2018-10-24T17:05:11+0000",
            "content": "can deal with \"safe\" X+2 upgrades if there ever are any.\n\nCertainly X+2 is not supported. If (and only if) there are situations where it would be safe, then it could conceivably do some low-level tricks to spoof the rewritten segments with version stamp X. That is not something I advocate be part of Solr, but with this notion it's possible to do if an existing Solr installation wants to.\n\nI'm not sure index locking is necessary, conceptually it's simpler and I wanted to throw it out. Another idea is to rewrite just a few (or just one) segment(s) at a time that needed whatever modification the merge policy is implementing and optionally do a commit periodically to flush the fieldCache. Or flush the field cache as a byproduct. Or.... The point would be to keep the fieldCache from getting too big.\n\nOne thing I'm not sure of (this is brainstorming after all) is if we do use a new endoint that rewrites segments, and assuming we don't lock out updates, insure that any segments rewritten by this new endpoint don't also get merged by the background merging process. ",
            "author": "Erick Erickson",
            "id": "comment-16662554"
        },
        {
            "date": "2018-10-24T17:27:01+0000",
            "content": "In addition to the issues mentioned on SOLR-11127 (upgrading .system collection schema from Trie to Points fields), Solr needs somehow to be able to re-index the .system collection on major version upgrade, because of the unsupported index version N-2 problem. ",
            "author": "Steve Rowe",
            "id": "comment-16662584"
        },
        {
            "date": "2018-10-26T20:48:15+0000",
            "content": "Michael McCandlessRobert MuirAdrien GrandAlan Woodward I'm particularly interested in any comments any of you have about the straw-man proposal I posted on the 24th (and following messages).\n\nI should reiterate that this is allowing for a one-off at-the-client's-own-risk kind of thing, not any attempt to saddle Lucene with responsibility for upgrades!\n\nI think there are some minimally-intrusive things that might be added to Lucene. In one scenario I've imagined a couple of additional interface methods for MergePolicy that would be no-ops unless specifically needed, we will discuss them before implementing any specifics.\n\nThe bit that worries me most is the co-existence of some custom merge policy operating on the existing segments at the same time the merge policy configured for normal operations was running and possibly merging. Does that problem seem tractable to you without having to suspend indexing?\n\nComments? ",
            "author": "Erick Erickson",
            "id": "comment-16665657"
        },
        {
            "date": "2018-10-31T02:46:02+0000",
            "content": "I'm having a design problem here. At the Solr level, we have MergePolicyFactory, while at the Lucene level we have MergePolicy. All well and good.\n\nHowever, I need to mix them up a bit and it's A Bad Idea to\u00a0have\u00a0Lucene be aware of anything\u00a0having to do with Solr.\n\nSo I'm coding up a new MergePolicy and associated Factory.\u00a0I can assign\u00a0the MergePolicy\u00a0to an IndexWriter and call writer.forceMerge and the writer calls findForcedMerges in my new policy. At that point I need to make decisions on which if any\u00a0of\u00a0the segments passed to findForcedMerges needs to be merged/rewritten. And some of the information I need is only available at the Solr level, in this case I need to compare the schema definitions against the info in the segments.\n\nIdeally, I want to do something in findForcedMerges like:\n\nfor (each segment in segmentInfos) { \u00a0 \u00a0 \u00a0\n   if (Solr thinks it should be rewritten)\u00a0 { put it in the real merge list }\n}\n\n\nWhat I'm having trouble with is figuring out how to reach back out into Solr and evaluate the \"if (Solr thinks it should be rewritten)\" part without doing violence to Lucene.\n\nIt seems like a function pointer that I could set in my MergePolicy could do the trick, but that seems complicated. And even if I could, is that even acceptable architecturally since it's code in Solr? Albeit, there's no dependency on Solr here, a Java function in anybody's calling code could set it. It would take a seginfo and return true or false. Oh for the old C days when a function pointer was just an int....\n\nOr is the right thing to do just put\u00a0any new MergePolicy in Solr where it can be aware of other \"Solr stuff\"?\n\nAny comments\u00a0Michael McCandless\u00a0Robert Muir\u00a0Adrien Grand\u00a0Alan Woodward\u00a0? ",
            "author": "Erick Erickson",
            "id": "comment-16669525"
        },
        {
            "date": "2018-10-31T12:59:43+0000",
            "content": "Erick Erickson: maybe make the Lucene MergePolicy have an abstract method boolean shouldRewrite(SegmentCommitInfo)? ",
            "author": "Steve Rowe",
            "id": "comment-16670063"
        },
        {
            "date": "2018-11-01T17:55:02+0000",
            "content": "Christine Poerschke So right here on my list it says \"create a test\" for the work here. WDYT of co-opting\u00a0\n\nUninvertDocValuesMergePolicyTest? IOW, how lazy can I be?\n\nI took a quick look at it and I think all I'd need to do is replace the optimize step at line 114 with a call to my new spiffy rewriteWithPolicy update parameter.\n\nHmmm, I suppose that really I could just randomize the optimize and rewriteWithPolicy approaches.\n\nI want to  emphasize to everyone that overloading update is a PoC bit only so we can poke holes in the general approach, TBD is where this stuff really lives. ",
            "author": "Erick Erickson",
            "id": "comment-16671938"
        },
        {
            "date": "2018-11-02T01:23:02+0000",
            "content": "Preliminary patch in case anyone's interested in looking at the approach. I have to leave tomorrow and won't be back at this until next week.\n\n> I consider this a PoC, meaning it demonstrates that the approach can work in a limited environment. If nobody shoots holes in the general idea it then needs a lot of polish\n > There are a ton of nocommit's\n > I'm thinking that what we really want here is a new endpoint rather than spoofing an update command. Before doing that I wanted to see whether the idea would work at all. \n > I've hardcoded a values that have to change, for example the hard 5G limit to merged segments.\n\nThe main bits are in DirectUpdateHandler2.rewriteSegments where the code:\n > intercepts the update command that looks like: \"....core/update?commit=true&rewriteWithPolicyFactory=org.apache.solr.index.RewriteWithDocValuesMergePolicyFactory\"\n > Substitutes the specified factory in liveConfig\n > forceMerges while respecting max segment size\n > sets the old factory back in liveConfig\n\n  private void rewriteSegments(IndexWriter writer, String policyFactory) throws IOException {\n\n    LiveIndexWriterConfig liveConfig = writer.getConfig();\n    MergePolicy oldPolicy = liveConfig.getMergePolicy();\n    try {\n      Class<?> factory = core.getResourceLoader().getClassLoader().loadClass(policyFactory);\n      Constructor constructor =\n          factory.getDeclaredConstructor(SolrResourceLoader.class, MergePolicyFactoryArgs.class, IndexSchema.class);\n      MergePolicyFactory newFactory = (MergePolicyFactory)constructor.newInstance(core.getResourceLoader(), new MergePolicyFactoryArgs(), core.getLatestSchema());\n      liveConfig.setMergePolicy(newFactory.getMergePolicy());\n      writer.forceMerge(Integer.MAX_VALUE, true); // nocommit MAX_VALUE? Wait? Really?\n    } catch (IllegalAccessException | InstantiationException | ClassNotFoundException | NoSuchMethodException |\n        InvocationTargetException e) {\n        String msg = String.format(Locale.ROOT, \"Could not instantiate %s MergePolicyFactory\", policyFactory);\n        log.error(msg);\n        throw new RuntimeException(msg, e);\n    } finally {\n      liveConfig.setMergePolicy(oldPolicy);\n    }\n  }\n\n\nHere's what I guarantee:\n > it compiles\n > it runs TestTieredMergePolicy and the (modified) UninvertDocValuesMergePolicyTest that exercises this process\n\nHere's what I don't guarantee:\n > I didn't break a bunch of other tests\n > precommit passes\n > it works when active indexing is going on\n > About a zillion other things that occurred to me, you'll see lots of questions in nocommits\n\nThe biggest questions I have at this point is what happens if indexing and background merging is all going on at the same time this is running.....\n\nAll comments welcome, especially around gotcha's people already know about. ",
            "author": "Erick Erickson",
            "id": "comment-16672469"
        },
        {
            "date": "2018-11-05T15:38:42+0000",
            "content": "Maybe you could abstract out the Solr specific parts under an interface / abstract class or something, and you pass an instance of that to the merge policy? ",
            "author": "Michael McCandless",
            "id": "comment-16675320"
        },
        {
            "date": "2018-11-05T19:28:11+0000",
            "content": "... WDYT of co-opting UninvertDocValuesMergePolicyTest? ... all I'd need to do is replace the optimize step at line 114 with a call to my new ...\nSince UninvertDocValuesMergePolicy and RewriteWithDocValuesMergePolicy do similar things them sharing test code doesn't seem unreasonable to me \u2013 perhaps UninvertDocValuesMergePolicyTest could be renamed somehow (RewritingMergePoliciesTest?) to reflect the extended dual coverage?\n... I could just randomize the optimize and rewriteWithPolicy approaches. ...\n+1 ",
            "author": "Christine Poerschke",
            "id": "comment-16675651"
        }
    ]
}