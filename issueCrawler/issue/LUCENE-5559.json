{
    "id": "LUCENE-5559",
    "title": "Argument validation for TokenFilters having numeric constructor parameter(s)",
    "details": {
        "type": "Improvement",
        "priority": "Minor",
        "labels": "",
        "resolution": "Fixed",
        "components": [
            "modules/analysis"
        ],
        "affect_versions": "4.7",
        "status": "Closed",
        "fix_versions": [
            "4.8",
            "6.0"
        ]
    },
    "description": "Some TokenFilters have numeric arguments in their constructors. They should throw IllegalArgumentException for negative or meaningless values. \n\nHere is some examples that demonstrates invalid/meaningless arguments :\n\n\n <filter class=\"solr.LimitTokenCountFilterFactory\" maxTokenCount=\"-10\" />\n\n\n\n\n <filter class=\"solr.LengthFilterFactory\" min=\"-5\" max=\"-1\" />\n\n\n\n\n <filter class=\"solr.LimitTokenPositionFilterFactory\" maxTokenPosition=\"-3\" />",
    "attachments": {
        "LUCENE-5559.patch": "https://issues.apache.org/jira/secure/attachment/12637483/LUCENE-5559.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "id": "comment-13951194",
            "author": "Ahmet Arslan",
            "content": "NGramTokenFilte, EdgeNGramTokenFilter, NGramTokenizer andEdgeNGramTokenizer have this check\n\n  \n    if (minGram < 1) {\n      throw new IllegalArgumentException(\"minGram must be greater than zero\");\n    }\n    if (minGram > maxGram) {\n      throw new IllegalArgumentException(\"minGram must not be greater than maxGram\");\n    }\n\n  \n\nIt is necessary to add checks to Factory classes too? ",
            "date": "2014-03-28T18:35:20+0000"
        },
        {
            "id": "comment-13951236",
            "author": "Robert Muir",
            "content": "I don't think the factories need anything if you will already hit the check from the Filter itself.\n\nBut if the factory would crash in some way that is confusing on certain inputs, then it would need a check too. ",
            "date": "2014-03-28T18:55:38+0000"
        },
        {
            "id": "comment-13951271",
            "author": "Ahmet Arslan",
            "content": "initial patch for LimitTokenCountFilter, LengthFilter and LimitTokenPositionFilter. This patch adds new TestLimitTokenCountFilter class. TokenFilters are responsible for argument validation. ",
            "date": "2014-03-28T19:23:38+0000"
        },
        {
            "id": "comment-13951275",
            "author": "Ahmet Arslan",
            "content": "ShingleFilter is OK in that sense. Only difference is that validity check repeated in ShingleFilterFactory too. ",
            "date": "2014-03-28T19:26:03+0000"
        },
        {
            "id": "comment-13951295",
            "author": "Ahmet Arslan",
            "content": "UAX29URLEmailTokenizer, StandardTokenizer and ClassicTokenizer added. ",
            "date": "2014-03-28T19:57:34+0000"
        },
        {
            "id": "comment-13951296",
            "author": "Ahmet Arslan",
            "content": "DictionaryCompoundWordTokenFilter, HyphenationCompoundWordTokenFilter, PathHierarchyTokenizer and ReversePathHierarchyTokenizer are OK.\n\nTokenRangeSinkFilter has (int lower, int upper) but I am not sure their valid values. ",
            "date": "2014-03-28T19:58:15+0000"
        },
        {
            "id": "comment-13951497",
            "author": "Ahmet Arslan",
            "content": "TokenRangeSinkFilter aded ",
            "date": "2014-03-28T22:22:31+0000"
        },
        {
            "id": "comment-13951505",
            "author": "Ahmet Arslan",
            "content": "In SinkTokenTest files, license header starts with this line  \n\nCopyright 2004 The Apache Software Foundation \n ",
            "date": "2014-03-28T22:25:31+0000"
        },
        {
            "id": "comment-13951508",
            "author": "Ahmet Arslan",
            "content": "TokenRangeSinkFilter aded ",
            "date": "2014-03-28T22:26:48+0000"
        },
        {
            "id": "comment-13954634",
            "author": "Uwe Schindler",
            "content": "Hi Achmet,\n\n\n+  public void test() throws Exception {\n+    MockTokenizer tokenizer = whitespaceMockTokenizer(\"A1 B2 C3 D4 E5 F6\");\n+    // LimitTokenCountFilter doesn't consume the entire stream that it wraps\n+    tokenizer.setEnableChecks(false);\n+    TokenStream stream = new LimitTokenCountFilter(tokenizer, 3);\n+    assertTokenStreamContents(stream, new String[]{\"A1\", \"B2\", \"C3\"});\n+  }\n\n\n\nLimitTokenCount (and others like LimitPosition*) filter has the option to consume all tokens. Maybe better check this configuration, so the tokenizer can have checks enabled. ",
            "date": "2014-03-30T10:10:09+0000"
        },
        {
            "id": "comment-13954876",
            "author": "Ahmet Arslan",
            "content": "Hi Uwe,\n\nI copied/applied the following 'for loop logic' from TestLimitTokenCountAnalyzer to TestLimitToken(Position|Count)Filter(Factory)\n\n\n for (boolean consumeAll : new boolean[] { true, false }) {      \n      MockAnalyzer mock = new MockAnalyzer(random());\n      // if we are consuming all tokens, we can use the checks, otherwise we can't\n      mock.setEnableChecks(consumeAll);      \n      new LimitTokenCountAnalyzer(mock, 2, consumeAll);      \n}\n\n\n ",
            "date": "2014-03-30T23:53:14+0000"
        },
        {
            "id": "comment-13956099",
            "author": "ASF subversion and git services",
            "content": "Commit 1583530 from Robert Muir in branch 'dev/trunk'\n[ https://svn.apache.org/r1583530 ]\n\nLUCENE-5559: Add missing checks to TokenFilters with numeric arguments ",
            "date": "2014-04-01T04:43:03+0000"
        },
        {
            "id": "comment-13956103",
            "author": "ASF subversion and git services",
            "content": "Commit 1583531 from Robert Muir in branch 'dev/branches/branch_4x'\n[ https://svn.apache.org/r1583531 ]\n\nLUCENE-5559: Add missing checks to TokenFilters with numeric arguments ",
            "date": "2014-04-01T04:52:29+0000"
        },
        {
            "id": "comment-13956105",
            "author": "Robert Muir",
            "content": "Thanks for cleaning this up Ahmet! ",
            "date": "2014-04-01T04:52:58+0000"
        },
        {
            "id": "comment-13961594",
            "author": "Ahmet Arslan",
            "content": "This patch added checks for overlooked TokenFilters : CapitalizationFilter and CodepointCountFilter. ",
            "date": "2014-04-07T00:50:13+0000"
        },
        {
            "id": "comment-13980175",
            "author": "Ahmet Arslan",
            "content": "Pinging Robert Muir, if there is an interest for last patch that covers two overlooked TokenFilters : CapitalizationFilter and CodepointCountFilter ",
            "date": "2014-04-24T19:57:22+0000"
        },
        {
            "id": "comment-13980187",
            "author": "Robert Muir",
            "content": "Oops, looks like i missed this patch? thanks Ahmet. I will take care. ",
            "date": "2014-04-24T20:06:44+0000"
        },
        {
            "id": "comment-13980202",
            "author": "Ahmet Arslan",
            "content": "looks like i missed this patch?\nNo, actually I found those two after your commit. ",
            "date": "2014-04-24T20:12:17+0000"
        },
        {
            "id": "comment-13980617",
            "author": "ASF subversion and git services",
            "content": "Commit 1589919 from Robert Muir in branch 'dev/trunk'\n[ https://svn.apache.org/r1589919 ]\n\nLUCENE-5559: additional argument validation for CapitalizationFilter and CodepointCountFilter ",
            "date": "2014-04-25T01:54:20+0000"
        },
        {
            "id": "comment-13980625",
            "author": "ASF subversion and git services",
            "content": "Commit 1589922 from Robert Muir in branch 'dev/branches/branch_4x'\n[ https://svn.apache.org/r1589922 ]\n\nLUCENE-5559: additional argument validation for CapitalizationFilter and CodepointCountFilter ",
            "date": "2014-04-25T02:12:17+0000"
        },
        {
            "id": "comment-13982548",
            "author": "Uwe Schindler",
            "content": "Close issue after release of 4.8.0 ",
            "date": "2014-04-27T23:25:42+0000"
        },
        {
            "id": "comment-13989767",
            "author": "ASF subversion and git services",
            "content": "Commit 1592590 from Robert Muir in branch 'dev/branches/lucene_solr_4_8'\n[ https://svn.apache.org/r1592590 ]\n\nLUCENE-5559: additional argument validation for CapitalizationFilter and CodepointCountFilter ",
            "date": "2014-05-05T17:55:27+0000"
        }
    ]
}