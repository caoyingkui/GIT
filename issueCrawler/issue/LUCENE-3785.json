{
    "id": "LUCENE-3785",
    "title": "Replace ant macros for running concurrent tests with ant-junit4.",
    "details": {
        "labels": "",
        "priority": "Minor",
        "components": [
            "general/build",
            "general/test"
        ],
        "type": "Sub-task",
        "fix_versions": [
            "4.0-ALPHA"
        ],
        "affect_versions": "None",
        "resolution": "Duplicate",
        "status": "Closed"
    },
    "description": "ant-junit4 is an ANT task for running tests in parallel (on slave JVMs). Its advantages over the current macros:\n\n\tdynamic load balancing based on historical test runs and current execution (job-stealing),\n\tjvm-crash resilience (I wrote tests that actually crash a slave jvms to make sure such an event is reported appropriately),\n\tnicer console reporting (no need for syserrs on LuceneTestCase level).\n\n\n\nMore documentation and info will follow as I roll out a patch.\n\nNOTE. The code for this issue is being developed at:\nhttps://github.com/dweiss/lucene_solr/tree/LUCENE-3785",
    "attachments": {
        "junit4-1.txt": "https://issues.apache.org/jira/secure/attachment/12514715/junit4-1.txt",
        "junit4-2.txt": "https://issues.apache.org/jira/secure/attachment/12514716/junit4-2.txt",
        "lucene-tests.txt": "https://issues.apache.org/jira/secure/attachment/12514722/lucene-tests.txt",
        "LUCENE-3785.patch": "https://issues.apache.org/jira/secure/attachment/12515256/LUCENE-3785.patch",
        "line-per-test.txt": "https://issues.apache.org/jira/secure/attachment/12514724/line-per-test.txt",
        "trunk1.txt": "https://issues.apache.org/jira/secure/attachment/12514717/trunk1.txt",
        "trunk2.txt": "https://issues.apache.org/jira/secure/attachment/12514718/trunk2.txt",
        "failure-cases.patch": "https://issues.apache.org/jira/secure/attachment/12514713/failure-cases.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2012-02-15T21:36:04+0000",
            "content": "This patch is not intended for inclusion, it provides all kinds of test failure points for testing/ debugging. ",
            "author": "Dawid Weiss",
            "id": "comment-13208809"
        },
        {
            "date": "2012-02-15T21:48:46+0000",
            "content": "\njvm-crash resilience (I wrote tests that actually crash a slave jvms to make sure such an event is reported appropriately),\n\nIts really annoying with our current setup that you have no clue which test the jvm crashed in... you just see (crashed) ",
            "author": "Robert Muir",
            "id": "comment-13208819"
        },
        {
            "date": "2012-02-15T21:54:59+0000",
            "content": "An example improvement over trunk. I've designed a \"super-failing\" set of classes that fail at various points (initializations, rules, hooks). The output from the current trunk is interleaved and hard to read (compare trunk1.txt and trunk2.txt \u2013 they're executions with the same seed; it's hard to tell which line of output is associated with which test). The output from junit4 is also reordered (because parallel tests execution is effectively a race condition...), but the OUTPUT passed to listeners (in this case the console output) is always fully consistent. \n\nCompare junit4-1.txt and junit4-2.txt. Every suite block is atomic. Like this one:\n\n   [junit4] Running org.apache.lucene.util.junitcompat.failures.TestFailOn07After\n   [junit4] ERROR   0.09s S3 | TestFailOn07After.testMethod\n   [junit4]    > Throwable #1: java.lang.RuntimeException: Failure on @After.\n   [junit4]    > \tat org.apache.lucene.util.junitcompat.failures.TestFailOn07After.after(TestFailOn07After.java:13)\n   [junit4]    > \tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n   [junit4]    > \tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n   [junit4]    > \tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n   [junit4]    > \tat java.lang.reflect.Method.invoke(Method.java:601)\n   [junit4]    > \tat org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)\n   [junit4]    > \tat org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)\n   [junit4]    > \tat org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)\n   [junit4]    > \tat org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:36)\n   [junit4]    > \tat org.apache.lucene.util.LuceneTestCase$SubclassSetupTeardownRule$1.evaluate(LuceneTestCase.java:700)\n   [junit4]    > \tat org.apache.lucene.util.LuceneTestCase$InternalSetupTeardownRule$1.evaluate(LuceneTestCase.java:599)\n   [junit4]    > \tat org.apache.lucene.util.LuceneTestCase$TestResultInterceptorRule$1.evaluate(LuceneTestCase.java:504)\n   [junit4]    > \tat org.apache.lucene.util.LuceneTestCase$RememberThreadRule$1.evaluate(LuceneTestCase.java:562)\n   [junit4]    > \tat org.junit.rules.RunRules.evaluate(RunRules.java:18)\n   [junit4]    > \tat org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)\n   [junit4]    > \tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)\n   [junit4]    > \tat org.apache.lucene.util.LuceneTestCaseRunner.runChild(LuceneTestCaseRunner.java:165)\n   [junit4]    > \tat org.apache.lucene.util.LuceneTestCaseRunner.runChild(LuceneTestCaseRunner.java:57)\n   [junit4]    > \tat org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)\n   [junit4]    > \tat org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)\n   [junit4]    > \tat org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)\n   [junit4]    > \tat org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)\n   [junit4]    > \tat org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)\n   [junit4]    > \tat org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)\n   [junit4]    > \tat org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)\n   [junit4]    > \tat org.junit.runners.ParentRunner.run(ParentRunner.java:300)\n   [junit4]    > \tat org.junit.runner.JUnitCore.run(JUnitCore.java:157)\n   [junit4]    > \tat com.carrotsearch.ant.tasks.junit4.slave.SlaveMain.execute(SlaveMain.java:124)\n   [junit4]    > \tat com.carrotsearch.ant.tasks.junit4.slave.SlaveMain.main(SlaveMain.java:186)\n   [junit4]    > \tat com.carrotsearch.ant.tasks.junit4.slave.SlaveMainSafe.main(SlaveMainSafe.java:12)\n   [junit4]    > \n   [junit4]   2> NOTE: reproduce with: ant test -Dtestcase=TestFailOn07After -Dtestmethod=testMethod -Dtests.seed=-737472ec6455983d:77a4c0da1ce834dd:1a2ea2ed4eba1655 -Dargs=\"-Dfile.encoding=Cp1252\"\n   [junit4]   2>\n   [junit4] Tests run:   1, Failures:   0, Errors:   1, Skipped:   0, Time:  0.25s <<< FAILURES!\n\n\n\nA block like this is composed of sections. It begins with the suite name, followed by tests:\n\n   [junit4] Running org.apache.lucene.util.junitcompat.failures.TestFailOn07After\n\n\nIf anything fails, it is reported as a consistent block within a suite. For example here, an @After hook failed on testMethod:\n\n   [junit4] ERROR   0.09s S3 | TestFailOn07After.testMethod\n   [junit4]    > Throwable #1: java.lang.RuntimeException: Failure on @After.\n   [junit4]    > \tat org.apache.lucene.util.junitcompat.failures.TestFailOn07After.after(TestFailOn07After.java:13)\n   [junit4]    > \tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n...\n   [junit4]    > \tat com.carrotsearch.ant.tasks.junit4.slave.SlaveMainSafe.main(SlaveMainSafe.java:12)\n   [junit4]    > \n   [junit4]   2> NOTE: reproduce with: ant test -Dtestcase=TestFailOn07After -Dtestmethod=testMethod -Dtests.seed=-737472ec6455983d:77a4c0da1ce834dd:1a2ea2ed4eba1655 -Dargs=\"-Dfile.encoding=Cp1252\"\n   [junit4]   2>\n\n\nAn output section like this also follows a pattern. The first line contains a test case's status, time, slave JVM identifier (S3) and cause description:\n\n   [junit4] ERROR   0.09s S3 | TestFailOn07After.testMethod\n\n\nthen follows (\">\"-indented) throwable cause and stack:\n\n   [junit4]    > Throwable #1: java.lang.RuntimeException: Failure on @After.\n   [junit4]    > \tat org.apache.lucene.util.junitcompat.failures.TestFailOn07After.after(TestFailOn07After.java:13)\n...\n\n\nfinally, standards output and standard error streams come at the end. They are also indented and prefixed with \"1>\" (stdout\" or \"2>\" (stderr). stderr and stdout calls come in the order they actually happened on the slave (they're synchronized). In this case, only stderr was used:\n\n   [junit4]   2> NOTE: reproduce with: ant test -Dtestcase=TestFailOn07After -Dtestmethod=testMethod -Dtests.seed=-737472ec6455983d:77a4c0da1ce834dd:1a2ea2ed4eba1655 -Dargs=\"-Dfile.encoding=Cp1252\"\n   [junit4]   2>\n\n\n\nNote that even when when LuceneTestCase fails to provide reproduce string (because the exception happened outside of @Rule boundaries), the output exception cause is still nicely formatted and provided. As in this suite class, which even fails to load properly:\n\n   [junit4] Running org.apache.lucene.util.junitcompat.failures.TestFailOn01ClassLoad\n   [junit4] ERROR   0.00s S0 | TestFailOn01ClassLoad (suite)\n   [junit4]    > Throwable #1: java.lang.ExceptionInInitializerError\n   [junit4]    > \tat java.lang.Class.forName0(Native Method)\n   [junit4]    > \tat java.lang.Class.forName(Class.java:186)\n   [junit4]    > \tat com.carrotsearch.ant.tasks.junit4.slave.SlaveMain.instantiate(SlaveMain.java:138)\n   [junit4]    > \tat com.carrotsearch.ant.tasks.junit4.slave.SlaveMain.execute(SlaveMain.java:116)\n   [junit4]    > \tat com.carrotsearch.ant.tasks.junit4.slave.SlaveMain.main(SlaveMain.java:186)\n   [junit4]    > \tat com.carrotsearch.ant.tasks.junit4.slave.SlaveMainSafe.main(SlaveMainSafe.java:12)\n   [junit4]    > Caused by: java.lang.ArithmeticException: / by zero\n   [junit4]    > \tat org.apache.lucene.util.junitcompat.failures.TestFailOn01ClassLoad.<clinit>(TestFailOn01ClassLoad.java:11)\n   [junit4]    > \t... 6 more\n   [junit4]    >\n   [junit4] Tests run:   0, Failures:   0, Errors:   1, Skipped:   0, Time:  0.00s <<< FAILURES!\n\n\nThe summary line contains \"Tests run: 0\" which may seem incorrect, but in fact no test even began \u2013 the error comes from the suite loader (the status line contains no method name, just the suite name). ",
            "author": "Dawid Weiss",
            "id": "comment-13208826"
        },
        {
            "date": "2012-02-15T22:00:06+0000",
            "content": "This is an output for all lucene tests (junit4). ",
            "author": "Dawid Weiss",
            "id": "comment-13208833"
        },
        {
            "date": "2012-02-15T22:03:29+0000",
            "content": "An output for full lucene tests under junit4. Note interesting corner cases:\n\n1) assumption failed (status: IGNOR/A; ignored by assumption). It is reported twice \u2013 once by junit4, then on stderr by LuceneTestCase.\n\n\n   [junit4] Running org.apache.lucene.index.TestIndexWriterReader\n   [junit4] IGNOR/A 0.22s S1 | TestIndexWriterReader.testNoTermsIndex\n   [junit4]    > Throwable #1: org.junit.internal.AssumptionViolatedException: got: <org.apache.lucene.util.InternalAssumptionViolatedException: failed assumption: PreFlex codec does not support ReaderTermsIndexDivisor!>, expected: null\n   [junit4]   2> NOTE: Assume failed in 'testNoTermsIndex(org.apache.lucene.index.TestIndexWriterReader)' (ignored): got: <org.apache.lucene.util.InternalAssumptionViolatedException: failed assumption: PreFlex codec does not support ReaderTermsIndexDivisor!>, expected: null\n   [junit4]   2>\n   [junit4] Tests run:  20, Failures:   0, Errors:   0, Skipped:   1, Time: 17.25s\n\n\n\n2) ignored tests, all reported under a suite:\n\n\n   [junit4] Running org.apache.lucene.util.junitcompat.TestReproduceMessage\n   [junit4] IGNORED 0.00s S0 | TestReproduceMessage.testAssumeAfterClass\n   [junit4] IGNORED 0.00s S0 | TestReproduceMessage.testAssumeInitializer\n   [junit4] IGNORED 0.00s S0 | TestReproduceMessage.testAssumeBeforeClass\n   [junit4] IGNORED 0.00s S0 | TestReproduceMessage.testFailureBeforeClass\n   [junit4] IGNORED 0.00s S0 | TestReproduceMessage.testFailureInitializer\n   [junit4] IGNORED 0.00s S0 | TestReproduceMessage.testFailureAfterClass\n   [junit4] IGNORED 0.00s S0 | TestReproduceMessage.testErrorBeforeClass\n   [junit4] IGNORED 0.00s S0 | TestReproduceMessage.testErrorInitializer\n   [junit4] IGNORED 0.00s S0 | TestReproduceMessage.testErrorAfterClass\n   [junit4] Tests run:  21, Failures:   0, Errors:   0, Skipped:   9, Time:  0.14s\n\n\n\n3) I've added past statistics for tests for load balancing; they seem to do a fairly good job:\n\n\n   [junit4] Expected execution time on slave 0:    89.37s\n   [junit4] Expected execution time on slave 1:    89.37s\n   [junit4] Expected execution time on slave 2:    89.37s\n   [junit4] Expected execution time on slave 3:    89.37s\n\n\n\nand the result was:\n\n\n   [junit4] Slave 0:     0.47 ..    81.83 =    81.36s\n   [junit4] Slave 1:     0.47 ..    84.37 =    83.89s\n   [junit4] Slave 2:     0.54 ..    81.92 =    81.38s\n   [junit4] Slave 3:     0.47 ..    84.75 =    84.28s\n   [junit4] Execution time total: 1 minute 24 seconds\n   [junit4] Tests summary: 284 suites, 1587 tests, 25 ignored (12 assumptions)\n\n\n\n ",
            "author": "Dawid Weiss",
            "id": "comment-13208837"
        },
        {
            "date": "2012-02-15T22:22:05+0000",
            "content": "An alternative output from lucene tests; I like it but it may be too orthodox for some who're used to maven-like output. Feel free to tweak yourself if you feel like it, the console formatter is in common-build.xml. For example test-per-line formatting, no intermediate summaries:\n\n                <report-text\n                    showThrowable=\"true\" \n                    showStackTraces=\"true\" \n                    showOutputStream=\"true\"\n                    showErrorStream=\"true\"\n\n                    showStatusOk=\"true\"\n                    showStatusError=\"true\"\n                    showStatusFailure=\"true\"\n                    showStatusIgnored=\"true\"\n\n                    showSuiteSummary=\"false\"\n                />\n\n ",
            "author": "Dawid Weiss",
            "id": "comment-13208867"
        },
        {
            "date": "2012-02-19T21:41:57+0000",
            "content": "I've found and fixed the gson issue. I re-run ant test (no nightly though) 10 times, everything went fine \u2013 7 successful builds and 3 errors (BasicZkTest.testBasic, BasicDistributedZkTest.testDistribSearch), but these are not caused by the testing framework I guess.\n\nI'm ready to merge this work with the trunk once I receive acks (this will probably break your existing forks/ branches/patches if you have any \u2013 there's quite a lot of tiny changes).\n\nI will attach a patch to this issue for completeness, but it'll be a huge blob (just warning). ",
            "author": "Dawid Weiss",
            "id": "comment-13211562"
        },
        {
            "date": "2012-02-20T15:52:33+0000",
            "content": "A non-binary patch for overview. Most of the changes are around encapsulating random as a method instead of a field access. ",
            "author": "Dawid Weiss",
            "id": "comment-13211936"
        },
        {
            "date": "2012-02-20T19:57:55+0000",
            "content": "I talked to Robert a bit and I've decided to postpone the commit until I have the backport on 3x branch ready too. It would make everyone's life very difficult if I applied it to the trunk only because of differences in acquiring the Random instance from LTC.\n\nI'll work on the backport and come back when I'm ready. ",
            "author": "Dawid Weiss",
            "id": "comment-13212039"
        },
        {
            "date": "2012-03-02T11:10:58+0000",
            "content": "Subsumed by LUCENE-3808. ",
            "author": "Dawid Weiss",
            "id": "comment-13220840"
        }
    ]
}