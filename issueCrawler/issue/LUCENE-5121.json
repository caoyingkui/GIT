{
    "id": "LUCENE-5121",
    "title": "4.4 RC0 can not read indexes created with 4.2.1 using Disk based docvals",
    "details": {
        "components": [],
        "fix_versions": [
            "4.4"
        ],
        "affect_versions": "None",
        "priority": "Blocker",
        "labels": "",
        "type": "Bug",
        "resolution": "Not A Problem",
        "status": "Closed"
    },
    "description": "On the #solr irc channel, user adityab reported a problem trying to upgrade an existing solr instance from 4.2.1 to the 4.4 RC0 code.  The specific error he reported was a \"CorruptIndexException: invalid type: 65\" from DiskDocValuesProducer.readFields using an MMapIndexInput.  While waiting for more details from adityab on reproducible configs, i attempted to do a trivial test using simple solr configs based on the docvals test configs, and was able to trigger a slightly different error in which DiskDocValuesProducer.readFields caused an EOFException.\n\nThe problem reproduces on both solr init, and when using CheckIndex \u2013 details to reproduce to follow in an attachment/comment",
    "attachments": {
        "disk_docvals_bug.tgz": "https://issues.apache.org/jira/secure/attachment/12593088/disk_docvals_bug.tgz"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2013-07-18T23:05:09+0000",
            "content": "We only provide back compat for the default codec. ",
            "author": "Robert Muir",
            "id": "comment-13713044"
        },
        {
            "date": "2013-07-18T23:07:52+0000",
            "content": "the attached disk_docvals_bug.tgz contains a simple solr home dir containing some very minimal config files and a sample index demonstrating this problem.\n\nthe same index was built using solr 4.2.1 by indexing the included inputdata.xml file using post.jar and confirming that a basic search for \":\" returned the indexed document.\n\nafter shutting down solr 4.2.1, the 4.2.1 version of CheckIndex was run against hte index directory, and no errors were reported...\n\n\nhossman@frisbee:~/lucene/lucene-4.2.1_tag$ java -ea:org.apache.lucene... -cp './lucene/build/codecs/*:lucene/build/core/*'  org.apache.lucene.index.CheckIndex /home/hossman/tmp/disk_docvals_bug/collection1/data/index/\n\nOpening index @ /home/hossman/tmp/disk_docvals_bug/collection1/data/index/\n\nSegments file=segments_3 numSegments=1 version=4.2.1 format= userData={commitTimeMSec=1374187354148}\n  1 of 1: name=_0 docCount=1\n    codec=Lucene42\n    compound=false\n    numFiles=16\n    size (MB)=0.003\n    diagnostics = {timestamp=1374187354189, os=Linux, os.version=3.2.0-50-generic, source=flush, lucene.version=4.2.1-SNAPSHOT 1487037 - hossman - 2013-05-28 11:55:58, os.arch=amd64, java.version=1.7.0_25, java.vendor=Oracle Corporation}\n    no deletions\n    test: open reader.........OK\n    test: fields..............OK [9 fields]\n    test: field norms.........OK [5 fields]\n    test: terms, freq, prox...OK [11 terms; 11 terms/docs pairs; 0 tokens]\n    test: stored fields.......OK [5 total field count; avg 5 fields per doc]\n    test: term vectors........OK [0 total vector count; avg 0 term/freq vector fields per doc]\n    test: docvalues...........OK [0 total doc count; 5 docvalues fields]\n\nNo problems were detected with this index.\n\n\n\nAt that point, I attempted to run the 4.4.0 RC0 version of CheckIndex against the same inex directory, and got an EOF error...\n\n\nhossman@frisbee:~/tmp/4.4/RC0-rev1503555/hoss/solr-4.4.0$ java -ea:org.apache.lucene... -cp './lucene/build/codecs/*:lucene/build/core/*'  org.apache.lucene.index.CheckIndex /home/hossman/tmp/disk_docvals_bug/collection1/data/index/\n\nOpening index @ /home/hossman/tmp/disk_docvals_bug/collection1/data/index/\n\nSegments file=segments_3 numSegments=1 version=4.2.1 format= userData={commitTimeMSec=1374187354148}\n  1 of 1: name=_0 docCount=1\n    codec=Lucene42\n    compound=false\n    numFiles=16\n    size (MB)=0.003\n    diagnostics = {timestamp=1374187354189, os=Linux, os.version=3.2.0-50-generic, source=flush, lucene.version=4.2.1-SNAPSHOT 1487037 - hossman - 2013-05-28 11:55:58, os.arch=amd64, java.version=1.7.0_25, java.vendor=Oracle Corporation}\n    no deletions\n    test: open reader.........FAILED\n    WARNING: fixIndex() would remove reference to this segment; full exception:\njava.io.EOFException: read past EOF: MMapIndexInput(path=\"/home/hossman/tmp/disk_docvals_bug/collection1/data/index/_0_Disk_0.dvdm\")\n\tat org.apache.lucene.store.ByteBufferIndexInput.readByte(ByteBufferIndexInput.java:78)\n\tat org.apache.lucene.codecs.diskdv.DiskDocValuesProducer.readFields(DiskDocValuesProducer.java:105)\n\tat org.apache.lucene.codecs.diskdv.DiskDocValuesProducer.<init>(DiskDocValuesProducer.java:72)\n\tat org.apache.lucene.codecs.diskdv.DiskDocValuesFormat.fieldsProducer(DiskDocValuesFormat.java:49)\n\tat org.apache.lucene.codecs.perfield.PerFieldDocValuesFormat$FieldsReader.<init>(PerFieldDocValuesFormat.java:213)\n\tat org.apache.lucene.codecs.perfield.PerFieldDocValuesFormat.fieldsProducer(PerFieldDocValuesFormat.java:282)\n\tat org.apache.lucene.index.SegmentCoreReaders.<init>(SegmentCoreReaders.java:134)\n\tat org.apache.lucene.index.SegmentReader.<init>(SegmentReader.java:56)\n\tat org.apache.lucene.index.CheckIndex.checkIndex(CheckIndex.java:543)\n\tat org.apache.lucene.index.CheckIndex.main(CheckIndex.java:1854)\n\nWARNING: 1 broken segments (containing 1 documents) detected\nWARNING: would write new segments file, and 1 documents would be lost, if -fix were specified\n\n\n\nThe same error occurs if you attempt to start up Solr 4.4.0 RC0 pointed at this solr home dir....\n\n\n\n\norg.apache.solr.common.SolrException: Error opening new searcher\n\tat org.apache.solr.core.SolrCore.<init>(SolrCore.java:835)\n\tat org.apache.solr.core.SolrCore.<init>(SolrCore.java:629)\n\tat org.apache.solr.core.CoreContainer.createFromLocal(CoreContainer.java:622)\n\tat org.apache.solr.core.CoreContainer.create(CoreContainer.java:657)\n\tat org.apache.solr.core.CoreContainer$1.call(CoreContainer.java:364)\n\tat org.apache.solr.core.CoreContainer$1.call(CoreContainer.java:356)\n\tat java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:166)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n\tat java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:166)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:724)\nCaused by: org.apache.solr.common.SolrException: Error opening new searcher\n\tat org.apache.solr.core.SolrCore.openNewSearcher(SolrCore.java:1522)\n\tat org.apache.solr.core.SolrCore.getSearcher(SolrCore.java:1634)\n\tat org.apache.solr.core.SolrCore.<init>(SolrCore.java:810)\n\t... 13 more\nCaused by: org.apache.solr.common.SolrException: Error opening Reader\n\tat org.apache.solr.search.SolrIndexSearcher.getReader(SolrIndexSearcher.java:177)\n\tat org.apache.solr.search.SolrIndexSearcher.<init>(SolrIndexSearcher.java:188)\n\tat org.apache.solr.search.SolrIndexSearcher.<init>(SolrIndexSearcher.java:184)\n\tat org.apache.solr.core.SolrCore.openNewSearcher(SolrCore.java:1497)\n\t... 15 more\nCaused by: java.io.EOFException: read past EOF: MMapIndexInput(path=\"/home/hossman/tmp/disk_docvals_bug/collection1/data/index/_0_Disk_0.dvdm\")\n\tat org.apache.lucene.store.ByteBufferIndexInput.readByte(ByteBufferIndexInput.java:78)\n\tat org.apache.lucene.codecs.diskdv.DiskDocValuesProducer.readFields(DiskDocValuesProducer.java:105)\n\tat org.apache.lucene.codecs.diskdv.DiskDocValuesProducer.<init>(DiskDocValuesProducer.java:72)\n\tat org.apache.lucene.codecs.diskdv.DiskDocValuesFormat.fieldsProducer(DiskDocValuesFormat.java:49)\n\tat org.apache.lucene.codecs.perfield.PerFieldDocValuesFormat$FieldsReader.<init>(PerFieldDocValuesFormat.java:213)\n\tat org.apache.lucene.codecs.perfield.PerFieldDocValuesFormat.fieldsProducer(PerFieldDocValuesFormat.java:282)\n\tat org.apache.lucene.index.SegmentCoreReaders.<init>(SegmentCoreReaders.java:134)\n\tat org.apache.lucene.index.SegmentReader.<init>(SegmentReader.java:56)\n\tat org.apache.lucene.index.StandardDirectoryReader$1.doBody(StandardDirectoryReader.java:62)\n\tat org.apache.lucene.index.SegmentInfos$FindSegmentsFile.run(SegmentInfos.java:812)\n\tat org.apache.lucene.index.StandardDirectoryReader.open(StandardDirectoryReader.java:52)\n\tat org.apache.lucene.index.DirectoryReader.open(DirectoryReader.java:88)\n\tat org.apache.solr.core.StandardIndexReaderFactory.newReader(StandardIndexReaderFactory.java:34)\n\tat org.apache.solr.search.SolrIndexSearcher.getReader(SolrIndexSearcher.java:174)\n\t... 18 more\n\n ",
            "author": "Hoss Man",
            "id": "comment-13713047"
        },
        {
            "date": "2013-07-18T23:09:38+0000",
            "content": "Again not a bug... ",
            "author": "Robert Muir",
            "id": "comment-13713050"
        },
        {
            "date": "2013-07-18T23:12:24+0000",
            "content": "We only provide back compat for the default codec.\n\nWTF?  Seriously?\n\n1) is this documented anywhere?\n\n2) I thought a major point of having multiple codecs and configurable posting formats and docvalues formats was that the old ones could be left alone for backcompat support, and entirely new ones, with new names, could be created if/when there were format improvements to be made?\n ",
            "author": "Hoss Man",
            "id": "comment-13713053"
        },
        {
            "date": "2013-07-18T23:13:14+0000",
            "content": "FWIW, the original stack trace reported by the user on IRC...\n\n\nCaused by: org.apache.lucene.index.CorruptIndexException: invalid type: 65, resource=MMapIndexInput(path=\"/storage/solrdata/index/_fd_Disk_0.dvdm\")\n        at org.apache.lucene.codecs.diskdv.DiskDocValuesProducer.readFields(DiskDocValuesProducer.java:159)\n        at org.apache.lucene.codecs.diskdv.DiskDocValuesProducer.<init>(DiskDocValuesProducer.java:72)\n        at org.apache.lucene.codecs.diskdv.DiskDocValuesFormat.fieldsProducer(DiskDocValuesFormat.java:49)\n        at org.apache.lucene.codecs.perfield.PerFieldDocValuesFormat$FieldsReader.<init>(PerFieldDocValuesFormat.java:213)\n        at org.apache.lucene.codecs.perfield.PerFieldDocValuesFormat.fieldsProducer(PerFieldDocValuesFormat.java:282)\n        at org.apache.lucene.index.SegmentCoreReaders.<init>(SegmentCoreReaders.java:134)\n        at org.apache.lucene.index.SegmentReader.<init>(SegmentReader.java:56)\n        at org.apache.lucene.index.StandardDirectoryReader$1.doBody(StandardDirectoryReader.java:62)\n        at org.apache.lucene.index.SegmentInfos$FindSegmentsFile.run(SegmentInfos.java:812)\n        at org.apache.lucene.index.StandardDirectoryReader.open(StandardDirectoryReader.java:52)\n        at org.apache.lucene.index.DirectoryReader.open(DirectoryReader.java:88)\n        at org.apache.solr.core.StandardIndexReaderFactory.newReader(StandardIndexReaderFactory.java:34)\n        at org.apache.solr.search.SolrIndexSearcher.getReader(SolrIndexSearcher.java:174)\n        ... 18 more\n\n\n ",
            "author": "Hoss Man",
            "id": "comment-13713055"
        },
        {
            "date": "2013-07-18T23:18:15+0000",
            "content": "This is documented everywhere, see solrconfig.xml or the docvalues wiki page for example.\n\nHaving a codec API doesn't mean expanding our back compat requirements to custom/experimental formats. If you don't want to reindex, just merge to the default codec, then upgrade. ",
            "author": "Robert Muir",
            "id": "comment-13713070"
        },
        {
            "date": "2013-07-18T23:39:46+0000",
            "content": "The wiki page says: \n\nNote that only the default implementation is supported by future version of Lucene: if you try an alternative format, you may need to switch back to the default and rewrite your index (e.g. forceMerge) before upgrading. ",
            "author": "Mark Miller",
            "id": "comment-13713103"
        },
        {
            "date": "2013-07-19T00:22:43+0000",
            "content": "Well the fields that we use for docValues are defined as below. Whats is non-standard here?\n\n \n <fieldType name=\"dv_long\" class=\"solr.TrieLongField\" precisionStep=\"0\" docValuesFormat=\"Disk\"  positionIncrementGap=\"0\"/>\n \n <dynamicField name=\"lcontNumOfDownload.*\" type=\"dv_long\" indexed=\"true\" stored=\"true\" default=\"0\"  docValues=\"true\"/>\n\n\n\nWhere as my solrconfig.xml file i had to add this line to make it work. (cause we upgraded from 3.5 to 4.2.1)\n\n \n<codecFactory class=\"solr.SchemaCodecFactory\"/>\n\n\n\nedited: Provided the correct field type. ",
            "author": "Aditya",
            "id": "comment-13713156"
        },
        {
            "date": "2013-07-19T01:35:50+0000",
            "content": "Some additional information as Hoss Man asked on solr IRC after running CheckIndex with 4.4 and 4.2.1 \n\nWith CheckIndex (4.4)\n\n[root@solrperfmv002 storage]# java -cp lucene-core-4.4.0.jar:lucene-codecs-4.4.0.jar org.apache.lucene.index.CheckIndex ./solrdata/index/\n\nNOTE: testing will be more thorough if you run java with '-ea:org.apache.lucene...', so assertions are enabled\n\nOpening index @ ./solrdata/index/\n\nSegments file=segments_q numSegments=1 version=4.2.1 format= userData={commitTimeMSec=1374020371815}\n  1 of 1: name=_fd docCount=24429799\n    codec=Lucene42\n    compound=false\n    numFiles=16\n    size (MB)=25,112.699\n    diagnostics = {timestamp=1374016842452, os=Linux, os.version=2.6.18-164.11.1.el5, mergeFactor=3, source=merge, lucene.version=4.2.1-SNAPSHOT 1490837M - greg - 2013-06-07 14:10:44, os.arch=amd64, mergeMaxNumSegments=1, java.version=1.6.0_45, java.vendor=Sun Microsystems Inc.}\n    no deletions\n    test: open reader.........FAILED\n    WARNING: fixIndex() would remove reference to this segment; full exception:\norg.apache.lucene.index.CorruptIndexException: invalid type: 65, resource=MMapIndexInput(path=\"/storage/solrdata/index/_fd_Disk_0.dvdm\")\n        at org.apache.lucene.codecs.diskdv.DiskDocValuesProducer.readFields(DiskDocValuesProducer.java:159)\n        at org.apache.lucene.codecs.diskdv.DiskDocValuesProducer.<init>(DiskDocValuesProducer.java:72)\n        at org.apache.lucene.codecs.diskdv.DiskDocValuesFormat.fieldsProducer(DiskDocValuesFormat.java:49)\n        at org.apache.lucene.codecs.perfield.PerFieldDocValuesFormat$FieldsReader.<init>(PerFieldDocValuesFormat.java:213)\n        at org.apache.lucene.codecs.perfield.PerFieldDocValuesFormat.fieldsProducer(PerFieldDocValuesFormat.java:282)\n        at org.apache.lucene.index.SegmentCoreReaders.<init>(SegmentCoreReaders.java:134)\n        at org.apache.lucene.index.SegmentReader.<init>(SegmentReader.java:56)\n        at org.apache.lucene.index.CheckIndex.checkIndex(CheckIndex.java:543)\n        at org.apache.lucene.index.CheckIndex.main(CheckIndex.java:1854)\n\nWARNING: 1 broken segments (containing 24429799 documents) detected\nWARNING: would write new segments file, and 24429799 documents would be lost, if -fix were specified\n\n\n\n\nWith CheckIndex (4.2.1)\n\n[root@solrperfmv002 storage]# java -d64 -Xmx16g -cp lucene-codecs-4.2.1-SNAPSHOT.jar:lucene-core-4.2.1-SNAPSHOT.jar org.apache.lucene.index.CheckIndex ./solrdata/index/\n\nNOTE: testing will be more thorough if you run java with '-ea:org.apache.lucene...', so assertions are enabled\n\nOpening index @ ./solrdata/index/\n\nSegments file=segments_q numSegments=1 version=4.2.1 format= userData={commitTimeMSec=1374020371815}\n  1 of 1: name=_fd docCount=24429799\n    codec=Lucene42\n    compound=false\n    numFiles=16\n    size (MB)=25,112.699\n    diagnostics = {timestamp=1374016842452, os=Linux, os.version=2.6.18-164.11.1.el5, mergeFactor=3, source=merge, lucene.version=4.2.1-SNAPSHOT 1490837M - greg - 2013-06-07 14:10:44, os.arch=amd64, mergeMaxNumSegments=1, java.version=1.6.0_45, java.vendor=Sun Microsystems Inc.}\n    no deletions\n    test: open reader.........OK\n    test: fields..............OK [12367 fields]\n    test: field norms.........OK [515 fields]\n    test: terms, freq, prox...OK [139455881 terms; 2613497338 terms/docs pairs; 803255554 tokens]\n    test: stored fields.......OK [2351712224 total field count; avg 96.264 fields per doc]\n    test: term vectors........OK [0 total vector count; avg 0 term/freq vector fields per doc]\n    test: docvalues...........OK [0 total doc count; 335 docvalues fields]\n\nNo problems were detected with this index.\n\n\n ",
            "author": "Aditya",
            "id": "comment-13713238"
        },
        {
            "date": "2013-07-19T06:04:00+0000",
            "content": "\nWell the fields that we use for docValues are defined as below. Whats is non-standard here?\n\nThe wiki page is quite clear about this: http://wiki.apache.org/solr/DocValues#Specifying_a_different_Codec_implementation\n\n\nWhere as my solrconfig.xml file i had to add this line to make it work. (cause we upgraded from 3.5 to 4.2.1)\n\n\n<codecFactory class=\"solr.SchemaCodecFactory\"/>\n\nIts too bad you didn't also include the comment that goes with that line in solrconfig.xml, which also warns about this!\n\n\n  <!-- The CodecFactory for defining the format of the inverted index.\n       The default implementation is SchemaCodecFactory, which is the official Lucene\n       index format, but hooks into the schema to provide per-field customization of\n       the postings lists and per-document values in the fieldType element\n       (postingsFormat/docValuesFormat). Note that most of the alternative implementations\n       are experimental, so if you choose to customize the index format, its a good\n       idea to convert back to the official format e.g. via IndexWriter.addIndexes(IndexReader)\n       before upgrading to a newer version to avoid unnecessary reindexing.\n  -->\n\n ",
            "author": "Robert Muir",
            "id": "comment-13713360"
        },
        {
            "date": "2013-07-19T06:05:45+0000",
            "content": "Currently (as documented), we don't provide index back compat for experimental codecs in lucene-codecs.jar.\n\nBackwards compatibility is not free: I think supporting the official format is really all we can handle and still have maintainable code. But if we want to discuss expanding the backwards compatibility policy, lets do that on a mailing list thread. ",
            "author": "Robert Muir",
            "id": "comment-13713363"
        },
        {
            "date": "2013-07-19T12:45:21+0000",
            "content": "I guess to the casual observer / user, it's not clear what is covered by the \"default codec\" and what is considered an experimental codec. ",
            "author": "Yonik Seeley",
            "id": "comment-13713616"
        },
        {
            "date": "2013-07-19T14:35:09+0000",
            "content": "So this concludes that for non-default codec we need to re-index on upgrade.  ",
            "author": "Aditya",
            "id": "comment-13713712"
        },
        {
            "date": "2013-07-19T16:15:36+0000",
            "content": "No, this is unnecessary. Again, please read the documentation (its all been pasted verbatim here on this issue) ",
            "author": "Robert Muir",
            "id": "comment-13713795"
        },
        {
            "date": "2013-07-23T18:37:10+0000",
            "content": "Bulk close resolved 4.4 issues ",
            "author": "Steve Rowe",
            "id": "comment-13716771"
        }
    ]
}