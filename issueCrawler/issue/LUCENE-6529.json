{
    "id": "LUCENE-6529",
    "title": "NumericFields + SlowCompositeReaderWrapper + UninvertedReader + -Dtests.codec=random can results in incorrect SortedSetDocValues",
    "details": {
        "resolution": "Fixed",
        "affect_versions": "None",
        "components": [],
        "labels": "",
        "fix_versions": [
            "5.3",
            "6.0"
        ],
        "priority": "Major",
        "status": "Closed",
        "type": "Bug"
    },
    "description": "Digging into SOLR-7631 and SOLR-7605 I became fairly confident that the only explanation of the behavior i was seeing was some sort of bug in either the randomized codec/postings-format or the UninvertedReader, that was only evident when two were combined and used on a multivalued Numeric Field using precision steps.  But since i couldn't find any -Dtests.codec or -Dtests.postings.format options that would cause the bug 100% regardless of seed, I switched tactices and focused on reproducing the problem using UninvertedReader directly and checking the SortedSetDocValues.getValueCount().\n\nI now have a test that fails frequently (and consistently for any seed i find), but only with -Dtests.codec=random \u2013 override it with -Dtests.codec=default and everything works fine (based on the exhaustive testing I did in the linked issues, i suspect every named codec works fine - but i didn't re-do that testing here)\n\nThe failures only seem to happen when checking the SortedSetDocValues.getValueCount() of a SlowCompositeReaderWrapper around the UninvertedReader \u2013 which suggests the root bug may actually be in SlowCompositeReaderWrapper? (but still has some dependency on the random codec)",
    "attachments": {
        "LUCENE-6529.patch": "https://issues.apache.org/jira/secure/attachment/12738114/LUCENE-6529.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "id": "comment-14575489",
            "author": "Hoss Man",
            "date": "2015-06-06T01:36:56+0000",
            "content": "\nsee patch for test case, a couple of example seeds that fail for me...\n\n\nant test -Dtestcase=TestUninvertingReader -Dtests.method=testSortedSetIntegerManyValues -Dtests.seed=3A8A592786F36F30 -Dtests.slow=true -Dtests.asserts=true\nant test  -Dtestcase=TestUninvertingReader -Dtests.method=testSortedSetIntegerManyValues -Dtests.seed=C7B1C0FEDB6252C4 -Dtests.slow=true -Dtests.locale=ar_BH -Dtests.timezone=Asia/Yakutsk -Dtests.asserts=true -Dtests.file.encoding=US-ASCII\nant test  -Dtestcase=TestUninvertingReader -Dtests.method=testSortedSetIntegerManyValues -Dtests.seed=6C6936440B92E593 -Dtests.slow=true -Dtests.locale=de_GR -Dtests.timezone=Atlantic/Bermuda -Dtests.asserts=true -Dtests.file.encoding=UTF-8\n\n\n\nBut you can find lots more fairely quickly with...\n\nant beast -Dbeast.iters=100 -Dtestcase=TestUninvertingReader -Dtests.method=testSortedSetIntegerManyValues -Dtests.slow=true -Dtests.asserts=true -Dtests.codec=random\n\n\n\nMeanwhile this never fails on me...\n\nant beast -Dbeast.iters=100 -Dtestcase=TestUninvertingReader -Dtests.method=testSortedSetIntegerManyValues -Dtests.slow=true -Dtests.asserts=true -Dtests.codec=default\n\n "
        },
        {
            "id": "comment-14575713",
            "author": "Robert Muir",
            "date": "2015-06-06T13:02:54+0000",
            "content": "I saw this, i didn't have a chance to look at it yet until now. Thanks for narrowing it down to this test!\n\nWhen fields actually have multiple values (which is the situation you test), DocTermsOrds is used, and, in the case the codec supports optional ord() and seek(ord), it will use them. So maybe there is a bug in one of the term dictionaries there, and why its only provoked with random codecs.\n\nI will play with the test and try to narrow it further. "
        },
        {
            "id": "comment-14575716",
            "author": "Robert Muir",
            "date": "2015-06-06T13:18:29+0000",
            "content": "In the case of all 3 provided seeds we have:\n\n\n   [junit4]   2> NOTE: test params are: codec=Asserting(Lucene50): {foo=PostingsFormat(name=MockRandom)}\n\n\n\nIf i disable the ord-sharing optimization in DocTermOrds, all 3 seeds pass. So I think there is a bug in e.g. FixedGap/BlockTerms dictionary or something like that. Maybe BasePostingsFormatTestCase does not adequately exercise methods like size()/ord()/seek(ord). It should be failing! "
        },
        {
            "id": "comment-14575718",
            "author": "Robert Muir",
            "date": "2015-06-06T13:31:21+0000",
            "content": "All BasePostingsFormatTestCase has is a measly check that ord() is the correct value when next()'ing through all the terms sequentially. \n\nIt does not test seek(ord) and other possibilities. I will try to fix the test... "
        },
        {
            "id": "comment-14575724",
            "author": "ASF subversion and git services",
            "date": "2015-06-06T13:52:42+0000",
            "content": "Commit 1683913 from Robert Muir in branch 'dev/trunk'\n[ https://svn.apache.org/r1683913 ]\n\nLUCENE-6529: add asserts "
        },
        {
            "id": "comment-14575756",
            "author": "Robert Muir",
            "date": "2015-06-06T14:41:45+0000",
            "content": "I have to run for now, one thing to investigate too:\n\nis the problem the \"extra\" terms introduced by precision step? Maybe crank precisionStep down and see if expected/actual change. Maybe the current optimization is unsafe in that case and yields a bogus valueCount including the range terms, which screws up things down the road. "
        },
        {
            "id": "comment-14575806",
            "author": "Hoss Man",
            "date": "2015-06-06T16:21:53+0000",
            "content": "thanks for looking into this rmuir.\n\ni haven't tried out your patch yet, but in response to your questions...\n\nis the problem the \"extra\" terms introduced by precision step? ...\n\nalmost certainly.  The test from SOLR-7631 that inspired this one never fails unless a precisionStep is used, but we definitely can/should beef this test up to demonstrate that as well. "
        },
        {
            "id": "comment-14577951",
            "author": "ASF subversion and git services",
            "date": "2015-06-08T22:16:02+0000",
            "content": "Commit 1684292 from Robert Muir in branch 'dev/branches/branch_5x'\n[ https://svn.apache.org/r1684292 ]\n\nLUCENE-6529: add asserts "
        },
        {
            "id": "comment-14577995",
            "author": "Hoss Man",
            "date": "2015-06-08T22:42:00+0000",
            "content": "Maybe BasePostingsFormatTestCase does not adequately exercise methods like size()/ord()/seek(ord). It should be failing!\n\nFWIW, as far as i understand BasePostingsFormatTestCase and RandomPostingsTester based on skimming them this morning, they may not ever reproduce this bug since (AFAICT) only ever operate on single segment indexes?\n\nAs mentioned: this patch only ever fails for me when testing the SlowCompositeReaderWrapper \u2013 asserts on the individual segment LeafReaders seem to pass all the time (even though one segment is forced to have every term that's in the index as a whole).  Likewise if you iw.forceMerge(1); then the SlowCompositeReaderWrapper asserts start to pass as well.\n\n\n\nI've updated the patch to include the test from SOLR-7631, as well as beefing up UninvertingReader.tTetestSortedSetIntegerManyValues to include all (4) permutations of multi/single-valued + (no)-precisionStep, (didn't turn up anything unexpected, only the trie fields are problematic) as well as to running TestUtil.checkReader on the SlowCompositeReader before using it.  This last change started triggering failure much earlier...\n\n\n   [junit4]   2> NOTE: reproduce with: ant test  -Dtestcase=TestUninvertingReader -Dtests.method=testSortedSetIntegerManyValues -Dtests.seed=3A8A592786F36F30 -Dtests.slow=true -Dtests.locale=in_ID -Dtests.timezone=Zulu -Dtests.asserts=true -Dtests.file.encoding=UTF-8\n   [junit4] ERROR   0.56s | TestUninvertingReader.testSortedSetIntegerManyValues <<<\n   [junit4]    > Throwable #1: java.lang.RuntimeException: dv for field: trie_multi reports wrong maxOrd=33 but this is not the case: 30\n   [junit4]    > \tat __randomizedtesting.SeedInfo.seed([3A8A592786F36F30:DB56E81A1372E276]:0)\n   [junit4]    > \tat org.apache.lucene.index.CheckIndex.checkSortedSetDocValues(CheckIndex.java:1917)\n   [junit4]    > \tat org.apache.lucene.index.CheckIndex.checkDocValues(CheckIndex.java:1987)\n   [junit4]    > \tat org.apache.lucene.index.CheckIndex.testDocValues(CheckIndex.java:1790)\n   [junit4]    > \tat org.apache.lucene.util.TestUtil.checkReader(TestUtil.java:318)\n   [junit4]    > \tat org.apache.lucene.util.TestUtil.checkReader(TestUtil.java:297)\n   [junit4]    > \tat org.apache.lucene.uninverting.TestUninvertingReader.testSortedSetIntegerManyValues(TestUninvertingReader.java:284)\n\n\n\n...so for good measure, i sprinkled in TestUtil.checkReader in some of the other oal.univerting.* tests i could find using SlowCompositeReader \u2013 but based on my limited beasting, this hasn't triggered any other failures.\n\n(note: patch still has nocommits related to limiting some of the random variables)\n\n\n\nIf i disable the ord-sharing optimization in DocTermOrds, all 3 seeds pass. So I think there is a bug in e.g. FixedGap/BlockTerms dictionary or something like that.\n\nMy inclination would be that we should remove this optimization for 5.2.1, commit these tests, and open a new issue to re-add the optimization if/when if can be done in such a way that these tests pass reliably.\n\nwhat do folks think? "
        },
        {
            "id": "comment-14578008",
            "author": "Robert Muir",
            "date": "2015-06-08T22:53:25+0000",
            "content": "\nFWIW, as far as i understand BasePostingsFormatTestCase and RandomPostingsTester based on skimming them this morning, they may not ever reproduce this bug since (AFAICT) only ever operate on single segment indexes?\n\nThe problem has nothing to do with single segment. Now we know: its that this DocTermOrds optimization is conceptually broken with precisionStep. This just causes problems downstream but its not filtering out the \"range terms\" and that is the root cause. It cannot return the terms dict directly, it needs to wrap it with something that filters those out. Methods like NumericUtils.intTerms()/longTerms() are close, but those currently do not yet support ord() and seek(ord) which is needed here. "
        },
        {
            "id": "comment-14578028",
            "author": "Hoss Man",
            "date": "2015-06-08T23:11:09+0000",
            "content": "Well, ok ... that may be obvious to you \u2013 but my point, as someone completley unfamiliar with that code, is that the new test in this issue only fails when SlowCompositReaderWrapper is used around an index with multiple segments \u2013 any other LeafReader (either Slow wrapper arround single segment index, or direct on the individual segments of multi segment index) don't cause the same failures regardless of codec used.\n\nHence my comment that if you are wondering why BasePostingsFormatTestCase isn't triggering similar failures, maybe there is a coreleation?\n\nif you know definitively that he two things have nothing to do with eachother - great, i'll take your word for it.  \n\n\n\tDo you have any specific suggestions for fixing this?\n\tDo you have any suggestions for why BasePostingsFormatTestCase isn't catching this? and/or what should be added to BasePostingsFormatTestCase in order to start catching this?\n\tDo you have opinions on my suggestion to remove this optimization? ...\n\n\n\n\nMy inclination would be that we should remove this optimization for 5.2.1, commit these tests, and open a new issue to re-add the optimization if/when if can be done in such a way that these tests pass reliably.\nwhat do folks think? "
        },
        {
            "id": "comment-14578059",
            "author": "Robert Muir",
            "date": "2015-06-08T23:31:08+0000",
            "content": "\n1) DocTermsOrds has an optimization in case the terms dictionary supports ord(). its broken if you are filtering out a subset of the terms, because it just passes the entire termsenum. Note this optimization never happens, except for a few oddball terms dicts we have, which support ord(). thats why it fails with them.\n2) those oddball terms dicts are just fine. Nothing wrong with them, its doctermsords that does the wrong thing.\n3) I do not have an opinion on the optimization. its probably easy to fix, but i would just disable it as you suggest for now, since it only impacts tests or if someone explicitly uses one of these term dictionaries with this functionality. "
        },
        {
            "id": "comment-14579378",
            "author": "Hoss Man",
            "date": "2015-06-09T18:36:54+0000",
            "content": "updated patch that remoes the DocTermOrds so it always uses OrdWrappedTermsEnum instead of conditionally using it based on the underlying reader.\n\npatch still contains nocommits about increasing randomness in the tests \u2013 i'm going to let my machine hammer on this a bit, then i plan to resolve those remaining test tweaks and commit to trunk later today. "
        },
        {
            "id": "comment-14579762",
            "author": "Hoss Man",
            "date": "2015-06-09T23:48:06+0000",
            "content": "\nSome of Solr's faceting tests uncovered an AIOOBE due to my last patch when dealing with empty indexes - so i updated TestDocTermOrds and TestUninvertingReader to have similar checks to catch things like this, and then updated the changes in DocTermOrds to better account for this.\n\npatch also updated to resolve the nocommits about increasing randomization.\n\nStill hammering... "
        },
        {
            "id": "comment-14579861",
            "author": "Hoss Man",
            "date": "2015-06-10T01:59:54+0000",
            "content": "Fix a stupid bug in TestUninvertingReader that showed up after i increased the randomization.\n\nstill hammering. "
        },
        {
            "id": "comment-14580738",
            "author": "ASF subversion and git services",
            "date": "2015-06-10T16:23:02+0000",
            "content": "Commit 1684704 from hossman@apache.org in branch 'dev/trunk'\n[ https://svn.apache.org/r1684704 ]\n\nLUCENE-6529: Removed an optimization in UninvertingReader that was causing incorrect results for Numeric fields using precisionStep "
        },
        {
            "id": "comment-14580741",
            "author": "Hoss Man",
            "date": "2015-06-10T16:24:50+0000",
            "content": "I'm going to let this soak on trunk for a bit before backporting. "
        },
        {
            "id": "comment-14584248",
            "author": "ASF subversion and git services",
            "date": "2015-06-12T23:25:30+0000",
            "content": "Commit 1685194 from hossman@apache.org in branch 'dev/branches/branch_5x'\n[ https://svn.apache.org/r1685194 ]\n\nLUCENE-6529: Removed an optimization in UninvertingReader that was causing incorrect results for Numeric fields using precisionStep (merge r1684704) "
        },
        {
            "id": "comment-14713141",
            "author": "Shalin Shekhar Mangar",
            "date": "2015-08-26T13:05:53+0000",
            "content": "Bulk close for 5.3.0 release "
        }
    ]
}