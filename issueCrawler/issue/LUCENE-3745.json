{
    "id": "LUCENE-3745",
    "title": "Need stopwords and stoptags lists for default Japanese configuration",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [
            "modules/analysis"
        ],
        "type": "Improvement",
        "fix_versions": [
            "3.6",
            "4.0-ALPHA"
        ],
        "affect_versions": "None",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "Stopwords and stoptags lists for Japanese needs to be developed, tested and integrated into Lucene.",
    "attachments": {
        "top-pos.txt": "https://issues.apache.org/jira/secure/attachment/12513239/top-pos.txt",
        "LUCENE-3745.patch": "https://issues.apache.org/jira/secure/attachment/12513290/LUCENE-3745.patch",
        "top-100000.txt": "https://issues.apache.org/jira/secure/attachment/12513237/top-100000.txt",
        "top-1000000-pos.txt": "https://issues.apache.org/jira/secure/attachment/12513238/top-1000000-pos.txt",
        "filter_stoptags.py": "https://issues.apache.org/jira/secure/attachment/12513240/filter_stoptags.py"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2012-02-04T05:46:00+0000",
            "content": "I'm attaching some lexical assets that are useful for building stopwords and stoptag lists.\n\nThe frequency lists are made from ~1.5 million segmented Japanese Wikipedia documents from after some scrubbing and handling.  I'd prefer to use a more balanced corpus for this, but I believe Wikipedia will be fine for this. \n\nThe following files are attached in TSV format using UTF-8 encoding:\n\n\n\ttop-pos.txt - Part-of-speech tag distribution\n\ttop-100000.txt - Top 100,000 most frequent surface forms and their frequencies\n\ttop-1000000-pos.txt - Top 1,000,000 most frequent surface form and part-of-speech tag combinations and their frequencies\n\n\n\nThere's also a tool filter_stoptags.py attached that reads a set of stoptags and evaluates it on top-1000000-pos.txt to give us an idea what passes through any given stoptag set.\n\nAn example with my current stoptag set is given below.\n\n\nfilter_stoptags.py -s stoptags.txt top-1000000-pos.txt\nstop: \u3001        freq: 14426806  pos: \u8a18\u53f7-\u8aad\u70b9\nstop: \u306e        freq: 14212851  pos: \u52a9\u8a5e-\u9023\u4f53\u5316\nstop: \u3002        freq: 10553747  pos: \u8a18\u53f7-\u53e5\u70b9\nstop: \u306f        freq: 8956177   pos: \u52a9\u8a5e-\u4fc2\u52a9\u8a5e\nstop: \u306b        freq: 8757138   pos: \u52a9\u8a5e-\u683c\u52a9\u8a5e-\u4e00\u822c\nstop: \u3092        freq: 7723958   pos: \u52a9\u8a5e-\u683c\u52a9\u8a5e-\u4e00\u822c\nstop:           freq: 7417005   pos: \u8a18\u53f7-\u7a7a\u767d\nstop: \u305f        freq: 7366368   pos: \u52a9\u52d5\u8a5e\nstop: \u304c        freq: 5427730   pos: \u52a9\u8a5e-\u683c\u52a9\u8a5e-\u4e00\u822c\nstop: \u3066        freq: 4874861   pos: \u52a9\u8a5e-\u63a5\u7d9a\u52a9\u8a5e\npass: \u3057        freq: 4312613   pos: \u52d5\u8a5e-\u81ea\u7acb\nstop: \u3067        freq: 3702106   pos: \u52a9\u8a5e-\u683c\u52a9\u8a5e-\u4e00\u822c\nstop:           freq: 3485125   pos: \u8a18\u53f7-\u7a7a\u767d\nstop: \uff09        freq: 3049861   pos: \u8a18\u53f7-\u62ec\u5f27\u9589\nstop: \uff08        freq: 3045461   pos: \u8a18\u53f7-\u62ec\u5f27\u958b\npass: \u308c        freq: 2722773   pos: \u52d5\u8a5e-\u63a5\u5c3e\npass: \u3055        freq: 2441965   pos: \u52d5\u8a5e-\u81ea\u7acb\nstop: \u3067        freq: 2403133   pos: \u52a9\u52d5\u8a5e\nstop: \u30fb        freq: 2250725   pos: \u8a18\u53f7-\u4e00\u822c\nstop: \u3082        freq: 1962142   pos: \u52a9\u8a5e-\u4fc2\u52a9\u8a5e\npass: \u3059\u308b      freq: 1959374   pos: \u52d5\u8a5e-\u81ea\u7acb\npass: \u3044\u308b      freq: 1937789   pos: \u52d5\u8a5e-\u975e\u81ea\u7acb\nstop: \u3068        freq: 1927529   pos: \u52a9\u8a5e-\u683c\u52a9\u8a5e-\u5f15\u7528\npass: \u5e74        freq: 1796435   pos: \u540d\u8a5e-\u63a5\u5c3e-\u52a9\u6570\u8a5e\nstop: \u300c        freq: 1701848   pos: \u8a18\u53f7-\u62ec\u5f27\u958b\nstop: \u3068        freq: 1697926   pos: \u52a9\u8a5e-\u683c\u52a9\u8a5e-\u4e00\u822c\nstop: \u300d        freq: 1672052   pos: \u8a18\u53f7-\u62ec\u5f27\u9589\nstop: \u304b\u3089      freq: 1414661   pos: \u52a9\u8a5e-\u683c\u52a9\u8a5e-\u4e00\u822c\nstop: \u3042\u308b      freq: 1400235   pos: \u52a9\u52d5\u8a5e\nstop:           freq: 1319235   pos: \u8a18\u53f7-\u7a7a\u767d\npass: \u3053\u3068      freq: 1272503   pos: \u540d\u8a5e-\u975e\u81ea\u7acb-\u4e00\u822c\nstop: \u306a        freq: 1254673   pos: \u52a9\u52d5\u8a5e\nstop: \u304c        freq: 1110771   pos: \u52a9\u8a5e-\u63a5\u7d9a\u52a9\u8a5e\npass: \u306e        freq: 1037815   pos: \u540d\u8a5e-\u975e\u81ea\u7acb-\u4e00\u822c\nstop: \u3068\u3057\u3066    freq: 1002940   pos: \u52a9\u8a5e-\u683c\u52a9\u8a5e-\u9023\u8a9e\nstop:           freq: 989166    pos: \u8a18\u53f7-\u7a7a\u767d\npass: \u3044        freq: 923836    pos: \u52d5\u8a5e-\u975e\u81ea\u7acb\n(...)\n\n ",
            "author": "Christian Moen",
            "id": "comment-13200339"
        },
        {
            "date": "2012-02-04T15:00:11+0000",
            "content": "I'll submit a patch for this tomorrow. ",
            "author": "Christian Moen",
            "id": "comment-13200461"
        },
        {
            "date": "2012-02-05T07:26:26+0000",
            "content": "Please find a patch attached.\n\nI've made stoptags.txt lighter by not stopping all prefixes and also allowing auxiliary verbs and interjections to pass.  I didn't come across any occurrences of unclassified symbols (\u8a18\u53f7) in Wikipedia, but it is now stopped as that seem to align better with our overall stop approach for symbols.\n\nMany of the most frequent terms that now pass have been re-introduced in stopwords.txt} so they are stopped using a {{StopFilter instead of KuromojiPartOfSpeechStopFilter.  I believe this configuration is more balanced.\n\nOverall, I've used the term frequencies attached to as a governing guideline for what to introduce into stopwords.txt.  It mostly contains hiragana words and expressions and I've deliberately left out common kanji as I'd like to keep the stopping fairly light.\n\nI'll create a separate JIRA for introducing stopwords and stoptags to Solr. ",
            "author": "Christian Moen",
            "id": "comment-13200680"
        },
        {
            "date": "2012-02-05T12:37:08+0000",
            "content": "Thanks for doing this, it will be much nicer to have a properly built configuration here!\n\nI agree with the overall approach of leaning towards the conservative side: if someone wants\nthey can always be more aggressive (and use the data on this issue as a guide).\n\n\n ",
            "author": "Robert Muir",
            "id": "comment-13200732"
        },
        {
            "date": "2012-02-05T12:49:14+0000",
            "content": "Thanks a lot for looking at this, Robert.  This was the thinking.  (I've referred to the issue in the stopwords and stoptags files.) ",
            "author": "Christian Moen",
            "id": "comment-13200747"
        },
        {
            "date": "2012-02-05T13:00:21+0000",
            "content": "Lets get my previous ad-hoc lists out of there \n\nI'll commit this for now and if there are any concerns we can reopen or refine in further issues. ",
            "author": "Robert Muir",
            "id": "comment-13200753"
        },
        {
            "date": "2012-02-05T13:07:53+0000",
            "content": "Thanks Christian! ",
            "author": "Robert Muir",
            "id": "comment-13200754"
        }
    ]
}