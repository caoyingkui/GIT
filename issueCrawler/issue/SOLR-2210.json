{
    "id": "SOLR-2210",
    "title": "Provide solr FilterFactory for Lucene ICUTokenizer",
    "details": {
        "affect_versions": "3.1",
        "status": "Open",
        "fix_versions": [],
        "components": [],
        "type": "New Feature",
        "priority": "Minor",
        "labels": "",
        "resolution": "Unresolved"
    },
    "description": "The Lucene ICUTokenizer provides many benefits for multilingual tokenizing.   There should be a ICUFilterFactory so that it can be used from Solr.   There are probably some issues in terms of passing configuration parameters.",
    "attachments": {
        "SOLR-2210.patch": "https://issues.apache.org/jira/secure/attachment/12458610/SOLR-2210.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Robert Muir",
            "id": "comment-12927048",
            "date": "2010-11-01T17:24:51+0000",
            "content": "Thanks for opening this, Tom.\n\nI've got some barebones filters for some of this stuff on my computer.\nBecause the ICU jar file is large, i was trying to see if i could solve LUCENE-2510 first, but this would only fix the problem for 4.0 anyway.\nI think we should just make an icu contrib for now, and put the factories (Tokenizer, Normalizer, Folding, Transliterator, Collation) and the jar file in there. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-12927053",
            "date": "2010-11-01T17:37:04+0000",
            "content": "actually another idea, would be to just make an 'extraAnalyzers' contrib. \nthen we could also add factories for smart chinese, polish etc, without creating a ton of contribs.\n\ni think this would be a good solution to expose all the lucene analyzers to Solr, \nsince to me, LUCENE-2510 seems tricky. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-12927304",
            "date": "2010-11-02T05:25:53+0000",
            "content": "here's a start: makes an analysis-extras contrib with all the build logic, and factories for the icu filters.\n\nstill todo: add support for custom normalization and custom tokenizer config, filters for smart chinese, and stempel.\n\nBut i think its ok to commit this as-is and improve it in svn. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-12927382",
            "date": "2010-11-02T12:45:38+0000",
            "content": "ok, i committed the baseline code (rev 1030012, rev 1030022 in 3x).\n\nwe can keep the issue open and just add patches against it for customization, etc.\nI just wanted to get all the build-system-stuff working so this was easy. "
        },
        {
            "author": "Christine Poerschke",
            "id": "comment-16002819",
            "date": "2017-05-09T14:50:49+0000",
            "content": "Thanks for committing the baseline code changes. Shall we close out this issue now then with any further changes to follow under a separate ticket, what do you think? "
        }
    ]
}