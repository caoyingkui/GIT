{
    "id": "LUCENE-7148",
    "title": "Support boolean subset matching",
    "details": {
        "resolution": "Not A Problem",
        "affect_versions": "None",
        "components": [
            "core/search"
        ],
        "labels": "",
        "fix_versions": [],
        "priority": "Major",
        "status": "Closed",
        "type": "New Feature"
    },
    "description": "In Lucene, I know of the possibility of Occur.SHOULD, Occur.MUST and the \u201cminimum should match\u201d setting on the boolean query.\n\nNow, when querying, I want to\n\n\t(1)  match the documents which either contain all the terms of the query (Occur.MUST for all terms would do that) or,\n\t(2)  if all terms for a given field of a document are a subset of the query terms, that document should match as well.\n\n\n\nExample:\nDocument d hast field f with terms A, B, C\nQuery with the following terms should match that document:\nA\nB\nA B\nA B C\nA B C D\nQuery with the following terms should not match:\nD\nA B D",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "id": "comment-15219346",
            "author": "David Smiley",
            "date": "2016-03-31T04:55:12+0000",
            "content": "FWIW I've done this years ago to implement search with special security rules that demand a user must have at least all of a set of auth tokens to match the document.  Today this is little easier thanks to FingerprintFilter on the indexing side.  On the search side, you can get creative with a RegexpQuery (easiest) or write a special Query implementation that works somewhat similar to but not the same as TermsQuery (what I had done) "
        },
        {
            "id": "comment-15226434",
            "author": "Igor Motov",
            "date": "2016-04-05T15:16:08+0000",
            "content": "I just want to mention that I have also seen many questions and requests for this feature on different elasticsearch forums. Here are a couple of examples from stackoverflow : \n\n\n\thttp://stackoverflow.com/questions/31258959/elasticsearch-documents-that-only-have-terms-intersecting-a-list-of-terms-but-no\n\thttp://stackoverflow.com/questions/32580295/elasticsearch-match-all-words-from-document-in-the-search-query\n\n\n\nIt seems to me that there is a need for such functionality.  "
        },
        {
            "id": "comment-15227378",
            "author": "Ahmet Arslan",
            "date": "2016-04-05T23:45:27+0000",
            "content": "can't we have a function query that just returns the number of matching terms here? Then we compare it with the document length. "
        },
        {
            "id": "comment-15227537",
            "author": "David Smiley",
            "date": "2016-04-06T01:39:56+0000",
            "content": "Ahment:  A FunctionQuery matches all documents and returns a custom score.  Perhaps you mean something like Solr's frange that filters based on the value?  That would be O(docs) as it evaluates per doc.  It's much preferable to leverage the index.\n\nAn example of an existing query using the regexp technique is here by Scott Stults: https://github.com/sstults/TermSubsetParser/blob/master/src/main/java/com/o19s/solr/TermSubsetQParserPlugin.java  (a custom Solr QParser).  Imagine making it configurable to take the separator char and then working with the FingerPrintFilter.  (as an aside, I wish FPF was named something like \"SortDedupeConcatFilter\") "
        },
        {
            "id": "comment-15227856",
            "author": "Mikhail Khludnev",
            "date": "2016-04-06T06:58:46+0000",
            "content": "It's much preferable to leverage the index.\nwhat if frange will be dragged by disjunction across all query terms?    "
        },
        {
            "id": "comment-15227887",
            "author": "Ahmet Arslan",
            "date": "2016-04-06T07:30:23+0000",
            "content": "Perhaps you mean something like Solr's frange that filters based on the value? \nExactly. Given that q=john smith, lets assume that we have a field titleLenght that stores the number of words in the field.  We can even extract that info from norm doc values later on. Something like: \n\n fq={!frange l=0 u=0 cache=false cost=200} sub(titleLength, sum(termfreq(title,'smith'), termfreq(title,'john'))) \n\n\nThat would be O(docs) as it evaluates per doc.\nCant we make this filter query executed last, with cache=false cost=150? "
        },
        {
            "id": "comment-15227916",
            "author": "Mikhail Khludnev",
            "date": "2016-04-06T08:02:22+0000",
            "content": "my solution is subtle different:\n\nfq={!frange cache=false l=0}sub(titleLength,sum(query($bq1),query($bq2),query($bq3),..))&bq1=title:smith^=1&bq2=title:john^=1&..&fq={!lucene df=title cache=false}john smith ..\n\n \nIt works, though a little bit verbose. I don't see what can be built in Solr or Lucene, I'd rather see it as a hackish oneliner, which is as verbose as rarely useful.   "
        },
        {
            "id": "comment-15228349",
            "author": "David Smiley",
            "date": "2016-04-06T14:33:46+0000",
            "content": "Ah, the ^= syntax with sum is clever!  Nonetheless I wonder what would perform better \u2013 the regexp technique or this.  I suspect the regexp based on the wonderful optimizations within Lucene for AutomatonQuery.  On the other hand, the 2-phase (Solr postfilter) technique would be fastest in the event there are lots of other discriminating queries in-play that reduce the matching set a ton. "
        },
        {
            "id": "comment-15231917",
            "author": "Otmar Caduff",
            "date": "2016-04-08T09:23:01+0000",
            "content": "David, your first comment regarding the FingerprintFilter pointed me to a solution that works for me.\n\nWhat I forgot to mention was that I also need the terms to match with some levenshtein distance. This is why I couldn't just be \"creative\" with RegexpQuery. Finally, I ended up with AutomatonQuery in conjunction with LevenshteinAutomata.\n\nIf no one insists I'll close the issue, since there seem to be quite some viable options to deal with these kinds of problems. "
        },
        {
            "id": "comment-15232175",
            "author": "David Smiley",
            "date": "2016-04-08T13:31:19+0000",
            "content": "Yeah, I suggest closing.  I guess this is the kind of thing better done higher up the stack (Solr/ES/...) since there isn't a real lack of anything from Lucene, it's more of a matter of which existing Lucene parts do you stitch together for multiple possible implementations. "
        },
        {
            "id": "comment-15245516",
            "author": "Otmar Caduff",
            "date": "2016-04-18T11:51:07+0000",
            "content": "There seem to be quite some viable options to deal with these kinds of problems. See previous comments. "
        }
    ]
}