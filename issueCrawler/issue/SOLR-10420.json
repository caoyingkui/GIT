{
    "id": "SOLR-10420",
    "title": "Solr 6.x leaking one SolrZkClient instance per second",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [],
        "type": "Bug",
        "fix_versions": [
            "5.5.5",
            "5.6",
            "6.5.1",
            "6.6",
            "7.0"
        ],
        "affect_versions": "5.5.2,                                            6.4.2,                                            6.5",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "One of our nodes became berzerk after a restart, Solr went completely nuts! So i opened VisualVM to keep an eye on it and spotted a different problem that occurs in all our Solr 6.4.2 and 6.5.0 nodes.\n\nIt appears Solr is leaking one SolrZkClient instance per second via DistributedQueue$ChildWatcher. That one per second is quite accurate for all nodes, there are about the same amount of instances as there are seconds since Solr started. I know VisualVM's instance count includes objects-to-be-collected, the instance count does not drop after a forced garbed collection round.\n\nIt doesn't matter how many cores or collections the nodes carry or how heavy traffic is.",
    "attachments": {
        "OverseerTest.106.stdout": "https://issues.apache.org/jira/secure/attachment/12863247/OverseerTest.106.stdout",
        "OverseerTest.DEBUG.58.stdout": "https://issues.apache.org/jira/secure/attachment/12863262/OverseerTest.DEBUG.58.stdout",
        "OverseerTest.80.stdout": "https://issues.apache.org/jira/secure/attachment/12863053/OverseerTest.80.stdout",
        "SOLR-10420-dragonsinth.patch": "https://issues.apache.org/jira/secure/attachment/12863715/SOLR-10420-dragonsinth.patch",
        "OverseerTest.DEBUG.43.stdout": "https://issues.apache.org/jira/secure/attachment/12863260/OverseerTest.DEBUG.43.stdout",
        "OverseerTest.119.stdout": "https://issues.apache.org/jira/secure/attachment/12863248/OverseerTest.119.stdout",
        "OverseerTest.DEBUG.48.stdout": "https://issues.apache.org/jira/secure/attachment/12863261/OverseerTest.DEBUG.48.stdout",
        "SOLR-10420.patch": "https://issues.apache.org/jira/secure/attachment/12863004/SOLR-10420.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2017-04-04T15:00:58+0000",
            "content": "Nothing changed in that code in the last few releases. Do you know if this worked fine in a prior 6x release?\nFYI, Scott Blum and Shalin Shekhar Mangar <-- experts in that code. ",
            "author": "Ishan Chattopadhyaya",
            "id": "comment-15955222"
        },
        {
            "date": "2017-04-04T15:30:10+0000",
            "content": "I only have 6.5.0 and a not-yet upgraded 6.4.2, both suffer the same.\n\nBut i just built a 6.3.0, ran it in cloud mode without registering a collection or core using the built-in Zookeeper. After two minutes, i had ~120 client objects, now i have more.\n\n6.0.0 doesn't show increased instance counts. Can't test 6.1 and 6.2, ant keeps hanging on resolve for whatever reason. ",
            "author": "Markus Jelsma",
            "id": "comment-15955253"
        },
        {
            "date": "2017-04-04T15:34:15+0000",
            "content": "The ant resolve could hang due to lock files. You could try this: find ~ -name \"*lck\" | xargs rm. ",
            "author": "Ishan Chattopadhyaya",
            "id": "comment-15955259"
        },
        {
            "date": "2017-04-04T15:46:04+0000",
            "content": "Ah, i found it, the problem appeared in 6.1.0. Versions 6.0.0 and 6.0.1 do not show this problem, the instances are eaten by GC. ",
            "author": "Markus Jelsma",
            "id": "comment-15955282"
        },
        {
            "date": "2017-04-04T15:48:15+0000",
            "content": "Hard to see how the problem could be localized to DistributedQueue$ChildWatcher.. it doesn't create any ZkClients, it's passed in from the outside. ",
            "author": "Scott Blum",
            "id": "comment-15955283"
        },
        {
            "date": "2017-04-04T15:51:49+0000",
            "content": "Well, actually DistributedQueue$ChildWatcher is being leaked well, so leaking of SolrZkClient could be a consequence of that.\n ",
            "author": "Markus Jelsma",
            "id": "comment-15955287"
        },
        {
            "date": "2017-04-04T15:56:53+0000",
            "content": "To note another oddity, some nodes of our regular search cluster (6.5.0) do not show increased counts. Some nodes with other roles (but running Solr) show the problem immediately after each restart every time i restarted them today. So it could be 6.0.1 and 6.0.0 also show the problem, although they didn't when i just tested them. ",
            "author": "Markus Jelsma",
            "id": "comment-15955293"
        },
        {
            "date": "2017-04-04T18:11:51+0000",
            "content": "To be clear, these are uncollectable objects? ",
            "author": "Walter Underwood",
            "id": "comment-15955538"
        },
        {
            "date": "2017-04-04T18:33:54+0000",
            "content": "So it seems. Forced GC does not remove the object instances in >= 6.1.0. In 6.0.x regular GC and forced GC does remove the instances from the object count. I think almost everyone should be able to see it for themselves, almost all our Solr instances show this problem immediately after restart, some don't in some occasions.\n\nAlthough they don't consume a lot of bytes, the problem appears to cause more CPU time being used up.\n\nFiltering the memory sampler for org.apache.solr.common reveals it right away. Also, the number of instances should correspond the the number of seconds the instance is running. A node running how about six days has roughly 500k instances, one running roughly 30 minutes just below 2k. ",
            "author": "Markus Jelsma",
            "id": "comment-15955575"
        },
        {
            "date": "2017-04-12T10:51:09+0000",
            "content": "Patch for this ticket. This problem was introduced by SOLR-9191. Serious problem for Solr 6.x ",
            "author": "Cao Manh Dat",
            "id": "comment-15965658"
        },
        {
            "date": "2017-04-12T13:03:11+0000",
            "content": "This patch appears to solve the problem.  ",
            "author": "Markus Jelsma",
            "id": "comment-15965790"
        },
        {
            "date": "2017-04-12T14:37:54+0000",
            "content": "I ran all Solr tests with the patch on master, and one test failed: \n\n\n   [junit4]   2> 264992 ERROR (OverseerExitThread) [    ] o.a.s.c.Overseer could not read the data\n   [junit4]   2> org.apache.zookeeper.KeeperException$SessionExpiredException: KeeperErrorCode = Session expired for /overseer_elect/leader\n   [junit4]   2>        at org.apache.zookeeper.KeeperException.create(KeeperException.java:127)\n   [junit4]   2>        at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)\n   [junit4]   2>        at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1155)\n   [junit4]   2>        at org.apache.solr.common.cloud.SolrZkClient$7.execute(SolrZkClient.java:356)\n   [junit4]   2>        at org.apache.solr.common.cloud.SolrZkClient$7.execute(SolrZkClient.java:353)\n   [junit4]   2>        at org.apache.solr.common.cloud.ZkCmdExecutor.retryOperation(ZkCmdExecutor.java:60)\n   [junit4]   2>        at org.apache.solr.common.cloud.SolrZkClient.getData(SolrZkClient.java:353)\n   [junit4]   2>        at org.apache.solr.cloud.Overseer$ClusterStateUpdater.checkIfIamStillLeader(Overseer.java:290)\n   [junit4]   2>        at java.lang.Thread.run(Thread.java:745)\n   [junit4]   2> NOTE: reproduce with: ant test  -Dtestcase=OverseerTest -Dtests.method=testExternalClusterStateChangeBehavior -Dtests.seed=2110CE0AEF674CFA -Dtests.slow=true -Dtests.locale=es-GT -Dtests.timezone=Asia/Kolkata -Dtests.asserts=true -Dtests.file.encoding=UTF-8\n   [junit4] FAILURE 5.46s J12 | OverseerTest.testExternalClusterStateChangeBehavior <<<\n   [junit4]    > Throwable #1: java.lang.AssertionError: Illegal state, was: down expected:active clusterState:live nodes:[]collections:{c1=DocCollection(c1//clusterstate.json/2)={\n   [junit4]    >   \"shards\":{\"shard1\":{\n   [junit4]    >       \"parent\":null,\n   [junit4]    >       \"range\":null,\n   [junit4]    >       \"state\":\"active\",\n   [junit4]    >       \"replicas\":{\"core_node1\":{\n   [junit4]    >           \"base_url\":\"http://127.0.0.1/solr\",\n   [junit4]    >           \"node_name\":\"node1\",\n   [junit4]    >           \"core\":\"core1\",\n   [junit4]    >           \"roles\":\"\",\n   [junit4]    >           \"state\":\"down\"}}}},\n   [junit4]    >   \"router\":{\"name\":\"implicit\"}}, test=LazyCollectionRef(test)}\n   [junit4]    >        at __randomizedtesting.SeedInfo.seed([2110CE0AEF674CFA:490ECDE60DF716B4]:0)\n   [junit4]    >        at org.apache.solr.cloud.AbstractDistribZkTestBase.verifyReplicaStatus(AbstractDistribZkTestBase.java:273)\n   [junit4]    >        at org.apache.solr.cloud.OverseerTest.testExternalClusterStateChangeBehavior(OverseerTest.java:1259)\n\n\n\nI ran the repro line a couple of times and it didn't reproduce.  I then beasted 100 iterations of the test suite using Miller's beasting script, and it failed once.  I'm attaching the test log from the failure.\n\nLooking at emailed Jenkins reports of testExternalClusterStateChangeBehavior() failing, I see that it was failing almost daily until the day SOLR-9191 was committed (June 9, 2016), and then zero failures since, so this failure seems suspicious to me, since this issue is related to SOLR-9191.\n\nI beasted 200 iterations of OverseerTest without the patch, and got zero failures. ",
            "author": "Steve Rowe",
            "id": "comment-15965973"
        },
        {
            "date": "2017-04-13T03:34:59+0000",
            "content": "Steve Rowe I think this is problem of the test. Can you run the test with this patch ( I increased the amount of time waiting for replica become active ). I also run testExternalClusterStateChangeBehavior for 1000 times and can not find any failure. ",
            "author": "Cao Manh Dat",
            "id": "comment-15967064"
        },
        {
            "date": "2017-04-13T05:18:00+0000",
            "content": "A patch for this ticket. In this patch, we reuse the ChildWatcher (this is Noble idea) so in any case ( race conditions ) we always reach the line\n\nlastWatcher = null\n\n ",
            "author": "Cao Manh Dat",
            "id": "comment-15967149"
        },
        {
            "date": "2017-04-13T05:33:23+0000",
            "content": "Ran the test with original patch as well as 15s timeout patch 250 times each. I saw no failures. I can run this on better hardware early next week (my AMD Ryzen is arriving soon!). ",
            "author": "Ishan Chattopadhyaya",
            "id": "comment-15967158"
        },
        {
            "date": "2017-04-13T11:19:43+0000",
            "content": "I beasted the latest patch (the one without the increased OverseerTest timeouts) for 200 iterations and got 2 failures - I've attached their logs: OverseerTest.106.stdout and OverseerTest.119.stdout.\n\nNext I'll try the patch with the OverseerTest changes. ",
            "author": "Steve Rowe",
            "id": "comment-15967425"
        },
        {
            "date": "2017-04-13T11:48:06+0000",
            "content": "Next I'll try the patch with the OverseerTest changes.\n\nI got 4 failures from 100 beasting iterations using this version of the patch.  The failures looked the same as the previously posted logs, so I won't add them.\n\nNext I'll try beasting the latest patch again, this time with DEBUG level on org.apache.solr.cloud. ",
            "author": "Steve Rowe",
            "id": "comment-15967470"
        },
        {
            "date": "2017-04-13T12:12:02+0000",
            "content": "I got 5 failures out of 100, attaching 3 of them here: OverseerTest.DEBUG.43.stdout, OverseerTest.DEBUG.48.stdout, OverseerTest.DEBUG.58.stdout ",
            "author": "Steve Rowe",
            "id": "comment-15967499"
        },
        {
            "date": "2017-04-14T05:07:27+0000",
            "content": "Fix LGTM.\n\nIs this actual fix this?\n\n```\n      // we're not in a dirty state, and we do not have in-memory children\n      if (lastWatcher != null) return null;\n```\n\nIE, if you just do that, would that fix the leak even without reusing the same object? ",
            "author": "Scott Blum",
            "id": "comment-15968618"
        },
        {
            "date": "2017-04-14T10:24:39+0000",
            "content": "It's actually fix the problem even without reusing the same object. But It makes the OverseerTest fail. ",
            "author": "Cao Manh Dat",
            "id": "comment-15968869"
        },
        {
            "date": "2017-04-15T07:12:58+0000",
            "content": "I kinda find out the reason why the test failure. There are some notice here\n\n\tIn current DQ version, for each time we peek() if in-memory queue is empty, we will actually look at the ZK to get new elements ( watcher are useless in this scenario )\n\tWith the patch, for each time we peek()  if in-memory queue is empty, we will only look at the ZK nodes when watcher tell us that there are change in our queue. So If ZK already contain new items we may still return empty.\n\n\n\nSo this is the reason why the test failure\n\n\toverseer.queue <- set a replica down\n\toverseer run the command successfully\n\toverseer.queue <- set a replica active\n\toverseer delay this command ( overseer.workqueue <- set a replica active )\n\ttouch /clusterstate.json to change its version\n\toverseer.queue <- some ZKWriteCommand, let's call this one ZK1\n\toverseer change the clusterstate to set replica active\n\toverseer meet badversion exception\n\toverseer fetch last element from overseer.workqueue. Here are where problem happen, overseer.workqueue.peek() return empty because the watcher is not fired.\n\toverseer process ZK1, it success -> overseer.workqueue is emptied.\n\n ",
            "author": "Cao Manh Dat",
            "id": "comment-15969839"
        },
        {
            "date": "2017-04-15T07:23:31+0000",
            "content": "I'm thinking about two different way to solve this problem :\n1. DQ will set lastWatcher = null when we run DQ.offer(byte[] data) sucessfully. Because the overseer.workqueue is locally offered by overseer so that will fix the problem. But we changed DQ.peek() from true positive ( if ZK contain new item, we will return that ) to false positive ( if ZK contain new item, we may not return that ) so this may inflict other parts as well.\n2. each time DQ.peek() is called we will look at the ZK nodes without using the watcher. ",
            "author": "Cao Manh Dat",
            "id": "comment-15969843"
        },
        {
            "date": "2017-04-15T08:30:16+0000",
            "content": "I have a discussion with Noble. It seems that DQ are not used in any places except Overseer. So I will go with solution #1.\n\nWill beast the test in Steve machine tonight ( thanks Steve Rowe a lot ) ",
            "author": "Cao Manh Dat",
            "id": "comment-15969865"
        },
        {
            "date": "2017-04-15T13:55:12+0000",
            "content": "Scott Blum Can you review the patch? ",
            "author": "Cao Manh Dat",
            "id": "comment-15969966"
        },
        {
            "date": "2017-04-15T17:14:03+0000",
            "content": "Let me try to unpack what you said..\n\n1) We want a synchronous offer() -> peek() on the same thread to return the item offered without delay.\n2) This works on master, but the original patch to fix the leak breaks #1.\n\nIs that correct?\n\nLet me look at this on Monday with Joshua Humphries.  I'm pretty sure there's a simplification to be made in DQ with how we're handling the watcher and dirty tracking.  There used to be an explicit \"isDirty\" bit that we traded out for watcher nullability, which in retrospect I'm not sure was the best choice. ",
            "author": "Scott Blum",
            "id": "comment-15970030"
        },
        {
            "date": "2017-04-16T00:10:12+0000",
            "content": "Scott Blum that's correct.\n\nThe last patch pass all the tests.  ",
            "author": "Cao Manh Dat",
            "id": "comment-15970205"
        },
        {
            "date": "2017-04-16T00:59:51+0000",
            "content": "Scott Blum As Steve said, Overseer.external.. test failed frequently before SOLR-9191 got committed. So I doubt that \"isDirty\" in retro-code will fix the problem. ",
            "author": "Cao Manh Dat",
            "id": "comment-15970215"
        },
        {
            "date": "2017-04-17T10:33:22+0000",
            "content": "Latest patch, I would like not to reuse lastWatcher. It can come to this case\n\npeek -> lastWatcher = resuseWatcher (1)\noffer -> lastWatcher = null\npeek -> lastWatcher = reuseWatcher (2)\n(1) event -> lastWatcher = null\n\n ",
            "author": "Cao Manh Dat",
            "id": "comment-15970955"
        },
        {
            "date": "2017-04-17T15:54:15+0000",
            "content": "Cao Manh Dat I didn't literally mean that we should bring back the isDirty bit.  I meant that clearly the last time around, there was a hole in the design that led to this leak.  I want to take the opportunity to re-look at the design again as a whole and make sure everything seems good, and we're not just putting a band-aid on it.  You may have already done this, so just give me a little bit to catch up.  ",
            "author": "Scott Blum",
            "id": "comment-15971259"
        },
        {
            "date": "2017-04-17T22:31:02+0000",
            "content": "Cao Manh Dat Joshua Humphries I think this may be the right approach after reviewing the overall design.  I don't see any real reason to specifically track lastWatcher, we just need to ensure that no more than one is ever set.  And having lastWatcher serve double-duty was a misdesign on my part.  There are really two separate stateful questions to answer:\n\n1) Is there a watcher set?\n2) Are we known to be dirty?\n\nThe answer to those two questions is not the same if we want to support same-thread synchronous offer -> poll working as you would want.  So this patch tracks them separately. ",
            "author": "Scott Blum",
            "id": "comment-15971753"
        },
        {
            "date": "2017-04-18T01:37:08+0000",
            "content": "Scott Blum The patch LGTM! \nI think this is good to reuse the watcher in your patch. ",
            "author": "Cao Manh Dat",
            "id": "comment-15971964"
        },
        {
            "date": "2017-04-18T17:06:28+0000",
            "content": "Scott Blum This issue is blocker for Solr 6.5.1. So I think we (you) should commit soon. ",
            "author": "Cao Manh Dat",
            "id": "comment-15973070"
        },
        {
            "date": "2017-04-18T17:13:40+0000",
            "content": "Agreed.  It passes for me.  Anyone on this issue want to do any extensive testing of https://issues.apache.org/jira/secure/attachment/12863715/SOLR-10420-dragonsinth.patch before I commit?  Otherwise I'll commit this today to master and then start backporting it to a number of branches. ",
            "author": "Scott Blum",
            "id": "comment-15973093"
        },
        {
            "date": "2017-04-18T17:31:14+0000",
            "content": "I did 500 beasting iterations of OverseerTest using your latest patch Scott Blum, zero failures.\n\nI'm running the full Solr core test suite a couple times now, I'll report back when it finishes (should be less than half an hour). ",
            "author": "Steve Rowe",
            "id": "comment-15973118"
        },
        {
            "date": "2017-04-18T18:15:29+0000",
            "content": "I'm running the full Solr core test suite a couple times now, I'll report back when it finishes (should be less than half an hour).\n\nI ran the solr-core and solrj suites three times each with Scott Blum's latest patch on master, and there were zero failures. ",
            "author": "Steve Rowe",
            "id": "comment-15973207"
        },
        {
            "date": "2017-04-18T18:30:32+0000",
            "content": "Great!  Thanks Steve Rowe!  I'll get this committed. ",
            "author": "Scott Blum",
            "id": "comment-15973246"
        },
        {
            "date": "2017-04-18T18:44:30+0000",
            "content": "Commit 43c2b2320dcf344c42086ceb782e0fc53c439952 in lucene-solr's branch refs/heads/master from Scott Blum\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=43c2b23 ]\n\nSOLR-10420: fix watcher leak in DistributedQueue ",
            "author": "ASF subversion and git services",
            "id": "comment-15973261"
        },
        {
            "date": "2017-04-18T19:14:35+0000",
            "content": "So my plan is to commit this to master, branch_6x, and branch_5x, and let the release managers pull it into the actual release branches.  SG? ",
            "author": "Scott Blum",
            "id": "comment-15973320"
        },
        {
            "date": "2017-04-18T19:22:39+0000",
            "content": "So my plan is to commit this to master, branch_6x, and branch_5x, and let the release managers pull it into the actual release branches. SG?\n\nI think at a minimum you should also commit to branch_6_5, since it's definitely going to be released, and you'll be better equipped to handle conflicts if there are any.\n\nI noticed you set fixVersion to releases on branches you won't be committing to: 6.4.3, 5.5.5.  I don't think you should do that.  If you're going to commit to branch_5x, then the fixVersion would be 5.6, since that's the next release on that branch.  Unless you commit to branch_6_4, you shouldn't include 6.4.3 as a fixVersion.\n\nMore generally, if you think it's essential that any X.Y.Z release includes this fix, i.e. that it would be a mistake to release without it, then you should commit to the branch from which that release will be made.  Otherwise you and others may/will forget to backport when such a release materializes. ",
            "author": "Steve Rowe",
            "id": "comment-15973330"
        },
        {
            "date": "2017-04-18T19:23:07+0000",
            "content": "I think you should do master, branch_6x and branch_6_5. branch_5x is optional. ",
            "author": "Ishan Chattopadhyaya",
            "id": "comment-15973331"
        },
        {
            "date": "2017-04-18T19:33:24+0000",
            "content": "Got it.  I do think it would be a mistake.  In that case, after I've committed to 5x and 6x, I'll also commit to 6_5 and 5_5. ",
            "author": "Scott Blum",
            "id": "comment-15973346"
        },
        {
            "date": "2017-04-18T19:36:45+0000",
            "content": "Commit ae55dfc10fd3843d35df9096b7626aad36735670 in lucene-solr's branch refs/heads/branch_6x from Scott Blum\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=ae55dfc ]\n\nSOLR-10420: fix watcher leak in DistributedQueue ",
            "author": "ASF subversion and git services",
            "id": "comment-15973351"
        },
        {
            "date": "2017-04-18T19:38:17+0000",
            "content": "Commit 42d08dd28c6609a2c70a691e6a88725c9aa31377 in lucene-solr's branch refs/heads/branch_5x from Scott Blum\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=42d08dd ]\n\nSOLR-10420: fix watcher leak in DistributedQueue ",
            "author": "ASF subversion and git services",
            "id": "comment-15973354"
        },
        {
            "date": "2017-04-18T20:04:25+0000",
            "content": "Commit e3beb61a72efbce37710ce3cc48b24093070d052 in lucene-solr's branch refs/heads/branch_6_5 from Scott Blum\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=e3beb61 ]\n\nSOLR-10420: fix watcher leak in DistributedQueue ",
            "author": "ASF subversion and git services",
            "id": "comment-15973382"
        },
        {
            "date": "2017-04-18T20:43:54+0000",
            "content": "Commit 89beee8d61346d50dbbf02f0cc9cfc5032e46eee in lucene-solr's branch refs/heads/branch_5_5 from Scott Blum\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=89beee8 ]\n\nSOLR-10420: fix watcher leak in DistributedQueue ",
            "author": "ASF subversion and git services",
            "id": "comment-15973453"
        },
        {
            "date": "2017-04-19T09:55:50+0000",
            "content": "Thanks! Great work! ",
            "author": "Markus Jelsma",
            "id": "comment-15974402"
        }
    ]
}