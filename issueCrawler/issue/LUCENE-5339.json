{
    "id": "LUCENE-5339",
    "title": "Simplify the facet module APIs",
    "details": {
        "components": [
            "modules/facet"
        ],
        "fix_versions": [
            "4.7",
            "6.0"
        ],
        "affect_versions": "None",
        "priority": "Major",
        "labels": "",
        "type": "Improvement",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "I'd like to explore simplifications to the facet module's APIs: I\nthink the current APIs are complex, and the addition of a new feature\n(sparse faceting, LUCENE-5333) threatens to add even more classes\n(e.g., FacetRequestBuilder).  I think we can do better.\n\nSo, I've been prototyping some drastic changes; this is very\nearly/exploratory and I'm not sure where it'll wind up but I think the\nnew approach shows promise.\n\nThe big changes are:\n\n\n\tInstead of *FacetRequest/Params/Result, you directly instantiate\n    the classes that do facet counting (currently TaxonomyFacetCounts,\n    RangeFacetCounts or SortedSetDVFacetCounts), passing in the\n    SimpleFacetsCollector, and then you interact with those classes to\n    pull labels + values (topN under a path, sparse, specific labels).\n\n\n\n\n\tAt index time, no more FacetIndexingParams/CategoryListParams;\n    instead, you make a new SimpleFacetFields and pass it the field it\n    should store facets + drill downs under.  If you want more than\n    one CLI you create more than one instance of SimpleFacetFields.\n\n\n\n\n\tI added a simple schema, where you state which dimensions are\n    hierarchical or multi-valued.  From this we decide how to index\n    the ordinals (no more OrdinalPolicy).\n\n\n\nSparse faceting is just another method (getAllDims), on both taxonomy\n& ssdv facet classes.\n\nI haven't created a common base class / interface for all of the\nsearch-time facet classes, but I think this may be possible/clean, and\nperhaps useful for drill sideways.\n\nAll the new classes are under oal.facet.simple.*.\n\nLots of things that don't work yet: drill sideways, complements,\nassociations, sampling, partitions, etc.  This is just a start ...",
    "attachments": {
        "LUCENE-5339.patch": "https://issues.apache.org/jira/secure/attachment/12613450/LUCENE-5339.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2013-11-12T23:07:56+0000",
            "content": "Starting patch. ",
            "author": "Michael McCandless",
            "id": "comment-13820626"
        },
        {
            "date": "2013-11-13T10:01:23+0000",
            "content": "Some comments about the patch:\n\n\n\tYou have a TODO file which seems to have been 'svn added' - are you aware of it? Just making sure, so it's not accidentally committed \n\n\n\n\n\tMaybe we should do this work in a branch and avoid the .simple package? It seems that the majority of the patch is about copy-pasting classes over to .simple, which I assume you did so you can work in isolation and have tests pass?\n\n\n\n\n\tFieldTypes:\n\t\n\t\tCan FT.FieldType provide a ctor taking these arguments and then DEFAULT_FIELD_TYPE pass (false,false)? Or, init those two members to false.\n\t\tI wonder if FieldTypes won't confuse users w/ Field.FieldType, so maybe you should name it DimType or something? And the upper class FacetsConfig?\n\t\tMaybe instead of setHierarchical + setMultiValued you do setDimType(DimType)? Then you could avoid the synchronization?\n\t\tNot sure, but I think that SimpleFacetFields adds the dimension's ordinal if the dim is both hierarchical and multi-valued? That's a step back from the default ALL_BUT_DIM that we have today. I think we might want to have a requiresDimValue or something, because I do think the dimension's value (count) is most often unneeded, and it's a waste to encode its ordinal?\n\t\n\t\n\n\n\n\n\tConstants isn't documented, not sure if 'precommit' will like that, but in general I think the constants should have jdocs. Maybe put a nocommit?\n\n\n\n\n\tTaxonomyFacetCounts\n\t\n\t\t.getAllDims() \u2013 If a dimension is not hierarchical, I think SimpleFacetResult.count == 0? In that case, sorting by its count is useless?\n\t\t\n\t\t\tI think it's also relevant for SortedSet?\n\t\t\n\t\t\n\t\n\t\n\n\n\n\n\tLabelAndValue has a Number as the value rather than double. I see this class is used only in the final step (labeling), but what's wrong w/ the previous 'double' primitive? Is it to avoid casting or something?\n\n\n\nOn the approach in general - I personally don't think the current API is overwhelming, but looking at your patch, I do think it could use some simplification. But all in all, it allows an app extend the facets capabilities in ways that do not force it to duplicate a lot of code. Let me explain:\n\nCategoryListIterator\n\nThat's the piece of code which is responsible for decoding the category list. It's currently used for two purposes: (1) allow you to encode the categories in different formats (using IntEncoder/Decoder abstraction) as well as load the categories from a different source. E.g. that's how we were able to test fast cutting over facets to DV from Payload, that's a nice abstraction for letting you load the values from a cache, and so forth.\n\nIf you want to specialize code, you can do what FastCountingFacetsAggregator does \u2013 if you encoded w/ DGapVInt and you want counting, it doesn't go through the CLI API. But if you look at SumScoreFacetsAggregator, there's no reason for it to be limited to just DGapVInt encoding, or that you (the app) won't be able to pull the ordinals from a cache, without rewriting SumScoreFacetsAggregator.\n\nHack, even though it's not implemented yet, we could implement a SortedSetCLI (as far as I can tell) which uses SortedSetDVReaderState to pull the ordinals of document. It's really a useful interface.\n\nSo IMO the CLI interface is important. Most apps, I believe, don't extend the facets module (they'll use counting and maybe aggregate by ValueSource pre-built classes). But those that do want to add another aggregation method (e.g. ValueSourceFacetsAggregator), can simply use the CLI API, or copy-paste the DGapVInt decode logic if they want to specialize. Especially that that code is not that trivial, and we've spent a lot of time optimizing it. And the few apps that want to explore other encoding/decoding logic can write their own CLI.\n\nWithout that interface, if e.g. you want to encode the ordinals differently, or load them from a cache (e.g. CachedOrds), you'd have to rewrite every aggregation method that you want to use. And most probably you'll copy-paste the majority of the code. So why let go of the interface?\n\nFacetsCollector\n\nIt's pretty much your SimpleFC, only it requires to get a FacetsAccumulator. That was done as a convenience so that apps can send in a collector and then call fc.getFacetResults. But its essense is really the fact that it collects MatchingDocs per segment, which the aggregators later use to aggreate the faces in those matching docs.\n\nGiven the changes in this patch, +1 for making it just return the List<MatchingDocs> and let whatever API we decide on to use that list, instead of FC.getFacetResults().\n\nFacetsAggregator\n\nThis class lets you implement the aggregation function, be it count, sum-score, value-source or by-association. I think it's equivalent to TaxoFacetCounts, e.g. in your approach, if anyone will want to aggregate the ordinals by other than count, that's what they will need to write.\n\nWhat I like about the approach in your patch is that (and I had similar thoughts on the last round of API changes) it \"reverses\" the flow. The app says \"I want to count the ords in that field, and sum-score the ords in that field\" and then the app can ask for the aggregated values from each such aggregator. Whereas today, app does \"new CFR(), new CFR(), new CFR(), new SumScore()\" and then receives back the List<FacetResult>. Today's API is convenient in that it allows you to pass a List<FR> around in your code and get back a List<FacetResult>. But I don't see this convenience getting away (you'll just pass a List<FacetsAggregator> and then pull the requested values later on). Also, you sort of pulled the specific requests, such as .getSpecificCount(CP) and .getAllDims() up to FacetsAggregator, where today this can be done by FacetResultsHandler (you'd have to write one, as I did on LUCENE-5333).\n\nWhat I like less about it is that it folds in the logic coded by FacetsAccumulator and FacetResultsHandler:\n\n\n\tFacetsAccumulator\n\t\n\t\tInvokes FacetsAggregator to aggregate the facets in MatchingDocs\n\t\tWhether the request specifies a CP for which we need to rollupValues, it asks the aggregator to do so\n\t\tIt uses a FacetResultsHandler to compute the top-K facets for each request.\n\t\n\t\n\n\n\n\n\tFacetResultsHandler\n\t\n\t\tComputes top-K values for each parent category\n\t\tHas variants that return a full sub-tree (TopKInEachNodeHandler)\n\t\tBy means of extension, allows you to get the value of a specific CategoryPath, as well as get values for all dimensions (as I've shown on LUCENE-5333).\n\t\n\t\n\n\n\nSo I'm torn here. I really like how the API lets you extend things, and only the things that you care about. If you only want to implement a ValueSourceFacetsAggregator, you shouldn't be worried about whether or not to call rollupValues or how to compute top-K. That seems redundant. You should focus on what you want to extend. I also like less the fact that now every TaxoFacetsSomething will need to be aware of the facets configuration...\n\nBut I do like the approach presented in the patch, so I wonder if there's anything we can do to preserve the focused extension points on one hand, yet simplify the app's integration with the API on the other hand. Like, if an app did something like this:\n\n\nFacetsAccumulator fa = new TaxoFA(..., matchingDocs, new CountingFacetsAggregator(\"dvFacets1\", [CategoryListIterator]), [FacetResultsHandler]); // or SortedSetFA()\nfa.getTopK(dimension); // or fa.getTopK(new CategoryPath(...))\nfa.getValueOf(CategoryPath);\nfa.getAllDimensions(); // does not depend on the aggregation function, only needs the Taxonomy and int[]/float[] array source.\n\nfa = new TaxoFA(..., matchingDocs, new SumScoreFacetsAggregator(\"dvFacets2\", [CategoryListIterator]), [FacetResultsHandler]); // or SortedSetFA()\nfa.getTopK(dimension); // or fa.getTopK(new CategoryPath(...))\nfa.getValueOf(CategoryPath);\nfa.getAllDimensions();\n\nfa = new TaxoFA(..., matchingDocs, new SumIntAssociationFacetsAggregator(\"dvFacets3\"), [FacetResultsHandler]); // no CLI or SortedSetFA\nfa.getTopK(dimension); // or fa.getTopK(new CategoryPath(...))\nfa.getValueOf(CategoryPath);\nfa.getAllDimensions();\n\nRangeAccumulator range = new RangeAccumulator(..., matchingDocs, ranges); // RangeAccumulator might not even extend FacetsAccumulator\nrange.getTopK(dimension);\n// I think the rest of the getters make no sense?\n\n\n\nThe idea is that internally, FacetsAccumulator uses FacetsAggregator to do the aggregation and rollup if needed, and you can optionally pass a FacetResultsHandler, while it defaults to a FlatFacetResultsHandler (today's silly name DepthOneFRH). You can also pass your CategoryListIterator to the FacetsAggregator (those that need it). That way, app's code looks similar to the one in the patch, only we allow more code reuse between different aggregation functions.\n\nI hope this will allow us to support other aggregation functions by SortedSet too, as there's really no reason why not to do it. There are two differences between SortedSet and TaxoIndex: (1) the Taxonomy implementation (where you pull the children of an ordinal from, how you do labeling etc.) and (2) where the ordinals are encoded in the search index (BinaryDV in TaxoIndex case, SortedSetDV in SortedSet case). The latter can easily be solved by a CLI implementation of SortedSet and former by an abstract Taxonomy (read-only) API which both SortedSet and TaxoIndex implement. We should explore these on a separate issue though.\n\nI think that the problem with your current patch is that the aggregation is done in the constructor, so it sort of eliminates reasonable ways to extend things. But if things were done differently, we could have an abstract FacetsAggregator instead of FacetsAccumulator which let you implement only the .aggregate() method, and take care of rollup + top-K computation itself. But that means you'd need to initialize the class and then call a .aggregate() or .compute() before you call any of the .getTopK() for instance (unless we check in every .getTopK() if it's already computed...).\n\nFacetArrays\n\nUnfortunately, there is no efficient way to hold either an int or float in Java, without specifying the type of the array (i.e. long[] or double[] are too expensive), so this class abstracts the way facets are aggregated, so that we can have different FacetAggregators implementations, again, reusing the majority of the irrelevant code (top-K computation, rollup, CategoryListIterator...).\n\nI don't know if we can get rid of it... especially as there might be aggregators that are interested in both arrays (e.g. avgOfSomething). Maybe if we have a FacetsAccumulator abstract class, we can have an IntFA and FloatFA abstract classes which give you access to an int[]/float[] arrays, and matching FacetResultsHandler?\n\nFacetIndexingParams\n\nBy all means, I'm +1 for simplifying this class and make it more user-friendly. I like how you can specify a DimType (hierarchical, singleValue...) instead of setting the more arbitrary OrdinalPolicy. I do think this class has some value today, e.g. in CategoryListParams (which you nuked), the app doesn't need to know about the field under which facets are indexed at all, only if it cares to change it or index multiple category lists. Not sure it's a blocker, just pointing that out. On the plus side - it makes app more aware about what's going on in its index...\n\nI don't have strong feelings about this class, we can rename it to FacetsConfig or whatever, but let's put the configuration parameters under it (e.g. DimType and drillDownDelimiter)? ",
            "author": "Shai Erera",
            "id": "comment-13821139"
        },
        {
            "date": "2013-11-13T10:03:02+0000",
            "content": "Mike, \nthe idea of simplifying the API sounds great, but is it really that complected now?\n\nFacet's Accumulator is similar to Lucene's Collector, the Aggregator is sort of a Scorer, and a FacetRequest is a sort of Query.\nActually the model after which the facets were designed was Lucene's.\nThe optional IndexingParams came before the IndexWriterConfig but these can be said to be similar as well.\n\nMore low-level objects such as the CategoryListParams are not a must, and the user may never know about them (and btw, they are similar to Codecs).\n\nI reviewed the patch (mostly the taxonomy related part) and I think that even without associations, counts only is a bit narrow.\nSpecially with large counts (say many thousands) the count doesn't say much because of the \"long tail\" problem.\nWhen there's a large result set, all the categories will get high hit counts. And just as scoring by counting the number of query terms each document matches doesn't always make much sense (and I think all scoring functions do things a lot smarter), using counts for facets may at times yield irrelevant results.\n\nWe found out that for large result sets, an aggregation of Lucene's score (rather than +1),  or even score^2 yields better results for the user. Also arbitrary expressions which are corpus specific (with or without associations) changes the facets' usability dramatically. That's partially why the code was built to allow different \"aggregation\" techniques, allowing associations, numeric values etc into each value for each category.\n\nAs for the new API, it may be useful if there would be a single \"interface\" - so all facets implementations could be switched easily, allowing users to experiment with the different implementations without writing a lot of code. \n\nBottom line, I'm all for simplifying the API but the current cost seems to great, and I'm not sure the benefits are proportional \n ",
            "author": "Gilad Barkai",
            "id": "comment-13821142"
        },
        {
            "date": "2013-11-13T16:19:12+0000",
            "content": "I took a look at the patch (actually just the tests!) and had these random thoughts:\n\nCan we rename CategoryPath to FacetLabel or something more intuitive?\nCan there be sugar like addFields(doc, FacetLabel) so a user doesnt have to make lists etc?\nMaybe it could be varargs like FacetLabel..., so just some sugar:\n\npublic void addFields(Document doc, FacetLabel... labels) {\n  addFields(doc, Arrays.asList(labels));\n}\n\n\n\nnew LongRange(\"less than 10\", 0L, true, 10L, false) <-- can we make it so this is less arguments?\n\nI like that RangeFacetCounts takes varargs though!\n\nFor the Taxo case, I think the \"document build\" process is still too complicated.\nWhat if it worked like this:\n\nIndexWriter iw = new FacetIndexWriter(dir1, dir2);\nDocument doc = new Document();\ndoc.add(...new TextField(body))\ndoc.add(new FacetField(\"foo\", \"bar\"))\niw.addDocument(doc);\n\n\n\nThen this FacetIW calls super.addDoc, with an iterable filtering out FacetFields, and also\ndoes whatever it needs to do with the FacetFields on the taxo index.  ",
            "author": "Robert Muir",
            "id": "comment-13821481"
        },
        {
            "date": "2013-11-14T07:33:04+0000",
            "content": "Can we rename CategoryPath to FacetLabel or something more intuitive?\n\nCategoryPath is all about the path components of a category. So the name is not entirely out of place. But FacetLabel is a nice too, and definitely aligns w/ the rest of the APi, e.g. FacetResultNode has a 'label' member, not 'path'. But, CP is such a core class, that renaming it will change all of the facet module's classes and every app out there (while the changes in this issue are less drastic), so I just wonder if it's a must or nice-to-have. I don't object to it, just saying it's a rote renaming of a core class. Anyway, if we want to do this, I suggest we do it under a separate issue, just to keep things contained.\n\nCan there be sugar like addFields(doc, FacetLabel) so a user doesnt have to make lists etc?\n\nI think the varargs version is good to have, though in practice (except for tests), I never found the need to use one because usually the facets are added by reading them from somewhere, so you anyway need to construct a List or Array. It's only in tests, mock demos, or very specific applications that such a vararg method will be useful. If we have a super FacetFields class, then this method could just be final and delegate to the List variant as you noted in the code example. Otherwise, we just need to make sure we add it to every FF, so we're consistent.\n\nnew LongRange(\"less than 10\", 0L, true, 10L, false) <-- can we make it so this is less arguments?\n\nYou mean omitting the inclusive params, maybe defaulting to true, or maybe minInclusive=true and maxInclusive=false (really depends how you view the max value)? I guess we could do that. But then we should do that in all other Range types (there are only 3).\n\nFor the Taxo case, I think the \"document build\" process is still too complicated.\n\nWhy the \"Taxo\" case? TaxoIndex and SortedSet have similar APIs \u2013 SimpleFacetFields (maybe we want to rename it to TaxonomyFacetFields) and SortedSetDVFacetFields. Both are needed because they add both drill-down terms and BinaryDV (Taxo) or SortedSetDV (SortedSet) fields.\n\nA FacetIndexWriter is a nice idea, but we'd need variants for Taxo, SortedSet and Mike explores an enum-method (LUCENE-5326). What I like less about it is that today the app can use two FacetFields, say one for Enum and one for SortedSet (or whatever other combination) and I don't see how it will do that using FacetIW.\n\nHmm ... or what we could do is have a single FacetIW, but different field types, e.g. TaxonomyFacetField, SortedSetFacetField and EnumFacetField. FacetIW will capture them and act accordingly. From the app's perspective, the interaction w/ the APIs is simpler, since it just adds another field to the document. Then we don't even need to change FacetFields APIs (varargs or not). I think I like it! Can we do this in a separate issue? I think it's lower hanging fruit than the changes proposed in this issue, and are also focused (nuking FacetFields essentially in exchange for dedicated Field extensions).\n\nWhat I also like about FacetIW is that if we want to, we can wrap the app's Codec with a more suitable FacetCodec. E.g. maybe there's a better way to encode the facet information than a plain BinaryDV (maybe it's a special BDV). Asking an app to set a Codec is rather high entry-point. Note that I'm not talking about apps that e.g. want to configure the facet DV to use DirectDVF. That's ok. I'm talking about if we think there's a better way to encode the data for all (or maybe depending on a schema) faceted-search apps - then requiring a special Codec even less approachable API. ",
            "author": "Shai Erera",
            "id": "comment-13822232"
        },
        {
            "date": "2013-11-14T09:32:57+0000",
            "content": "About FacetIndexWriter, it will need to take an optional TaxonomyWriter (i.e. if you intend to use TaxonomyFacetField). But then I wonder if users won't expect that FacetIW.commit() won't commit both the underlying IW and TW. Actually, this could be a very good thing to do, since we could control the order those two objects are committed, and do the two-phase commit properly, rather than telling users what to do. But that means we'd need to make IW.commit() not final. Besides the advantage of doing the commit right, I worry that if we don't do that, users will be confused about having to call TW.commit() themselves, just because now FacetIW already has a handle to their TW. What do you think? We could also just add a commitTaxoAndIndex() method, but that's less elegant. ",
            "author": "Shai Erera",
            "id": "comment-13822273"
        },
        {
            "date": "2013-11-14T12:09:12+0000",
            "content": "Thanks for the feedback everyone ... I'm attaching a new patch. ",
            "author": "Michael McCandless",
            "id": "comment-13822358"
        },
        {
            "date": "2013-11-14T12:10:09+0000",
            "content": "You have a TODO file which seems to have been 'svn added' - are you aware of it? \n\nI put a nocommit.\n\nMaybe we should do this work in a branch and avoid the .simple package? \n\nI'll start a branch, but on the branch I'd like to keep working on\n.simple for now while we bang out the API changes.  If things start to\ncrystallize then we can start cutting everything else over?\n\nCan FT.FieldType provide a ctor taking these arguments and then DEFAULT_FIELD_TYPE pass (false,false)? Or, init those two members to false.\nMaybe instead of setHierarchical + setMultiValued you do setDimType(DimType)? Then you could avoid the synchronization?\n\nI put a nocommit.\n\nI wonder if FieldTypes won't confuse users w/ Field.FieldType, so maybe you should name it DimType or something? And the upper class FacetsConfig?\n\nGood, I renamed both.\n\nNot sure, but I think that SimpleFacetFields adds the dimension's ordinal if the dim is both hierarchical and multi-valued? That's a step back from the default ALL_BUT_DIM that we have today. I think we might want to have a requiresDimValue or something, because I do think the dimension's value (count) is most often unneeded, and it's a waste to encode its ordinal?\n\nIt does, and I think that's OK?  Yes, it's one extra ord it indexes,\nbut that will be a minor perf hit since it's a multi-valued and\nhierarchical.\n\nConstants isn't documented, not sure if 'precommit' will like that, but in general I think the constants should have jdocs. Maybe put a nocommit?\n\nI put nocommits.  Sadly, precommit won't fail (lucene/facet is\n\"missing\" in document-lint target in build.xml, because we never fixed\nall its javadocs).  We should separately fix that.\n\nTaxonomyFacetCounts.getAllDims() \u2013 If a dimension is not hierarchical, I think SimpleFacetResult.count == 0? In that case, sorting by its count is useless?  I think it's also relevant for SortedSet?\n\nI THINK these will work correctly (we sum the dim value as we visit\nall children), but I was missing the \"corrected\" dim count in the\nhierarchical + MV case so I added that.  Also, I put nocommits to test\nthis.\n\nLabelAndValue has a Number as the value rather than double. I see this class is used only in the final step (labeling), but what's wrong w/ the previous 'double' primitive? Is it to avoid casting or something?\n\nI think it's crazy when I ask for counts that I get a double back \nThat's why I switched it to a Number.\n\nCategoryListIterator\n\nI appreciate the usefulness of this API, but rather that adding in\ninto \"simple\" from the get-go, I'd like to build out the different\nfacet methods and understand if it's actually useful / worth the\nadditional abstraction.\n\nFor example, I'm not sure it would work very well with SSDV, since we\nfirst count in seg-ord space an then convert to global-ord space only\nwhen combining counts across segments (this gave better performance).\nI mean, yes, it would \"work\" in that the abstraction would be correct,\nbut we'd be paying a performance penalty.\n\nE.g. that's how we were able to test fast cutting over facets to DV from Payload, that's a nice abstraction for letting you load the values from a cache, and so forth.\n\nI think doing such future tests with the simple APIs will still be\neasy; I don't think we should open up abstractions for the\nencoding/decoding today.\n\nFacetsAggregator\n\nI added another facet method, TaxonomyFacetSumValueSource for value\nsource aggregation, in the next patch, to explore this need...\n\nBut I don't see this convenience getting away (you'll just pass a List<FacetsAggregator> and then pull the requested values later on). \n\nTrue but ... we need some base class / interface that all these\n*Facets.java implement ... I haven't done that yet (it's a TODO).\n\nWhat I like less about it is that it folds in the logic coded by FacetsAccumulator and FacetResultsHandler\n\nMaybe we can move some of these methods into the base class?  I'm not\nsure though... since for the TaxonomyFacetSumValueSource it's float[]\nvalues and for the *Count it's int[] counts.\n\nAt the end of the day, the code that does the facet counting, the\nrollup, pulling the topK, is in fact a small amount of code; I think\nreplicating bits of this code for the different methods is the lesser\nevil than adding so many abstractions that the module is hard to\napproach by new devs/users.\n\nHas variants that return a full sub-tree (TopKInEachNodeHandler)\n\nThat handler is such an exotic use case ... and the app can just\nrecurse itself, calling TaxoFacetCounts.getTopChildren?\n\nFacetArrays\n\nWe avoid the need to factor this out, by simply enumerating the facet\nimpls directly.  E.g. we (or a user) can make a TaxoFacetAvgScore that\nallocates its own int[] and float[]...\n\nI do think this class has some value today, e.g. in CategoryListParams (which you nuked), the app doesn't need to know about the field under which facets are indexed at all, only if it cares to change it or index multiple category lists.\n\nThe facet field is now optional (defaults to $facets =\nConstants.DEFAULT_FACET_FIELD); the TestXXX.testBasic now look quite\nsimple.\n\nlet's put the configuration parameters under it (e.g. DimType and drillDownDelimiter)?\n\nI added nocommits; I think it's a good idea to move delim char inside\nhere; we'd need to enforce that all fields sharing the same indexed\nfield have the same delim char, but I think that's fine.\n\nWhat do you mean by DimType?  Taxo vs SSDV?  That's interesting to put\nin the DimConfig... it'd mean we (almost?) could pick the right\naccum/agg/results impl at search time. ",
            "author": "Michael McCandless",
            "id": "comment-13822360"
        },
        {
            "date": "2013-11-14T12:10:26+0000",
            "content": "\nFacet's Accumulator is similar to Lucene's Collector, the Aggregator is sort of a Scorer, and a FacetRequest is a sort of Query.\nActually the model after which the facets were designed was Lucene's.\nThe optional IndexingParams came before the IndexWriterConfig but these can be said to be similar as well.\n\nI appreciate those analogies but I think the two cases are very\ndifferent: I think faceting is (ought to be) far simpler than\nsearching.\n\nMore low-level objects such as the CategoryListParams are not a must, and the user may never know about them (and btw, they are similar to Codecs).\n\nLikewise, I don't think we need to expose \"codec like control\" /\npluggability over facet ords encoding at this point.\n\nI reviewed the patch (mostly the taxonomy related part) and I think that even without associations, counts only is a bit narrow.\n\nI added ValueSource aggregation in the next patch, but not\nassociations; I think associations can come later (it's just another\nindex time and search time impl).\n\n\nSpecially with large counts (say many thousands) the count doesn't say much because of the \"long tail\" problem.\nWhen there's a large result set, all the categories will get high hit counts. And just as scoring by counting the number of query terms each document matches doesn't always make much sense (and I think all scoring functions do things a lot smarter), using counts for facets may at times yield irrelevant results.\n\nWe found out that for large result sets, an aggregation of Lucene's score (rather than +1), or even score^2 yields better results for the user. Also arbitrary expressions which are corpus specific (with or without associations) changes the facets' usability dramatically. That's partially why the code was built to allow different \"aggregation\" techniques, allowing associations, numeric values etc into each value for each category.\n\nI agree.\n\nDo you think ValueSource faceting is sufficient for such apps?  Or do\nthey \"typically\" use associations?  Aren't associations only really\nrequired in the multi-valued facet field case?\n\nAs for the new API, it may be useful if there would be a single \"interface\" - so all facets implementations could be switched easily, allowing users to experiment with the different implementations without writing a lot of code.\n\nYeah I think so too ... it's on the TODO list.  Especially, if the\nFacetsConfig knows the facet method used by a given field, then we\ncould (almost) produce the right impl at search time. ",
            "author": "Michael McCandless",
            "id": "comment-13822361"
        },
        {
            "date": "2013-11-14T12:10:39+0000",
            "content": "Can we rename CategoryPath to FacetLabel or something more intuitive?\n\n+1 for FacetLabel; I put a nocommit.\n\nBut, the new patch actually nearly eliminates the need to create\nCategoryPath (it's still needed to create a DrillDownQuery but I\ndropped a nocommit to see if we can fix that).\n\nnew LongRange(\"less than 10\", 0L, true, 10L, false) <-- can we make it so this is less arguments?\n\nNot sure exactly how \n\nWhat if it worked like this:\n\nThis is an awesome idea!  I did that in the new patch; now indexing is\nreally simple, e.g.:\n\n\n    doc = new Document();\n    doc.add(new FacetField(\"Author\", \"Frank\"));\n    doc.add(new FacetField(\"Publish Date\", \"1999\", \"5\", \"5\"));\n\n\n\nand:\n\n\n    doc = new Document();\n    doc.add(new SortedSetDocValuesFacetField(\"a\", \"bar\"));\n\n ",
            "author": "Michael McCandless",
            "id": "comment-13822362"
        },
        {
            "date": "2013-11-14T13:46:13+0000",
            "content": "About the patch:\n\n\n\tI think FacetField should an optional ctor taking the indexedFacetField, defaulting to $facets, then the ctor calls super() with the right field, and not \"dummy\"? And you can remove set/get?\n\n\n\n\n\tSimpleFacetsCollector jdocs are wrong \u2013 there's no create?\n\n\n\n\n\tDo we still need SSDVFacetFields?\n\n\n\n\n\tI like FacetIW, but the nocommit, to handle updateDoc, addDocs etc. makes me think if down the road we won't be sorry about doing this change (i.e. if anything changes on IW APIs). The good thing about FacetFields is that it just adds fields to a Document, and doesn't worry about IW API at all...\n\n\n\n\n\tDimType == DimConfig . Sorry if I wasn't clear somewhere in my long response.\n\n\n\n\nThat handler is such an exotic use case ... and the app can just\nrecurse itself, calling TaxoFacetCounts.getTopChildren?\n\nCould be, maybe it will work. It definitely allows asking for different topK for each child (something we currently don't support).\n\n\nIt does, and I think that's OK? Yes, it's one extra ord it indexes,\nbut that will be a minor perf hit since it's a multi-valued and\nhierarchical.\n\nI don't know. Like if your facet has 2 levels, that's 33% more ords. I think the count of the root ord is most likely never needed? And if it's needed, app can compute it by traversing its children and their values in the facet arrays? Maybe as a default we just never index it, and don't add a vague requiresDimCount/Value/Weight boolean?\n\n\nI think replicating bits of this code for the different methods is the lesser\nevil than adding so many abstractions that the module is hard to\napproach by new devs/users.\n\nDid we ever get such feedback from users? That the module is unapproachable?\nI get the opposite feedback - that we don't have many abstractions! \n\n\nAt the end of the day, the code that does the facet counting, the\nrollup, pulling the topK, is in fact a small amount of code;\n\nYou have a nocommit \"maybe we should do this lazily\" in regards for when to rollupValues. That shows me that now every developer who extends this API (let's be clear - users are oblivious to this happening) will facet the same decision (nocommit). If we discover one day that it's better to rollup lazily or not, other developers don't benefit from that decision. That's why I think some abstractions are good.\n\n\nI added ValueSource aggregation in the next patch, but not\nassociations; I think associations can come later (it's just another\nindex time and search time impl).\n\nI'm not sure we should do that (cut over associations later). The whole point about these features (associations, complements, sampling..) is that they are existing features. If we think they are useless / unneeded - that's one thing. But if we believe they are important, it's useless to make all the API changes without taking them into account, only to figure out later that we need abstraction X and Y in order to implement them.\n\nAnd we make heavy use of associations, and some users asked (and use) sampling and I remember a question about complements. So obviously we cannot conclude that these are useless features. Therefore I think it's important that we try to tackle them now, so don't we don't do a full round trip to find ourselves with the same API again.\n\nCan we do FacetIndexWriter in a separate issue (if we want to do it at all)? It's unrelated to the search API changes you want to do here, and it might be easier to contain within a single issue?\n\nAbout CategoryListIterator ... what if we do manage to come up tomorrow with a better encoding strategy for facets. Do you really think that changing all existing WhateverFacets makes sense!? And if developers write their own WhateverFacets, it means they need to change their code too? Really, you're mixing optimizations (inlining dgap+vint) with ease of use. I know (!!) that there are apps that can benefit from a different encoding scheme (e.g. FourOnesIntEncoder). We don't need to wait until someone comes up w/ a better default encoding scheme to introduce abstractions. I mean .. that's just sounds crazy to me. ",
            "author": "Shai Erera",
            "id": "comment-13822450"
        },
        {
            "date": "2013-11-14T18:24:34+0000",
            "content": "Thanks for the feedback Shai.\n\nI think FacetField should an optional ctor taking the indexedFacetField, defaulting to $facets, then the ctor calls super() with the right field, and not \"dummy\"? And you can remove set/get?\n\nI moved the indexed field name to the DimConfig.\n\nSimpleFacetsCollector jdocs are wrong \u2013 there's no create?\n\nI removed it and put nocommit.\n\nDo we still need SSDVFacetFields?\n\nWoops, no; I removed it.\n\nI like FacetIW, but the nocommit, to handle updateDoc, addDocs etc. makes me think if down the road we won't be sorry about doing this change (i.e. if anything changes on IW APIs). The good thing about FacetFields is that it just adds fields to a Document, and doesn't worry about IW API at all...\n\nI think that's an acceptable risk in exchange for the simpler\nindex-time API.\n\nDimType == DimConfig . Sorry if I wasn't clear somewhere in my long response.\n\nAhh, OK.  I'm still wondering if we should put the \"facetMethod\" onto\nthe DimConfig...\n\nLike if your facet has 2 levels, that's 33% more ords. I think the count of the root ord is most likely never needed? And if it's needed, app can compute it by traversing its children and their values in the facet arrays? Maybe as a default we just never index it, and don't add a vague requiresDimCount/Value/Weight boolean?\n\nWait, the app cannot compute this (accurately) by summing the child counts?  It will overcount in general, right?\n\n\nI think replicating bits of this code for the different methods is the lesser evil than adding so many abstractions that the module is hard to approach by new devs/users.\n\nDid we ever get such feedback from users? That the module is unapproachable?\n\nIt's mostly from my own assessment, looking at the code, and my own\nfrustrations over time in trying to improve the facets module;\nLUCENE-5333 was finally the straw (for me)... I find complex APIs\nfrustrating and I think it's a serious barrier to new contributors\ngetting involved and users consuming them.\n\nThere was a user on the ML (I don't have the link) who just wanted to\nget the facet count for a specific label after faceting was done, and\nthe hoops s/he had to jump through (custom FacetResultHandler I\nthink??) to achieve that was just crazy.\n\nI get the opposite feedback - that we don't have many abstractions! \n\nSeriously?  What abstractions are we missing?\n\nIf this is too much change for the facets module, we could, instead,\nleave the facets module as is, and break this effort out as a\ndifferent module (facets2, simplefacets, something?).  We also have\nmany queryparsers, many highlighters, etc., and I think that's\nhealthy: all options can be explored.\n\nYou have a nocommit \"maybe we should do this lazily\" in regards for when to rollupValues. That shows me that now every developer who extends this API (let's be clear - users are oblivious to this happening) will facet the same decision (nocommit). If we discover one day that it's better to rollup lazily or not, other developers don't benefit from that decision. That's why I think some abstractions are good.\n\nIt's a crazy expert thing to create another faceting impl, so I think\nsuch developers can handle changing their rollup to be lazy if it's\nbeneficial/necessary for their use case.\n\nI'm not sure we should do that (cut over associations later). The whole point about these features (associations, complements, sampling..) is that they are existing features. If we think they are useless / unneeded - that's one thing. But if we believe they are important, it's useless to make all the API changes without taking them into account, only to figure out later that we need abstraction X and Y in order to implement them.\n\nWell this could be a good argument for just making a new module?\n\nThe new module would have a simpler API and less thorough\nfunctionality?\n\nCan we do FacetIndexWriter in a separate issue (if we want to do it at all)? It's unrelated to the search API changes you want to do here, and it might be easier to contain within a single issue?\n\nI'm not sure it's so easily separated out; the DimConfig is common to\nindex time and search time, and we're still iterating on that (I just\nmoved the indexedFieldName into it).\n\nAbout CategoryListIterator ... what if we do manage to come up tomorrow with a better encoding strategy for facets. Do you really think that changing all existing WhateverFacets makes sense!? And if developers write their own WhateverFacets, it means they need to change their code too? Really, you're mixing optimizations (inlining dgap+vint) with ease of use. I know (!!) that there are apps that can benefit from a different encoding scheme (e.g. FourOnesIntEncoder). We don't need to wait until someone comes up w/ a better default encoding scheme to introduce abstractions. I mean .. that's just sounds crazy to me.\n\nWe'd have to change 3 places if we did that right now: FacetIndexWriter\n(where we encode) and TaxonomyFacetCounts/SumValueSource (where we\ndecode).\n\nMaybe... we can have a decode method in TFC, and TFSVC subclasses TFC,\nor ... something ... but I'd like to be very careful in just adding\nback abstractions here: this really is a small amount of code at the\nend of the day. ",
            "author": "Michael McCandless",
            "id": "comment-13822721"
        },
        {
            "date": "2013-11-14T19:06:03+0000",
            "content": "Commit 1542023 from Michael McCandless in branch 'dev/branches/lucene5339'\n[ https://svn.apache.org/r1542023 ]\n\nLUCENE-5339: make branch ",
            "author": "ASF subversion and git services",
            "id": "comment-13822776"
        },
        {
            "date": "2013-11-14T19:08:29+0000",
            "content": "Commit 1542025 from Michael McCandless in branch 'dev/branches/lucene5339'\n[ https://svn.apache.org/r1542025 ]\n\nLUCENE-5339: current patch ",
            "author": "ASF subversion and git services",
            "id": "comment-13822778"
        },
        {
            "date": "2013-11-14T19:09:37+0000",
            "content": "OK I created a branch at https://svn.apache.org/repos/asf/lucene/dev/branches/lucene5339 and committed my current patch (same as last patch I think, except I moved the indexedFieldName from FacetField to DimConfig). ",
            "author": "Michael McCandless",
            "id": "comment-13822780"
        },
        {
            "date": "2013-11-14T20:10:49+0000",
            "content": "\n Really, you're mixing optimizations (inlining dgap+vint) with ease of use. I know (!!) that there are apps that can benefit from a different encoding scheme (e.g. FourOnesIntEncoder). We don't need to wait until someone comes up w/ a better default encoding scheme to introduce abstractions. I mean .. that's just sounds crazy to me.\n\nHow common is this, I'm curious?\n\nJust to lend my opinion/support to this issue: imo the pure number of classes to the faceting module can be overwhelming. \n\nLets take the encode/decode case: it seems to me you guys iterated a lot and figured out vint was \"the best default encoding\". I'm not going to argue that some use case could benefit from a custom encoding scheme: instead I'm going to argue if it justifies a whole java package with 20 public classes?\n\nSo I think its fine to bake in the encoding, but with the two key methods in those 20 classes 'protected' in the appropriate places so that an expert user could subclass them:\n\n\ndecode(BytesRef buf, IntsRef values);\nencode(IntsRef values, BytesRef buf);\n\n\n\nI'd make the argument: if someone is expert enough to do this, they dont need pre-provided concrete encoder/decoder classes anyway, they can write their own method? ",
            "author": "Robert Muir",
            "id": "comment-13822840"
        },
        {
            "date": "2013-11-14T20:28:51+0000",
            "content": "Commit 1542062 from Michael McCandless in branch 'dev/branches/lucene5339'\n[ https://svn.apache.org/r1542062 ]\n\nLUCENE-5339: add abstract Facets base class; fix separate test failure ",
            "author": "ASF subversion and git services",
            "id": "comment-13822855"
        },
        {
            "date": "2013-11-15T05:42:54+0000",
            "content": "I think that's an acceptable risk in exchange for the simpler index-time API.\n\nWhat if someone already extends IW? Or, we'll like that approach so much that we'll want to apply it elsewhere too (I mean in other modules)? I'm just saying that extending IW is a pretty big thing, compared to FacetFields.\n\nI was thinking maybe we can wrap an IW, and present an interface with only add/updateDoc so on one hand you get to add new FacetField() easily, but on the other you get to use whatever IW that you want. It's like RandomIW, only we may not want to copy the entire set of APIs, only the document-related ones? And in the future we can think about TaxoFacetIW which also owns the commit()?\n\nAnother crazy idea is to implement a FacetDocument which extends Document (we'd need to allow that first!) and does the same trick on addField() / indexableFields(). I think if we can pull this off (extending Document is preferred IMO), it's far less intrusive than a new FacetIW.\n\nWait, the app cannot compute this (accurately) by summing the child counts? It will overcount in general, right?\n\nOoops, you're right. So in that case, we can open up the extension point (I think it's FacetIW.dedupAndEncode) to let the app add the DIM ordinal too? Then I think the rest of the search code will just work?\n\n\nThere was a user on the ML (I don't have the link) who just wanted to\nget the facet count for a specific label after faceting was done, and\nthe hoops s/he had to jump through (custom FacetResultHandler I\nthink??) to achieve that was just crazy.\n\nMaybe it's crazy I don't know. All I'm saying is that now you took that user's request and made it a top-level API. I don't know if that qualifies as simplifying the APIs, or whether similar requests in the future will be easy to implement by extension, or we'd need to add them to our core code. For instance, this API makes Range and Count not share the same API (not saying it's a bad thing, just an example). But I already +1 the idea of having that on the API.\n\nSeriously? What abstractions are we missing?\n\nWell, FacetArrays committing to an int[], while we have someone which wants to use a Map, because he has millions of facets, yet queries typically hit very few of them. And he uses both the int[] and float[] arrays, which for the most part of them are allocated for no good reason. In order to use a Map he needs to write a FacetResultsHandler which computes top-K from the map, as well extend FacetsAccumulator to override createFRH. Just an example. If we have a FacetValues abstraction w/ get/set/iterator methods, all he'd need to do is override the FacetValues that should be used.\n\nBut I already told him that this is something he can just do w/ FacetResultsHandler. And just to point out that this patch won't make things worse - since he already overrides the aggregation method, he can just implement a MapBasedTaxoFacetsSomething. So I only gave it as an example (FacetValues abstraction, I think, will hurt the performance in general, but we could benchmark).\n\nAnother abstraction is LUCENE-5316, which we struggle to get it to perform (really frustrating!).\n\n\nIf this is too much change for the facets module, we could, instead,\nleave the facets module as is, and break this effort out as a\ndifferent module (facets2, simplefacets, something?). We also have\nmany queryparsers, many highlighters, etc., and I think that's\nhealthy: all options can be explored.\n\n-1 to that. I think it delivers the wrong message. Why have two faceting modules? A branch is the perfect choice here, since it allows us to move the entire module to the new API. And on the way we benefit by assessing that the new API can really allow implementing associations, complements, sampling.\n\nTo give an example - the API first was overwhelming and in the last round of changes I removed and moved things (I thought I simplify it!). So for instance once upon a time FacetRequest let you specify the FacetsAggregator and FacetResultsHandler. I moved them both to FacetsAccumulator, but recently moved FacetsAggregator back to FacetRequest (it allows more easily to define which aggregator a certain FR needs to use). And on LUCENE-5333 I suggested to move FacetResultsHandler back to FR, to implement an AllDimFR.\n\nSo wearing the \"experienced\" hat, I just want to make sure we won't move everything out only to gradually swap it back in. I'm not against changing the APIs, but because this module is rich with features (which I, and apparently our users too, think are important), I'd like to make sure the new API works for all of them. I may compromise on complements and sampling because: (1) complements is not per-segment and I think it might require a full rewrite anywhere (there's an issue for it) and (2) sampling because it's under the *.old package, meaning it was never fully migrated to the new APIs and I think it could use some serious simplification there too.\n\nIf you're worried that you'll do this work alone, I promise to help. On the branch.\n\n\nIt's a crazy expert thing to create another faceting impl, so I think\nsuch developers can handle changing their rollup to be lazy if it's\nbeneficial/necessary for their use case.\n\nLet's use MapReduce as an analogy. The framework says \"you worry about the Map and Reduce phase, I'll take care of the distribution stuff\". Nice and clean. In the beginning the facets API said \"you worry about aggregating a single ordinal, I'll worry about the rest\". Then we changed it to \"you worry about aggregating all ordinals in a segment, I'll worry about the rest\".\n\nNow, some users we have, well think of them as data scientists. All they're interested about is ranking facets to drive some insights out of the data. I feel that we're putting too much burden on them more and more. Cutting the API from the single-ord level to the segment-level was to gain sizable improvements to faceted search. But letting them do the rollup ... anyway, let's proceed with that, we can see as we go.\n\nI personally like code reuse, and it kills me to see code that's duplicated. Often this calls out for bad design of APIs, not necessarily simplification.\n\n\nI'm not sure it's so easily separated out; the DimConfig is common to\nindex time and search time, and we're still iterating on that (I just\nmoved the indexedFieldName into it).\n\nI was thinking to develop it still with FacetIndexingParams in mind - just cutover from FacetFields to FacetIW/FacetDocument. This makes the change gradual and allows us to investigate it separately. It's also, I think, a much lower hanging fruit. But, it looks like the changes in this patch will require rewriting large parts of it, so maybe we should do it here.\n\n\nWe'd have to change 3 places if we did that right now: FacetIndexWriter\n(where we encode) and TaxonomyFacetCounts/SumValueSource (where we\ndecode).\n\nWrong? I mean you still didn't write a version which pulls the ords from OrdinalsCache (and I assume you don't want to get rid of it!). With those two TFCs, it already means we'll have 4 classes? While I think the SumValueSource could be oblivious to how the ords are encoded/fetched out-of-the-box, since it's less common to use (we only optimize counting) and someone can rewrite it to pull the ords from OrdinalsCache directly (instead of going through the CLI abstraction).\n\nSo I think its fine to bake in the encoding, but with the two key methods in those 20 classes 'protected' in the appropriate places so that an expert user could subclass them:\n\nI think you point out two problems - one is the fact that we have the *.encoding package at all and the other one is how to override encoding/decoding. The nice thing about IntEncoder/Decoder (let's think of it as PackedInts ok?) is that you can use an implementation without affecting other classes, while with encode/decode protected methods you need to extend every class that you have which reads the data. I don't think that qualifies as good software design. Why do we have PackedInts then?\n\nNow the question is whether we should keep the different IntEncoders or not - I don't know. Why do we have so many PackedInts versions? Do we use all of them or are they there so that someone can make a pick? If they don't hurt anyone, and requires almost no maintenance, why remove them?\n\nThe argument is whether we should open up encoding/decoding at all. What Mike is saying \"if you want to encode differently, you're an expert and you can rewrite all of your and Lucene's aggregators (count, sum VS) too\". What you're saying, add encode/decode protected methods, is more how the API looks today, only instead of a method we have an IntEncoder/Decoder (a'la PackedInts) class. That's just easier to use in conjunction with other classes (especially if we do the CLI abstraction).\n\nJust to clarify, I don't mean we have to have the CLI abstraction and use it everywhere. I think it's a good API for someone to use if he doesn't care about how ordinals are fetched (BDV, CachedOrds, whatever) as well as how they are encoded/decoded. It could very well be a CLITaxoFacetCounts impl which lets you pass the CLI you want to use (BDVCLI, CachedOrdsCLI, MySuperExpertDecodingCLI). That's it. Most users won't know about it, but the few that do, won't need to rewrite so many classes. ",
            "author": "Shai Erera",
            "id": "comment-13823304"
        },
        {
            "date": "2013-11-15T05:51:47+0000",
            "content": "\nNow the question is whether we should keep the different IntEncoders or not - I don't know. Why do we have so many PackedInts versions? Do we use all of them or are they there so that someone can make a pick? If they don't hurt anyone, and requires almost no maintenance, why remove them?\n\nYour analogy is 100% wrong Shai. PackedInts uses the different implementations behind the scenes automatically.\n\nHere we just have a lot of public classes overwhelming the user for absolutely no good reason.\n\nI will reopen this JIRA issue if it is marked 'resolved' without these classes being removed!!!!!! ",
            "author": "Robert Muir",
            "id": "comment-13823316"
        },
        {
            "date": "2013-11-15T08:20:40+0000",
            "content": "I don't think it's 100% wrong - look at all the classes under o.a.l.util.packed \u2013 I'm talking about the public: PackedInts, Mutable, GrowableWriter, PagedGrowableWriter, AppendingPackedLongBuffer, AppendingDeltaPackedLongBuffer, MontonicAppendingLongBuffer - these classes exist for a reason \u2013 you need to be able to pick the best one for you needs. They great.\n\nI don't care much if you want to remove o.a.l.facet.encoding package - I think it's fair to say that if you want to have a different encoding scheme, you should extend FacetIW/FacetDocument/FacetFields (whatever we come up with) .encode() and then either write a matching CategoryListIterator, or TaxoFacetCounts.\n\nAnd I wished you used less !!!!  ",
            "author": "Shai Erera",
            "id": "comment-13823466"
        },
        {
            "date": "2013-11-16T07:17:27+0000",
            "content": "About IntEncoder, one thing it lets us do today is detect the encoding used for this category list, and eg throw a meaningful exception in FastCountingAggregator if a FIP is passed which uses a different decoder. I think it's good if we can somehow detect it in TaxoFacetCounts? If not, maybe we just document that this class assumes default encoding is used and that if you changed that, you shouldn't use this class? If you think documentation isn't enough, please drop a nocommit so we remember to handle it? \n\nI've been thinking to get rid of IntEncoder in a separate issue (do this change in baby steps), so whatever we decide here, I'll apply there.  ",
            "author": "Shai Erera",
            "id": "comment-13824407"
        },
        {
            "date": "2013-11-17T12:23:39+0000",
            "content": "Commit 1542712 from Michael McCandless in branch 'dev/branches/lucene5339'\n[ https://svn.apache.org/r1542712 ]\n\nLUCENE-5339: add nocommits ",
            "author": "ASF subversion and git services",
            "id": "comment-13824821"
        },
        {
            "date": "2013-11-17T12:23:46+0000",
            "content": "If not, maybe we just document that this class assumes default encoding is used and that if you changed that, you shouldn't use this class?\n\nI just committed nocommits that we should jdoc this ... ",
            "author": "Michael McCandless",
            "id": "comment-13824822"
        },
        {
            "date": "2013-11-17T12:28:51+0000",
            "content": "Commit 1542713 from Michael McCandless in branch 'dev/branches/lucene5339'\n[ https://svn.apache.org/r1542713 ]\n\nLUCENE-5339: cutover DrillSideways ",
            "author": "ASF subversion and git services",
            "id": "comment-13824823"
        },
        {
            "date": "2013-11-17T12:52:37+0000",
            "content": "I was thinking maybe we can wrap an IW,\n\nI think that's a good idea?  I added to TODO.\n\nAnother crazy idea is to implement a FacetDocument which extends Document \n\nI'm not sure how this can work, since in order to write the ords we\nneed to see all FacetFields?  Ie, at what point would we compile all\nthe FacetFields into the BDV field?\n\nwe can open up the extension point (I think it's FacetIW.dedupAndEncode) to let the app add the DIM ordinal too?\n\nHmm, we could open that up, but ... I think that's \"too late\"?  You\ncan't easily know which dim ords to add back at that point.  I added a\nTODO. \n\n\nSeriously? What abstractions are we missing?\n\nWell, FacetArrays committing to an int[], while we have someone which wants to use a Map, because he has millions of facets, yet queries typically hit very few of them.\n\nWith the simplified APIs this user could just make a custom facet\nmethod?\n\nAnother abstraction is LUCENE-5316, which we struggle to get it to perform (really frustrating!).\n\nI agree we need better abstraction here... the 3 int we require per\nunique facet label is costly.  But, I don't think we need to force\nSSDVFacets to use this abstraction?\n\nWhy have two faceting modules? A branch is the perfect choice here, since it allows us to move the entire module to the new API. And on the way we benefit by assessing that the new API can really allow implementing associations, complements, sampling.\n\nI would also prefer to have a single facet module after all this, but\nif the requirements (rich functionality vs. simple API) are too\ndivergent, then two modules is at least an option.  Progress not\nperfection...\n\nI may compromise on complements and sampling because: (1) complements is not per-segment and I think it might require a full rewrite anywhere (there's an issue for it) and (2) sampling because it's under the *.old package, meaning it was never fully migrated to the new APIs and I think it could use some serious simplification there too.\n\nI agree it's bad that complements is \"top level\"; everything else in\nthe facet module is NRT friendly and I think we should stick with\nthat.\n\nI'll work on associations...\n\nI personally like code reuse, and it kills me to see code that's duplicated. Often this calls out for bad design of APIs, not necessarily simplification.\n\nI think this is a precarious balance.  If a little code dup can\ngreatly simplify the APIs, then that's the better tradeoff.\n\nWrong? I mean you still didn't write a version which pulls the ords from OrdinalsCache (and I assume you don't want to get rid of it!).\n\nYou're right, the ords cache filling will be another place that \"bakes\nin\" the decoding.  So, I agree: if we can find a clean way to abstract\nthe encoding/source then let's pursue that. ",
            "author": "Michael McCandless",
            "id": "comment-13824826"
        },
        {
            "date": "2013-11-17T12:53:18+0000",
            "content": "Commit 1542717 from Michael McCandless in branch 'dev/branches/lucene5339'\n[ https://svn.apache.org/r1542717 ]\n\nLUCENE-5339: update TODOs ",
            "author": "ASF subversion and git services",
            "id": "comment-13824827"
        },
        {
            "date": "2013-11-17T13:29:40+0000",
            "content": "\nI'm not sure how this can work, since in order to write the ords we\nneed to see all FacetFields? Ie, at what point would we compile all\nthe FacetFields into the BDV field?\n\nI was thinking when Doc.indexableFields() is called?\n\n\nHmm, we could open that up, but ... I think that's \"too late\"? You\ncan't easily know which dim ords to add back at that point. I added a\nTODO.\n\nMaybe that's the wrong extension point, but what I had in mind is something similar to what FacetFields does today \u2013 it adds the categories to the TaxoIndex and receives their ordinal. Then it calls a CategoryListBuilder which asks for the parent of an ordinal until it hits ROOT (depending on OrdPolicy of course). I mentioned dedupAndEncode because I thought it does something like that (i.e. that you've inlined CategoryListBuilder in FacetIW). If it's not, then whatever method that does that ... and if there is none, let's wrap it in an overridable method?\n\nWith the simplified APIs this user could just make a custom facet method?\n\nHe already does that with the current APIs too (a special FacetsAccumulator. I don't know if it's easier/harder/the same to do w/ the new API. I guess it won't be harder.\n\n\nYou're right, the ords cache filling will be another place that \"bakes\nin\" the decoding. So, I agree: if we can find a clean way to abstract\nthe encoding/source then let's pursue that.\n\nAs I said, let's divide that into two problems: API and optimization. For API, we can stick w/ CategoryListIterator and implement both a DGapVIntBinaryDVIterator as well as OrdinalsCacheIterator. That way, FacetsSomething (do we have a name yet? Is it just Facets?) can use a CLI if they don't care where the ordinals come from.\n\nFor optimization, we do a FastFacetCounts which inlines dgap+vint and reads from BDV, and we can also do a CachedOrdsFacetCounts which inlines the interaction with OrdinalsCache. Actually, if we provide these two, we can skip the third FacetCounts (uses CLI), as it will be for demo purposes only given current encoding. If anyone changes the encoding, he can write a FacetCounts. Also, we can always add it later ...\n\nThe rest of the Facets (i.e. non-counts) should IMO at this point use the CLI abstraction. If anyone wants to optimize a SumValueSourceFacets, he can do so however he wants. But the CLI is the abstraction I'm thinking \u2013 it only has two methods: setNextReader and getOrdinals(int doc).\n\n\nI think this is a precarious balance. If a little code dup can\ngreatly simplify the APIs, then that's the better tradeoff.\n\nIn general I agree. It then becomes what's considered little vs a lot of code dup. I think that dgap+vint + rollup is not little (put together), as well as making the decision to rollup. But at this point I don't mind .. let's force code dup, and then simplify if users are angry.\n\n\nI agree we need better abstraction here... the 3 int we require per\nunique facet label is costly. But, I don't think we need to force\nSSDVFacets to use this abstraction?\n\nWell, at first what I had in mind is a Taxonomy interface (read-only) with two implementations: TaxoIndex and SortedSet. Especially since we're talking about supporting full hierarchies w/ SortedSet. I think it will be cool if a TaxoFacetCounts just takes a Taxonomy and we don't need to duplicate the code. But then I realized it's not just how the taxonomy is managed, but also where the ords are pulled from (BDV vs SSDV).\n\nWe basically could have a SortedSetTaxonomy and SortedSetCLI to support any 'general' counting, but then as you pointed out somewhere, a SortedSetCLI may not be able to optimize by counting in seg-ord space and re-map afterwards. So at this point I'm not sure we should pursue the implementation of a SortedSet Taxonomy and CLI. Would be nice to know the APIs allow that (even if it means you lose some performance, e.g. always count in global ord-space), should anyone want to do that. Let's drop it for now. ",
            "author": "Shai Erera",
            "id": "comment-13824833"
        },
        {
            "date": "2013-11-17T17:57:01+0000",
            "content": "Commit 1542773 from Michael McCandless in branch 'dev/branches/lucene5339'\n[ https://svn.apache.org/r1542773 ]\n\nLUCENE-5339: add OrdinalsReader + Cache to abstract the source of the ords ",
            "author": "ASF subversion and git services",
            "id": "comment-13824913"
        },
        {
            "date": "2013-11-17T20:31:46+0000",
            "content": "Commit 1542804 from Michael McCandless in branch 'dev/branches/lucene5339'\n[ https://svn.apache.org/r1542804 ]\n\nLUCENE-5339: simplify DrillDownQuery ",
            "author": "ASF subversion and git services",
            "id": "comment-13824944"
        },
        {
            "date": "2013-11-17T21:58:10+0000",
            "content": "Commit 1542843 from Michael McCandless in branch 'dev/branches/lucene5339'\n[ https://svn.apache.org/r1542843 ]\n\nLUCENE-5339: remove delim char ",
            "author": "ASF subversion and git services",
            "id": "comment-13824969"
        },
        {
            "date": "2013-11-18T14:54:24+0000",
            "content": "Commit 1543047 from Michael McCandless in branch 'dev/branches/lucene5339'\n[ https://svn.apache.org/r1543047 ]\n\nLUCENE-5339: assocations ",
            "author": "ASF subversion and git services",
            "id": "comment-13825369"
        },
        {
            "date": "2013-11-18T15:46:22+0000",
            "content": "Thanks Mike! Currently, int and float associations are written in different BDVs, one for int and one for float. If you look in CategoryAssociation, it has an ID() which is added to the facet field. That means fields like $facet$int, $facet$float, $facet$CA.getID(). This is also related to the nocommit you put about the association facet field \u2013 I think it should be indexFieldName + CategoryAssociation.ID.\n\nI see though that AssociationFacetField can handle both integers and floats. While the treatment is the same (writing a float is just like writing an int after FloatToIntBits), I think it's better if we separate them either into two fields, or keep the CategoryAssociation class to distinguish between them. Then FacetIW can iterate on the AssociationFacetFields and group them by CategoryAssociation type to index them under the respective BDV.\n\nWe cannot allow mixing different association types in the same BDV, as their decoding isn't the same (even float vs int \u2013 you have to know whether to do Float.intBitsToFloat or not, after reading the int). ",
            "author": "Shai Erera",
            "id": "comment-13825408"
        },
        {
            "date": "2013-11-18T21:11:05+0000",
            "content": "Commit 1543161 from Michael McCandless in branch 'dev/branches/lucene5339'\n[ https://svn.apache.org/r1543161 ]\n\nLUCENE-5339: renames ",
            "author": "ASF subversion and git services",
            "id": "comment-13825778"
        },
        {
            "date": "2013-11-18T22:32:10+0000",
            "content": "Commit 1543202 from Michael McCandless in branch 'dev/branches/lucene5339'\n[ https://svn.apache.org/r1543202 ]\n\nLUCENE-5339: add base class for taxo facet impls; catch wrong index field name for a given dim ",
            "author": "ASF subversion and git services",
            "id": "comment-13825861"
        },
        {
            "date": "2013-11-18T22:46:09+0000",
            "content": "Commit 1543213 from Michael McCandless in branch 'dev/branches/lucene5339'\n[ https://svn.apache.org/r1543213 ]\n\nLUCENE-5339: renames ",
            "author": "ASF subversion and git services",
            "id": "comment-13825883"
        },
        {
            "date": "2013-11-19T12:37:05+0000",
            "content": "\nI'm not sure how this can work, since in order to write the ords we need to see all FacetFields? Ie, at what point would we compile all the FacetFields into the BDV field?\n\nI was thinking when Doc.indexableFields() is called?\n\nHmm, that's iffy.  First off, IW also calls .storableFields(), and\nit's not defined which will be called first, and we need to add both\nstorable and indexable fields.\n\nSecond off, Document has a longer lifecycle, e.g. one can reuse it,\nreuse field instance in it, etc., and I don't think we should alter it\nin-place (remove FacetFields, add new fields).\n\nMaybe Document should have a \"rewrite\" method, that IW calls to the\n\"actual\" document to index?  The default would just \"return this\".\n\nMaybe that's the wrong extension point, but what I had in mind is something similar to what FacetFields does today \u2013 it adds the categories to the TaxoIndex and receives their ordinal. Then it calls a CategoryListBuilder which asks for the parent of an ordinal until it hits ROOT (depending on OrdPolicy of course). I mentioned dedupAndEncode because I thought it does something like that (i.e. that you've inlined CategoryListBuilder in FacetIW). If it's not, then whatever method that does that ... and if there is none, let's wrap it in an overridable method?\n\nReally this is just adding complexity for a minor gain?\n\n\nAs I said, let's divide that into two problems: API and optimization. For API, we can stick w/ CategoryListIterator and implement both a DGapVIntBinaryDVIterator as well as OrdinalsCacheIterator. That way, FacetsSomething (do we have a name yet? Is it just Facets?) can use a CLI if they don't care where the ordinals come from.\n\nFor optimization, we do a FastFacetCounts which inlines dgap+vint and reads from BDV, and we can also do a CachedOrdsFacetCounts which inlines the interaction with OrdinalsCache. Actually, if we provide these two, we can skip the third FacetCounts (uses CLI), as it will be for demo purposes only given current encoding. If anyone changes the encoding, he can write a FacetCounts. Also, we can always add it later ...\n\nThe rest of the Facets (i.e. non-counts) should IMO at this point use the CLI abstraction. If anyone wants to optimize a SumValueSourceFacets, he can do so however he wants. But the CLI is the abstraction I'm thinking \u2013 it only has two methods: setNextReader and getOrdinals(int doc).\n\nOK, I added an OrdinalsReader abstraction, and CachedOrdinalsReader\n(holds all decoded ords in shared int[]), and a\nDocValuesOrdinalsReader with a protected decode() method that a\nsubclass could customize.  FastTaxonomyFacetCounts specializes the DV\ndecode.\n\n\nI think this is a precarious balance. If a little code dup can greatly simplify the APIs, then that's the better tradeoff.\n\nIn general I agree. It then becomes what's considered little vs a lot of code dup. I think that dgap+vint + rollup is not little (put together), as well as making the decision to rollup. But at this point I don't mind .. let's force code dup, and then simplify if users are angry.\n\nI pulled out a base class (TaxonomyFacets) for all the taxonomy based\nfacet methods, to share some code. ",
            "author": "Michael McCandless",
            "id": "comment-13826439"
        },
        {
            "date": "2013-11-19T15:09:12+0000",
            "content": "\nHmm, that's iffy. First off, IW also calls .storableFields(), and\nit's not defined which will be called first, and we need to add both\nstorable and indexable fields.\n\nWhy are storableFields() related? None of the facet fields are also storable. I think we should only override indexableFields(). The part about reusing fields is a bigger problem though, so maybe your Document.rewrite() idea (like Query) could work... I just think that extending IW for this minor task (adding facets) is too much. I like the way you add FacetField to a Document, I just prefer to avoid the IW extension (at this point). So if we can pursue Doc.rewrite(), that may be good. Otherwise, maybe we could bring back FacetFields, only you won't add all CPs, but rather add FacetField one by one and then you can call createDoc() or something.\n\nReally this is just adding complexity for a minor gain?\n\nWe can do this later. I just think that indexing the dimension is in 99% of the cases redundant. I prefer that the 1 app out there that might be interested in that do hard work, rather than we enforce more ordinals in the BDV for all faceted search apps.\n\nOK, I added an OrdinalsReader abstraction\n\nThanks!\n\n\nI pulled out a base class (TaxonomyFacets) for all the taxonomy based\nfacet methods, to share some code.\n\nAwesome! ",
            "author": "Shai Erera",
            "id": "comment-13826570"
        },
        {
            "date": "2013-11-19T17:13:39+0000",
            "content": "Commit 1543506 from Michael McCandless in branch 'dev/branches/lucene5339'\n[ https://svn.apache.org/r1543506 ]\n\nLUCENE-5339: migrate some more tests; fix 'ignores IntsRef.offset bug' in TaxoFacetCounts; add FacetTestCase.getFacetCounts ",
            "author": "ASF subversion and git services",
            "id": "comment-13826685"
        },
        {
            "date": "2013-11-19T18:36:18+0000",
            "content": "Commit 1543530 from Michael McCandless in branch 'dev/branches/lucene5339'\n[ https://svn.apache.org/r1543530 ]\n\nLUCENE-5339: switch to DocumentBuilder.build instead of FacetIndexWriter ",
            "author": "ASF subversion and git services",
            "id": "comment-13826789"
        },
        {
            "date": "2013-11-19T19:24:33+0000",
            "content": "Commit 1543535 from Michael McCandless in branch 'dev/branches/lucene5339'\n[ https://svn.apache.org/r1543535 ]\n\nLUCENE-5339: add best-effort detection of invalid mixing of different association field types in single indexed field ",
            "author": "ASF subversion and git services",
            "id": "comment-13826836"
        },
        {
            "date": "2013-11-19T20:55:39+0000",
            "content": "Commit 1543572 from Michael McCandless in branch 'dev/branches/lucene5339'\n[ https://svn.apache.org/r1543572 ]\n\nLUCENE-5339: another test, cutover taxo writer/reader to pathToString/stringToPath ",
            "author": "ASF subversion and git services",
            "id": "comment-13826926"
        },
        {
            "date": "2013-11-20T12:33:37+0000",
            "content": "Commit 1543803 from Michael McCandless in branch 'dev/branches/lucene5339'\n[ https://svn.apache.org/r1543803 ]\n\nLUCENE-5339: more tests, add DimConfig.requireDimCount ",
            "author": "ASF subversion and git services",
            "id": "comment-13827602"
        },
        {
            "date": "2013-11-21T19:48:44+0000",
            "content": "Commit 1544299 from Michael McCandless in branch 'dev/branches/lucene5339'\n[ https://svn.apache.org/r1544299 ]\n\nLUCENE-5339: cutover more tests; fixed a few bugs ",
            "author": "ASF subversion and git services",
            "id": "comment-13829272"
        },
        {
            "date": "2013-11-22T15:52:00+0000",
            "content": "Commit 1544586 from Michael McCandless in branch 'dev/branches/lucene5339'\n[ https://svn.apache.org/r1544586 ]\n\nLUCENE-5339: cutover more tests ",
            "author": "ASF subversion and git services",
            "id": "comment-13830069"
        },
        {
            "date": "2013-11-23T23:27:20+0000",
            "content": "Commit 1544892 from Michael McCandless in branch 'dev/branches/lucene5339'\n[ https://svn.apache.org/r1544892 ]\n\nLUCENE-5339: move build into FacetsConfig; cutover more tests ",
            "author": "ASF subversion and git services",
            "id": "comment-13830799"
        },
        {
            "date": "2013-11-24T13:30:07+0000",
            "content": "Commit 1544971 from Michael McCandless in branch 'dev/branches/lucene5339'\n[ https://svn.apache.org/r1544971 ]\n\nLUCENE-5339: cutover more tests ",
            "author": "ASF subversion and git services",
            "id": "comment-13830942"
        },
        {
            "date": "2013-11-24T22:15:29+0000",
            "content": "Commit 1545086 from Michael McCandless in branch 'dev/branches/lucene5339'\n[ https://svn.apache.org/r1545086 ]\n\nLUCENE-5339: more tests; add search utility methods; remove request path from SimpleFacetResult ",
            "author": "ASF subversion and git services",
            "id": "comment-13831066"
        },
        {
            "date": "2013-11-24T22:32:40+0000",
            "content": "Commit 1545096 from Michael McCandless in branch 'dev/branches/lucene5339'\n[ https://svn.apache.org/r1545096 ]\n\nLUCENE-5339: remove RangeAccumulator/FacetRequest ",
            "author": "ASF subversion and git services",
            "id": "comment-13831071"
        },
        {
            "date": "2013-11-24T22:35:41+0000",
            "content": "Commit 1545097 from Michael McCandless in branch 'dev/branches/lucene5339'\n[ https://svn.apache.org/r1545097 ]\n\nLUCENE-5339: remove old sorted set ",
            "author": "ASF subversion and git services",
            "id": "comment-13831073"
        },
        {
            "date": "2013-11-26T00:12:58+0000",
            "content": "Commit 1545466 from Michael McCandless in branch 'dev/branches/lucene5339'\n[ https://svn.apache.org/r1545466 ]\n\nLUCENE-5339: finish cutover ",
            "author": "ASF subversion and git services",
            "id": "comment-13832109"
        },
        {
            "date": "2013-11-26T12:46:14+0000",
            "content": "Commit 1545637 from Michael McCandless in branch 'dev/branches/lucene5339'\n[ https://svn.apache.org/r1545637 ]\n\nLUCENE-5339: cutover demo to new APIs ",
            "author": "ASF subversion and git services",
            "id": "comment-13832543"
        },
        {
            "date": "2013-11-26T12:49:18+0000",
            "content": "Commit 1545639 from Michael McCandless in branch 'dev/branches/lucene5339'\n[ https://svn.apache.org/r1545639 ]\n\nLUCENE-5339: add missing file ",
            "author": "ASF subversion and git services",
            "id": "comment-13832544"
        },
        {
            "date": "2013-11-26T15:29:47+0000",
            "content": "I built javadocs from this branch and took a look, much less overwhelming!\n\nCan we do something about the .writercache packages? must there really be 3 of them with names like cl2o?\n\n\norg.apache.lucene.facet \t\norg.apache.lucene.facet.simple \t \norg.apache.lucene.facet.taxonomy \t\norg.apache.lucene.facet.taxonomy.directory \t\norg.apache.lucene.facet.taxonomy.writercache \t\norg.apache.lucene.facet.taxonomy.writercache.cl2o \t\norg.apache.lucene.facet.taxonomy.writercache.lru \t\n\n ",
            "author": "Robert Muir",
            "id": "comment-13832664"
        },
        {
            "date": "2013-11-26T18:14:26+0000",
            "content": "Can we do something about the .writercache packages?\n\n+1 for moving both LRU and CL2O under the *.writercache package. Those packages are tiny, there's no need to really separate them. Also, while we're at it, I think we can rename the Cl2o cache to something more meaningful like FullTaxoInMemoryCache or better name. Cl2o, which stands for CategoryLabelToOrdinal is just meaningless...\n\nBTW, I noticed in your list of packages above that we still have .simple \u2013 are we going to keep it or it's just that not all of the facet module was cutover to the new API? ",
            "author": "Shai Erera",
            "id": "comment-13832824"
        },
        {
            "date": "2013-11-26T19:53:24+0000",
            "content": "Commit 1545798 from Michael McCandless in branch 'dev/branches/lucene5339'\n[ https://svn.apache.org/r1545798 ]\n\nLUCENE-5339: move/rename away from simple ",
            "author": "ASF subversion and git services",
            "id": "comment-13832950"
        },
        {
            "date": "2013-11-26T19:55:06+0000",
            "content": "Can we do something about the .writercache packages?\n+1 for moving both LRU and CL2O under the *.writercache package.\n\nGood idea, I'll move them.\n\nBTW, I noticed in your list of packages above that we still have .simple \u2013 are we going to keep it or it's just that not all of the facet module was cutover to the new API?\n\nI just committed the cutover to remove \"simple\" ... ",
            "author": "Michael McCandless",
            "id": "comment-13832952"
        },
        {
            "date": "2013-11-26T20:14:23+0000",
            "content": "Commit 1545808 from Michael McCandless in branch 'dev/branches/lucene5339'\n[ https://svn.apache.org/r1545808 ]\n\nLUCENE-5339: remove writercache sub-packages ",
            "author": "ASF subversion and git services",
            "id": "comment-13832989"
        },
        {
            "date": "2013-11-27T09:12:45+0000",
            "content": "Been away from the issue for some time and it looks like a major progress,  Chapeau \u00e0 lui\n\nLabelAndValue & FacetResult use instanceof checks in their equals method - is that a must?\n\nFacetResult has a member called childCount - I think it's the number of categories/path/labels that were encountered. The current jdocs \"How many labels were populated under the requested path\" reveals implementation (population). Perhaps exchange populated with encountered?\n\nFloatRange and DoubleRange uses Math.nextUp/Down for infinity as the ranges are always inclusive. Perhaps these constants for float and double could be static final. \n\nTaxonomyFacetSumFloatAssociations and TaxonomyFacetSumValueSource reuse a LOT of code, can they extend one another? perhaps extract a common super for both?\n\nIn TaxonomyFacets the parents array is saves, I could not see where it's being used (and I think it's not used even in the older taxonomy-facet implementation). \n\nFacetConfig confuses me a bit, as it's very much aware of the Taxonomy, on another it handles all the kinds of the facets.\nPerhaps FacetConfig.build() could be split up, allowing each FacetField.Type a build() method of its own, rather than every types' building being done in the same method. It will also bring a common parent class to all FacetField types, which I also like. As such, the taxonomy part, with processFacetFields() could be moved to its respective Facet implementation.\n ",
            "author": "Gilad Barkai",
            "id": "comment-13833596"
        },
        {
            "date": "2013-11-27T11:55:34+0000",
            "content": "\nBeen away from the issue for some time and it looks like a major progress, Chapeau \u00e0 lui\n\nThanks Gilad, bit by bit...\n\nLabelAndValue & FacetResult use instanceof checks in their equals method - is that a must?\n\nHmm, I'm don't know how to implement .equals without an instanceof check?\n\nFacetResult has a member called childCount - I think it's the number of categories/path/labels that were encountered. The current jdocs \"How many labels were populated under the requested path\" reveals implementation (population). Perhaps exchange populated with encountered?\n\nFixed.\n\nFloatRange and DoubleRange uses Math.nextUp/Down for infinity as the ranges are always inclusive. Perhaps these constants for float and double could be static final.\n\nWell, .nextUp and .nextAfter.  But, what constants?  The number is\ncomputed differently for each range (from the provided min and mx)...\n\nTaxonomyFacetSumFloatAssociations and TaxonomyFacetSumValueSource reuse a LOT of code, can they extend one another? perhaps extract a common super for both?\n\nWell, they differ in the source of the value to aggregate (per doc vs\nper ord), but then the other methods are nearly the same except for\nthe int/float difference... in fact, Fast/TaxoFacetCounts\ngetTopChildren is also the same.\n\nI'll add a TODO...\n\nIn TaxonomyFacets the parents array is saves, I could not see where it's being used (and I think it's not used even in the older taxonomy-facet implementation).\n\nOoh, good catch: I removed it.\n\n\nFacetConfig confuses me a bit, as it's very much aware of the Taxonomy, on another it handles all the kinds of the facets.\nPerhaps FacetConfig.build() could be split up, allowing each FacetField.Type a build() method of its own, rather than every types' building being done in the same method. It will also bring a common parent class to all FacetField types, which I also like. As such, the taxonomy part, with processFacetFields() could be moved to its respective Facet implementation.\n\nI'm on the fence on whether FacetsConfig should hold the\ntaxonomyWriter, vs you must pass it to the build method ...\n\nI like the idea of moving the build logic into each FacetField impl,\nbut I want to keep it simple for the app (i.e. the app should not have\nto invoke N build methods). ",
            "author": "Michael McCandless",
            "id": "comment-13833695"
        },
        {
            "date": "2013-11-27T12:07:32+0000",
            "content": "Commit 1546008 from Michael McCandless in branch 'dev/branches/lucene5339'\n[ https://svn.apache.org/r1546008 ]\n\nLUCENE-5339: Gilad's feedback, improve javadocs ",
            "author": "ASF subversion and git services",
            "id": "comment-13833711"
        },
        {
            "date": "2013-11-27T16:34:40+0000",
            "content": "Commit 1546097 from Michael McCandless in branch 'dev/branches/lucene5339'\n[ https://svn.apache.org/r1546097 ]\n\nLUCENE-5339: factor out base classes for int/float taxonomy aggregates ",
            "author": "ASF subversion and git services",
            "id": "comment-13833923"
        },
        {
            "date": "2013-11-27T17:32:43+0000",
            "content": "Commit 1546129 from Michael McCandless in branch 'dev/branches/lucene5339'\n[ https://svn.apache.org/r1546129 ]\n\nLUCENE-5339: address some nocommits ",
            "author": "ASF subversion and git services",
            "id": "comment-13833975"
        },
        {
            "date": "2013-11-27T19:35:23+0000",
            "content": "Commit 1546167 from Michael McCandless in branch 'dev/branches/lucene5339'\n[ https://svn.apache.org/r1546167 ]\n\nLUCENE-5339: nocommits ",
            "author": "ASF subversion and git services",
            "id": "comment-13834068"
        },
        {
            "date": "2013-11-29T21:49:15+0000",
            "content": "Commit 1546653 from Michael McCandless in branch 'dev/branches/lucene5339'\n[ https://svn.apache.org/r1546653 ]\n\nLUCENE-5339: fix some nocommits; move taxoWriter out of FacetsConfig; move search + collect utility methods to FacetsCollector ",
            "author": "ASF subversion and git services",
            "id": "comment-13835549"
        },
        {
            "date": "2013-12-02T23:44:14+0000",
            "content": "Commit 1547241 from Michael McCandless in branch 'dev/branches/lucene5339'\n[ https://svn.apache.org/r1547241 ]\n\nLUCENE-5339: nocommits, javadocs, tests, range drill downs ",
            "author": "ASF subversion and git services",
            "id": "comment-13837086"
        },
        {
            "date": "2013-12-03T18:22:15+0000",
            "content": "Commit 1547511 from Michael McCandless in branch 'dev/branches/lucene5339'\n[ https://svn.apache.org/r1547511 ]\n\nLUCENE-5339: small opto for range facets, and factor out base class; put longHashCode back ",
            "author": "ASF subversion and git services",
            "id": "comment-13837993"
        },
        {
            "date": "2013-12-19T01:07:45+0000",
            "content": "Commit 1552197 from Michael McCandless in branch 'dev/branches/lucene5339'\n[ https://svn.apache.org/r1552197 ]\n\nLUCENE-5339: address remaining nocommits ",
            "author": "ASF subversion and git services",
            "id": "comment-13852428"
        },
        {
            "date": "2013-12-19T17:48:50+0000",
            "content": "Commit 1552377 from Michael McCandless in branch 'dev/branches/lucene5339'\n[ https://svn.apache.org/r1552377 ]\n\nLUCENE-5339: merge trunk ",
            "author": "ASF subversion and git services",
            "id": "comment-13853069"
        },
        {
            "date": "2013-12-19T18:35:56+0000",
            "content": "I think this branch is nearly ready.  I'm attaching the current diffs vs trunk.\n\nForbidden APIs is still angry (I enabled method level document linting for the facets module), and I need to get \"ant precommit\" happy, but I think it's close.\n\nThis also includes the fixes for LUCENE-5371 (use segment trees for range faceting). ",
            "author": "Michael McCandless",
            "id": "comment-13853123"
        },
        {
            "date": "2013-12-25T07:11:15+0000",
            "content": "Few comments about package organization and names:\n\n\n\tCan we move all the taxonomy stuff under o.a.l.facet.taxonomy?\n\t\n\t\tInside create *.associations and put all the associations stuff there (*FacetField, *Facets)\n\t\n\t\n\n\n\n\n\tCan we move all the SortedSet stuff under o.a.l.facet.sortedset?\n\n\n\n\n\tDo you think we need o.a.l.facet.range for all the range collecting classes? It seems we have now more than before.\n\n\n\n\n\tI think we can remove FacetPackage.java - it was needed in the past because o.a.l.facet had no classes.\n\n\n\nIf you agree with moving packages, then we need to do the same for tests too.\n\nI haven't fully reviewed the branch yet, I plan to though it may take me 1-2 weeks to finish a current project with a tight deadline. If you don't want to wait that's fine, we can open follow-up issues later. ",
            "author": "Shai Erera",
            "id": "comment-13856535"
        },
        {
            "date": "2013-12-28T10:33:07+0000",
            "content": "Thanks Shai.\n\nI'd rather not add the sub-package hierarchy here; these sub-packages would only have a few classes and I think that's overkill?  I think having so many sub-packages is also intimidating on first impression.\n\nI think we can remove FacetPackage.java - it was needed in the past because o.a.l.facet had no classes.\n\nAhh, OK, I'll remove it.\n\nI haven't fully reviewed the branch yet, I plan to though it may take me 1-2 weeks to finish a current project with a tight deadline. If you don't want to wait that's fine, we can open follow-up issues later.\n\nOK, I'll likely commit this early next week ... we can iterate after that. ",
            "author": "Michael McCandless",
            "id": "comment-13857995"
        },
        {
            "date": "2013-12-29T07:46:51+0000",
            "content": "It's just that we have *.facet.taxonomy package, yet many taxonomy related classes are outside it. I prefer to have a more organized package hierarchy which groups classes together, than having them in an arbitrary *.facet package. For instance, the *.facet package alone contains 40 classes, yet the \"suggest\" package contains a total of 28 classes, that are divided into logical packages (*.analyzing, *.fst, *.tst, *.jaspell and *.suggest itself). What's the benefit of dumping all the classes in one package, when they don't share any common code? If we have a *.taxonomy, *.sortedset and *.range, you can at least know where to look for if you want to e.g. facet by taxonomy or sortedset. I don't know why you think packages are intimidating, they are meant to organize the code, and help users find related stuff. I did a quick count and compare:\n\n\n\tSuggest module's packages contain 6 classes under *.analyzing and *.fst (each), 2 classes under *.jaspell and 3 classes under *.tst.\n\tFacet module could contain 6 classes under *.range, 3 classes under *.sortedset and 9 classes under *.taxonomy (besides the ones that are already there).\n\n\n\nThe two modules are similar IMO, just like you have several methods for \"suggesting\", you have several methods for \"faceting\"... ",
            "author": "Shai Erera",
            "id": "comment-13858276"
        },
        {
            "date": "2013-12-29T07:58:13+0000",
            "content": "Maybe one crazy idea is to look at the JDK apis for inspiration.\n\nSometimes the separate packages help, sometimes they hurt. Look at codecs/ for example:\n\n\tit helps from an organization perspective, since we have quite a few of them, and its a super-expert thing where users by definition are probably looking at the source code anyway.\n\tit hurts that we have a bunch of classes exposed (in both o.a.l.index and also o.a.l.codecs). This makes the javadocs overwhelming.\n\n\n\nFor the faceting module, I don't think we should expect users are looking at the source code, at the same time this is an open source project so we should also care how its organized.\n\nI don't have an opinion either way: I'm just going to note that one big difference in the JDK apis (since i consider them very well done), is that they have a concept of \"internal packages\" that they hide from javadocs and so on, a way of getting the best of both worlds and keep things reasonably organized while also providing a minimal surface area for the public api.\n\nI'm not trying to promote that here, its just interesting. ",
            "author": "Robert Muir",
            "id": "comment-13858279"
        },
        {
            "date": "2013-12-29T12:49:42+0000",
            "content": "OK I agree it would be good to make sub-packages; the range impls already have 6 classes, which is non-trivial, and if we add further facet methods over time (e.g. there's an issue open for the \"enum\" method), then the single-package will be more and more awkward. ",
            "author": "Michael McCandless",
            "id": "comment-13858332"
        },
        {
            "date": "2013-12-31T06:50:57+0000",
            "content": "Commit 1554372 from Shai Erera in branch 'dev/branches/lucene5339'\n[ https://svn.apache.org/r1554372 ]\n\nLUCENE-5339: handle warnings and javadoc errors ",
            "author": "ASF subversion and git services",
            "id": "comment-13859373"
        },
        {
            "date": "2013-12-31T07:33:55+0000",
            "content": "Commit 1554379 from Shai Erera in branch 'dev/branches/lucene5339'\n[ https://svn.apache.org/r1554379 ]\n\nLUCENE-5339: organize packages ",
            "author": "ASF subversion and git services",
            "id": "comment-13859393"
        },
        {
            "date": "2013-12-31T07:37:01+0000",
            "content": "Committed the packages changes. ",
            "author": "Shai Erera",
            "id": "comment-13859394"
        },
        {
            "date": "2014-01-02T00:23:38+0000",
            "content": "Commit 1554710 from Michael McCandless in branch 'dev/branches/lucene5339'\n[ https://svn.apache.org/r1554710 ]\n\nLUCENE-5339: javadocs ",
            "author": "ASF subversion and git services",
            "id": "comment-13859977"
        },
        {
            "date": "2014-01-04T11:19:39+0000",
            "content": "Commit 1555338 from Michael McCandless in branch 'dev/trunk'\n[ https://svn.apache.org/r1555338 ]\n\nLUCENE-5371, LUCENE-5339: speed up range faceting from O(N) per hit to O(log(N)) using segment trees; simplify facet APIs ",
            "author": "ASF subversion and git services",
            "id": "comment-13862269"
        },
        {
            "date": "2014-01-04T12:34:10+0000",
            "content": "Commit 1555342 from Michael McCandless in branch 'dev/branches/branch_4x'\n[ https://svn.apache.org/r1555342 ]\n\nLUCENE-5371, LUCENE-5339: speed up range faceting from O(N) per hit to O(log(N)) using segment trees; simplify facet APIs ",
            "author": "ASF subversion and git services",
            "id": "comment-13862292"
        },
        {
            "date": "2014-01-05T00:23:05+0000",
            "content": "Commit 1555438 from Michael McCandless in branch 'dev/trunk'\n[ https://svn.apache.org/r1555438 ]\n\nLUCENE-5339: PrintTaxonomyStats is allowed to use System.out ",
            "author": "ASF subversion and git services",
            "id": "comment-13862452"
        },
        {
            "date": "2014-01-05T00:23:32+0000",
            "content": "Commit 1555439 from Michael McCandless in branch 'dev/branches/branch_4x'\n[ https://svn.apache.org/r1555439 ]\n\nLUCENE-5339: PrintTaxonomyStats is allowed to use System.out ",
            "author": "ASF subversion and git services",
            "id": "comment-13862453"
        },
        {
            "date": "2014-01-05T06:40:42+0000",
            "content": "Thanks Mike! Do we need to delete the branch? ",
            "author": "Shai Erera",
            "id": "comment-13862499"
        },
        {
            "date": "2014-01-05T17:50:25+0000",
            "content": "Do we need to delete the branch?\n\nI'll delete it... ",
            "author": "Michael McCandless",
            "id": "comment-13862608"
        },
        {
            "date": "2014-01-05T17:52:05+0000",
            "content": "Commit 1555590 from Michael McCandless in branch 'dev/branches/lucene5339'\n[ https://svn.apache.org/r1555590 ]\n\nLUCENE-5339: remove now dead branch (it's merged/committed to trunk) ",
            "author": "ASF subversion and git services",
            "id": "comment-13862610"
        },
        {
            "date": "2014-01-05T18:03:03+0000",
            "content": "Commit 1555592 from Michael McCandless in branch 'dev/trunk'\n[ https://svn.apache.org/r1555592 ]\n\nLUCENE-5339: also move OrdinalReaders under taxonomy ",
            "author": "ASF subversion and git services",
            "id": "comment-13862613"
        },
        {
            "date": "2014-01-05T18:06:51+0000",
            "content": "Commit 1555595 from Michael McCandless in branch 'dev/branches/branch_4x'\n[ https://svn.apache.org/r1555595 ]\n\nLUCENE-5339: also move OrdinalReaders under taxonomy ",
            "author": "ASF subversion and git services",
            "id": "comment-13862614"
        },
        {
            "date": "2014-01-05T20:52:46+0000",
            "content": "Commit 1555627 from Michael McCandless in branch 'dev/trunk'\n[ https://svn.apache.org/r1555627 ]\n\nLUCENE-5339: also catch invalid components in *FacetField ",
            "author": "ASF subversion and git services",
            "id": "comment-13862650"
        },
        {
            "date": "2014-01-05T20:53:54+0000",
            "content": "Commit 1555628 from Michael McCandless in branch 'dev/branches/branch_4x'\n[ https://svn.apache.org/r1555628 ]\n\nLUCENE-5339: also catch invalid components in *FacetField ",
            "author": "ASF subversion and git services",
            "id": "comment-13862651"
        }
    ]
}