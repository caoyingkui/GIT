{
    "id": "SOLR-8208",
    "title": "DocTransformer executes sub-queries",
    "details": {
        "components": [
            "Response Writers"
        ],
        "type": "Improvement",
        "labels": "",
        "fix_versions": [
            "6.1",
            "7.0"
        ],
        "affect_versions": "None",
        "status": "Closed",
        "resolution": "Fixed",
        "priority": "Major"
    },
    "description": "The initial idea was to return \"from\" side of query time join via doctransformer. I suppose it isn't  query-time join specific, thus let to specify any query and parameters for them, let's call it sub-query. But it might be problematic to escape subquery parameters, including local ones, e.g. what if subquery needs to specify own doctransformer in &fl=[..] ?\nI suppose we can specify subquery parameter prefix:\n\n..&q=name_s:john&fl=*,depts:[subquery fromIndex=departments]&\ndepts.q={!term f=dept_id_s v=$row.dept_ss_dv}&depts.fl=text_t,dept_id_s_dv&depts.rows=12&depts.sort=id desc\n\n       \nresponse is like\n\n       \n<response>\n...\n    <result name=\"response\" numFound=\"1\" start=\"0\">\n        <doc>\n            <str name=\"id\">1</str>\n            <str name=\"name_s_dv\">john</str>\n..\n            <result name=\"depts\" numFound=\"2\" start=\"0\">\n                <doc>\n                    <str name=\"dept_id_s_dv\">Engineering</str>\n                    <str name=\"text_t\">These guys develop stuff</str>\n                </doc>\n                <doc>\n                    <str name=\"dept_id_s_dv\">Support</str>\n                    <str name=\"text_t\">These guys help users</str>\n                </doc>\n            </result>\n        </doc>\n    </result>\n</response>\n\n       \n\n\n\tfl=depts:[subquery] executes a separate request for every query result row, and adds it into a document as a separate result list. The given field name (here it's 'depts') is used as a prefix to shift subquery parameters from main query parameter, eg depts.q turns to q for subquery, depts.rows to rows.\n\tdocument fields are available as implicit parameters with prefix row. eg. if result document has a field dept_id it can be referred as v=$row.dept_id this combines well with {!terms} query parser\n\tseparator=',' is used when multiple field values are combined in parameter. eg. a document has multivalue field \n\ndept_ids={2,3}\n\n, thus referring to it via \n\n..&dept.q={!terms f=id v=$row.dept_ids}&..\n\n executes a subquery \n\n{!terms f=id}2,3\n\n. When omitted  it's a comma.\n\tfromIndex=othercore optional param allows to run subquery on other core, like it works on query time join\nHowever, it doesn't work on cloud setup (and will let you know), but it's proposed to use regular params (collection, shards - whatever, with subquery prefix as below ) to issue subquery to a collection\n\nq=name_s:dave&indent=true&fl=*,depts:[subquery]&rows=20&\ndepts.q={!terms f=dept_id_s v=$row.dept_ss_dv}&depts.fl=text_t&\ndepts.indent=true&\ndepts.collection=departments&\ndepts.rows=10&depts.logParamsList=q,fl,rows,row.dept_ss_dv\n\n\n\n\n\nCaveat: it should be a way slow; it handles only search result page, not entire result set.",
    "attachments": {
        "SOLR-8208.diff": "https://issues.apache.org/jira/secure/attachment/12794400/SOLR-8208.diff",
        "SOLR-8208-distrib-test-fix.patch": "https://issues.apache.org/jira/secure/attachment/12803933/SOLR-8208-distrib-test-fix.patch",
        "SOLR-8208.patch": "https://issues.apache.org/jira/secure/attachment/12777719/SOLR-8208.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2015-10-25T23:07:42+0000",
            "author": "Upayavira",
            "content": "Something I've wanted for a long time - you've got my vote.\n\nWhy should it be way slow? Obviously for a very large number of docs in the result set it would get resource intensive, but for medium numbers it should be quite acceptable, no?\n\nAnother feature that would make this really neat would be to specify the tag of a filter query that you want to use as your sub-query - assuming it includes a join query. Thus, you would only need to specify your join query once - including fromIndex, join fields, etc - all you would need to specify would be the fields you want to include:\n\n\nfq={!tag=join}{!join fromIndex=other from=id to=id}some_query&\nfl=*,[subquery fq.tag=join fl=field1,field2]\n\n ",
            "id": "comment-14973476"
        },
        {
            "date": "2015-10-26T11:43:56+0000",
            "author": "Mikhail Khludnev",
            "content": "Something I've wanted for a long time - you've got my vote.\nThanks! Appreciate. but it's only \"watch\", not vote!\nbut for medium numbers it should be quite acceptable,\nthat's what I meant.\nfq={!tag=join}\n\n\tthis approach is limited by join subquery that's might not be bad, actually, but join query might be really expensive, eg it doesn't leapfrog well;\n\talso in this case join subquery should be turned: \"from\"<->\"to\", that's might be tricky;\n\tit seems limited to score less join, but now there is a score-emitting twin!\n\tI'm really afraid of parsing splitting:\n\nfl=*,[subquery fq.tag=join fl=field1,field2,[transf param=etc]]\n\n \n\n ",
            "id": "comment-14974078"
        },
        {
            "date": "2015-12-15T03:57:37+0000",
            "author": "Cao Manh Dat",
            "content": "Mikhail Khludnev I really want to work on this issue, can you assign this issue to me? ",
            "id": "comment-15057301"
        },
        {
            "date": "2015-12-15T04:43:18+0000",
            "author": "Erick Erickson",
            "content": "Hmm, for some reason I can't seem to assign it to you. While we figure that out, you could simply start working on it anyway without it being assigned to you...\n\nCan you click on the \"more\" button at the top and have an option to \"upload files\"? If so, you can freely upload patches..\n\nBTW, I don't know if you know this already, but usually we work against trunk. Then whoever commits the patch will merge it back to 5x. ",
            "id": "comment-15057332"
        },
        {
            "date": "2015-12-15T04:53:06+0000",
            "author": "Cao Manh Dat",
            "content": "Erick EricksonThanks Erick, I can upload file so will update work process through patch file. ",
            "id": "comment-15057346"
        },
        {
            "date": "2015-12-15T10:30:50+0000",
            "author": "Cao Manh Dat",
            "content": "Initial patch,\nI change the API a little bit to make it easier to parse.\n\n[subquery f=fromField t=toField v=value start=0 rows=10]\n\n\n\nThe result so far.\nInput\n\ndoc(\"id\", \"4\",\"name_s\", \"dave\", \"title_s\", \"MTS\", \"dept_ss_dv\",\"Support\", \"dept_ss_dv\",\"Engineering\"))\n\ndoc(\"id\",\"10\", \"dept_id_s\", \"Engineering\", \"text_t\",\"These guys develop stuff\", \"salary_i_dv\", \"1000\")\ndoc(\"id\",\"13\", \"dept_id_s\", \"Support\", \"text_t\",\"These guys help customers\",\"salary_i_dv\", \"800\")\n\n\n\nQuery\n\nq=name_s:dave&fl=*,[subquery f=dept_ss_dv t=dept_id_s v=depts]\n\n\n\nOutput\n\n{\n  \"id\": \"4\",\n  \"name_s_dv\": \"dave\",\n  \"title_s_dv\": \"MTS\",\n  \"dept_ss_dv\": [\n    \"Support\",\n    \"Engineering\"\n  ],\n  \"depts\": [\n    {\n      \"id\": \"10\",\n      \"dept_id_s_dv\": \"Engineering\",\n      \"text_t\": \"These guys develop stuff\",\n      \"salary_i_dv\": 1000\n    },\n    {\n      \"id\": \"13\",\n      \"dept_id_s_dv\": \"Support\",\n      \"text_t\": \"These guys help customers\",\n      \"salary_i_dv\": 800\n    }\n  ]\n}\n\n\n\nManaging to work on sort and fl params. Am i on right track? ",
            "id": "comment-15057812"
        },
        {
            "date": "2015-12-15T11:02:15+0000",
            "author": "Upayavira",
            "content": "This is useful stuff. Much needed. I assume this would work as well on block joins and alongside pseudo joins, which I think I'm seeing above?\n\nTraditionally, in a local params query parser, the parameter v refers to the actual query string, so: \n\nq={!lucene v=$qq}&qq=field:(my search) \n\n would be a valid syntax. I would suggest using n= (for name) or tag= for the field name of the newly created field to avoid association with this v= syntax.\n\nIs a lookup based upon the ID of a field in the current document sufficient? I suspect it is.\n\nDo you also support fromIndex - that is, executing the query against another core or collection? That would be the killer feature.\n\nAs to the fq=\n{!tag=join}\n{!join blah....}\n syntax, if you had [subquery fq=join], you wouldn't actually execute the join query, you would just locate the query object, and extract its key parameters to avoid the user from having to enter them multiple times. Having both options would be super cool. ",
            "id": "comment-15057857"
        },
        {
            "date": "2015-12-16T09:17:32+0000",
            "author": "Cao Manh Dat",
            "content": "I changed the api back like Mikhail's suggestion\n\nResult so far. \nQuery\n\nq=name_s:dave\n&fl=*,[subquery prefix=subq1 name=depts]\n&subq1.q={!term f=dept_id_s v=$subq1.row.dept_ss_dv}\n\n\n\nInput\n\ndoc(\"id\", \"4\",\"name_s\", \"dave\", \"title_s\", \"MTS\", \"dept_ss_dv\",\"Support\", \"dept_ss_dv\",\"Engineering\"))\n\ndoc(\"id\",\"10\", \"dept_id_s\", \"Engineering\", \"text_t\",\"These guys develop stuff\", \"salary_i_dv\", \"1000\")\ndoc(\"id\",\"13\", \"dept_id_s\", \"Support\", \"text_t\",\"These guys help customers\",\"salary_i_dv\", \"800\")\n\n\n\nResult\n\n{\n  \"id\": \"4\",\n  \"name_s_dv\": \"dave\",\n  \"title_s_dv\": \"MTS\",\n  \"dept_ss_dv\": [\n    \"Support\",\n    \"Engineering\"\n  ],\n  \"depts\": [\n    {\n      \"id\": \"13\",\n      \"dept_id_s_dv\": \"Support\",\n      \"text_t\": \"These guys help customers\",\n      \"salary_i_dv\": 800\n    }\n  ]\n}\n\n\n\nI just have one question. What should we do when from field have multiple values? Should we change the \n\nsubq1.q\n\n to\n\n{!term f=dept_id_s v=\"Support Engineer\"}\n\n\n\nI will submit the patch frequently to keep me on track. Hope that it not bother people. ",
            "id": "comment-15059731"
        },
        {
            "date": "2015-12-17T20:22:19+0000",
            "author": "Mikhail Khludnev",
            "content": "Do you also support fromIndex - that is, executing the query against another core or collection? That would be the killer feature.\n\ngreat idea. Let me spawn a sub-task. \n ",
            "id": "comment-15062727"
        },
        {
            "date": "2015-12-17T20:24:47+0000",
            "author": "Mikhail Khludnev",
            "content": "What should we do when from field have multiple values?\n\nI prefer to forget about it, until we have real life challenge from someone. So, far support  single value fields.    ",
            "id": "comment-15062731"
        },
        {
            "date": "2015-12-18T03:36:58+0000",
            "author": "Cao Manh Dat",
            "content": "Thanks Mikhail, It will make thing more easier. I also consider about distributing the sub-queries, so I'm trying to do this (execute the subquery through solrCore)\n\nSolrCore solrCore = subQueryRequest.getCore();\nSolrQueryResponse response = new SolrQueryResponse();\nsolrCore.execute(solrCore.getRequestHandler(null), subQueryRequest, response);\nDocsStreamer docsStreamer = new DocsStreamer((ResultContext) response.getValues().get(\"response\"));\n\n\nBut i'm afraid that it will mess up the logic inside SolrCore.execute ",
            "id": "comment-15063358"
        },
        {
            "date": "2015-12-18T08:48:22+0000",
            "author": "Mikhail Khludnev",
            "content": "I added a couple of assertions.\n\nI suppose the last snippet makes much sense, just because scoring query parsers do [something|\nhttps://github.com/apache/lucene-solr/blob/trunk/solr/core/src/java/org/apache/solr/search/join/ScoreJoinQParserPlugin.java#L95] like this.    ",
            "id": "comment-15063704"
        },
        {
            "date": "2015-12-23T07:20:29+0000",
            "author": "Cao Manh Dat",
            "content": "Mikhail Khludnev Please review my patch. I thinks it quite ok now. ",
            "id": "comment-15069343"
        },
        {
            "date": "2015-12-23T07:41:07+0000",
            "author": "Mikhail Khludnev",
            "content": "don't worry. both of your patches in my commit queue. It just takes some time.  ",
            "id": "comment-15069354"
        },
        {
            "date": "2016-03-18T23:15:16+0000",
            "author": "Mikhail Khludnev",
            "content": "Hello Cao Manh Dat,\nI terribly sorry for such late review.\n\nI applied the recent patch to master. There was some compile problems with StoredField or, so. I can't pass units. \nTestSubQueryTransformer.testSubQuerytransformer()\n\n assertQ(\"subq1.fl is limited to single field\",\n      req(\"q\",\"name_s:john\",\n        \"fl\",\"*,depts:[subquery prefix=subq1]\", \"subq1.q\",\"{!term f=dept_id_s v=$subq1.row.dept_ss_dv}\", \"subq1.fl\",\"text_t\"),\n      \"//result/doc/str[@name='name_s_dv'][.='john']/../arr[@name='depts']/doc/str[@name='text_t'][.='These guys develop stuff']\",\n      \"count(//result/doc/str[@name='name_s_dv'][.='john']/../arr[@name='depts']/doc/*)=1\");// only text_t\n\n\n\n REQUEST FAILED: xpath=count(//result/doc/str[@name='name_s_dv'][.='john']/../arr[@name='depts']/doc/*)=1\n<response>\n<lst name=\"responseHeader\"><int name=\"status\">0</int><int name=\"QTime\">15474</int></lst><result name=\"response\" numFound=\"1\" start=\"0\">\n\n<doc><str name=\"id\">1</str>\n        <str name=\"name_s_dv\">john</str>\n        <str name=\"title_s_dv\">Director</str>\n        <arr name=\"dept_ss_dv\"><str>Engineering</str></arr>\n        <arr name=\"depts\">\n                 <doc><str name=\"text_t\">These guys develop stuff</str></doc>\n                 <doc><str name=\"text_t\">These guys develop other stuff</str></doc>\n                 <doc><str name=\"text_t\">These guys develop manage other engineers</str></doc></arr>\n       </doc>\n</result>\n</response>\n\n\n\nthis xpath matches three times, not once as it's asserted\n\n\n<str name=\"text_t\">These guys develop stuff</str>\n<str name=\"text_t\">These guys develop other stuff</str>\n<str name=\"text_t\">These guys develop manage other engineers</str>\n\n\n\nCan't it happen as that there should be subq1.rows=1? Can you make sure that tests pass?\n\nAlso, I didn't get deep yet, but I noticed some request/closable infrastructure, it's wise to avoid obtaining core on very transformation, but couldn't it be achieved via SolrRequestInfo.addCloseHook(Closeable)  ?\n\nthe also thing which I want to think about is to avoid code with regexp replace/field types and toExternal, I have an idea to use already resolved document fields as parameters view with keys prepended with \"subq1.row.\" This can be used by chaining like DefaultSolrParams.  \n ",
            "id": "comment-15202346"
        },
        {
            "date": "2016-03-20T10:26:26+0000",
            "author": "Cao Manh Dat",
            "content": "Hi Mikhail,\n\nI updated the code with lastest code in trunk. All tests are passed now. ",
            "id": "comment-15203227"
        },
        {
            "date": "2016-03-20T21:13:46+0000",
            "author": "Mikhail Khludnev",
            "content": "I moved patch to existing closeables. Now I'm looking into change in DocStreamer and trying to avoid it.   ",
            "id": "comment-15203528"
        },
        {
            "date": "2016-03-22T22:38:41+0000",
            "author": "Mikhail Khludnev",
            "content": "attaching a patch which pass existing tests.   now it avoids changes in DocStreamer and SolrQueryRequest. As a detail, subquery results are represents with <result>, but not <arr> \n\n<response>\n\n<lst name=\"responseHeader\">\n  <int name=\"status\">0</int>\n  <int name=\"QTime\">650</int>\n</lst>\n<result name=\"response\" numFound=\"1\" start=\"0\">\n  <doc>\n    <str name=\"id\">1</str>\n    <str name=\"name_s_dv\">john</str>\n    <str name=\"title_s_dv\">Director</str>\n    <arr name=\"dept_ss_dv\">\n      <str>Engineering</str>\n    </arr>\n    <result name=\"depts\" numFound=\"1\" start=\"0\">\n      <doc>\n        <str name=\"text_t\">These guys develop stuff</str></doc>\n    </result></doc>\n</result>\n</response>\n\n\n\nHow do you feel about it?  ",
            "id": "comment-15207447"
        },
        {
            "date": "2016-03-25T21:49:48+0000",
            "author": "Mikhail Khludnev",
            "content": "SOLR-8208.patch here is how I'd like to handle parameters substitution.\nNote, the patch might in in really early stages (might not even work on may docs, etc). \nSubquery still accepts only single value doc fields as a parameter, how do you prefer handle multivalue field, if you do? ",
            "id": "comment-15212464"
        },
        {
            "date": "2016-03-26T20:14:11+0000",
            "author": "Mikhail Khludnev",
            "content": "I just got an idea how to handle multivalue fields, there should be [subquery prefix=products mv-delim=,] thus muliple values are concatenated and can be used as an input for \n\n...&products.q={!terms separator=, v=$products.row.id} \n\nWDYT?   ",
            "id": "comment-15213183"
        },
        {
            "date": "2016-03-26T21:54:03+0000",
            "author": "Mikhail Khludnev",
            "content": "made some severe improvements  ",
            "id": "comment-15213216"
        },
        {
            "date": "2016-04-01T08:27:36+0000",
            "author": "Mikhail Khludnev",
            "content": "attaching the shuffled tests. \nrevealed a design gap - even if doc field isn't referred in subquery, because solr eagerly copies params. That's a pity.\n\norg.apache.solr.common.SolrException: SubQuery depts cant substitute  multiple values [stored,indexed,toke via parameter \"subq1.row.dept_ss_dv\" for document SolrDocument{id=stor\n\nSubQueryAugmenter$DocParams.get(String) line: 172\t\nSubQueryAugmenter$DocParams.getParams(String) line: 139\t\nDefaultSolrParams.getParams(String) line: 44\t\nMultiMapSolrParams.asMultiMap(SolrParams, boolean) line: 103\t\nRequestUtil.processParams(SolrRequestHandler, SolrQueryRequest, SolrParams, SolrParams, SolrParams) line: 104\t\nSolrPluginUtils.setDefaults(SolrRequestHandler, SolrQueryRequest, SolrParams, SolrParams, SolrParams) line: 176\t\nSearchHandler(RequestHandlerBase).handleRequest(SolrQueryRequest, SolrQueryResponse) line: 152\t\nSolrCore.execute(SolrRequestHandler, SolrQueryRequest, SolrQueryResponse) line: 2033\t\nSubQueryAugmenter.transform(SolrDocument, int, float) line: 226\t\nDocsStreamer.next() line: 146\t\n...\n\n\n\nMultivalue fields substitution should be implemented before it moves further. \n ",
            "id": "comment-15221362"
        },
        {
            "date": "2016-04-02T21:32:45+0000",
            "author": "Mikhail Khludnev",
            "content": "attaching an implementation with multivalue fix and tests.\n\nReveal a potential usability usage: Implicit subquery params (doc values) are not logged:\n\n params={q=name_s:dave&subq1.rows=6&indent=true&fl=*,depts:[subquery+prefix%3Dsubq1+separator%3D\"+\"]&rows=3&subq1.indent=true&wt=xml&subq1.fl=text_t&subq1.q={!lucene+df%3Ddept_id_s+v%3D$subq1.row.dept_ss_dv}} hits=3 status=0 QTime=2\n params={rows=6&indent=true&fl=text_t&q={!lucene+df%3Ddept_id_s+v%3D$subq1.row.dept_ss_dv}} hits=6 status=0 QTime=4\n params={rows=6&indent=true&fl=text_t&q={!lucene+df%3Ddept_id_s+v%3D$subq1.row.dept_ss_dv}} hits=6 status=0 QTime=7\n params={rows=6&indent=true&fl=text_t&q={!lucene+df%3Ddept_id_s+v%3D$subq1.row.dept_ss_dv}} hits=6 status=0 QTime=10\n\n\nthe first line is a main query, and the latter are subqueries. here you see that and actual value of subq1.row.dept_ss_dv are not logged, but it might by deadly needful.\n\nWhat's you prefer tweak params somehow for logging, or allow debugQuery=true for subqueries, and inject it into main query debug? ",
            "id": "comment-15223049"
        },
        {
            "date": "2016-04-03T20:48:41+0000",
            "author": "Mikhail Khludnev",
            "content": "it seems like param tracing can be done with logParamsList\n\n...Request [collection1]  webapp=null path=null params={q=name_s:dave&subq1.rows=6&indent=true&fl=*,depts:[subquery+prefix%3Dsubq1+]&rows=2&subq1.indent=true&subq1.logParamsList=q,fl,rows,subq1.row.dept_ss_dv&wt=xml&subq1.fl=text_t&subq1.q={!terms+f%3Ddept_id_s+v%3D$subq1.row.dept_ss_dv+separator%3D,}} hits=2 status=0 QTime=9979\n...Request [collection1]  webapp=null path=null params={q={!terms+f%3Ddept_id_s+v%3D$subq1.row.dept_ss_dv+separator%3D,}&subq1.row.dept_ss_dv=Support,Engineering&fl=text_t&rows=6} hits=6 status=0 QTime=60740\n\n ",
            "id": "comment-15223511"
        },
        {
            "date": "2016-04-11T21:37:33+0000",
            "author": "Mikhail Khludnev",
            "content": "attaching a test with logParamsList and json assert ",
            "id": "comment-15236024"
        },
        {
            "date": "2016-04-25T07:24:49+0000",
            "author": "Mikhail Khludnev",
            "content": "Added cloud test. As expected it doesn't pass. Keep going.   ",
            "id": "comment-15256001"
        },
        {
            "date": "2016-04-26T22:03:04+0000",
            "author": "Mikhail Khludnev",
            "content": "Making subquery call via embedded solr server, I believe it help to handle solr cloud case easier.   ",
            "id": "comment-15259027"
        },
        {
            "date": "2016-04-28T03:00:52+0000",
            "author": "Cao Manh Dat",
            "content": "Make distrib test pass. ",
            "id": "comment-15261458"
        },
        {
            "date": "2016-04-28T21:15:22+0000",
            "author": "Mikhail Khludnev",
            "content": "Cao Manh Dat, your last patch is awesome!!! \nfor the reference, attempt to request cloud collection via EmbeddedSolrServer were too naive:\n\nERROR (qtp1310704163-67) [n:127.0.0.1:65356_ c:people s:shard1 r:core_node2 x:people_shard1_replica1] o.a.s.s.HttpSolrCall null:org.apache.solr.common.SolrException: No such core: departments\n\tat org.apache.solr.client.solrj.embedded.EmbeddedSolrServer.request(EmbeddedSolrServer.java:149)\n\tat org.apache.solr.response.transform.LocalSubQueryAugmenter.transform(SubQueryAugmenterFactory.java:239)\n\tat org.apache.solr.response.DocsStreamer.next(DocsStreamer.java:146)\n\tat org.apache.solr.response.DocsStreamer.next(DocsStreamer.java:1)\n\n ",
            "id": "comment-15263016"
        },
        {
            "date": "2016-04-30T12:40:16+0000",
            "author": "Mikhail Khludnev",
            "content": "\n\tremoved call via cloud client, turns out we can request it via EmbeddedServer explicitly specifying collection=, I'm not sure it's better, but it's just neat at least (which means better, most times)\n\tI introduced thread executor, there are two points behind it: it's allows to don't restore SolrRequestInfo threadlocal every request, however it's necessary to clean it before request, because it's inherited; in future it will be used to enrich docs in parallel, but under another ticket;\n\n\n\nopinions?\n\n\n\tI reconstruct ResultContext to pass numFound and start for subquery result, it might be redundant but seems reasonable\n\tI added empty test method for remaining cases\n\tI want to challenge $subq.doc.field  can't prefix be removed?\n\tit's also make sense to show how [subquery] compete with [child] ig order result or so.\n\n ",
            "id": "comment-15265301"
        },
        {
            "date": "2016-05-02T20:50:05+0000",
            "author": "Mikhail Khludnev",
            "content": "I think it's almost ready. I'll post the final syntax in the description above. Note fore reviewers. It introduces thread pool executor, but use it for sequential invocations for a while.  Change in MLT is just line move no impact at all.\nThe last test I would like to add is just demonstrate how [subquery] can be used instead of [child].\nMy plan is to commit it next week. Concerns?  ",
            "id": "comment-15267481"
        },
        {
            "date": "2016-05-03T17:48:56+0000",
            "author": "David Smiley",
            "content": "I looked at it extremely briefly and just want to say you did a nice thorough job of testing.  Hopefully someone will have more time to look more carefully, but I'm too busy. ",
            "id": "comment-15269180"
        },
        {
            "date": "2016-05-03T21:34:12+0000",
            "author": "Mikhail Khludnev",
            "content": "Appreciate. Take care! ",
            "id": "comment-15269642"
        },
        {
            "date": "2016-05-04T10:01:04+0000",
            "author": "Cao Manh Dat",
            "content": "+1 The last patch sound great! Turn out that SearchHandler distribute the search for us. ",
            "id": "comment-15270428"
        },
        {
            "date": "2016-05-04T20:54:41+0000",
            "author": "Mikhail Khludnev",
            "content": "hmm... you might be laughing, but game is over.\nThe problem is to call EmbeddedSolrServer from DocTransformer. This call isn't possible from thread where SolrRequestInfo is present. So far it's not possible to suspend and then resume SolrRequestInfo. Juggling with threads complicates it a lot, however it's possible to manage threads after all, but not SolrRequestInfo.\n\nYonik Seeley can you suggest an approach?  ",
            "id": "comment-15271411"
        },
        {
            "date": "2016-05-04T23:21:20+0000",
            "author": "Ryan McKinley",
            "content": "Did you try something like:\n\n\n    SolrRequestInfo orig = SolrRequestInfo.getRequestInfo();\n    try {\n      SolrRequestInfo.clearRequestInfo();\n      \n      // TODO, make whatever call you need\n    }\n    finally {\n      SolrRequestInfo.setRequestInfo(orig);\n    }\n\n ",
            "id": "comment-15271620"
        },
        {
            "date": "2016-05-05T03:03:46+0000",
            "author": "Cao Manh Dat",
            "content": "Ryan McKinley I think the above code is quite dangerous because the original SolrRequestInfo can have some close hooks and the call to \n\n SolrRequestInfo.clearRequestInfo()\n\n will close all the hooks.\n\nMikhail Khludnev I'm not laughing at all, i think it is a clever idea to handle swap out/swap in SolrRequestInfo (without modify SolrRequestInfo class) . I propose another approach, that change SolrRequestInfo a little bit.\n\n\npublic static void doActionInEmptyRequestInfo(Action action) throws IOException {\n    SolrRequestInfo prev = threadLocal.get();\n    threadLocal.remove();\n    try {\n      action.doAction();\n      SolrRequestInfo current = threadLocal.get();\n      if (current != null) {\n        log.error(\"New SolrRequestInfo was not closed!  req=\" + current.req.getOriginalParams().toString());\n      }\n      assert current == null;\n    } finally {\n      threadLocal.set(prev);\n    }\n  }\n\n  public interface Action {\n    void doAction() throws IOException;\n  }\n\n ",
            "id": "comment-15271821"
        },
        {
            "date": "2016-05-05T21:50:18+0000",
            "author": "Mikhail Khludnev",
            "content": "\n\tGood news! Cao Manh Dat your approach laid quite well!  For you know sake we have a backdoor to suspend SolrRequestInfo. I wonder if it legal enough?\n\tthreads were removed (I'll comment about a pain, which those who want to get, can get with it).\n\tadded a few tests proving that [subquery] is on par with [child]\n\tmoved tests in a subpackage\n\tone question about code style: the core class (300 LOC) is compiled into more than five classes, doesn't it deserve a separate o.a.s.response.transform.subquery ?\n\n ",
            "id": "comment-15273166"
        },
        {
            "date": "2016-05-06T02:14:56+0000",
            "author": "Cao Manh Dat",
            "content": "Great patch! I think doInSuspension is good (better than swap in/swap out try catch) and we should add doInSuspension  to SolrRequestInfo (to prevent anyone who try to do swap in/swap out in the future). ",
            "id": "comment-15273532"
        },
        {
            "date": "2016-05-07T20:41:21+0000",
            "author": "Mikhail Khludnev",
            "content": "added changes, committing in two days.  ",
            "id": "comment-15275383"
        },
        {
            "date": "2016-05-09T16:42:03+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 7571e747c3506ee93d63c9bd3534254944b5caa7 in lucene-solr's branch refs/heads/master from Mikhail Khludnev\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=7571e74 ]\n\nSOLR-8208: [subquery] document transformer executes separate requests per result document. ",
            "id": "comment-15276595"
        },
        {
            "date": "2016-05-09T17:17:46+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 75a84b7d2d0d8f0ed36efad4306e5a938cae3a2a in lucene-solr's branch refs/heads/branch_6x from Mikhail Khludnev\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=75a84b7 ]\n\nSOLR-8208: [subquery] document transformer executes separate requests per result document. ",
            "id": "comment-15276649"
        },
        {
            "date": "2016-05-09T19:07:56+0000",
            "author": "Mikhail Khludnev",
            "content": "this commit adds TestSubQueryTransformerDistrib which took 1m 34s. Let me know if it's not affordable, and I need mark it somehow. It's a copy-cat twin bro of DistribJoinFromCollectionTest. ",
            "id": "comment-15276833"
        },
        {
            "date": "2016-05-10T18:59:00+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 184983280e9b47a24a448b1894b05bd97e221011 in lucene-solr's branch refs/heads/branch_6x from Mikhail Khludnev\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=1849832 ]\n\nSOLR-8208: miserable javadoc fixes ",
            "id": "comment-15278681"
        },
        {
            "date": "2016-05-10T19:00:31+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 470ba0794ecddd6375db3da521272dde46ed6761 in lucene-solr's branch refs/heads/master from Mikhail Khludnev\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=470ba07 ]\n\nSOLR-8208: miserable javadoc fixes ",
            "id": "comment-15278685"
        },
        {
            "date": "2016-05-10T19:13:02+0000",
            "author": "Mikhail Khludnev",
            "content": "TLDR\nok some notes about an attempt to use separate threads to invoke EmbeddedSolrServer. \nThe first obstacle: it doesn't fully help to clean SolrRequestInfo. (and the problem is that EmbeddedSolrServer can't be invoked from Solr threads where SolrRequestInfo is set). So, even if we introduce thread pool to call EmbeddedSolrServer, SolrRequestInfo.clear() should be called before, because threadpool inherits SolrRequestInfo. Sic.\n\nThe real problem comes later: when randomized tests run. EmbeddedSolrServer internals are larded with randomized flipping gears. So, when it requests a randomized context, it's obtained from a mapping. But the key of this map is a thread group, and DefaultSolrFactory assigns a thread group from the tread which load the threadpool, but it was a thread pool used to launch the first test in the suite, which usually finished already. That makes randomized context unavailable for tests request EmbeddedSolrServer running later. That's a bummer. No way. Don't do this ever.   ",
            "id": "comment-15278697"
        },
        {
            "date": "2016-05-11T06:22:25+0000",
            "author": "David Smiley",
            "content": "ok some notes about an attempt to use separate threads to invoke EmbeddedSolrServer. \n\nInteresting.  Nonetheless it seems that we shouldn't let our test infrastructure prevent us from what we want to do \u2013 it can be changed.  This is an idealistic statement, maybe it isn't sufficiently worth-it, but it depends. ",
            "id": "comment-15279634"
        },
        {
            "date": "2016-05-11T07:05:48+0000",
            "author": "Mikhail Khludnev",
            "content": "I think that tests' hurdles can be tricked after all. Probably the more itching problem is the prohibition to call EmbeddedSolrServer from Solr threads. It's just not intended to do such recurrent requests.  Let's address it in SOLR-9101  ",
            "id": "comment-15279680"
        },
        {
            "date": "2016-05-13T13:51:30+0000",
            "author": "Steve Rowe",
            "content": "Here's a reproducible failure of TestSubQueryTransformerDistrib on my Jenkins:\n\n\nChecking out Revision 9d5b834b09d4ff23e89755e5d1af407a2bd96c16 (refs/remotes/origin/master)\n[...]\n   [junit4]   2> NOTE: reproduce with: ant test  -Dtestcase=TestSubQueryTransformerDistrib -Dtests.method=test -Dtests.seed=A6B6D43AC01C202D -Dtests.multiplier=2 -Dtests.nightly=true -Dtests.slow=true -Dtests.linedocsfile=/home/jenkins/lucene-data/enwiki.random.lines.txt -Dtests.locale=de-LU -Dtests.timezone=Pacific/Tongatapu -Dtests.asserts=true -Dtests.file.encoding=US-ASCII\n   [junit4] ERROR   55.9s J7 | TestSubQueryTransformerDistrib.test <<<\n   [junit4]    > Throwable #1: org.apache.solr.client.solrj.impl.HttpSolrClient$RemoteSolrException: Error from server at http://127.0.0.1:54181: Cannot create collection departments. Value of maxShardsPerNode is 12, and the number of nodes currently live or live and part of your createNodeSet is 5. This allows a maximum of 60 to be created. Value of numShards is 6 and value of replicationFactor is 12. This requires 72 shards to be created (higher than the allowed number)\n   [junit4]    > \tat __randomizedtesting.SeedInfo.seed([A6B6D43AC01C202D:2EE2EBE06EE04DD5]:0)\n   [junit4]    > \tat org.apache.solr.client.solrj.impl.HttpSolrClient.executeMethod(HttpSolrClient.java:606)\n   [junit4]    > \tat org.apache.solr.client.solrj.impl.HttpSolrClient.request(HttpSolrClient.java:259)\n   [junit4]    > \tat org.apache.solr.client.solrj.impl.HttpSolrClient.request(HttpSolrClient.java:248)\n   [junit4]    > \tat org.apache.solr.client.solrj.SolrClient.request(SolrClient.java:1219)\n   [junit4]    > \tat org.apache.solr.cloud.AbstractFullDistribZkTestBase.createCollection(AbstractFullDistribZkTestBase.java:1592)\n   [junit4]    > \tat org.apache.solr.cloud.AbstractFullDistribZkTestBase.createCollection(AbstractFullDistribZkTestBase.java:1549)\n   [junit4]    > \tat org.apache.solr.cloud.AbstractFullDistribZkTestBase.createCollection(AbstractFullDistribZkTestBase.java:1604)\n   [junit4]    > \tat org.apache.solr.cloud.AbstractFullDistribZkTestBase.createCollection(AbstractFullDistribZkTestBase.java:1545)\n   [junit4]    > \tat org.apache.solr.response.transform.TestSubQueryTransformerDistrib.test(TestSubQueryTransformerDistrib.java:64)\n   [junit4]    > \tat org.apache.solr.BaseDistributedSearchTestCase$ShardsRepeatRule$ShardsFixedStatement.callStatement(BaseDistributedSearchTestCase.java:985)\n   [junit4]    > \tat org.apache.solr.BaseDistributedSearchTestCase$ShardsRepeatRule$ShardsStatement.evaluate(BaseDistributedSearchTestCase.java:960)\n   [junit4]    > \tat java.lang.Thread.run(Thread.java:745)\n   [junit4]   2> 743644 INFO  (SUITE-TestSubQueryTransformerDistrib-seed#[A6B6D43AC01C202D]-worker) [    ] o.a.s.SolrTestCaseJ4 ###deleteCore\n   [junit4]   2> NOTE: leaving temporary files on disk at: /var/lib/jenkins/jobs/Lucene-Solr-Nightly-master/workspace/solr/build/solr-core/test/J7/temp/solr.response.transform.TestSubQueryTransformerDistrib_A6B6D43AC01C202D-001\n   [junit4]   2> May 13, 2016 7:06:27 AM com.carrotsearch.randomizedtesting.ThreadLeakControl checkThreadLeaks\n   [junit4]   2> WARNING: Will linger awaiting termination of 1 leaked thread(s).\n   [junit4]   2> NOTE: test params are: codec=Asserting(Lucene62): {}, docValues:{}, maxPointsInLeafNode=772, maxMBSortInHeap=6.297414713628615, sim=RandomSimilarity(queryNorm=true,coord=no): {}, locale=de-LU, timezone=Pacific/Tongatapu\n   [junit4]   2> NOTE: Linux 4.1.0-custom2-amd64 amd64/Oracle Corporation 1.8.0_77 (64-bit)/cpus=16,threads=1,free=267803120,total=527433728\n   [junit4]   2> NOTE: All tests run in this JVM: [CoreMergeIndexesAdminHandlerTest, TestIBSimilarityFactory, AnalyticsMergeStrategyTest, SolrIndexSplitterTest, SolrPluginUtilsTest, DocumentBuilderTest, TestQueryTypes, BlockJoinFacetDistribTest, TestReplicationHandlerBackup, BadIndexSchemaTest, DistanceUnitsTest, CleanupOldIndexTest, OverseerRolesTest, DocValuesTest, DistributedFacetPivotSmallAdvancedTest, TestReloadAndDeleteDocs, TestSolrJ, TestPHPSerializedResponseWriter, TlogReplayBufferedWhileIndexingTest, TestSha256AuthenticationProvider, TestFaceting, DeleteStatusTest, TestSubQueryTransformerDistrib]\n   [junit4] Completed [218/597 (3!)] on J7 in 56.17s, 1 test, 1 error <<< FAILURES!\n\n\n\nand another one from ASFJenkins a few days back https://builds.apache.org/job/Lucene-Solr-NightlyTests-master/1011/:\n\n\nChecking out Revision 470ba0794ecddd6375db3da521272dde46ed6761 (refs/remotes/origin/master)\n[...]\n   [junit4]   2> NOTE: reproduce with: ant test  -Dtestcase=TestSubQueryTransformerDistrib -Dtests.method=test -Dtests.seed=594D23296C3F97B8 -Dtests.multiplier=2 -Dtests.nightly=true -Dtests.slow=true -Dtests.linedocsfile=/x1/jenkins/lucene-data/enwiki.random.lines.txt -Dtests.locale=es-US -Dtests.timezone=Etc/GMT-1 -Dtests.asserts=true -Dtests.file.encoding=US-ASCII\n   [junit4] ERROR   59.8s J0 | TestSubQueryTransformerDistrib.test <<<\n   [junit4]    > Throwable #1: org.apache.solr.client.solrj.impl.HttpSolrClient$RemoteSolrException: Error from server at http://127.0.0.1:43474/ldvl/gb: Cannot create collection departments. Value of maxShardsPerNode is 10, and the number of nodes currently live or live and part of your createNodeSet is 5. This allows a maximum of 50 to be created. Value of numShards is 6 and value of replicationFactor is 10. This requires 60 shards to be created (higher than the allowed number)\n   [junit4]    > \tat __randomizedtesting.SeedInfo.seed([594D23296C3F97B8:D1191CF3C2C3FA40]:0)\n   [junit4]    > \tat org.apache.solr.client.solrj.impl.HttpSolrClient.executeMethod(HttpSolrClient.java:606)\n   [junit4]    > \tat org.apache.solr.client.solrj.impl.HttpSolrClient.request(HttpSolrClient.java:259)\n   [junit4]    > \tat org.apache.solr.client.solrj.impl.HttpSolrClient.request(HttpSolrClient.java:248)\n   [junit4]    > \tat org.apache.solr.client.solrj.SolrClient.request(SolrClient.java:1219)\n   [junit4]    > \tat org.apache.solr.cloud.AbstractFullDistribZkTestBase.createCollection(AbstractFullDistribZkTestBase.java:1592)\n   [junit4]    > \tat org.apache.solr.cloud.AbstractFullDistribZkTestBase.createCollection(AbstractFullDistribZkTestBase.java:1549)\n   [junit4]    > \tat org.apache.solr.cloud.AbstractFullDistribZkTestBase.createCollection(AbstractFullDistribZkTestBase.java:1604)\n   [junit4]    > \tat org.apache.solr.cloud.AbstractFullDistribZkTestBase.createCollection(AbstractFullDistribZkTestBase.java:1545)\n   [junit4]    > \tat org.apache.solr.response.transform.TestSubQueryTransformerDistrib.test(TestSubQueryTransformerDistrib.java:64)\n   [junit4]    > \tat org.apache.solr.BaseDistributedSearchTestCase$ShardsRepeatRule$ShardsFixedStatement.callStatement(BaseDistributedSearchTestCase.java:985)\n   [junit4]    > \tat org.apache.solr.BaseDistributedSearchTestCase$ShardsRepeatRule$ShardsStatement.evaluate(BaseDistributedSearchTestCase.java:960)\n   [junit4]    > \tat java.lang.Thread.run(Thread.java:745)\n   [junit4]   2> 4199324 INFO  (SUITE-TestSubQueryTransformerDistrib-seed#[594D23296C3F97B8]-worker) [    ] o.a.s.SolrTestCaseJ4 ###deleteCore\n   [junit4]   2> NOTE: leaving temporary files on disk at: /x1/jenkins/jenkins-slave/workspace/Lucene-Solr-NightlyTests-master/solr/build/solr-core/test/J0/temp/solr.response.transform.TestSubQueryTransformerDistrib_594D23296C3F97B8-001\n   [junit4]   2> May 11, 2016 5:31:49 AM com.carrotsearch.randomizedtesting.ThreadLeakControl checkThreadLeaks\n   [junit4]   2> WARNING: Will linger awaiting termination of 1 leaked thread(s).\n   [junit4]   2> NOTE: test params are: codec=Asserting(Lucene60): {}, docValues:{}, maxPointsInLeafNode=2044, maxMBSortInHeap=7.8998054031288465, sim=ClassicSimilarity, locale=es-US, timezone=Etc/GMT-1\n   [junit4]   2> NOTE: Linux 3.13.0-85-generic amd64/Oracle Corporation 1.8.0_74 (64-bit)/cpus=4,threads=1,free=275515608,total=532676608\n   [junit4]   2> NOTE: All tests run in this JVM: [TestExceedMaxTermLength, DistributedSpellCheckComponentTest, TestComponentsName, TestSha256AuthenticationProvider, TestGraphTermsQParserPlugin, AddSchemaFieldsUpdateProcessorFactoryTest, TestFunctionQuery, TestConfigSetImmutable, CursorPagingTest, XsltUpdateRequestHandlerTest, JsonLoaderTest, TestRawResponseWriter, TestPseudoReturnFields, PrimUtilsTest, LeaderElectionIntegrationTest, ParsingFieldUpdateProcessorsTest, TestInitParams, TestIBSimilarityFactory, TestCustomDocTransformer, SegmentsInfoRequestHandlerTest, TestTrackingShardHandlerFactory, PreAnalyzedFieldTest, CloneFieldUpdateProcessorFactoryTest, TestLRUStatsCache, CurrencyFieldOpenExchangeTest, TestLRUCache, TestConfigReload, DistributedQueryComponentOptimizationTest, TestConfigSetsAPIExclusivity, BlockDirectoryTest, JSONWriterTest, TestDistributedSearch, TolerantUpdateProcessorTest, TestLuceneMatchVersion, TestRandomFaceting, HdfsChaosMonkeyNothingIsSafeTest, RequiredFieldsTest, TestLMDirichletSimilarityFactory, TestUseDocValuesAsStored, RulesTest, TestRandomDVFaceting, PeerSyncTest, TestSSLRandomization, TestRangeQuery, TestOrdValues, SmileWriterTest, PathHierarchyTokenizerFactoryTest, LeaderInitiatedRecoveryOnCommitTest, TestSchemaVersionResource, TestCloudBackupRestore, TestCustomSort, SharedFSAutoReplicaFailoverTest, SolrRequestParserTest, SolrCoreTest, AlternateDirectoryTest, StandardRequestHandlerTest, CachingDirectoryFactoryTest, TestShardHandlerFactory, TestPhraseSuggestions, TestReplicationHandler, TestHighlightDedupGrouping, TestSolrQueryParserResource, DistributedQueryElevationComponentTest, CdcrVersionReplicationTest, TestConfig, DistribJoinFromCollectionTest, TestCSVLoader, ConcurrentDeleteAndCreateCollectionTest, SOLR749Test, OverseerTaskQueueTest, OutputWriterTest, TestJoin, AnalyticsQueryTest, ResponseLogComponentTest, TestRTGBase, ForceLeaderTest, TestJsonRequest, TestOverriddenPrefixQueryForCustomFieldType, IndexSchemaTest, DateRangeFieldTest, ActionThrottleTest, TestBinaryField, DeleteStatusTest, BasicZkTest, CdcrReplicationDistributedZkTest, IndexSchemaRuntimeFieldTest, BlockJoinFacetDistribTest, TestBadConfig, PolyFieldTest, TestDynamicFieldCollectionResource, SpatialRPTFieldTypeTest, CollectionTooManyReplicasTest, TestStressLucene, TestDistribDocBasedVersion, TestMergePolicyConfig, CoreMergeIndexesAdminHandlerTest, DistributedFacetPivotLargeTest, SSLMigrationTest, SaslZkACLProviderTest, ShardSplitTest, TestRequestForwarding, TestRequestStatusCollectionAPI, TestTolerantUpdateProcessorCloud, TlogReplayBufferedWhileIndexingTest, HdfsTlogReplayBufferedWhileIndexingTest, TestRestoreCore, DistributedDebugComponentTest, DistributedFacetPivotSmallTest, DistributedSuggestComponentTest, FacetPivotSmallTest, SpatialHeatmapFacetsTest, TestExpandComponent, WrapperMergePolicyFactoryTest, TestIntervalFaceting, TestGraphMLResponseWriter, TestSortingResponseWriter, TestChildDocTransformer, TestSubQueryTransformerDistrib]\n   [junit4] Completed [549/597 (8!)] on J0 in 60.44s, 1 test, 1 error <<< FAILURES!\n\n ",
            "id": "comment-15282702"
        },
        {
            "date": "2016-05-13T15:51:12+0000",
            "author": "Mikhail Khludnev",
            "content": "I.ll fix it in a few hours. Is there a quick hint, how to ? I remember something about setting numShards.. But appreciate a suggestion. ",
            "id": "comment-15282824"
        },
        {
            "date": "2016-05-13T20:13:52+0000",
            "author": "Mikhail Khludnev",
            "content": "seting resonable numbers for createCollection(people, 2, 1, 10);\nSOLR-8208-distrib-test-fix.patch ",
            "id": "comment-15283089"
        },
        {
            "date": "2016-05-13T20:24:09+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 3b0a79a13ee77c867576edcfb82477ee0ea65db6 in lucene-solr's branch refs/heads/master from Mikhail Khludnev\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=3b0a79a ]\n\nSOLR-8208: fixing TestSubQueryTransformerDistrib by passing reasonable numbers in creatCollection() ",
            "id": "comment-15283100"
        },
        {
            "date": "2016-05-13T20:42:19+0000",
            "author": "ASF subversion and git services",
            "content": "Commit e94ffde44e654b9b68a7d3a9d37db3fb0f66ba20 in lucene-solr's branch refs/heads/branch_6x from Mikhail Khludnev\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=e94ffde ]\n\nSOLR-8208: fixing TestSubQueryTransformerDistrib by passing reasonable numbers in creatCollection() ",
            "id": "comment-15283124"
        }
    ]
}