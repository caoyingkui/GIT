{
    "id": "SOLR-4116",
    "title": "Log Replay [recoveryExecutor-8-thread-1] - : java.io.EOFException",
    "details": {
        "affect_versions": "5.1",
        "status": "Closed",
        "fix_versions": [
            "5.5",
            "6.0"
        ],
        "components": [
            "SolrCloud"
        ],
        "type": "Bug",
        "priority": "Major",
        "labels": "",
        "resolution": "Cannot Reproduce"
    },
    "description": "With SOLR-4032 fixed we see other issues when randomly taking down nodes (nicely via tomcat restart) while indexing a few million web pages from Hadoop. We do make sure that at least one node is up for a shard but due to recovery issues it may not be live.\n\n\n2012-11-28 11:32:33,086 WARN [solr.update.UpdateLog] - [recoveryExecutor-8-thread-1] - : Starting log replay tlog{file=/opt/solr/cores/openindex_e/data/tlog/tlog.0000000000000000028 refcount=2} active=false starting pos=0\n2012-11-28 11:32:41,873 ERROR [solr.update.UpdateLog] - [recoveryExecutor-8-thread-1] - : java.io.EOFException\n        at org.apache.solr.common.util.FastInputStream.readFully(FastInputStream.java:151)\n        at org.apache.solr.common.util.JavaBinCodec.readStr(JavaBinCodec.java:479)\n        at org.apache.solr.common.util.JavaBinCodec.readVal(JavaBinCodec.java:176)\n        at org.apache.solr.common.util.JavaBinCodec.readSolrInputDocument(JavaBinCodec.java:374)\n        at org.apache.solr.common.util.JavaBinCodec.readVal(JavaBinCodec.java:225)\n        at org.apache.solr.common.util.JavaBinCodec.readArray(JavaBinCodec.java:451)\n        at org.apache.solr.common.util.JavaBinCodec.readVal(JavaBinCodec.java:182)\n        at org.apache.solr.update.TransactionLog$LogReader.next(TransactionLog.java:618)\n        at org.apache.solr.update.UpdateLog$LogReplayer.doReplay(UpdateLog.java:1198)\n        at org.apache.solr.update.UpdateLog$LogReplayer.run(UpdateLog.java:1143)\n        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)\n        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)\n        at java.util.concurrent.FutureTask.run(FutureTask.java:138)\n        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)\n        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)\n        at java.util.concurrent.FutureTask.run(FutureTask.java:138)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)\n        at java.lang.Thread.run(Thread.java:662)",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "author": "Yonik Seeley",
            "id": "comment-13505458",
            "date": "2012-11-28T14:06:55+0000",
            "content": "I don't know what \"tomcat restart\" does, but perhaps it's not as nice as you think if it causes a log replay on restart?  Anyway, bringing down a server roughly enough (like kill -9) can cause truncated tlog files.\nBut truncated log files are expected and should not cause fatal exceptions (and we have tests for that).  This exception causes the core not to come up? "
        },
        {
            "author": "Markus Jelsma",
            "id": "comment-13505466",
            "date": "2012-11-28T14:16:53+0000",
            "content": "Restarting or stopping Tomcat shuts down CoreContainer and stops recovery, i believe this is nice enough or isn't it? This error does not cause the core not to come up.\n\n\n2012-11-28 14:10:15,227 INFO [solr.core.CoreContainer] - [Thread-6] - : Shutting down CoreContainer instance=1830423861\n2012-11-28 14:10:15,227 WARN [solr.cloud.RecoveryStrategy] - [Thread-6] - : Stopping recovery for zkNodeName=178.21.118.195:8080_solr_shard_fcore=shard_f\n2012-11-28 14:10:15,227 WARN [solr.cloud.RecoveryStrategy] - [Thread-6] - : Stopping recovery for zkNodeName=178.21.118.195:8080_solr_shard_gcore=shard_g\n2012-11-28 14:10:15,227 INFO [solr.core.SolrCore] - [Thread-6] - : [shard_f]  CLOSING SolrCore org.apache.solr.core.SolrCore@513c952f\n2012-11-28 14:10:15,230 INFO [solr.update.UpdateHandler] - [Thread-6] - : closing DirectUpdateHandler2{commits=1,autocommit maxTime=120000ms,autocommits=0,soft autocommit maxTime=10000ms,soft autocommits=0,optimizes=0,rollbacks=0,expungeDeletes=0,docsPending=0,adds=0,deletesById=0,deletesByQuery=0,errors=0,cumulative_adds=0,cumulative_deletesById=0,cumulative_deletesByQuery=0,cumulative_errors=0}\n2012-11-28 14:10:15,231 INFO [solr.core.SolrCore] - [Thread-6] - : Closing SolrCoreState\n2012-11-28 14:10:15,231 INFO [solr.update.DefaultSolrCoreState] - [Thread-6] - : SolrCoreState ref count has reached 0 - closing IndexWriter\n2012-11-28 14:10:15,231 INFO [solr.update.DefaultSolrCoreState] - [Thread-6] - : closing IndexWriter with IndexWriterCloser\n2012-11-28 14:10:15,234 INFO [solr.core.CachingDirectoryFactory] - [Thread-6] - : Releasing directory:/opt/solr/cores/shard_f/data/index.20121128113300496\n2012-11-28 14:10:15,235 INFO [solr.core.SolrCore] - [Thread-6] - : [shard_f] Closing main searcher on request.\n2012-11-28 14:10:15,244 INFO [solr.core.CachingDirectoryFactory] - [Thread-6] - : Releasing directory:/opt/solr/cores/shard_f/data/index.20121128113300496\n2012-11-28 14:10:15,244 INFO [solr.core.SolrCore] - [Thread-6] - : [shard_g]  CLOSING SolrCore org.apache.solr.core.SolrCore@24be0446\n2012-11-28 14:10:15,248 INFO [solr.update.UpdateHandler] - [Thread-6] - : closing DirectUpdateHandler2{commits=1,autocommit maxTime=120000ms,autocommits=0,soft autocommit maxTime=10000ms,soft autocommits=0,optimizes=0,rollbacks=0,expungeDeletes=0,docsPending=0,adds=0,deletesById=0,deletesByQuery=0,errors=0,cumulative_adds=0,cumulative_deletesById=0,cumulative_deletesByQuery=0,cumulative_errors=0}\n2012-11-28 14:10:15,248 INFO [solr.core.SolrCore] - [Thread-6] - : Closing SolrCoreState\n2012-11-28 14:10:15,248 INFO [solr.update.DefaultSolrCoreState] - [Thread-6] - : SolrCoreState ref count has reached 0 - closing IndexWriter\n2012-11-28 14:10:15,248 INFO [solr.update.DefaultSolrCoreState] - [Thread-6] - : closing IndexWriter with IndexWriterCloser\n2012-11-28 14:10:15,250 INFO [solr.core.CachingDirectoryFactory] - [Thread-6] - : Releasing directory:/opt/solr/cores/shard_g/data/index.20121128113035951\n2012-11-28 14:10:15,250 INFO [solr.core.SolrCore] - [Thread-6] - : [shard_g] Closing main searcher on request.\n2012-11-28 14:10:15,256 INFO [solr.core.CachingDirectoryFactory] - [Thread-6] - : Releasing directory:/opt/solr/cores/shard_g/data/index.20121128113035951\n2012-11-28 14:10:15,281 INFO [apache.zookeeper.ZooKeeper] - [Thread-6] - : Session: 0x13b4668803e000f closed\n\n "
        },
        {
            "author": "Markus Jelsma",
            "id": "comment-14580309",
            "date": "2015-06-10T09:42:32+0000",
            "content": "Awesome, i got a strange exception, searched the web for it and ended up here, again! This time it is Solr 5.1, i completely removed the data directory, restarted and indexed 18 million records. Then restarted Solr again, and got this slightly different stack trace:\n\n\n10400 [recoveryExecutor-19-thread-1] ERROR org.apache.solr.update.UpdateLog  [   ] \u2013 java.io.EOFException\n        at org.apache.solr.common.util.FastInputStream.readUnsignedByte(FastInputStream.java:73)\n        at org.apache.solr.common.util.FastInputStream.readLong(FastInputStream.java:240)\n        at org.apache.solr.common.util.JavaBinCodec.readVal(JavaBinCodec.java:211)\n        at org.apache.solr.common.util.JavaBinCodec.readArray(JavaBinCodec.java:492)\n        at org.apache.solr.common.util.JavaBinCodec.readVal(JavaBinCodec.java:186)\n        at org.apache.solr.update.TransactionLog$LogReader.next(TransactionLog.java:642)\n        at org.apache.solr.update.UpdateLog$LogReplayer.doReplay(UpdateLog.java:1305)\n        at org.apache.solr.update.UpdateLog$LogReplayer.run(UpdateLog.java:1233)\n        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n        at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n        at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n        at java.lang.Thread.run(Thread.java:745)\n\n\n\nThere is no further real malfunction so this error could be ignored, but shouldnt occur anyway. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-14580535",
            "date": "2015-06-10T13:48:18+0000",
            "content": "Perhaps related to https://issues.apache.org/jira/browse/SOLR-7478\n\nSeems like the tlog was likely not closed properly if reading it shows corruption. "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-14713363",
            "date": "2015-08-26T13:14:21+0000",
            "content": "Bulk move to 5.4 after 5.3 release. "
        },
        {
            "author": "Mike Drob",
            "id": "comment-15036160",
            "date": "2015-12-02T17:14:21+0000",
            "content": "I saw similar stack traces recently with the same EOFException when running on HDFS. Looking at the javadoc on LogReader.next it suggests that we should return null in case of EOF, or is that only when we hit a \"nice\" EOF at a record boundary?\n\nAlternatively, if we're going to continue throwing the EOF to signal that a file is probably corrupt (or at least truncated), we should include the file name in the message. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-15037884",
            "date": "2015-12-03T15:03:02+0000",
            "content": "Looks like with tomcat you have to crank the unloadDelay for the webapp context to be sure there is enough time for the final commit and the shutdown stuff that could take a while. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-15037938",
            "date": "2015-12-03T15:32:39+0000",
            "content": "Hmm...that for how long a request can finish, but this stuff should be how long it allows for filter#destroy I think. Jetty has a setting for this if I recall correctly, but not finding tomcats version. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-15037989",
            "date": "2015-12-03T16:01:36+0000",
            "content": "May be related, adding link just in case. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-15038117",
            "date": "2015-12-03T17:08:48+0000",
            "content": "Markus Jelsma, if you see this again, could you dump the shutdown logs?  "
        },
        {
            "author": "Markus Jelsma",
            "id": "comment-15038141",
            "date": "2015-12-03T17:20:54+0000",
            "content": "Yes of course! Btw, the last time i saw the error, we were already using Jetty (Solr 5.1). "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-15943835",
            "date": "2017-03-27T18:56:25+0000",
            "content": "If this hasn't come back around for over a year, I think we can close it as \"cannot reproduce?\" "
        },
        {
            "author": "Markus Jelsma",
            "id": "comment-15944820",
            "date": "2017-03-28T09:05:35+0000",
            "content": "No, it is not a problem anymore. Closing "
        }
    ]
}