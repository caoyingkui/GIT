{
    "id": "LUCENE-4795",
    "title": "Add FacetsCollector based on SortedSetDocValues",
    "details": {
        "components": [
            "modules/facet"
        ],
        "fix_versions": [
            "4.3",
            "6.0"
        ],
        "affect_versions": "None",
        "priority": "Major",
        "labels": "",
        "type": "Improvement",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "Recently (LUCENE-4765) we added multi-valued DocValues field\n(SortedSetDocValuesField), and this can be used for faceting in Solr\n(SOLR-4490).  I think we should also add support in the facet module?\n\nIt'd be an option with different tradeoffs.  Eg, it wouldn't require\nthe taxonomy index, since the main index handles label/ord resolving.\n\nThere are at least two possible approaches:\n\n\n\tOn every reopen, build the seg -> global ord map, and then on\n    every collect, get the seg ord, map it to the global ord space,\n    and increment counts.  This adds cost during reopen in proportion\n    to number of unique terms ...\n\n\n\n\n\tOn every collect, increment counts based on the seg ords, and then\n    do a \"merge\" in the end just like distributed faceting does.\n\n\n\nThe first approach is much easier so I built a quick prototype using\nthat.  The prototype does the counting, but it does NOT do the top K\nfacets gathering in the end, and it doesn't \"know\" parent/child ord\nrelationships, so there's tons more to do before this is real.  I also\nwas unsure how to properly integrate it since the existing classes\nseem to expect that you use a taxonomy index to resolve ords.\n\nI ran a quick performance test.  base = trunk except I disabled the\n\"compute top-K\" in FacetsAccumulator to make the comparison fair; comp\n= using the prototype collector in the patch:\n\n\n                    Task    QPS base      StdDev    QPS comp      StdDev                Pct diff\n               OrHighLow       18.79      (2.5%)       14.36      (3.3%)  -23.6% ( -28% -  -18%)\n                HighTerm       21.58      (2.4%)       16.53      (3.7%)  -23.4% ( -28% -  -17%)\n               OrHighMed       18.20      (2.5%)       13.99      (3.3%)  -23.2% ( -28% -  -17%)\n                 Prefix3       14.37      (1.5%)       11.62      (3.5%)  -19.1% ( -23% -  -14%)\n                 LowTerm      130.80      (1.6%)      106.95      (2.4%)  -18.2% ( -21% -  -14%)\n              OrHighHigh        9.60      (2.6%)        7.88      (3.5%)  -17.9% ( -23% -  -12%)\n             AndHighHigh       24.61      (0.7%)       20.74      (1.9%)  -15.7% ( -18% -  -13%)\n                  Fuzzy1       49.40      (2.5%)       43.48      (1.9%)  -12.0% ( -15% -   -7%)\n         MedSloppyPhrase       27.06      (1.6%)       23.95      (2.3%)  -11.5% ( -15% -   -7%)\n                 MedTerm       51.43      (2.0%)       46.21      (2.7%)  -10.2% ( -14% -   -5%)\n                  IntNRQ        4.02      (1.6%)        3.63      (4.0%)   -9.7% ( -15% -   -4%)\n                Wildcard       29.14      (1.5%)       26.46      (2.5%)   -9.2% ( -13% -   -5%)\n        HighSloppyPhrase        0.92      (4.5%)        0.87      (5.8%)   -5.4% ( -15% -    5%)\n             MedSpanNear       29.51      (2.5%)       27.94      (2.2%)   -5.3% (  -9% -    0%)\n            HighSpanNear        3.55      (2.4%)        3.38      (2.0%)   -4.9% (  -9% -    0%)\n              AndHighMed      108.34      (0.9%)      104.55      (1.1%)   -3.5% (  -5% -   -1%)\n         LowSloppyPhrase       20.50      (2.0%)       20.09      (4.2%)   -2.0% (  -8% -    4%)\n               LowPhrase       21.60      (6.0%)       21.26      (5.1%)   -1.6% ( -11% -   10%)\n                  Fuzzy2       53.16      (3.9%)       52.40      (2.7%)   -1.4% (  -7% -    5%)\n             LowSpanNear        8.42      (3.2%)        8.45      (3.0%)    0.3% (  -5% -    6%)\n                 Respell       45.17      (4.3%)       45.38      (4.4%)    0.5% (  -7% -    9%)\n               MedPhrase      113.93      (5.8%)      115.02      (4.9%)    1.0% (  -9% -   12%)\n              AndHighLow      596.42      (2.5%)      617.12      (2.8%)    3.5% (  -1% -    8%)\n              HighPhrase       17.30     (10.5%)       18.36      (9.1%)    6.2% ( -12% -   28%)\n\n\n\nI'm impressed that this approach is only ~24% slower in the worst\ncase!  I think this means it's a good option to make available?  Yes\nit has downsides (NRT reopen more costly, small added RAM usage,\nslightly slower faceting), but it's also simpler (no taxo index to\nmanage).",
    "attachments": {
        "LUCENE-4795.patch": "https://issues.apache.org/jira/secure/attachment/12570788/LUCENE-4795.patch",
        "pleaseBenchmarkMe.patch": "https://issues.apache.org/jira/secure/attachment/12570790/pleaseBenchmarkMe.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2013-02-25T14:07:30+0000",
            "content": "Thanks for benchmarking this approach Mike! \n\nI'm happy with the results, though i still added a TODO that we should investigate the cost of the special packed-ints compression we do.\n\ncan you benchmark the attached change just out of curiousity? ",
            "author": "Robert Muir",
            "id": "comment-13585867"
        },
        {
            "date": "2013-02-25T14:19:37+0000",
            "content": "Not having to manage a taxonomy index is very appealing to me!\n\nWhat about collecting based on segment ords and bulk translating these ords to the global ords in setNextReader and when the collection ends? This way ordinalMap.get would be called less often (once per value per segment instead of once per value per doc per segment) and in a sequential way so I assume it would be faster while remaining easy to implement? ",
            "author": "Adrien Grand",
            "id": "comment-13585878"
        },
        {
            "date": "2013-02-25T14:26:48+0000",
            "content": "What about collecting based on segment ords and bulk translating these ords to the global ords in setNextReader and when the collection ends? \n\nThat sounds great!  I'll try that.\n ",
            "author": "Michael McCandless",
            "id": "comment-13585882"
        },
        {
            "date": "2013-02-25T14:45:41+0000",
            "content": "Nice Mike.\n\nIf you want to integrate that with the current classes, all you need to do is to implement a partial TaxonomyReader, which resolves ordinals to CPs using the global ord map? Or actually make that TR the entity that's responsible to manage to global ordinal map, so that TR.doOpenIfChanged opens the new segments and updates the global map?\n\nSince this taxonomy, at least currently, doesn't support hierarchical facets, you'll need to hack something as a ParallelTaxoArray, but that should be easy .. I think.\n\nIs the only benefit in this approach that you don't need to manage a sidecar taxonomy index? ",
            "author": "Shai Erera",
            "id": "comment-13585892"
        },
        {
            "date": "2013-02-25T14:53:08+0000",
            "content": "Fixed small bug (wasn't counting ord 0); here's the same test as\nbefore, just running on Term & Or queries:\n\n\n                    Task    QPS base      StdDev    QPS comp      StdDev                Pct diff\n                 MedTerm       52.70      (3.1%)       40.87      (2.0%)  -22.5% ( -26% -  -17%)\n               OrHighMed       25.54      (3.6%)       20.18      (2.4%)  -21.0% ( -26% -  -15%)\n                HighTerm        9.22      (4.1%)        7.33      (2.4%)  -20.4% ( -25% -  -14%)\n              OrHighHigh       12.92      (3.6%)       10.41      (2.8%)  -19.4% ( -24% -  -13%)\n               OrHighLow       13.12      (3.8%)       10.61      (2.8%)  -19.2% ( -24% -  -13%)\n                 LowTerm      145.94      (1.9%)      125.51      (1.6%)  -14.0% ( -17% -  -10%)\n\n\n\nThen I applied Rob's patch (base = trunk, comp = Rob's + my patch):\n\n\n                    Task    QPS base      StdDev    QPS comp      StdDev                Pct diff\n                 MedTerm       52.97      (2.2%)       42.34      (1.6%)  -20.1% ( -23% -  -16%)\n               OrHighMed       25.66      (2.2%)       20.73      (1.7%)  -19.2% ( -22% -  -15%)\n              OrHighHigh       12.99      (2.4%)       10.69      (1.8%)  -17.7% ( -21% -  -13%)\n               OrHighLow       13.19      (2.3%)       10.94      (2.0%)  -17.0% ( -20% -  -12%)\n                HighTerm        9.30      (2.6%)        7.76      (1.8%)  -16.6% ( -20% -  -12%)\n                 LowTerm      146.48      (1.3%)      129.04      (0.9%)  -11.9% ( -13% -   -9%)\n\n\n\nSo a wee bit faster but not much... (good!  The awesome predictive\ncompression from MonotonicALB doesn't hurt much).\n\nThen I made a new collector that resolves ords after each segment from\nAdrien's idea (SortedSetDocValuesCollectorMergeBySeg) \u2013 base = same\nas above, comp = new collector w/o Rob's patch:\n\n\n                    Task    QPS base      StdDev    QPS comp      StdDev                Pct diff\n                HighTerm        9.29      (3.1%)        7.14      (1.9%)  -23.2% ( -27% -  -18%)\n               OrHighMed       25.51      (2.7%)       19.60      (2.2%)  -23.2% ( -27% -  -18%)\n               OrHighLow       13.08      (2.8%)       10.20      (2.3%)  -22.0% ( -26% -  -17%)\n              OrHighHigh       12.89      (2.9%)       10.21      (2.6%)  -20.8% ( -25% -  -15%)\n                 MedTerm       53.00      (2.7%)       43.34      (1.5%)  -18.2% ( -21% -  -14%)\n                 LowTerm      145.97      (1.6%)      133.05      (0.9%)   -8.9% ( -11% -   -6%)\n\n\n\nStrangely it's not really faster ... maybe I have a bug.\nUnfortunately, until we get the top K working, we can't do the\nend-to-end comparison to make sure we're getting the right facet\nvalues ... ",
            "author": "Michael McCandless",
            "id": "comment-13585899"
        },
        {
            "date": "2013-02-25T14:55:33+0000",
            "content": "Thanks for benchmarking: I think we should keep the monotonic compression! \nIt will use significantly less RAM for this thing. ",
            "author": "Robert Muir",
            "id": "comment-13585901"
        },
        {
            "date": "2013-02-25T15:00:56+0000",
            "content": "If you want to integrate that with the current classes, all you need to do is to implement a partial TaxonomyReader, which resolves ordinals to CPs using the global ord map? Or actually make that TR the entity that's responsible to manage to global ordinal map, so that TR.doOpenIfChanged opens the new segments and updates the global map?\n\nThat sounds great!\n\nSince this taxonomy, at least currently, doesn't support hierarchical facets, you'll need to hack something as a ParallelTaxoArray, but that should be easy .. I think.\n\nOK.\n\nI think it could be hierarchical w/o so much work, ie on reopen as it\nwalks the terms it should be able to easily build up the parent/child\narrays since the terms are in sorted order.  Hmm, except, with SSDV\nyou cannot have a term/ord that had no docs indexed.  So the\n\"ancestor\" ords would not exist... hmm.  Better start\nnon-hierarchical.\n\nI guess if we are non-hierarchical then we don't really need to\nintegrate at indexing time?  Ie, app can just add the facet values\nusing SortedSetDVF.\n\nIs the only benefit in this approach that you don't need to manage a sidecar taxonomy index?\n\nI think so? ",
            "author": "Michael McCandless",
            "id": "comment-13585903"
        },
        {
            "date": "2013-03-02T14:37:24+0000",
            "content": "New patch ... I think it's close but there are still some nocommits.\n\n I switched to a FacetsAccumulator (SortedSetDVAccumulator) instead of\nXXXCollector because:\n\n\n\tIt's more fair since it now does all counting \"in the end\",\n    matching trunk, which was a bit faster than count-as-you-go when\n    we last tested.\n\n\n\n\n\tIt means you can use this class with DrillSideways ... I fixed\n    TestDrillSideways to test it (passes!).\n\n\n\nI also got a custom topK impl working.\n\nThe facets are the same as trunk, except for tie-break differences.\nThe new collector is better in this regard: it breaks ties in an\nunderstandable-to-the-end-user way (by ord = Unicode sort order),\nunlike the taxo index which is \"order in which label was indexed into\ntaxo index\" (confusing to end user).\n\nI first went down the road of making a TaxoReader that wraps a\nSlowCompositeReaderWrapper ... but this became problematic because a\nDV instance is not thread-safe, yet TaxoReader's APIs are supposed to\nbe thread-safe.  I also really didn't like making 3 int[maxOrd] to\nhandle \"hierarchy\" when SorteSetDV facets only support 2 level\nhierarchy (dim + child).\n\nSo I backed off of that and made a separate State object, which you\nmust re-init after ever top-reader-reopen, and it does the heavyish\nstuff.\n\nCurrent results (base = trunk w/ allbutdim, comp = patch, full wikibig\nindex with 5 flat dims):\n\n\n                    Task    QPS base      StdDev    QPS comp      StdDev                Pct diff\n                HighTerm        9.36      (1.9%)        7.02      (3.6%)  -25.0% ( -29% -  -19%)\n                 MedTerm       53.21      (1.5%)       40.65      (2.8%)  -23.6% ( -27% -  -19%)\n               OrHighLow       13.25      (2.1%)       10.55      (3.4%)  -20.4% ( -25% -  -15%)\n               OrHighMed       25.77      (1.9%)       20.90      (3.1%)  -18.9% ( -23% -  -14%)\n              OrHighHigh       13.03      (2.2%)       10.63      (3.2%)  -18.4% ( -23% -  -13%)\n                 LowTerm      146.28      (1.7%)      120.22      (1.7%)  -17.8% ( -20% -  -14%)\n\n ",
            "author": "Michael McCandless",
            "id": "comment-13591422"
        },
        {
            "date": "2013-03-11T18:39:06+0000",
            "content": "New patch, just cleaning everything up ... I think it's ready.\n\nI know this approach isn't perfect (it has its own topK code), but I\nthink it's a good enough start that we should get it in and make it\navailable.  We can iterate over time ... ",
            "author": "Michael McCandless",
            "id": "comment-13599114"
        },
        {
            "date": "2013-03-11T19:10:44+0000",
            "content": "I'm not sure i understand the dim/value stuff going on inside the single dv field.\n\nwouldnt it be more natural to just use multiple lucene fields? ",
            "author": "Robert Muir",
            "id": "comment-13599150"
        },
        {
            "date": "2013-03-11T21:27:38+0000",
            "content": "wouldnt it be more natural to just use multiple lucene fields?\n\nYeah ... maybe.  I agree this is a weird thing about the facet module,\ni.e. that we don't have a FacetField, and you add one per \"dimension\",\nlike new FacetField(\"category\", ...), new FacetField(\"price\", ...).\n\nInstead you have any number of CategoryPaths, like\n/price/1-100/20-30/25.99 and /category/Fiction/..., and those are all\nindexed into a single $facet binary DV field (by default), using a\nsingle call to FacetFields.addFields.\n\nWe could maybe generalize this new FacetsAccumulator to allow for\n\"single DV field has single facet dim\" approach ... but it's a break\nfrom how the rest of facets work, and I also suspect there's a\nnon-trivial performance hit to it (haven't yet tested).\n\nI think we should explore that later?  The current patch at least\nmakes faceting in the \"facet module\" approach possible...\n ",
            "author": "Michael McCandless",
            "id": "comment-13599334"
        },
        {
            "date": "2013-03-12T02:33:29+0000",
            "content": "I agree: and actually rethinking it, I think its healthier to keep as much of the facet modules existing approach (minus the sidecar for this case).\n\nWe can always add other approaches that work on each field like solr/elasticsearch. I'd rather have more choices out there. ",
            "author": "Robert Muir",
            "id": "comment-13599623"
        },
        {
            "date": "2013-03-12T04:23:28+0000",
            "content": "I also suspect there's a non-trivial performance hit to it (haven't yet tested)\n\nMike, we did experiment with that during the overall refactoring/optimization work. I was able to dig up the results \u2013 we tried to simulate \"column-stride ordinals\" by indexing different dimensions into different DV fields, using different taxoWriters. I created a SingleValuedFacetField (over the old DV, using VAR_INTS) and indexed the ordinal of the CP there. So I think kind of simulates SortedSet when there's only one value?\n\nThe results were not good:\n\n\n                   Per Dim    Trunk   Diff (%)\nAndHighHigh         64.35     89.41    38.94%\nAndHighLow         358.7    1033.32   188.07%\nAndHighMed         181.22    318.36    75.68%\nFuzzy1              78.49    116.99    49.05%\nFuzzy2              72.79    104.12    43.04%\nHighPhrase          36.83     43.67    18.57%\nHighSloppyPhrase     3.12      3.25     4.17%\nHighSpanNear        10.76     11.74     9.11%\nHighTerm            40.23     65.07    61.74%\nIntNRQ             109.46    114.52     4.62%\nLowPhrase           60.63     72.59    19.73%\nLowSloppyPhrase     66.01     82.9     25.59%\nLowSpanNear         38.5      43.81    13.79%\nLowTerm            187.58     378.86  101.97%\nMedPhrase          103.57     153.26   47.98%\nMedSloppyPhrase     70.86     89.78    26.70%\nMedSpanNear         69.29     89.2     28.73%\nMedTerm            120.72    237.39    96.65%\nOrHighHigh          26.41     38.55    45.97%\nOrHighLow           36.6      55.38    51.31%\nOrHighMed           37.62     56.81    51.01%\nPKLookup           250.59    301.5     20.32%\nPrefix3            170.76    176.48     3.35%\nRespell            101.4     136.58    34.69%\nWildcard           225.08    252.69    12.27%\n\n\n\nTrunk was trunk at the time, and per-dim is the new FacetField. We suspected that that's because when you index different dimensions into different DV fields, you need to go over the result docs X times (where X is the number of dimensions you asked to count; we tested 9).\n\nI think its healthier to keep as much of the facet modules existing approach\n\nDo you have an idea how can one use the new field to index weighted facets? I.e. category/Computers=0.9 and category/Sceience=0.84? If the only way is to use BinaryDV, is there a way we can use the ordinals from SortedSet to put in a BDV 1=0.9, 2=0.84? Hmm, but since those ords are per-segment, we'd need to rewrite the BDV upon merge right?\n\nI ask because it seems that the only thing that we get from this SortedSet approach is not having to maintain a sidecar index (which for some reason freaks everybody), and we even lose performance. Plus, I don't see how we can support other facet features with it. So perhaps we should focus on how to use the search index to build a taxonomy? Maybe it's all in-memory, that's fine. If we manage to support on-disk lookups too, even better. But if we do that, then we should have no problems supporting all current facet features, because all that the taxonomy index gives us is a global-ordinal (plus hierarchy management, but I think we can do that w/ SortedSet too). We can of course explore that in a different issue. ",
            "author": "Shai Erera",
            "id": "comment-13599687"
        },
        {
            "date": "2013-03-12T04:29:01+0000",
            "content": "About the patch: Mike, why do you need to initialize a FacetRequest like so: requests.add(new CountFacetRequest(new CategoryPath(\"a\", sep), 10));? Why do you need to do \"a/\" and not just \"a\"? It's not like how requests are initialized today right? ",
            "author": "Shai Erera",
            "id": "comment-13599691"
        },
        {
            "date": "2013-03-12T04:42:06+0000",
            "content": "\nI ask because it seems that the only thing that we get from this SortedSet approach is not having to maintain a sidecar index (which for some reason freaks everybody), and we even lose performance. Plus, I don't see how we can support other facet features with it. So perhaps we should focus on how to use the search index to build a taxonomy? Maybe it's all in-memory, that's fine. If we manage to support on-disk lookups too, even better. But if we do that, then we should have no problems supporting all current facet features, because all that the taxonomy index gives us is a global-ordinal (plus hierarchy management, but I think we can do that w/ SortedSet too). We can of course explore that in a different issue.\n\nWell the taxonomy index doesn't give you global ordinals. it gives you global \"termIDs\", which are unique integers: but they aren't ordinals: their sort order is meaningless. this creates additional trouble if you want to try to integrate the current lucene facet module with e.g. solr that has faceting options that rely upon these properties.\n\nIts also unclear to me how the taxonomy index would really integrate in a distributed system like solr or elasticsearch. I know there has been discussion about it before, and I'm sure there are solutions, but it just seems fairly complicated. \n\non the other hand SortedSet doesn't have these problems. maybe it doesnt support weighted facets or other features, but its a nice option. I personally don't think its the end of the world if Mike's patch doesnt support all the features of the faceting module initially or even ever.\n\nThe idea is just to have more choices. I'm not saying you should get rid of the taxonomy index: just provide options. I don't think lucene's faceting support needs to be limited to only a single one-size-fits-all solution but instead have a few options with different tradeoffs. Compare with something like the suggest module, it has like 5 or 6 implementations. ",
            "author": "Robert Muir",
            "id": "comment-13599699"
        },
        {
            "date": "2013-03-12T06:53:13+0000",
            "content": "Well the taxonomy index doesn't give you global ordinals. it gives you global \"termIDs\", which are unique integers: but they aren't ordinals\n\nThat's right. I am not familiar with how Solr utilizes that, but I agree with your statement. The term ordinal was derived from the fact that the taxonomy does preserve order between parent/children. I.e. Date < Date/2010 <> Date/2011. So Date will always have a lower ordinal than its children, but there is not meaningful order between siblings.\n\nIts also unclear to me how the taxonomy index would really integrate in a distributed system like solr or elasticsearch.\n\nWhy? We work with the taxonomy index in two modes in a distributed environment:\n\n\n\tEvery shard maintains its own taxonomy index and facets are merged by their label. That's basically what Solr/ES/SortedSet would do right?\n\tIn a specific project we run, where every document goes through a MapReduce analysis (no NRT!), we maintain a truly global taxonomy index, where ordinal=17 means the same category in all shards. The taxonomy index itself is replicated to all shards. There are tradeoffs of course, but you cannot do that with SortedSet right? The advantage is that you can do the merge by the ordinal (integer ID), rather than the label.\n\n\n\nI personally don't think its the end of the world if Mike's patch doesnt support all the features of the faceting module initially or even ever.\n\n+1, I don't criticize that approach negatively. I personally don't understand why the sidecar taxonomy index freaks the hell out of people, but I don't mind if there are multiple facet implementations. I can share with you that we used to have few implementations too, before we converged to one (and then contributed to Lucene).\n\nYou didn't answer my question though, and perhaps it doesn't belong in this issue, but is there a way to utilize the ordinal given to a DV value somehow? Or is it internal to the SortedSet DV?\n\nMike, should you also check in SortedSetDocValuesAccumulator that FR.getDepth() == 1? I don't think that you support counting up to depth N, right? ",
            "author": "Shai Erera",
            "id": "comment-13599779"
        },
        {
            "date": "2013-03-12T11:48:32+0000",
            "content": "Mike, why do you need to initialize a FacetRequest like so: requests.add(new CountFacetRequest(new CategoryPath(\"a\", sep), 10));?\n\nWoops, that's just silly: I'll remove the sep there.\n\nMike, should you also check in SortedSetDocValuesAccumulator that FR.getDepth() == 1? I don't think that you support counting up to depth N, right?\n\nRight, it only supports flat (dim / label) today ... ok, I'll add that\ncheck. ",
            "author": "Michael McCandless",
            "id": "comment-13599945"
        },
        {
            "date": "2013-03-12T12:42:52+0000",
            "content": "Thanks. Also (sorry that it comes in parts), I find this confusing: new SortedSetDocValuesField(\"myfacets\", new BytesRef(\"a\" + sep + \"foo\")). The user needs to decide under which field all facets will be indexed. This could lead users to do new SSDVF(\"author\", new BytesRef(\"shai\")) and new SSDVF(\"date\", new BytesRef(\"2010/March/13\")). We know, from past results, that this will result in worse search performance. Also, this doesn't take a CP which is not consistent e.g. with the FacetRequest, where you need to pass a CP. So rather perhaps we should:\n\n\n\tAdd a FacetField (extends SSDVF) which takes a CP (potentially FacetIndexingParams as well).\n\tIt will call super(CLP.DEFAULT_FIELD, new BytesRef(cp.toString())) (we can optimize that later, e.g. have CP expose a BytesRef API too if we want).\n\tPotentially, allow (or not) to define the field type.\n\n\n\nWhat do you think? ",
            "author": "Shai Erera",
            "id": "comment-13599990"
        },
        {
            "date": "2013-03-12T13:09:51+0000",
            "content": "Another thing, in the accumulator you do q.insertWithOverflow(new FacetResultNode(ord, counts[ord])). Any reason why you don't get a hold of the returned FRN? Or pre-fill the queue with sentinel objects?\n\nIn ReaderState you can call SlowComposite.wrap instead of checking if (reader instanceof AtomicReader) which is essentially the same thing, just less lines of code. ",
            "author": "Shai Erera",
            "id": "comment-13600017"
        },
        {
            "date": "2013-03-12T13:22:42+0000",
            "content": "\nYou didn't answer my question though, and perhaps it doesn't belong in this issue, but is there a way to utilize the ordinal given to a DV value somehow? Or is it internal to the SortedSet DV?\n\nBecause I don't want to encourage crazy software designs to support fringe features. Want weighted faceting? use the tax index: pretty simple. \n ",
            "author": "Robert Muir",
            "id": "comment-13600026"
        },
        {
            "date": "2013-03-12T19:10:36+0000",
            "content": "\nSo rather perhaps we should:\n\n\tAdd a FacetField (extends SSDVF) which takes a CP (potentially FacetIndexingParams as well).\n\tIt will call super(CLP.DEFAULT_FIELD, new BytesRef(cp.toString())) (we can optimize that later, e.g. have CP expose a BytesRef API too if we want).\n\tPotentially, allow (or not) to define the field type.\n\n\n\nI agree it's awkward now.\n\nBut ... FacetField makes me nervous, just because it's too close to\nFacetFields and users may think they can mix & match the two\napproaches.  It's trappy ... maybe SortedSetDocValuesFacetField\ninstead?\n\nBut you'd need to provide it with this separator... hmm, or maybe we\ncan use the same sep as FIP.\n\nSeparately, I wonder whether facet module should escape the delimiter\nwhen it appears in a cat path label, in general (and, here)?  This way\nthe app does not have to ensure it never appears in any label (which I\nthink is tricky for some apps to do, eg a search server like\nElasticSearch/Solr can't do this).\n\nAny reason why you don't get a hold of the returned FRN? \n\nI wanted to keep it simple for starters ... but I'll fix to reuse the\nrejected entry. ",
            "author": "Michael McCandless",
            "id": "comment-13600355"
        },
        {
            "date": "2013-03-13T04:28:59+0000",
            "content": "maybe SortedSetDocValuesFacetField instead?\n\n+1.\n\nThere's also another thing that bothers me \u2013 nothing prevents the app from creating a SSDVField with hierarchical facets now. So while your tests don't do it, I could easily create such a category (Date/2010/March/21), and then what would happen?\n\nBy having SSDVFacetField you can control that by yelling at whoever attempts to do that. For that, taking a CP (see comment below) would make the check easier (if cp.length > 2, it's an error).\n\nBut you'd need to provide it with this separator... hmm, or maybe we can use the same sep as FIP.\n\nI think that you should give it a CP, not BytesRef. There is a difference between the separator you give to CP(str, '/') to the one that's defined in FIP. The one that you give to CP (and you can use the vararg constructor to avoid that) just tells CP how to break the string into the path components. For instance, if we removed that ctor, you'd need to call the vararg one by splitting the string yourself.\n\nThe one in FIP is used to write the drill-down terms. Currently, following your recent change, it's set to a character that is really not expected to be part of a category string. Therefore I don't worry about it.\n\nAs for how the app can set the separator in a server-based environment, there are two options. Define it as part of the index schema \u2013 Solr/ES shouldn't care about it, they would just use it to split category strings, but app should know what's a safe separator for it. Another option that we chose to implement, since we work with JSON input, we just defined the facets as an array of strings and then there's no separator worry for the server. App should still be able to construct the array, meaning it should be able to split the category strings based on a 'safe' separator. I don't think we should worry about escaping delimiters. If an app cannot be sure that e.g. '>' is a safe separator, it should escape it itself? ",
            "author": "Shai Erera",
            "id": "comment-13600804"
        },
        {
            "date": "2013-03-13T11:00:36+0000",
            "content": "By having SSDVFacetField you can control that by yelling at whoever attempts to do that.\n\nGood!  I'll add that index-time check ...\n\nThere is a difference between the separator you give to CP(str, '/') to the one that's defined in FIP. \n\nI'm talking about FIP's/Consts.java separator, that's baked into the index.\n\nI think hidden separators are trappy, and yes U+001F is rather unlikely to appear, I still think it's bad to disallow it in the input.  Maybe an app wants to hide some payload in its facet labels so it joins two things with U+001F...\n\nMaking users of server apps (Solr/ElasticSearch) specify this in their schema is still trappy...\n\nAlso, the cost of doing this escaping / unescaping would be minor.\n\nAnyway, this is a separate issue ... I'll open a new jira. ",
            "author": "Michael McCandless",
            "id": "comment-13601035"
        },
        {
            "date": "2013-03-13T12:04:12+0000",
            "content": "From more than a dozen faceted search applications I've worked with, none had any issue with the separator. Therefore I think it's over defensive programming for Lucene to do it. If an app wants to be defensive, it can escape on its own. ",
            "author": "Shai Erera",
            "id": "comment-13601061"
        },
        {
            "date": "2013-03-13T17:06:48+0000",
            "content": "From more than a dozen faceted search applications I've worked with, none had any issue with the separator. Therefore I think it's over defensive programming for Lucene to do it. If an app wants to be defensive, it can escape on its own.\n\nOK, fair enough.\n\nIt still seems like bad practice to me but I guess we can keep it / worry about it if a user hits it. ",
            "author": "Michael McCandless",
            "id": "comment-13601362"
        },
        {
            "date": "2013-03-13T17:55:11+0000",
            "content": "Patch.  The sep is now hardwired to FIP's default sep, and I added SortedSetDocValuesFacetField for indexing.\n\nOne thing I don't like is how I compute the DV field as clpParams.field + \"sdv\" ... I did this so that a single index could easily (w/o having to make a custom CLP) index both kinds of facets ... not sure if there's a better way. ",
            "author": "Michael McCandless",
            "id": "comment-13601430"
        },
        {
            "date": "2013-03-13T18:30:12+0000",
            "content": "I don't think we should do it. First it's not really supported. Whoever users SSDVF must use the accompanied accumulator which cannot handle requests against the taxonomy, or hierarchical facets. Second, if someone already chose to have a sidecar taxonomy, why would he do both methods?\n\nAgain, \"by mistake\" won't work because of what I wrote above. In order to make it work you need to write a special accumulator, and I think that if you already reached that level of expertise, you can work with per-dimension params?  ",
            "author": "Shai Erera",
            "id": "comment-13601464"
        },
        {
            "date": "2013-03-13T18:44:32+0000",
            "content": "Hmmm, correction. You cannot write an accumulator which handles both type of facets since the ordinal space is different and therefore it cannot reuse the same FacetArrays. While potentially it could allocate two arrays and delegate to the appropriate accumulator, I think this points at the high risk of indexing facets in two ways.\n\nIf someone wants to do it though (I still don't think it makes sense), he should use PerDimIndexingParams. That's what we have them for.\n\nMike, I think that SortedSetDVFacetField should go under o.a.l.facet.sortedset together with all relevant classes. That will make it both easier for people to integrate with it, since by looking at the jdocs you'll see all relevant classes as well as (I hope) reduce the chance for a mistake. ",
            "author": "Shai Erera",
            "id": "comment-13601481"
        },
        {
            "date": "2013-03-13T19:31:38+0000",
            "content": "The use case I'm picturing is an app would choose to use the existing\nAPIs for the hierarchical fields and the sorted set field/accumulator\nfor the flat fields; I think this is a reasonable typical example and\nI think it's important to make that easy.  At search time they make\ntwo FacetCollectors ...\n\nThe new method uses much less RAM for flat fields (doesn't allocate 3\nX int[maxOrd]), which I think for some apps is a good tradeoff.\n\nAlso, I don't like the risk that the app will try to add both \"styles\" of\nfacet field to a Document and expect it to work ... they will get a\ncryptic exception about DocValues type changing for a single field.\n\nMike, I think that SortedSetDVFacetField should go under o.a.l.facet.sortedset together with all relevant classes.\n\nGood idea; I'll do that. ",
            "author": "Michael McCandless",
            "id": "comment-13601531"
        },
        {
            "date": "2013-03-14T05:53:25+0000",
            "content": "At search time they make two FacetCollectors\n\nThey should be making two FacetAccumulators and a delegating one. It's more efficient than having two collectors which track matching documents per-segment.\n\nThe new method uses much less RAM for flat fields\n\nI scanned the issue but did not find the right numbers. Do you have them? How much more RAM does the taxo consume (with its 3 int[]) on the non-hierarchical dimensions only, vs the sorted set approach?\n\n\nAlso, I don't like the risk that the app will try to add both \"styles\" of\nfacet field to a Document and expect it to work ... they will get a\ncryptic exception about DocValues type changing for a single field.\n\nI think that's fine? It's an exception that the app will hit quite fast (hopefully during testing). And if you put the sorted set stuff in its own package, then we should document that this does not work with FacetFields, unless the categories are put in different CLPs (using PerDimIndexingParams).\n\nIMO, that that you add \"sdv\" to sorted set field is premature optimization. No one has used the new method yet, let alone tried to use both of them. Why not do it when it will really hit someone? ",
            "author": "Shai Erera",
            "id": "comment-13602063"
        },
        {
            "date": "2013-03-14T06:40:36+0000",
            "content": "Few more comments about the patch:\n\n\n\tSortedSetDVFacetField:\n\t\n\t\tShould it extend SSDVField? It means you will need to construct the BytesRef before you make all the validity checks, but that's ok?\n\t\t\n\t\t\tYou could also make all those validity checks in a static toBytesRef(CP) method?\n\t\t\n\t\t\n\t\tYou should use FIP.getFacetDelimChar instead of the DEFAULT constant, as an app can override that\n\t\t\n\t\t\tAlso in SortedSetDVReaderState, tests (where it makes sense).\n\t\t\tMaybe add a test which overrides FIP.getFacetDelimChar and make sure SSDFF uses it instead of the constant?\n\t\t\n\t\t\n\t\tInstead of doing cp[0] + delim + cp[1] you can call cp.toString(fip.getFacetDelimChar())?\n\t\t\n\t\t\tIn that regard, if we added BytesRef.append(CharSequence) we could impl CP.toBytesRef(char delim) and save the redundant StringBuilder and String allocations.\n\t\t\n\t\t\n\t\n\t\n\n\n\n\n\tIn TestDemoFacets you do doc.add(new SortedSetDocValuesFacetField(new CategoryPath(\"b\", \"baz\" + FacetIndexingParams.DEFAULT_FACET_DELIM_CHAR + \"foo\"))). What's the purpose?\n\t\n\t\tIf facetDelimChar is '/', this will create a drill-down term b/baz/foo right? What does this mean in terms of the test? Is this counted as baz/foo or baz? (perhaps add a comment in the test what exactly does it test?)\n\t\n\t\n\n\n\n\n\tIn SSDVAccumulator:\n\t\n\t\tShould the javadocs say \"that uses previously indexed {@link SortedSetDocValuesFacetField}\"? Will it really work with any SSDV indexed?\n\t\tIn the Aggregator, can u add a meaningful message to UnsupportedOpEx?\n\t\tRegarding the top-K, you do not optimize for now the case where someone asks for \"all facets\" (i.e. numResults=Integer.MAX_VALUE, or > numOrds). Would you like to handle it in this patch? Look at DepthOneFacetResultsHandler, which adds all values to a list and sorts it, rather than working w/ the PQ.\n\t\t\n\t\t\tIf you don't want to handle it now (i.e. if you don't think that improves things) then at least construct the PQ with min(numResults, taxo.size).\n\t\t\n\t\t\n\t\tIs this code really preferred over just setting bottomCount to top().value in every iteration? I think that in the common case we should expect more than K facets per dim, and if there are less, then I don't think it matters if we do that assignment, vs. always calling q.size().\n\n+          if (q.size() == request.numResults) {\n+            bottomCount = (int) q.top().value;\n+            //System.out.println(\"    new bottom=\" + bottomCount);\n+          }\n\n\n\t\n\t\n\n ",
            "author": "Shai Erera",
            "id": "comment-13602093"
        },
        {
            "date": "2013-03-14T22:50:23+0000",
            "content": "OK I folded in all that feedback Shai, thanks!\n\nI also improved TestDrillSideways to not always ask for all results\n(so we test the topN).\n\nIn that regard, if we added BytesRef.append(CharSequence) we could impl CP.toBytesRef(char delim) and save the redundant StringBuilder and String allocations.\n\nHmm, true.  Later...\n\nIn TestDemoFacets you do doc.add(new SortedSetDocValuesFacetField(new CategoryPath(\"b\", \"baz\" + FacetIndexingParams.DEFAULT_FACET_DELIM_CHAR + \"foo\"))). What's the purpose?\n\nI want to assert that the label is allowed to use the delimiter;\nonly the dimension is not allowed to.\n\nInstead of doing cp[0] + delim + cp[1] you can call cp.toString(fip.getFacetDelimChar())>\n\nI can't ... because CP.toString gets angry about the delim in the\nlabel when in fact this is fine.\n\nIn the Aggregator, can u add a meaningful message to UnsupportedOpEx?\n\nI changed this to a no-op and left a comment.\n\nIs this code really preferred over just setting bottomCount to top().value in every iteration?\n\nI think that's wrong, i.e you can only apply the bottomCount check once\nthe queue is full?  (Unless I pre-fill with sentinels ... which feels\nlike too much optimizing). ",
            "author": "Michael McCandless",
            "id": "comment-13602861"
        },
        {
            "date": "2013-03-15T03:46:41+0000",
            "content": "I can't ... because CP.toString gets angry about the delim in the label when in fact this is fine.\n\nIt's fine only in this case, since you don't support hierarchy right? Then perhaps just drop a comment in the ctor?\n\n\nI think that's wrong, i.e you can only apply the bottomCount check once\nthe queue is full? (Unless I pre-fill with sentinels ... which feels\nlike too much optimizing).\n\nArgh, you're right. I don't think it's too much optimizing but I'm not going to argue about it. Your call.\n\nI'm +1 to commit! ",
            "author": "Shai Erera",
            "id": "comment-13603084"
        },
        {
            "date": "2013-03-15T11:01:36+0000",
            "content": "Then perhaps just drop a comment in the ctor?\n\nOK I'll put a comment where I append w/ the delim explaining why I can't use CP.toString ...\n\nThanks Shai!  I'll commit soon... ",
            "author": "Michael McCandless",
            "id": "comment-13603299"
        },
        {
            "date": "2013-03-15T20:17:30+0000",
            "content": "[trunk commit] Michael McCandless\nhttp://svn.apache.org/viewvc?view=revision&revision=1457092\n\nLUCENE-4795: add new facet method to facet from SortedSetDocValues without using taxonomy index ",
            "author": "Commit Tag Bot",
            "id": "comment-13603796"
        },
        {
            "date": "2013-03-15T20:28:44+0000",
            "content": "[branch_4x commit] Michael McCandless\nhttp://svn.apache.org/viewvc?view=revision&revision=1457095\n\nLUCENE-4795: add new facet method to facet from SortedSetDocValues without using taxonomy index ",
            "author": "Commit Tag Bot",
            "id": "comment-13603808"
        },
        {
            "date": "2013-03-16T08:51:54+0000",
            "content": "Mike, I think it will be good if we also have an example code under demo/facet that demonstrates how to use the new field at indexing and search time? Something very similar to SimpleFacetExample, only without the Date/ hierarchical facet. This can be done in a separate issue if you prefer. ",
            "author": "Shai Erera",
            "id": "comment-13604167"
        },
        {
            "date": "2013-03-16T20:10:49+0000",
            "content": "That's a good idea ... I'll open a new issue ... we need to get drill-down working first (LUCENE-4840). ",
            "author": "Michael McCandless",
            "id": "comment-13604408"
        },
        {
            "date": "2013-05-10T10:33:04+0000",
            "content": "Closed after release. ",
            "author": "Uwe Schindler",
            "id": "comment-13653814"
        },
        {
            "date": "2014-01-06T21:54:55+0000",
            "content": "Commit 1556045 from Michael McCandless in branch 'dev/branches/lucene5376'\n[ https://svn.apache.org/r1556045 ]\n\nLUCENE-4795, LUCENE-5376: expose SortedSetDocValuesFacets in lucene server ",
            "author": "ASF subversion and git services",
            "id": "comment-13863474"
        }
    ]
}