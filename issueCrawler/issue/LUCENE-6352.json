{
    "id": "LUCENE-6352",
    "title": "Add global ordinal based query time join",
    "details": {
        "resolution": "Fixed",
        "affect_versions": "None",
        "components": [],
        "labels": "",
        "fix_versions": [],
        "priority": "Major",
        "status": "Resolved",
        "type": "Improvement"
    },
    "description": "Global ordinal based query time join as an alternative to the current query time join. The implementation is faster for subsequent joins between reopens, but requires an OrdinalMap to be built.\n\nThis join has certain restrictions and requirements:\n\n\tA document can only refer to on other document. (but can be referred by one or more documents)\n\tA type field must exist on all documents and each document must be categorized to a type. This is to distingues between the \"from\" and \"to\" side.\n\tThere must be a single sorted doc values field use by both the \"from\" and \"to\" documents. By encoding join into a single doc values field it is trival to build an ordinals map from it.",
    "attachments": {
        "LUCENE-6352.patch": "https://issues.apache.org/jira/secure/attachment/12703319/LUCENE-6352.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "id": "comment-14352347",
            "author": "Martijn van Groningen",
            "date": "2015-03-08T23:36:26+0000",
            "content": "Attached draft patch. "
        },
        {
            "id": "comment-14375620",
            "author": "Martijn van Groningen",
            "date": "2015-03-23T09:35:04+0000",
            "content": "Attached a new version of the global ordinal based query time join:\n\n\tAdded support for the max, total and avg score mode.\n\tAdded more tests.\n\n "
        },
        {
            "id": "comment-14386238",
            "author": "Martijn van Groningen",
            "date": "2015-03-30T06:01:04+0000",
            "content": "Attached a new version:\n\n\tadded hascode/equal/extractTerms methods to the query impls.\n\tadded optimization for in the case an index has only 1 segment\n\tupdated to the latest two phase iterator changes.\n\n "
        },
        {
            "id": "comment-14386461",
            "author": "Adrien Grand",
            "date": "2015-03-30T09:38:19+0000",
            "content": "Thanks Martijn! I had a look at the patch it looks very clean, I like it.\n\n\nQuery rewrittenFromQuery = fromQuery.rewrite(indexReader); (JoinUtil.java)\n\n\n\nI think you should rather call searcher.rewrite(fromQuery) here, which will take care of rewriting until rewrite returns 'this'.\n\n\nfinal float[][] blocks = new float[Integer.MAX_VALUE / arraySize][];\n\n\n\nInstead of allocating based on Integer.MAX_VALUE, maybe it should use the number of unique values? ie. '(int) (((long) valueCount + arraySize - 1) / arraySize)' ?\n\n\nreturn new ComplexExplanation(true, score, \"Score based on join value \" + joinValue.utf8ToString());\n\n\n\nI don't think it is safe to convert to a string as we have no idea whether the value represents an utf8 string?\n\nIn BaseGlobalOrdinalScorer, you are caching the current doc ID, maybe we should not? When I worked on approximations, caching the current doc ID proved to be quite error-prone and it was often better to just call approximation.docID() when the current doc ID was needed.\n\nAnother thing I'm wondering about is the equals/hashCode impl of this global ordinal query: since documents that match depend on what happens in other segments, this query cannot be cached per segment. So maybe it should include the current IndexReader in its equals/hashCode comparison in order to work correctly with query caches? In the read-only case, this would still allow this query to be cached since the current reader never changes while in the read/write case this query will unlikely be cached given that the query cache will notice that it does not get reused? "
        },
        {
            "id": "comment-14390132",
            "author": "Martijn van Groningen",
            "date": "2015-04-01T07:22:19+0000",
            "content": "Adrien, Thanks for taking a look at it!\n\nI updated the patch and applied all the comments, but the comment about the explain.  I wonder if we can check whether a BytesRef is valid utf8 and then convert it? Otherwise just use the BytesRef directly. I like the explain to be somewhat useful and this is the best I can think of right now. "
        },
        {
            "id": "comment-14390204",
            "author": "Adrien Grand",
            "date": "2015-04-01T08:15:56+0000",
            "content": "Or maybe we could just document that this feature expects that the join field stores utf8 string values? "
        },
        {
            "id": "comment-14390213",
            "author": "Martijn van Groningen",
            "date": "2015-04-01T08:27:08+0000",
            "content": "Yes, that makes sense. I updated the join util jdocs to reflect this. "
        },
        {
            "id": "comment-14390217",
            "author": "Martijn van Groningen",
            "date": "2015-04-01T08:34:57+0000",
            "content": "Another patch, forgot to change the size of the int[][] array in GlobalOrdinalsWithScoreCollector.Occurrences "
        },
        {
            "id": "comment-14390223",
            "author": "Adrien Grand",
            "date": "2015-04-01T08:36:19+0000",
            "content": "Just had another look at the patch and found two issues:\n\n\tOccurrences still allocates blocks using MAX_VALUE instead of the number of docs per segment\n\tScores allocates using '(valueCount + arraySize - 1) / arraySize' but I think we need to cast to a long before the addition and then back to an int after the division in order to avoid overflows if the doc count in the segment is greater than MAX_VALUE - arraySize. So this would be: '(int) (((long) valueCount + arraySize - 1) / arraySize)'\n\n\n\nOtherwise +1 to commit! This is interesting usage of two-phase iteration. "
        },
        {
            "id": "comment-14390254",
            "author": "Martijn van Groningen",
            "date": "2015-04-01T09:04:05+0000",
            "content": "Good point about the potential overflow issue! I changed the patch to avoid this. I'll commit this shortly to trunk and 5x. "
        },
        {
            "id": "comment-14393544",
            "author": "ASF subversion and git services",
            "date": "2015-04-02T22:00:29+0000",
            "content": "Commit 1670990 from Martijn van Groningen in branch 'dev/trunk'\n[ https://svn.apache.org/r1670990 ]\n\nLUCENE-6352: Added a new query time join to the join module that uses global ordinals, which is faster for subsequent joins between reopens. "
        },
        {
            "id": "comment-14393569",
            "author": "ASF subversion and git services",
            "date": "2015-04-02T22:12:32+0000",
            "content": "Commit 1670991 from Martijn van Groningen in branch 'dev/branches/branch_5x'\n[ https://svn.apache.org/r1670991 ]\n\nLUCENE-6352: Added a new query time join to the join module that uses global ordinals, which is faster for subsequent joins between reopens. "
        },
        {
            "id": "comment-14482915",
            "author": "ASF subversion and git services",
            "date": "2015-04-07T09:37:21+0000",
            "content": "Commit 1671774 from Martijn van Groningen in branch 'dev/trunk'\n[ https://svn.apache.org/r1671774 ]\n\nLUCENE-6352: Improved tests for global ordinal join "
        },
        {
            "id": "comment-14482924",
            "author": "ASF subversion and git services",
            "date": "2015-04-07T09:45:57+0000",
            "content": "Commit 1671777 from Martijn van Groningen in branch 'dev/branches/branch_5x'\n[ https://svn.apache.org/r1671777 ]\n\nLUCENE-6352: Improved tests for global ordinal join "
        }
    ]
}