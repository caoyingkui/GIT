{
    "id": "LUCENE-5564",
    "title": "Currency characters are not tokenized",
    "details": {
        "type": "Bug",
        "priority": "Major",
        "labels": "",
        "resolution": "Invalid",
        "components": [
            "core/index"
        ],
        "affect_versions": "3.6.2",
        "status": "Resolved",
        "fix_versions": []
    },
    "description": "It is not possible to have the SmartChineseAnalyzer(nor the StandardAnalyzer) include the currency characters (e.g $ or \u20ac) in the token stream.\n\nFor example, the following will output 100 200. I would expect a way to configure the analyzers to output 100$ 200\u20ac instead.\n\nimport java.io.StringReader;\nimport org.apache.lucene.analysis.Analyzer;\nimport org.apache.lucene.analysis.TokenStream;\nimport org.apache.lucene.analysis.cn.smart.SmartChineseAnalyzer;\nimport org.apache.lucene.analysis.tokenattributes.CharTermAttribute;\nimport org.apache.lucene.util.Version;\npublic class Test {\n\tpublic static void main(String[] args) throws Exception {\n\t\tAnalyzer analyzer = new SmartChineseAnalyzer(Version.LUCENE_36); //new StandardAnalyzer(Version.LUCENE_36);\n\t\tTokenStream stream = analyzer.tokenStream(null, new StringReader(\"100$ 200\u20ac\"));\n\t\twhile (stream.incrementToken()) \n{\n\t\t\tCharTermAttribute attr = stream.getAttribute(CharTermAttribute.class);\n\t\t\tSystem.out.print(new String(attr.buffer(), 0, attr.length()));\n\t\t\tSystem.out.print(' ');\n\t\t}\n\t}\n}",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "id": "comment-13956809",
            "author": "Erick Erickson",
            "content": "First of all, please raise this kind of issue on the user's list first so others have a chance to comment and you have some assurance that what you expect is a good thing.\n\nIn this case, the analyzer isn't much good if it can't compare numbers for currency. If it has the Euro or US dollar sign attached, it isn't a number any more, and it's compared lexically. So, for instance, the sort order (and this affects range queries etc) for $100 and $20 would sort (ascending) as\n$100\n$20\n\nwhich is clearly wrong. The symbol will be stored if you set things to stored, so you can get it back, it just won't be part of the token in the index.\n\nWhat is it you really want? This seems like an XY problem; you're asking for a solution without clearly defining the problem.\n\nFeel free to reopen this if, through discussion on the user's list, you truly find that this behavior is unexpected. ",
            "date": "2014-04-01T17:42:07+0000"
        }
    ]
}