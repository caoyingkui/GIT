{
    "id": "SOLR-12672",
    "title": "Implement Synchronized Disruption into Solr",
    "details": {
        "labels": "",
        "priority": "Trivial",
        "components": [],
        "type": "New Feature",
        "fix_versions": [],
        "affect_versions": "None",
        "resolution": "Unresolved",
        "status": "Open"
    },
    "description": "On large Solr clusters, at any given time, there is probably an instance running garbage collection.\u00a0 By implementing a synchronized disruption across the entire cluster, the response times of\u00a0a large cluster should decrease as it helps prevent random instances from running GC while the rest of the cluster is responding to a request.",
    "attachments": {
        "Synchronized Disruption in Solr.pdf": "https://issues.apache.org/jira/secure/attachment/12935894/Synchronized%20Disruption%20in%20Solr.pdf"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2018-08-16T16:59:11+0000",
            "content": "I've attached a PDF presentation to explain Synchronized Disruption, it's benefits, and resources (specifically, Bloomberg's use of synchronized disruption on HBase). ",
            "author": "Trey Cahill",
            "id": "comment-16582829"
        },
        {
            "date": "2018-08-16T17:00:51+0000",
            "content": "Interesting idea. Some random thoughts:\n\n\tI can see \"issues\" if the process prevented indexing, might lead to recoveries that are worse than the original problem.\n\tWhat about a \"rolling disruption\"? What I have in mind here is just preventing queries from going to a node that's \"disrupted\". Something like \"while the node is disrupted, don't use for serving queries\". I'm thinking that you'd do some kind of rolling disruption and have all the non disrupted nodes be the only ones that served queries. NOTE: I have no idea how easy/hard/practical this is....\n\n\n\n\n\t\n\t\n\t\tNot sure how to communicate this to other nodes, using ZooKeeper seems like it would lead to a zillion alerts being triggered.....\n\t\tMaybe what'd happen is the node that's disrupted somehow forwards the request somewhere else or replies immediately with \"I'm busy, ask someone else\".\n\t\n\t\n\n\n\nI'm running from one place to another so I haven't thought about the implementation so feel free to ignore... ",
            "author": "Erick Erickson",
            "id": "comment-16582832"
        },
        {
            "date": "2018-08-17T13:22:16+0000",
            "content": "Erick Erickson, the disruptions should interrupt the entire cluster (imagine every instance in the cluster running a stop-the-world gc at the same time), so I'd hope that it wouldn't lead to some sort of recovery situation.\u00a0 I have not tried this out on a sufficiently big cluster to verify this though.\n\nAnd hopefully, there is no need to communicate to other nodes that the disruption is occurring because every node\u00a0should be disrupted (on startup, the node will check Zookeeper for any disruptions).\u00a0 When disruptions are added/removed, the request is sent to all the nodes, rather than communicated through zookeeper (this could be a potential issue, if a single instance failed to add a disruption becoming out of sync with the rest of the cluster).\n\nI think this blog\u00a0will help give a better understanding to what it's actually trying to achieve. ",
            "author": "Trey Cahill",
            "id": "comment-16583935"
        },
        {
            "date": "2018-08-18T04:51:01+0000",
            "content": "As far as I am aware, if you ask Java for an explicit GC, it's going to be a full GC.  Does your experience align with this?  I suppose you can use jstat or jconsole to monitor a JVM that is doing the synchronized disruption, see whether the full GC counter or one of the generation-specific counters is incrementing.  Are you tracking how long the System.gc() call takes in your code that does this synchronization?\n\nI found the secret to good GC tuning is to give Java parameters that allow it to avoid doing full garbage collections, freeing up plenty of memory using only the generation-specific collectors, which run much faster and tend to create short pauses.\n\nA full GC, no matter which collector you have configured, is going to be slow.  With an 8GB heap and no tuning beyond either choosing G1 or CMS, I was seeing full GCs happen regularly, and there were pauses of 10-15 seconds every time Java did a full GC.  With good tuning, full GCs became extremely rare.  If one did happen for some reason, there was still a long pause.\n\nDo you find that explicit GCs done on a regular basis perform faster than several seconds?  If a scheduled GC does take several seconds, and this happens on every machine in the cluster at the same time, that would be a worse problem than an extra hundred milliseconds every now and then. ",
            "author": "Shawn Heisey",
            "id": "comment-16584632"
        },
        {
            "date": "2018-08-18T16:07:02+0000",
            "content": "By implementing a synchronized disruption across the entire cluster\nThis seems a little more far fetched , but what if they GCs could be synchronized for replica1 for all shards and query\u00a0in that small window would be routed only to replica2 of the shards .\u00a0 ",
            "author": "Varun Thacker",
            "id": "comment-16584832"
        },
        {
            "date": "2018-08-18T16:49:29+0000",
            "content": "SOLR-6730 has a similar goal (reducing chance of hitting GC) via a different method. ",
            "author": "Michael Braun",
            "id": "comment-16584839"
        },
        {
            "date": "2018-08-20T12:24:27+0000",
            "content": "Shawn Heisey, \nif you ask Java for an explicit GC, it's going to be a full GC. Does your experience align with this?  - As far as I know, it does a full GC (although IIRC, it doesn't\u00a0have to run a GC; it's more of a suggestion).\nAre you tracking how long the System.gc() call takes in your code that does this synchronization?  - Not explicitly, but it does happen as a side effect of scheduling the next disruption.\nDo you find that explicit GCs done on a regular basis perform faster than several seconds?  - I've not looked into that; I'll work on finding out.\nIf a scheduled GC does take several seconds, and this happens on every machine in the cluster at the same time, that would be a worse problem than an extra hundred milliseconds every now and then. - Absolutely and it'd defeat the purpose of entire PR.\n\nMichael Braun, it does look like that.  It seems like a commonality between SOLR-6730 and Varun Thacker's suggestion is that the cluster is available the entire time. So, rather than disrupting the entire cluster, only part of the cluster would be affected.\n\n\u00a0 ",
            "author": "Trey Cahill",
            "id": "comment-16585856"
        },
        {
            "date": "2018-08-20T16:04:31+0000",
            "content": "The NRT indexing case is tricky. Temporarily taking a replica out of rotation for queries might work though.\n\nConsider the indexing cycle (NRT).\n\n\tleader gets an update\n\tleader forwards request to replica\n\tif leader does not get a response back from the replica, it may put the replica into Leader Initiated Recovery (LIR) after retries.\n\n\n\nUnder all circumstances, the update operation does not return to the client until all active replicas have replied. And if a replica somehow doesn't reply, it goes into recovery.\n\nSo at least in the NRT case, whatever mechanism is in place must still accept updates or it would be A Bad Thing.\n\nPULL replicas don't have the same problem, but there you wouldn't want them to start answering queries until after the next sync after the \"I'm busy\" state.\n\nTLOG replicas. hmmmmm. Not quite sure what happens here if they don't respond to an update.\n\nNext practicality: How to deal with multiple replicas all on the same Solr instance? Apart from having one replica per JVM you can't take a single replica out of rotation without affecting all the other replicas hosted by the JVM. Practically, this may not be a problem since you want as few replicas for the same shard hosted on a particular JVM as possible, but you'd have to build in some safeguards.\n\nOne way this could work (and this seems to fall \"naturally\" to the Overseer\" is\n\nfor (all my live_nodes)\n\n{\u00a0 * send live_node_x the \"do your GC bit\" * live_node_x broadcasts \"all my replicas are going to be busy\"\u00a0[1] * live_node_x does a GC * live_node_x broadcasts \"I'm not busy any more\" [2] }\n\n[1]\u00a0this would cause each Solr instance receiving the message to mark their local copy of the node states \"don't use replicas on this node for queries\". How that would interact with them having a watch triggered for an unrelated state change is interesting.\n\n[2] there would have to be some reasonable\u00a0bailout built in in case the \"I'm not busy now\" message didn't get to all live_nodes. Perhaps the Overseer itself also gets the \"I'm not busy\" message, it's a Solr instance after all.\n\n\u00a0\n\nNOTE: there is a JIRA out there somewhere\u00a0about separating the query and update threads into separate pools, this all might be much easier after that is done. ",
            "author": "Erick Erickson",
            "id": "comment-16586145"
        },
        {
            "date": "2018-08-21T14:09:36+0000",
            "content": "I think that in order for this idea to be safe, the max heap needs to be larger than what that install of Solr would normally need \u2013 to ensure that there's enough heap memory that Java won't ever decide to do a GC on its own.  The explicit GCs should be the only GCs that occur.\n\nIf the explicit GCs take more than about one second, then I think the entire idea is problematic.  If a heap size of 8GB makes the explicit GCs take 10 seconds or longer, it's a REALLY bad idea.  I'd rather deal with subsecond pauses on an unpredictable interval than that scenario.\n\nIf we can do what Erick seems to be suggesting and synchronize pauses on one replica at a time, with overseer updates telling SolrCloud to NOT use those replicas until the synchronized event is done, that MIGHT eliminate all concerns.  It would mean that this must be a cloud-only feature.  And if the pauses are longer than five seconds for larger heaps, that's a problem. ",
            "author": "Shawn Heisey",
            "id": "comment-16587472"
        }
    ]
}