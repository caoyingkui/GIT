{
    "id": "SOLR-7292",
    "title": "OutOfMemory happened in Solr, but /clusterstates.json shows cores \"active\"",
    "details": {
        "components": [
            "contrib - Clustering"
        ],
        "type": "Bug",
        "labels": "",
        "fix_versions": [],
        "affect_versions": "4.7",
        "status": "Closed",
        "resolution": "Won't Fix",
        "priority": "Major"
    },
    "description": "One of our 5 Solr server got OOM, but in /clusterstates.json in ZK, it is still \"active\".  The OOM Ex are the attached OOM.txt.\n\nBut update and commit to the collection which has cores on that Solr server will got failure. The logs are in the failure.txt.",
    "attachments": {
        "failure.txt": "https://issues.apache.org/jira/secure/attachment/12706494/failure.txt",
        "OOM.txt": "https://issues.apache.org/jira/secure/attachment/12706495/OOM.txt"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2015-03-23T12:40:40+0000",
            "author": "Shawn Heisey",
            "content": "I hope that we can improve Solr to deal with the problem you found, but there's something important to say:  The results of OOM errors are, by their very nature, extremely hard to predict.\n\nIt is possible to force a program into predictable behavior on OOM, but it is a difficult task to accomplish.  Such programming has been done in parts of the Lucene codebase, specifically those parts that write the index files, so that OOM will not produce a corrupt index.  The \"no corruption\" guarantee is the only one that Lucene attempts to make ... in all other ways, the behavior of a Lucene program (like Solr) is not predictable in the face of OOM.\n\nYour best bet is to ensure that Java runs an OOM script that will kill Solr entirely when OOM happens.  This is handled automatically by the Solr 5.0 start script. ",
            "id": "comment-14375854"
        },
        {
            "date": "2015-03-23T21:12:00+0000",
            "author": "Ramkumar Aiyengar",
            "content": "I agree with Shawn here, the foolproof way is to just kill Solr through an OOM handler. That will still not update cluster state as the shutdown is not clean. However, ZK will remove the live node for the cores in the JVM, and all of Solr's distributed logic consider both of these pieces of information. Even if Solr handled OOME, that operation will need memory and that might fail as well.. ",
            "id": "comment-14376646"
        },
        {
            "date": "2015-03-24T01:52:24+0000",
            "author": "Forest Soup",
            "content": "Thank you all! \nWill consider your suggestion! ",
            "id": "comment-14377084"
        }
    ]
}