{
    "id": "LUCENE-6400",
    "title": "SynonymParser should encode 'expand' correctly.",
    "details": {
        "resolution": "Fixed",
        "affect_versions": "None",
        "components": [],
        "labels": "",
        "fix_versions": [
            "5.2",
            "6.0"
        ],
        "priority": "Major",
        "status": "Closed",
        "type": "Bug"
    },
    "description": "Today SolrSynonymParser encodes something like A, B, C with 'expand=true' like this:\nA -> A, B, C (includeOrig=false)\nB -> B, A, C (includeOrig=false)\nC -> C, A, B (includeOrig=false)\n\nThis gives kinda buggy output (synfilter sees it all as replacements, and makes all the terms with type synonym, positionLength isnt supported, etc) and it wastes space in the FST (includeOrig is just one bit). \n\nExample with \"spiderman, spider man\" and analysis on 'spider man'\n\nTrunk:\nterm=spider,startOffset=0,endOffset=6,positionIncrement=1,positionLength=1,type=SYNONYM\nterm=spiderman,startOffset=0,endOffset=10,positionIncrement=0,positionLength=1,type=SYNONYM\nterm=man,startOffset=7,endOffset=10,positionIncrement=1,positionLength=1,type=SYNONYM\n\nYou can see this is confusing, all the words have type SYNONYM, because spider and man got deleted, and totally replaced by new terms (Which happen to have the same text).\n\nPatch:\nterm=spider,startOffset=0,endOffset=6,positionIncrement=1,positionLength=1,type=word\nterm=spiderman,startOffset=0,endOffset=10,positionIncrement=0,positionLength=2,type=SYNONYM\nterm=man,startOffset=7,endOffset=10,positionIncrement=1,positionLength=1,type=word",
    "attachments": {
        "LUCENE-6400.patch": "https://issues.apache.org/jira/secure/attachment/12723459/LUCENE-6400.patch",
        "unittests-expand-and-parse.patch": "https://issues.apache.org/jira/secure/attachment/12725924/unittests-expand-and-parse.patch",
        "PositionLenghtAndType-unittests.patch": "https://issues.apache.org/jira/secure/attachment/12724029/PositionLenghtAndType-unittests.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "id": "comment-14482045",
            "author": "Robert Muir",
            "date": "2015-04-06T21:59:46+0000",
            "content": "Here is a patch. just needs tests. "
        },
        {
            "id": "comment-14482048",
            "author": "Michael McCandless",
            "date": "2015-04-06T22:01:39+0000",
            "content": "+1 "
        },
        {
            "id": "comment-14486089",
            "author": "Ian Ribas",
            "date": "2015-04-08T21:25:00+0000",
            "content": "I did some unit tests, to try and get into the code and saw a behavior that I think is not right.\n\nFor the same example of  \"spiderman, spider man\", an analysis on 'spiderman' gives:\n\nterm=spiderman,positionIncrement=1,positionLength=1,type=word\nterm=spider,positionIncrement=1,positionLength=1,type=SYNONYM\nterm=man,positionIncrement=1,positionLength=1,type=SYNONYM\n\nTo be coherent, I thought it should be:\nterm=spiderman,positionIncrement=1,positionLength=2,type=word\nterm=spider,positionIncrement=1,positionLength=1,type=SYNONYM\nterm=man,positionIncrement=1,positionLength=1,type=SYNONYM\n\nThings get even more complicated when the synonyms have even more different word counts, such as this example (from the Elasticsearch documentation: http://www.elastic.co/guide/en/elasticsearch/guide/current/multi-word-synonyms.html):\n\n\"usa,united states,u s a,united states of america\"\n\nThe analysis of the longest synonym: 'united states of america', works fine, but an analysis of a text containing a shorter one, such as 'the united states is wealthy' still yields a sausage.\n\nI attached a patch with the changes plus the unit tests that exemplify these situations. The tests now pass, but the results I think are the correct ones are commented just under the one's I think are wrong. To be used if useful, and discarded if not, of course.\n\nI'm not sure I'll be able to do it, but I'm looking into how to handle positionLength to have a better graph. "
        },
        {
            "id": "comment-14486205",
            "author": "Robert Muir",
            "date": "2015-04-08T22:25:51+0000",
            "content": "Thanks Ian. What you see is a limitation of synonymfilter (unrelated to this parser). synonymfilter doesn't \"introduce additional positions\" except for a trailer at the end as a special case. Otherwise it \"sausages\" by interleaving phrases together. To change this is much more complicated. \n\nSo your \"spiderman\" case will not behave correctly, but its unrelated to my patch here. The parser does the right thing...  "
        },
        {
            "id": "comment-14487220",
            "author": "Ian Ribas",
            "date": "2015-04-09T11:45:27+0000",
            "content": "Thank you for the explanation. I can see now that the behavior I mentioned is unrelated to the patch, and to the parser, for that matter ... "
        },
        {
            "id": "comment-14487436",
            "author": "Robert Muir",
            "date": "2015-04-09T14:42:23+0000",
            "content": "Yeah, that problem is disappointing, but a difficult problem. Definitely one that needs to be fixed. I get the impression from Mike (who is the expert on it), that it requires changes to the tokenstream api so that it can be done safely.\n\nOn the other hand we should look at your tests and try to integrate ones for parsing that show we do the right thing. Maybe we can find or add an assert method that just compares against the SynonymMap directly. Something like assertEntryEquals(String word, boolean includeOrig, String synonyms...) as a start and build from there. It could verify synonyms.length vs count and includeOrig from the header and then the set of strings (empty string means a hole). "
        },
        {
            "id": "comment-14487453",
            "author": "Robert Muir",
            "date": "2015-04-09T14:49:02+0000",
            "content": "I also tend to think we should fix this parser here (it was just a TODO all along) at least so SYNONYM types are correct for the common case. "
        },
        {
            "id": "comment-14498356",
            "author": "Ian Ribas",
            "date": "2015-04-16T17:35:22+0000",
            "content": "Here is a new patch with unit tests.\n\nI left a simple \"spiderman\" test based on what is said on the description of the issue, validating the type and positionLength (of the common case).\n\nI and also added the assertEntryEquals() method Robert suggested, that can be used to validate the parsed synonyms directly, and created some simple tests.\n\nI didn't really understand \"holes\" on the synonyms, so I didn't implement support for that on the method above. "
        },
        {
            "id": "comment-14498436",
            "author": "Robert Muir",
            "date": "2015-04-16T18:16:37+0000",
            "content": "Thank you, that patch is great!\n\nI folded those in with the change into a new patch. I think its ready. "
        },
        {
            "id": "comment-14498515",
            "author": "Michael McCandless",
            "date": "2015-04-16T18:58:18+0000",
            "content": "Patch looks great!\n\nI tried to further simplify SolrSynonymParser by breaking out separate for loops for the expand true vs false cases in the non-explicit case ... attached.\n\nI also put a new TODO. "
        },
        {
            "id": "comment-14498540",
            "author": "Michael McCandless",
            "date": "2015-04-16T19:11:46+0000",
            "content": "OK a bit more simplifiying: I don't create outputs in the 2a case, I moved inputs/outputs decls down into where they are used, and I just pass true / false for expand since we are already in the if clauses... "
        },
        {
            "id": "comment-14498554",
            "author": "Michael McCandless",
            "date": "2015-04-16T19:26:05+0000",
            "content": "Yeah, that problem is disappointing, but a difficult problem. Definitely one that needs to be fixed. I get the impression from Mike (who is the expert on it), that it requires changes to the tokenstream api so that it can be done safely.\n\nFixing SynFilter to be able to \"make positions\" is really important.\n\nIt's somewhat tricky but not impossible, because PosIncAtt + PosLengthAtt are sufficient for expressing any graph and changing any incoming graph to another graph (with enough buffering).  I don't think we need changes to TokenStream API, only to the SynFilter impl.\n\nWhat makes fixing SynFilter tricky is noting when a new position was created and then fixing any syns that had \"spanned\" that new position to also increase their position lengths, I think?  And it may require more buffering than syn filter does now... "
        },
        {
            "id": "comment-14498568",
            "author": "Ian Ribas",
            "date": "2015-04-16T19:40:45+0000",
            "content": "About the TODO, when not expanding (expand = false), the mappings are created without preserving the original (includeOrig=false), isn't that why the mapping of the first term to itself is needed? "
        },
        {
            "id": "comment-14498583",
            "author": "Ian Ribas",
            "date": "2015-04-16T19:49:47+0000",
            "content": "Sorry, looked at it again and saw that actually, if that mapping was absent, it would be even better. There would be no match and the term would stay there with type word, and not SYNONYM. "
        },
        {
            "id": "comment-14498589",
            "author": "Michael McCandless",
            "date": "2015-04-16T19:53:46+0000",
            "content": "isn't that why the mapping of the first term to itself is needed?\n\nWell, if we simply don't add a rule for inputs[0] -> inputs[0] then it would keep that token?\n\nBut it would be a slight change in behavior because today we remove that token, and put back a type=SYNONYM token....\n\nSo I left it as is now even though it really is quite wasteful... "
        },
        {
            "id": "comment-14498598",
            "author": "Michael McCandless",
            "date": "2015-04-16T19:58:46+0000",
            "content": "There would be no match and the term would stay there with type word, and not SYNONYM.\n\nRight!  I think it's more sane that way.  But I wonder if anything would care that we no longer label as type=SYNONYM... "
        },
        {
            "id": "comment-14498762",
            "author": "ASF subversion and git services",
            "date": "2015-04-16T21:26:37+0000",
            "content": "Commit 1674155 from Michael McCandless in branch 'dev/trunk'\n[ https://svn.apache.org/r1674155 ]\n\nLUCENE-6400: preserve original token when possible in SolrSynonymParser "
        },
        {
            "id": "comment-14498799",
            "author": "ASF subversion and git services",
            "date": "2015-04-16T21:53:17+0000",
            "content": "Commit 1674159 from Michael McCandless in branch 'dev/branches/branch_5x'\n[ https://svn.apache.org/r1674159 ]\n\nLUCENE-6400: preserve original token when possible in SolrSynonymParser "
        },
        {
            "id": "comment-14498801",
            "author": "Michael McCandless",
            "date": "2015-04-16T21:53:50+0000",
            "content": "Thanks Ian! "
        },
        {
            "id": "comment-14586783",
            "author": "Anshum Gupta",
            "date": "2015-06-15T21:42:30+0000",
            "content": "Bulk close for 5.2.0. "
        }
    ]
}