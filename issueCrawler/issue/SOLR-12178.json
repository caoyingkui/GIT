{
    "id": "SOLR-12178",
    "title": "Improve efficiency of distributed random sampling",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [],
        "type": "Improvement",
        "fix_versions": [
            "7.6",
            "master (8.0)"
        ],
        "affect_versions": "None",
        "resolution": "Unresolved",
        "status": "Open"
    },
    "description": "Currently the random Streaming Expression performs a distributed random sampling using CloudSolrClient. This means that a random sample of\u00a0N\u00a0docs from each shard is read into memory on the aggregator node and then a page of N\u00a0docs is created from the samples from each shard. Reading all the samples from the shards into memory in the aggregator node means the memory consumption for random sampling grows as a function of: N*numshards. This clearly limits both N and numshards.\n\nThis ticket will change the random sampling approach to an approach similar to the one used in CloudSolrStream\u00a0where a stream is generated from the shards without reading all the documents into memory.\n\nWhen combined with SOLR-12159 this will allow for much larger random samples.",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "date": "2018-08-09T01:01:41+0000",
            "content": "Move issue from deprecated 'In  Progress' back to 'Open' ",
            "author": "Gavin",
            "id": "comment-16574151"
        }
    ]
}