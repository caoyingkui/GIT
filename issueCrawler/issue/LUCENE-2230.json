{
    "id": "LUCENE-2230",
    "title": "Lucene Fuzzy Search: BK-Tree can improve performance 3-20 times.",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [
            "core/search"
        ],
        "type": "Improvement",
        "fix_versions": [],
        "affect_versions": "3.0",
        "resolution": "Unresolved",
        "status": "Open"
    },
    "description": "W. Burkhard and R. Keller. Some approaches to best-match file searching, CACM, 1973\nhttp://portal.acm.org/citation.cfm?doid=362003.362025\n\nI was inspired by http://blog.notdot.net/2007/4/Damn-Cool-Algorithms-Part-1-BK-Trees (Nick Johnson, Google).\n\n\nAdditionally, simplified algorythm at http://www.catalysoft.com/articles/StrikeAMatch.html seems to be much more logically correct than Levenstein distance, and it is 3-5 times faster (isolated tests).\n\nBig list od distance implementations:\nhttp://www.dcs.shef.ac.uk/~sam/stringmetrics.htm",
    "attachments": {
        "DistanceImpl.java": "https://issues.apache.org/jira/secure/attachment/12431061/DistanceImpl.java",
        "FuzzyTermEnumNEW.java": "https://issues.apache.org/jira/secure/attachment/12431063/FuzzyTermEnumNEW.java",
        "Distance.java": "https://issues.apache.org/jira/secure/attachment/12431060/Distance.java",
        "BKTree.java": "https://issues.apache.org/jira/secure/attachment/12431059/BKTree.java"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2010-01-21T20:21:36+0000",
            "content": "First version of BKTree.java ",
            "author": "Fuad Efendi",
            "id": "comment-12803473"
        },
        {
            "date": "2010-01-21T20:27:26+0000",
            "content": "FuzzyTermEnumNEW.java\n\nIn order to use it with Lucene 2.9.1, complie all files (4 files) in a separate JAR file (Java 6).\n\nIn a source distribution of Lucene 2.9.1, modify FuzzyQuery, single method:\n  protected FilteredTermEnum getEnum(IndexReader reader) throws IOException \n{\n    return new FuzzyTermEnumNEW(reader, getTerm(), minimumSimilarity, prefixLength);\n  }\n\n\tand complie it (using default settings such as Java 1.4 compatibility); \"ant jar-core\" will do it.\n\n\n\nUse 2 new jars instead of lucene-core-2.9.1.jar\n\n ",
            "author": "Fuad Efendi",
            "id": "comment-12803476"
        },
        {
            "date": "2010-01-23T02:45:52+0000",
            "content": "Minor bug fixed (with cache warm-up)...\n\nDon't forget to disable QueryResultsCache and to enable large DocumentCache (if you are using SOLR); otherwise you won't see the difference. (SOLR users: there are some other tricks!)\n\nWith Lucene 2.9.1: \n800ms\n\nWith BKTree and Levenstein algo: \n200ms\n\nWith BKTree and http://www.catalysoft.com/articles/StrikeAMatch.html\n70ms\n\nAverage timing after many hours of tests. We may consider \"integer\" distance instead of \"float\" for Lucene Query if we accept this algo; I tried the best to have it close to \"float\" distance.\n\nBKTree is cached at FuzzyTermEnumNEW. It needs warm-up if index changed; simplest way - to recalc it at night (separate thread will do it).\n\n======\nP.S.\n\nFuzzyQuery constructs instance of FuzzyTermEnum and passes instance of IndexReader to constructor. This is the way... If IndexReader changed (new instance) we can simply repopulate BKTree (or, for instance, we can compare list of terms and simply add terms missed in BKTree)... ",
            "author": "Fuad Efendi",
            "id": "comment-12804001"
        },
        {
            "date": "2010-02-03T18:04:17+0000",
            "content": "After long-run load-stress tests...\n\nI used 2 boxes, one with SOLR, another one with simple multithreaded stress simulator (with randomply generated fuzzy query samples); each box is 2x AMD Opteron 2350 (8 core per box); 64-bit.\n\nI disabled all SOLR caches except Document Cache (I want isolated tests; I want to ignore time taken by disk I/O to load document).\n\nPerformance boosted accordingly to number of load-stress threads (on \"client\" computer), then dropped: \n\n9 Threads:\n==========\nTPS: 200 - 210\nResponse: 45 - 50 (ms)\n\n10 Threads:\n===========\nTPS: 200 - 215\nResponse: 45 - 55 (ms)\n\n12 Threads:\n===========\nTPS: 180 - 220\nResponse: 50 - 90 (ms)\n\n16 Threads:\n===========\nTPS: 60 - 65\nResponse: 230 - 260 (ms)\n\n\nIt can be explained by CPU-bound processing and 8 cores available; \"top\" command on SOLR instance was shown 750% - 790% CPU time (8-core) on 3rd step (12 stressing threads), and 200% on 4th step (16 stressing threads) - due probably to Network I/O, Tomcat internals, etc.\n\nIt's better to have Apache HTTPD in front of SOLR in production, with proxy_ajp (persistent connections) and HTTP caching enabled; and fine-tune Tomcat threads according to use case.\n\nBTW, my best counters for default SOLR/Lucene were:\nTPS: 12\nResponse: 750ms\n\n\"Fuzzy\" queries were tuned such a way that distance threshold was less than or equal two. I used \"StrikeAMatch\" distance...\n\nThanks,\nhttp://www.tokenizer.ca\n+1 416-993-2060(cell)\n\nP.S.\nBefore performing load-stress tests, I established the baseline in my environment: 1500 TPS by pinging http://x.x.x.x:8080/apache-solr-1.4/admin/ (static JSP).\nAnd, I reached 220TPS for fuzzy search, starting from 12-15TPS (default Lucene/SOLR)...\n\nP.P.S.\nDistance function must follow 3 'axioms':\n\nD(a,a) = 0\nD(a,b) = D(b,a)\nD(a,b) + D(b,c) >= D(a,c)\n\n\n\nAnd, function must return Integer value.\n\nOtherwise, BKTree will produce wrong results. \n\n\nAlso, it's mentioned somewhere in Levenstein Algo Java Docs (in contrib folder I believe) that instance method runs faster than static method; need to test with Java 6... most probably 'yes', depends on JVM implementation; I can guess only that CPU-internals are better optimized for instance method... ",
            "author": "Fuad Efendi",
            "id": "comment-12829163"
        },
        {
            "date": "2010-02-05T16:45:50+0000",
            "content": "I have tried your patch on lucene 3.0.0. I had to make a small change to get it work. \nIn the current implementation the enumerator is before the first element. This is no problem in lucene 2.9.1 as it simply does one more iteration in FuzzyQuery (rewrite). In lucene 3.0.0 FuzzyQuery directly accesses the first element of the enumeration. As this is null it simply stops further processing of terms (if (t == null) break. \n\nI have made a small change in the FuzzyTermEnumNEW class to assign the first element to the enumerator during creation. I simply appended the following lines within the constructor:\n\n\t\tif (this.termIterator.hasNext()) \n{\n\t\t\tTerm firstTerm = new Term(field, termMap.keySet().iterator().next());\n\t\t\tthis.currentTerm = firstTerm;\n\t\t}\n \n\nThank you for the patch. ",
            "author": "Dirk Goldhan",
            "id": "comment-12830160"
        },
        {
            "date": "2010-02-10T14:20:23+0000",
            "content": "Hi Fuad,\n\nthanks for submitting your changed FuzzyQuery. After quickly looking through the classes I found the following problems:\n\n\n\tThe cache is incorrectly synchronized: The cache is static but access is synchronized against the instance.\n\tThe cache is not limited, maybe it should be a WeakHashMap. It can easily overflow the memory (as it consumes lots of memory).\n\tWhen you build the tree, you use a class from spellchecker: org.apache.lucene.search.spell.LuceneDictionary. This adds an additional memory consumption, esp. if the index has a large term dict. Why not simply iterate over the IndexReaders's TermEnum?\n\tThe cache cannot work correctly with per segment search (since 2.9) or reopened IndexReaders, because it is only bound to the field name but not an index reader. To have a correct cache, do it like FieldCache and use a combined key from field name and IndexReader.getFieldCacheKey().\n\n\n\nElse it looks like a good approach, but the memory consumption is immense for large term dicts. We currently develop a DFA-based FuzzyQuery, which will be provided, when the new flex branch gets out: LUCENE-2089\n\nIf you fix the problems in your classes, we can add this patch to contrib. ",
            "author": "Uwe Schindler",
            "id": "comment-12832001"
        },
        {
            "date": "2010-02-10T15:28:50+0000",
            "content": "Hi Uwe,\n\n\nThanks for the analysis! I spent only few days on this basic PoC.\n\nI need to use IndexReader (index version number and etc.) also to rewarm a cache; if term disappeared from index we can still leave it in BKTree (not a problem; can't remove!), and if we have new term we need simply call \n\npublic void add(E term)\n\n\nSynchronization should be significantly improved...\n\nCache warming takes 10-15 seconds in my environment, about 250k tokens, and I use TreeSet internally for fast lookup. I also believe that main performance issue is related to Levenstein algo (which is significantly improved in trunk; plus synchronization is removed from FuzzySearch: LUCENE-2258)\n\nRegarding memory requirements: BKTree is not heavy... I should use \n\nStringHelper.intern(fld);\n\n\n\tit's already in memory... and FuzzyTermEnum uses almost same amount of memory for processing as BKTree. I'll check FieldCache.\n\n\n\nBKTree-approach can be significantly improved. ",
            "author": "Fuad Efendi",
            "id": "comment-12832027"
        },
        {
            "date": "2010-02-10T16:35:37+0000",
            "content": "Hi Fuad,\n\nOk thanks for the explanation about the cache. But there should still be some eviction algorithm or at least a WeakHashmap so the JVM can cleanup the cache for unused fields. My problem with IndexReaders missing in the cache logic was that if you reopen the index, the BKTree contains terms no longer available and the FuzzyTermEnum enumerates terms that are no longer available. This is bad parctise and should not be done in query rewrite. So enumerating terms with no relation to a real term dict is not really supported by MultiTermQuery, but works for fuzzy, because it does not use the low level segment-based term enumeration and linkage to TermDocs.\n\nThe new LUCENE-2258 issue needs no warmup, as it uses a different algorithm for the Levenstein algorithm and also does not scan the whole term dict. By the way, in flex also RegEx queries and Wildcard queries are speed up. The problem with trunk not having this automaton package used for that is the problem, that the AutomatonTermsEnum used for that needs to do lots of seeking in the TermsEnum, which is improved in flex and we do not want to do the work twice.\n\nFlex has a completely different API on the enum side, so TermEnumerations work different and so on. ",
            "author": "Uwe Schindler",
            "id": "comment-12832055"
        },
        {
            "date": "2010-02-10T17:55:34+0000",
            "content": "Hi Uwe,\n\n\nI am trying to study LUCENE-2258 right now...\n\nBKTree contains terms no longer available\n\nBKTree contains objects, not terms; in my sample it contains Strings, new BKTree<String>(new Distance()). It is a structure for fast lookup of close objects from a set of objects, with predefined distance algorithm.\n\nIt won't hurt if String appears in BKTree structure, and corresponding Term disappeared from Index; search results will be the same. Simply, search for <DisappearedTerm> OR <AnotherTerm> is the same as search for <AnotherTerm>.\nAt least, we can run background thread which will create new BKTree instance, without hurting end users.\n\nYes, Term<->String is another thing to do... I recreate fake terms in TermEnum...\n\n\n\nBKTree allows to iterate about 5-10% of whole structure in order to find closest matches only if distance threshold is small, 2. If it is 4, almost no any improvement. And, classic Levenshtein distance is slow...\n\nEdited: trying to study LUCENE-2089... ",
            "author": "Fuad Efendi",
            "id": "comment-12832096"
        },
        {
            "date": "2010-02-12T14:25:48+0000",
            "content": "LUCENE-2089 - extremely good staff (Lucene-Flex branch, applicable for wildcard-queries, RegEx, and Fuzzy Search). BKTree improves performance if distance is 2; otherwise it is almost full-term-scan.\nSome links borrowed:\nhttp://en.wikipedia.org/wiki/Deterministic_finite-state_machine\nhttp://rcmuir.wordpress.com/2009/12/04/finite-state-queries-for-lucene/\nhttp://www.amazon.com/Algorithms-Strings-Trees-Sequences-Computational/dp/0521585198 ",
            "author": "Fuad Efendi",
            "id": "comment-12833010"
        },
        {
            "date": "2010-07-05T00:33:56+0000",
            "content": "Could this or a similar technique improve searches for things that use both leading and trailing wildcards - like a search for 'ildcar'?\n ",
            "author": "Ron Mayer",
            "id": "comment-12885087"
        },
        {
            "date": "2011-05-17T19:43:13+0000",
            "content": "I believe this issue should be closed due to significant performance improvements related to LUCENE-2089 and LUCENE-2258.\nI don't think there is any interest from the community to continue with this (BK Tree and \"Strike a Match\") naive approach; although some people found it useful. Of course we might have few more distance implementations as a separate improvement.\n\nPlease close it.\n\n\nThanks ",
            "author": "Fuad Efendi",
            "id": "comment-13034999"
        }
    ]
}