{
    "id": "LUCENE-5638",
    "title": "Default Attributes are expensive",
    "details": {
        "type": "Bug",
        "priority": "Major",
        "labels": "",
        "resolution": "Fixed",
        "components": [
            "modules/analysis"
        ],
        "affect_versions": "None",
        "status": "Resolved",
        "fix_versions": [
            "4.9",
            "6.0"
        ]
    },
    "description": "Changes like LUCENE-5634 make it clear that the default AttributeFactory stuff has a very high cost: weakmaps/reflection/etc.\n\nAdditionally I think clearAttributes() is more expensive than it should be: it has to traverse a linked-list, calling clear() per token.\n\nOperations like cloning (save/restoreState) have a high cost tll.\n\nMaybe we can have a better Default? In other words, rename DEFAULT_ATTRIBUTE_FACTORY to REFLECTION_ATTRIBUTE_FACTORY, and instead have a faster default factory that just has one AttributeImpl with the \"core ones\" that 95% of users are dealing with (TOKEN_ATTRIBUTE_FACTORY?): anything outside of that falls back to reflection.",
    "attachments": {
        "LUCENE-5638.patch": "https://issues.apache.org/jira/secure/attachment/12643137/LUCENE-5638.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "id": "comment-13987965",
            "author": "Uwe Schindler",
            "content": "Changes like LUCENE-5634 make it clear that the default AttributeFactory stuff has a very high cost: weakmaps/reflection/etc.\n\nThe problem are not the weak maps and reflections. The reason why it is expensive is the fact that all attribute instances have to be put into the 2 LinkedHashMaps on creating the TokenStream. I just repeat: It is not the refection! We had this discussion already back 5 years ago with Michael Busch!\n\nIn addition, the AttributeFactory itsself has less impact (this was already tested while developing it in 2.9). This is why the weak maps are there - so it is fast, the only reflection ever happens is: Class#newInstance() is cheap in recent Java versions, the speed difference in micro benchmarks is small, as fast as a native new.\n\nSo I disagree with removing the default AttributeFactory, we still need it for non-default attributes, so: The simple workaround would be to use TOKEN_ATTRIBUTE_FACTORY instead, which falls back to the default one for unknown attributes.\n\nI agree with clearAttributes(), but this should be solved with TOKEN_ATTRIBUTE_FACTORY , too. ",
            "date": "2014-05-02T17:16:39+0000"
        },
        {
            "id": "comment-13988319",
            "author": "Uwe Schindler",
            "content": "Easy and simple one-line patch.\n\nThis uses the Token class as attributes impl, which supports:\n\npublic class Token extends CharTermAttributeImpl \n                   implements TypeAttribute, PositionIncrementAttribute,\n                              FlagsAttribute, OffsetAttribute, PayloadAttribute, PositionLengthAttribute {\n\n\nStrangely, this test fails:\n\n\n[junit4] Tests with failures:\n[junit4]   - org.apache.lucene.analysis.TestGraphTokenizers.testMockGraphTokenFilterOnGraphInput\n[junit4]\n\n\n\nSo this one seems to catch some bug in Token.java or the test does not work with this attribute impl (maybe it copies/clones in a wrong way). ",
            "date": "2014-05-02T22:02:28+0000"
        },
        {
            "id": "comment-13988330",
            "author": "Uwe Schindler",
            "content": "I found the bug: Token implemented PositionLengthAttribute but missed to implement all the clone/copyTo/equals/... shit. I willheavy commit that, because its a bug. ",
            "date": "2014-05-02T22:11:42+0000"
        },
        {
            "id": "comment-13988337",
            "author": "Uwe Schindler",
            "content": "I created a subtask: LUCENE-5639 ",
            "date": "2014-05-02T22:18:55+0000"
        },
        {
            "id": "comment-13988377",
            "author": "Uwe Schindler",
            "content": "In analysis module, TestWikipediaTokenizer also fails, we have to dig. I don't understand the failure. ",
            "date": "2014-05-02T22:50:12+0000"
        },
        {
            "id": "comment-13988378",
            "author": "Uwe Schindler",
            "content": "I also created another subtask to clean up the Token class and remove stupid copy-ctors and all those reinit() methods. Unmaintainable! LUCENE-5640 ",
            "date": "2014-05-02T22:51:12+0000"
        },
        {
            "id": "comment-13988707",
            "author": "Robert Muir",
            "content": "I benchmarked this patch against trunk with luceneutil's TestAnalyzerPerf.java.\n\nI ran 3 runs of it against both trunk and patch (because its quite noisy), but I think it shows a trend:\nespecially for ones like Shingles doing lots of saveState()/restoreState() and ones like n-grams calling clearAttributes() many times.\n\nTimes are reported in milliseconds to analyze en-wiki linedocs file: lower is better.\n\n\n\n\nStandard\nRun 1\nRun 2\nRun 3\n\n\ntrunk\n22983.37\n23680.52\n27390.50\n\n\npatch\n21303.90\n21419.21\n21351.63\n\n\n\n\n\n\n\n\nLowerCase\nRun 1\nRun 2\nRun 3\n\n\ntrunk\n18032.37\n17795.05\n17533.72\n\n\npatch\n16688.78\n17267.51\n16650.72\n\n\n\n\n\n\n\n\nEdgeNGrams\nRun 1\nRun 2\nRun 3\n\n\ntrunk\n40774.93\n38842.67\n53023.12\n\n\npatch\n30798.36\n31389.50\n31799.47\n\n\n\n\n\n\n\n\nShingles\nRun 1\nRun 2\nRun 3\n\n\ntrunk\n75702.71\n75594.85\n82081.14\n\n\npatch\n49572.20\n58220.35\n48895.09\n\n\n\n\n\n\n\n\nWordDelimiter\nRun 1\nRun 2\nRun 3\n\n\ntrunk\n40101.05\n38491.25\n46736.42\n\n\npatch\n30995.33\n31743.91\n30488.61\n\n\n\n\n\nAbout the patch: there are more Tokenizers in the analysis/ module referring to DEFAULT_ATTRIBUTE_FACTORY directly today (because they all have ctors to pass in a custom factory). So we should fix those too. ",
            "date": "2014-05-03T14:49:12+0000"
        },
        {
            "id": "comment-13988726",
            "author": "Robert Muir",
            "content": "Updated patch: I added it to other tokenizers, i also got MockTokenizer using it by default and randomize between DEFAULT and TOKEN attribute factories in TestRandomChains.\n\nThere were some test failures in TestPayloads, because they asserted PayloadAttribute was not present. I just removed the assertions.\n\nI will look for other failures and also inspect FreqProxTermsWriter to ensure it is optimized for the case where payloadAtt != null but returns null every time, and benchmark indexing somehow with the patch.\n ",
            "date": "2014-05-03T16:01:22+0000"
        },
        {
            "id": "comment-13988730",
            "author": "Robert Muir",
            "content": "Core tests are passing. Some analysis/common tests fail:\n\n   [junit4] Tests with failures:\n   [junit4]   - org.apache.lucene.analysis.wikipedia.WikipediaTokenizerTest.testRandomStrings\n   [junit4]   - org.apache.lucene.analysis.wikipedia.WikipediaTokenizerTest.testRandomHugeStrings\n   [junit4]   - org.apache.lucene.analysis.miscellaneous.TestWordDelimiterFilter.testRandomStrings\n   [junit4]   - org.apache.lucene.analysis.miscellaneous.TestWordDelimiterFilter.testRandomHugeStrings\n   [junit4]   - org.apache.lucene.analysis.path.TestPathHierarchyTokenizer.testRandomStrings\n   [junit4]   - org.apache.lucene.analysis.path.TestPathHierarchyTokenizer.testRandomHugeStrings\n   [junit4]   - org.apache.lucene.analysis.path.TestReversePathHierarchyTokenizer.testRandomStrings\n   [junit4]   - org.apache.lucene.analysis.path.TestReversePathHierarchyTokenizer.testRandomHugeStrings\n\n\n\nLooking into these now... ",
            "date": "2014-05-03T16:09:13+0000"
        },
        {
            "id": "comment-13988977",
            "author": "Robert Muir",
            "content": "Now that tests are sorted out: here is an updated patch. ",
            "date": "2014-05-04T12:43:18+0000"
        },
        {
            "id": "comment-13988991",
            "author": "Robert Muir",
            "content": "Updated patch: all tests (and precommit) pass.\n\nI benchmarked indexing with various types of fields, the change actually gives a speedup even to StringFields (i suppose from faster clearAttributes?)\n\nThis is ready to commit. ",
            "date": "2014-05-04T14:22:49+0000"
        },
        {
            "id": "comment-13988995",
            "author": "Uwe Schindler",
            "content": "+1 We shoudl fix the Token subtask, too. Most of work is done, but maybe we split Token up.\n\nAnd: We should remove FlagsAttrbute! ",
            "date": "2014-05-04T14:31:06+0000"
        },
        {
            "id": "comment-13988998",
            "author": "ASF subversion and git services",
            "content": "Commit 1592353 from Robert Muir in branch 'dev/trunk'\n[ https://svn.apache.org/r1592353 ]\n\nLUCENE-5638: pack the core attributes into one impl by default ",
            "date": "2014-05-04T14:36:29+0000"
        },
        {
            "id": "comment-13989012",
            "author": "ASF subversion and git services",
            "content": "Commit 1592357 from Robert Muir in branch 'dev/branches/branch_4x'\n[ https://svn.apache.org/r1592357 ]\n\nLUCENE-5638: pack the core attributes into one impl by default ",
            "date": "2014-05-04T15:22:46+0000"
        },
        {
            "id": "comment-13989525",
            "author": "Uwe Schindler",
            "content": "More improvements to the DefaultAttributeFactory are developed in the subtask: LUCENE-5640 (using Java 7 MethodHandles) ",
            "date": "2014-05-05T13:46:25+0000"
        }
    ]
}