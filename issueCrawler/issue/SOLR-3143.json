{
    "id": "SOLR-3143",
    "title": "Supply a phrase-oriented QueryConverter for Suggesters",
    "details": {
        "affect_versions": "None",
        "status": "Closed",
        "fix_versions": [
            "3.6",
            "4.0-ALPHA"
        ],
        "components": [
            "spellchecker"
        ],
        "type": "New Feature",
        "priority": "Major",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "The supplied QueryConverter makes sense for Spellcheckers:\nit tries to parse out the 'meat' of the query (using e.g. identifier rules), \nand analyzes each parsed 'word' with the configured analyzer (separate tokenstream).\n\n\nwords[] = splitByIdentifierRules();\nfor (each word) {\n tokenstream ts = analyzer.tokenStream(word)\n for (each analyzedWord from tokenstream) {\n   tokens.add(analyzedWord)\n }\n}\n\n\n\nHowever, for Suggesters this is not really optimal, because in the general\ncase they do not work one word at a time: they aren't really suggesting \nindividual words but instead an entire 'query' that matches a prefix.\n\nso instead here, I think we just want a QueryConverter that creates a \nsingle string containing all the 'meat', and we pass the whole thing to \nthe analyzer, then the suggester.\n\nThe current workaround on the wiki to this problem, is to ask the user to write custom\ncode (http://wiki.apache.org/solr/Suggester#Tips_and_tricks), I think thats not \ngreat since this phrase-based suggesting is really the primary use case for\nsuggesters.",
    "attachments": {
        "SOLR-3143.patch": "https://issues.apache.org/jira/secure/attachment/12515246/SOLR-3143.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Robert Muir",
            "id": "comment-13211850",
            "date": "2012-02-20T14:03:55+0000",
            "content": "Wow, phrase suggestions are ridiculously complicated to get working.\n\nI think we need to add some configuration to the example (maybe commented out), because in my opinion this is really the default use case... but its a lot of configuration and the biggest traps imo are:\n\n\n\tYou need to write a custom queryconverter in java code (i provide one in this patch) configured as a plugin, and set as queryConverter (is this global or is there a way to set this per-suggester?!)\n\tYou need to make sure onlyMorePopular is true, even though it says it doesn't affect file-based spellcheckers, thats a lie. This controls whether results are alpha-sorted or ordered by relevance!\n\t(Assuming your queryConverter is well-behaved and respects the analyzer), You need to define a custom fieldType in schema.xml, even though its likely not used by any actual solr fields, that uses KeywordTokenizer + lowercase or whatever you want, and set this via queryAnalyzerFieldType. If you don't do this, it will default to whitespacetokenizer.\n\n\n\nAnyway, attached is my patch, basically its a QueryConverter that just passes the whole string as-is to the query analyzer.\n\nIn my test analyzer config, i added a horrible regexp that tries to emulate what google's autocomplete seems to do: lowercase, collapse runs of whitespace, remove query syntax etc.\n\nBut maybe for a lot of people thats even overkill and they could just use Keyword+Lowercase or whatever. "
        }
    ]
}