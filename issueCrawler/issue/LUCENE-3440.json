{
    "id": "LUCENE-3440",
    "title": "FastVectorHighlighter: IDF-weighted terms for ordered fragments",
    "details": {
        "labels": "",
        "priority": "Minor",
        "components": [
            "modules/highlighter"
        ],
        "type": "Improvement",
        "fix_versions": [
            "4.0-ALPHA",
            "6.0"
        ],
        "affect_versions": "None",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "The FastVectorHighlighter uses for every term found in a fragment an equal weight, which causes a higher ranking for fragments with a high number of words or, in the worst case, a high number of very common words than fragments that contains all of the terms used in the original query. \n\nThis patch provides ordered fragments with IDF-weighted terms: \n\ntotal weight = total weight + IDF for unique term per fragment * boost of query; \n\nThe ranking-formula should be the same, or at least similar, to that one used in org.apache.lucene.search.highlight.QueryTermScorer.\n\nThe patch is simple, but it works for us. \n\nSome ideas:\n\n\tA better approach would be moving the whole fragments-scoring into a separate class.\n\tSwitch scoring via parameter\n\tExact phrases should be given a even better score, regardless if a phrase-query was executed or not\n\tedismax/dismax-parameters pf, ps and pf^boost should be observed and corresponding fragments should be ranked higher",
    "attachments": {
        "weight-vs-boost_table01.html": "https://issues.apache.org/jira/secure/attachment/12497628/weight-vs-boost_table01.html",
        "weight-vs-boost_table02.html": "https://issues.apache.org/jira/secure/attachment/12497629/weight-vs-boost_table02.html",
        "LUCENE-4.0-SNAPSHOT-3440-9.patch": "https://issues.apache.org/jira/secure/attachment/12499363/LUCENE-4.0-SNAPSHOT-3440-9.patch",
        "LUCENE-3440.patch": "https://issues.apache.org/jira/secure/attachment/12500589/LUCENE-3440.patch",
        "LUCENE-3440_3.6.1-SNAPSHOT.patch": "https://issues.apache.org/jira/secure/attachment/12525584/LUCENE-3440_3.6.1-SNAPSHOT.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2011-09-20T09:34:57+0000",
            "content": "Works for lucene_solr_branch_3x. ",
            "author": "Sebastian Lutze",
            "id": "comment-13108474"
        },
        {
            "date": "2011-09-20T19:18:19+0000",
            "content": "Ups, wrong patch ... here's the right one. ",
            "author": "Sebastian Lutze",
            "id": "comment-13108945"
        },
        {
            "date": "2011-09-22T00:32:00+0000",
            "content": "I think this is an interesting point of view, thanks! But I couldn't apply the patch to the latest trunk:\n\n\n[koji@MacBook LUCENE-3440]$ patch -p0 --dry-run < LUCENE-3440.patch \npatching file lucene/contrib/highlighter/src/java/org/apache/lucene/search/vectorhighlight/FieldFragList.java\npatching file lucene/contrib/highlighter/src/java/org/apache/lucene/search/vectorhighlight/FieldPhraseList.java\npatching file lucene/contrib/highlighter/src/java/org/apache/lucene/search/vectorhighlight/FieldTermStack.java\nHunk #1 FAILED at 31.\nHunk #2 FAILED at 96.\nHunk #3 FAILED at 108.\nHunk #4 succeeded at 148 (offset -9 lines).\n3 out of 4 hunks FAILED -- saving rejects to file lucene/contrib/highlighter/src/java/org/apache/lucene/search/vectorhighlight/FieldTermStack.java.rej\n\n\n\nCan you verify that? ",
            "author": "Koji Sekiguchi",
            "id": "comment-13112261"
        },
        {
            "date": "2011-09-22T11:22:50+0000",
            "content": "No, can't verify that. It's my first patch, maybe I did something wrong. The patch is built from branch_3x with the subversion-plug-in for Eclipse.  I took the todays branch_3x (Import -> SVN -> Checkout projects ...) a few minutes ago and patched it (Team -> Apply patch). No problem with my setup. \n\nAnother approach:\n\nAssuming a user searches for a single word, he rather would like to see fragments with a culmination of that word:\n\nBoost with number of distinct terms per fragment\nfor( WeightedPhraseInfo phraseInfo : phraseInfoList ){\n SubInfo subInfo = new SubInfo( phraseInfo.text, phraseInfo.termsOffsets, phraseInfo.seqnum );\n subInfos.add( subInfo );\n        \n Iterator it = phraseInfo.termInfos.iterator();\n TermInfo ti;\n        \n while ( it.hasNext() ) {\n  ti = ( TermInfo ) it.next();\n  distinctTerms.add( ti.text );\n  totalBoost += ti.weight * phraseInfo.boost;\n }\n}\ntotalBoost *= distinctTerms.size();\n\n\n\n ",
            "author": "Sebastian Lutze",
            "id": "comment-13112481"
        },
        {
            "date": "2011-09-22T11:48:47+0000",
            "content": "Ah, I see. I saw trunk, but you made the patch for 3x. I'll see. ",
            "author": "Koji Sekiguchi",
            "id": "comment-13112490"
        },
        {
            "date": "2011-09-22T20:43:14+0000",
            "content": "Here another patch. \n\n\n\tThe calculation of WeightedFragInfo.totalBoost remains unmodified\n\tA new field WeightedFragInfo.totalWeight has been introduced\n\tA class WeightOrderFragmentsBuilder sorts now by WeightedFragInfo.totalWeight\n\n ",
            "author": "Sebastian Lutze",
            "id": "comment-13112887"
        },
        {
            "date": "2011-09-23T01:06:06+0000",
            "content": "Hi,\n\n\n\tWhich patch do you want me to try?\n\tCan you make that for trunk branch?\n\n ",
            "author": "Koji Sekiguchi",
            "id": "comment-13113086"
        },
        {
            "date": "2011-09-23T12:32:37+0000",
            "content": "Patch for branch_3x. ",
            "author": "Sebastian Lutze",
            "id": "comment-13113368"
        },
        {
            "date": "2011-09-23T12:33:48+0000",
            "content": "Patch for trunk. ",
            "author": "Sebastian Lutze",
            "id": "comment-13113369"
        },
        {
            "date": "2011-09-23T12:54:09+0000",
            "content": "Hi Koji,\n\n1. Which patch do you want me to try?\n\nDoesn't matter. First time I took the trunk for a long time. I'm looking forward to the new admin-interface in solr/lucene-4.0! \n\n2. Can you make that for trunk branch?\n\nHere we go. This Version is slightly different, the weight is now boosted by the normalized number of terms per fragment:\n\n\nfor( WeightedPhraseInfo phraseInfo : phraseInfoList ){\n SubInfo subInfo = new SubInfo( phraseInfo.text, phraseInfo.termsOffsets, phraseInfo.seqnum );\n subInfos.add( subInfo );   \n Iterator it = phraseInfo.termInfos.iterator();\n TermInfo ti;    \n totalBoost += phraseInfo.boost;      \n while ( it.hasNext() ) {\n  ti = ( TermInfo ) it.next();\n  if ( uniqueTerms.add( ti.text ) )\n   totalWeight += Math.pow(ti.weight, 2) * phraseInfo.boost;\n  termsPerFrag++;\n  }\n }     \n}\ntotalWeight *= termsPerFrag * ( 1 / Math.sqrt( termsPerFrag ) );\n\n\n\nDue to a significant lack of mathematical knowledge, a very intuitive solution. \nBut it seems to work very well, at least for our data (highly multi-lingual, mostly historical, dirty OCRed, books, journals + papers).   ",
            "author": "Sebastian Lutze",
            "id": "comment-13113389"
        },
        {
            "date": "2011-09-24T02:17:59+0000",
            "content": "Patch looks great! A few comments:\n\n\n\tFor the new totalWeight, add getter method and modify toString() in WeightedFragInfo().\n\tThe patch uses hard-coded DefaultSimilarity to calculate idf. I don't think that a custom similarity can be used here, too. If so, how about just copying idf method rather than creating a similarity object?\n\tPlease do not hesitate to update ScoreComparator (do not add WeightOrderFragmentsBuilder)\n\tCould you update package javadoc ( https://builds.apache.org//job/Lucene-trunk/javadoc/contrib-highlighter/org/apache/lucene/search/vectorhighlight/package-summary.html#package_description ) and insert totalWeight into description and figures.\n\tuse docFreq(String field, BytesRef term) version for trunk to avoid creating Term object.\n\n\n\nDue to a significant lack of mathematical knowledge, a very intuitive solution. \n\nI agree. I think if there is a table so that we can compare totalBoost (current) and totalWeight (patch) with real values, it helps a lot. ",
            "author": "Koji Sekiguchi",
            "id": "comment-13113873"
        },
        {
            "date": "2011-09-25T16:51:18+0000",
            "content": "Patch looks great! \n\nThanks.  \n\n1. For the new totalWeight, add getter method and modify toString() in WeightedFragInfo().\n\nOkay.\n\n2. The patch uses hard-coded DefaultSimilarity to calculate idf. I don't think that a custom similarity can be used here, too. If so, how about just copying idf method rather than creating a similarity object?\n\nI played a little with log(numDocs - docFreq  + 0.5 / docFreq + 0.5) but is seems to make no difference. If I'm not mistaken there is no method IndexReader.getSimilarity() or IndexReader.getDefaultSimilarity(). \n\nTherefore: Okay. \n\n3. Please do not hesitate to update ScoreComparator (do not add WeightOrderFragmentsBuilder) \n\nHm, I thought about something like that: \n\n\n<highlighting>\n  <fragmentsBuilder name=\"ordered\" class=\"org.apache.solr.highlight.ScoreOrderFragmentsBuilder\" default=\"false\"/>\n  <fragmentsBuilder name=\"weighted\" class=\"org.apache.solr.highlight.WeightOrderFragmentsBuilder\" default=\"true\"/>\n</highlighting>\n\n\n\nFor Solr-users (like me). If somebody would like to use the boost-based ordering, he could. Maybe, for some use-cases the boost-based approach is better than the weighted one.  \n\n4 Could you update package javadoc ( https://builds.apache.org//job/Lucene-trunk/javadoc/contrib-highlighter/org/apache/lucene/search/vectorhighlight/package-summary.html#package_description ) and insert totalWeight into description and figures.\n\nOkay. \n\n5. use docFreq(String field, BytesRef term) version for trunk to avoid creating Term object.\n\nOkay. \n\nI agree. I think if there is a table so that we can compare totalBoost (current) and totalWeight (patch) with real values, it helps a lot.\n\nI'll write some Proof-of-concept Test-Class. But this may take some time. \n\n\nI discovered a little problem with overlapping terms, depending on the analyzing-process:\n\nWeightedPhraseInfo.addIfNoOverlap() dumps the second part of hyphenated words (for example: social-economics). The result is that all informations in TermInfo are lost and not available for computing the fragments weight. I simple modified WeightedPhraseInfo.addIfNoOverlap() a little to change this behavior: \n\n\nvoid addIfNoOverlap( WeightedPhraseInfo wpi ){\n for( WeightedPhraseInfo existWpi : phraseList ){\n  if( existWpi.isOffsetOverlap( wpi ) ) {\n   existWpi.termInfos.addAll( wpi.termInfos );\n   return;\n  }\n }\n phraseList.add( wpi );\n}\n\n\n\nBut I am not sure if there could be some unforeseen site-effects? \n\n\n\n\n ",
            "author": "Sebastian Lutze",
            "id": "comment-13114291"
        },
        {
            "date": "2011-09-25T23:54:17+0000",
            "content": "\nHm, I thought about something like that: \n\n\n<highlighting>\n  <fragmentsBuilder name=\"ordered\" class=\"org.apache.solr.highlight.ScoreOrderFragmentsBuilder\" default=\"false\"/>\n  <fragmentsBuilder name=\"weighted\" class=\"org.apache.solr.highlight.WeightOrderFragmentsBuilder\" default=\"true\"/>\n</highlighting>\n\n\n\nFor Solr-users (like me). If somebody would like to use the boost-based ordering, he could. Maybe, for some use-cases the boost-based approach is better than the weighted one.  \n\nI thought that, too. But I saw the following in the patch:\n\n\npublic List<WeightedFragInfo> getWeightedFragInfoList( List<WeightedFragInfo> src ) {\n    Collections.sort( src, new ScoreComparator() );\n//    Collections.sort( src, new WeightComparator() );\n    return src;\n}\n\n\n\nAnd I thought you wanted to use WeightComparator from ScoreOrderFragmentsBuilder. \n\nWell now, let's introduce WeightOrderFragmentsBuilder. ",
            "author": "Koji Sekiguchi",
            "id": "comment-13114402"
        },
        {
            "date": "2011-09-30T12:07:54+0000",
            "content": "Patch for 3.5. Docs are still missing.  ",
            "author": "Sebastian Lutze",
            "id": "comment-13118006"
        },
        {
            "date": "2011-09-30T12:09:41+0000",
            "content": "WeightOrderFragmentsBuilder_table01.html:\nA one-word-query for 'testament'. Obviously, the sum-of-distinct-weights-approach makes no difference to the existing one. ",
            "author": "Sebastian Lutze",
            "id": "comment-13118007"
        },
        {
            "date": "2011-09-30T12:10:35+0000",
            "content": "WeightOrderFragmentsBuilder_table02.html:\nA more-word-query for 'das alte testament'. Obviously, the sum-of-boosts-approach scores \"das das das das\" higher than \"das alte testament\".  ",
            "author": "Sebastian Lutze",
            "id": "comment-13118009"
        },
        {
            "date": "2011-09-30T12:13:45+0000",
            "content": "LUCENE-3.5-SNAPSHOT-3440-6-ProofOfConcept.java:\nThe two tables are created by this simple class. I took, representatively, some single pages as documents from our book-stock to build a \"bag-of-words\".  ",
            "author": "Sebastian Lutze",
            "id": "comment-13118010"
        },
        {
            "date": "2011-09-30T12:18:52+0000",
            "content": "Hm, I tried to do that all with trunk but: \n\n\n29.09.2011 15:43:09 org.apache.solr.common.SolrException log\nSEVERE: java.lang.VerifyError: class org.apache.lucene.analysis.ReusableAnalyzerBase overrides final method tokenStream.(Ljava/lang/String;Ljava/io/Reader;)Lorg/apache/lucene/analysis/TokenStream;\n\tat java.lang.ClassLoader.defineClass1(Native Method)\n\tat java.lang.ClassLoader.defineClassCond(ClassLoader.java:632)\n\tat java.lang.ClassLoader.defineClass(ClassLoader.java:616)\n\tat java.security.SecureClassLoader.defineClass(SecureClassLoader.java:141)\n\tat org.apache.catalina.loader.WebappClassLoader.findClassInternal(WebappClassLoader.java:2733)\n\tat org.apache.catalina.loader.WebappClassLoader.findClass(WebappClassLoader.java:1124)\n\tat org.apache.catalina.loader.WebappClassLoader.loadClass(WebappClassLoader.java:1612)\n\tat org.apache.catalina.loader.WebappClassLoader.loadClass(WebappClassLoader.java:1491)\n\tat java.lang.ClassLoader.defineClass1(Native Method)\n\tat java.lang.ClassLoader.defineClassCond(ClassLoader.java:632)\n\tat java.lang.ClassLoader.defineClass(ClassLoader.java:616)\n\tat java.security.SecureClassLoader.defineClass(SecureClassLoader.java:141)\n\tat org.apache.catalina.loader.WebappClassLoader.findClassInternal(WebappClassLoader.java:2733)\n\tat org.apache.catalina.loader.WebappClassLoader.findClass(WebappClassLoader.java:1124)\n\tat org.apache.catalina.loader.WebappClassLoader.loadClass(WebappClassLoader.java:1612)\n\tat org.apache.catalina.loader.WebappClassLoader.loadClass(WebappClassLoader.java:1491)\n\tat java.lang.Class.forName0(Native Method)\n\tat java.lang.Class.forName(Class.java:247)\n\tat org.apache.solr.core.SolrResourceLoader.findClass(SolrResourceLoader.java:403)\n\tat org.apache.solr.core.SolrCore.createInstance(SolrCore.java:407)\n\tat org.apache.solr.core.SolrCore.createInitInstance(SolrCore.java:456)\n\tat org.apache.solr.core.SolrCore.initPlugins(SolrCore.java:1653)\n\tat org.apache.solr.core.SolrCore.initPlugins(SolrCore.java:1647)\n\tat org.apache.solr.core.SolrCore.initPlugins(SolrCore.java:1680)\n\tat org.apache.solr.core.SolrCore.loadSearchComponents(SolrCore.java:875)\n\tat org.apache.solr.core.SolrCore.<init>(SolrCore.java:574)\n\tat org.apache.solr.core.SolrCore.<init>(SolrCore.java:507)\n\tat org.apache.solr.core.CoreContainer.create(CoreContainer.java:653)\n\tat org.apache.solr.core.CoreContainer.load(CoreContainer.java:407)\n\tat org.apache.solr.core.CoreContainer.load(CoreContainer.java:292)\n\tat org.apache.solr.core.CoreContainer$Initializer.initialize(CoreContainer.java:241)\n\tat org.apache.solr.servlet.SolrDispatchFilter.init(SolrDispatchFilter.java:93)\n\tat org.apache.catalina.core.ApplicationFilterConfig.getFilter(ApplicationFilterConfig.java:295)\n\tat org.apache.catalina.core.ApplicationFilterConfig.setFilterDef(ApplicationFilterConfig.java:422)\n\tat org.apache.catalina.core.ApplicationFilterConfig.<init>(ApplicationFilterConfig.java:115)\n\tat org.apache.catalina.core.StandardContext.filterStart(StandardContext.java:4001)\n\tat org.apache.catalina.core.StandardContext.start(StandardContext.java:4651)\n\tat org.apache.catalina.core.ContainerBase.start(ContainerBase.java:1045)\n\tat org.apache.catalina.core.StandardHost.start(StandardHost.java:785)\n\tat org.apache.catalina.core.ContainerBase.start(ContainerBase.java:1045)\n\tat org.apache.catalina.core.StandardEngine.start(StandardEngine.java:445)\n\tat org.apache.catalina.core.StandardService.start(StandardService.java:519)\n\tat org.apache.catalina.core.StandardServer.start(StandardServer.java:710)\n\tat org.apache.catalina.startup.Catalina.start(Catalina.java:581)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n\tat java.lang.reflect.Method.invoke(Method.java:597)\n\tat org.apache.catalina.startup.Bootstrap.start(Bootstrap.java:289)\n\tat org.apache.catalina.startup.Bootstrap.main(Bootstrap.java:414)\n\n ",
            "author": "Sebastian Lutze",
            "id": "comment-13118012"
        },
        {
            "date": "2011-09-30T12:36:45+0000",
            "content": "WeightOrderFragmentsBuilder_table01.html:\nA one-word-query for testament. Obviously, the sum-of-distinct-weights-approach makes no difference to the existing one.\n\n\n\n\nTerms in fragment\ntotalWeight\ntotalBoost\n\n\ntestament testament\n1.8171139\n2.0\n\n\ntestament\n1.2848935\n1.0\n\n\ntestament\n1.2848935\n1.0\n\n\ntestament\n1.2848935\n1.0\n\n\ntestament\n1.2848935\n1.0\n\n\ntestament\n1.2848935\n1.0\n\n\n\n\n\n\n\nWeightOrderFragmentsBuilder_table02.html:\nA multi-word-query for das alte testament. Obviously, the sum-of-boosts-approach scores das das das das higher than das alte testament.\n\n\n\n\nTerms in fragment\ntotalWeight\ntotalBoost\n\n\ndas alte testament\n5.799069\n3.0\n\n\ndas alte testament\n5.799069\n3.0\n\n\ndas testament alte\n5.799069\n3.0\n\n\ndas alte testament\n5.799069\n3.0\n\n\ndas testament\n2.9178061\n2.0\n\n\ndas alte\n2.9178061\n2.0\n\n\ntestament testament\n1.8171139\n2.0\n\n\ndas das das das\n1.5566137\n4.0\n\n\ndas das das\n1.348067\n3.0\n\n\nalte\n1.2848935\n1.0\n\n\nalte\n1.2848935\n1.0\n\n\ndas das\n1.100692\n2.0\n\n\ndas das\n1.100692\n2.0\n\n\ndas\n0.77830684\n1.0\n\n\ndas\n0.77830684\n1.0\n\n\ndas\n0.77830684\n1.0\n\n\ndas\n0.77830684\n1.0\n\n\ndas\n0.77830684\n1.0\n\n\n\n\n\n ",
            "author": "Sebastian Lutze",
            "id": "comment-13118023"
        },
        {
            "date": "2011-10-01T12:47:14+0000",
            "content": "Here's the patch for 4.0. I forgot to update my Solr-plugin-lib to 4.0-SNAPSHOT.  \n\nAnother patch, another idea! \n\nSome thoughts: \n\n\tWith the last patch, sum-of-distinct-weights will be calculated anyhow, even if ScoreOrderFragmentsBuilder is used.\n\tAlso regardless of further calculations, FieldTermsStack retrieves document frequency for each term from IndexReader in any case.\n\tSolr-Developers have no chance to implement a FragmentsBuilder-plugin with their custom-scoring for fragments, because the weighting-formula is \"hard-coded\" in WeightedFragInfo. BTW, that's the reason I started to work on this patch anyway.\n\n\n\nPossible Solution:\n\n1. Collect and pass all needed Informations to the BaseFragmentsBuilder-implementation \n\n\tIntroduction of TermInfo.fieldName\n\tIntroduction of WeightedFragInfo.phraseInfos\n\tPassing a instance of IndexReader as argument to BaseFragmentsBuilder.getWeightedFragInfoList() in order to get the needed statistical data from the index\n\n\n\n2. Move the calculation of sum-of-boosts to ScoreOrderFramentsBuilder.calculateScore()\n\n\n    \n  /**\n   * Compute WeightedFragInfo.score based on query-boosts\n   * @throws IOException \n   */\n  public List<WeightedFragInfo> calculateScore( List<WeightedFragInfo> weightedFragInfos, IndexReader reader ) throws IOException{\n    for( WeightedFragInfo wfi : weightedFragInfos ){\n      for( WeightedPhraseInfo wpi : wfi.phraseInfos ){\n        wfi.score += wpi.boost;\n      }\n    }\n    return weightedFragInfos;\n  }\n\n\n\n3. Calculation of sum-of-distinct-weights with WeightOrderFramentsBuilder.calculateScore()\n\n\n\tIn this patch WeightOrderFramentsBuilder is a subclass of ScoreOrderFragmentsBuilder.\n\tBut I think the introduction of an abstract class OrderedFragmentsBuilder as superclass of ScoreOrderFragmentsBuilder and WeightOrderFragmentsBuilder would be a better strategy.\n\tMoving calculateScore() into BaseFragmentsBuilder and making it abstract would be another idea.\n\tThe sum-of-distinct-weight-approach is the same as presented in the last patch.\n\n\n\n\n  /**\n   * Compute WeightedFragInfo.score based on IDF-weighted terms\n   * @throws IOException \n   */\n  @Override\n  public List<WeightedFragInfo> calculateScore( List<WeightedFragInfo> weightedFragInfos, IndexReader reader ) throws IOException{\n    \n    Map<String, Float> lookup = new HashMap<String, Float>(); \n    HashSet<String> distinctTerms  = new HashSet<String>();\n    \n    int numDocs = reader.numDocs() - reader.numDeletedDocs();\n    \n    int docFreq;\n    int length;\n    float boost;\n    float weight;\n    \n    for( WeightedFragInfo wfi : weightedFragInfos ){\n      uniqueTerms.clear();\n      length = 0;\n      boost = 0;\n      for( WeightedPhraseInfo wpi : wfi.phraseInfos ){\n        for( TermInfo ti : wpi.termInfos ) {\n          length++;\n          if( !distinctTerms.add( ti.text ) ) \n            continue;\n          if ( lookup.containsKey( ti.text ) )\n            weight = lookup.get( ti.text ).floatValue();\n          else {\n            docFreq = reader.docFreq( new Term( ti.fieldName, ti.text ) );\n            weight = ( float ) ( Math.log( numDocs / ( double ) ( docFreq + 1 ) ) + 1.0 );\n            lookup.put( ti.text, new Float( weight ) );\n          }\n          boost += Math.pow( weight, 2 ) * wpi.boost;\n        }\n      }\n      wfi.score = ( float ) ( boost * length * ( 1 / Math.sqrt( length ) ) );\n    }\n    \n    return weightedFragInfos;\n  }\n\n\n\nWith this approach programmers can implement their own fragments-weighting with ease, simply overwriting calculateScore(). \n\nI think, the major drawback of this idea is that the FragmentsBuilder must traverse the whole stack of WeightedFragInfo once again. Since we have tomes with more than 3000 pages of OCR, this could be a problem. But I can't confirm that for sure. One way to avoid this would be making FieldFragList \"plugable\" with an Interface \"FragList\" and the FragmentsBuilder-plugin could be parametrized with the intended implementation of FragList:\n\n\n<highlighter>\n <fragmentsBuilder name=\"weight-ordered\" class=\"org.apache.solr.highlight.OrderedFragmentsBuilder\" />\n  <fragList class=\"org.apache.lucene.search.vectorhighlight.WeightedFragList\" />\n </fragmentsBuilder>\n <fragmentsBuilder name=\"boost-ordered\" class=\"org.apache.solr.highlight.OrderedFragmentsBuilder\" />\n  <fragList class=\"org.apache.lucene.search.vectorhighlight.BoostedFragList\" />\n </fragmentsBuilder>\n</highlighter>\n\n    \n\nFurther notes:\n\n\tAs shown in this patch \"WeightedFragInfo.totalBoost\" should be renamed into \"WeightedFragInfo.score\".\n\t\"ScoreOrderFragmentsBuilder\" should be renamed into \"BoostOrderFragmentsBuilder\".\n\n ",
            "author": "Sebastian Lutze",
            "id": "comment-13118784"
        },
        {
            "date": "2011-10-01T12:48:25+0000",
            "content": "Patch for 4.0 trunk. ",
            "author": "Sebastian Lutze",
            "id": "comment-13118785"
        },
        {
            "date": "2011-10-01T13:15:54+0000",
            "content": "Hm, since FieldFragList is created in SimpleFraglistBuilder.createFieldFragList() it should look more like that: \n\n\n<highlighter>\n <fragListBuilder name=\"simple-boosted\" class=\"org.apache.solr.highlight.SimpleFragListBuilder\">\n  <fragList name=\"boosted\" class=\"org.apache.lucene.search.vectorhighlight.BoostedFragList\"/>\n </fragListBuilder>\n <fragListBuilder name=\"simple-weighted\" class=\"org.apache.solr.highlight.SimpleFragListBuilder\" default=\"true\">\n  <fragList name=\"weighted\" class=\"org.apache.lucene.search.vectorhighlight.WeightedFragList\">\n </fragListBuilder>\n <fragmentsBuilder name=\"ordered\" class=\"org.apache.solr.highlight.ScoreOrderFragmentsBuilder\" default=\"true\"/>\n</highlighter>\n\n ",
            "author": "Sebastian Lutze",
            "id": "comment-13118799"
        },
        {
            "date": "2011-10-04T13:07:46+0000",
            "content": "Another patch for 4.0. This one makes FieldFragList \"plugable\".  \n\nThis patch contains:\n\n\tIntroduction of interface FieldFragList\n\tIntroduction of abstract class BaseFieldFragList which contains SubInfo and FieldFragInfo (I renamed WeightedFragInfo)\n\tIntroduction of class SimpleFieldFragList (default)\n\tIntroduction of class WeightedFieldFragList\n\tIntroduction of abstract class BaseFragListBuilder\n\tIntroduction of class SimpleFragListBuilder (default)\n\tIntroduction of class WeightedFragListBuilder\n\n\n\nThe weighting-formula now depends on the implementation of \nFieldFragList.add(int startOffset, int endOffset, List<FieldPhraseInfo> phraseInfoList):\n\n\n  /* (non-Javadoc)\n   * @see org.apache.lucene.search.vectorhighlight.FieldFragList#getFragInfos()\n   */ \n  @Override\n  public void add( int startOffset, int endOffset, List<FieldPhraseInfo> phraseInfoList ) {\n    float score = 0;\n    List<SubInfo> subInfos = new ArrayList<SubInfo>();\n    for( FieldPhraseInfo phraseInfo : phraseInfoList ){\n      subInfos.add( new SubInfo( phraseInfo.getText(), phraseInfo.getTermsOffset(), phraseInfo.getSeqnum() ) );\n      score += phraseInfo.getBoost();\n    }\n    getFragInfos().add( new FieldFragInfo( startOffset, endOffset, subInfos, score ) );\n  }\n\n\n\nThe choosen FieldFragList depends on FragListBuilder.createFieldFragList( FieldPhraseList fieldPhraseList, int fragCharSize ):\n\n\n  /* (non-Javadoc)\n   * @see org.apache.lucene.search.vectorhighlight.FragListBuilder#createFieldFragList(FieldPhraseList fieldPhraseList, int fragCharSize)\n   */ \n  @Override\n  public FieldFragList createFieldFragList( FieldPhraseList fieldPhraseList, int fragCharSize ){\n    return createFieldFragList( fieldPhraseList, new SimpleFieldFragList( fragCharSize ), fragCharSize );\n  } \n\n\n\nOf course, Solr-config could look like this:\n\n\n<highlighter>\n <fragListBuilder name=\"simple\" class=\"org.apache.solr.highlight.SimpleFragListBuilder\"/>\n <fragListBuilder name=\"weighted\" class=\"org.apache.solr.highlight.WeightedFragListBuilder\" default=\"true\"/>\n <fragmentsBuilder name=\"ordered\" class=\"org.apache.solr.highlight.ScoreOrderFragmentsBuilder\" default=\"true\"/>\n</highlighter>\n\n\n\nI think, this is the best possible approach, because it maintains backwards-compatibility, but do also some refactoring which would/could/should/can make it easier to plug-in different approaches in future. \n\nBut, after a few weeks of banging my head against the wall I have to admit: I have no idea.   ",
            "author": "Sebastian Lutze",
            "id": "comment-13120049"
        },
        {
            "date": "2011-10-04T13:11:24+0000",
            "content": "Patch for trunk (1178632). ",
            "author": "Sebastian Lutze",
            "id": "comment-13120053"
        },
        {
            "date": "2011-10-04T14:02:49+0000",
            "content": "Hi sebastian, thank you for the continuous work on this! I'd like to take a look them in this week. ",
            "author": "Koji Sekiguchi",
            "id": "comment-13120143"
        },
        {
            "date": "2011-10-04T14:39:54+0000",
            "content": "Patch for branch_3x (1177996). ",
            "author": "Sebastian Lutze",
            "id": "comment-13120167"
        },
        {
            "date": "2011-10-07T01:26:20+0000",
            "content": "Very nice progress, thanks! I think this is almost close to commit. I think the following is a must to do:\n\n\n\tupdate description and figures of the package javadoc ( https://builds.apache.org//job/Lucene-trunk/javadoc/contrib-highlighter/org/apache/lucene/search/vectorhighlight/package-summary.html#package_description )\n\tupdate test cases. currently they cannot be compiled.\n\n ",
            "author": "Koji Sekiguchi",
            "id": "comment-13122474"
        },
        {
            "date": "2011-10-11T14:37:55+0000",
            "content": "Patch for 3.5-SNAPSHOT & 4.0-SNAPSHOT ",
            "author": "Sebastian Lutze",
            "id": "comment-13125072"
        },
        {
            "date": "2011-10-11T14:38:42+0000",
            "content": "Okay, here we go again. \n\nThis patch contains:\n\n\n\tFixed docs\n\tFixed test cases\n\n ",
            "author": "Sebastian Lutze",
            "id": "comment-13125074"
        },
        {
            "date": "2011-10-15T01:24:11+0000",
            "content": "In the latest patch, now FieldFragList becomes interface and BaseFieldFragList abstract class, which implements the interface, is introduced. But I think it is strange that the javadoc of add() method says that the interface depends on FieldFragInfo, which is defined in the abstract class.\n\n\n* convert the list of FieldPhraseInfo to FieldFragInfo, then add it to the fragInfos\n\n\n\nHow about just changing FieldFragList to abstract and avoiding to introduce BaseFieldFragList? ",
            "author": "Koji Sekiguchi",
            "id": "comment-13128022"
        },
        {
            "date": "2011-10-15T01:29:48+0000",
            "content": "In this patch, I removed FieldFragList interface and renamed BaseFieldFragList to FieldFragList, and moved javadocs to the abstract from interface.\n\nI'm still working. ",
            "author": "Koji Sekiguchi",
            "id": "comment-13128025"
        },
        {
            "date": "2011-10-15T01:32:37+0000",
            "content": "Ah, sebastian, I think you needed to check \"Grant license to ASF for inclusion in ASF works\" when you attach your patch. Can you remove the latest patches and reattach them with that flag? Thanks! ",
            "author": "Koji Sekiguchi",
            "id": "comment-13128026"
        },
        {
            "date": "2011-10-15T03:27:57+0000",
            "content": "And I found a lot of test errors... ",
            "author": "Koji Sekiguchi",
            "id": "comment-13128049"
        },
        {
            "date": "2011-10-17T10:09:35+0000",
            "content": "Hi Koji, patch don't work because of https://issues.apache.org/jira/browse/LUCENE-3513.    \n\nAnd I found a lot of test errors...\n\nFrankly, I didn't run the tests because I thought the changes provided with the last patch shouldn't affect the original behavior. \nI'll have a look into it. But this may take some time, due to the fact that I have no knowledge about the test-framework.   ",
            "author": "Sebastian Lutze",
            "id": "comment-13128762"
        },
        {
            "date": "2011-10-17T11:25:58+0000",
            "content": "Hi sebastian,\n\n\nFrankly, I didn't run the tests because I thought the changes provided with the last patch shouldn't affect the original behavior.\nI'll have a look into it. But this may take some time, due to the fact that I have no knowledge about the test-framework. \n\nOk, no problem. I'll see the test case (hopefully next week or so). But can you take care of the following to go forward?\n\n\nAh, sebastian, I think you needed to check \"Grant license to ASF for inclusion in ASF works\" when you attach your patch. Can you remove the latest patches and reattach them with that flag? Thanks! ",
            "author": "Koji Sekiguchi",
            "id": "comment-13128795"
        },
        {
            "date": "2011-10-17T11:32:37+0000",
            "content": "I've removed my latest patch. Because the patch had ASF granted license flag but it was not right because it was totally based on sebastian's patch, which was not granted to ASF. ",
            "author": "Koji Sekiguchi",
            "id": "comment-13128799"
        },
        {
            "date": "2011-10-17T11:39:10+0000",
            "content": "Ah, sebastian, I think you needed to check \"Grant license to ASF for inclusion in ASF works\" when you attach your patch. Can you remove the latest patches and reattach them with that flag? Thanks!\n\nSorry, I forgot that. Done. ",
            "author": "Sebastian Lutze",
            "id": "comment-13128802"
        },
        {
            "date": "2011-10-25T01:35:02+0000",
            "content": "New patch, still has failures in test, though. ",
            "author": "Koji Sekiguchi",
            "id": "comment-13134686"
        },
        {
            "date": "2011-11-23T15:40:50+0000",
            "content": "Patch for trunk 1205430. Works for me so far. \n\n\n\tTest fixed\n\tNew test case \"WeightedFragListBuilderTest\"\n\n ",
            "author": "Sebastian Lutze",
            "id": "comment-13155924"
        },
        {
            "date": "2012-03-21T18:14:22+0000",
            "content": "Bulk of fixVersion=3.6 -> fixVersion=4.0 for issues that have no assignee and have not been updated recently.\n\nemail notification suppressed to prevent mass-spam\npsuedo-unique token identifying these issues: hoss20120321nofix36 ",
            "author": "Hoss Man",
            "id": "comment-13234771"
        },
        {
            "date": "2012-05-04T09:40:10+0000",
            "content": "Patch for 3.6.1-SNAPSHOT. ",
            "author": "Sebastian Lutze",
            "id": "comment-13268225"
        },
        {
            "date": "2012-05-23T20:48:17+0000",
            "content": "Koji, do you wanna get this in any time? Now is likely a good time since 4.0 is getting close. We won't apply this to 3.6.1 since that is a bugfix only release if it is going to happen at all. ",
            "author": "Simon Willnauer",
            "id": "comment-13281897"
        },
        {
            "date": "2012-05-23T20:49:11+0000",
            "content": "remove 3.6.1 from fix version - bugfix only relase ",
            "author": "Simon Willnauer",
            "id": "comment-13281899"
        },
        {
            "date": "2012-05-24T02:12:35+0000",
            "content": "Koji, do you wanna get this in any time? Now is likely a good time since 4.0 is getting close.\n\nHi Simon, thank you for bring this up to me! Yes, I do want sebastian's great patch to get in 4.0. It has been on my TODO list for a long time, but I couldn't find time to look into it deeply. I'm very sorry about that.\n\nIf I remember correctly, when I tried previous patch, I got errors on testing. Then sebastian fixed them and attached updated patch. I looked into the updated test, but I think I couldn't understand them very well at that time. Just after that, couldn't have my time because I was assigned something.\n\nAnyway, the idea of this ticket is definitely great and should be committed. So can someone take over it? ",
            "author": "Koji Sekiguchi",
            "id": "comment-13282129"
        },
        {
            "date": "2012-05-25T14:21:11+0000",
            "content": "Hi Koji, \nhi Simon,\n\nif there is something to do for me, please let me know. \n\nMaybe it would be better to split the patch in several smaller ones, e.g.\n\n1. Use Getters/Setters where possible in FVH \n2. Make FieldFragList interface and BaseFieldFragList abstract class\n3. Introduction of SimpleFieldFragList and SimpleFragListBuilder as default  \n4. Introduction of WeightedFieldFragList and WeightedFragListBuilder  \n5. Integration into Solr\n\nWhen's the 4.0-release scheduled, anyway? \n\nA Patch for trunk 1342490 is on it's way.  ",
            "author": "Sebastian Lutze",
            "id": "comment-13283467"
        },
        {
            "date": "2012-05-25T14:22:30+0000",
            "content": "Patch for trunk (1342490) ",
            "author": "Sebastian Lutze",
            "id": "comment-13283470"
        },
        {
            "date": "2012-05-25T14:48:30+0000",
            "content": "Hi sebastian!\n\nMaybe it would be better to split the patch in several smaller ones, e.g.\n\nThis is a great idea and it helps me a lot! If you could provide them one by one for trunk, I think I can review the smaller patch and commit them one by one. ",
            "author": "Koji Sekiguchi",
            "id": "comment-13283496"
        },
        {
            "date": "2012-05-30T16:19:09+0000",
            "content": "Hi Koji, \n\nThis is a great idea and it helps me a lot! If you could provide them one by one for trunk, I think I can review the smaller patch and commit them one by one.\n\nOkay, lets give it a try, here the first one: \n\nhttps://issues.apache.org/jira/browse/LUCENE-4091 \n\nThis one simply adds getters. Tests were okay.   ",
            "author": "Sebastian Lutze",
            "id": "comment-13285787"
        },
        {
            "date": "2012-06-01T01:45:42+0000",
            "content": "Hi sebastian,\n\nI committed LUCENE-4091 in trunk and branch_4x. For the credit, I will give it in CHANGES.txt when committing the main body (LUCENE-3440) patch. ",
            "author": "Koji Sekiguchi",
            "id": "comment-13287088"
        },
        {
            "date": "2012-06-04T12:42:52+0000",
            "content": "Hi Koji,\n\nI committed LUCENE-4091 in trunk and branch_4x. For the credit, I will give it in CHANGES.txt when committing the main body (LUCENE-3440) patch.\n\ngreat, here is the next one: \n\nhttps://issues.apache.org/jira/browse/LUCENE-4107\n\nThis one simply makes FieldFragList abstract and \"plugable\". Tests were okay.  \n ",
            "author": "Sebastian Lutze",
            "id": "comment-13288532"
        },
        {
            "date": "2012-06-04T15:22:39+0000",
            "content": "Hi sebastian,\n\nI committed LUCENE-4107 in trunk and branch_4x. ",
            "author": "Koji Sekiguchi",
            "id": "comment-13288625"
        },
        {
            "date": "2012-06-05T14:20:47+0000",
            "content": "Hi Koji,\n\nI committed LUCENE-4107 in trunk and branch_4x.\n\nThat was fast! \n\nhttps://issues.apache.org/jira/browse/LUCENE-4113 \n\nThis one introduces and maintains IDF-weight for FieldTermStack.TermInfo. \n ",
            "author": "Sebastian Lutze",
            "id": "comment-13289448"
        },
        {
            "date": "2012-06-05T14:43:01+0000",
            "content": "Hi Koji,\n\nI was just wondering about\n\nhttps://issues.apache.org/jira/browse/LUCENE-2949  ",
            "author": "Sebastian Lutze",
            "id": "comment-13289459"
        },
        {
            "date": "2012-06-05T15:52:14+0000",
            "content": "Hi sebastian,\n\nI committed LUCENE-4113 in trunk and branch_4x. Is the next the last one?  ",
            "author": "Koji Sekiguchi",
            "id": "comment-13289498"
        },
        {
            "date": "2012-06-11T14:47:06+0000",
            "content": "Hi Koji,\n\nIs the next the last one? \n\nalmost.  Next thing would be Solr-Integration. \n\nSo, I just realized: trunk is not trunk anymore! \n\nThis one is for branch_4x: \n\nhttps://issues.apache.org/jira/browse/LUCENE-4133 \n\nTests are fine.  ",
            "author": "Sebastian Lutze",
            "id": "comment-13292822"
        },
        {
            "date": "2012-06-12T14:19:25+0000",
            "content": "Hi Sebastian,\n\nI've committed LUCENE-4133.\n\nI'm going to close and mark this issue as resolved because I think Lucene part has been completed. Can you open a separate issue for Solr part?\n\nThis is a great improvement for FVH. I really appreciate what you've done! ",
            "author": "Koji Sekiguchi",
            "id": "comment-13293653"
        },
        {
            "date": "2012-06-12T14:22:19+0000",
            "content": "Thanks, Sebastian! ",
            "author": "Koji Sekiguchi",
            "id": "comment-13293655"
        },
        {
            "date": "2012-06-12T14:50:27+0000",
            "content": "Hi Koji,\n\nI'm going to close and mark this issue as resolved because I think Lucene part has been completed. \n\nthat's really awesome! \n\nCan you open a separate issue for Solr part? \n\nSure. \n\nThis is a great improvement for FVH. I really appreciate what you've done! \n\nIt was an honor for me!   ",
            "author": "Sebastian Lutze",
            "id": "comment-13293669"
        },
        {
            "date": "2012-06-13T13:59:18+0000",
            "content": "Hi Koji,\n\nhere's the Solr-Integration: \n\nhttps://issues.apache.org/jira/browse/SOLR-3542 \n ",
            "author": "Sebastian Lutze",
            "id": "comment-13294461"
        }
    ]
}