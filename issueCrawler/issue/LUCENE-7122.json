{
    "id": "LUCENE-7122",
    "title": "BytesRefArray can be more efficient for fixed width values",
    "details": {
        "resolution": "Fixed",
        "affect_versions": "None",
        "components": [],
        "labels": "",
        "fix_versions": [
            "6.1",
            "7.0"
        ],
        "priority": "Major",
        "status": "Closed",
        "type": "Improvement"
    },
    "description": "Today BytesRefArray uses one int (int[], overallocated) per\nvalue to hold the length, but for dimensional points these values are\nalways the same length. \n\nThis can save another 4 bytes of heap per indexed dimensional point,\nwhich is a big improvement (more points can fit in heap at once) for\n1D and 2D lat/lon points.",
    "attachments": {
        "LUCENE-7122.patch": "https://issues.apache.org/jira/secure/attachment/12794367/LUCENE-7122.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "id": "comment-15202856",
            "author": "Michael McCandless",
            "date": "2016-03-19T17:12:31+0000",
            "content": "Patch, changing BytesRefArray to lazily create the int[] offsets only when it sees that they are different across values.  We could alternatively make a separate class (FixedWidthBytesRefArray?) but I think we have too many of these already... "
        },
        {
            "id": "comment-15202859",
            "author": "Dawid Weiss",
            "date": "2016-03-19T17:16:31+0000",
            "content": "I'd say do create a separate class... the scenario of all values having exactly the same length is kind of exceptional \u2013 it'll make for a very clean logic in a separate class (no conditional jumps too) and it'll leave BytesRefArray much cleaner for the eyes. "
        },
        {
            "id": "comment-15203198",
            "author": "Michael McCandless",
            "date": "2016-03-20T09:48:45+0000",
            "content": "I'd say do create a separate class...\n\nThis (forking BytesRefArray) has its costs too, and I thought keeping a single class and having it handle its storage more efficiently is the lesser evil.\n\nBut I'll explore the forking option ... "
        },
        {
            "id": "comment-15203224",
            "author": "Uwe Schindler",
            "date": "2016-03-20T10:14:52+0000",
            "content": "Maybe a common base class? "
        },
        {
            "id": "comment-15203308",
            "author": "Robert Muir",
            "date": "2016-03-20T14:20:58+0000",
            "content": "Can we not make any more crazy abstractions here, please?\n\nIts already screwed up how many of these BytesRefArray-type abstractions we have: far too many, none are justified. "
        },
        {
            "id": "comment-15203322",
            "author": "Dawid Weiss",
            "date": "2016-03-20T14:59:03+0000",
            "content": "If you do keep it inside one class it'll get so hairy nobody will be able to understand it. Subclassing/ interfaces may cause call site degeneration into polymorphic calls, leading to inefficiencies.\n\nI would personally leave it as is, without trying to optimize, but if it's really a gain worth the short then I'd keep a separate class for it (fully optimized for a particular use case, without multiple layered conditional logic). "
        },
        {
            "id": "comment-15203913",
            "author": "Michael McCandless",
            "date": "2016-03-21T08:51:30+0000",
            "content": "if it's really a gain worth the short\n\nHmm, to clarify here: I'm not trying to optimize away that on-disk short (2 bytes) here.  We could do that, later.\n\nI'm trying to optimize away the in-RAM int (4 bytes) that OfflineSorter (because of BytesRefArray) now uses when sorting each in-heap partition.\n\nI do think this is an important/worthwhile optimization:\n\nE.g. if you are indexing 1D IntPoint s, which I suspect is a common case, today we need 12 bytes per value, and with this patch, 8 bytes per value, which means OfflineSorter can sort more values in heap before it must spill to disk, can create larger initial segments, so it can index more values before requiring 2nd level merges, etc.\n\nThe gains are still sizable for the 2D cases, e.g. a LatLonPoint would only need 12 bytes per value vs the 16 bytes today. "
        },
        {
            "id": "comment-15203920",
            "author": "Dawid Weiss",
            "date": "2016-03-21T09:00:23+0000",
            "content": "I have a feeling that the introduction of that conditional logic into BytesRefArray may slow things down more than the extra spills... especially with faster and faster SSDs, but I'll leave it to your judgement! "
        },
        {
            "id": "comment-15203965",
            "author": "Michael McCandless",
            "date": "2016-03-21T10:00:13+0000",
            "content": "OK how about this as a compromise?\n\nI added a new (package private!) class, FixedLengthBytesRefArray, and a minimal common interface (also package private) between it and the existing public BytesRefArray, which OfflineSorter holds.\n\nBytesRefArray.java is otherwise unchanged.\n\nI don't think we should try factor out a common base class, for the reasons listed above, but also because I think we may want to later improve how values are stored in FixedLengthBytesRefArray vs the more generic BytesRefPool, e.g. sizing each block so that a value never crosses a boundary.  But that's for later... "
        },
        {
            "id": "comment-15203973",
            "author": "Dawid Weiss",
            "date": "2016-03-21T10:03:28+0000",
            "content": "I think we may want to later improve how values are stored in FixedLengthBytesRefArray vs the more generic BytesRefPool\n\nYeah, that's why I was kind of worried that this more and more specific logic, if pushed to BytesRefPool, may eventually become dreadfully complex to read. "
        },
        {
            "id": "comment-15204090",
            "author": "Robert Muir",
            "date": "2016-03-21T12:17:27+0000",
            "content": "Can we have a concerted effort to really keep it package private?\n\nI know how people love to just slap the public keyword on these kinds of classes without any thought or hesitation its what creates this kind of mess IMO. And its so much work to cleanup that nobody does it. "
        },
        {
            "id": "comment-15204091",
            "author": "Robert Muir",
            "date": "2016-03-21T12:18:03+0000",
            "content": "Maybe tahts a good compromise? Lets make all of BytesRefArray package private here too. \n "
        },
        {
            "id": "comment-15204122",
            "author": "David Smiley",
            "date": "2016-03-21T12:49:20+0000",
            "content": "Lets make all of BytesRefArray package private here too.\n\nDo you mean make BytesRefArray package private altogether?  I hope not; I rather like this utility.  It's used in some places like MemoryIndex and a highlighter utility.  Instead I recommend resolving whatever we dislike about the API \u2013 clean whatever people think need cleaning up. "
        },
        {
            "id": "comment-15204123",
            "author": "Robert Muir",
            "date": "2016-03-21T12:51:48+0000",
            "content": "Yes it must become package private. We are a search engine api not a byte pool utility api, sorry. I don't care if you like it.\n\nSeeing stuff like RecyclingByteBlockAllocator as public classes: thats horrible. "
        },
        {
            "id": "comment-15204130",
            "author": "Robert Muir",
            "date": "2016-03-21T12:56:13+0000",
            "content": "And where are the benchmarks showing this fancy byte pooling actually helps memory index and highlighting (and how much? is it worth the api damage to lucene-core?) \n\nI want to see numbers. If you like this class, be prepared to defend it  "
        },
        {
            "id": "comment-15205479",
            "author": "David Smiley",
            "date": "2016-03-22T00:49:19+0000",
            "content": "I'm coming at this out of the usefulness of the data structure/utility for use within Lucene (since that's where BytesRef is defined of course); not from an efficiency standpoint although I could make such an argument.  For that, look no further than your friend Mike who is using it as described in this issue.  Lets consider MemoryIndex which uses BytesRefArray to hold the payload data for each term position.  Use of BytesRefArray for this is pretty straight-forward (see for yourself).  If BRA didn't exist... it would be more complicated to deal without it given what else is in scope.  The postingsWriter variable is a SliceWriter which just has writeInt.  That'd be awkward to write the payload with.  Or perhaps as an alternative, a new BytesRefHash could be created although there's more overhead in use of that versus a simple BytesRefArray.  Or might you propose an ArrayList of deep-copied BytesRef?  Ugh; think of all the GC and overhead for each token position.  Or perhaps you have another solution in mind?\n\nI want to see numbers. If you like this class, be prepared to defend it\n\nThat's a little aggressive.  Any way, The reverse argument of yours could be made.  Defend that removing uses of something doesn't slow other things down.  Shrug.\n\nHey by the way, I think it would be useful for us to consider modifying our Javadoc publishing to prevent publishing @lucene.internal classes.  I think that would help assuage some of your concern at the root of this matter. "
        },
        {
            "id": "comment-15206454",
            "author": "Michael McCandless",
            "date": "2016-03-22T14:36:11+0000",
            "content": "Hey by the way, I think it would be useful for us to consider modifying our Javadoc publishing to prevent publishing @lucene.internal classes. I think that would help assuage some of your concern at the root of this matter.\n\n+1, can you open a new issue?\n\nI'm coming at this out of the usefulness of the data structure/utility for use within Lucene (since that's where BytesRef is defined of course); not from an efficiency standpoint although I could make such an argument. \n\nHmm but the only valid reason to use BytesRefArray instead of BytesRef[] is efficiency?\n\nFor that, look no further than your friend Mike who is using it as described in this issue. \n\n\"Mike\" is not using it.  Names should not be attached to our source code \n\nLucene's OfflineSorter, used heavily by the new dimensional points feature, is using it.  And the inefficiency of 4 heap bytes per value is non-trivial, very much so for the likely common IntPoint use case, but also heavily so for e.g. LatLonPoint as well. "
        },
        {
            "id": "comment-15206468",
            "author": "David Smiley",
            "date": "2016-03-22T14:49:00+0000",
            "content": "+1, can you open a new issue?\n\nLUCENE-7129\n\n\"Mike\" is not using it. Names should not be attached to our source code \n\nPeace.  I meant that if Rob needs someone to vouch for the value of the efficiencies, he need not look any further than you specifically.\n\nHmm but the only valid reason to use BytesRefArray instead of BytesRef[] is efficiency?\n\nFair point. "
        },
        {
            "id": "comment-15206494",
            "author": "Michael McCandless",
            "date": "2016-03-22T15:03:06+0000",
            "content": "I think people may be underestimating the priority of this issue:\n\nOfflineSorter, now suddenly heavily used by Lucene's new dimensional points, is like a baby Lucene: it pulls values into heap, up until its budget, and then sorts them and writes another segment, having to merge them all in the end.  I have watched it go through its file slowly while indexing 3.2B OSM points \n\nThis patch would mean we can store 33% more IntPoint s in heap before writing a segment, which is an amazing improvement, especially when it can mean 0 vs 1 merges needed, or 1 vs 2 merges needed, etc., for many use cases.  No matter how fast your SSD is, having to do 1 instead of 2 merges is a big win.\n\nIf I had a way to make Lucene's IndexWriter postings heap buffer 33% more RAM efficient, that would be incredible \n\nAnd yes I know OfflineSorter is also used by non-fixed-length users (e.g. suggesters, and possibly/probably external users) but I think this new core usage for numerics and geo of it is (suddenly) the most important usage of it by Lucene.\n\nDawid Weiss, do you disagree so much with the first patch that you would veto it?  If it's OK, I'd rather commit that approach, and open followon issues to improve it later.  I prefer that patch, since it adds no new classes/interfaces, and (like Lucene's doc values) it hides all heap storage optimizations under the hood.  OfflineSorter is typically IO bound, so I don't think we should fret about the added conditionals for the CPU. "
        },
        {
            "id": "comment-15206496",
            "author": "Michael McCandless",
            "date": "2016-03-22T15:04:54+0000",
            "content": "I meant that if Rob needs someone to vouch for the value of the efficiencies, he need not look any further than you specifically.\n\nBut even that is not really valid \n\nThe two uses cases (Lucene's new dimensional points, and MemoryIndex and highlighters) are wildly different, so different tradeoffs do apply... "
        },
        {
            "id": "comment-15206498",
            "author": "Michael McCandless",
            "date": "2016-03-22T15:05:06+0000",
            "content": "LUCENE-7129\n\nThanks! "
        },
        {
            "id": "comment-15206510",
            "author": "Dawid Weiss",
            "date": "2016-03-22T15:09:42+0000",
            "content": "Of course I  wouldn't veto it. I just expressed my opinion that cramming too much logic into one class makes it very difficult to read later on (and has potential performance implications). This is what happened to fst builder, for example - I can't understand portions of the code anymore even though I was actively participating in it at the beginning.  "
        },
        {
            "id": "comment-15207432",
            "author": "Michael McCandless",
            "date": "2016-03-22T22:29:37+0000",
            "content": "Of course I wouldn't veto it.\n\nOK thanks.  Of the two patches here, the first one at least seems the least controversial, even if it's not perfect ... progress not perfection.\n\nThis is what happened to fst builder, for example \n\nSigh  "
        },
        {
            "id": "comment-15208058",
            "author": "Dawid Weiss",
            "date": "2016-03-23T08:27:14+0000",
            "content": "> progress not perfection.\n\nWell, that depends on whether you're focused on the task or paranoid. I'm still trying to figure out which group I belong to...\n\nWith regard to the FST builder \u2013 nobody is to blame, I just observed the fact: there have been so many improvements and there are so many code paths inside that code that it's hard to grasp, especially for newcomers. Whether it's possible to rewrite it in a cleaner way is a whole different issue. "
        },
        {
            "id": "comment-15213221",
            "author": "Michael McCandless",
            "date": "2016-03-26T22:06:50+0000",
            "content": "OK here's another iteration of the 2nd patch.\n\nI added some more tests, and cleaned up BKDWriter a bit (the crazy\nlastWriter hack is gone).  I also fixed\nFixedLengthBytesRefArray to manage its own byte blocks (not rely\non the overly complex ByteBlockPool), and to size its blocks to\nalways be congruent with the incoming value length so we never have to\ncopy bytes while sorting.\n\nI tested performance on the first 500 M points from the OpenStreetMaps\nexport and the patch is ~12% faster to write each segment of ~53\nmillion lat/lon points, with big IW/sorter buffer (1 GB), or ~9%\nfaster overall index time for the first 1B points.  The gains should\nbe even better at smaller (e.g. the default) IW/sorter buffers, since\nthe number of merge passes would often be lower. "
        },
        {
            "id": "comment-15213337",
            "author": "David Smiley",
            "date": "2016-03-27T04:55:15+0000",
            "content": "+1 Patch looks nice Mike.  I think a separate class is good; it's not that long.\n\nmanage its own byte blocks (not rely on the overly complex ByteBlockPool), \n\nThis is a bit theoretical but lets say the block length congruency optimization didn't occur to you.  Would you have still steer'ed clear of ByteBlockPool?  That it's internally complex is implementation detail that calling code doesn't need to care about.  The surface API could be clearer, yes.  I could be mistaken but I recall you or Rob complaining about that class before, and it's not clear to me what will become of it (if anything). "
        },
        {
            "id": "comment-15217745",
            "author": "ASF subversion and git services",
            "date": "2016-03-30T09:50:25+0000",
            "content": "Commit c47a2996b51a9763026252f9692e9ba105e82805 in lucene-solr's branch refs/heads/master from Mike McCandless\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=c47a299 ]\n\nLUCENE-7122: handle fixed length byte[] values more efficiently in OfflineSorter "
        },
        {
            "id": "comment-15217752",
            "author": "ASF subversion and git services",
            "date": "2016-03-30T09:55:21+0000",
            "content": "Commit e2d58ccb3711d838df55d99ea63fb4d075fcc9c8 in lucene-solr's branch refs/heads/branch_6x from Mike McCandless\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=e2d58cc ]\n\nLUCENE-7122: handle fixed length byte[] values more efficiently in OfflineSorter "
        },
        {
            "id": "comment-15217754",
            "author": "Michael McCandless",
            "date": "2016-03-30T09:59:35+0000",
            "content": "This is a bit theoretical but lets say the block length congruency optimization didn't occur to you. Would you have still steer'ed clear of ByteBlockPool?\n\nYour question is not theoretical at all: it's simply a recap of exactly what happened on this issue: see my first patch \n\nThat it's internally complex is implementation detail that calling code doesn't need to care about.\n\nThe problem is, not only is this class's implementation hairy, so its its numerous APIs, because it has so many diverse consumers.\n\nSo, yeah, something like ConcurrentHashMap has wildly complex implementation but a simple-ish API, but I don't put BytesRefArray and ByteBlockPool in the same category: their APIs are messy and often changing in very expert/trappy ways. "
        },
        {
            "id": "comment-15278976",
            "author": "Hoss Man",
            "date": "2016-05-10T21:24:34+0000",
            "content": "\nManually correcting fixVersion per Step #S5 of LUCENE-7271 "
        }
    ]
}