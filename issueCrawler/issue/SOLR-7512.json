{
    "id": "SOLR-7512",
    "title": "SolrOutputFormat creates an invalid solr.xml in the solr home zip for MapReduceIndexerTool",
    "details": {
        "components": [
            "contrib - MapReduce"
        ],
        "type": "Bug",
        "labels": "",
        "fix_versions": [
            "5.2.1",
            "5.3",
            "6.0"
        ],
        "affect_versions": "5.1",
        "status": "Closed",
        "resolution": "Fixed",
        "priority": "Blocker"
    },
    "description": "Sometime after Solr 4.9, the `MapReduceIndexerTool` got busted because invalid `solr.xml` contents were being written to the solr home dir zip. My guess is that a 5.0 change made the invalid file start to matter. \n\nThe error manifests as:\n\nError: java.lang.IllegalStateException: Failed to initialize record writer for org.apache.solr.hadoop.MapReduceIndexerTool/SolrMapper, attempt_1430953999892_0012_r_000001_1\n        at org.apache.solr.hadoop.SolrRecordWriter.<init>(SolrRecordWriter.java:126)\n        at org.apache.solr.hadoop.SolrOutputFormat.getRecordWriter(SolrOutputFormat.java:163)\n        at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.<init>(ReduceTask.java:569)\n        at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:643)\n        at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:394)\n        at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:175)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:415)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)\n        at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:170)\nCaused by: org.apache.solr.common.SolrException: org.xml.sax.SAXParseException; Premature end of file.\n        at org.apache.solr.core.Config.<init>(Config.java:156)\n        at org.apache.solr.core.SolrXmlConfig.fromInputStream(SolrXmlConfig.java:127)\n        at org.apache.solr.core.SolrXmlConfig.fromFile(SolrXmlConfig.java:110)\n        at org.apache.solr.core.SolrXmlConfig.fromSolrHome(SolrXmlConfig.java:138)\n        at org.apache.solr.core.CoreContainer.<init>(CoreContainer.java:142)\n        at org.apache.solr.hadoop.SolrRecordWriter.createEmbeddedSolrServer(SolrRecordWriter.java:162)\n        at org.apache.solr.hadoop.SolrRecordWriter.<init>(SolrRecordWriter.java:119)\n        ... 9 more\nCaused by: org.xml.sax.SAXParseException; Premature end of file.\n        at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)\n        at org.apache.xerces.util.ErrorHandlerWrapper.fatalError(Unknown Source)\n        at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)\n        at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)\n        at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)\n        at org.apache.xerces.impl.XMLVersionDetector.determineDocVersion(Unknown Source)\n        at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)\n        at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)\n        at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)\n        at org.apache.xerces.parsers.DOMParser.parse(Unknown Source)\n        at org.apache.xerces.jaxp.DocumentBuilderImpl.parse(Unknown Source)\n        at org.apache.solr.core.Config.<init>(Config.java:145)\n        ... 15 more\n\n\n\n\nThe last version that I've successfully used `MapReduceIndexerTool` was 4.9, and I verified that this patch resolves the issue for me (testing on 5.1). I spent a couple hours trying to write a simple test case to exhibit the error, but I haven't quite figured out how to deal with the \n\njava.security.AccessControlException: java.io.FilePermission ...\n\n errors. \n\nPull request for bugfix here",
    "attachments": {
        "SOLR-7512.patch": "https://issues.apache.org/jira/secure/attachment/12736172/SOLR-7512.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2015-05-08T05:15:10+0000",
            "author": "Adam McElwee",
            "content": "I've updated the PR to include the test case, but I'm still wrestling with the security manager, and have to disable it to successfully execute the test. ",
            "id": "comment-14533879"
        },
        {
            "date": "2015-05-29T16:36:36+0000",
            "author": "Uwe Schindler",
            "content": "There are some problems with the patch:\n\n\n-        Path targetFile = destDir.resolve(entry.getName());\n-        \n+        Path targetFile = new File(destDir.toFile(), entry.getName()).toPath();\n+\n\n\n\nThis is a no-go with Lucene/Solr: java.io.File is not allowed to be aused anywhere in Lucene code. ",
            "id": "comment-14565038"
        },
        {
            "date": "2015-05-29T16:48:45+0000",
            "author": "Mark Miller",
            "content": "but I haven't quite figured out how to deal with the \njava.security.AccessControlException: java.io.FilePermission ...\n errors.\n\nThat's a known current problem - a couple tests have to be run via IDE or without a security manager because a Hadoop piece tries to write in an illegal location for tests. ",
            "id": "comment-14565047"
        },
        {
            "date": "2015-05-29T16:50:35+0000",
            "author": "Mark Miller",
            "content": "Though if you are writing a new test, perhaps it's just your new code as Uwe points out.\n\nThere are two tests that are currently generally skipped because of what I mention above - they are likely the tests that would catch this. ",
            "id": "comment-14565050"
        },
        {
            "date": "2015-05-29T16:56:34+0000",
            "author": "Adam McElwee",
            "content": "Patch updated to remove usage of `java.io.File`. \n\nFor some reason that method in `TestUtil` wasn't correctly unpacking the zip and using relative paths. Maybe that's another issue, in itself. I switched to the hadoop fs `FileUtil.unZip`. ",
            "id": "comment-14565058"
        },
        {
            "date": "2015-05-29T17:02:44+0000",
            "author": "Uwe Schindler",
            "content": "For some reason that method in `TestUtil` wasn't correctly unpacking the zip and using relative paths. Maybe that's another issue, in itself. I switched to the hadoop fs `FileUtil.unZip`.\n\nThe reason could be a \"incorrectly packed ZIP file\". There are some ZIP files out there that use backslashes as separator. Maybe the one you uses had this problem. ",
            "id": "comment-14565063"
        },
        {
            "date": "2015-05-29T17:06:34+0000",
            "author": "Adam McElwee",
            "content": "Hmm, possibly. The zip in question is the one created as part of the existing MRIndexerTool in `SolrOutputFormat`. A quick look at it shows that it's simply doing substring manipulation for creating the zip entries. Seems a bit questionable. At any rate, the hadoop `FileUtil.unZip` unpacks it w/ no issues. ",
            "id": "comment-14565070"
        },
        {
            "date": "2015-06-08T11:50:33+0000",
            "author": "Mark Miller",
            "content": "I've been working on getting this in. First dealing with a bunch of issues around the tests that would have already picked this up but can't run with a security manager - they couldnt run without additional dependencies and fixes due to recent hadoop upgrades it seems. Once I finished getting that straightened out, I'll pull in the new test. ",
            "id": "comment-14577066"
        },
        {
            "date": "2015-06-08T19:47:15+0000",
            "author": "Adam McElwee",
            "content": "Mark Miller, if there's something that you think a newb solr contributor can help out w/, just let me know. ",
            "id": "comment-14577726"
        },
        {
            "date": "2015-06-09T16:25:49+0000",
            "author": "Mark Miller",
            "content": "Okay, this patch gets things back up to speed. I'll look at integrating the new test next. ",
            "id": "comment-14579169"
        },
        {
            "date": "2015-06-09T17:21:05+0000",
            "author": "Mark Miller",
            "content": "I'm having some trouble with the new test, so I'll commit the standard cleanup first - I want to make sure that get's into 5.2.1.\n\nRecent hadoop lib updates allow us to properly run a couple tests that required no security manager to run - that should prevent this from popping up again.\n\nWe do actually have to write the solr.xml file out - 6x requires a solr.xml file. ",
            "id": "comment-14579261"
        },
        {
            "date": "2015-06-09T18:18:13+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1684494 from Mark Miller in branch 'dev/trunk'\n[ https://svn.apache.org/r1684494 ]\n\nSOLR-7512: SolrOutputFormat creates an invalid solr.xml in the solr home zip for MapReduceIndexerTool. ",
            "id": "comment-14579350"
        },
        {
            "date": "2015-06-09T18:31:12+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1684495 from Mark Miller in branch 'dev/branches/branch_5x'\n[ https://svn.apache.org/r1684495 ]\n\nSOLR-7512: SolrOutputFormat creates an invalid solr.xml in the solr home zip for MapReduceIndexerTool. ",
            "id": "comment-14579362"
        },
        {
            "date": "2015-06-09T19:46:54+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1684509 from Mark Miller in branch 'dev/branches/lucene_solr_5_2'\n[ https://svn.apache.org/r1684509 ]\n\nSOLR-7512: SolrOutputFormat creates an invalid solr.xml in the solr home zip for MapReduceIndexerTool. ",
            "id": "comment-14579473"
        }
    ]
}