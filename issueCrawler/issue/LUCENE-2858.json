{
    "id": "LUCENE-2858",
    "title": "Separate SegmentReaders (and other atomic readers) from composite IndexReaders",
    "details": {
        "labels": "",
        "priority": "Blocker",
        "components": [],
        "type": "Task",
        "fix_versions": [
            "4.0-ALPHA"
        ],
        "affect_versions": "None",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "With current trunk, whenever you open an IndexReader on a directory you get back a DirectoryReader which is a composite reader. The interface of IndexReader has now lots of methods that simply throw UOE (in fact more than 50% of all methods that are commonly used ones are unuseable now). This confuses users and makes the API hard to understand.\n\nThis issue should split \"atomic readers\" from \"reader collections\" with a separate API. After that, you are no longer able, to get TermsEnum without wrapping from those composite readers. We currently have helper classes for wrapping (SlowMultiReaderWrapper - please rename, the name is really ugly; or Multi*), those should be retrofitted to implement the correct classes (SlowMultiReaderWrapper would be an atomic reader but takes a composite reader as ctor param, maybe it could also simply take a List<AtomicReader>). In my opinion, maybe composite readers could implement some collection APIs and also have the ReaderUtil method directly built in (possibly as a \"view\" in the util.Collection sense). In general composite readers do not really need to look like the previous IndexReaders, they could simply be a \"collection\" of SegmentReaders with some functionality like reopen.\n\nOn the other side, atomic readers do not need reopen logic anymore? When a segment changes, you need a new atomic reader? - maybe because of deletions thats not the best idea, but we should investigate. Maybe make the whole reopen logic simplier to use (ast least on the collection reader level).\n\nWe should decide about good names, i have no preference at the moment.",
    "attachments": {
        "LUCENE-2858-FixSlowEnsureOpen.patch": "https://issues.apache.org/jira/secure/attachment/12512621/LUCENE-2858-FixSlowEnsureOpen.patch",
        "LUCENE-2858-FCinsanity.patch": "https://issues.apache.org/jira/secure/attachment/12512508/LUCENE-2858-FCinsanity.patch",
        "LUCENE-2858.patch": "https://issues.apache.org/jira/secure/attachment/12512480/LUCENE-2858.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2011-01-11T18:00:34+0000",
            "content": "+1\n\nWe very much need this now \u2013 it should be strongly (statically) typed, whether you are using an AtomicIndexReader vs CompositeIndexReader.\n\nAnd I agree CompositeIndexReader should feel more like a Collection than what IR is today. ",
            "author": "Michael McCandless",
            "id": "comment-12980215"
        },
        {
            "date": "2011-01-11T18:02:01+0000",
            "content": "(SlowMultiReaderWrapper - please rename, the name is really ugly; or Multi*)\n\nMy problem with Multi* is that this makes things sound cool and powerful.\nIf they are really slow transition mechanisms, I prefer Slow* as it will actually discourage their use.\n\nBut I agree with this issue in general and it would be great for it to be cleaned up. ",
            "author": "Robert Muir",
            "id": "comment-12980216"
        },
        {
            "date": "2011-01-11T22:30:47+0000",
            "content": "On the other side, atomic readers do not need reopen logic anymore? When a segment changes, you need a new atomic reader?\nThere is a freakload of places that \"upgrade\" SegmentReader in various ways, with deletions guilty only for the part of the cases. I'll try getting back to LUCENE-2355 at the end of the week. ",
            "author": "Earwin Burrfoot",
            "id": "comment-12980388"
        },
        {
            "date": "2011-01-15T10:26:14+0000",
            "content": "Any comments about removing write access from IndexReaders? I think setNorms() will be removed soon, but how about the others like deleteDocument()? I would propose to also make all IndexReaders simply readers not writers? ",
            "author": "Uwe Schindler",
            "id": "comment-12982057"
        },
        {
            "date": "2011-01-15T14:30:37+0000",
            "content": "I think setNorms() will be removed soon\n\nWhy do you think this?\n\nOn the norms cleanup issue, i only removed setNorm(float), because its completely useless.\nAll it did was call Similarity.getDefault().encode(float) + setNorm(byte). ",
            "author": "Robert Muir",
            "id": "comment-12982102"
        },
        {
            "date": "2011-01-15T14:50:22+0000",
            "content": "I was talking about replacing norms by CSF, maybe It's just not soon. ",
            "author": "Uwe Schindler",
            "id": "comment-12982107"
        },
        {
            "date": "2011-01-15T15:18:05+0000",
            "content": "Ah, ok. sorry i was confused. Still, i think we would need this method (somewhere) even \nwith CSF, so that people can change the norms and they instantly take effect for searches. ",
            "author": "Robert Muir",
            "id": "comment-12982115"
        },
        {
            "date": "2011-01-15T16:34:58+0000",
            "content": "Any comments about removing write access from IndexReaders? I think setNorms() will be removed soon, but how about the others like deleteDocument()? I would propose to also make all IndexReaders simply readers not writers? \n\nVoting with all my extremities - yes!! ",
            "author": "Earwin Burrfoot",
            "id": "comment-12982126"
        },
        {
            "date": "2011-01-15T16:49:39+0000",
            "content": "Still, i think we would need this method (somewhere) even with CSF, so that people can change the norms and they instantly take effect for searches.\nThis still puzzles me. I can strain my imagination, and get people who just need to change norms without reindexing.\nBut doing this and requiring instant turnaround? Kid me not  ",
            "author": "Earwin Burrfoot",
            "id": "comment-12982132"
        },
        {
            "date": "2011-01-15T16:57:44+0000",
            "content": "I don't think we should remove setNorm/deleteDocuments, even from the composite reader class.\n\nDeleting docs from IR has advantages over deleting from IW: the change is \"live\" to any searches running on that IR; you get an immediate count of how many docs were deleted; you can delete by docID.\n\nsetNorm is also useful in that it can be use to boost docs (globally), live, if that reader is being used for searching.  When/if we cutover norms -> doc values we'll have to decide what to do about setNorm...\n\nAt a higher level, for this \"strong typing of atomic vs composite IRs\", we shouldn't try to change functionality \u2013 let's just do a rote refactoring, such that methods that now throw UOE on IR are moved to the atomic reader only.\n\nSeparately we can think about whether existing functions should be dropped... ",
            "author": "Michael McCandless",
            "id": "comment-12982134"
        },
        {
            "date": "2011-01-15T19:07:30+0000",
            "content": "> Deleting docs from IR has advantages over deleting from IW: the change is\n> \"live\" to any searches running on that IR; you get an immediate count of how\n> many docs were deleted; you can delete by docID.\n\nAlternate plan:\n\n\n\tMove responsibility for deletions to a pluggable DeletionsReader\n    subcomponent of SegmentReader.\n\tHave the default DeletionsReader be read-only.\n\tPeople who need the esoteric functionality described above can use a\n    subclass of DeletionsReader.\n\n ",
            "author": "Marvin Humphrey",
            "id": "comment-12982152"
        },
        {
            "date": "2011-01-15T20:52:04+0000",
            "content": "APIs have to be there still. All that commity, segment-deletery, mutabley stuff (that spans both atomic and composite readers).\nSo, while your plan is viable, it won't remove that much cruft. ",
            "author": "Earwin Burrfoot",
            "id": "comment-12982166"
        },
        {
            "date": "2011-12-14T22:35:13+0000",
            "content": "I try to do this now, Robert will help.\n\nMost crap is removed form IndexReader, so this should be easy now. We should use AtomicIndexReader and CompositeIndexReader.\n\n\n\tIndexReader base class only contains the methods that can actually be implemented in every reader.\n\tThe current BaseMultiReader (pkg-private) would be the later CompositeIndexReader\n\tAtomicIndexReader is also abstract, SegmentReader and SlowMultiReaderWrapper would implement it.\n\tThe static open methods should maybe in a separate class or the abstract IndexReader base with the limited API, but they would return CompositeIndexReader\n\tFilterIndexReader could be split in two classes, but a FilterMultiReader makes no sense  FilterIndexReader will be FilterAtomicIndexReader (also the superclass of SlowMultiReaderWrapper)\n\n ",
            "author": "Uwe Schindler",
            "id": "comment-13169760"
        },
        {
            "date": "2012-01-17T21:19:26+0000",
            "content": "uwe are you gonna work on this? ",
            "author": "Simon Willnauer",
            "id": "comment-13188005"
        },
        {
            "date": "2012-01-17T22:30:02+0000",
            "content": "I will hopefully start this weekend. I just have a schedule currently that has no slots left for that.\n\nRobert and I wanted to start a branch soon, maybe I simply do that as first step soon! ",
            "author": "Uwe Schindler",
            "id": "comment-13188076"
        },
        {
            "date": "2012-01-21T16:19:07+0000",
            "content": "Simon: Just to inform you, I am working on this. Currently I have a heavy broken checkout that does no longer compile at all  Working, working, working... It's a mess!\n\nOnce I have something intially compiling for core (not tests), I will create a branch! ",
            "author": "Uwe Schindler",
            "id": "comment-13190456"
        },
        {
            "date": "2012-01-21T23:50:54+0000",
            "content": "I created the branch at https://svn.apache.org/repos/asf/lucene/dev/branches/lucene2858 and committed my first steps:\n\n\n\tAdd CompositeIndexReader and AtomicIndexReader\n\tMoved methods around, still not yet finished (see below)\n\tDirectoryReader is public now and is returned by IR.open() and IW.getReader()\n\n\n\nTODO:\n\n\n\tIR.openIfChanged makes no sense for any reader other than DirectoryReader, let's move it also there\n\tisCurrent and getVersion() is also useless for atomic readers and composite readers except DR\n\tThe strange generics in ReaderContext caused by the final field will go away, when changing reader field to aaccessor method returning the correct type (by return type overloading).\n\n\n\nComments welcome and also heavy committing. ",
            "author": "Uwe Schindler",
            "id": "comment-13190559"
        },
        {
            "date": "2012-01-22T12:56:20+0000",
            "content": "Some TODOs fixed:\n\n\n\tThe strange generics in ReaderContext caused by the final field will go away, when changing reader field to aaccessor method returning the correct type (by return type overloading).\n\tSome refactoring done on docFreq()\n\tMoved the ReaderContext impls to the corresponding abstract reader class: CompositeReaderContext -> CompositeIndexReader, AtomicReaderContext -> AtomicIndexReader\n\n ",
            "author": "Uwe Schindler",
            "id": "comment-13190662"
        },
        {
            "date": "2012-01-22T12:59:40+0000",
            "content": "More TODOs:\n\n\n\tRename SlowMultiReaderWrapper -> SlowCompositeReaderWrapper (as its not only for MultiReaders, also other CompositeIndexReaders like DirectoryReader. Name is not in line with our current naming\n\tAll version/commit/reopen stuff should go into DirectoryReader, its useless for the abstract IR interfaces\n\n ",
            "author": "Uwe Schindler",
            "id": "comment-13190663"
        },
        {
            "date": "2012-01-29T14:17:28+0000",
            "content": "I now fixed the branch's test-framework and all remaining TODOs about the API.\n\nNow the horrible stupid slave-work to port all test starts. I assume the API is now fixed, as nobody complained after one week. ",
            "author": "Uwe Schindler",
            "id": "comment-13195757"
        },
        {
            "date": "2012-01-29T15:38:34+0000",
            "content": "SlowMultiReaderWrapper - please rename, the name is really ugly; or Multi*\n\n+1, the Slow* is misleading as it makes it seem like there's a faster way you should be doing it.\nCompositeReaderWrapper should be fine.  And no, it doesn't sound too \"cool\" for the hypothetical developers who use that as a criteria when coding \n\nOther possibilities include AtomicReaderEmulator, AtomicEmulatorReader, CompositeAsAtomicReader, etc ",
            "author": "Yonik Seeley",
            "id": "comment-13195768"
        },
        {
            "date": "2012-01-29T22:58:17+0000",
            "content": "Can we please do some eclipse-renames like:\n\nAtomicIndexReader -> AtomicReader\nAtomicIndexReader.AtomicReaderContext -> AtomicReader.Context\n\nThe verbosity of the api is killing me  ",
            "author": "Robert Muir",
            "id": "comment-13195868"
        },
        {
            "date": "2012-01-29T23:06:58+0000",
            "content": "+1 for those names. ",
            "author": "Michael McCandless",
            "id": "comment-13195873"
        },
        {
            "date": "2012-01-29T23:25:45+0000",
            "content": "Jaja, will fix this... ",
            "author": "Uwe Schindler",
            "id": "comment-13195876"
        },
        {
            "date": "2012-01-30T01:27:50+0000",
            "content": "I renamed the enclosing classes and also removed the public ctors from ReaderContexts (to prevent stupid things already reported on mailing lists).\n\nThe renameing of ReaderContexts all to the same name Context, but with different enclosing class is a refactoring, Eclipse cannot do (it creates invalid code). It seems only NetBeans can do this, I will try to find a solution. The problem is that Eclipse always tries to import the inner class, what causes conflicts.\n\nFinally, e.g. the method getDocIdSet should look like getDocIdSet(AtomicReader.Context,...) [only importing AtomicReader], but Eclipse always tries to use Context [and import oal.AtomicReader.Context]. At the end we should have abstract IndexReader.Context, AtomicReader.Context, CompositeReader.Context.\n\nWill go to bed now. ",
            "author": "Uwe Schindler",
            "id": "comment-13195904"
        },
        {
            "date": "2012-01-30T10:08:52+0000",
            "content": "After sleeping one more night about it, the easiest and most simple way to remove the stupid verbosity in imports:\n\nI will move the ReaderContexts out of their enclosing class and make a top-level class without ctor out of it. Then import statements look nice. The RCs are now so important for search, so they should be on its own. ",
            "author": "Uwe Schindler",
            "id": "comment-13196024"
        },
        {
            "date": "2012-01-30T22:21:04+0000",
            "content": "Here the final patch. Thanks for the good work and lots of help from Robert and Mike.\n\nAs this patch contains heavy changes, we will commit it as soon as possible so work can go on. It would be nice, if you would not commit anything until this is done.\n\nThere are some minor issues open:\n\n\tDirectoryReader is final and has only static factory methods. It is not possible to subclass it in any way. The problem is mainly Solr, as Solr accesses directory(), IndexCommits,... and therefore cannot work on abstract IndexReader anymore. This should be changed, by e.g. handling reopening in the IRFactory, also versions, commits,... Currently its not possible to implement any other IRFactory that returns something else.\n\tThe PayloadProcessorProvider has a broken API, this should be fixed. The current patch mimics the old behaviour, but not 100%.\n\tParallelReader is now atomic. We should add a sugar wrapper method to allow synchronized composite readers (with same segment sizes) to be aligned with MultiReaders or wrapped by Slow.\n\n\n\nThe remaining issues will be fixed in later issues! ",
            "author": "Uwe Schindler",
            "id": "comment-13196479"
        },
        {
            "date": "2012-01-30T22:37:01+0000",
            "content": "Patch with nocommits removed. ",
            "author": "Uwe Schindler",
            "id": "comment-13196496"
        },
        {
            "date": "2012-01-30T23:02:43+0000",
            "content": "Thanks for all the work here Uwe! I think its a great step forward. \nThe previous situation where half the methods were UOE is really unreleasable. ",
            "author": "Robert Muir",
            "id": "comment-13196518"
        },
        {
            "date": "2012-01-30T23:38:42+0000",
            "content": "Committed trunk revision: 1238085 ",
            "author": "Uwe Schindler",
            "id": "comment-13196542"
        },
        {
            "date": "2012-01-31T00:01:54+0000",
            "content": "Nice work guys! ",
            "author": "Michael McCandless",
            "id": "comment-13196561"
        },
        {
            "date": "2012-01-31T00:32:54+0000",
            "content": "Patch that adds FC insanity checking for slow wrappers back. Will commit now. ",
            "author": "Uwe Schindler",
            "id": "comment-13196580"
        },
        {
            "date": "2012-01-31T00:37:11+0000",
            "content": "Committed trunk revision: 1238112 ",
            "author": "Uwe Schindler",
            "id": "comment-13196583"
        },
        {
            "date": "2012-01-31T19:16:57+0000",
            "content": "I think somehow ensureOpen is broken here in some situations (possibly slowmultireaderwrapper):\n\n\nant test -Dtestcase=TestReaderClosed -Dtestmethod=test -Dtests.seed=42907a63342da06b:-1490dd5f0d0f26d9:-7e3c360ea2d32539 -Dargs=\"-Dfile.encoding=UTF-8\"\n\n\n ",
            "author": "Robert Muir",
            "id": "comment-13197134"
        },
        {
            "date": "2012-01-31T20:21:04+0000",
            "content": "Hi Robert, this patch fixes the problem:\n\nSlowMultiReaderWrapper creates the fields and liveDocs on its ctor (as its expensive) and reuses. This is no problem, but the test did something very bad: It closed not the slow reader but the wrapped DirectoryReader. As fields() was not delegated to the DR or MultiFields with DR, Slow returned its own cached instance. Slow's ensureOpen was not throwing Ex, as it was still open.\n\nTheoretically, Slow* should incRef the underlying indexreader and decRef on close(). But that would require, that you close the SlowReader after wrapping.\n\nThe current solution is not optimal but makes it easy to wrap without explicitely closing the slow wrapper.\n\nThe fix was to call in.ensureOpen() in slow before the cached instance was returned. ",
            "author": "Uwe Schindler",
            "id": "comment-13197184"
        },
        {
            "date": "2012-01-31T20:24:09+0000",
            "content": "Committed fix in revision: 1238788\nI removed the extra in.ensureOpen() for hasDeletions(), as this was only a null-check. ",
            "author": "Uwe Schindler",
            "id": "comment-13197187"
        },
        {
            "date": "2012-06-01T17:48:43+0000",
            "content": "Not entirely sure why but it looks like the commits here slowed down our NRT reopen latency.  If you look at the nightly bench graph: http://people.apache.org/~mikemccand/lucenebench/nrt.html and click + drag from Jan 2012 to today, annotation R shows we increased from ~46 msec NRT reopen latency to ~50 msec ... could just be hotspot being upset... ",
            "author": "Michael McCandless",
            "id": "comment-13287563"
        },
        {
            "date": "2012-06-03T09:59:31+0000",
            "content": "Not entirely sure why but it looks like the commits here slowed down our NRT reopen latency.\n\nOK, sorry, I was wrong about this!\n\nI went back and re-ran the NRTPerfTest and isolated the slowdown to LUCENE-3728 (also committed on the same day)... it was because we lost the SegmentInfo.sizeInBytes caching... but then in LUCENE-4055 we got it back and we got the performance back ... so all's well that ends well  ",
            "author": "Michael McCandless",
            "id": "comment-13288129"
        },
        {
            "date": "2012-06-03T10:16:03+0000",
            "content": "Thanks Mike for taking care. For me this looked crazy, because refactoring like this should not change perf.\n\nThis explains the change back  after 4055, I thought un-compressed oops responsible for the speedup. ",
            "author": "Uwe Schindler",
            "id": "comment-13288133"
        },
        {
            "date": "2012-06-03T10:19:42+0000",
            "content": "This explains the change back after 4055, I thought un-compressed oops responsible for the speedup.\n\nThat's what I thought too (and I was very confused that uncompressed oops would improve things)!  But LUCENE-4055 landed on the same day I turned off uncompressed oops... so I think all mysteries are now explained. ",
            "author": "Michael McCandless",
            "id": "comment-13288135"
        }
    ]
}