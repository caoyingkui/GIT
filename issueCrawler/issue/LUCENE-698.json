{
    "id": "LUCENE-698",
    "title": "FilteredQuery ignores boost",
    "details": {
        "labels": "",
        "priority": "Minor",
        "components": [
            "core/search"
        ],
        "type": "Bug",
        "fix_versions": [
            "2.2"
        ],
        "affect_versions": "2.0.0",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "Filtered query ignores it's own boost.",
    "attachments": {
        "lucene-698.patch": "https://issues.apache.org/jira/secure/attachment/12358392/lucene-698.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2006-10-25T04:25:48+0000",
            "content": "I just commited hashCode() and equals() changes to take boost into account so that\ngeneric tests in QueryUtils.check(query) can pass.\n\nOne should arguably be able to set the boost on any query clause, so I'm leaving this open since I think scoring probably ignores the boost too. ",
            "author": "Yonik Seeley",
            "id": "comment-12444570"
        },
        {
            "date": "2007-05-28T19:03:24+0000",
            "content": "With this patch FilteredQuery takes the boost into account for\nscoring. It includes a test that fails with the trunk version\nand passes with this patch.\n\nThis patch also removes one test from TestSimpleExplanations:\ntestFQ7(). These tests check if the score and the value in the \nexplanation are the same. testFQ7() in particular verifies this\nfor a FilterQuery with a boost of 0. But with a boost of 0 the \nscore and the explanation has the value NaN, which makes\nassertEquals() fail. So I believe this is a incorrect test case.\nWe just didn't notice it before because FilteredQuery did not\ntake the boost into account.\n\nAll unit tests pass. ",
            "author": "Michael Busch",
            "id": "comment-12499622"
        },
        {
            "date": "2007-05-29T01:07:20+0000",
            "content": "i think the test class and test case testFQ7 in particular are \"correct\" in the sense that they try to verify every conceivable permutation of stock query times has an explanation that matches it's score ... the problem may just be in the CheckHits.ExplanationAsserter class ... perhaps it should test if either the score or the explanation value are NaN before comparing them, and fail if only one is NaN or if neither is NaN but they are not equal)\n\n(after all: if the score is NaN, then the explanation should be NaN as well) ",
            "author": "Hoss Man",
            "id": "comment-12499652"
        },
        {
            "date": "2007-05-29T02:06:12+0000",
            "content": "> perhaps it should test if either the score or the explanation value are NaN \n> before comparing them, and fail if only one is NaN or if neither is NaN but \n> they are not equal)\n\nThanks for reviewing, Hoss! You are right, we could do that and I was actually\nthinking about it already. The problem is if I make this fix than testFQ7 fails\nfor TestSimpleExplanationsOfNonMatches because it is assumed that all\nnon matching docs have a score of 0.0. I can easily change that, so that non\nmatching docs can either have a score of 0.0 or NaN but I was not sure if we\nwant that, because other scoring bugs resulting in a score of NaN (which we \nwill hopefully never have) wouldn't be noticed then anymore.\n\nThe reason why I argued that testFQ7 is an invalid test case is that it would\nfail for any other query with a boost set to 0. Ironically we have this test\nonly for FilteredQuery, the only query class that ignores the boost, which\nmade it pass in the past. ",
            "author": "Michael Busch",
            "id": "comment-12499658"
        },
        {
            "date": "2007-05-29T02:58:17+0000",
            "content": "\n\nAhhhh ... yes, looking back at the comments in LUCENE-557 I remember now: I originally thought boosts of 0.0 were legal for all queries, and then discovered i was wrong, and removed a bunch of tests \u2013 but i clearly missed this one because it wasn't failing.\n\nwe should go ahead and remove the test ... but we should probably also fix FilteredQuery so that a boost of 0 produces some other result then just a NaN score (either an exception, or a score of 0) since as you say: NaN scores are bad. ",
            "author": "Hoss Man",
            "id": "comment-12499668"
        },
        {
            "date": "2007-05-29T03:50:24+0000",
            "content": "> but we should probably also fix FilteredQuery so that a boost of 0 \n> produces some other result then just a NaN score (either an exception,\n> or a score of 0) since as you say: NaN scores are bad.\n\nTermQuery actually behaves the same way. If boost is zero, then\nsumOfSquaredWeights() returns zero as well, resulting in a\nqueryNorm of Infinity (due to a div by zero if DefaultSimilarity is \nused). Then it multiplies boost and queryNorm and 0*Infinity=NaN.\n ",
            "author": "Michael Busch",
            "id": "comment-12499673"
        },
        {
            "date": "2007-05-29T04:00:16+0000",
            "content": "Maybe Query.setBoost() should throw an IllegalArgumentException\nin case the value is zero? ",
            "author": "Michael Busch",
            "id": "comment-12499674"
        },
        {
            "date": "2007-05-29T04:03:24+0000",
            "content": "Hmmm.. didn't realize that. I withdrawal all previous comments.  patch seems fine to me. ",
            "author": "Hoss Man",
            "id": "comment-12499675"
        },
        {
            "date": "2007-05-29T04:04:38+0000",
            "content": "whoops .. comment collision.\n\ni think the patch as it stands is fine for this issue .. but we may want another issue to hollisticly question NaN as a score. ",
            "author": "Hoss Man",
            "id": "comment-12499676"
        },
        {
            "date": "2007-05-29T20:54:57+0000",
            "content": "> Maybe Query.setBoost() should throw an IllegalArgumentException in case the value is zero?\n\nFYI, Nutch uses Query.setBoost(0.0f) to add clauses which affect the set of results but not their ranking.  In particular, it uses this to automatically convert query clauses into filters, so that query clauses like \"lang:en\" can be implemented as cached filters.  Note that not all such clauses are so optimized.\n\nhttp://svn.apache.org/viewvc/lucene/nutch/trunk/src/java/org/apache/nutch/searcher/LuceneQueryOptimizer.java?view=markup ",
            "author": "Doug Cutting",
            "id": "comment-12499921"
        },
        {
            "date": "2007-05-30T22:38:05+0000",
            "content": "> FYI, Nutch uses Query.setBoost(0.0f) to add clauses which affect the \n> set of results but not their ranking. In particular, it uses this to \n> automatically convert query clauses into filters, so that query \n> clauses like \"lang:en\" can be implemented as cached filters. Note \n> that not all such clauses are so optimized. \n\nThanks for the hint, Doug. OK, I understand how you use boost=0.0f in\nNutch. Quite cool and elegant idea actually!\n\nI guess then throwing an IllegalArgumentException in case boost=0 would\nbreak this. The question remains if we should fix the scorers to never\nreturn NaN. Hmm, I'm not completely sure how to do this. Maybe \nDefaultSimilarity.queryNorm() should return 0 instead of Infinity in \ncase sumOfSquaredWeights is 0. But then with custom Similarity \nimplemenations we could still end up getting NaN.\n\nA different solution of course is to fix it in the scorers itself, to\nreturn a score of 0 in case boost is 0. But then we'd have to add \nchecks in the score() and explain() methods, which might be a \nperformance overhead.\n\nSo I'm not sure if we should \"fix\" this at all considering these \ndifficulties and the fact that nobody complained (I think?) about the \nNaN so far.\n\nAnyway, I'll go ahead and commit LUCENE-698 since this NaN problem is a \nseparate issue and not only happing for the FilteredQuery. ",
            "author": "Michael Busch",
            "id": "comment-12500252"
        },
        {
            "date": "2007-05-30T23:11:20+0000",
            "content": "Patch committed. ",
            "author": "Michael Busch",
            "id": "comment-12500257"
        },
        {
            "date": "2007-05-31T18:04:22+0000",
            "content": "> If boost is zero, then\n> sumOfSquaredWeights() returns zero as well, resulting in a\n> queryNorm of Infinity (due to a div by zero if DefaultSimilarity is\n> used). Then it multiplies boost and queryNorm and 0*Infinity=NaN.\n\nThe bug here to me seems that queryNorm is Infinity.  A boost of zero has a reasonable interpretation (don't influence scoring), but I don't see how a queryNorm of Infinity is ever useful.  So perhaps we can remove the NaN by modifying the default implementation of queryNorm to return 1.0 instead of Infinity when passed zero.  Would that cause any harm? ",
            "author": "Doug Cutting",
            "id": "comment-12500427"
        },
        {
            "date": "2007-05-31T18:28:19+0000",
            "content": "> the default implementation of queryNorm to return 1.0 instead of Infinity when passed zero.\n\nThat seems like it should be fine, esp since Similarity.queryNorm is only called at the top level when creating a weight. ",
            "author": "Yonik Seeley",
            "id": "comment-12500437"
        },
        {
            "date": "2007-06-01T01:56:07+0000",
            "content": "> So perhaps we can remove the NaN by modifying the default implementation of \n> queryNorm to return 1.0 instead of Infinity when passed zero. Would that \n> cause any harm?\n\nYes I believe this should work, too. This would prevent the NaN score when\nDefaultSimilarity is used. It will be the responsibility of people\nwho implement their own Similarity then to take care of this in a similar way.\n\nI'll open a new issue for fixing the DefaultSimilarity. ",
            "author": "Michael Busch",
            "id": "comment-12500552"
        }
    ]
}