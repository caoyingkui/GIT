{
    "id": "LUCENE-4931",
    "title": "Make oal.document.Field reuse its internal StringTokenStream",
    "details": {
        "components": [
            "core/index"
        ],
        "fix_versions": [],
        "affect_versions": "4.0,                                            4.1,                                            4.2,                                            4.2.1",
        "priority": "Major",
        "labels": "",
        "type": "Bug",
        "resolution": "Not A Problem",
        "status": "Resolved"
    },
    "description": "Followup from LUCENE-4930:\nField.java has a private StringTokenStream which is used as TokenStream implementation for StringField (single value String tokens). Unfortunately this TokenStream is created on every new document/field while indexing, making the cost of creating the TS a significant time. With very old Java versions this also involves a lock in ReferenceQueue.poll() when called from addAttribute().\n\nIn Lucene 3.x, DocInverterPerThread has a private thread-local AttributeSource for reusing, but because this was factored out to Field.java, we can no longer use CloseableThreadLocal (because Field are not Closeable). We should maybe move the special One-Token TokenStream back to DocInverterPerThread and just let Field.java delegate there. I know this would let us move back to 3.x where we had special handling of single token Fields in the indexer....\n\nAnother approach would be to make Field.java use a static KeywordAnalyzer (it needs then be moved to core) or we add a ThreadLocal to Field.java (which may be expensive). Unfortunately this makes it hard to maintain, as the thread-localness is also needed to be bound to the IndexWriter instance. Because you could have 2 IndexWriters open at same time and add documents to both of them from one thread... This brings us back to my previous solution.",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "date": "2013-04-12T16:54:53+0000",
            "content": "I'm trying to understand the problem, its only if:\n\n\tyou aren't reusing field instances\n\tyou aren't just using KeywordTokenizer in your Analyzer for \"string fields\" (so they also work with queryparser etc)\n\tyou have an ancient JVM\n\n\n\nI dont like the idea of adding the private analyzer back to documentsinverter if we can avoid it.\n\nI also don't understand how its not an issue for e.g. IntField too, shouldnt it be the same there? ",
            "author": "Robert Muir",
            "id": "comment-13630309"
        },
        {
            "date": "2013-04-12T18:57:21+0000",
            "content": "Robert, you are right.\nI added the approach on a IndexWriter-based cache to the issue, because this is how Lucene 3.x worked. In Lucene 3.x you were able to recreate Field instances on every document and IndexWriter would still reuse the internal per-thread AttributeSource.\n\nIn Lucene 4.0, all NumericFields can be reused and that works. The NumericField reuses the NumericTokenStream inside (but its lazy inited to not load it together if you are only interested in stored fields on the IndexReader side). Whenever you set a new value to the Field, it is reset to the new value. Of course if you don't reuse your NumericField instances, its created over an over (this was the same in Lucene 3.x).\n\nA default Field (e.g. StringField) creates a new TokenStream on every call to Field#tokenStream(). So if you reuse your StringField instances, the TokenStreams are recreated again and again. This is the bug here.\n\nI will provide a patch that des the same like NumericField does: I will add the same logic like used for NumericTokenStream:\n\n\tStringTokenStream gets a pkg-private reset(String) method, the String is removed from ctor.\n\tOn Field#tokenStream() it first lazyly creates the TokenStream (if needed) using the no-arg ctor, it then calls reset(stringValue()) and returns it\n\n ",
            "author": "Uwe Schindler",
            "id": "comment-13630488"
        },
        {
            "date": "2013-04-12T19:13:18+0000",
            "content": "Sorry,\nthis issue was already solved by an earlier commit by me: LUCENE-4317 and LUCENE-4315\n\nIf you still see the problems, you should reuse your StringField instances. If you recreate them, the TokenStream is not reused!\n\nUwe ",
            "author": "Uwe Schindler",
            "id": "comment-13630514"
        }
    ]
}