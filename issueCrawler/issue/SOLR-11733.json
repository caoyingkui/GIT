{
    "id": "SOLR-11733",
    "title": "add an option make json.facet refinement more \"optimistic\" like facet.field/facet.pivot so that long tail have a change to bubble up",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [
            "Facet Module"
        ],
        "type": "Improvement",
        "fix_versions": [],
        "affect_versions": "None",
        "resolution": "Unresolved",
        "status": "Open"
    },
    "description": "json.facet refinement is currently \"pessimistic\" by default.  Specifically: \"Long Tail\" terms that may not be in the \"top n\" on every shard, but are in the \"top n + overrequest\" for at least 1 shard aren't getting refined and included in the aggregated response in some cases.\n\nThis is different then the \"optimistic\" approach taken in the existing facet.field and facet.pivot refinement, that refines all known terms whose counts might be high enough to put them in the topN based on what's known about the lowest count returned by each shard in phase #1.\n\nA mitigating option that people with particular concerns about long tail terms can consider is to set a \"high\" value for the overrefine parameter \u2013 forcing Solr to refine more terms from phase#1 \u2013 but this is somewhat of a \"brute force\" workaround, since it doesn't take into account any known info about the results of each shard from phase#1.\n\nThis issue tracks possible improvements that could be made to the faceting code to be more sophisticated.\n\u00a0\n\n(NOTE: this Jira was originally filed as a bug report noting that json.facet refinement didn't seem to be working properly compared to facet.field refinement, and early comments are written in this mindset)",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "date": "2017-12-07T00:44:05+0000",
            "content": "\nSteps to reproduce..\n\nBuild Collection & Index Some Data\n\n\n# start up a small solr cluster\n$ bin/solr -e cloud -noprompt\n...\n\n# NOTE: we're ignoring the getting started collection that was created\n# we'll make our own using the implicit router with one shard per node\n\n$ curl 'http://localhost:8983/solr/admin/collections?action=CREATE&name=test&router.name=implicit&numShards=2&shards=shardX,shardY'\n...\n\n# Index 5 docs to *each* shards with:\n# - the same \"top 5\" terms in all 5 docs on both shards\n# - a common \"tail\" term in 2 docs on *both* shards\n#   - w/a total of 4 docs, \n# - some shard specific \"distrating\" terms that each appear in only 3 docs, and always on single shard\n#   - On the 1st shard: there are 5 of these terms, such that 'tail' will be the #11 ranked term (on this shard)\n#   - On the 2nd shard: 'tail' will be the #7 ranked term (on this shard)\n\n$ curl -H 'Content-Type: application/json' 'http://localhost:8983/solr/test/update?commit=true' --data-binary '[\n{ \"id\": \"1_1\", \"foo_t\": \"a1 a2 a3 a4 a5   x1 x2 x3 x4 x5\" },\n{ \"id\": \"1_2\", \"foo_t\": \"a1 a2 a3 a4 a5   x1 x2 x3 x4 x5\" },\n{ \"id\": \"1_3\", \"foo_t\": \"a1 a2 a3 a4 a5   x1 x2 x3 x4 x5\" },\n{ \"id\": \"1_4\", \"foo_t\": \"a1 a2 a3 a4 a5                   tail\" },\n{ \"id\": \"1_5\", \"foo_t\": \"a1 a2 a3 a4 a5                   tail\" },\n]'\n...\n$ curl -H 'Content-Type: application/json' 'http://localhost:7574/solr/test/update?commit=true' --data-binary '[\n{ \"id\": \"2_1\", \"foo_t\": \"a1 a2 a3 a4 a5   yyy\" },\n{ \"id\": \"2_2\", \"foo_t\": \"a1 a2 a3 a4 a5   yyy\" },\n{ \"id\": \"2_3\", \"foo_t\": \"a1 a2 a3 a4 a5   yyy\" },\n{ \"id\": \"2_4\", \"foo_t\": \"a1 a2 a3 a4 a5        tail\" },\n{ \"id\": \"2_5\", \"foo_t\": \"a1 a2 a3 a4 a5        tail\" },\n]'\n...\n\n\n\n\nSanity Check Queries\n\nWith an excessive 'limit' or 'overrequest' we can verify that 'tail' is the #6 ranked term overall (even with refinement explicitly disabled)\n\n\n$ curl http://localhost:7574/solr/test/select -d 'q=*:*&wt=json&rows=0&json.facet={foo:{type:terms,field:foo_t,limit:7,overrequest:100,refine:false}}'\n...\n  \"response\":{\"numFound\":10,\"start\":0,\"maxScore\":1.0,\"docs\":[]\n  },\n  \"facets\":{\n    \"count\":10,\n    \"foo\":{\n      \"buckets\":[{\n          \"val\":\"a1\",\n          \"count\":10},\n        {\n          \"val\":\"a2\",\n          \"count\":10},\n        {\n          \"val\":\"a3\",\n          \"count\":10},\n        {\n          \"val\":\"a4\",\n          \"count\":10},\n        {\n          \"val\":\"a5\",\n          \"count\":10},\n        {\n          \"val\":\"tail\",\n          \"count\":4},\n        {\n          \"val\":\"x1\",\n          \"count\":3}]}}}\n\n$ curl http://localhost:7574/solr/test/select -d 'q=*:*&wt=json&rows=0&json.facet={foo:{type:terms,field:foo_t,limit:100,overrequest:0,refine:false}}'\n...\n  \"facets\":{\n    \"count\":10,\n    \"foo\":{\n      \"buckets\":[{\n          \"val\":\"a1\",\n          \"count\":10},\n        {\n          \"val\":\"a2\",\n          \"count\":10},\n        {\n          \"val\":\"a3\",\n          \"count\":10},\n        {\n          \"val\":\"a4\",\n          \"count\":10},\n        {\n          \"val\":\"a5\",\n          \"count\":10},\n        {\n          \"val\":\"tail\",\n          \"count\":4},\n        {\n          \"val\":\"x1\",\n          \"count\":3},\n        ...\n\n\n\nLikewise, if we query each shard individual (w/ distrib=false ) we confirm that the \"tail\" term shows up in it's expected ranking...\n\n\n$ curl http://localhost:8983/solr/test/select -d 'distrib=false&q=*:*&wt=json&rows=0&json.facet={foo:{type:terms,field:foo_t,limit:11}}'\n...\n      \"buckets\":[{\n          \"val\":\"a1\",\n          \"count\":5},\n        {\n          \"val\":\"a2\",\n          \"count\":5},\n        {\n          \"val\":\"a3\",\n          \"count\":5},\n        {\n          \"val\":\"a4\",\n          \"count\":5},\n        {\n          \"val\":\"a5\",\n          \"count\":5},\n        {\n          \"val\":\"x1\",\n          \"count\":3},\n        {\n          \"val\":\"x2\",\n          \"count\":3},\n        {\n          \"val\":\"x3\",\n          \"count\":3},\n        {\n          \"val\":\"x4\",\n          \"count\":3},\n        {\n          \"val\":\"x5\",\n          \"count\":3},\n        {\n          \"val\":\"tail\",\n          \"count\":2}]}}}\n\n$ curl http://localhost:7574/solr/test/select -d 'distrib=false&q=*:*&wt=json&rows=0&json.facet={foo:{type:terms,field:foo_t,limit:7}}'\n...\n      \"buckets\":[{\n          \"val\":\"a1\",\n          \"count\":5},\n        {\n          \"val\":\"a2\",\n          \"count\":5},\n        {\n          \"val\":\"a3\",\n          \"count\":5},\n        {\n          \"val\":\"a4\",\n          \"count\":5},\n        {\n          \"val\":\"a5\",\n          \"count\":5},\n        {\n          \"val\":\"yyy\",\n          \"count\":3},\n        {\n          \"val\":\"tail\",\n          \"count\":2}]}}}\n\n\n\n\n\nQueries that Fail\n\nw/refinement, a limit of 6 (plus the implicit default overrequest) should be enough to find 'tail' \u2013 but it's not included in the response from this query...\n\n\n$ curl http://localhost:7574/solr/test/select -d 'q=*:*&wt=json&rows=0&json.facet={foo:{type:terms,field:foo_t,limit:6,refine:true}}'\n...\n      \"buckets\":[{\n          \"val\":\"a1\",\n          \"count\":10},\n        {\n          \"val\":\"a2\",\n          \"count\":10},\n        {\n          \"val\":\"a3\",\n          \"count\":10},\n        {\n          \"val\":\"a4\",\n          \"count\":10},\n        {\n          \"val\":\"a5\",\n          \"count\":10},\n        {\n          \"val\":\"x1\",\n          \"count\":3}]}}}\n\n\n\nEven if we assume the implicit overrequest calculation may be broken, a \"limit\" of 6 + an explicit overrequest of \"1\" should be enough to discover 'tail' on the 2nd shard, and (w/refinement) it should bubble up into the top 6 \u2013 but again, this limit:6,overrequest:1 query doesn't find tail...\n\n\n$ curl http://localhost:7574/solr/test/select -d 'q=*:*&wt=json&rows=0&json.facet={foo:{type:terms,field:foo_t,limit:6,overrequest:1,refine:true}}'\n...\n      \"buckets\":[{\n          \"val\":\"a1\",\n          \"count\":10},\n        {\n          \"val\":\"a2\",\n          \"count\":10},\n        {\n          \"val\":\"a3\",\n          \"count\":10},\n        {\n          \"val\":\"a4\",\n          \"count\":10},\n        {\n          \"val\":\"a5\",\n          \"count\":10},\n        {\n          \"val\":\"x1\",\n          \"count\":3}]}}}\n\n\n\nHere's the log messages from each node when the last request ( limit:6,overrequest:1,refine:true ) was executed...\n\n\nINFO  - 2017-12-07 00:27:37.821; [c:test s:shardY r:core_node4 x:test_shardY_replica_n2] org.apache.solr.core.SolrCore; [test_shardY_replica_n2]  webapp=/solr path=/select params={df=_text_&distrib=false&_facet_={}&fl=id&fl=score&shards.purpose=1048580&start=0&fsv=true&shard.url=http://127.0.1.1:8983/solr/test_shardY_replica_n2/&rows=0&version=2&q=*:*&json.facet={foo:{type:terms,field:foo_t,limit:6,overrequest:1,refine:true}}&NOW=1512606457819&isShard=true&wt=javabin} hits=5 status=0 QTime=0\n\n==> example/cloud/node2/logs/solr.log <==\nINFO  - 2017-12-07 00:27:37.821; [c:test s:shardX r:core_node3 x:test_shardX_replica_n1] org.apache.solr.core.SolrCore; [test_shardX_replica_n1]  webapp=/solr path=/select params={df=_text_&distrib=false&_facet_={}&fl=id&fl=score&shards.purpose=1048580&start=0&fsv=true&shard.url=http://127.0.1.1:7574/solr/test_shardX_replica_n1/&rows=0&version=2&q=*:*&json.facet={foo:{type:terms,field:foo_t,limit:6,overrequest:1,refine:true}}&NOW=1512606457819&isShard=true&wt=javabin} hits=5 status=0 QTime=0\nINFO  - 2017-12-07 00:27:37.823; [c:test s:shardX r:core_node3 x:test_shardX_replica_n1] org.apache.solr.core.SolrCore; [test_shardX_replica_n1]  webapp=/solr path=/select params={df=_text_&distrib=false&_facet_={\"refine\":{\"foo\":{\"_l\":[\"x1\"]}}}&shards.purpose=2097152&shard.url=http://127.0.1.1:7574/solr/test_shardX_replica_n1/&rows=0&version=2&q=*:*&json.facet={foo:{type:terms,field:foo_t,limit:6,overrequest:1,refine:true}}&NOW=1512606457819&isShard=true&facet=false&wt=javabin} hits=5 status=0 QTime=0\nINFO  - 2017-12-07 00:27:37.824; [c:test s:shardX r:core_node3 x:test_shardX_replica_n1] org.apache.solr.core.SolrCore; [test_shardX_replica_n1]  webapp=/solr path=/select params={q=*:*&json.facet={foo:{type:terms,field:foo_t,limit:6,overrequest:1,refine:true}}&rows=0&wt=json} hits=10 status=0 QTime=5\n\n\n\n\n...note that this appears to show:\n\n\n\tan explicit \"refine\" request for \" \"_l\":[\"x1\"] \" logged by port 7574\n\t\n\t\tport 7574  doesn't have the term \"x1\" at all so would not have returned it in it's initial results\n\t\n\t\n\tNO indication of attempting to refine \"x2\", \"yyy\", or \"tail\"\n\t\n\t\tthis in spite of the fact that they should have all been in the \"top 6+1\" from one shard, with counts making them competitive in the final results\n\t\n\t\n\n\n\nWhat strikes me as most odd, is that even if there was some sort of \"off by one\" error preventing \"x2\" & \"tail\" (which should have been the \"last\" bucket from each of their respective shards) from being refined, \"yyy\" would have had the exact same count, and been in the exact same (shard specific) bucket as \"x1\" \u2013 so why isn't there at a request to port #8983 to refine it?!  How is it different from \"x1\" ???\n ",
            "author": "Hoss Man",
            "id": "comment-16281188"
        },
        {
            "date": "2017-12-07T02:51:49+0000",
            "content": "I mentioned in SOLR-11729 the refinement algorithm being different (and for a single-level facet field, simpler).\nIt can be explained as:\n1) find buckets to return as if you weren't doing refinement\n2) for those buckets, make sure all shards have contributed to the statistics\ni.e. simple refinement doesn't change the buckets you get back.\n\nI started with the simplest for obvious reasons... to get something out.  From a correctness POV, smarter faceting is equivalent to increasing the overrequest amount... we still can't make guarantees.\nWe could easily implement a mode for some field facets that does the \"could this possibly be in the top N\" logic to consider more buckets in the first phase... but only if it's not a sub-facet of another partial facet (a facet with something like a limit).  If we're sorting by something other than count (like stddev for instance) then I guess we'd have to discard smart pruning and just try to get all buckets we saw in the first phase.\n\nIf a partial facet is a sub-facet of another partial-facet, the logic of what one can exclude seems to get harder, and then sub-facets need to add new candidate buckets to parent facets (I think? need to think about it more... but I guess that's part of my point .  Good ideas perhaps, but definitely more difficult to implement.\n\nOther refinement implementations could range all the way to \"exact\"... guarantee that no buckets are missed, and there's more than one way to go about that too.\n ",
            "author": "Yonik Seeley",
            "id": "comment-16281258"
        },
        {
            "date": "2017-12-07T18:23:00+0000",
            "content": "\n\nI mentioned in SOLR-11729 the refinement algorithm being different (and for a single-level facet field, simpler).\n\nFWIW, here's yonik's comment from SOLR-11729 which seems to specifically be on point for this issue (emphaiss mine)...\n\nIt seems like there are many logical ways to refine results - I originally thought about using refine:simple because I imagined we would have other implementations in the future.  Anyway, this one is the simplest one to think about and implement: the top buckets to return for all facets are determined in the first phase. The second phase only gets contributions from other shards for those buckets.\n\ni.e. simple refinement doesn't change the buckets you get back.\n\nAh ... ok.  I didn't realize the refinement approach in json.facet wasn't as sophisticated as facet.field\n\nTo summarize again (in my own words to ensure I'm understanding you correctly):\n\n\n\tdo a first pass, requesting \"#limit + #overrequest\" buckets from each shard\n\t\n\t\tuse the accumulated results of the first pass to determine the \"top #limit buckets\"\n\t\n\t\n\tdo a second passs, in which we back-fill the \"top #limit buckets\" with data from any shards that have no yet contributed.\n\n\n\nIn which case, in my example above, the reason yyy isn't refined, even though it has the same \"first pass\" total as x1, is because during the first pass x1 sorts higher (due to a secondary tie breaker sort on the terms) pushing yyy out of the \"top 6\".  (likewise x2 and tail are never considered because they were never part of the \"top 6\" even w/o a tie breaker sort)\n\nDo I have that correct?\n\n\n\nThe Bottom line: even if i don't fully grasp the current refinement mechanism you've described, is that you're saying the behavior i described with the above sample documents is not a bug: it's the intended/expected behavior of refine:true (aka refine:simple )\n\nIf so i'll edit this jira into an \"Improvement\" & update the summary/description to clarify how facet.pivot refinement differs from json.facet + refine:simple & leave open for future improvement\n\n\n\n\nAs far as discussion on potential improvements....\n\n\nFrom a correctness POV, smarter faceting is equivalent to increasing the overrequest amount... we still can't make guarantees.\n\nHmmm... I'm not sure that i agree with that assessment.  I guess \"mathematically\" speaking it's true that compared to a \"smarter\" refinement method, this \"simple\" refine method can product equally \"correct\" top terms solely by increasing the overrequest amount \u2013 but that's like saying we don't even need any refinement method at all as long as we specify an infinite amount of overrequest.\n\nWith the refinement approach used by facet.field (and facet.pivot) we can make garuntees about the correctness of the top terms \u2013 regardless of if/how-much overrequesting is used \u2013 for any term that is in the \"top buckets\" of at least one shard.\n\nIIUC the current json.facet refinement method can't make any similar garuntees at all, regardless of what (finite) overrequest value is specified ... but facet.field certainly can:\n\nIn facet.field today, If:\n\n\tA term is in the \"top buckets\" (limit + overrequest) returned by at least one shard\n\tAnd the sort value (ie: count) returned by that shard (along with the lowest sort-value/count returned by all other shards) indicates that the term might be competitive realtive to the other terms returned by other shards\n...then that term is refined. That's a garuntee we can make.\n\n\n\nMeaning that even if you have shards with widely diff term stats (ie: time partioned shards, or docs co-located due to multi-level compositeId, or block join, etc..) we can/will refine the top terms from each shard.\n\nIn facet.field the overrequest helps to:\n\n\tincrease the scope of how deep we look to find the \"top (candidate) terms\" from each shard\n\tdecreases the amount of data we have to request when refineing\n\n\n\n...but the distribution of terms across shards has very little (none? ... not certain) impact on the \"correctness\" of the \"top N\" in the aggregate.  Even if the first pass \"top terms\" from each shard is 100% unique, the realtive \"bottom\" counts from each shard is considered before assuming that the \"higher\" counts should win \u2013 meaning that if the shards have very different sizes, \"top terms\" from the smaller shards still have a chance of being considered as an \"aggregated top term\" as long as the \"bottom count\" from the (larger) shards is high enough to indicate that those (missing) terms might still be competitive.\n\nBut in the json.facet approach to refinement, IIUC: A term returned by only one shard won't be considered unless the count from just that one shard is high enough to help it dominate over the cumulative counts from each of the top terms of the other shards.\n\nWhich seems to not only make the amount of overrequesting much more important to consider when requesting refinement, but also requires you to consider the comparative sizes of the shards, and the potential term distribution variances between them.  \n\n\nOr to put it another way...\n\nTL,DR: IIUC, the amount of overrequest is much more important to consider when requesting refinement on json.facet then it has ever been with facet.field, but when picking an overrequest amount for json.facet, people also need to consider the relative differences in sizes of their shards, and the potential term distribution variances that may exist between them.\n\n\n(correct?)\n\n\n\nWe could easily implement a mode for some field facets that does the \"could this possibly be in the top N\" logic to consider more buckets in the first phase... but only if it's not a sub-facet of another partial facet (a facet with something like a limit). If we're sorting by something other than count (like stddev for instance) then I guess we'd have to discard smart pruning and just try to get all buckets we saw in the first phase.\n\nYou lost me there.... If the sort is on some criteria other then count (ex: stddev), why can't we compute a hypothetical \"best case\" sort value for the candidates based on the pre-aggregation values returned by the \"bottom\" of the other shards (ex: the sum, sumsq, and num_values already needed from each shard for the aggregated stddev) in combination with the values from the one shard that does have that term?\n\nIf a partial facet is a sub-facet of another partial-facet, the logic of what one can exclude seems to get harder, ...\n\nYou completely lost me there ... I think maybe you're alluding to the need for multi-stage refinement depending on how deep the nested facets go?  which FWIW is exactly what facet.pivot does today.\n\n ",
            "author": "Hoss Man",
            "id": "comment-16282264"
        },
        {
            "date": "2017-12-12T19:03:03+0000",
            "content": "Commit 53f2d4aa3aa171d5f37284eba9ca56d987729796 in lucene-solr's branch refs/heads/branch_7x from Chris Hostetter\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=53f2d4a ]\n\nBeef up testing of json.facet 'refine:simple' when dealing with 'Long Tail' terms\n\nIn an attempt to get more familiar with json.facet refinement, I set out to try and refactor/generalize/clone\nsome of the existing facet.pivot refinement tests to assert that json.facet could produce the same results.\nThis test is a baby step towards doing that: Cloning DistributedFacetPivotLongTailTest into\nDistributedFacetSimpleRefinementLongTailTest (with shared index building code).\n\nAlong the way, I learned that the core logic of 'refine:simple' is actually quite different then how facet.field\n& facet.pivot work (see discussion in SOLR-11733), so they do NOT produce the same results in many \"Long Tail\"\nSitautions.  As a result, many of the logic/assertions inDistributedFacetSimpleRefinementLongTailTest are very\ndiffernet then their counter parts in DistributedFacetPivotLongTailTest, with detailed explanations in comments.\n\nHopefully this test will prove useful down the road to anyone who might want to compare/contrast facet.pivot\nwith json.facet, and to prevent regressions in 'refine:simple' if/when we add more complex refinement\napproaches in the future.\n\nThere are also a few TODOs in the test related to some other small discrepencies between json.facet and\nstats.field that I opened along the way, indicating where the tests should be modified once those issues are\naddressed in json.facet...\n\n\n\tSOLR-11706: support for multivalued numeric fields in stats\n\tSOLR-11695: support for 'missing()' & 'num_vals()' (aka: 'count' from stats.field) numeric stats\n\tSOLR-11725: switch from 'uncorrected stddev' to 'corrected stddev'\n\n\n\n(cherry picked from commit 2990c88a927213177483b61fe8e6971df04fc3ed) ",
            "author": "ASF subversion and git services",
            "id": "comment-16288083"
        },
        {
            "date": "2017-12-12T19:03:17+0000",
            "content": "Commit 2990c88a927213177483b61fe8e6971df04fc3ed in lucene-solr's branch refs/heads/master from Chris Hostetter\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=2990c88 ]\n\nBeef up testing of json.facet 'refine:simple' when dealing with 'Long Tail' terms\n\nIn an attempt to get more familiar with json.facet refinement, I set out to try and refactor/generalize/clone\nsome of the existing facet.pivot refinement tests to assert that json.facet could produce the same results.\nThis test is a baby step towards doing that: Cloning DistributedFacetPivotLongTailTest into\nDistributedFacetSimpleRefinementLongTailTest (with shared index building code).\n\nAlong the way, I learned that the core logic of 'refine:simple' is actually quite different then how facet.field\n& facet.pivot work (see discussion in SOLR-11733), so they do NOT produce the same results in many \"Long Tail\"\nSitautions.  As a result, many of the logic/assertions inDistributedFacetSimpleRefinementLongTailTest are very\ndiffernet then their counter parts in DistributedFacetPivotLongTailTest, with detailed explanations in comments.\n\nHopefully this test will prove useful down the road to anyone who might want to compare/contrast facet.pivot\nwith json.facet, and to prevent regressions in 'refine:simple' if/when we add more complex refinement\napproaches in the future.\n\nThere are also a few TODOs in the test related to some other small discrepencies between json.facet and\nstats.field that I opened along the way, indicating where the tests should be modified once those issues are\naddressed in json.facet...\n\n\n\tSOLR-11706: support for multivalued numeric fields in stats\n\tSOLR-11695: support for 'missing()' & 'num_vals()' (aka: 'count' from stats.field) numeric stats\n\tSOLR-11725: switch from 'uncorrected stddev' to 'corrected stddev'\n\n ",
            "author": "ASF subversion and git services",
            "id": "comment-16288087"
        },
        {
            "date": "2018-07-23T17:32:17+0000",
            "content": "Edited summary & description based on discussion in comments so far \u2013 added an explicit note about the overrefine option as a potential workaround/mitigation approach for people particularly concerned about long tail terms ",
            "author": "Hoss Man",
            "id": "comment-16553147"
        },
        {
            "date": "2018-07-23T17:32:52+0000",
            "content": "Linking SOLR-12343 where overrefine was added ",
            "author": "Hoss Man",
            "id": "comment-16553149"
        }
    ]
}