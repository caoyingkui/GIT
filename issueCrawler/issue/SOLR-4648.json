{
    "id": "SOLR-4648",
    "title": "Create a PreAnalyzedUpdateProcessor",
    "details": {
        "affect_versions": "4.3,                                            6.0",
        "status": "Closed",
        "fix_versions": [
            "4.3",
            "6.0"
        ],
        "components": [
            "update"
        ],
        "type": "Bug",
        "priority": "Major",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "Spin-off from the discussion in SOLR-4619.\n\nInstead of using a PreAnalyzedField type we can use an UpdateRequestProcessor that converts any input field values to StorableField-s, using the PreAnalyzedParser-s, and then directly passes StorableField-s to DocumentBuilder for indexing.",
    "attachments": {
        "SOLR-4648.patch": "https://issues.apache.org/jira/secure/attachment/12575745/SOLR-4648.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Andrzej Bialecki",
            "id": "comment-13615636",
            "date": "2013-03-27T18:58:00+0000",
            "content": "Patch and unit test. "
        },
        {
            "author": "Andrzej Bialecki",
            "id": "comment-13615640",
            "date": "2013-03-27T19:03:06+0000",
            "content": "Oops, this needs to be visible after all... "
        },
        {
            "author": "David Smiley",
            "id": "comment-13617342",
            "date": "2013-03-29T13:53:15+0000",
            "content": "Great start Andrzej!\n\nReviewing the patch...\n\nI think PreAnalyzedUpdateProcessorFactory should extend Jan H\u00f8ydahl's FieldMutatingUpdateProcessorFactory, which will shorten some of your code and give it more flexibility on how fields are matched.\n\nIn PreAnalyzedField line 112:\n\n      LOG.warn(\"Error parsing pre-analyzed field '\" + field.getName() + \"': \" + e.toString());\n\n\nShouldn't you pass 'e' as the last arg to warn()?\n\nIt would be interesting to test this against the example Solr schema with pre-analyzing every field to see if it works, comparing the index output using the SimpleTextCodec.  I strongly suspect it won't, since there is more to the state of a Field than it's tokenStream and stored value \u2013 which seem to be the only thing the code in this patch accounts for.  For example its 'type' (Lucene FieldType).\n\nIn summary, great start!\n "
        },
        {
            "author": "Andrzej Bialecki",
            "id": "comment-13617463",
            "date": "2013-03-29T16:08:38+0000",
            "content": "David, thanks for the review. I'll prepare a new patch, using the FieldMutatingUP* classes - indeed, I missed them and they help a lot.\n\nsince there is more to the state of a Field than it's tokenStream and stored value...\nI can try creating the StorableField using the SchemaField.createField(...) for this field's type, so that most of its state will be specific to the declared schema field, and the only mutations will be to set the optional stringValue and the tokenStreamValue, and to flip the type flags accordingly. "
        },
        {
            "author": "Andrzej Bialecki",
            "id": "comment-13620863",
            "date": "2013-04-03T11:45:39+0000",
            "content": "Updated patch, using FieldMutatingUP*, more tests and javadocs. "
        },
        {
            "author": "David Smiley",
            "id": "comment-13621024",
            "date": "2013-04-03T16:21:19+0000",
            "content": "Feedback on your patch:\n\n\tin Solr, it's bad form to call Class.forName() as you're doing in PreAnalzyedField; you're supposed to use the SolrResourceLoader instead.  Instead use schema.getResourceLoader().findClass(implName, PreAnalyzedParser.class);\n\tminor: you're using 4-spaces indent instead of 2 in the main value loop in your URP\n\tin those log.debug() calls, it's creating the string to potentially not even log it.  Instead use this feature of SLF4J: log.debug(\"Ignoring stored part - field '{}' is not stored.\", sf.getName());  So few people use that great feature of SLF4J and instead rely on more bulky surrounding conditionals.\n\tWhen you call sf.createFields(o, 1.0f) in the URP, isn't this doing analysis \u2013 the very analysis that you're trying to avoid by pre-analyzing?  It is.  And isn't 'o' the JSON or similar representation of the analyzed token stream, and thus shouldn't be passed in here?  When I run your test, I get a logged error because of this, actually.  Stepping through with a debugger further validated this.  This must be remedied.  Looking at what FieldType.createField() is doing, I propose you do the same in this URP:\n\n\n\n\norg.apache.lucene.document.FieldType newType = new org.apache.lucene.document.FieldType();\n    newType.setIndexed(field.indexed());\n    newType.setTokenized(field.isTokenized());\n    newType.setStored(field.stored());\n    newType.setOmitNorms(field.omitNorms());\n    newType.setIndexOptions(getIndexOptions(field, val));\n    newType.setStoreTermVectors(field.storeTermVector());\n    newType.setStoreTermVectorOffsets(field.storeTermOffsets());\n    newType.setStoreTermVectorPositions(field.storeTermPositions());\n//getIndexOptions() is:\n    IndexOptions options = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS;\n    if (field.omitTermFreqAndPositions()) {\n      options = IndexOptions.DOCS_ONLY;\n    } else if (field.omitPositions()) {\n      options = IndexOptions.DOCS_AND_FREQS;\n    } else if (field.storeOffsetsWithPositions()) {\n      options = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n    }\n//then what createField() does is:\n    Field f = new Field(name, val, type);\n    f.setBoost(boost);\n\n\nThis won't work for all field types (e.g. numbers) but it will for TextField (the one with analysis!) and could potentially for a custom FieldType.  I don't think we should put much if any work into supporting other FieldTypes.\n\nThe resulting \"Field\" instance can be shared from one document to the next I believe, and so you can cache this in the URP and reset its value & tokenStream. "
        },
        {
            "author": "Andrzej Bialecki",
            "id": "comment-13622080",
            "date": "2013-04-04T12:21:04+0000",
            "content": "Thanks again for a thorough review. New patch is attached.\n\nin Solr, it's bad form to call Class.forName() ..\n\nFixed.\n\nminor: you're using 4-spaces indent instead of 2 in the main value loop in your URP\n\nFixed (it was actually a left-over from removing an outer-level loop, all other indents are 2 spaces).\n\nin those log.debug() calls, it's creating the string to potentially not even log it\n\nFixed.\n\nLooking at what FieldType.createField() is doing, I propose you do the same in this URP ...\n\nFunny thing, I had this in one version of the patch, and then decided to reuse SF.createField(..) to avoid code duplication. The problem is that SchemaField.isTokenized() has package-level visibility so it's not visible in the UP's package. I fixed this by providing a utility method in PreAnalyzedField to create a FieldType. Also, I moved there the chunk of logic for setting / resetting the Field content and type flags based on SchemaField. Overall, it simplifies the UP.\n\nThe resulting \"Field\" instance can be shared from one document to the next I believe, and so you can cache this in the URP and reset its value & tokenStream.\n\nHmm, this doesn't seem feasible at all. First, this cache would have to be thread safe, and prevent reuse of Field instances until the document is actually processed by IndexWriter - I don't think there's a mechanism to enforce this in the context of this class? Also it would have to cache multiple instances of Field, because processing a single document may result in creating multiple instances (at least one per pre-analyzed field, more if fields are multi-valued). "
        },
        {
            "author": "David Smiley",
            "id": "comment-13622621",
            "date": "2013-04-04T18:26:31+0000",
            "content": "I like how your refactoring has clarified the logic in the URP.  And I like your new PreAnalyzedUpdateProcessorFactory.createFieldType() method.\n\nI think you're right that sharing Field instances isn't such a good idea after all.\n\n\n\tminor: in the URP, \"for (Object o : src.getValues()) {\" can be \"for (Object o : src) {\"  since it implements Iterable, and for the single-value case avoids redundant collection wrapping.\n\n\n\nThe remaining thing I'm thinking of is wether PreAnalyzedUpdateProcessorFactory.createFieldType() should move down into Solr's FieldType where it can be re-used so we don't duplicate this code.  Seems pretty clear this is a good idea.  Then, I'm wondering if these Lucene FieldType instances could be cached on Solr's SchemaField so that they don't have to be needlessly re-created for each indexed value that runs through Solr.  The only obstacle I see to this is that getIndexOptions(field,val) takes the value, and if that value were to alter the logic then the FieldType can't be shared.  This is a protected method and I don't see anything that overrides it, and the default implementation doesn't use the value.  I'll create another issue for that; I can get off track easily and try to fix the world in one issue  "
        },
        {
            "author": "Andrzej Bialecki",
            "id": "comment-13622672",
            "date": "2013-04-04T19:15:42+0000",
            "content": "minor: in the URP, \"for (Object o : src.getValues()) {\" can be \"for (Object o : src) {\" since it implements Iterable\n\nI'll fix this before committing. Thanks again for the review.\n\nPreAnalyzedUpdateProcessorFactory.createFieldType() ..\n\n+1 to create a separate issue. "
        },
        {
            "author": "Andrzej Bialecki",
            "id": "comment-13623486",
            "date": "2013-04-05T09:51:17+0000",
            "content": "Committed to trunk in rev. 1464889.\nCommitted to branch_4x in rev. 1464902. "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-13653885",
            "date": "2013-05-10T10:33:17+0000",
            "content": "Closed after release. "
        }
    ]
}