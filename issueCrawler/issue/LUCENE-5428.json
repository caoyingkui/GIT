{
    "id": "LUCENE-5428",
    "title": "Make Faceting counting array overridable",
    "details": {
        "type": "Improvement",
        "priority": "Major",
        "labels": "",
        "resolution": "Unresolved",
        "components": [
            "modules/facet"
        ],
        "affect_versions": "4.6.1",
        "status": "Open",
        "fix_versions": []
    },
    "description": "In SortedSetDocValuesFacetCounts, the count array is allocated as an int[] size of number of total values across all facets and that is allocated per query.\n\nIn the case where number of values are large, large amount of garbage maybe created. Furthermore, the size of the array is dependent on the number of possible values, not number of number values needed for which facets fields are being accumulated for. E.g. if FacetSearchParam indicates counting only one 1 field with 2 values, we are still creating the array for all values across all fields.\n\nThis patch makes the count array abstract to allow for\n1) caching\n2) hash counting - which can choose to count only of needed fields.\n\nThis patch can be further enhanced to create FacetCouter per segment, per field by pass in the ordinal map.",
    "attachments": {
        "facetcounter.patch": "https://issues.apache.org/jira/secure/attachment/12626403/facetcounter.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "id": "comment-13888449",
            "author": "Shai Erera",
            "content": "Mike and I discussed this in the past, but I cannot find the discussion now, perhaps it was on Chat. The idea was the same as your patch - add an abstraction layer to how you count facets (and BTW, not just for SortedSet, but for the Taxonomy path too), because e.g. I'm working with a team which seems to have the exact same problem like yours \u2013 they have few million categories, yet sometimes they need to count only 1 (of very few), yet have to incur the cost of allocating the big FacetArrays.\n\nThe discussion happened in parallel to our attempts to abstract the taxonomy arrays API, on LUCENE-5316. We were forced to back off from that idea though, because faceted search insisted to slow down, to our disappointment.\n\nFor now, I advised the other team to write their own FacetsAggregator (Facets in the new API). I'm all for exploring a FacetsCounter API abstraction here, just noting that you have an option already, which is to implement your own Facets (yes, and maybe duplicate code...). ",
            "date": "2014-02-01T04:23:19+0000"
        },
        {
            "id": "comment-13888677",
            "author": "John Wang",
            "content": "Hi Shai:\n\n     We are currently writing our own accumulator/aggregator. But we would like to leverage as much Lucene code as possible.\n\n     I am not sure I understand how this abstraction would slow down faceting. Do you mean the method call overhead it would create?\n\n-John ",
            "date": "2014-02-01T19:08:25+0000"
        },
        {
            "id": "comment-13888682",
            "author": "Shai Erera",
            "content": "Do you mean the method call overhead it would create?\n\nExactly! On LUCENE-5316 we tried to replace a direct array access call with a method call which accesses the array internally, and the slowdowns were significant. The purpose there, as is the purpose here, is to allow for a more efficient representation of the arrays (whether compressed / map-based), but losing 60% on some queries seemed too much. Also, we didn't see an improvement on any of the changes. So ... it's kind of hard to justify such change in general.\n\nBasically, our MO is to make sure the abstraction doesn't hurt (much) the current implementations (i.e. FacetArrays). If that's case, I'll 1 to add the abstraction. With that behind us we're more free to explore whatever representation we feel like for the aggregated values (e.g. map). But if the abstraction itself loses like 10%, that's a bad sign because at the end of the day, most apps don't run extreme edge cases where they want to count 1-2 categories only, so they shouldn't suffer from a great slowdown. The expert apps should be able to optimize their case, sometimes it unfortunately means also duplicating code...\n\nSo let's first make sure how much do we lose by the abstraction itself. BTW, if there's a better representation for the counts that overall improves performance (with the abstraction), then that's of course a win/win! ",
            "date": "2014-02-01T19:25:40+0000"
        }
    ]
}