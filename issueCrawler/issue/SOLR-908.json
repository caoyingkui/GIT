{
    "id": "SOLR-908",
    "title": "Port of Nutch  CommonGrams filter to Solr",
    "details": {
        "affect_versions": "None",
        "status": "Closed",
        "fix_versions": [
            "1.4"
        ],
        "components": [
            "Schema and Analysis"
        ],
        "type": "Wish",
        "priority": "Minor",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "Phrase queries containing common words are extremely slow.  We are reluctant to just use stop words due to various problems with false hits and some things becoming impossible to search with stop words turned on. (For example \"to be or not to be\", \"the who\", \"man in the moon\" vs \"man on the moon\" etc.)  \n\nSeveral postings regarding slow phrase queries have suggested using the approach used by Nutch.  Perhaps someone with more Java/Solr experience might take this on.\n\nIt should be possible to port the Nutch CommonGrams code to Solr  and create a suitable Solr FilterFactory so that it could be used in Solr by listing it in the Solr schema.xml.\n\n\"Construct n-grams for frequently occuring terms and phrases while indexing. Optimize phrase queries to use the n-grams. Single terms are still indexed too, with n-grams overlaid.\"\nhttp://lucene.apache.org/nutch/apidocs-0.8.x/org/apache/nutch/analysis/CommonGrams.html",
    "attachments": {
        "SOLR-908.patch": "https://issues.apache.org/jira/secure/attachment/12411568/SOLR-908.patch",
        "CommonGramsPort.zip": "https://issues.apache.org/jira/secure/attachment/12404608/CommonGramsPort.zip"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Tom Burton-West",
            "id": "comment-12695637",
            "date": "2009-04-03T23:06:21+0000",
            "content": "Attached is my first cut at a port of the Nutch CommonGrams filter to Solr.   I still need to write tests for CommonGramsFilterFactory and CommonGramsQueryFilterFactory.  Nutch had a method call to optimize phrase queries.  For Solr I just wrote CommonGramsQueryFilter for handling queries.   Preliminary tests with a relatively small* index of 100,000 full-text documents (index size 44GB, about  30% larger than the index without commongrams)  indicate about 10x decrease in response times for phrase queries.   \n\nThis post by Hoss was extremely helpful as was his suggestion to use the Solr BufferedTokenStream  as a base class:\nhttp://www.nabble.com/Re%3A-Index---search-questions--special-cases-p7344056.html\n\n\nHere is an example schema.xml entry\n<fieldType name=\"ocrCommon\" class=\"solr.TextField\" positionIncrementGap=\"100\">\n      <analyzer type=\"index\">\n        <tokenizer class=\"solr.WhitespaceTokenizerFactory\"/>\n        <filter class=\"solr.LowerCaseFilterFactory\"/>\n        <filter class=\"solr.CommonGramsFilterFactory\"  words=\"commonwords.txt\"/>\n      </analyzer>\n      <analyzer type=\"query\">\n        <tokenizer class=\"solr.WhitespaceTokenizerFactory\"/>\n        <filter class=\"solr.LowerCaseFilterFactory\"/>\n        <filter class=\"solr.CommonGramsQueryFilterFactory\"  words=\"commonwords.txt\"/>\n      </analyzer>\n    </fieldType> \n\nTom Burton-West\nUniversity of Michigan Library\n-----------------------------------\n*We are working on indexing 1-6 million full-text documents. Our current 1 million document index is about 235GB,  so in our context 100,000 docs is relatively small.\n\nThe files in CommonGramsPort.zip are:\nCommonGramsFilter.java  \nCommonGramsFilterTest.java    \nCommonGramsFilterFactory.java \nCommonGramsQueryFilter.java   \nCommonGramsQueryFilterFactory.java   \nCommonGramsQueryFilterTest.java   \nTestCommonGrams.java     (Non-junit test for input on STDIN)\n\n "
        },
        {
            "author": "Tom Burton-West",
            "id": "comment-12723288",
            "date": "2009-06-23T20:24:30+0000",
            "content": "Attached is a patch which includes the code and unit tests for CommonGramsFilterFactory and CommonGramsQueryFilterFactory as well as the doce and  unit tests for CommonGramsFilter and CommonGramsQueryFilter. "
        },
        {
            "author": "Otis Gospodnetic",
            "id": "comment-12723418",
            "date": "2009-06-24T03:47:46+0000",
            "content": "I took a super quick look and noticed:\n\n\tnot all classes have ASL (I think unit test classes need it, too)\n\tMentions of Copyright 2009, The Regents of The University of Michigan.  I have a feeling this would need to be removed\n\t@author and @version. I know we remove @author lines, and I'm not sure if @version is really desired\n\n\n\nLooks like a very thorough and complete patch, but I haven't tried it yet. "
        },
        {
            "author": "Tom Burton-West",
            "id": "comment-12726105",
            "date": "2009-07-01T15:18:55+0000",
            "content": "Thanks Otis.   I'll add the ASL and remove the @author and @version.  I must have misunderstood the ASL regarding copyright.  I'll go ahead and remove the UMich copyright statements as well.   Should I also remove the TODO's in the comments?\n\nTom  "
        },
        {
            "author": "Otis Gospodnetic",
            "id": "comment-12726209",
            "date": "2009-07-01T20:07:01+0000",
            "content": "Thanks Tom.  TODOs are good reminders, so I'd say leave them. "
        },
        {
            "author": "Hoss Man",
            "id": "comment-12726695",
            "date": "2009-07-02T21:44:32+0000",
            "content": "\nFWIW: There are some decently readable docs from the legal team about this topic...\n\nhttp://www.apache.org/legal/src-headers.html "
        },
        {
            "author": "Tom Burton-West",
            "id": "comment-12736147",
            "date": "2009-07-28T17:14:37+0000",
            "content": "Cleaned up patch.\n\nASF license now included in all files. \nUmich copyright statements removed\nRemoved author and revision tags\nCleaned up code and reformatted using Solr Eclipse codestyle "
        },
        {
            "author": "Jason Rutherglen",
            "id": "comment-12736208",
            "date": "2009-07-28T18:35:51+0000",
            "content": "Great Tom!\n\n\n\tCan we add a flag to not return the actual stop words? (I know\nwe could add a StopWordFilter after, however it seems redundant?)\n\n\n\n\n\tCommonGramsFilter.ArrayTokens is not used?\n\n\n "
        },
        {
            "author": "Jason Rutherglen",
            "id": "comment-12736314",
            "date": "2009-07-28T21:30:11+0000",
            "content": "\n\tAdded an includeCommon flag which when false, does not return\ncommon words in the token stream\n\n\n\n\n\tRemoved static stop words, we refer to\nStopAnalyzer.ENGLISH_STOP_WORDS\n\n\n\n\n\tNeeds test cases for includeCommon\n\n\n\n\n\tMaybe there's more redundant code that can be removed or\nadjusted?\n\n\n\n\n\tCan we change this to be a fix for 1.4?\n\n "
        },
        {
            "author": "Jason Rutherglen",
            "id": "comment-12736322",
            "date": "2009-07-28T21:41:21+0000",
            "content": "Sorry, patch without the patch inlined! "
        },
        {
            "author": "Tom Burton-West",
            "id": "comment-12736800",
            "date": "2009-07-29T20:27:23+0000",
            "content": "Hi Jason,\n\n\nThanks for the contribution.  I applied the patch to the latest Solr and the QueryFilter tests failed (see below).  Perhaps something is wrong with my configuration. Did they pass for you.?\n\nI'll dig in to this tomorrow.\n\nTom. \n\nTEST-org.apache.solr.analysis.CommonGramsQueryFilterTest.xml:<testsuite errors=\"0\" failures=\"17\" hostname=\"ULIB-LIT0602\"\n name=\"org.apache.solr.analysis.CommonGramsQueryFilterTest\" tests=\"22\" time=\"0.453\" timestamp=\"2009-07-29T19:49:24\">\nTESTS-TestSuites.xml:  <testsuite errors=\"0\" failures=\"17\" hostname=\"ULIB-LIT0602\" id=\"12\" name=\"CommonGramsQueryFilterT\nest\" package=\"org.apache.solr.analysis\" tests=\"22\" time=\"0.453\" timestamp=\"2009-07-29T19:49:24\">\nbash-3.2$ "
        },
        {
            "author": "Jason Rutherglen",
            "id": "comment-12736960",
            "date": "2009-07-30T02:13:53+0000",
            "content": "I'll post a new patch tomorrow, essentially nothing is changing,\njust cleaned up some of the code. Adding StopFilterFactory at\nthe end of the analyzer chain performed the same function as\nincludeCommon=false with no performance difference.  "
        },
        {
            "author": "Tom Burton-West",
            "id": "comment-12737309",
            "date": "2009-07-30T21:46:49+0000",
            "content": "Thanks for cleaning up the code.\n\nI found the problem that was causing the CommonGramsQueryFilter test to fail.  CommonGramsQueryFilter checks for token type = \"gram\".  Since the patch changed the type to \"shingle\"  in CommonGramsFilter,, the same change has to be made in CommonGramsQueryFilter.\n\nI'm suprised that adding StopFilterFactory to the end of the filter change doesn't affect performance.   I'll wait for your new patch before proceeding.\n\nBTW  you asked >>Can we change this to be a fix for 1.4?\nI'd love to, but don't the committers make that decision?  How do we do that?\n\nTom\n "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12737327",
            "date": "2009-07-30T22:09:29+0000",
            "content": "\nBTW you asked >>Can we change this to be a fix for 1.4?\nI'd love to, but don't the committers make that decision? How do we do that?\n\nConsidering that:\n\n\tThe issue is old and a patch has been here in one form or another since April\n\tWe have ample time before 1.4 release\n\n\n\nI see no reason why it can't be committed for 1.4. Otis, since you have looked at this in the past, will you take this up? Or, I can try to have a look this weekend.\n "
        },
        {
            "author": "Jason Rutherglen",
            "id": "comment-12737332",
            "date": "2009-07-30T22:22:07+0000",
            "content": "We ran an indexing performance test with CommonGramFilter and a\nheavily modified/optimized filter state machine from the book\nBuilding Search Applications that does not emit stop words. I\ntried to change CommonGramFilter to not emit stop words, however\nBufferedTokenStream seems to only move forwards.\n\nCommonGramFilter was 10% faster with the StopWordsFilter at the\nend of the chain compared with the book's version. The book has\na GNU license for it's code so I cannot post it here.\n\nThe attached patch just cleans up a few things.  Perhaps more of\nthe test code can be shared?\n\nTo mark the issue as 1.4 you'd edit it, change affected version\nto 1.3, fix version to 1.4. \n "
        },
        {
            "author": "Otis Gospodnetic",
            "id": "comment-12737845",
            "date": "2009-08-01T07:27:03+0000",
            "content": "I won't get to it before going on vacation.  Assigning to you if you want it. "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12740506",
            "date": "2009-08-07T11:14:20+0000",
            "content": "Perhaps more of the test code can be shared?\n\nCan't we use BaseTokenTestCase's helper methods? "
        },
        {
            "author": "Jason Rutherglen",
            "id": "comment-12740689",
            "date": "2009-08-07T19:48:42+0000",
            "content": "\n\tCleaned up more\n\n\n\n\n\tConsolidated the test classes into one\n\n\n\n\n\tFormatting in CHANGES.txt for 66 seemed off, fixed it\n\n\n\n\n\tI didn't see how we could use BaseTokenTestCase\n\n "
        },
        {
            "author": "Jason Rutherglen",
            "id": "comment-12742657",
            "date": "2009-08-12T23:43:31+0000",
            "content": "I'll add resuableToken support to this patch. "
        },
        {
            "author": "Jason Rutherglen",
            "id": "comment-12742679",
            "date": "2009-08-13T02:07:54+0000",
            "content": "Tom,\n\nIs it our intention to support phrase queries with slop?  I'm not sure this works? "
        },
        {
            "author": "Tom Burton-West",
            "id": "comment-12742959",
            "date": "2009-08-13T21:02:13+0000",
            "content": "Hi Jason,\n\nThanks for all your work on this. \n\nI would be inclined to not deal with supporting slop at this point.  \n\nI guess slop of more than 0 will work as long as the query matches the commongrams exactly.  (so each commongram gets treated as one token for calculating slop).  Otherwise it would seem that you would have to generate commongrams for each combination of a common word and words n edit distance away to support a slop of n.  At least for our use case, the increase in the size of the index would not be worth it.  \n\nTom\n "
        },
        {
            "author": "Jason Rutherglen",
            "id": "comment-12743460",
            "date": "2009-08-14T21:45:55+0000",
            "content": "Tom,\n\nI'll add in the javadocs that if a phrase has a stop word, slop will not work. "
        },
        {
            "author": "Jason Rutherglen",
            "id": "comment-12746964",
            "date": "2009-08-24T17:29:07+0000",
            "content": "I'm reworking BufferedTokenStream to use the new token API. It\nseems like caching tokens goes against the way the new token api\nworks. Is there an example to follow, it seems like we're\nallocating objects per gram (which is what we're trying to\navoid?).  "
        },
        {
            "author": "Jason Rutherglen",
            "id": "comment-12747632",
            "date": "2009-08-25T20:53:53+0000",
            "content": "There seems to be a bug in CommonGramsQueryFilterFactory where the last word of a non common word query is removed.  I'm going to fix it and check in a new patch. "
        },
        {
            "author": "Tom Burton-West",
            "id": "comment-12748423",
            "date": "2009-08-27T16:21:21+0000",
            "content": "Hi Jason,\n\nIf the last non-common word in a query is part of the previous common-gram then it gets removed by design.  \ni.e.    query=\" see the hat\"  query filter output should be |see-the|the-hat|\n\nIs this a different case?  The test cases should have caught the bug.  Maybe we need to add a few more test cases. Could you send me a test case that shows the bug?  \n\nTom "
        },
        {
            "author": "Jason Rutherglen",
            "id": "comment-12748478",
            "date": "2009-08-27T17:54:19+0000",
            "content": "I changed: if (prev != null && prev.type() != \"gram\") from\nchecking for \"word\" which when a token was created from\nStandardFilter, would be of type \"<ALPHANUM>\" and was being\ndiscarded. This was causing at least one of the bugs, though\nthere may be another. "
        },
        {
            "author": "Jason Rutherglen",
            "id": "comment-12748639",
            "date": "2009-08-28T01:39:41+0000",
            "content": "There is a bug that seems to be related to\nHTMLStripStandardTokenizerFactory where a single word query\nfails to generate a token using the following chain. However a\nStandardTokenizer in it's place returns a token as expected.\nWhen SOLR-908.patch was tested with rev 799698, HTMLSSTF worked.\n\n\n<tokenizer class=\"solr.HTMLStripStandardTokenizerFactory\"/>\n<filter class=\"solr.StandardFilterFactory\"/>\n<filter class=\"solr.LowerCaseFilterFactory\"/>\n<filter class=\"solr.EnglishPorterFilterFactory\" protected=\"stopwords.txt\"/> \n<filter class=\"solr.CommonGramsQueryFilterFactory\" words=\"stopwords.txt\"/>\n<filter class=\"solr.StopFilterFactory\" ignoreCase=\"true\" words=\"stopwords.txt\" enablePositionIncrements=\"true\"/>\n\n "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12753065",
            "date": "2009-09-09T12:48:51+0000",
            "content": "I'll not be able to look at this before the end of the week, so un-assigning myself. "
        },
        {
            "author": "Jason Rutherglen",
            "id": "comment-12755597",
            "date": "2009-09-15T17:33:16+0000",
            "content": "Is there a reason this patch is unassigned for 1.4? "
        },
        {
            "author": "Jason Rutherglen",
            "id": "comment-12756933",
            "date": "2009-09-18T03:12:49+0000",
            "content": "This schema consistently and randomly generates query\ntruncations. Perhaps because we're mixing the new and old\ntokenizing APIs? I can't figure out what state is being shared\nnor how to debug this. We unfortunately upgraded to Solr 1.4\ntrunk and so cannot revert back to 1.3. I wrote a test case that\nhas not reproduced the bug locally. The bug happens in a\ndistributed environment with 20+ servers. \n\n\n<fieldType name=\"vCommonGrams\" class=\"solr.TextField\" positionIncrementGap=\"100\">\n  <analyzer type=\"index\">\n  <tokenizer class=\"solr.HTMLStripStandardTokenizerFactory\"/>  \n  <filter class=\"solr.StandardFilterFactory\"/>\n  <filter class=\"solr.CommonGramsFilterFactory\" ignoreCase=\"true\" words=\"stopwords.txt\"/>\n  <filter class=\"solr.StopFilterFactory\" ignoreCase=\"true\" words=\"stopwords.txt\" enablePositionIncrements=\"true\"/>\n  </analyzer>\n  <analyzer type=\"query\">\n  <tokenizer class=\"solr.StandardTokenizerFactory\"/>\n  <filter class=\"solr.StandardFilterFactory\"/>\n  <filter class=\"solr.CommonGramsQueryFilterFactory\" ignoreCase=\"true\" words=\"stopwords.txt\"/>\n  <filter class=\"solr.StopFilterFactory\" ignoreCase=\"true\" words=\"stopwords.txt\" enablePositionIncrements=\"true\"/>\n  </analyzer>\n</fieldType>\n\n "
        },
        {
            "author": "Jason Rutherglen",
            "id": "comment-12756995",
            "date": "2009-09-18T06:25:32+0000",
            "content": "It looks like our problem could be due to\nAnalyzer.reusableTokenStream and how it reuses tokenstreams from\na thread local variable. This would explain the random behavior\n(i.e. depending on the thread one was assigned for a query, the\nassociated token stream, if it were in an invalid state, would\nreturn incorrect results). I'm thinking reusableTokenStream can\nbe overridden to return a new token stream each time? And so\nbypass whatever reseting issue is occurring from the mixture of\nthe old and new tokenizer APIs. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12757267",
            "date": "2009-09-18T17:04:40+0000",
            "content": "Jason, at a quick look, I see that this filter maintains state, but doesn't implement reset() - could that be the issue? "
        },
        {
            "author": "Robert Muir",
            "id": "comment-12757271",
            "date": "2009-09-18T17:15:11+0000",
            "content": "just my opinion, do not think this problem is due to mixed tokenizer APIs (LUCENE-1919)\n\nthis is because this BufferedTokenStream does not mix the apis that cause that issue... it only uses TokenStream.next()\n\ni think instead Yonik might be on the right track, could be wrong. "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-12757344",
            "date": "2009-09-18T18:52:04+0000",
            "content": "In my opinion, the problem is BufferedTokenStream (should its name not BufferedTokenFilter?). It has the linked list but does not implement reset(). So the problem is not this issue, more the usage of reset because you reuse the token stream. As long as BufferedTokenStream is not fixed to support reset() you have to create new instances. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-12757364",
            "date": "2009-09-18T19:18:24+0000",
            "content": "Uwe, i opened an issue for this: SOLR-1446\n\ni think even if not the cause of this problem, BufferedTokenStream should implement reset() since it keeps internal state. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-12757381",
            "date": "2009-09-18T19:49:52+0000",
            "content": "similar to the BufferedTokenStream reset, the CommonGramsQueryFilter here has its own internal state:\n\nprivate Token prev;\n\n\n\nso this filter too should implement reset (and must call super.reset() so the BufferedTokenStream lists get reset too). "
        },
        {
            "author": "Jason Rutherglen",
            "id": "comment-12757413",
            "date": "2009-09-18T20:59:01+0000",
            "content": "Interesting, the whole reusableTokenStream model is new to me,\nso it wasn't in my mental view of how Lucene analyzers work. It\nseems if BTS is caching tokens, then being reused, and isn't\nreset, then there would be excess tokens instead of deletions?\nOr perhaps the reset is being called from another analyzer? It's\nquite confusing. I started work on a LoggingTokenizer that could\nbe inserted between tokenizers in the Solr schema, however have\nbeen working on reproducing the issue (which hasn't worked\neither). \n\nUwe, Yonik, and Robert, thanks for taking a look!  "
        },
        {
            "author": "Robert Muir",
            "id": "comment-12757432",
            "date": "2009-09-18T21:11:04+0000",
            "content": "\nIt seems if BTS is caching tokens, then being reused, and isn't\nreset, then there would be excess tokens instead of deletions?\n\nright, thats what the test case I added for BufferedTokenStream showed. \nthis would be more of a corner case, as i think most BufferedTokenStreams would have empty lists anyway\nby the time they are reset(), so its likely not causing your problem (though it should be fixed!)\n\nyour problem, again is probably the internal state kept in CommonGramsQueryFilter\nas you can see, CommonGramsQueryFilter has hairy logic involving the buffered token 'prev'\na lot of this logic has to do with what happens at end of stream.\n\nunfortunately there is no reset() for CommonGramsQueryFilter to set 'prev' back to its initial state, so when something like QueryParser tries to reuse it, it is probably not behaving correctly.  "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12757445",
            "date": "2009-09-18T21:20:37+0000",
            "content": "I guess if something causes an exception during analysis, things like BufferedTokenStream can be left with unwanted state.\nNote that BufferedTokenStream didn't inherit from TokenFilter and thus wouldn't automatically chain the reset() to it's input... so any upstream filters wouldn't be reset().  I just fixed that. "
        },
        {
            "author": "Jason Rutherglen",
            "id": "comment-12757461",
            "date": "2009-09-18T21:46:02+0000",
            "content": "Added reset overrides to CommonGramsFilter and CommonGramsQueryFilter.   "
        },
        {
            "author": "Robert Muir",
            "id": "comment-12757472",
            "date": "2009-09-18T21:58:53+0000",
            "content": "jason, i took a glance. i think the reset() for CommonGramsQueryFilter should not set prev = null\nthis is because the initial state is not null:\nin the ctor, prev = new Token() \nwith the current logic, this is what reset() must do also.\n\nalso, fyi CommonGramsFilter does not need a reset since the stringbuffer isn't used to keep state,\n\nthe best way I think to ensure its correct i think, is to add tests that consume and reuse/reset() "
        },
        {
            "author": "Jason Rutherglen",
            "id": "comment-12757504",
            "date": "2009-09-18T23:06:26+0000",
            "content": "Robert thanks.  I added the new token in CGQF.reset and reset test cases. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12757675",
            "date": "2009-09-19T16:28:32+0000",
            "content": "I've updated the lucene libs to rc5 in trunk - hopefully that, coupled with the recent changes to this patch will eliminate the flakiness. "
        },
        {
            "author": "Jason Rutherglen",
            "id": "comment-12757820",
            "date": "2009-09-21T04:56:18+0000",
            "content": "Yeah, unfortunately it's going to be hard to upgrade as folks\nfeel a bit burned at this point and reverting to Solr trunk 8/31\nplus the old HTMLStripReader which seems to be more stable than\nthe latest Solr builds. I need to reproduce our wacky crazy\nrandom query truncations, and haven't yet. I'll probably try\ncreating completely randomized queries in multiple threads and\nsee what happens. Without reproducing the problem and showing it\nfixed, upgrading will be difficult to justify. Logically the\nthreadlocal reusableTokenStream is the problem, however,\nperception is things got way too broken. \n\nAlso I need to upgrade the patch to use the new tokenizing API.\nI think this belongs in Lucene analyzers rather than in Solr\nanyways, and BufferedTokenStream totally changes with the new\ntokenizing API. Hacking ShingleFilter to only include certain\nwords seemed like too much of a rewrite of it. So porting is the\nnext task here after hopefully reproducing.\n "
        },
        {
            "author": "Jason Rutherglen",
            "id": "comment-12758354",
            "date": "2009-09-22T18:47:13+0000",
            "content": "Thanks everyone on this, we deployed the latest patch with the latest Solr build and things work now, reliably.  "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12758388",
            "date": "2009-09-22T19:34:57+0000",
            "content": "Yay!  I think we could commit this now... any objections/concerns with the latest patch? "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12758396",
            "date": "2009-09-22T19:52:53+0000",
            "content": "Yay! I think we could commit this now... any objections/concerns with the latest patch?\n\nLooks good. +1 for commit. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-12758403",
            "date": "2009-09-22T20:03:12+0000",
            "content": "i've been doing some tests, latest patch has been working fine for me.\ni think jason cleared up any remaining reset/reusable issues with this latest patch. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12758472",
            "date": "2009-09-22T23:02:24+0000",
            "content": "Committed.  Thanks everyone! "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12775604",
            "date": "2009-11-10T15:51:53+0000",
            "content": "Bulk close for Solr 1.4 "
        }
    ]
}