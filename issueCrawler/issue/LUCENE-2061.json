{
    "id": "LUCENE-2061",
    "title": "Create benchmark & approach for testing Lucene's near real-time performance",
    "details": {
        "labels": "",
        "priority": "Minor",
        "components": [
            "core/index"
        ],
        "type": "Task",
        "fix_versions": [],
        "affect_versions": "None",
        "resolution": "Unresolved",
        "status": "Open"
    },
    "description": "With the improvements to contrib/benchmark in LUCENE-2050, it's now\npossible to create compelling algs to test indexing & searching\nthroughput against a periodically reopened near-real-time reader from\nthe IndexWriter.\n\nComing out of the discussions in LUCENE-1526, I think to properly\ncharacterize NRT, we should measure net search throughput as a\nfunction of both reopen rate (ie how often you get a new NRT reader\nfrom the writer) and indexing rate.  We should also separately measure\npure adds vs updates (deletes + adds); the latter is much more work\nfor Lucene.\n\nThis can help apps make capacity decisions... and can help us test\nperformance of pending improvements for NRT (eg LUCENE-1313,\nLUCENE-2047).",
    "attachments": {
        "LUCENE-2061.patch": "https://issues.apache.org/jira/secure/attachment/12424853/LUCENE-2061.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2009-11-13T15:11:46+0000",
            "content": "Attached first cut python script nrtBench.py.\n\nYou have to edit the constants up top, to point to both Wiki XML\nexport and a Wiki line file.  It use the XML export to build up the\nbase index, and then the line file to do the \"live\" indexing.\n\nIt first runs a baseline, redline searching with 9 (default) threads,\nand reports the net qps.  (You'll have to write a queries.txt w/ the\nqueries to test).  Then it steps through NRT reopen rates of every\n0.1, 1.0, 2.5, 5.0 seconds X indexing rate of 1, 10, 100, 1000 per sec\n(using 2 indexing threads), and then redlines the search threads,\ncomparing their search throughput to the baseline. ",
            "author": "Michael McCandless",
            "id": "comment-12777521"
        },
        {
            "date": "2009-11-14T10:53:40+0000",
            "content": "New nrtBench.py attached, fixed a few small issues... also, I removed\n-Xbatch to java; it seems to make less consistent results.\n\nMy initial results:\n\n\nJAVA:\njava version \"1.6.0_14\"\nJava(TM) SE Runtime Environment (build 1.6.0_14-b08)\nJava HotSpot(TM) 64-Bit Server VM (build 14.0-b16, mixed mode)\n\n\nOS:\nSunOS rhumba 5.11 snv_111b i86pc i386 i86pc Solaris\n\n\nBaseline QPS 158.12\n\n\n\n\nIndexing docs/sec\nNRT reopen period (sec)\nQPS add\nQPS update\nQPS add (% diff)\nQPS update (% diff)\n\n\n1\n1\n157.5\n125.7\n-0.4%\n-20.5%\n\n\n1\n2.5\n157.6\n127.5\n-0.4%\n-19.4%\n\n\n1\n5\n156.9\n127.2\n-0.8%\n-19.5%\n\n\n10\n0.1\n156.3\n142.4\n-1.2%\n-9.9%\n\n\n10\n0.5\n155.8\n125.0\n-1.5%\n-20.9%\n\n\n10\n1\n156.0\n142.6\n-1.3%\n-9.8%\n\n\n10\n2.5\n156.6\n143.4\n-0.9%\n-9.3%\n\n\n10\n5\n156.2\n144.0\n-1.2%\n-8.9%\n\n\n100\n0.1\n153.9\n138.8\n-2.7%\n-12.2%\n\n\n100\n0.5\n155.0\n141.1\n-2.0%\n-10.8%\n\n\n100\n1\n156.1\n141.3\n-1.3%\n-10.6%\n\n\n100\n2.5\n155.9\n116.7\n-1.4%\n-26.2%\n\n\n100\n5\n157.0\n143.8\n-0.7%\n-9.1%\n\n\n1000\n0.1\n145.9\n110.0\n-7.7%\n-30.4%\n\n\n1000\n0.5\n148.0\n117.6\n-6.4%\n-25.6%\n\n\n1000\n1\n148.3\n97.7\n-6.2%\n-38.2%\n\n\n1000\n2.5\n149.3\n99.1\n-5.6%\n-37.3%\n\n\n1000\n5\n147.4\n124.3\n-6.8%\n-21.4%\n\n\n\n\n\nThe docs are ~1KB sized docs derived from wikipedia.  The searching is\nonly running a single fixed query (1), over and over.\n\nSome rough observations:\n\n\n\tEven at only 1 update/sec, QPS already drops way too much\n    (~20%), which is weird.  Something is amiss.\n\n\n\n\n\tAt all indexing rates, handling updates slows NRT down much more\n    than pure adds.\n\n\n\n\n\tPure adds (no deletes) are handled quite well, at <= 100 adds/sec,\n    the hit to QPS is ~1-2%, which is great.  Even at 1000 docs/sec\n    the QPS only drops ~6%, which seems reasonable.\n\n\n\n\n\tThere isn't really a clear correlation of reopen rate to QPS,\n    which is also weird.\n\n\n\nLooks like we have some puzzles to solve...\n ",
            "author": "Michael McCandless",
            "id": "comment-12777875"
        },
        {
            "date": "2009-11-16T14:04:28+0000",
            "content": "OK the last test had a silly bug, that made update QPS slowdown even @ low indexing & reopen rates look worse than it should be...\n\nThe test ran on a fully optimized index, ie, it had no deletions.\n\nSo the pure searching & add tests had no deletedDocs vector to check, but the update test, after the very first doc was indexed, had to check the deleteDocs.  So, really, that 20% slowdown we see right off the bat for the updates case is the added cost of having to check the BitVector.\n\nSo the test was unfair.  I'll re-run after deleting one doc from the base index... ",
            "author": "Michael McCandless",
            "id": "comment-12778346"
        },
        {
            "date": "2009-11-18T10:14:05+0000",
            "content": "OK I modified nrtBench.py to take advantage of some of the features in\nLUCENE-2079:\n\n\n\tReopen thread runs with pri +2, indexing threads pri +1, search\n    threads normal pri\n\n\n\n\n\tI compute mean/stddev reopen time, and added to the tables\n\n\n\nI made some other small changes, eg changed -report to create a\nseparate 'add only' vs 'delete + add' table.\n\nFinally, I switched to a non-optimized 5M Wikpedia index (12\nsegments), with 1% deletions.  I think this is a more typical index\nthat an app would have after running NRT for a while.\n\nNew results:\n\nJAVA:\njava version \"1.6.0_14\"\nJava(TM) SE Runtime Environment (build 1.6.0_14-b08)\nJava HotSpot(TM) 64-Bit Server VM (build 14.0-b16, mixed mode)\n\n\nOS:\nSunOS rhumba 5.11 snv_111b i86pc i386 i86pc Solaris\n\n\nBaseline QPS 144.24\n\n\nAdd only:\n\n\n\nDocs/sec\nReopen every (sec)\nReopen mean (ms)\nReopen stddev(ms)\nQPS\n% diff\n\n\n10.0\n0.1\n0.0\n1.0\n132.11\n-8.4%\n\n\n10.0\n1.0\n3.0\n0.0\n132.79\n-7.9%\n\n\n10.0\n5.0\n9.0\n2.0\n121.31\n-15.9%\n\n\n10.0\n10.0\n14.0\n2.0\n134.7\n-6.6%\n\n\n10.0\n33.3\n30.0\n3.7\n133.57\n-7.4%\n\n\n100.0\n0.1\n2.0\n0.0\n142.02\n-1.5%\n\n\n100.0\n1.0\n12.0\n1.4\n125.9\n-12.7%\n\n\n100.0\n5.0\n41.0\n2.8\n105.46\n-26.9%\n\n\n100.0\n10.0\n61.0\n4.2\n126.09\n-12.6%\n\n\n100.0\n33.3\n128.0\n5.8\n141.46\n-1.9%\n\n\n1000.0\n0.1\n15.0\n168.8\n102.14\n-29.2%\n\n\n1000.0\n1.0\n62.0\n5.1\n117.06\n-18.8%\n\n\n1000.0\n5.0\n192.0\n7.4\n123.7\n-14.2%\n\n\n1000.0\n10.0\n166.0\n10.3\n97.57\n-32.4%\n\n\n1000.0\n33.3\n162.0\n12.1\n101.52\n-29.6%\n\n\n\n\n\nDelete + add:\n\n\n\nDocs/sec\nReopen every (sec)\nReopen mean (ms)\nReopen stddev(ms)\nQPS\n% diff\n\n\n10.0\n0.1\n1.0\n1.7\n132.82\n-7.9%\n\n\n10.0\n1.0\n6.0\n1.0\n134.57\n-6.7%\n\n\n10.0\n5.0\n21.0\n8.8\n119.37\n-17.2%\n\n\n10.0\n10.0\n38.0\n17.4\n129.19\n-10.4%\n\n\n10.0\n33.3\n82.0\n11.1\n135.14\n-6.3%\n\n\n100.0\n0.1\n6.0\n1.0\n127.01\n-11.9%\n\n\n100.0\n1.0\n34.0\n6.8\n141.1\n-2.2%\n\n\n100.0\n5.0\n126.0\n17.9\n105.43\n-26.9%\n\n\n100.0\n10.0\n203.0\n29.3\n117.16\n-18.8%\n\n\n100.0\n33.3\n538.0\n77.5\n132.26\n-8.3%\n\n\n1000.0\n0.1\n45.0\n187.8\n96.84\n-32.9%\n\n\n998.9\n1.0\n246.0\n41.0\n95.32\n-33.9%\n\n\n996.6\n5.0\n941.0\n154.4\n102.17\n-29.2%\n\n\n999.5\n10.0\n1680.0\n549.1\n90.69\n-37.1%\n\n\n990.2\n33.3\n4587.0\n2660.9\n90.89\n-37.0%\n\n\n\n\n\n\nObservations:\n\n\n\tSomething odd is still going on \u2013 eg at 100 docs/sec, when we\n    reopen every 30 sec we see fairly small hit to QPS for both the\n    add & delete+add, vs reopening more often.  Reopening every 5\n    seconds is by far the worse.  Strange.\n\n\n\n\n\tRight off the bat, even at 10 docs/sec, we take a hit in QPS for\n    both add and delete+add cases\n\n\n\n\n\tThe delete+add generally (though not always) has worse QPS than\n    the add only case\n\n\n\n\n\tCuriously it seems like reopening less frequently often hurts QPS\n    more (though not always) \u2013 I would have expected overall better\n    QPS throughput, even though when the reopen happens it takes\n    longer to turnaround; strange.\n\n\n\n\n\tDelete+add clearly takes longer to turnaround the new reader, but,\n    the times remain reasonable even up to 1000 docs/sec.  The faster\n    you reopen your reader, the less time the reopen takes since there\n    are fewer delete+adds to process.\n\n ",
            "author": "Michael McCandless",
            "id": "comment-12779387"
        },
        {
            "date": "2009-11-19T10:33:34+0000",
            "content": "I was baffled by why I see such sporadic QPS differences for reopen\nrates, so I ran another test, this time always flushing after 100\nbuffered docs:\n\nJAVA:\njava version \"1.6.0_14\"\nJava(TM) SE Runtime Environment (build 1.6.0_14-b08)\nJava HotSpot(TM) 64-Bit Server VM (build 14.0-b16, mixed mode)\n\n\nOS:\nSunOS rhumba 5.11 snv_111b i86pc i386 i86pc Solaris\n\nBaseline QPS 146.74\n\n\nAdd only:\n\n\n\nDocs/sec\nReopen every (sec)\nReopen mean (ms)\nReopen stddev(ms)\nQPS\n% diff\n\n\n100.0\n0.1\n2.0\n1.4\n143.7\n-2.1%\n\n\n100.0\n1.0\n5.0\n7.5\n145.1\n-1.1%\n\n\n100.0\n5.0\n6.0\n4.8\n144.72\n-1.4%\n\n\n100.0\n10.0\n9.0\n8.5\n143.95\n-1.9%\n\n\n100.0\n33.3\n11.0\n11.1\n143.12\n-2.5%\n\n\n\n\n\n\nBaseline QPS 146.3\n\n\nDelete + add:\n\n\n\nDocs/sec\nReopen every (sec)\nReopen mean (ms)\nReopen stddev(ms)\nQPS\n% diff\n\n\n100.0\n0.1\n6.0\n2.2\n143.15\n-2.2%\n\n\n100.0\n1.0\n28.0\n10.1\n133.78\n-8.6%\n\n\n100.0\n5.0\n77.0\n29.9\n143.28\n-2.1%\n\n\n100.0\n10.0\n92.0\n49.5\n142.63\n-2.5%\n\n\n100.0\n33.3\n91.0\n47.4\n143.57\n-1.9%\n\n\n\n\n\n\nVery strangely, by flushing every 100 docs, ie once per second even if\nyou're reopening at a slower rate, the QPS is much more reasonable:\npretty much unaffected by the ongoing indexing, either adding or\ndelete + adding.  I don't know how to explain this....\n\nAlso, note that reopen times are still longer for delete+add.  This is\nbecause the deletes are still only being resolved when it's time to\nreopen (or, time to merge), not after every 100 docs.  This also\nexplains why going from reopen sec 10 -> 30 didn't see any change in\nthe reopen time: after 10 seconds (= 10 new segments), a merge kicks\noff, which always resolves the deletes.\n\nSo I think this is good news, in that it brings QPS back up to nearly\nthe baseline, but bad news in that, I have no idea why... ",
            "author": "Michael McCandless",
            "id": "comment-12779923"
        },
        {
            "date": "2009-11-20T17:26:29+0000",
            "content": "Just attaching latest nrtBench.py... ",
            "author": "Michael McCandless",
            "id": "comment-12780667"
        },
        {
            "date": "2009-11-27T10:48:54+0000",
            "content": "BTW, based on these last results I posted here, the rough conclusion\nseems to be that so long as you set up IW to flush every N docs (which\nI still don't understand why it's necessary) the ongoing indexing &\nreopening does not hurt QPS substantially when compared to the \"pure\nsearching\" baseline.\n\nThis is an important result.  It means all the other optimizations\nwe're pursuing for NRT are not really necessary.  (At least on the env\nI tested).  I think it must be that the OS is quite efficient at\ncreating smallish files and turning around these files for reading (ie\nits file write cache is \"effectively\" emulating a RAMDirectory). ",
            "author": "Michael McCandless",
            "id": "comment-12783093"
        },
        {
            "date": "2009-11-28T23:28:36+0000",
            "content": "Mike, I tried running nrtBench.py, generated a 2 million doc\nindex as I didn't want to wait for the 5 mil to finish. \n\nCan you post the queries file you've used? (the nrtBench was\nlooking for it) I'd like to keep things as consistent as\npossible between runs. \n\nI haven't seen the same results in regards to the OS managing\nsmall files, and I suspect that users in general will choose a\nvariety of parameters (i.e. 1 max buffered doc) that makes\nwriting to disk inherently slow. Logically the OS should work as\na write cache, however in practice, it seems a variety of users\nhave reported otherwise. Maybe 100 docs works, however that\nfeels like a fairly narrow guideline for user's of NRT.\n\nThe latest LUCENE-1313 is a step in a direction that doesn't\nchange IW internals too much. ",
            "author": "Jason Rutherglen",
            "id": "comment-12783322"
        },
        {
            "date": "2009-11-29T09:52:31+0000",
            "content": "Can you post the queries file you've used?\n\nI only used TermQuery \"1\", sorting by score.  I'd generally like to focus on worst case query latency rather than QPS of \"easy\" queries.  Maybe we should switch to harder queries (phrase, boolean).\n\nThough one thing I haven't yet focused on testing (which your work on LUCENE-1785 would improve) is queries that hit the FieldCache \u2013 we should test that as well.\n\n\nI haven't seen the same results in regards to the OS managing\nsmall files, and I suspect that users in general will choose a\nvariety of parameters (i.e. 1 max buffered doc) that makes\nwriting to disk inherently slow. Logically the OS should work as\na write cache, however in practice, it seems a variety of users\nhave reported otherwise. Maybe 100 docs works, however that\nfeels like a fairly narrow guideline for user's of NRT.\n\nYeah we need to explore this (when OS doesn't do effective write-caching), in practice.\n\n\nThe latest LUCENE-1313 is a step in a direction that doesn't\nchange IW internals too much.\nI do like this simplification \u2013 basically IW is internally managing how best to use RAM in NRT mode \u2013 but I think we need to scrutinize (through benchmarking, here) whether this is really needed (ie, whether we can't simply rely on the OS to behave, with its IO cache). ",
            "author": "Michael McCandless",
            "id": "comment-12783376"
        }
    ]
}