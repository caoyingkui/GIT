{
    "id": "SOLR-66",
    "title": "CSV data loader",
    "details": {
        "affect_versions": "None",
        "status": "Closed",
        "fix_versions": [
            "1.2"
        ],
        "components": [],
        "type": "New Feature",
        "priority": "Major",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "A way to efficiently load simple formatted text files, including CSV files.",
    "attachments": {
        "csv.patch": "https://issues.apache.org/jira/secure/attachment/12345585/csv.patch",
        "commons-csv-20061121.jar": "https://issues.apache.org/jira/secure/attachment/12345636/commons-csv-20061121.jar"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Yonik Seeley",
            "id": "comment-12447460",
            "date": "2006-11-06T16:08:18+0000",
            "content": "To most efficiently load a large export file from some other datasource, we should allow an upload of a local file and avoid going through the network/servlet container for each individual record.\n\nWay to slurp a local file: a post to /solr/upload/localfile?file=full_path_to_file\nParameter Ideas:\n  file   #the full path name of the local file\n  separator=,   #the field separator\n  charset=utf8\n  commit=false  #do a commit after finished\n  fieldnames=foo,bar,baz   #define field names, if not taken from the header \n  header=true  #read field names from the header\n  skip=baz        #fields to skip\n  skiplines=1   #number of lines at the start of the file to skip\n  skipempty=true  #don't index zero length values \n  trim=true  #trim whitespace from field values\n\n  map=Yes:true  #map a field value\n\n  #per-field params\n  f.myfield.map=No:false\n\n  escape=true  #backslash escaping\n  quotedfields=true  #optionally quoted fields (like CVS)\n\n  csv=true #sets options correctly for a CSV file\n\n  #support comments in the file? "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12447463",
            "date": "2006-11-06T16:18:31+0000",
            "content": "Should we also somehow support uploading a text file over the network?\nHTTP-POST of the file would be the obvious thing, but then how are parameters specified.\nMulti-part post? "
        },
        {
            "author": "Erik Hatcher",
            "id": "comment-12447497",
            "date": "2006-11-06T18:27:17+0000",
            "content": "What about having an XSL transformation on the input to Solr as well?   This would allow someone to POST in XML documents of any variety, but an XSL would turn it into the field definitions.  This would certainly increase the appeal of Solr in my (library) domain - a standard TEI -> Solr stylesheet would allow folks to POST into Solr without doing much on the client end at all. "
        },
        {
            "author": "Fuad Efendi",
            "id": "comment-12447877",
            "date": "2006-11-07T18:10:36+0000",
            "content": "Encoding:\nHow to encode 'comma'?\nHow to encode UTF-8?\nShould we use Base64 and encode raw values?\n\nhttp://rfc.net/rfc4180.html:\n\"Common usage of CSV is US-ASCII, but other character sets defined by IANA for the \"text\" tree may be used in conjunction with the  \"charset\" parameter.\n\nhttp://www.creativyst.com/Doc/Articles/CSV/CSV01.htm\nhttp://www.edoceo.com/utilis/csv-file-format.php\nhttp://www.ricebridge.com/products/csvman/reference.htm\n\nThis is interesting (from last link):\nFIELD:    [trim]? ( UNQUOTED | QUOTED ) [trim]? \nUNQUOTED: ( [data]* | ESCAPE )*;\nQUOTED:   [quote] ( DOUBLE | ESCAPE | [data]* )* [quote]\n\n "
        },
        {
            "author": "Fuad Efendi",
            "id": "comment-12447894",
            "date": "2006-11-07T19:16:13+0000",
            "content": "/sorry for not having access to E-mail and using POST temporarily.../\n\nHTTP-POST: should work without any code changes.\n\nIn /resources/admin/index.jsp, <form name=queryForm method=\"GET\" action=\"../select/\"> Simply replace GET to POST, and everything should work ...\n\nYou have following in org.apache.solr.servlet.SolrServlet:\n  public void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException \n{\n    doGet(request,response);\n  }\n\nAnd, you are using standard Servlet API to retrieve ServletRequest parameters,\nhttp://java.sun.com/j2ee/1.4/docs/api/javax/servlet/ServletRequest.html#getParameterMap() \n\npublic class ServletSolrParams extends MultiMapSolrParams {\n  public ServletSolrParams(ServletRequest req) \n{\n    super(req.getParameterMap());\n  }\n\nExisting SOLR should work with POST HTML forms without any change in Java... "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12447898",
            "date": "2006-11-07T19:22:32+0000",
            "content": "> Existing SOLR should work with POST HTML forms without any change in Java...\n\nYes, posting queries work because it's all form-data (query args).\nBut, what if we want to post a complete file, and some extra info/parameters about how that file should be handled? "
        },
        {
            "author": "Hoss Man",
            "id": "comment-12447900",
            "date": "2006-11-07T19:25:10+0000",
            "content": "Fuad: the issue isn't really wether POSTed queries work ... those have been tested and are known to work ... it's more a question of POSTed updates ... the current update mechanism does not use \"application/x-www-form-urlencoded\" instead the raw POST body is read as an XML message containing docs to index.\n\nThis issue is attempting to address a more convininet method to bulk import records, possibly using CSV, and probably using a local file \u2013 but we'd want to support a POSTed file as well, so there was some discussion (on list) of how to POST both a file nd send query params (using either \"application/x-www-form-urlencoded\" or the mechanism we currently use) "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12447901",
            "date": "2006-11-07T19:26:48+0000",
            "content": "> How to encode 'comma'?\n\nFor standard CSV, ytou could quote the entire field value...   \"a,b\"\nI don't know if Commons CSV supports backslash escaping or not, but that would be another way.\n\n> How to encode UTF-8?\n\nTwo ways... the user can define a charset for the file (and the file could actually be UTF-8),\nand we can support unicode escapes \\u1234\n\n> Should we use Base64 and encode raw values?\n\nI hadn't thought about binary fields (they aren't even supported in the XML update yet).\nDoing Base64 would seem relatively easy though. "
        },
        {
            "author": "Fuad Efendi",
            "id": "comment-12447911",
            "date": "2006-11-07T19:44:47+0000",
            "content": "Sorry for not correctly understanding the multipart HTTP POST / File Upload issue, it's not easy, I just browsed sources of org.springframework.web.multipart.support (although it's very easy with Spring...) "
        },
        {
            "author": "Fuad Efendi",
            "id": "comment-12447918",
            "date": "2006-11-07T20:25:28+0000",
            "content": "CSV:\n\n\tshould we support standard CSVs generated by Excel, Oracle DataPump, etc?\n\n\n\nXML: we currently preprocess some data to create XML, then we post it to SOLR.\n\nCan we preprocess standard CSV? For instance, we have two tables: CATEGORY (parent), PRODUCT (child)\nCSV produced by Oracle might seem like\n\n001,IBM,001,17R7021,14 7/8 X 8 1/2\" - 1/2\" Greenbar\n001,IBM,002,17R8018,8 1/2 x 11\" Micro Perf @ 3 2/3\"\n\nHere, [001,Paper] is a single record from CATEGORY table, and rest is PK, SKU, NAME from PRODUCT table.\n\n1. Use 'extended' CSV such as\n001,Paper,multi-value:\"001,17R7021,14 7/8 X 8 1/2\"\" - 1/2\"\" Greenbar002,17R8018,8 1/2 x 11\"\" Micro Perf @ 3 2/3\"\"\"\n(multi-value:\"<comma separated>,...\")\n\n\tvery difficult... and not compatible with exported data...\n\n\n\n2. Standard CSV with fixed width + preprocessing (sorting, and removing repeated values)\n\n001,Paper,001,17R7021,14 7/8 X 8 1/2\" - 1/2\" Greenbar\n001,,002,17R8018,8 1/2 x 11\" Micro Perf @ 3 2/3\"\n\n\nWe removed repeated value 'Paper', but we left Primary Key of this Category intact... It should work with both, standard 'large' CSV and preprocessed one... And, we don't have huge single line in case of IBM producing different kinds of paper...; we have multi-line with fixed width... First column (repeated 001 value) is primary key, same as  <field name=\"id\">001</field> "
        },
        {
            "author": "Fuad Efendi",
            "id": "comment-12447919",
            "date": "2006-11-07T20:28:40+0000",
            "content": "mistake... (Paper, instead of IBM):\n\n001, Paper, 001, 17R7021, 14 7/8 X 8 1/2\" - 1/2\" Greenbar \n001, Paper, 002, 17R8018, 8 1/2 x 11\" Micro Perf @ 3 2/3\" \n...\n\noptimized:\n001, Paper, 001, 17R7021, 14 7/8 X 8 1/2\" - 1/2\" Greenbar \n001, , 002, 17R8018, 8 1/2 x 11\" Micro Perf @ 3 2/3\" \n... "
        },
        {
            "author": "Fuad Efendi",
            "id": "comment-12447923",
            "date": "2006-11-07T20:49:05+0000",
            "content": "Another sample...\n\n<add><doc>\n  <field name=\"id\">9885A004</field>\n  <field name=\"name\">Canon PowerShot SD500</field>\n  <field name=\"manu\">Canon Inc.</field>\n  <field name=\"cat\">electronics</field>\n  <field name=\"cat\">camera</field>\n  <field name=\"features\">3x zoop, 7.1 megapixel Digital ELPH</field>\n  <field name=\"features\">movie clips up to 640x480 @30 fps</field>\n  <field name=\"features\">2.0\" TFT LCD, 118,000 pixels</field>\n  <field name=\"features\">built in flash, red-eye reduction</field>\n  <field name=\"includes\">32MB SD card, USB cable, AV cable, battery</field>\n  <field name=\"weight\">6.4</field>\n  <field name=\"price\">329.95</field>\n  <field name=\"popularity\">7</field>\n  <field name=\"inStock\">true</field>\n</doc></add>\n\n\nCarthesian Product of Facets (can I cay that?):\n====================================\n9885A004, Canon PowerShot SD500, Canon Inc., electronics, 3x zoop, 7.1 megapixel Digital ELPH, \"32MB SD card, USB cable, AV cable, battery\", 6.4, 329.95, 7, true\n9885A004, Canon PowerShot SD500, Canon Inc., electronics, 3x zoop, movie clips up to 640x480 @30 fps, \"32MB SD card, USB cable, AV cable, battery\", 6.4, 329.95, 7, true\n9885A004, Canon PowerShot SD500, Canon Inc., electronics, 3x zoop, 2.0\" TFT LCD, 118,000 pixels, \"32MB SD card, USB cable, AV cable, battery\", 6.4, 329.95, 7, true\n9885A004, Canon PowerShot SD500, Canon Inc., electronics, 3x zoop, built in flash, red-eye reduction, \"32MB SD card, USB cable, AV cable, battery\", 6.4, 329.95, 7, true\n9885A004, Canon PowerShot SD500, Canon Inc., camera, 3x zoop, 7.1 megapixel Digital ELPH, \"32MB SD card, USB cable, AV cable, battery\", 6.4, 329.95, 7, true\n9885A004, Canon PowerShot SD500, Canon Inc., camera, 3x zoop, movie clips up to 640x480 @30 fps, \"32MB SD card, USB cable, AV cable, battery\", 6.4, 329.95, 7, true\n9885A004, Canon PowerShot SD500, Canon Inc., camera, 3x zoop, 2.0\" TFT LCD, 118,000 pixels, \"32MB SD card, USB cable, AV cable, battery\", 6.4, 329.95, 7, true\n9885A004, Canon PowerShot SD500, Canon Inc., camera, 3x zoop, built in flash, red-eye reduction, \"32MB SD card, USB cable, AV cable, battery\", 6.4, 329.95, 7, true\n\n\nOptimized CSV (just for improved network traffic for areas without DSL!!!):\n9885A004, Canon PowerShot SD500, Canon Inc., electronics, \"3x zoop, 7.1 megapixel Digital ELPH\", \"32MB SD card, USB cable, AV cable, battery\", 6.4, 329.95, 7 true\n9885A004, , , , \"movie clips up to 640x480 @30 fps\", , , , ,\n9885A004, , , , \"3x zoop, 2.0\" TFT LCD, 118,000 pixels\", , , , ,\n9885A004, , , , \"built in flash, red-eye reduction\", , , , ,\n9885A004, , ,  camera, \"3x zoop, 7.1 megapixel Digital ELPH\", \n9885A004, , , , \"movie clips up to 640x480 @30 fps\", , , , ,\n9885A004, , , , \"3x zoop, 2.0\" TFT LCD, 118,000 pixels\", , , , ,\n9885A004, , , , \"built in flash, red-eye reduction\", , , , ,\n\nalmost EDI... XML looks much better... May be specific GZIP version for a standard \"Carthesian\" CSV?\n "
        },
        {
            "author": "Fuad Efendi",
            "id": "comment-12447924",
            "date": "2006-11-07T21:03:40+0000",
            "content": "This is probably SOLR-specific (the best? be focused on task?)...\n\nWe stick on 4-column format for everything (in case of surrogate PK we may have [id,\"001,003,abxc\"]):\n\nid,9885A004,name,Canon PowerShot SD500\nid,9885A004,manu,Canon Inc.\nid,9885A004,cat,electronics</field> \nid,9885A004,cat,camera</field> \nid,9885A004,features,\"3x zoop, 7.1 megapixel Digital ELPH\"\nid,9885A004,features,movie clips up to 640x480 @30 fps\nid,9885A004,features,\"2.0\"\" TFT LCD, 118,000 pixels\" \nid,9885A004,features,\"built in flash, red-eye reduction\"\nid,9885A004,includes,\"32MB SD card, USB cable, AV cable, battery\"\nid,9885A004,weight,6.4\nid,9885A004,price,329.95\nid,9885A004,popularity,7 \nid,9885A004,inStock,true "
        },
        {
            "author": "Fuad Efendi",
            "id": "comment-12447953",
            "date": "2006-11-07T22:56:19+0000",
            "content": "even 3-column... \nBTW, good SOLR-targeted single-table database design:\n<PrimaryKey>,<FieldName>,<FieldValue>\nYes, we can use even index-organized tables in Oracle, without repeated 'parent' values!\nAnd good standard for CNET customers sending them daily updated product info (is it really search engine?...)\nThanks "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12452351",
            "date": "2006-11-24T03:52:35+0000",
            "content": "Here's a first cut on a CSV loader.\n\nYou can load the example data file with the following command:\ncurl http://localhost:8983/solr/upload/csv' --data 'file=./exampledocs/books.csv'\n\nThis version only implements local file uploading.  Perhaps there should be a separate URL for actually posting the CSV file itself?\n\nSupported parameters:\nfile \u2013 name of the file to load (needs to be fully qualified, or relative to $CWD)\ncharset \u2013 default is UTF-8\nseparator \u2013 default is ,\nfieldnames \u2013 can specify or override the names of the columns\nheader \u2013 \"true\" if the file contains a header with the fieldnames\nskip \u2013 list of fields not to index\nmap \u2013 maps one value to another.. from:to, either from or to can be empty, multiple rules may be specified.\nkeepEmpty  \u2013 index zero length values\nsplit  \u2013 do CSV splitting on a single field value\nencapsulator \u2013 char for optionally encapsulating values (needed if reserved char is in val) defaults to \"\ncommit \u2013 automatically commit after loading is finished, default=true\n\nPer-field overrides for params can be specified via\nf.field.param for the following params: separator, map, keepEmpty,split,encapsulator "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12452352",
            "date": "2006-11-24T03:54:04+0000",
            "content": "The other thing you will need to build & try this is commons-csv\nhttp://people.apache.org/builds/jakarta-commons/nightly/commons-csv/ "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12452495",
            "date": "2006-11-24T16:51:01+0000",
            "content": "attached commons-csv nightly build "
        },
        {
            "author": "Andy Nahapetian",
            "id": "comment-12485172",
            "date": "2007-03-29T13:12:50+0000",
            "content": "If you change builder.addField in the FieldAdder class to call builder.addField(fields[column].getName(),val,1.0f) instead of builder.addField(fields[column],val,1.0f) then the copyField feature of solr will also work when using the CSVLoader. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12485224",
            "date": "2007-03-29T15:36:10+0000",
            "content": "Good catch, thank Andy! "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12485364",
            "date": "2007-03-29T21:56:11+0000",
            "content": "Adapted to new update handler framework...\nI think this is about ready to commit. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12485565",
            "date": "2007-03-30T17:02:21+0000",
            "content": "committed. "
        },
        {
            "author": "Hoss Man",
            "id": "comment-12589309",
            "date": "2008-04-15T23:44:44+0000",
            "content": "This bug was modified as part of a bulk update using the criteria...\n\n\n\tMarked (\"Resolved\" or \"Closed\") and \"Fixed\"\n\tHad no \"Fix Version\" versions\n\tWas listed in the CHANGES.txt for 1.2\n\n\n\nThe Fix Version for all 39 issues found was set to 1.2, email notification\nwas suppressed to prevent excessive email.\n\nFor a list of all the issues modified, search jira comments for this\n(hopefully) unique string: 20080415hossman2 "
        }
    ]
}