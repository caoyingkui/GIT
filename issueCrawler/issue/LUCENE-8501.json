{
    "id": "LUCENE-8501",
    "title": "An ability to define the sum method for custom term frequencies",
    "details": {
        "components": [
            "core/index"
        ],
        "status": "Resolved",
        "resolution": "Won't Fix",
        "fix_versions": [],
        "affect_versions": "None",
        "labels": "",
        "priority": "Major",
        "type": "Improvement"
    },
    "description": "Custom term frequencies allows expert users to index and score in custom ways, however, DefaultIndexingChain adds a limitation to this as the sum of frequencies can't overflow\n\ntry {\n    invertState.length = Math.addExact(invertState.length, invertState.termFreqAttribute.getTermFrequency());\n} catch (ArithmeticException ae) {\n    throw new IllegalArgumentException(\"too many tokens for field \\\"\" + field.name() + \"\\\"\");\n}\n\n\nThis might become an issue if for example the frequency data is encoded in a different way, say the specific scorer works with float frequencies.\n\nThe sum method can be added to TermFrequencyAttribute to get something like\n\ninvertState.length = invertState.termFreqAttribute.addFrequency(invertState.length);\n\n\nso users may define the summing method and avoid the owerflow exceptions.",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "id": "comment-16617272",
            "author": "Adrien Grand",
            "content": "Storing floats as term frequencies not only raises issues with field length, but also with storage efficiency since that will likely add 4 bytes for every (term,document) pair of your dataset. For instance Lucene's FeatureField only retains 16 bits of the 32 bits of floats: no sign bit, 8 exponent bits like regular floats, and 8 mantissa bits instead of 23. It makes the overhead of floats as term frequencies drop to 2 bytes per (term,document) pair instead of 4: https://github.com/apache/lucene-solr/blob/1d85cd783863f75cea133fb9c452302214165a4d/lucene/core/src/java/org/apache/lucene/document/FeatureField.java#L153-L154 Would a similar approach work for you too? ",
            "date": "2018-09-17T09:11:36+0000"
        },
        {
            "id": "comment-16617478",
            "author": "Olli Kuonanoja",
            "content": "Thanks for the pointer\u00a0Adrien Grand. In my case I'd be a bit worried about the loss of precision with the 16 bit encoding, can't say for sure without proper testing how much it would affect the results. However, the storage efficiency has not been an issue for me in practise. One more issue I forgot to point out in the original description is the value of invertState.length\u00a0becomes useless for similarities as it is always the sum of the integer representations. Using a fixed point encoding would be a workaround for that but I'm still\u00a0wondering would it make sense\u00a0to allow the users to overwrite the sum function for different use-cases. ",
            "date": "2018-09-17T12:57:48+0000"
        },
        {
            "id": "comment-16617541",
            "author": "Adrien Grand",
            "content": "In my case I'd be a bit worried about the loss of precision with the 16 bit encoding\n\nDo you know how many values per field you expect at most? For instance using 24 bits by shifting the bits of the float representation right by 7 instead of 15 would retain more accuracy while allowing for about 128 values per field per document. In general scoring doesn't focus on accuracy: we are happy with recording lengths on a single byte, using Math.log(1+x) rather than Math.log1p or tweaking scoring formulas to add ones if it can help avoid dividing by zero. Better accuracy doesn't improve ranking significantly.\n\nI'm still wondering would it make sense to allow the users to overwrite the sum function for different use-cases.\n\nIt might... but such extension points have a significant impact on the API and testing. In general we'd rather not add them unless there is a strong case to introduce them. Also there are ramifications: if we change the way that the length is computed, then we also need to change the way that frequencies are combined when a field has the same value twice, we also need to worry about how to reflect it on index statistics like totalTermFreq and sumTotalTermFreq, etc.\n ",
            "date": "2018-09-17T13:46:50+0000"
        },
        {
            "id": "comment-16619192",
            "author": "Olli Kuonanoja",
            "content": "\n\nDo you know how many values per field you expect at most? For instance using 24 bits by shifting the bits of the float representation right by 7 instead of 15 would retain more accuracy while allowing for about 128 values per field per document. In general scoring doesn't focus on accuracy: we are happy with recording lengths on a single byte, using Math.log(1+x) rather than Math.log1p\u00a0or tweaking scoring formulas to add ones if it can help avoid dividing by zero. Better accuracy doesn't improve ranking significantly.\n\n\nNeed to support\u00a0some thousands at max at the moment so it becomes tricky. In theory the frequencies could be represented in a very\u00a0concise way by examining the values and sorting them. In practise, when using a distributed system to calculate them, it is infeasible to find such ordering.\n\n\u00a0\n\n\n\nIt might... but such extension points have a significant impact on the API and testing. In general we'd rather not add them unless there is a strong case to introduce them. Also there are ramifications: if we change the way that the length is computed, then we also need to change the way that frequencies are combined when a field has the same value twice, we also need to worry about how to reflect it on index statistics like totalTermFreq and sumTotalTermFreq, etc.\n\n\nUnderstood, now after mentioning things like totalTermFreq and\u00a0sumTotalTermFreq, probably the whole \"algebra\" related to these should be interfaced to implement that properly. If that change is not in the line of the project, I guess we can just close this issue and live with workarounds. ",
            "date": "2018-09-18T14:28:09+0000"
        },
        {
            "id": "comment-16620607",
            "author": "Adrien Grand",
            "content": "If that change is not in the line of the project, I guess we can just close this issue and live with workarounds.\n\nThis might change in the future, but as things stand today, I think this is something that we wouldn't like to change. ",
            "date": "2018-09-19T13:47:45+0000"
        }
    ]
}