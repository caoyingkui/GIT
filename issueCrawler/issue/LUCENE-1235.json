{
    "id": "LUCENE-1235",
    "title": "NGramTokenizer optimization in query phase",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [
            "modules/analysis"
        ],
        "type": "Improvement",
        "fix_versions": [],
        "affect_versions": "None",
        "resolution": "Won't Fix",
        "status": "Resolved"
    },
    "description": "As I described in LUCENE-1229, we can optimize token stream in query.",
    "attachments": {
        "NGramTokenizer.patch": "https://issues.apache.org/jira/secure/attachment/12377965/NGramTokenizer.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2008-03-15T04:19:43+0000",
            "content": "NGramTokenizer.patch includes LUCENE-1227, LUCENE-1225. ",
            "author": "Hiroaki Kawai",
            "id": "comment-12579005"
        },
        {
            "date": "2013-03-10T13:31:16+0000",
            "content": "SPRING_CLEANING_2013 We can reopen if necessary.  ",
            "author": "Erick Erickson",
            "id": "comment-13598247"
        }
    ]
}