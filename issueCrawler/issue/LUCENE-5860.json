{
    "id": "LUCENE-5860",
    "title": "Use Terms.getMin/Max to speed up range queries/filters",
    "details": {
        "type": "Improvement",
        "priority": "Major",
        "labels": "",
        "resolution": "Won't Fix",
        "components": [],
        "affect_versions": "None",
        "status": "Resolved",
        "fix_versions": [
            "4.10",
            "6.0"
        ]
    },
    "description": "As of LUCENE-5610, Lucene's Terms API now exposes min and max terms in\neach field.  I think we can use this in our term/numeric range\nquery/filters to avoid visiting a given segment by detecting up front\nthat the terms in the segment don't overlap with the query's range.\n\nEven though block tree avoids disk seeks in certain cases when the\nterm cannot exist on-disk, I think this change would further avoid\ndisk seeks in additional cases because the min/max term has\nmore/different information than the in-memory FST terms index.",
    "attachments": {
        "LUCENE-5860.patch": "https://issues.apache.org/jira/secure/attachment/12658705/LUCENE-5860.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "id": "comment-14079742",
            "author": "Michael McCandless",
            "content": "Patch.\n\nI also hit and fixed a bug in MemoryIndex's TermsEnum seek-by-ord ... ",
            "date": "2014-07-30T18:42:10+0000"
        },
        {
            "id": "comment-14079942",
            "author": "Uwe Schindler",
            "content": "Hi, looks interesting, although I am not sure if the added complexity, especially in NRQ is woth the small speed improvement. I have to carefully apply the patch and review it, maybe tomorrow.\n\nWithout a good benchmark result that brings a good speed improvemenmt, I would -1 it for NRQ (especially as NRQ only looks at few terms at all - at least with my preferred precisionSteps, I still disagree with the new defaults). For NRQ it is also not sure, if the additional min/max lookup cost is useful (because the min/max term in the term dictionary does not help for the NRQ case, you need the min/max shift=0 term).\n\nGo for it for TRQ! Strong +1 ",
            "date": "2014-07-30T20:43:36+0000"
        },
        {
            "id": "comment-14079996",
            "author": "Yonik Seeley",
            "content": "Wouldn't NRQ benefit at least as much as TRQ?  That said, this is about speeding up what is already the fastest case, so I don't have an opinion if the complexity added complexity is worth it. ",
            "date": "2014-07-30T21:21:14+0000"
        },
        {
            "id": "comment-14081213",
            "author": "Michael McCandless",
            "content": "I don't think there's that much added complexity here?\n\nThe changes to NRQ look biggish only because I factored out common code; I could dup the code instead and the changes would look smaller ...\n\nI think the possibility of saving disk seeks for the coldish case makes this a worthwhile opto.  I'll probably have trouble showing the gains in the luceneutil benchmark ... I can try forcing it to be cold (Robert wrote a cool tool for this!) but that's somewhat synthetic.\n\nNet/net I still think we should commit both. ",
            "date": "2014-07-31T18:15:01+0000"
        },
        {
            "id": "comment-14081436",
            "author": "Uwe Schindler",
            "content": "Hi Mike,\n\nI am fine with that improvement. I am just a bit confused: For numeric trie terms the maximum and minimum values are not quite right (because of the additional shift!=0 terms)? As far as I remember, the min/max value is the found by binary search? Or is it now changed that min/max values come from the min/max shift=0 term? If thats the case I am fine, otherwise I think the binary search is more costly.\n\nSorry did not yet look at the patch in more detail, at least not at NumericUtils. ",
            "date": "2014-07-31T20:42:55+0000"
        },
        {
            "id": "comment-14082107",
            "author": "Michael McCandless",
            "content": "For numeric trie terms the maximum and minimum values are not quite right (because of the additional shift!=0 terms)? As far as I remember, the min/max value is the found by binary search? Or is it now changed that min/max values come from the min/max shift=0 term? If thats the case I am fine, otherwise I think the binary search is more costly.\n\nHmm ... you are right: this is in fact doing a binary search for a numeric field (see NumericUtils), which is no good: the one disk seek we save is replaced by several!  So I agree: until we can pull the min/max for a numeric field w/o any disk seeks (which I think we should do), this is really not worth doing for numeric fields. ",
            "date": "2014-08-01T09:43:57+0000"
        },
        {
            "id": "comment-14481088",
            "author": "Michael McCandless",
            "content": "I opened LUCENE-6395 for the bug in MemoryIndex.\n\nI don't think we should fix NumericRangeQuery here: the opto adds more cost than it saves, and anyway apps should probably switch to straight up byte[] encoding for numeric data and let auto-prefix do the range searching efficiently.\n\nWith LUCENE-5879, TermRangeQuery now uses Terms.intersect, which should be quite efficient with the default postings format (block tree) in skipping segments whose terms are \"out of bounds\" for the automaton.\n\nSo net/net there's nothing else to do here... ",
            "date": "2015-04-06T09:46:41+0000"
        }
    ]
}