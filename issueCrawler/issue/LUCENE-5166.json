{
    "id": "LUCENE-5166",
    "title": "PostingsHighlighter fails with IndexOutOfBoundsException",
    "details": {
        "components": [
            "modules/highlighter"
        ],
        "fix_versions": [
            "4.5",
            "6.0"
        ],
        "affect_versions": "4.4",
        "priority": "Major",
        "labels": "",
        "type": "Bug",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "Given a document with a match at a startIndex < PostingsHighlighter.maxlength and an endIndex > PostingsHighlighter.maxLength, DefaultPassageFormatter will throw an IndexOutOfBoundsException when DefaultPassageFormatter.append() is invoked.",
    "attachments": {
        "LUCENE-5166.patch": "https://issues.apache.org/jira/secure/attachment/12597430/LUCENE-5166.patch",
        "LUCENE-5166-revisited.patch": "https://issues.apache.org/jira/secure/attachment/12598187/LUCENE-5166-revisited.patch",
        "LUCENE-5166-2.patch": "https://issues.apache.org/jira/secure/attachment/12597436/LUCENE-5166-2.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2013-08-12T07:41:46+0000",
            "content": "java.lang.IndexOutOfBoundsException: start 9999, end 10004, s.length() 10000\n\tat java.lang.AbstractStringBuilder.append(AbstractStringBuilder.java:453)\n\tat java.lang.StringBuilder.append(StringBuilder.java:179)\n\tat org.apache.lucene.search.postingshighlight.DefaultPassageFormatter.append(DefaultPassageFormatter.java:135)\n\tat org.apache.lucene.search.postingshighlight.DefaultPassageFormatter.format(DefaultPassageFormatter.java:79)\n\tat org.apache.lucene.search.postingshighlight.PostingsHighlighter.highlightField(PostingsHighlighter.java:435)\n\tat org.apache.lucene.search.postingshighlight.PostingsHighlighter.highlightFields(PostingsHighlighter.java:353)\n\tat org.apache.lucene.search.postingshighlight.PostingsHighlighter.highlightFields(PostingsHighlighter.java:268) ",
            "author": "Manuel Amoabeng",
            "id": "comment-13736666"
        },
        {
            "date": "2013-08-12T09:15:54+0000",
            "content": "Can you show a real usecase for a document matching beyond content.length()? Your patch artificially creates an out-of-bound Passage, but I think it's better if we can see a real usecase, e.g. maybe a combination of TokenFilters may cause that?\n\nBut if e.g. the app indexed content1 but then tries to highlight content2, I don't think that's a supported usecase... ",
            "author": "Shai Erera",
            "id": "comment-13736705"
        },
        {
            "date": "2013-08-12T10:01:24+0000",
            "content": "Please find attached another test case. It is sort of bad luck to run into this in a real use case but it actually happened to me.   ",
            "author": "Manuel Amoabeng",
            "id": "comment-13736726"
        },
        {
            "date": "2013-08-12T11:45:34+0000",
            "content": "Interesting. FYI, I will not be available in the next 2 weeks, and haven't reproduced it yet. If no one assigns himself to the issue, I will when I'm back. ",
            "author": "Shai Erera",
            "id": "comment-13736784"
        },
        {
            "date": "2013-08-12T11:46:58+0000",
            "content": "I have reproduced it with Manuel's test ",
            "author": "Robert Muir",
            "id": "comment-13736785"
        },
        {
            "date": "2013-08-12T11:48:56+0000",
            "content": "Attached is just a combined patch of Manuel's 2 patches.\n\nThere is definitely bug(s) here.\n\nAs far as the fix, to me the big question (I put it in a nocommit to his test case), is if formatter classes should really have to deal with these cases. ",
            "author": "Robert Muir",
            "id": "comment-13736787"
        },
        {
            "date": "2013-08-12T12:05:58+0000",
            "content": "I think we shouldn't send \"out of bounds\" matches to the formatter?  Because all it can do is bounds check and skip it?\n\nI think maybe we also shouldn't even send the passage if it was \"truncated\", even if some matches were before the truncation? ",
            "author": "Michael McCandless",
            "id": "comment-13736800"
        },
        {
            "date": "2013-08-12T12:21:29+0000",
            "content": "OK here's a patch. the cause of the bug is that we only know startOffsets are always increasing (the algorithm relies on this, and merges them across terms). \n\nSo we cannot safely terminate when end >= limit (only start >= limit), but we don't have to confuse the formatter with the cases of terms that 'span' the limit. ",
            "author": "Robert Muir",
            "id": "comment-13736806"
        },
        {
            "date": "2013-08-12T14:57:13+0000",
            "content": "Hmm so this means we may pick a truncated passage to present?  I suppose it's unlikely to score well ... just seems bad though.\n\nWait, couldn't we fix passageQueue.offer(current) to not offer it if current.endOffset == contentLength? ",
            "author": "Michael McCandless",
            "id": "comment-13736924"
        },
        {
            "date": "2013-08-12T15:06:08+0000",
            "content": "Well the passage may not be truncated: for example depending on the analyzer (e.g. ngrams or something), it could just be that the term \"spans sentences\". \n\nAnd the problem is: only startOffset is guaranteed to be increasing. so if we discard the passage just because of this, it could be unsafe since new terms that are \"in bounds\" have still yet to be seen... ",
            "author": "Robert Muir",
            "id": "comment-13736929"
        },
        {
            "date": "2013-08-12T15:23:01+0000",
            "content": "Improved patch, thank you Mike  ",
            "author": "Robert Muir",
            "id": "comment-13736947"
        },
        {
            "date": "2013-08-12T15:37:26+0000",
            "content": "I'm still confused about how we handle the \"truncated passage\" ... I added a [failing] test but maybe the test is bogus? ",
            "author": "Michael McCandless",
            "id": "comment-13736959"
        },
        {
            "date": "2013-08-12T15:48:13+0000",
            "content": "Well the patch doesnt attempt to change anything about the breakiterator logic: so your test is \"valid\" but testing something different.\n\nLet me try to explain:\nThe bug Manuel found here is \"matching term spanning the content boundary\". so lets call this \"truncated term\". This patch fixes this so formatter doesnt have to deal with it, and there is no AIOOBE or strange checks in the formatter.\n\nThe test you write is for different behavior: it saying, if the passage itself spans the content boundary, don't present it to the formatter at all. But, this is sorta a different issue, its already handled here today by Math.min and the formatter never has to deal with it:\n\n        // advance breakiterator\n        assert BreakIterator.DONE < 0;\n        current.startOffset = Math.max(bi.preceding(start+1), 0);\n        current.endOffset = Math.min(bi.next(), contentLength);\n\n\n\nIf we want to change the behavior for this, thats cool too, but its not really related to the bug at hand. I am not opposed to fixing it, but one problem would be someone using stuff like WholeBreakIterator, though we could \"solve\" it in a different way by having WholeBreakIterator take in the limit itself (I dont know if this would address your concern though). ",
            "author": "Robert Muir",
            "id": "comment-13736966"
        },
        {
            "date": "2013-08-12T15:51:12+0000",
            "content": "OK let's not try to address that on this issue ... I'm not even sure it needs fixing.  It ought to be rare-ish that a truncated passage is selected. ",
            "author": "Michael McCandless",
            "id": "comment-13736971"
        },
        {
            "date": "2013-08-12T17:11:13+0000",
            "content": "There was a bug in my patch: I added another unit test for this!\n\nI think its ready. ",
            "author": "Robert Muir",
            "id": "comment-13737052"
        },
        {
            "date": "2013-08-12T17:15:09+0000",
            "content": "+1\n\nTricky! ",
            "author": "Michael McCandless",
            "id": "comment-13737057"
        },
        {
            "date": "2013-08-12T17:47:11+0000",
            "content": "Commit 1513207 from Robert Muir in branch 'dev/trunk'\n[ https://svn.apache.org/r1513207 ]\n\nLUCENE-5166: PostingsHighlighter fails with IndexOutOfBoundsException ",
            "author": "ASF subversion and git services",
            "id": "comment-13737101"
        },
        {
            "date": "2013-08-12T19:39:54+0000",
            "content": "Commit 1513231 from Robert Muir in branch 'dev/branches/branch_4x'\n[ https://svn.apache.org/r1513231 ]\n\nLUCENE-5166: PostingsHighlighter fails with IndexOutOfBoundsException ",
            "author": "ASF subversion and git services",
            "id": "comment-13737270"
        },
        {
            "date": "2013-08-12T19:40:25+0000",
            "content": "Thank you Manuel! ",
            "author": "Robert Muir",
            "id": "comment-13737271"
        },
        {
            "date": "2013-08-13T08:43:46+0000",
            "content": "Thank you for the quick help! ",
            "author": "Manuel Amoabeng",
            "id": "comment-13737983"
        },
        {
            "date": "2013-08-15T12:56:59+0000",
            "content": "I just found another problem here: If we have both, matches that do and matches that don't span the content boundary the formatter is asked to highlight the spanning match.\nPlease find attached additional tests and a possible fix for this.  ",
            "author": "Manuel Amoabeng",
            "id": "comment-13740925"
        },
        {
            "date": "2013-08-15T13:59:30+0000",
            "content": "Hi Manuel: thank you! Another bug, or a bug in my fix to the other bug \n\nI'll investigate deeper in a bit. ",
            "author": "Robert Muir",
            "id": "comment-13740975"
        },
        {
            "date": "2013-08-15T16:23:32+0000",
            "content": "Manuel: your fix is correct, thank you.\n\nTo explain: I had totally forgotten about this little loop on tf within the passage (i had removed this optimization in LUCENE-4909, which didnt turn out to work that great, so wasn't committed).\n\nWe might at some point want to still just remove the optimization just based on the reason that it makes this thing more complicated, it was just intended to speed up the worst case (where someone has very common stopwords and stuff like that).\n\nBut for now to complete the bugfix, we should commit your patch (LUCENE-5166-revisited.patch). ",
            "author": "Robert Muir",
            "id": "comment-13741140"
        },
        {
            "date": "2013-08-15T16:52:16+0000",
            "content": "Commit 1514367 from Robert Muir in branch 'dev/trunk'\n[ https://svn.apache.org/r1514367 ]\n\nLUCENE-5166: also fix and test this case where tf > 1 within the passage for a term ",
            "author": "ASF subversion and git services",
            "id": "comment-13741174"
        },
        {
            "date": "2013-08-15T17:05:28+0000",
            "content": "Commit 1514379 from Robert Muir in branch 'dev/branches/branch_4x'\n[ https://svn.apache.org/r1514379 ]\n\nLUCENE-5166: also fix and test this case where tf > 1 within the passage for a term ",
            "author": "ASF subversion and git services",
            "id": "comment-13741188"
        },
        {
            "date": "2013-08-15T17:05:51+0000",
            "content": "Thank you again! ",
            "author": "Robert Muir",
            "id": "comment-13741189"
        },
        {
            "date": "2013-10-05T10:18:46+0000",
            "content": "4.5 release -> bulk close ",
            "author": "Adrien Grand",
            "id": "comment-13787020"
        },
        {
            "date": "2014-05-14T05:51:31+0000",
            "content": "Commit 1594464 from Robert Muir in branch 'dev/branches/lucene5666'\n[ https://svn.apache.org/r1594464 ]\n\nLUCENE-5166: clear most nocommits, move ord/rord to solr (and speed them up), nuke old purging stuff ",
            "author": "ASF subversion and git services",
            "id": "comment-13997305"
        }
    ]
}