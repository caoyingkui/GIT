{
    "id": "LUCENE-2327",
    "title": "IndexOutOfBoundsException in FieldInfos.java",
    "details": {
        "labels": "",
        "priority": "Minor",
        "components": [
            "core/index"
        ],
        "type": "Bug",
        "fix_versions": [],
        "affect_versions": "3.0.1",
        "resolution": "Invalid",
        "status": "Resolved"
    },
    "description": "When retrieving the scoreDocs from a multisearcher, the following exception is thrown:\n\njava.lang.IndexOutOfBoundsException: Index: 52, Size: 4\n        at java.util.ArrayList.rangeCheck(ArrayList.java:571)\n        at java.util.ArrayList.get(ArrayList.java:349)\n        at org.apache.lucene.index.FieldInfos.fieldInfo(FieldInfos.java:285)\n        at org.apache.lucene.index.FieldInfos.fieldName(FieldInfos.java:274)\n        at org.apache.lucene.index.TermBuffer.read(TermBuffer.java:86)\n        at org.apache.lucene.index.SegmentTermEnum.next(SegmentTermEnum.java:131)\n        at org.apache.lucene.index.SegmentTermEnum.scanTo(SegmentTermEnum.java:162)\n        at org.apache.lucene.index.TermInfosReader.get(TermInfosReader.java:232)\n        at org.apache.lucene.index.TermInfosReader.get(TermInfosReader.java:179)\n        at org.apache.lucene.index.SegmentReader.docFreq(SegmentReader.java:911)\n        at org.apache.lucene.index.DirectoryReader.docFreq(DirectoryReader.java:644)\n\nThe error is caused when the fieldNumber passed to FieldInfos.fieldInfo() is greater than the size of array list containing the FieldInfo values.  I am not sure what the field number represents or why it would be larger than the array list's size.  The quick fix would be to validate the bounds but there may be a bigger underlying problem.  The issue does appear to be directly related to LUCENE-939.  I've only been able to duplicate this in my production environment and so can't give a good test case.",
    "attachments": {
        "CheckIndex.txt": "https://issues.apache.org/jira/secure/attachment/12439161/CheckIndex.txt"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2010-03-18T09:31:13+0000",
            "content": "This exception looks like index corruption... would be good to get to the root cause of how this happened.\n\nYour terms dict, which records the field number and character data for each term, has somehow recorded a field number of 52 when in fact this segment appears to only have 4 fields.\n\nCan you run CheckIndex on the index and post the result back?\n\nAny prior exceptions when creating this index?\n\nI don't think adding a bounds check to FieldInfos makes sense \u2013 the best we could do is throw a \"FieldNumberOutOfBounds\" exception. ",
            "author": "Michael McCandless",
            "id": "comment-12846813"
        },
        {
            "date": "2010-03-18T13:51:41+0000",
            "content": "CheckIndex output generated by Luke v1.0.0. ",
            "author": "Shane",
            "id": "comment-12846905"
        },
        {
            "date": "2010-03-18T14:03:16+0000",
            "content": "The index is relatively old and doesn't appear to have been modified for a number of years.  I can't say for certain about prior exceptions.  If the CheckIndex results provides any more details, then great.  Regardless, I'm willing to chalk this up to a system specific error and close the ticket.  I was able to fix the index using Luke. ",
            "author": "Shane",
            "id": "comment-12846912"
        },
        {
            "date": "2010-03-18T15:06:51+0000",
            "content": "Yikes \u2013 you had 10 corrupted segments (of 23) and there's at least 4 different flavors of corruption across those segments!  Curious...  What storage device did you store the index on? \n\nNote the that \"fix\" just drops those segments from the index, so any docs that were in them are lost. ",
            "author": "Michael McCandless",
            "id": "comment-12846947"
        },
        {
            "date": "2010-03-18T15:17:54+0000",
            "content": "I believe at the time we were storing on a NAS via NFS.  If my memory serves me well, there were known issues with running Lucene over NFS at the time.   We were experiencing issues with the file system at the time so have since moved to a different architecture. \n\nAlso, I was aware that the fix drops the segments, but thanks anyway.  ",
            "author": "Shane",
            "id": "comment-12846954"
        },
        {
            "date": "2010-03-18T15:49:18+0000",
            "content": "OK I'm resolving as optimistically invalid  ",
            "author": "Michael McCandless",
            "id": "comment-12846961"
        },
        {
            "date": "2014-04-01T01:54:46+0000",
            "content": "I have an almost identical stack trace from v3.6, but I did get the index from someone else so I don't know where they were storing it.\n\n\njava.lang.IndexOutOfBoundsException: Index: 100, Size: 64\n  at java.util.ArrayList.rangeCheck(ArrayList.java:635)\n  at java.util.ArrayList.get(ArrayList.java:411)\n  at org.apache.lucene.index.FieldInfos.fieldInfo(FieldInfos.java:255)\n  at org.apache.lucene.index.FieldInfos.fieldName(FieldInfos.java:244)\n  at org.apache.lucene.index.TermBuffer.read(TermBuffer.java:86)\n  at org.apache.lucene.index.SegmentTermEnum.next(SegmentTermEnum.java:133)\n  at org.apache.lucene.index.SegmentTermEnum.scanTo(SegmentTermEnum.java:174)\n  at org.apache.lucene.index.TermInfosReader.get(TermInfosReader.java:202)\n  at org.apache.lucene.index.TermInfosReader.get(TermInfosReader.java:172)\n  at org.apache.lucene.index.SegmentReader.docFreq(SegmentReader.java:539)\n  at org.apache.lucene.search.TermQuery$TermWeight$1.add(TermQuery.java:56)\n  at org.apache.lucene.util.ReaderUtil$Gather.run(ReaderUtil.java:81)\n  at org.apache.lucene.util.ReaderUtil$Gather.run(ReaderUtil.java:87)\n  at org.apache.lucene.util.ReaderUtil$Gather.run(ReaderUtil.java:70)\n  at org.apache.lucene.search.TermQuery$TermWeight.<init>(TermQuery.java:53)\n  at org.apache.lucene.search.TermQuery.createWeight(TermQuery.java:199)\n  at org.apache.lucene.search.BooleanQuery$BooleanWeight.<init>(BooleanQuery.java:176)\n  at org.apache.lucene.search.BooleanQuery.createWeight(BooleanQuery.java:354)\n  at org.apache.lucene.search.Searcher.createNormalizedWeight(Searcher.java:168)\n  at org.apache.lucene.search.IndexSearcher.createNormalizedWeight(IndexSearcher.java:664)\n  at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:364)\n\n ",
            "author": "Trejkaz",
            "id": "comment-13956008"
        }
    ]
}