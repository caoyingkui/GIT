{
    "id": "LUCENE-3482",
    "title": "Refactor grouping module to be more maintainable",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [
            "modules/grouping"
        ],
        "type": "Improvement",
        "fix_versions": [
            "4.0-ALPHA"
        ],
        "affect_versions": "4.0-ALPHA",
        "resolution": "Won't Fix",
        "status": "Closed"
    },
    "description": "Currently we have 4 types of grouping collectors and 8 concrete subclasses in Lucene / Solr. In current architecture for each type of collector two concrete subclasses need to be created. An implementation optimized for single term based groups and a more general implementation that works with MutableValue to also support grouping by functions. If we want for example group by IndexDocValues each type of grouping collector needs to have three concrete subclasses. This design isn't very maintainable.\n\nI think it is best to introduce a concept that knows how deals with dealing groups for all the different sources. Therefore the grouping module should depend on the queries module, so that grouping can reuse the ValueSource concept. A term based concrete impl. of this concept knows for example to use the DocValues.ord() method. Or more generic concrete impl. will use DocValues.ValueFiller.",
    "attachments": {
        "LUCENE-3482.patch": "https://issues.apache.org/jira/secure/attachment/12497410/LUCENE-3482.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2011-10-02T20:02:16+0000",
            "content": "Attached initial patch. The patch has a concept named GroupHolder that knowns how to efficiently collect groups. All grouping collectors use that concept to prevent subclassing. \n\nI didn't change the already existing collectors in the grouping module. I added a package research inside the grouping package. I decided to keep the original collectors around to test performance between the original collectors and collectors that use the GroupHolder.\n\nThe grouping module depends now on the queries module. I added a method to DocValues to retrieve the ord from a value:\n\npublic int ord(MutableValue value) { throw new UnsupportedOperationException(); }\n\n\nThe attached patch also support grouping by bytes IndexDocValues. We already have NumericIndexDocValueSource maybe that can be merged with ByteRefIndexDocDV (included in this patch) into IndexDocValueSource? ",
            "author": "Martijn van Groningen",
            "id": "comment-13119052"
        },
        {
            "date": "2011-10-02T21:25:23+0000",
            "content": "With respect to some modules depending on other modules, I'm not sure where I stand... some have the opinion that the modules should be independent.\n\nWhat caught my attention in this issue though is that the refactoring seems extensive enough that we should do performance testing of all the current cases to ensure there are no regressions.  Performance is the most important factor here, and I'm not sure if trying to introduce more layers of abstraction (when it's really just an implementation detail) is worth it.\n\nThe addition of remove() to SentinelIntSet also seems erroneous:\n\n+  public void remove(int key) {\n+    int s = find(key);\n+    if (s >= 0) {\n+      count--;\n+      keys[s] = emptyVal;\n+    }\n+  }\n\n\nThat won't work, as it will foil future lookups for some keys.  If we need a Set that supports removal, it should prob be implemented in a different class. ",
            "author": "Yonik Seeley",
            "id": "comment-13119073"
        },
        {
            "date": "2011-10-02T22:11:45+0000",
            "content": "\nWhat caught my attention in this issue though is that the refactoring seems extensive enough that we should do performance testing of all the current cases to ensure there are no regressions. Performance is the most important factor here, and I'm not sure if trying to introduce more layers of abstraction (when it's really just an implementation detail) is worth it.\nI agree with you that any negative performance impact should be kept to an absolute minimum. That is why I put the refactored collectors in a research package and kept the unchanged versions around. This allows easy performance comparison.\n\nThe addition of remove() to SentinelIntSet also seems erroneous\nThat shouldn't have made it in the patch. I'm not using this method in any code. ",
            "author": "Martijn van Groningen",
            "id": "comment-13119085"
        },
        {
            "date": "2011-10-03T01:23:43+0000",
            "content": "I really have to echo Yonik's concerns here.  If we provide too much abstraction and indirection in the code then you're going to see a performance decrease just from method call overhead.  This is especially so if the ValueSources contain multiple layers. ",
            "author": "Chris Male",
            "id": "comment-13119119"
        },
        {
            "date": "2011-10-03T09:58:10+0000",
            "content": "I will attach some benchmark results in the issue. But in general I saw a performance difference between 0% and 5%. Depending on the query, number of documents and how documents are divided between groups. The question is how much performance penalty is acceptable for a better code design. ",
            "author": "Martijn van Groningen",
            "id": "comment-13119225"
        },
        {
            "date": "2011-11-02T07:39:07+0000",
            "content": "Ok I think this issue should be closed. The trade off for more maintainable code has a negative impact on performance that is just a bit too much.   ",
            "author": "Martijn van Groningen",
            "id": "comment-13141986"
        }
    ]
}