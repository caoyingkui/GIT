{
    "id": "LUCENE-1761",
    "title": "low level Field metadata is never removed from index",
    "details": {
        "labels": "",
        "priority": "Minor",
        "components": [
            "core/index"
        ],
        "type": "Bug",
        "fix_versions": [],
        "affect_versions": "2.2,                                            2.3,                                            2.3.1,                                            2.3.2,                                            2.4,                                            2.4.1",
        "resolution": "Unresolved",
        "status": "Open"
    },
    "description": "with heterogeneous docs, or an index whose fields evolve over time, field names that are no longer used (ie: all docs that ever referenced them have been deleted) still show up when you use IndexReader.getFieldNames.\n\nIt seems logical that segment merging should only preserve metadata about fields that actually existing the new segment, but even after deleting all documents from an index and optimizing the old field names are still present.",
    "attachments": {
        "LUCENE-1761.patch": "https://issues.apache.org/jira/secure/attachment/12414492/LUCENE-1761.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2009-07-25T03:28:30+0000",
            "content": "test case demonstrating bug. ",
            "author": "Hoss Man",
            "id": "comment-12735235"
        },
        {
            "date": "2010-02-17T00:24:41+0000",
            "content": "Does this cause any performance cost? \n\nFor example, if the \"dead\" field had norm vectors, will the norm vector byte-per-document array still be created and maintained? ",
            "author": "Lance Norskog",
            "id": "comment-12834567"
        },
        {
            "date": "2010-02-17T10:54:52+0000",
            "content": "I don't think there will be much perf loss.  Each dead field will cause a FieldInfo instance to be created (which is very small).\n\nNorms won't be loaded unless something explicitly asks for them.  EG if you do a search against the dead field, that will create the 1 byte per doc array.  If you do a sort against the dead field, FieldCache will be populated (which is silly since the values will all be null/0).  But if no searching is done against the fields I believe there's very little cost.\n\nBut we really should fix merging to purge fields that don't occur anymore... ",
            "author": "Michael McCandless",
            "id": "comment-12834730"
        },
        {
            "date": "2014-04-03T23:49:14+0000",
            "content": "[This comment stems from a discussion on the ElasticSearch mailing list: http://elasticsearch-users.115913.n3.nabble.com/Removing-unused-fields-more-Lucene-than-ES-but-td4053205.html]\n\nJust thought I would jot down some real world \u2018experience\u2019 on why I would love to see this addressed.  For background, we use ElasticSearch 0.19.10 at the moment (yes this is old\u2026), which is using Lucene 3.6.1 under the hood.  An application bug slipped in and was starting to generate dynamic fields within the ES index.  Eventually it got to 25,000 unique fields, and performance was super-sluggish.  We eliminated the data that was using these fields, and tried optimising but of course this doesn\u2019t help.  Using Luke we can still see the fields are in there even after a complete optimize (which this bug report is about).\n\nWithin ElasticSearch, the stack trace commonly seen here looks like this:\n\n\n\"elasticsearch[app5.syd.acx][index][T#6398]\" daemon prio=10 tid=0x00007fb59459b000 nid=0x7f9a runnable [0x00007fb156407000]\n   java.lang.Thread.State: RUNNABLE\n        at java.util.Arrays.copyOfRange(Arrays.java:3209)\n        at java.lang.String.<init>(String.java:215)\n        at java.lang.StringBuilder.toString(StringBuilder.java:430)\n        at org.apache.lucene.index.IndexFileNames.segmentFileName(IndexFileNames.java:227)\n        at org.apache.lucene.index.IndexFileNames.fileNameFromGeneration(IndexFileNames.java:189)\n        at org.apache.lucene.index.SegmentInfo.getNormFileName(SegmentInfo.java:508)\n        at org.apache.lucene.index.SegmentReader.reopenSegment(SegmentReader.java:232)\n        - locked <0x000000073c73c5e8> (a org.apache.lucene.index.SegmentReader)\n        at org.apache.lucene.index.SegmentReader.clone(SegmentReader.java:207)\n        - locked <0x000000073c73c5e8> (a org.apache.lucene.index.SegmentReader)\n        at org.apache.lucene.index.IndexWriter$ReaderPool.getReadOnlyClone(IndexWriter.java:656)\n        - locked <0x000000070b83cd38> (a org.apache.lucene.index.IndexWriter$ReaderPool)\n        at org.apache.lucene.index.DirectoryReader.<init>(DirectoryReader.java:142)\n        at org.apache.lucene.index.ReadOnlyDirectoryReader.<init>(ReadOnlyDirectoryReader.java:36)\n        at org.apache.lucene.index.IndexWriter.getReader(IndexWriter.java:451)\n        - locked <0x000000070029ac98> (a org.apache.lucene.index.XIndexWriter)\n        at org.apache.lucene.index.IndexWriter.getReader(IndexWriter.java:399)\n        at org.apache.lucene.index.DirectoryReader.doOpenFromWriter(DirectoryReader.java:413)\n        at org.apache.lucene.index.DirectoryReader.doOpenIfChanged(DirectoryReader.java:432)\n        at org.apache.lucene.index.DirectoryReader.doOpenIfChanged(DirectoryReader.java:375)\n        at org.apache.lucene.index.IndexReader.openIfChanged(IndexReader.java:508)\n        at org.apache.lucene.search.SearcherManager.refreshIfNeeded(SearcherManager.java:109)\n        at org.apache.lucene.search.SearcherManager.refreshIfNeeded(SearcherManager.java:57)\n        at org.apache.lucene.search.ReferenceManager.maybeRefresh(ReferenceManager.java:137)\n        at org.elasticsearch.index.engine.robin.RobinEngine.refresh(RobinEngine.java:767)\n        - locked <0x00000007001b8ec0> (a java.lang.Object)\n        at org.elasticsearch.index.engine.robin.RobinEngine.refreshVersioningTable(RobinEngine.java:926)\n        at org.elasticsearch.index.engine.robin.RobinEngine.delete(RobinEngine.java:727)\n        at org.elasticsearch.index.shard.service.InternalIndexShard.deleteByQuery(InternalIndexShard.java:381)\n        at org.elasticsearch.action.deletebyquery.TransportShardDeleteByQueryAction.shardOperationOnReplica(TransportShardDeleteByQueryAction.java:106)\n        at org.elasticsearch.action.support.replication.TransportShardReplicationOperationAction$ReplicaOperationTransportHandler.messageReceived(TransportShardReplicationOperationAction.java:255)\n        at org.elasticsearch.action.support.replication.TransportShardReplicationOperationAction$ReplicaOperationTransportHandler.messageReceived(TransportShardReplicationOperationAction.java:241)\n        at org.elasticsearch.transport.netty.MessageChannelHandler$RequestHandler.run(MessageChannelHandler.java:268)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)\n        at java.lang.Thread.run(Thread.java:662)\n\n\n\nThe crutch here is within SegmentReader.java:\n\n\n    boolean[] fieldNormsChanged = new boolean[core.fieldInfos.size()];\n    final int fieldCount = core.fieldInfos.size();\n    for (int i = 0; i < fieldCount; i++) {\n      if (!this.si.getNormFileName(i).equals(si.getNormFileName(i))) {\n        normsUpToDate = false;\n        fieldNormsChanged[i] = true;\n      }\n    }\n\n\n\n\nThe reopen causes an iteration the size of the # fields.  The outer ES loop is a function of the # deleted documents.    So the pathological case here is a high-write intensive workload (us) with a lot of deleted documents accumulating with a large # fields... ouch.\n\nAt first I thought optimizing would help a lot (which it does a bit) but the inner loop of 25,000 fields in this case is a killer.\n\nThe performance degradation is probably more about the way ElasticSearch works, but I think having within the Lucene structure dead stuff that isn\u2019t self cleaned is asking for trouble, and honestly shouldn\u2019t be that hard to fix, right?  If dead fields are culled as the segments are merged, this would just fix itself naturally wouldn\u2019t it?\n\nAnyway I just wanted to highlight a specific, painful experience where the lack of options here to recover really hurt us. So appreciate if this gets worked on!  ",
            "author": "Paul Smith",
            "id": "comment-13959439"
        },
        {
            "date": "2014-04-03T23:59:44+0000",
            "content": "\nand honestly shouldn\u2019t be that hard to fix, right? If dead fields are culled as the segments are merged, this would just fix itself naturally wouldn\u2019t it?\n\nIts pretty tricky to fix actually. There is a lot going on here including concurrency concerns with field numbers. Recycling field numbers would be even more difficult. The price paid for a mistake here is going to be index corruption because of how bulk stored fields merges and stuff work.\n\nThe risk is high, and the use-case for this is... not clear (in your case as you describe, it was an app bug). In such a situation I think filtering them out with something like addIndexes+FieldFilterAtomicReader is an acceptable workaround.\n\nAs far as why the opening is slow, thats specific to lucene 3.x's updatable norms (separate norms), which I'd bet $20 you arent even using. Unfortunately the same situation presents itself in SegmentReader due to updatable docvalues: i committed a comment that will hopefully be addressed:\n\n    // TODO: can we avoid iterating over fieldinfos several times and creating maps of all this stuff if dv updates do not exist?\n\n ",
            "author": "Robert Muir",
            "id": "comment-13959450"
        },
        {
            "date": "2016-01-27T01:19:33+0000",
            "content": "I've also seen this happen recently on 4.10.x. As in the original problem statement the fields added were added because of an app bug.\n\nWe're seeing Lucene and Solr and ES being used in ever larger-and-more-difficult-to-reindex situations. Thinking out loud here I wonder if there's a way to accomplish this, perhaps as an option to checkindex or maybe even a new index maintenance utility? What I'm thinking here is that rather than make this part of the standard merge process, make it something that has to be explicitly requested.\n\nOne advantage of that kind of utility would be users could back up the index, run the utility then verify. That way they'd at least have a fallback if the index became corrupted. That would also remove performance considerations from the normal processing. ",
            "author": "Erick Erickson",
            "id": "comment-15118410"
        },
        {
            "date": "2017-08-18T21:52:15+0000",
            "content": "We're trying to migrate from UninvertingReader to DocValues, and from Legacy*Field to *Point, and this bug is causing searches to fail.\n\nThere are many fields that used to have values, but don't any more. Things that would work fine if the fields were removed completely are failing because of the old field remnants:\nDocValues.get* throws an IllegalStateException (unexpected docvalues type NONE for field 'foo')\nPointRangeQuery throws an IllegalArgumentException (field=\"foo\" was indexed with numDims=0 but this query has numDims=1) ",
            "author": "Jeffrey Morlan",
            "id": "comment-16133669"
        }
    ]
}