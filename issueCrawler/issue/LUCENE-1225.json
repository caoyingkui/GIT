{
    "id": "LUCENE-1225",
    "title": "NGramTokenizer creates bad TokenStream",
    "details": {
        "labels": "",
        "priority": "Minor",
        "components": [
            "modules/analysis"
        ],
        "type": "Bug",
        "fix_versions": [],
        "affect_versions": "None",
        "resolution": "Won't Fix",
        "status": "Resolved"
    },
    "description": "The issue is much the same with https://issues.apache.org/jira/browse/LUCENE-1224",
    "attachments": {
        "NGramTokenizer.patch": "https://issues.apache.org/jira/secure/attachment/12377688/NGramTokenizer.patch",
        "LUCENE-1225.patch": "https://issues.apache.org/jira/secure/attachment/12377987/LUCENE-1225.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2008-03-12T10:46:48+0000",
            "content": "This patch will fix the issue. ",
            "author": "Hiroaki Kawai",
            "id": "comment-12577796"
        },
        {
            "date": "2008-03-15T18:09:32+0000",
            "content": "Please add unit tests.  Also, while not required, you do have several patches w/ the same name.  I find it useful to name my patches after the JIRA issue, something like LUCENE-1225.patch.\n\nThanks! ",
            "author": "Grant Ingersoll",
            "id": "comment-12579070"
        },
        {
            "date": "2008-03-16T03:58:35+0000",
            "content": "Modified unit tests to do in more appropriate way and add a test that index and query.\n\nI had to fix my patch again which is included in LUCENE-1225.patch. :-p\nThank you. ",
            "author": "Hiroaki Kawai",
            "id": "comment-12579157"
        },
        {
            "date": "2013-03-10T13:30:27+0000",
            "content": "SPRING_CLEANING_2013 We can reopen if necessary.  ",
            "author": "Erick Erickson",
            "id": "comment-13598245"
        }
    ]
}