{
    "id": "SOLR-5606",
    "title": "REST based Collections API",
    "details": {
        "affect_versions": "None",
        "status": "Closed",
        "fix_versions": [
            "6.0"
        ],
        "components": [
            "SolrCloud"
        ],
        "type": "Improvement",
        "priority": "Minor",
        "labels": "",
        "resolution": "Duplicate"
    },
    "description": "For consistency reasons, the collections API (and other admin APIs) should be REST based. Spinoff from SOLR-1523",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "author": "Timothy Potter",
            "id": "comment-14643229",
            "date": "2015-07-27T19:11:19+0000",
            "content": "I think striving for a REST solution is not practical at this point with the maturing of the bulk-style Schema and Configs APIs. Rather than continuing to argue about REST (see discussion on SOLR-7312), we should embrace this bulk approach and try to be consistent. In other words, having the same feel across all admin APIs seems more productive than having a REST-based Collection API and a bulk-style Schema / Config API. Specifically, here are some additional ideas I have for this effort:\n\n1) Adapt the current collections API to use the bulk-style API used by Schema and Config API at the /solr/<collection>/admin endpoint. For instance, to add a replica to shard1 of the gettingstarted collection, I would do:\n\n\ncurl -X POST -H 'Content-type:application/json' --data-binary '{\n  \"add-replica\":{\n     \"shard\":\"shard1\",\n     \"node\":\"192.168.0.1_solr\"}\n}' http://localhost:8983/solr/gettingstarted/admin\n\n\n\nThe other collection admin actions would work similarly. This also has the benefit of allowing multiple collection admin actions to be applied at the same time, such as to add a replica for each shard at the same time.\n\nIn general, no operations that change the state of Solr should accept GET requests, see: SOLR-1523\n\n2) Move all of the cluster-level API actions currently in the collections API to a cluster API. Specifically, the following actions should not be in the \"collections\" API:\n\n/admin/collections?action=CLUSTERPROP: Add/edit/delete a cluster-wide property \n/admin/collections?action=ADDROLE: Add a specific role to a node in the cluster \n/admin/collections?action=REMOVEROLE: Remove an assigned role \n/admin/collections?action=OVERSEERSTATUS: Get status and statistics of the overseer \n/admin/collections?action=CLUSTERSTATUS: Get cluster status \n\nIn addition, we should add a node status API endpoint similar to what is reported by bin/solr status, i.e.\n\n\nSolr process 81705 running on port 7574\n{\n  \"solr_home\":\"/Users/timpotter/dev/lw/projects/br5x/solr/example/cloud/node2/solr/\",\n  \"version\":\"5.3.0-SNAPSHOT 1689511 - timpotter - 2015-07-06 16:00:47\",\n  \"startTime\":\"2015-07-06T22:36:38.322Z\",\n  \"uptime\":\"0 days, 21 hours, 39 minutes, 50 seconds\",\n  \"memory\":\"88 MB (%17.9) of 490.7 MB\",\n  \"cloud\":{\n    \"ZooKeeper\":\"localhost:9983\",\n    \"liveNodes\":\"2\",\n    \"collections\":\"3\"}}\n\n\n\nNOTE: The JSON returned by the node status API should use a consistent naming style for names; the Schema / Config APIs use a snake-case with dashes vs. camel case. Whichever we chose, it needs to be consistent across all requests / responses returned by Solr.\n\n3) The CLUSTERSTATUS action takes an optional collection / shard parameters, which should be migrated under a specific collection endpoint, such as:\n\n/solr/<collection>/status\n\nIntegrate the healthcheck code in the SolrCLI with the /solr/<collection>/status action so that the healthcheck is available to all clients and not just from the command-line.\n\n4) Sending a GET request to the /solr/<collection> endpoint should return 200 (exists) or 404 (not found). The body could also return basic metadata (as JSON) about the specified collection if it exists. This also helps fix the issue of determining if a collection already exists. Currently, users have to either iterate over the list of collections to determine existence or use the CLUSTERSTATUS command with the collection parameter, neither of which are as intuitive as sending a GET request to a collection resource.\n\nAlternatively, rather than having a separate status endpoint for a collection, we could just return the status information for the collection for a GET request to /solr/<collection>. We can use a query string parameter to allow users to control how much status information should be returned as things like the healthcheck are not free to execute so should only be done when requested. For instance:\n\nGET /solr/<collection> returns 200 or 404\nGET /solr/<collection>?status=true returns status information in the response body\n\n5) Ability to filter collections from the API based on the following criteria (similar to what the cloud panel enables in the UI):\n\nGET /solr/collections returns a list of all collection names\n\nor\n\nGET /solr/collections?params return a list of collections matching criteria specified in the additional params. \n\nFiltering criteria could include:\n+ name prefix matching (tj*)\n+ config name (to show me all the collections that use config xyz)\n+ activity level (to show my busiest collections in the past X time range)\n+ replica status (to show me all the collections that have replicas that are down | recovering | etc)\n+ by node (to show me all the collections that have replicas on a specific node in my cluster)\n+ creation date (to show me all the collections created since some date or before some other date)\n\n6) Deleting a collection should use the DELETE HTTP verb, i.e.\n\nDELETE /solr/<collection>\n\nThis makes it easier to secure.\n\n7) Creating a collection needs to be overhauled. Currently, a user sends a GET request to /solr/admin/collections?action=CREATE&args \u2026. There are several issues with this:\n\n\n\tGET requests should not be used to change the state of the system, should be a PUT or a POST (or both is fine too).\n\tLong list of query parameters to specify collection parameters\n\tXML is returned by default using embedded <lst> elements (confusing)\n\tcollection.configName parameter: numerous issues\n\tresponse (besides being XML) makes no sense to a new user (see below, looks like a bunch of mumbo jumbo to me):\n\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<response>\n  <lst name=\"responseHeader\">\n    <int name=\"status\">0</int>\n    <int name=\"QTime\">1672</int>\n  </lst>\n  <lst name=\"success\">\n    <lst>\n      <lst name=\"responseHeader\">\n        <int name=\"status\">0</int>\n        <int name=\"QTime\">1497</int>\n      </lst>\n      <str name=\"core\">foo_shard2_replica1</str>\n    </lst>\n    <lst>\n      <lst name=\"responseHeader\">\n        <int name=\"status\">0</int>\n        <int name=\"QTime\">1557</int>\n      </lst>\n      <str name=\"core\">foo_shard1_replica1</str>\n    </lst>\n  </lst>\n</response>\n\n\n\n\n\nIntroduce an approach that will appeal to the REST lovers among us that accepts a JSON definition of a collection where you can POST to /solr/collections/, such as:\n\n\ncurl -XPOST -H 'Content-type: application/json' -d '{\"name\":\"golf\",\"numShards\":2,\"configName\":\"foo\"}' http://localhost:8080/solr/collections/\n\n\n\nPOST should be used instead of PUT as PUT requests are intended / expected to be idempotent. At this point, the /collections endpoint is solely used to handle creation and list/find collection requests. The API should use a sensible default for numShards and replicationFactor as a new user may not really understand these the first time they use Solr, as is done currently by the bin/solr create -c command. Response is either 201 (created) or an error code and explanation (in JSON)\n\nThere are obviously more issues to be dealt with around collection configs, but I'll address those in other ticket. The point here is to clean-up how create works.\n\n7) We need a collection-level metrics API endpoint. SolrCloud doesn't provide any aggregate stats about the cluster or a collection. Very common questions such as document counts per shard, index sizes, request rates etc cannot be answered easily without figuring out the cluster state, invoking multiple core admin APIs and aggregating them manually, see: SOLR-6325\n\n\n "
        },
        {
            "author": "Noble Paul",
            "id": "comment-14643316",
            "date": "2015-07-27T20:17:47+0000",
            "content": "+1 to the collection-name/admin end point . All operations on a given collection should be performed there like create-shard , create-replica etc\n\nanother question is why to have  a special end point called /solr/collections\n\nWhy not\n\ncurl -XPOST -H 'Content-type: application/json' -d ' {\n\"create-collection\": {\"name\":\"golf\",\n                             \"numShards\":2,\n                             \"configName\":\"foo\"}}' http://localhost:8080/solr\n\n\n\nThat way we can get rid of special URLs such as /admin/cores /admin/collections etc\na GET on http://localhost:8080/solr can respond with all available collection names "
        },
        {
            "author": "Mark Miller",
            "id": "comment-14643326",
            "date": "2015-07-27T20:27:55+0000",
            "content": "In other words, having the same feel across all admin APIs seems more productive\n\n+1. That's actually why this API was originally made to match the core admin API (which I am not a fan of at all).\n\nConsistency and REST-(like) seems best to me though. And the new schema API's were always meant to be the way of the future - start there, then start moving the other API's more in line with them. "
        },
        {
            "author": "Timothy Potter",
            "id": "comment-14644601",
            "date": "2015-07-28T16:24:13+0000",
            "content": "thanks for the feedback Mark ... \n\nAnd the new schema API's were always meant to be the way of the future - start there, then start moving the other API's more in line with them.\n\nJust to be clear, are you talking about the pure REST APIs for Schema that Steve Rowe did or the bulk-style Schema API that Noble did? I'm personally a fan of the bulk operation style vs. addressing every object inside of schema (or config) as a specific resource.\n\nre: Noble's comment \"a GET on http://localhost:8080/solr can respond with all available collection names\"\n\nI'll buy that, but it's a little subtle ... I do think it's important to have a way to filter collections when requesting the list, so would one just do something like the following?\n\nhttp://localhost:8983/solr?type=collection&filter=name&name=tj*\n\n\n\nThe type parameter could default to \"collection\" but I was thinking having it could allow us to support other types of resources if needed in the future and makes the GET request in the example easier to understand. "
        },
        {
            "author": "Noble Paul",
            "id": "comment-14644627",
            "date": "2015-07-28T16:45:07+0000",
            "content": "Yes, By default it will just give a list of all available collections . use extra params to filter . We need to push collections front and center\n\nThe type parameter could default to \"collection\" and I should be able to request for \"cores\" as well "
        },
        {
            "author": "Mark Miller",
            "id": "comment-14644662",
            "date": "2015-07-28T17:07:55+0000",
            "content": "Just to be clear, are you talking about the pure REST APIs for Schema that Steve Rowe did or the bulk-style Schema API that Noble did? I'm personally a fan of the bulk operation style vs. addressing every object inside of schema (or config) as a specific resource.\n\nWhichever makes sense for the situation. I have no problem with the bulk approach when it's more user friendly. I just mean the newer more restlike approaches (rather than everything is a GET and handled by ACTION=, etc). "
        },
        {
            "author": "Noble Paul",
            "id": "comment-14644716",
            "date": "2015-07-28T17:34:45+0000",
            "content": "We need to standardize how we build our APIs . consistency is more important. \n\nOnce we have a standard way of building an API we can think of exposing metadata on what are the expected method names and parameters "
        },
        {
            "author": "Mark Miller",
            "id": "comment-14644761",
            "date": "2015-07-28T17:57:59+0000",
            "content": "Having both bulk and individual API's is consistent IMO.\n\nWe won't standardize first though. Many devs, all with different opinions, all working and paying attention at different times. It's a pipe dream.\n\nWe just need to slowly get away from the terrible Core Admin pattern - that's the best I can hope for. "
        },
        {
            "author": "Anshum Gupta",
            "id": "comment-14644843",
            "date": "2015-07-28T18:47:39+0000",
            "content": "I'm totally +10 on the newer style APIs, both bulk and REST, more inclined towards bulk though.\n\nAnd though standardizing would be a great thing, I think as Mark put it, it'd be tough to control across different developers, being active at different times. In the past, most of the times I've tried to do something on those lines, it almost always got stalled trying to reach a consensus i.e. if you're talking about re-writing everything (even Schema in case we move to bulk). "
        },
        {
            "author": "Steve Molloy",
            "id": "comment-14645018",
            "date": "2015-07-28T20:46:30+0000",
            "content": "I agree with pretty much all that is being said, with one big exception on the \"type\" parameter. If you want some REST-like API, you should not get different types of results depending on query parameters. So I'd definitely recommend keeping the /solr/collection approach, and have /solr/core for cores, /solr/schema, /solr/alias, etc... All this can live very well with bulk operations, you could either PUT a single schema to update it, or POST a list of collection information to create multiple collections in bulk, but on the right resource type. Not only is it cleaner to have the resource you want to interact with part of the URL used to access it, it would also make it much easier to integrate with standard client libraries for REST APIs. "
        },
        {
            "author": "Timothy Potter",
            "id": "comment-14645179",
            "date": "2015-07-28T23:17:27+0000",
            "content": "Steve Molloy what's your proposal for how to get a list of collections? If I'm reading this statement correctly:\n\nNot only is it cleaner to have the resource you want to interact with part of the URL used to access it, it would also make it much easier to integrate with standard client libraries for REST APIs.\n\nSounds like you want the API to get a list of collections to be at endpoint /solr/collections and when addressing a specific collection /solr/collections/<collection>/[query|update|admin|whatever] \n\nNoble proposed hanging the list of collections off of /solr to avoid this issue, which I'm fine with and also POST'ing to /solr to create a collection (with the correct JSON params in the request body of course). Without the type parameter, we either have to say /solr always deals with collections only and any other types have their own unique path, such as /solr/cores. If we want /solr/collections/ in every path that addresses anything collection related, then I'm not going to argue ... just want to be clear. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-14645374",
            "date": "2015-07-29T02:19:45+0000",
            "content": "Honestly, having collections related things hang off solr/collections seems much better to me. Having everything off /solr and using a type param reminds of the ugly core admin API. I wish I was around when that API was added to veto it  "
        },
        {
            "author": "Anshum Gupta",
            "id": "comment-14645380",
            "date": "2015-07-29T02:34:13+0000",
            "content": "I didn't +1 on a /solr endpoint . I love the bulk API + sensible rest endpoints. I'm not too concerned about PUT Vs POST but that we have clean (REST like) end points. "
        },
        {
            "author": "Noble Paul",
            "id": "comment-14645443",
            "date": "2015-07-29T04:50:10+0000",
            "content": "It is fine to have /solr/collections end point for collection related APIs. Just keep in mind that we are taking up a name in the namespace (this could collide with a collection name) with every path we add. \n\nWhat I mean to say is let us not add too many top level paths /solr/collections, /solr/cores , /solr/configs, solr/cluster\n\nLet's have  a list of end points we need and make a call on what should be the paths. \n\nIt is OK to have a prefix of /solr/admin/* because we already have that namespace taken up. So the only name collision is admin which is already taken up\n\nI mean we can have end points such as \n\n\n\t/admin/collections\n\t/admin/cores\n\t/admin/cluster\n\t/admin/configs\n\t/admin/security\n\n "
        },
        {
            "author": "Shai Erera",
            "id": "comment-14645547",
            "date": "2015-07-29T06:34:36+0000",
            "content": "+1 on having /admin/* paths for Solr admin related stuff and /{collection}/{handler} for collection specific stuff that are not collection-admin operations. "
        },
        {
            "author": "Steve Molloy",
            "id": "comment-14645950",
            "date": "2015-07-29T12:10:10+0000",
            "content": "I guess others have already replied, but just to make sure my comment is not perceived as contradictory... I don't have an issue with /solr/admin/collections, /solr/admin/cores, etc. I think it actually makes a lot of sense. I wasn't debating about the actual endpoint but rather about the fact that the endpoint could work with multiple resource types with that \"type\" parameter. So last comment by Noble Paul makes perfect sense to me. \n\nBasically, /solr/admin/collections would manage collections, while /solr/<collection>/<handler> would work with documents in it, so it makes sense to have them separate. "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-14645990",
            "date": "2015-07-29T12:48:06+0000",
            "content": "\nI mean we can have end points such as\n/admin/collections\n/admin/cores\n/admin/cluster\n/admin/configs\n/admin/security\n\n+1\n\nI like this. "
        },
        {
            "author": "Timothy Potter",
            "id": "comment-14646234",
            "date": "2015-07-29T15:06:18+0000",
            "content": "So if I want to add a replica to a specific collection, what's the endpoint?\n\n\ncurl -XPOST -H 'Content-type:application/json' --data-binary '{ \"add-replica\":{ \"shard\":\"shard1\", \"node\":\"192.168.0.1_solr\"} }' http://localhost:8983/solr/<collection>/admin\n\n\n\nor\n\n\ncurl -XPOST -H 'Content-type:application/json' --data-binary '{ \"add-replica\":{ \"shard\":\"shard1\", \"node\":\"192.168.0.1_solr\"} }' http://localhost:8983/solr/collections/admin/gettingstarted\n\n "
        },
        {
            "author": "Steve Molloy",
            "id": "comment-14646266",
            "date": "2015-07-29T15:22:32+0000",
            "content": "I would expect POST on /solr/admin/collections/gettingstarted/replicas with optional content \n{\"node\":\"192.168.0.1_solr\"}\n, node being chosen randomly if not specified. You could then list a collection's replicas using GET on /solr/admin/collections/gettingstarted/replicas, same for shards on /solr/admin/collections/gettingstarted/shards. In the case of shards, there's also the split shard to consider, which I guess could either be POST on /solr/admin/collections/gettingstarted/shards/shard1?action=split or a PUT on the same endpoint. Not sure what the best approach is here as you're effectively creating new resources (2 new shards) from an existing one. Maybe a dedicated shard action endpoint for shard actions.\n\nThe other approach would be to consider replicas and shards as part of the collection metadata, implying that adding a replica would be done through a PUT on /solr/admin/collections/gettingstarted with content like {\"name\":\"gettingstarted\", replicas:[\n{\"shard\":\"shard1\",\"node\"192.168.0.1_solr\"}\n,\n{\"shard\":\"shard1\",\"node\"192.168.0.2_solr\"}\n]}. This works in theory but brings complications such as what to do if existing replica is not in the PUT sent. Would that mean delete it or keep it and just create new ones for what user sent. I think having sub-resources for replicas and shards would make it easier to maintain and understand. "
        },
        {
            "author": "Shai Erera",
            "id": "comment-14646275",
            "date": "2015-07-29T15:29:57+0000",
            "content": "I like the POST /solr/admin/collections/gettingstarted/replicas to create a replica, only the replicas is created for a shard, so the call should probably be POST /solr/admin/collections/gettingstarted/shards/shard1/replicas with a payload relevant to the ADDREPLICA API.\n\nI don't think that we should have GET /solr/admin/collections/gettingstarted/replicas though, but rather GET /solr/admin/collections/gettingstarted/shards since replicas belong to shards. We can have GET /solr/admin/collections/gettingstarted/shards/shard1 to get the replicas of shard1. "
        },
        {
            "author": "Steve Molloy",
            "id": "comment-14646282",
            "date": "2015-07-29T15:36:33+0000",
            "content": "Makes sense. Basically, what I'm trying to get at is that action to be performed should not be part of query parameters (or POST body which is pretty much the same). It should be represented by the HTTP method used as much as possible, POST to create, PUT to modify, GET to list/retrieve info, DELETE to delete. There are some operations that cannot fit this, but we should go that route when possible. "
        },
        {
            "author": "Timothy Potter",
            "id": "comment-14646303",
            "date": "2015-07-29T15:46:57+0000",
            "content": "POST to /solr/admin/collections/gettingstarted/shards/shard1/replicas is good for REST aficionados but that's different than how the new bulk-style schema and config APIs work. The bulk style APIs work off the concept of a coarse-grained resource (collection, schema, config) and then apply one or more operations on that resource depending on what's in the request body. Both approaches have pros and cons. Seems weird to have two different styles in Solr's \"new\" API. In other words, breaking the collection API down into fine-grained sub-resources but then having the bulk approach for schema & configs seems awkward at best. If we go the REST route, then I'd advocate for going all-in with HATEOS to help users navigate through all the sub-resources. "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-14646315",
            "date": "2015-07-29T16:01:47+0000",
            "content": "Requiring http methods other than GET will remove an option that currently sees a lot of use \u2013 typing the URLs into a browser.  This is how I've created all the collections that I currently have on my 4.2.1 SolrCloud install, and is one of the things I really like about Solr's interface.  Constructing requests with POST, PUT, or DELETE currently requires additional tools and complexity.  If you're already writing code, it's usually no big deal, but there are Solr admins who do not write code. "
        },
        {
            "author": "Timothy Potter",
            "id": "comment-14646334",
            "date": "2015-07-29T16:16:42+0000",
            "content": "Sorry, Shawn Heisey I don't think modifying the state of the system with a GET request is up for discussion anymore, that has to go! It's too hard to secure the system otherwise and is just weird. As for special tools, curl sends POST, PUT, DELETE as easy as it does GET so not sure what you mean about special tools? "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-14646400",
            "date": "2015-07-29T16:52:03+0000",
            "content": "not sure what you mean about special tools?\n\nThe tool that you can use now is a browser.  To some people, anything else is a special tool.  "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-14646404",
            "date": "2015-07-29T16:56:19+0000",
            "content": "FYI, I can cope completely with this change, I'm just being a little bit of a devil's advocate. "
        },
        {
            "author": "Steve Molloy",
            "id": "comment-14646453",
            "date": "2015-07-29T17:21:44+0000",
            "content": "The tool that you can use now is a browser. To some people, anything else is a special tool.\n\nCouldn't it be done through Solr Admin UI? I think the API and the admin UI have different target audience, one for devs and the other for administrators. "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-14646457",
            "date": "2015-07-29T17:27:39+0000",
            "content": "Couldn't it be done through Solr Admin UI?\n\nHaving Collections API capability exposed through the admin UI (similar to what we have now for CoreAdmin) is something I definitely look forward to having, and it would take care of everything I've described. "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-15517548",
            "date": "2016-09-23T20:55:07+0000",
            "content": "Closing this in favor of SOLR-8029 "
        }
    ]
}