{
    "id": "LUCENE-2035",
    "title": "TokenSources.getTokenStream() does not assign positionIncrement",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [
            "modules/highlighter"
        ],
        "type": "Bug",
        "fix_versions": [
            "3.1",
            "4.0-ALPHA"
        ],
        "affect_versions": "2.4,                                            2.4.1,                                            2.9",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "TokenSources.StoredTokenStream does not assign positionIncrement information. This means that all tokens in the stream are considered adjacent. This has implications for the phrase highlighting in QueryScorer when using non-contiguous tokens.\n\nFor example:\nConsider  a token stream that creates tokens for both the stemmed and unstemmed version of each word - the fox (jump|jumped)\nWhen retrieved from the index using TokenSources.getTokenStream(tpv,false), the token stream will be - the fox jump jumped\n\nNow try a search and highlight for the phrase query \"fox jumped\". The search will correctly find the document; the highlighter will fail to highlight the phrase because it thinks that there is an additional word between \"fox\" and \"jumped\". If we use the original (from the analyzer) token stream then the highlighter works.\n\nAlso, consider the converse - the fox did not jump\n\"not\" is a stop word and there is an option to increment the position to account for stop words - (the,0) (fox,1) (did,2) (jump,4)\nWhen retrieved from the index using TokenSources.getTokenStream(tpv,false), the token stream will be - (the,0) (fox,1) (did,2) (jump,3).\n\nSo the phrase query \"did jump\" will cause the \"did\" and \"jump\" terms in the text \"did not jump\" to be highlighted. If we use the original (from the analyzer) token stream then the highlighter works correctly.",
    "attachments": {
        "LUCENE-2035.patch": "https://issues.apache.org/jira/secure/attachment/12428123/LUCENE-2035.patch",
        "LUCENE-2305.patch": "https://issues.apache.org/jira/secure/attachment/12424126/LUCENE-2305.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2009-11-05T13:43:11+0000",
            "content": "For the highlighter trunk ",
            "author": "Christopher Morris",
            "id": "comment-12773929"
        },
        {
            "date": "2009-12-16T03:00:28+0000",
            "content": "Thanks for the tests and fix Christopher!\n\nI've got one more patch coming and ill commit in a few days.\n\nI'm going to break the tests back out in a separate file again (on second thought I think how you had is a good idea) and remove an author tag. Then after one more review I think this good to go in. ",
            "author": "Mark Miller",
            "id": "comment-12791152"
        },
        {
            "date": "2009-12-16T23:47:01+0000",
            "content": "Hey Christopher, why are you going through the trouble of the custom collector to check that there are no hits? Why not just do a standard search? ",
            "author": "Mark Miller",
            "id": "comment-12791680"
        },
        {
            "date": "2009-12-16T23:53:32+0000",
            "content": "I've broken the new tests back out into there own file, change the hit collector code to just search basically, and improved the test coverage of TokenSources a bit. ",
            "author": "Mark Miller",
            "id": "comment-12791686"
        },
        {
            "date": "2009-12-17T14:11:44+0000",
            "content": "I'll commit this soon. ",
            "author": "Mark Miller",
            "id": "comment-12791939"
        },
        {
            "date": "2009-12-18T09:32:17+0000",
            "content": "Cheers Mark,\n\nThe custom collector was probably because I was learning the new API at the time.\n\nThe only changes I've made since the patch I submitted were to initialise the ArrayList with tpv.getTerms().length because that represents the minimum size that the list will grow to, and to replace the List and Iterator fields with an array (derived from the list) and an integer pointer. Both of which are probably unnecessary.\n\nThe tests could be improved - the first case could be fixed in it's present form by using the Analyzer to generate the phrase query. If the stemmed word was the middle word of the phrase then that fix wouldn't work. ",
            "author": "Christopher Morris",
            "id": "comment-12792410"
        },
        {
            "date": "2010-01-06T19:08:57+0000",
            "content": "Thanks Christopher! ",
            "author": "Mark Miller",
            "id": "comment-12797251"
        },
        {
            "date": "2010-10-29T13:11:45+0000",
            "content": "reopening for possible 2.9.4/3.0.3 backport. ",
            "author": "Robert Muir",
            "id": "comment-12926269"
        },
        {
            "date": "2010-11-27T23:25:33+0000",
            "content": "Resolving again as this issue will not be backported to 2.9/3.0 branches. ",
            "author": "Uwe Schindler",
            "id": "comment-12964468"
        },
        {
            "date": "2011-03-30T15:50:25+0000",
            "content": "Bulk close for 3.1 ",
            "author": "Grant Ingersoll",
            "id": "comment-13013475"
        }
    ]
}