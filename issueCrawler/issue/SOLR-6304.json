{
    "id": "SOLR-6304",
    "title": "Transforming and Indexing custom JSON data",
    "details": {
        "affect_versions": "None",
        "status": "Resolved",
        "fix_versions": [
            "4.10",
            "6.0"
        ],
        "components": [],
        "type": "Improvement",
        "priority": "Major",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "example\n\ncurl localhost:8983/update/json/docs?split=/batters/batter&f=recipeId:/id&f=recipeType:/type&f=id:/batters/batter/id&f=type:/batters/batter/type -d '\n{\n\t\t\"id\": \"0001\",\n\t\t\"type\": \"donut\",\n\t\t\"name\": \"Cake\",\n\t\t\"ppu\": 0.55,\n\t\t\"batters\": {\n\t\t\t\t\"batter\":\n\t\t\t\t\t[\n\t\t\t\t\t\t{ \"id\": \"1001\", \"type\": \"Regular\" },\n\t\t\t\t\t\t{ \"id\": \"1002\", \"type\": \"Chocolate\" },\n\t\t\t\t\t\t{ \"id\": \"1003\", \"type\": \"Blueberry\" },\n\t\t\t\t\t\t{ \"id\": \"1004\", \"type\": \"Devil's Food\" }\n\t\t\t\t\t]\n\t\t\t}\n}'\n\n\n\nshould produce the following output docs\n\n\n{ \"recipeId\":\"001\", \"recipeType\":\"donut\", \"id\":\"1001\", \"type\":\"Regular\" }\n{ \"recipeId\":\"001\", \"recipeType\":\"donut\", \"id\":\"1002\", \"type\":\"Chocolate\" }\n{ \"recipeId\":\"001\", \"recipeType\":\"donut\", \"id\":\"1003\", \"type\":\"Blueberry\" }\n{ \"recipeId\":\"001\", \"recipeType\":\"donut\", \"id\":\"1004\", \"type\":\"Devil's food\" }\n\n\n\nthe split param is the element in the tree where it should be split into multiple docs. The 'f' are field name mappings",
    "attachments": {
        "SOLR-6304.patch": "https://issues.apache.org/jira/secure/attachment/12660203/SOLR-6304.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-14087756",
            "date": "2014-08-06T15:02:44+0000",
            "content": "I like this. We should try to standardize this across CSV and XML formats too (but don't let that stop you).\n\nInitially I thought that we could do f.id.map=/batters/batter/id instead of f=id:/batters/batter/id but then that'd mean that not specifying field names would not be possible. In the current syntax, one can just write f=:/batters/batter/id and the field name can automatically be inferred as id if required. "
        },
        {
            "author": "Noble Paul",
            "id": "comment-14087763",
            "date": "2014-08-06T15:07:11+0000",
            "content": "In the current syntax, one can just write f=:/batters/batter/id and the field name can automatically be inferred as id \n\nit will be f=/batters/batter/id . omit the colon too. And I expect this to be a very common usecase "
        },
        {
            "author": "Noble Paul",
            "id": "comment-14087770",
            "date": "2014-08-06T15:09:34+0000",
            "content": "We should try to standardize this across CSV and XML formats too\nWe already have  avery powerful XPathRecordReader in the DIH. I'm planning to move that into the common util and make this syntax valid for xml as well. But for csv , we already have a very powerful processing syntax . I'm not sure if we should change that  "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-14087771",
            "date": "2014-08-06T15:11:01+0000",
            "content": "it will be f=/batters/batter/id . omit the colon too. And I expect this to be a very common usecase\n\nYes, you are right, the colon is not necessary.\n\nWe already have avery powerful XPathRecordReader in the DIH. I'm planning to move that into the common util and make this syntax valid for xml as well.\n\n+1, yay! Being able to consume most XMLs easily would be great.\n "
        },
        {
            "author": "Noble Paul",
            "id": "comment-14088102",
            "date": "2014-08-06T19:29:07+0000",
            "content": "A streaming parser for JSON  "
        },
        {
            "author": "Noble Paul",
            "id": "comment-14092151",
            "date": "2014-08-10T19:09:22+0000",
            "content": "This fixes all the cases, including raw json \n\nI plan to commit this soon "
        },
        {
            "author": "Erik Hatcher",
            "id": "comment-14092171",
            "date": "2014-08-10T19:54:02+0000",
            "content": "Noble Paul - looks good!   It'll be really cool when this type of flattening is available for XML too.  One thing, I think the \"echo\" debugging parameter in there should at least be \"json.echo\" to qualify it, though with XML flattening future, maybe \"echo\" is just fine, or \"flatten.echo\"?   I'm just thinking out loud with namespacing in mind. "
        },
        {
            "author": "Noble Paul",
            "id": "comment-14092421",
            "date": "2014-08-11T04:16:33+0000",
            "content": "I think the \"echo\" debugging parameter in there should at least be \"json.echo\" to qualify it\n\nI want all paths to support it .That is why I did not use a prefix. Why can't csv too do it?\n\nt'll be really cool when this type of flattening is available for XML too.\n\nIt's coming. The capability is already there . I just need to move the XPathRecordReader.java to the common util and add a path  "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14092791",
            "date": "2014-08-11T14:08:12+0000",
            "content": "Commit 1617287 from Noble Paul in branch 'dev/trunk'\n[ https://svn.apache.org/r1617287 ]\n\nSOLR-6304 JsonLoader should be able to flatten an input JSON to multiple docs "
        },
        {
            "author": "Erik Hatcher",
            "id": "comment-14092818",
            "date": "2014-08-11T14:34:36+0000",
            "content": "I want all paths to support it .That is why I did not use a prefix. Why can't csv too do it?\n\nOk, cool.  As for CSV, the echo feature is for when an incoming payload is split into multiple documents, right?   So it doesn't have quite the same value/effect that it does for this flattening of JSON and XML.   "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14092819",
            "date": "2014-08-11T14:36:11+0000",
            "content": "Commit 1617296 from Noble Paul in branch 'dev/branches/branch_4x'\n[ https://svn.apache.org/r1617296 ]\n\nSOLR-6304 JsonLoader should be able to flatten an input JSON to multiple docs "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14093821",
            "date": "2014-08-12T07:01:19+0000",
            "content": "Commit 1617424 from Noble Paul in branch 'dev/trunk'\n[ https://svn.apache.org/r1617424 ]\n\nSOLR-6304 wildcard fix "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14093827",
            "date": "2014-08-12T07:07:50+0000",
            "content": "Commit 1617425 from Noble Paul in branch 'dev/branches/branch_4x'\n[ https://svn.apache.org/r1617425 ]\n\nSOLR-6304 wildcard fix "
        },
        {
            "author": "Ingo Renner",
            "id": "comment-14099421",
            "date": "2014-08-16T01:01:33+0000",
            "content": "Just read the article on searchhub for this issue [1]. If echo is meant for debugging purposes and doesn't create documents, wouldn't it make more sense to call the parameter 'debug' or 'dryrun'?\n\n[1] http://searchhub.org/2014/08/12/indexing-custom-json-data/ "
        },
        {
            "author": "Noble Paul",
            "id": "comment-14109381",
            "date": "2014-08-25T17:46:44+0000",
            "content": "Ingo Renner 'debug' somehow suggested that it is actually doing indexing. I thought of 'dryrun' which  better describes the functionality but not as simple as a single word 'echo' "
        },
        {
            "author": "Bryan Bende",
            "id": "comment-14349298",
            "date": "2015-03-05T19:11:21+0000",
            "content": "Is there a way to send multiple JSON documents in a single request?\n\nThe comments of JsonRecordReader for the splitPath say:\n\n\n\t... Any fields collected in the\n\tparent tag or above will also be included in the record, but these are\n\tnot cleared after emitting the record.\n\t<p/>\n\tIt uses the ' | ' syntax of PATH to pass in multiple paths.\n\n\n\nSo if you took the example from the blog post with the exams data, and sent two json documents with different first and last names, and split on /exams, then the first document gets added correctly, but the second document gets two values for first name since it is not cleared after the first record.\n\nI would imagine there is some way to do this with the correct split path, but can't figure it out. "
        },
        {
            "author": "Noble Paul",
            "id": "comment-14349345",
            "date": "2015-03-05T19:36:41+0000",
            "content": "The example is correct and Works as designed.\n\nI'm not clear what your requirement is. \n\nPlease give an example as to what your input is and what do you expect your output as\n "
        },
        {
            "author": "Bryan Bende",
            "id": "comment-14349389",
            "date": "2015-03-05T19:58:19+0000",
            "content": "Sorry I didn't mean to imply that anything was wrong with the example... I wanted to know if it was possible to send multiple JSON documents in a single request, like this:\n\ncurl 'http://localhost:8983/solr/collection1/update/json/docs'\n'?split=/exams'\n'&f=first:/first'\n'&f=last:/last'\n'&f=grade:/grade'\n'&f=subject:/exams/subject'\n'&f=test:/exams/test'\n'&f=marks:/exams/marks'\n -H 'Content-type:application/json' -d '\n{\n  \"first\": \"John\",\n  \"last\": \"Doe\",\n  \"grade\": 8,\n  \"exams\": [\n      {\"subject\": \"Maths\", \"test\"   : \"term1\", \"marks\":90},\n      {\"subject\": \"Biology\", \"test\"   : \"term1\", \"marks\":86}\n      ]\n}\n{\n  \"first\": \"Bob\",\n  \"last\": \"Smith\",\n  \"grade\": 7,\n  \"exams\": [\n      {\"subject\": \"Maths\", \"test\"   : \"term1\", \"marks\":95},\n      {\"subject\": \"Biology\", \"test\"   : \"term1\", \"marks\":92}\n      ]\n}\n'\n\n\nAnd then get 4 documents added to solr:\njohn, doe, maths...\njohn, doe, biology...\nbob, smith, maths...\nbob, smith, biology...\n\nAn example of the code I was trying to write is here:\nhttps://github.com/bbende/solrj-custom-json-update/blob/master/src/test/java/org/apache/solr/IndexJSONTest.java\ntestAddMultipleJsonDocsWithContentStreamUpdateRequest "
        },
        {
            "author": "Noble Paul",
            "id": "comment-14352610",
            "date": "2015-03-09T06:34:08+0000",
            "content": "So , what was the outcome? How many docs were indexed? "
        },
        {
            "author": "Bryan Bende",
            "id": "comment-14353066",
            "date": "2015-03-09T14:58:25+0000",
            "content": "For the first JSON document it indexes two solr documents as expected:\njohn, doe, maths...\njohn, doe, biology...\n\nbut when it hits the second JSON document it still has values left over from the first document and tries to index a document like:\n[john, bob], [doe, smith], maths....  "
        },
        {
            "author": "Noble Paul",
            "id": "comment-14353268",
            "date": "2015-03-09T17:49:16+0000",
            "content": "opened a ticket SOLR-7209 "
        },
        {
            "author": "Kelly Kagen",
            "id": "comment-14988279",
            "date": "2015-11-03T22:19:55+0000",
            "content": "I'm having some difficulty while indexing custom JSON data using v5.3.1. I took the same example from the documentation, but it doesn't seem to be working as expected. Can someone validate if this is a bug or there's an issue with the procedure followed? The below are the scenarios.\n\nSource: Indexing custom JSON data, Transforming and Indexing Custom JSON\n\nNote: The echo parameter has been added.\n\nInput:\n\ncurl 'http://localhost:8983/solr/collection1/update/json/docs'\n'?split=/exams'\n'&f=first:/first'\n'&f=last:/last'\n'&f=grade:/grade'\n'&f=subject:/exams/subject'\n'&f=test:/exams/test'\n'&f=marks:/exams/marks'\n'&echo=true'\n -H 'Content-type:application/json' -d '\n{\n  \"first\": \"John\",\n  \"last\": \"Doe\",\n  \"grade\": 8,\n  \"exams\": [\n      {\n        \"subject\": \"Maths\",\n        \"test\"   : \"term1\",\n        \"marks\":90},\n        {\n         \"subject\": \"Biology\",\n         \"test\"   : \"term1\",\n         \"marks\":86}\n      ]\n}'\n\n\n\nOutput:\n\n{\n  \"error\":{\n    \"msg\":\"Raw data can be stored only if split=/\",\n    \"code\":400\n  }\n}\n\n\n\nSay I pass only '/' to the split parameter as reported, but with different field mappping, it doesn't seem to index the data per mentioned fields. Notice the suffix 'Name' added in the input JSON and also the field mapping.\n\nInput:\n\ncurl 'http://localhost:8983/solr/collection1/update/json/docs'\n'?split=/'\n'&f=first:/firstName'\n'&f=last:/lastName'\n'&f=grade:/grade'\n'&f=subject:/exams/subjectName'\n'&f=test:/exams/test'\n'&f=marks:/exams/marks'\n'&echo=true'\n -H 'Content-type:application/json' -d '\n{\n  \"firstName\": \"John\",\n  \"lastName\": \"Doe\",\n  \"grade\": 8,\n  \"exams\": [\n      {\n        \"subjectName\": \"Maths\",\n        \"test\"   : \"term1\",\n        \"marks\":90},\n        {\n         \"subject\": \"Biology\",\n         \"test\"   : \"term1\",\n         \"marks\":86}\n      ]\n}'\n\n\n\nOutput:\n\n{\"responseHeader\":{\"status\":0,\"QTime\":0},\"docs\":[{\"id\":\"3c5fa5a0-ff71-4fef-b3e9-8e279cc0d724\",\"_src_\":\"{  \\\"firstName\\\": \\\"John\\\",  \\\"lastName\\\": \\\"Doe\\\",  \\\"grade\\\": 8,  \\\"exams\\\": [      {        \\\"subjectName\\\": \\\"Maths\\\",        \\\"test\\\"   : \\\"term1\\\",        \\\"marks\\\":90},        {         \\\"subject\\\": \\\",         \\\"test\\\"   : \\\"term1\\\",         \\\"marks\\\":86}      ]}\",\"text\":[\"John\",\"Doe\",8,\"Maths\",[\"term1\",\"term1\"],[90,86]]}]}\n\n\n\nIf there is a field named \"id\" is present then that reflects in the reponse, but all other fields are ignored for some reason.\n\nInput:\n\ncurl 'http://localhost:8983/solr/collection1/update/json/docs'\n'?split=/'\n'&f=first:/firstName'\n'&f=id:/lastName'\n'&f=grade:/grade'\n'&f=subject:/exams/subjectName'\n'&f=test:/exams/test'\n'&f=marks:/exams/marks'\n'&echo=true'\n -H 'Content-type:application/json' -d '\n{\n  \"firstName\": \"John\",\n  \"lastName\": \"Doe\",\n  \"grade\": 8,\n  \"exams\": [\n      {\n        \"subjectName\": \"Maths\",\n        \"test\"   : \"term1\",\n        \"marks\":90},\n        {\n         \"subject\": \"Biology\",\n         \"test\"   : \"term1\",\n         \"marks\":86}\n      ]\n}'\n\n\n\nOutput:\n\n{\"responseHeader\":{\"status\":0,\"QTime\":1},\"docs\":[{\"id\":\"Doe\",\"_src_\":\"{  \\\"firstName\\\": \\\"John\\\",  \\\"lastName\\\": \\\"Doe\\\",  \\\"grade\\\": 8,  \\\"exams\\\": [      {        \\\"subjectName\\\": \\\"Maths\\\",        \\\"test\\\"   : \\\"term1\\\",        \\\"marks\\\":90},        {         \\\"subject\\\": \\\",         \\\"test\\\"   : \\\"term1\\\",         \\\"marks\\\":86}      ]}\",\"text\":[\"John\",\"Doe\",8,\"Maths\",[\"term1\",\"term1\"],[90,86]]}]}\n\n "
        },
        {
            "author": "Alexandre Rafalovitch",
            "id": "comment-14988312",
            "date": "2015-11-03T22:35:03+0000",
            "content": "Seems like a conflict with SOLR-6633 feature (store JSON as a blob). Check your solrconfig.xml for srcField and remove it. \n\nNoble PaulI can debug, but I can't explain it. Should these two things be possible at once? Should we document the interplay somewhere? "
        },
        {
            "author": "Noble Paul",
            "id": "comment-14989413",
            "date": "2015-11-04T11:49:03+0000",
            "content": "I guess you are not using the schemaless example\n\nplease go to your solrconfig.xml and edit out the two lines\n\n\n      <!--this ensures that the entire json doc will be stored verbatim into one field-->\n      <str name=\"srcField\">_src_</str>\n      <!--This means a the uniqueKeyField will be extracted from the fields and\n       all fields go into the 'df' field. In this config df is already configured to be 'text'\n        -->\n      <str name=\"mapUniqueKeyOnly\">true</str>\n\n\n\nPlease note that, you should have all your fields specified in your schema.xml before running the example  "
        },
        {
            "author": "Kelly Kagen",
            "id": "comment-14990557",
            "date": "2015-11-04T22:16:34+0000",
            "content": " Thank you for the note and it worked this time with defined fields in schema.xml.\n\nShould it have worked for dynamic fields, as these too defined in the schema? FYI, it didn't work in my case and works only with fully defined (static) fields. "
        },
        {
            "author": "Mikhail Khludnev",
            "id": "comment-14991275",
            "date": "2015-11-05T07:43:50+0000",
            "content": "this what happen to me. I raised SOLR-8240, please let me know what you think about.  "
        },
        {
            "author": "Noble Paul",
            "id": "comment-14998103",
            "date": "2015-11-10T07:32:37+0000",
            "content": "yes it could work w/ dynamic fields if your field names match the dynamic field pattern. \n\neg:\n\n\nf=first_s:/firstName\n\n "
        },
        {
            "author": "sriram vaithianathan",
            "id": "comment-15298623",
            "date": "2016-05-24T17:59:35+0000",
            "content": "Hi,\n\nCan you please let me know if such a feature is available in importing a Json from mysql? I have given more info here: http://lucene.472066.n3.nabble.com/Solr-mysql-Json-import-td4278686.html\n\nThanks,\nSriram "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-15298681",
            "date": "2016-05-24T18:32:17+0000",
            "content": "Please don't comment on closed JIRA tickets, they're likely to have very few eyes-on.\n\nThis kind of question is usually best brought up on the Solr user's list. "
        },
        {
            "author": "sriram vaithianathan",
            "id": "comment-15298744",
            "date": "2016-05-24T19:16:37+0000",
            "content": "Sure Erick. I actually raised in the Solr user group. Since I didn't get reply regarding that, I thought of posting in the corresponding ticket. If you have additional info, kindly add to my post. "
        }
    ]
}