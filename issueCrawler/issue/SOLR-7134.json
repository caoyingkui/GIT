{
    "id": "SOLR-7134",
    "title": "Replication can still cause index corruption.",
    "details": {
        "components": [
            "replication (java)"
        ],
        "type": "Bug",
        "labels": "",
        "fix_versions": [
            "5.1",
            "6.0"
        ],
        "affect_versions": "None",
        "status": "Closed",
        "resolution": "Fixed",
        "priority": "Critical"
    },
    "description": "While we have plugged most of these holes, there appears to be another that is fairly rare.\n\nI've seen it play out a couple ways in tests, but it looks like part of the problem is that even if we decide we need a file and download it, we don't care if we then cannot move it into place if it already exists.\n\nI'm working with a fix that does two things:\n\n\tFail a replication attempt if we cannot move a file into place because it already exists.\n\tIf a replication attempt during recovery fails, on the next attempt force a full replication to a new directory.",
    "attachments": {
        "SOLR-7134.patch": "https://issues.apache.org/jira/secure/attachment/12700521/SOLR-7134.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2015-02-21T19:49:35+0000",
            "author": "Mark Miller",
            "content": "This seems to be working well.\n\nWhile looking into chaosmonkey test fails, I've also found another issue I'll file a JIRA for - we wait for 2 seconds in RecoveryStrategy to make sure any updates that saw the old cloudstate are done - that doesn't appear like it's enough in some cases. I'm trying with 5 seconds. ",
            "id": "comment-14330408"
        },
        {
            "date": "2015-02-21T19:59:53+0000",
            "author": "Mark Miller",
            "content": "I've also found another issue\n\nI think raising the time is a good start, but this is a hard problem to solve as nicely as I'd like - what if you get a long stop the world gc pause at the wrong time? ",
            "id": "comment-14330413"
        },
        {
            "date": "2015-02-22T17:24:18+0000",
            "author": "Mark Miller",
            "content": "I've raised SOLR-7141 for this other issue. ",
            "id": "comment-14332260"
        },
        {
            "date": "2015-02-24T16:53:01+0000",
            "author": "Mark Miller",
            "content": "First patch. Includes SOLR-7141.\n\nI've been mostly testing this on our Cloudera search branch so far (4.4 with lots of backports, especially around SolrCloud). It has resolved all of the most worrisome trouble spots I could find with HdfsChaosMonkeySafeLeader with thousands and thousands of runs so far. ",
            "id": "comment-14335079"
        },
        {
            "date": "2015-02-25T17:41:52+0000",
            "author": "Mark Miller",
            "content": "New patch. I think this is about ready. ",
            "id": "comment-14336831"
        },
        {
            "date": "2015-02-25T23:09:37+0000",
            "author": "Mike Drob",
            "content": "RealTimeGetComponent.java\n+        } catch (Exception e) {\n+          throw new SolrException(ErrorCode.SERVER_ERROR, null, e);\n+        }\n\n\nIs it ok to kill the whole operation from inside of a debug block? Maybe just debug log that we couldn't get correct debug logging for some reason (log exception too).\n\nHdfsTestUtil.java\n+      try {\n+        dfsCluster.shutdown();\n+      } catch (Error e) {\n+        log.warn(\"Exception shutting down dfsCluster\", e);\n+      }\n\n\nIs this related, or just incidental test cleanup?\n\nStopableIndexingThread.java\n-  public StopableIndexingThread(SolrClient controlClient, SolrClient cloudClient, String id, boolean doDeletes, int numCycles) {\n\n\nNo reason to remove this constructor, I think.\n\nChaosMonkeySafeLeaderTest.java\n+    if (!pauseBetweenUpdates) {\n+      maxUpdates = 10000 + random().nextInt(1000);\n+    } else {\n+      maxUpdates = 15000;\n+    }\n\n\nWhy is there a difference?\n\nSnapPuller.java\n+          LOG.info(\"Reloading SolrCore\");\n\n\nPossibly worth logging which core? ",
            "id": "comment-14337423"
        },
        {
            "date": "2015-02-26T00:27:35+0000",
            "author": "Mark Miller",
            "content": "Is it ok to kill the whole operation from inside of a debug block? \n\nFrom my perspective I'd rather that as I'm more likely to notice there is an issue. Probably nicer for the end user to chug along though.\n\nIs this related, or just incidental test cleanup?\n\nRarely, shutting down hdfs can throw an exception - in some cases because it cannot find a class it wants, in other cases a null pointer exception - starting and stopping hdfs test issues are outside of what we are testing though - it shouldn't randomly fail our chaosmonkey tests.\n\nNo reason to remove this constructor, I think.\n\nI'd rather force devs to pay attention to the other params they use than offer more constructors here. \n\nWhy is there a difference?\n\nTests can last much too long if when we have no pauses between updates and we allow too many updates. When there are pauses, its not so bad, but the pauses can be so short (it's random), we still want to have some upper limit. This is probably a result of log replay not being able to keep up with updates coming.\n\nPossibly worth logging which core?\n\nIt's always worth doing this everywhere, but since we do it so little already (except when you use our special test logger, which tries to figure it out), I've been waiting for a more holistic fix rather doing ad hoc fixes. No real pain adding it here though. ",
            "id": "comment-14337561"
        },
        {
            "date": "2015-02-26T00:38:01+0000",
            "author": "Mark Miller",
            "content": "New patch that changes all of the solrcloud_debug sections to only debug log caught exceptions, adds the core name to the reload log line, and adds a note about ignoring rare hdfs shutdown issues. ",
            "id": "comment-14337579"
        },
        {
            "date": "2015-02-26T02:50:15+0000",
            "author": "Mike Drob",
            "content": "Tests can last much too long if when we have no pauses between updates and we allow too many updates. When there are pauses, its not so bad, but the pauses can be so short (it's random), we still want to have some upper limit. This is probably a result of log replay not being able to keep up with updates coming.\nIt just doesn't look like there is an appreciable difference between [10000,11000) and [15000]. Is the supposition here that the pauses slow things down enough that we want to raise how many we do?\n\n+1 on the rest. ",
            "id": "comment-14337757"
        },
        {
            "date": "2015-02-26T07:39:05+0000",
            "author": "Shalin Shekhar Mangar",
            "content": "Thanks Mark. Some comments on your latest patch:\n\n\n\tThe SolrCoreState.setLastReplicateIndexSuccess is not used anywhere?\n\tThe first time a recovery is requested, it will always force replication because SolrCoreState.getLastReplicateIndexSuccess will return false\n\tA replication failure because of connect exception or timeout etc shouldn't necessarily force a full replication but it looks like it will in this patch\n\tThe SnapPuller.cleanup method releases tmpIndexDir even if deleteTmpIdxDir=false.\n\n ",
            "id": "comment-14338052"
        },
        {
            "date": "2015-02-26T14:00:30+0000",
            "author": "Mark Miller",
            "content": "It just doesn't look like there is an appreciable difference between [10000,11000) and [15000]\n\nWhoops - with no pause it should be 1000+ not 10000+. ",
            "id": "comment-14338406"
        },
        {
            "date": "2015-02-26T14:10:55+0000",
            "author": "Mark Miller",
            "content": "Thanks shalin.\n\n1,2\n\nWhoops - lost these in the refactoring for the new patch.\n\n3\n\nYup. There are already so many bugs when trying to replicate partially into an index, I don't think it's currently worth trying to distinguish here yet. We need to back off to something safer and more conservative until we can have greater confidence in our tests catching more more easily. Right now they are not catching tons of horrible stuff and rather than introduce more bugs trying to be careful about when we try a full rep, I'd rather start very conservative - one chance at partial rep, then do the safe thing.\n\n4\n\nIll look closer, but that's the same code that currently there. ",
            "id": "comment-14338420"
        },
        {
            "date": "2015-02-26T14:16:11+0000",
            "author": "Mark Miller",
            "content": "New patch that address' Mike's test comment and Shalin's comment 1&2.\n\n4 is not an issue - the release is for reference counting, hasn't been changed, and should remain as is. ",
            "id": "comment-14338424"
        },
        {
            "date": "2015-02-26T14:23:03+0000",
            "author": "Mark Miller",
            "content": "One more - moves the set of last replication success into the cleanup method so it always set. ",
            "id": "comment-14338441"
        },
        {
            "date": "2015-02-26T14:32:42+0000",
            "author": "Mark Miller",
            "content": "A fair amount of flux since I've 'test beasted' this work - I'll spend some time doing that with the latest patch this morning.\n\nHdfsChaosMonkeySafeLeader test has been better at catching a lot of these issues than ChaosMonkeySafeLeader test for some reason. ",
            "id": "comment-14338462"
        },
        {
            "date": "2015-03-24T03:19:39+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1668779 from Mark Miller in branch 'dev/trunk'\n[ https://svn.apache.org/r1668779 ]\n\nSOLR-7134: Replication can still cause index corruption. ",
            "id": "comment-14377198"
        },
        {
            "date": "2015-03-27T11:56:49+0000",
            "author": "Ramkumar Aiyengar",
            "content": "Mark, do you plan to merge this to branch_5x soon? I wanted to merge my commit for SOLR-7291, which I still can, but will end up causing a few conflicts for you when you merge \u2013 hence wanted to check.. ",
            "id": "comment-14383719"
        },
        {
            "date": "2015-03-27T13:55:57+0000",
            "author": "Mark Miller",
            "content": "Yeah, thanks, give me a couple hours, I'll do it shortly. ",
            "id": "comment-14383858"
        },
        {
            "date": "2015-03-27T14:38:27+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1669600 from Mark Miller in branch 'dev/branches/branch_5x'\n[ https://svn.apache.org/r1669600 ]\n\nSOLR-7134: Replication can still cause index corruption. ",
            "id": "comment-14383928"
        },
        {
            "date": "2015-04-15T00:30:04+0000",
            "author": "Timothy Potter",
            "content": "Bulk close after 5.1 release ",
            "id": "comment-14495208"
        }
    ]
}