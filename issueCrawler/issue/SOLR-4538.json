{
    "id": "SOLR-4538",
    "title": "DateMath strings truncated to 32 chars by lucene qparser in simple term queries",
    "details": {
        "affect_versions": "4.1",
        "status": "Closed",
        "fix_versions": [
            "4.3"
        ],
        "components": [
            "search"
        ],
        "type": "Bug",
        "priority": "Major",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "When using the \"lucene\" QParser, term queries on date fields cause the field value portion of the query clause to be truncated at 32 characters. This can cause visible errors about invalid date math expressions, or may result in silently returning incorrect results if the truncation results in a valid (but incomplete) date math expression.\n\nFor example...\n\n\nExample...\n\nlast_modified:\"2013-03-08T00:46:15Z/DAY+6MONTHS+3DAYS\"\n...truncates to...\nlast_modified:\"2013-03-08T00:46:15Z/DAY+6MONTHS\"\n(silently incorrect)\n\nfoo_tdt:\"2013-03-10T08:00:00.1Z/MINUTE+6MONTHS\"\n...truncates to...\nfoo_tdt:2013-03-10T08:00:00.1Z/MINUTE+6M\n(\"Invalid Date Math String\" error msg)\n\n\n\nThis problem does not affect range queries, or queries using either the term or field qparsers...\n\n\nExamples that work fine even though the math is longer then 32 chars...\n\nfoo_tdt:[2013-03-10T08:00:00.1Z/MINUTE+6MONTHS TO 2013-03-10T08:00:00.1Z/MINUTE+6MONTHS]\n\n{!term f=bday}1976-07-04T12:08:56.45Z/SECOND+235MILLIS\nfoo_tdt:\"2013-03-10T08:00:00.1Z/MINUTE+6MONTHS\"\n\n\n\nOriginal problem report\nDateMathParser doesn't work correctly.\nhttp://lucene.apache.org/solr/4_1_0/solr-core/org/apache/solr/util/DateMathParser.html\n\nfq=last_modified:\"2013-03-08T00:46:15Z/DAY+6MONTHS+3DAYS\"\n\nexpected; last_modified:2013-09-11T00:00:00Z\nactual; last_modified:2013-09-08T00:00:00Z",
    "attachments": {
        "SOLR-4538_test.patch": "https://issues.apache.org/jira/secure/attachment/12572823/SOLR-4538_test.patch",
        "SOLR-4538.patch": "https://issues.apache.org/jira/secure/attachment/12572838/SOLR-4538.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Hoss Man",
            "id": "comment-13596773",
            "date": "2013-03-08T03:46:23+0000",
            "content": "Weird.  \n\nThis appears to be a query parsing issue, not a DateMathParser issue.\n\nWorks...\n\n\nhttp://localhost:8983/solr/select?q={!field%20f=foo_dt}2013-03-08T00:46:15Z/DAY%2B6MONTHS%2B3DAYS&debug=query\n--> <str name=\"parsedquery\">foo_dt:2013-09-11T00:00:00Z</str>\n\nhttp://localhost:8983/solr/select?q={!term%20f=foo_dt}2013-03-08T00:46:15Z/DAY%2B6MONTHS%2B3DAYS&debug=query\n--> <str name=\"parsedquery\">foo_dt:2013-09-11T00:00:00Z</str>\n\n\nhttp://localhost:8983/solr/select?q=*:*&rows=0&debug=query&facet=true&facet.range=foo_dt&facet.range.start=2013-03-08T00:46:15Z/DAY%2B6MONTHS%2B3DAYS&facet.range.end=2013-03-08T00:46:15Z/DAY%2B6MONTHS%2B3DAYS&facet.range.gap=%2B1DAY\n--> <date name=\"start\">2013-09-11T00:00:00Z</date>\n--> <date name=\"end\">2013-09-11T00:00:00Z</date>\n\n\n\nFails...\n\n\nhttp://localhost:8983/solr/select?q=foo_dt:2013-03-08T00\\:46\\:15Z/DAY%2B6MONTHS%2B3DAYS&debug=query\n--> <str name=\"parsedquery\">foo_dt:2013-09-08T00:00:00Z</str>\n\nhttp://localhost:8983/solr/select?q=foo_dt:%222013-03-08T00:46:15Z/DAY%2B6MONTHS%2B3DAYS%22&debug=query\n--> <str name=\"parsedquery\">foo_dt:2013-09-08T00:00:00Z</str>\n\n\n\n(all URLs using Solr 4.1.0 with example configs) "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13597513",
            "date": "2013-03-08T20:19:30+0000",
            "content": "This is so weird.  Somehow the query parser is deciding to ignore the last N chars of the string, where N can vary depending on the string.  in the examples posted to this issue so far, it just so happens that N winds up being the exact length of the last clause in the math, but in other cases you'll get an invalid date math expression which causes an error..\n\n\nhttp://localhost:8983/solr/select?q=foo_tdt:%222013-03-10T08:00:00Z/MONTH%2B6MONTHS%22\nInvalid Date Math String:'2013-03-10T08:00:00Z/MONTH+6MONT'\n\nhttp://localhost:8983/solr/select?q=foooooo_tdt:%222013-03-10T08:00:00Z/MONTH%2B6MONTHS%22\nInvalid Date Math String:'2013-03-10T08:00:00Z/MONTH+6MONT'\n\nhttp://localhost:8983/solr/select?debug=query&q=foo_tdt:2013-03-10T08\\:00\\:00.1Z/MONTH%2B6MONTHS%2B1DAY\nInvalid Date Math String:'2013-03-10T08:00:00.1Z/MONTH+6MO'\n\nhttp://localhost:8983/solr/select?debug=query&q=foo_tdt:2013-03-10T08\\:00\\:00.123Z/MONTH%2B6MONTHS%2B1DAY\nInvalid Date Math String:'2013-03-10T08:00:00.123Z/MONTH+6'\n\nhttp://localhost:8983/solr/select?debug=query&q=foo_tdt:%222013-03-10T08:00:00Z/MINUTE%2B6MONTHS%22\nInvalid Date Math String:'2013-03-10T08:00:00Z/MINUTE+6MON'\n\nhttp://localhost:8983/solr/select?debug=query&q=foo_tdt:%222013-03-10T08:00:00.1Z/MINUTE%2B6MONTHS%22\nInvalid Date Math String:'2013-03-10T08:00:00.1Z/MINUTE+6M'\n\n\n\n(all URLs using Solr 4.1.0 with example configs) "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13597534",
            "date": "2013-03-08T20:41:53+0000",
            "content": "still no idea where the problem is, but here's a patch with tests showing off some of hte various problems "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13597546",
            "date": "2013-03-08T20:50:16+0000",
            "content": "I do know at this point that the difference is due to the query parser electing to use newFieldQuery() (which goes through the analyzer) rather than FieldType.getFieldQuery().\nNot yet sure what's the issue with the analyzer though. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13597603",
            "date": "2013-03-08T21:47:55+0000",
            "content": "Here's a patch that should fix the issue.  The TrieTokenizer previously assumed a max buffer length of 32 chars.  I just changed it to 128 for date fields. "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13597794",
            "date": "2013-03-09T01:53:43+0000",
            "content": "I just changed it to 128 for date fields.\n\nI don't like the idea of kicking the can from 32 chars to 128 chars ... particularly since we've already seen from the original report of this issue how simple truncation can lead to silently incorrect results instead of any clear and obvious error message.\n\nit seems simple enough to just grow the buffer if the input is long then expected \u2013 it doesn't add any overhead to the common case of \"normal\" date (math) strings.\n\nNew patch includes:\n\n\n\tmy previous tests\n\tyonik's test\n\tyonik's change to default the buffer size to 128 if it's a DATE field\n\ta change to grow the buffer if it's not long enough\n\ta test demonstrating date math strings longer then 128 chars\n\n "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13597810",
            "date": "2013-03-09T02:16:15+0000",
            "content": "updated summary & description know that hte scope & root issue is known. "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-13599066",
            "date": "2013-03-11T18:03:54+0000",
            "content": "Hoss: The term attribute is misused in the patch (as it is populated in ctor/reset()). It is also shared with the inner NumericTokenStream, which makes me nervous in combination with your changes. I just want to be sure, that the termattribute's contents are not used after thee ctor finishes, so incrementToken() can do what it wants with the attribute.\n\nYou should maybe add a comment or use a separate growable instance like StringBuilder to get the chars and not misuse the term attribute.\n\nEDIT: The patch is fine, it uses a completely private term attribute instance, just to have a growable \"charsref-like\" instance. I would still prefer to use a StringBuilder for that, which can also be reset to zero length  "
        },
        {
            "author": "Commit Tag Bot",
            "id": "comment-13599083",
            "date": "2013-03-11T18:16:31+0000",
            "content": "[trunk commit] Chris M. Hostetter\nhttp://svn.apache.org/viewvc?view=revision&revision=1455269\n\nSOLR-4538: Date Math expressions were being truncated to 32 characters when used in field:value queries in the lucene QParser "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13599370",
            "date": "2013-03-11T21:55:11+0000",
            "content": "Committed revision 1455269.\nCommitted revision 1455348.\nh "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-13599375",
            "date": "2013-03-11T21:58:46+0000",
            "content": "Thanks, all is fine! Although I don't like the pattern-misuse of CharTermAttribute, I am fine with the fix. "
        },
        {
            "author": "Commit Tag Bot",
            "id": "comment-13599384",
            "date": "2013-03-11T22:04:22+0000",
            "content": "[branch_4x commit] Chris M. Hostetter\nhttp://svn.apache.org/viewvc?view=revision&revision=1455348\n\nSOLR-4538: Date Math expressions were being truncated to 32 characters when used in field:value queries in the lucene QParser (merge r1455269) "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13599389",
            "date": "2013-03-11T22:09:24+0000",
            "content": "Although I don't like the pattern-misuse of CharTermAttribute\n\nas mentioned in IRC: the patch initially started trying to be consistent with how KeywordTokenizer works, but since NumericTokenStream doesn't support CharTermAttribute i made it private instead of using addAttribute().\n\nIf anyone feels strongly about changing the implementation to not using CharTermAttributeImpl (and replace with StringBuilder, io-utils reader2String, whatever..) feel free, but i just choose to leave CharTermAttributeImpl in here because: a) i'd already written the code & committed it to trunk before i even saw uwe's comment; b) it keeps the buffer resizing abstracted away out of the tokenizer and consistent with the behaviour of other tokenizers. "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-13653750",
            "date": "2013-05-10T10:32:52+0000",
            "content": "Closed after release. "
        }
    ]
}