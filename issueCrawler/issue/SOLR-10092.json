{
    "id": "SOLR-10092",
    "title": "HDFS: AutoAddReplica fails",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [
            "hdfs"
        ],
        "type": "Bug",
        "fix_versions": [],
        "affect_versions": "6.3",
        "resolution": "Unresolved",
        "status": "Open"
    },
    "description": "OverseerAutoReplicaFailoverThread fails to create replacement core with this exception:\n\no.a.s.c.OverseerAutoReplicaFailoverThread Exception trying to create new replica on http://...:9000/solr:org.apache.solr.client.solrj.impl.HttpSolrClient$RemoteSolrException: Error from server at http://...:9000/solr: Error CREATEing SolrCore 'test2.collection-09_shard1_replica1': Unable to create core [test2.collection-09_shard1_replica1] Caused by: No shard id for CoreDescriptor[name=test2.collection-09_shard1_replica1;instanceDir=/var/opt/solr/test2.collection-09_shard1_replica1]\n    at org.apache.solr.client.solrj.impl.HttpSolrClient.executeMethod(HttpSolrClient.java:593)\n    at org.apache.solr.client.solrj.impl.HttpSolrClient.request(HttpSolrClient.java:262)\n    at org.apache.solr.client.solrj.impl.HttpSolrClient.request(HttpSolrClient.java:251)\n    at org.apache.solr.client.solrj.SolrClient.request(SolrClient.java:1219)\n    at org.apache.solr.cloud.OverseerAutoReplicaFailoverThread.createSolrCore(OverseerAutoReplicaFailoverThread.java:456)\n    at org.apache.solr.cloud.OverseerAutoReplicaFailoverThread.lambda$addReplica$0(OverseerAutoReplicaFailoverThread.java:251)\n    at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n    at org.apache.solr.common.util.ExecutorUtil$MDCAwareThreadPoolExecutor.lambda$execute$0(ExecutorUtil.java:229)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at java.lang.Thread.run(Thread.java:745) \n\nalso see this mail thread about the issue: https://lists.apache.org/thread.html/%3CCAA70BoWyzbvQuJTyzaG4Kx1tj0Djgcm+MV=x_HoAc1e6CSE7ww@mail.gmail.com%3E",
    "attachments": {
        "SOLR-10092.patch": "https://issues.apache.org/jira/secure/attachment/12853806/SOLR-10092.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2017-02-21T21:06:30+0000",
            "content": "With this patch the automatic replica fail over worked for me on Solr 6.3. ",
            "author": "Hendrik Haddorp",
            "id": "comment-15876715"
        },
        {
            "date": "2017-02-22T21:22:59+0000",
            "content": "Mark Miller - Thoughts on this? See you were last in here. ",
            "author": "Kevin Risden",
            "id": "comment-15879262"
        },
        {
            "date": "2017-02-22T21:24:14+0000",
            "content": "Mike Drob or Hrishikesh Gadre - maybe you have thoughts as well since its HDFS related? ",
            "author": "Kevin Risden",
            "id": "comment-15879264"
        },
        {
            "date": "2017-02-22T21:58:55+0000",
            "content": "I don't think local filesystem support was ever actually done for this feature? Originally it still had to be a shared filesystem. ",
            "author": "Mark Miller",
            "id": "comment-15879325"
        },
        {
            "date": "2017-02-22T23:17:01+0000",
            "content": "Ah good point Mark Miller.\n\nHendrik Haddorp - Is this collection actually on HDFS? The stack trace shows the instance dir is local and not on HDFS?\n\n\ninstanceDir=/var/opt/solr/test2.collection-09_shard1_replica1 ",
            "author": "Kevin Risden",
            "id": "comment-15879447"
        },
        {
            "date": "2017-02-23T07:46:18+0000",
            "content": "For a setup using a local filesystem I did not see this code to be triggered at all. But I was just trying to reproduce this on an unpatched installation and for some reason it looks like it worked now as well. So am going to recheck again. From what I saw in the code it looked like the code required the shard id/name to be set, which is also what the exception said, but the OverseerAutoReplicaFailoverThread is not doing that.\n\nRegarding the instance dir. I'm seeing this in the logs:\n2017-02-23 06:43:13.968 INFO  (qtp1224347463-12) [c:test.test s:shard1 r:core_node3 x:test.test_shard1_replica1] o.a.s.c.SolrCore [[test.test_shard1_replica1] ] Opening new SolrCore at [/var/opt/solr/test.test_shard1_replica1], dataDir=[hdfs://my-hdfs-namenode:8000/solr/test.test/core_node3/data/]\nSo even for HDFS there is local information. The folder only contains a core.properties file. Seems to contain everything required to determine the replica. Not sure why this is not taken from ZooKeeper though. ",
            "author": "Hendrik Haddorp",
            "id": "comment-15880065"
        },
        {
            "date": "2017-02-23T13:31:44+0000",
            "content": "ok, tested again. plain solr 6.3 works in the default legacyCloud mode. but once I set legacyCloud=false it fails with the exception above.\nafter some more testing I do now actually have a different problem. I do not get the exception from above by the following message and no fail over happens:\n2017-02-23 13:29:07.876 WARN  (OverseerHdfsCoreFailoverThread-25449593782534174-search-integration.rtp.raleigh.ibm.com:9005_solr-n_0000000015) [   ] o.a.s.c.OverseerAutoReplicaFailoverThread Could not find dataDir or ulogDir in cluster state.\n\nsorry, all quite inconsistent at the moment. ",
            "author": "Hendrik Haddorp",
            "id": "comment-15880421"
        },
        {
            "date": "2017-02-23T15:31:09+0000",
            "content": "Sorry for the spam looks like I tested my patch wrong last time. Solr 6.3 on HDFS with legacyMode=false fails with the stated exception. But just using my patch does not fix that. The exception is gone but then I get:\norg.apache.solr.common.SolrException: coreNodeName core_node1 exists, but does not match expected node or core name: DocCollection(test.test3//collections/test.test3/state.json/50)={\n....\n}\n        at org.apache.solr.cloud.ZkController.checkStateInZk(ZkController.java:1562)\n\tat org.apache.solr.cloud.ZkController.preRegister(ZkController.java:1488)\n\tat org.apache.solr.core.CoreContainer.create(CoreContainer.java:837)\n\tat org.apache.solr.core.CoreContainer.create(CoreContainer.java:779) ",
            "author": "Hendrik Haddorp",
            "id": "comment-15880651"
        },
        {
            "date": "2017-02-24T09:48:56+0000",
            "content": "This new patch works with legacyCloud=false correctly for me but I must admit that I do not fully understand what the code tries to do.\n\nThe flow in Solr is like this:\n1) OverseerAutoReplicaFailoverThread decides to create a new core to replace a failed one\n2) CoreContainer.create(String coreName, Path instancePath, Map<String, String> parameters, boolean newCollection) gets invoked\n3) CoreContainer.create(CoreDescriptor dcore, boolean publishState, boolean newCollection)\n4) ZkController.preRegister\n5) ZkController.checkStateInZk\n\nIf the legacyCloud mode is on nothing at all happens in step 5 and one check in step 2 is also not made.\n\nWhen legacyCloud mode is on things work but if it is off the code fails in step 5 because no shardId is set in the create core call done from the Overseer. This I fixed in my first patch so that the shared id/name gets passed into the core creation. The code in step 5 does check if the core creation data matches to what is stored in ZK. This can however not work in this case as the \"baseUrl\" will of course not match as we are trying to replace the core with a new one. So I now removed the baseUrl comparison and everything seems to work fine for with legacyClound on and off. Given that I don't really understand what check is done here and why that is only done when legacyCloud=false my fix might also not be correct and should be done different. But my patched version works at least  ",
            "author": "Hendrik Haddorp",
            "id": "comment-15882341"
        }
    ]
}