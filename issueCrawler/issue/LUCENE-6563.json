{
    "id": "LUCENE-6563",
    "title": "MockFileSystemTestCase.testURI should be improved to handle cases where OS/JVM cannot create non-ASCII filenames",
    "details": {
        "resolution": "Fixed",
        "affect_versions": "None",
        "components": [],
        "labels": "",
        "fix_versions": [
            "5.3",
            "6.0"
        ],
        "priority": "Minor",
        "status": "Closed",
        "type": "Wish"
    },
    "description": "ant test -Dtestcase=TestVerboseFS -Dtests.method=testURI -Dtests.file.encoding=UTF-8 fails (for example) with 'Oracle Corporation 1.8.0_45 (64-bit)' when the default sun.jnu.encoding system property is (for example) ANSI_X3.4-1968\n\n[details to follow]",
    "attachments": {
        "LUCENE-6563.patch": "https://issues.apache.org/jira/secure/attachment/12743919/LUCENE-6563.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "id": "comment-14584005",
            "author": "ASF GitHub Bot",
            "date": "2015-06-12T20:18:17+0000",
            "content": "GitHub user cpoerschke opened a pull request:\n\n    https://github.com/apache/lucene-solr/pull/152\n\n    LUCENE-6563: sun.jnu.encoding to match file.encoding system property\n\n    for https://issues.apache.org/jira/i#browse/LUCENE-6563\n\nYou can merge this pull request into a Git repository by running:\n\n    $ git pull https://github.com/bloomberg/lucene-solr trunk-sun-jnu-encoding\n\nAlternatively you can review and apply these changes as the patch at:\n\n    https://github.com/apache/lucene-solr/pull/152.patch\n\nTo close this pull request, make a commit to your master/trunk branch\nwith (at least) the following in the commit message:\n\n    This closes #152\n\n\ncommit 58baae43edff917d46d1799d0e24b7f7ab828565\nAuthor: Christine Poerschke <cpoerschke@bloomberg.net>\nDate:   2015-06-12T19:00:25Z\n\n    LUCENE-????: changed common-build.xml to ensure sun.jnu.encoding matches file.encoding system property\n\n    changes:\n\n\tadding -Dtests.sun.jnu.encoding to common-build.xml (it is to take the same value as -Dtests.file.encoding)\n\tadd to RunListenerPrintReproduceInfo.java (for illustration purposes only) the sun.jnu.encoding system property\n\n\n\n    background:\n\n\tant test -Dtestcase=TestVerboseFS -Dtests.method=testURI -Dtests.file.encoding=UTF-8\n      fails (for example) with 'Oracle Corporation 1.8.0_45 (64-bit)' when the\n      default sun.jnu.encoding system property is (for example) ANSI_X3.4-1968\n\n\n\n    related links/tickets:\n\n\thttps://netbeans.org/bugzilla/show_bug.cgi?id=246438#c24\n\thttp://happygiraffe.net/blog/2009/09/24/java-platform-encoding/\n\thttp://bugs.java.com/bugdatabase/view_bug.do?bug_id=8003228\n\n\n\n    test failure details:\n\n    NOTE: reproduce with: ant test  -Dtestcase=TestVerboseFS -Dtests.method=testURI -Dtests.seed=31F5C6E85DAF4E6B -Dtests.slow=true -Dtests.locale=no -Dtests.timezone=Australia/Melbourne -Dtests.asserts=true -Dtests.file.encoding=UTF-8\n       0.12s | TestVerboseFS.testURI <<<\n    Throwable #1: java.nio.file.InvalidPathException: Malformed input or input contains unmappable characters: ??\n            at __randomizedtesting.SeedInfo.seed([31F5C6E85DAF4E6B:B847BD4395B0145A]:0)\n            at sun.nio.fs.UnixPath.encode(UnixPath.java:147)\n            at sun.nio.fs.UnixPath.<init>(UnixPath.java:71)\n            at sun.nio.fs.UnixFileSystem.getPath(UnixFileSystem.java:281)\n            at sun.nio.fs.AbstractPath.resolve(AbstractPath.java:53)\n            at org.apache.lucene.mockfile.FilterPath.resolve(FilterPath.java:156)\n            at org.apache.lucene.mockfile.MockFileSystemTestCase.testURI(MockFileSystemTestCase.java:71)\n            at java.lang.Thread.run(Thread.java:745)\n\n    test case code snippet:\n\n    MockFileSystemTestCase.testURI\n    ...\n    69 assumeTrue(Charset.defaultCharset().name() + \" can't encode chinese\",\n    70            Charset.defaultCharset().newEncoder().canEncode(\"\u00e4\u00b8\u00ad\u00e5<9B>1/2\"));\n    71 Path f3 = dir.resolve(\"\u00e4\u00b8\u00ad\u00e5<9B>1/2\");\n    ...\n\n "
        },
        {
            "id": "comment-14613438",
            "author": "Ramkumar Aiyengar",
            "date": "2015-07-03T20:15:46+0000",
            "content": "Uwe Schindler, Dawid Weiss, any opinions on this? I can pick this up if this looks good.. "
        },
        {
            "id": "comment-14613499",
            "author": "Dawid Weiss",
            "date": "2015-07-03T22:55:38+0000",
            "content": "I would like to see a reproducible failure first. This is an internal JVM's property \u2013 why is it causing problems? "
        },
        {
            "id": "comment-14613502",
            "author": "Ramkumar Aiyengar",
            "date": "2015-07-03T23:05:09+0000",
            "content": "This reproduceably fails for me..\n\nLANG=C ant test  -Dtestcase=TestVerboseFS -Dtests.method=testURI -Dtests.seed=31F5C6E85DAF4E6B -Dtests.slow=true -Dtests.locale=no -Dtests.timezone=Australia/Melbourne -Dtests.asserts=true -Dtests.file.encoding=UTF-8\n\nWith my default locale (LANG=en_GB.UTF-8), things work fine..\n\nLANG=en_GB causes the test to fail as well.. "
        },
        {
            "id": "comment-14614652",
            "author": "Dawid Weiss",
            "date": "2015-07-06T07:39:29+0000",
            "content": "This is indeed an interesting one. \n\nsun.jnu.encoding is a very deep, internal, JVM-specific and largely undocumented property that controls how unicode characters are mapped into bytes to encode file names. Looking at OpenJDK code I think it dates back to times when most filesystem-related APIs were byte-based (not unicode-based), so such a conversion was required to somehow translate Java's default string representation into operating system's defaults.\n\nOpenJDK tries to figure it out internally (on Windows and on Unix systems) with sun.jnu.encoding functioning as an override.\n\nI don't think the patch should be incorporated though. This is an attempt to dodge an odd behavior of the JVM itself; if you specify LANG=C then this means that the JVM won't be able to write any filenames with non-ASCII characters. The test is failing and I think it should be failing \u2013 it fails exactly at the check it was supposed to do. We shouldn't be trying to improve the defaults.\n\nI think there are two solutions \u2013 either we agree that all Lucene-related filesystem operations use only ASCII (and this can be verified at mock filesystem level), then the test can be corrected as well. Or we agree that filesystems with crippled unicode support are not supported. Then the test should keep failing (with a better message perhaps). "
        },
        {
            "id": "comment-14614684",
            "author": "Uwe Schindler",
            "date": "2015-07-06T08:07:10+0000",
            "content": "I think there are two solutions \u2013 either we agree that all Lucene-related filesystem operations use only ASCII (and this can be verified at mock filesystem level), then the test can be corrected as well. Or we agree that filesystems with crippled unicode support are not supported. Then the test should keep failing (with a better message perhaps).\n\n\n\t\"and this can be verified at mock filesystem level\": we should only verify this below Lucene directories (so we dont create new filenames for segments in non-ASCII), but we should not assume that e.g. the test directory or the directory where a user has placed the index is ASCII-only. E.g. on a Windows system with Umlauts in User name you have both a whitespace and a Umlaut in the path name of the home directory.\n\n\n\n\n\tI think the test should keep failing in this configuration. This is something that the test has setup in a wrong way.\n\n\n\nWe should never ever change the sun.jnu.encoding property, because this may produce broken filenames on some system (that you cannot even delete later from command line...). "
        },
        {
            "id": "comment-14614691",
            "author": "Dawid Weiss",
            "date": "2015-07-06T08:17:58+0000",
            "content": "> but we should not assume that e.g. the test directory or the directory where a user has placed the index is ASCII-only.\n\nYeah, I agree. I think this test should keep failing. When somebody has LANG=C and this causes the JVM not to be able to properly encode certain filenames then this is a problem of the test environment (and arguably a JVM bug if the filesystem an handle unicode properly). "
        },
        {
            "id": "comment-14614693",
            "author": "Dawid Weiss",
            "date": "2015-07-06T08:19:21+0000",
            "content": "Christine Poerschke could you shed more light on the software/ hardware platform where this originally occurred? "
        },
        {
            "id": "comment-14614822",
            "author": "Christine Poerschke",
            "date": "2015-07-06T10:14:09+0000",
            "content": "Dawid Weiss and Uwe Schindler - thanks for taking a look at this.\n\nIt's consistently reproducible for -Dtests.file.encoding=UTF-8 both running on the dev machines our team usually uses and also within the jenkins instance when that runs the test suite.\n\nThe dev machines have LANG=C environment by default and junit reports Linux 2.6.32-358.11.1.el6.x86_64 amd64/Oracle Corporation 1.8.0_45 (64-bit) or Linux 2.6.32-358.41.1.el6.x86_64 amd64/Oracle Corporation 1.8.0_45 (64-bit) versions.\n\nOn the machines where the jenkins job runs, including a 'locale' step shows LANG= and junit reports Linux 2.6.18-238.1.1.el5 amd64/Oracle Corporation 1.8.0_45 (64-bit) versions. "
        },
        {
            "id": "comment-14614830",
            "author": "Uwe Schindler",
            "date": "2015-07-06T10:20:46+0000",
            "content": "Thanks.\n\nI dont see this as a bug. "
        },
        {
            "id": "comment-14614842",
            "author": "Ramkumar Aiyengar",
            "date": "2015-07-06T10:31:27+0000",
            "content": "I see why we shouldn't modify the internal prop \u2013 it sounded hacky to begin with, but I still think our tests shouldn't fail for some supported locale on a supported OS (I was able to reproduce this on the latest Ubuntu on my laptop).\n\nTo the best of my knowledge, Lucene doesn't need non-ASCII file names for itself \u2013 so if we are not able to create non-ASCII filenames to begin with, shouldn't the mock filesystem not try to use them? That way we continue to test that if the OS was able to create non-ASCII parent directories, Lucene should continue to work fine, but that shouldn't be a requirement for Lucene per se. "
        },
        {
            "id": "comment-14614861",
            "author": "Dawid Weiss",
            "date": "2015-07-06T10:55:01+0000",
            "content": "I honestly think this is a quirk/bug in the JVM... and perhaps should be reported. Setting LANG=C shouldn't be affecting how filenames are (mis)handled (and it currently does).\n\nso if we are not able to create non-ASCII filenames to begin with, shouldn't the mock filesystem not try to use them?\n\nWell, it's a good test, isn't it?  Caught the nasty thing right away... I don't have a strong opinion. I think modifying the mock filesystem to enforce ASCII-only names and them removing that non-ascii test section sounds all right. Could you provide a patch and check if it passes on your systems? "
        },
        {
            "id": "comment-14614888",
            "author": "Christine Poerschke",
            "date": "2015-07-06T11:17:30+0000",
            "content": "Sure. Will give that a go. "
        },
        {
            "id": "comment-14614939",
            "author": "Uwe Schindler",
            "date": "2015-07-06T11:59:55+0000",
            "content": "OK, I aggree.\n\nBut as I said, MockFileSystem should not validate all file name components, only those that are created by Lucene: E.g. If my checkout is named C:/Users/Uwe Schindler/tr\u00fcnk this must still work. "
        },
        {
            "id": "comment-14614944",
            "author": "Dawid Weiss",
            "date": "2015-07-06T12:02:50+0000",
            "content": "C:/Users/Uwe Schindler/tr\u00fcnk\n\nLOL. I think this should become the default for our svn as well...\n "
        },
        {
            "id": "comment-14614946",
            "author": "Robert Muir",
            "date": "2015-07-06T12:04:53+0000",
            "content": "\nBut as I said, MockFileSystem should not validate all file name components, only those that are created by Lucene\n\nThen there is no point in doing anything. So please don't add necessary confusing code.\n\nThe point of the current test logic is to throw an assumption if the system cannot encode unicode. The test just needs to be improved. "
        },
        {
            "id": "comment-14615065",
            "author": "ASF GitHub Bot",
            "date": "2015-07-06T14:10:12+0000",
            "content": "GitHub user cpoerschke opened a pull request:\n\n    https://github.com/apache/lucene-solr/pull/182\n\n    LUCENE-6563: tweak MockFileSystemTestCase.testURI assumptions\n\n    for https://issues.apache.org/jira/i#browse/LUCENE-6563\n\nYou can merge this pull request into a Git repository by running:\n\n    $ git pull https://github.com/bloomberg/lucene-solr trunk-lucene-6563\n\nAlternatively you can review and apply these changes as the patch at:\n\n    https://github.com/apache/lucene-solr/pull/182.patch\n\nTo close this pull request, make a commit to your master/trunk branch\nwith (at least) the following in the commit message:\n\n    This closes #182\n\n\ncommit 6d792bba409fe080efad30c1e03f060f3c66a039\nAuthor: Christine Poerschke <cpoerschke@bloomberg.net>\nDate:   2015-07-06T13:34:12Z\n\n    LUCENE-6563: tweak MockFileSystemTestCase.testURI assumptions\n\n\n\ttestURI itself now is only for plain ASCII file name\n\tchinese file name now is in testURIchinese\n\talso added a testURIumlaute file name case\n\timplTestURI factored out to hold the test logic itself (if resolve fails for non-ASCII file names then the toUri part of the test is skipped)\n\n\n\n "
        },
        {
            "id": "comment-14615276",
            "author": "Uwe Schindler",
            "date": "2015-07-06T16:32:42+0000",
            "content": "I like this test more. Maybe Robert Muir has a look, too. The assumeNoException is fine, but I think with that we can remove the assume for chinese - bcause its subsumed by the assumeNoException!? "
        },
        {
            "id": "comment-14615483",
            "author": "Dawid Weiss",
            "date": "2015-07-06T18:58:59+0000",
            "content": "Don't want to be picky, but Charset.defaultCharset() isn't exactly what's used for filename encoding... most of the time it will be the same thing though so I think it's still an improvement.\n\nFor the record, all of this charset-to-byte related stuff is a legacy headache... check out the interesting comments in openjdk if you're interested.\n\n                /* On windows the system locale may be different than the\n                 * user locale. This is an unsupported configuration, [...]\n\n\n "
        },
        {
            "id": "comment-14615487",
            "author": "Uwe Schindler",
            "date": "2015-07-06T19:03:52+0000",
            "content": "Don't want to be picky, but Charset.defaultCharset() isn't exactly what's used for filename encoding... most of the time it will be the same thing though so I think it's still an improvement.\n\nthis is why I said:\n\n...but I think with that we can remove the assume for chinese - bcause its subsumed by the assumeNoException!?\n\nSo I think we should just put the resolve into try/catch and if this fails, cancel test. "
        },
        {
            "id": "comment-14615488",
            "author": "Uwe Schindler",
            "date": "2015-07-06T19:04:37+0000",
            "content": "Also I think we should remove the true/false parameter. ASCII should always pass, so why add condition? "
        },
        {
            "id": "comment-14615509",
            "author": "Christine Poerschke",
            "date": "2015-07-06T19:17:26+0000",
            "content": "The boolean tryResolve flag was aiming to preserve existing logic i.e. not catching any InvalidPathException that dir.resolve(\"file1\"); might throw. Happy to remove both it and the existing Charset.defaultCharset() in favour of just try/catch-ing on the resolve. "
        },
        {
            "id": "comment-14615649",
            "author": "Uwe Schindler",
            "date": "2015-07-06T20:59:34+0000",
            "content": "Fine, thanks. Waiting for patch! "
        },
        {
            "id": "comment-14615766",
            "author": "Ramkumar Aiyengar",
            "date": "2015-07-06T22:20:41+0000",
            "content": "I honestly think this is a quirk/bug in the JVM... and perhaps should be reported. Setting LANG=C shouldn't be affecting how filenames are (mis)handled (and it currently does).\n\nI digged a bit, and it appears that Java is kind of doing the right thing given it's current API. Certain newer versions/FSs of Windows and MacOSX guarantee that all files are in UTF-16/8 respectively. Linux/Solaris etc. (aka the more traditional Unix systems) tend not to care about the encoding at all. As a matter of fact, a filename is just a sequence of bytes, it's not even a string. How that byte array is displayed comes down to the locale. This is probably why this works.\n\n\n$ LANG=C touch \u4e2d\u56fd\n\n\n\ntouch doesn't care about the input, the shell maps it into a set of UTF-8 bytes, and is stored as a filename. ls, then, in an UTF-8 locale shows the correct thing\n\n\n$ ls\nbuild.xml  ivy.xml  lib  lucene-test-framework.iml  src  \u4e2d\u56fd\n\n\n\nAnd if I try to read in the C locale, I get a bunch of unreadable chars\n\n\n$ LANG=C ls\nbuild.xml  ivy.xml  lib  lucene-test-framework.iml  src  ??????\n\n\n\nJava APIs on the other hand treats filenames as strings in all it's APIs, and as a result is forced to need an encoding even when it is using it only for I/O and not for display. As a result, it is forced to choose some encoding, and it goes with the locale.. In platforms where the filename encoding is guaranteed to be UTF-8, it goes with that \u2013 see http://bugs.java.com/bugdatabase/view_bug.do?bug_id=8003228 for MacOSX.\n\nLooks like this issue is not specific to Java \u2013 see https://bugs.python.org/issue19846 this for example. "
        },
        {
            "id": "comment-14616271",
            "author": "Dawid Weiss",
            "date": "2015-07-07T06:44:16+0000",
            "content": "As a matter of fact, a filename is just a sequence of bytes, it's not even a string. \n\nIn the end most things are just a sequence of bytes, Ramkumar  And seriously, standard C didn't have any unicode-related utilities for a looong time (because there was no unicode); strings were/are 0-byte terminated byte regions. The interpretation of which characters they constitute is a higher-level concept.\n\nLANG=C touch \u4e2d\u56fd\n\nThe question is how does the terminal know how to decode your input above into an argument (itself being a byte*)... and how did it know what you typed in (and which glyphs to pick in order to display it)... I'm guessing the terminal accepts unicode on input then if it sees C locale it  blindly passes the input bytes without any conversion at all. The unicode is very likely UTF-8, which was specifically designed to be an identity conversion coding page (so that C \"strings\" just work with it) and it just happens to be the default filesystem encoding... That's why it works, it just performs no conversion at all... \n\nIt's no magic, really. But trying to understand how and where character-to-byte(-to-glyph) conversions occur will drive you nuts because there is no consistency here. "
        },
        {
            "id": "comment-14616300",
            "author": "Ramkumar Aiyengar",
            "date": "2015-07-07T07:09:27+0000",
            "content": "My point is that the layer which stops caring about the sequence of bytes being a string is different in OSs. In MacOSX, right up to the FS understands it as UTF-8. In Linux, its at the application layer.\n\nActually in this case, my terminal emulator was still in UTF-8, so it accepted Chinese chars. Which then got passed to touch as a stream of utf-8 bytes (a simple char* to void main()), and then touch, regardless of the locale, just created a filename with those bytes as input. Similarly ls just read these bytes from the directory, and on display alone tried to interpret it using the locale. In both these cases, the interface used with the OS passed in/out bytes and nothing more. Java on the other hand uses Strings with an implicit encoding for these inputs and hence is forced to interpret these bytes even if they are not being displayed or input. "
        },
        {
            "id": "comment-14616331",
            "author": "Dawid Weiss",
            "date": "2015-07-07T07:41:05+0000",
            "content": "In MacOSX, right up to the FS understands it as UTF-8.\n\nI doubt it does anything special. Try forming an incorrect UTF-8 sequence in a C application and creating a file on disk. If it fails, it means it is interpreted as such (but I don't think it will).\n\nOr mount a FAT-32 filesystem and create some UTF-8 files in there, then re-mount it under Windows. Good luck. \n\nAs for Java, yes, the fact that the API uses UTF-16 has been a problem (or a blessing, depends how you look at it). Till this day I see ways to \"fix\" codepage conversion problems with horrible things like new String(bytesFromNetwork, \"ISO-8859-1\")... "
        },
        {
            "id": "comment-14616368",
            "author": "Christine Poerschke",
            "date": "2015-07-07T08:32:52+0000",
            "content": "patch updated. thanks. "
        },
        {
            "id": "comment-14616404",
            "author": "Uwe Schindler",
            "date": "2015-07-07T09:17:04+0000",
            "content": "Just reopening to apply that patch. "
        },
        {
            "id": "comment-14616410",
            "author": "Uwe Schindler",
            "date": "2015-07-07T09:20:07+0000",
            "content": "I like the current patch. Very clean and simple. If the Path does not resolve on the original filesystem, cancel test. "
        },
        {
            "id": "comment-14616422",
            "author": "Uwe Schindler",
            "date": "2015-07-07T09:27:26+0000",
            "content": "I attached Christine's patch. Tests pass for me, so I would like to commit this soon. Any comments from MacOSX users? "
        },
        {
            "id": "comment-14616449",
            "author": "Uwe Schindler",
            "date": "2015-07-07T10:00:54+0000",
            "content": "By the way, the chinese test now passes on windows with default (8bit) charset \"windows-1252\" (my machine), because the underlying filesystem can still encode chinese chars... SO this is an improvments, the previous assume was just wrong, because it relied on the default charset not the one used by filesystem internally. So the assumeNoException() is much better. "
        },
        {
            "id": "comment-14616475",
            "author": "Ramkumar Aiyengar",
            "date": "2015-07-07T10:22:31+0000",
            "content": "Uwe Schindler, looks like this is the original patch and not the one without the Charset assume etc.? "
        },
        {
            "id": "comment-14616492",
            "author": "Uwe Schindler",
            "date": "2015-07-07T10:35:07+0000",
            "content": "Sorry uploaded wrong patch. I HATE GIT!!! Die, GIT, die!  "
        },
        {
            "id": "comment-14616494",
            "author": "Christine Poerschke",
            "date": "2015-07-07T10:38:45+0000",
            "content": "Interesting, looks like https://github.com/apache/lucene-solr/pull/182 contains both commits (original and arg removal follow-up) but https://github.com/apache/lucene-solr/pull/182.patch still has just the original commit. "
        },
        {
            "id": "comment-14616513",
            "author": "Uwe Schindler",
            "date": "2015-07-07T10:51:06+0000",
            "content": "I had the same problem initially. I solved the whole thing by just downloading the raw file and copypaste them over mine \nI just missed to create a new patch from my subversion checkout! "
        },
        {
            "id": "comment-14616516",
            "author": "Uwe Schindler",
            "date": "2015-07-07T10:52:16+0000",
            "content": "https://patch-diff.githubusercontent.com/raw/apache/lucene-solr/pull/182.diff works better! I have no idea why this is like that but this is just horrible! "
        },
        {
            "id": "comment-14616538",
            "author": "Ramkumar Aiyengar",
            "date": "2015-07-07T11:19:06+0000",
            "content": "I think it's one patch per commit, and the patch file has multiple commits in it. git tools probably understand this multi-patch format, and may be svn doesn't.. "
        },
        {
            "id": "comment-14616542",
            "author": "Christine Poerschke",
            "date": "2015-07-07T11:26:18+0000",
            "content": "Yeah, just noticed same, very subtle! Never mind git or svn, as human reader would i wish to scroll through multi-patches?\n\n182.diff much clearer in my opinion. The ASF GitHub Bot wording mentions 182.patch but not 182.diff - is what it mentions configurable? Might a case be made for including a 182.diff link also? "
        },
        {
            "id": "comment-14616550",
            "author": "Dawid Weiss",
            "date": "2015-07-07T11:35:39+0000",
            "content": "The .diff is a (consolidated) unified diff from the branch your pull request goes into. \n\nThe .patch contains all commits (diffs for each individual commit) so that you could recreate the full history of your pull request if you wanted to do it from command-line, for example. "
        },
        {
            "id": "comment-14617599",
            "author": "ASF subversion and git services",
            "date": "2015-07-07T23:04:00+0000",
            "content": "Commit 1689768 from Uwe Schindler in branch 'dev/trunk'\n[ https://svn.apache.org/r1689768 ]\n\nLUCENE-6563: Improve MockFileSystemTestCase.testURI to check if a path can be encoded according to local filesystem requirements. Otherwise stop test execution "
        },
        {
            "id": "comment-14617603",
            "author": "ASF subversion and git services",
            "date": "2015-07-07T23:05:01+0000",
            "content": "Commit 1689769 from Uwe Schindler in branch 'dev/branches/branch_5x'\n[ https://svn.apache.org/r1689769 ]\n\nMerged revision(s) 1689768 from lucene/dev/trunk:\nLUCENE-6563: Improve MockFileSystemTestCase.testURI to check if a path can be encoded according to local filesystem requirements. Otherwise stop test execution "
        },
        {
            "id": "comment-14617606",
            "author": "Uwe Schindler",
            "date": "2015-07-07T23:05:29+0000",
            "content": "Thanks Christine! "
        },
        {
            "id": "comment-14713181",
            "author": "Shalin Shekhar Mangar",
            "date": "2015-08-26T13:06:00+0000",
            "content": "Bulk close for 5.3.0 release "
        },
        {
            "id": "comment-15094476",
            "author": "ASF GitHub Bot",
            "date": "2016-01-12T18:50:28+0000",
            "content": "Github user cpoerschke closed the pull request at:\n\n    https://github.com/apache/lucene-solr/pull/152 "
        },
        {
            "id": "comment-15094478",
            "author": "ASF GitHub Bot",
            "date": "2016-01-12T18:51:38+0000",
            "content": "Github user cpoerschke closed the pull request at:\n\n    https://github.com/apache/lucene-solr/pull/182 "
        }
    ]
}