{
    "id": "SOLR-8480",
    "title": "Progress info for TupleStream",
    "details": {
        "components": [
            "SolrJ"
        ],
        "type": "Improvement",
        "labels": "",
        "fix_versions": [],
        "affect_versions": "None",
        "status": "Open",
        "resolution": "Unresolved",
        "priority": "Major"
    },
    "description": "I suggest adding progress info for TupleStream. It can be very helpful for tracking consuming process\n\npublic abstract class TupleStream {\n   public abstract long getSize();\n   public abstract long getConsumed();\n}",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "date": "2016-01-04T17:05:21+0000",
            "author": "Jason Gerlowski",
            "content": "As a disclaimer, I'm new to the Streaming Expression API and TupleStreams in general.  So take what I say with a grain of salt.\n\nThe getConsumed() method might be do-able and useful, but I'm less sure about a getSize() method.\n\nAs I understand the idea of streaming, nothing really knows how many records are in the stream.  That's one of the main points/advantages.  The whole result set is never fetched all at once, even in the leaves of the TupleStream hierarchy.  All things are possible I suppose, but right now there's nothing that knows the size of the result-set.\n\nEven assuming that we do know the result-size of underlying searches, getSize would be pretty tricky to figure out for some decorator TupleStreams. For example, consider: unique(search(...)).  How would a UniqueStream define its size?  Even if the underlying search knows how many results there are total, that doesn't necessarily give UniqueStream any hint at how many tuples it will output.  That depends on what the actual result values returned by the search().  It can't really be known until all search-result values have been read/processed by UniqueStream.\n\nIt would be nice to have these methods, but it doesn't seem possible in the current streaming API.  Unless I'm missing something, that is.  That's definitely possible, as I'm still new to SOLR.  Did you have a particular method in mind for reporting these sort of stats? ",
            "id": "comment-15081382"
        },
        {
            "date": "2016-01-05T01:10:11+0000",
            "author": "Cao Manh Dat",
            "content": "I'm a new one too. But as Streaming API is getting more and more complicated, users may have very long running streaming job (ex : parallel update from many sources ...). So it will be necessary to have these info.\n\n\nAll things are possible I suppose, but right now there's nothing that knows the size of the result-set.\nI use this snippet to get size of SolrStream (JsonTupleStream#advanceToDocs())\n\nexpect(JSONParser.OBJECT_START);\nif (advanceToMapKey(\"numFound\", true)){\n  numFound = parser.getLong();\n}\n\n\n\n\nFor example, consider: unique(search(...)). How would a UniqueStream define its size?\nYou are absolutely right. We can change the method to {{ getEstimatedSize() }}. It is good enough. ",
            "id": "comment-15082151"
        },
        {
            "date": "2016-01-05T03:33:38+0000",
            "author": "Jason Gerlowski",
            "content": "I use this snippet to get size...\n\nFair enough.  I take back my complaint/hesitation then.\n\nI'll let others chime in then and see what (more knowledgeable) people think. ",
            "id": "comment-15082315"
        },
        {
            "date": "2016-01-09T18:06:21+0000",
            "author": "Joel Bernstein",
            "content": "I think this ticket will be important as we start to make the Streaming API more robust. I think something like a status bar with %complete would be doable.\n\nAs Cao Manh Dat mentioned we can get the count from the JSONTupleStream. From that we know how many documents there are to process and we can track how many documents have already been read.\n\nThe tricky part will be getting this information back to the client. One approach to this is to have the JSONTupleStream add the metrics to a JMX Bean on each worker. Then outside tools could gather up this information from each worker node and present a dashboard.\n\nOtis Gospodnetic, curious if you think this monitoring approach makes sense?\n\nIf we use this approach then this ticket would be about instrumenting the JSONTupleStream to gather the metrics. ",
            "id": "comment-15090723"
        },
        {
            "date": "2016-01-09T18:09:47+0000",
            "author": "Joel Bernstein",
            "content": "The great thing about adding this to the Streaming API, is that the Parallel SQL interface will get this also. ",
            "id": "comment-15090725"
        }
    ]
}