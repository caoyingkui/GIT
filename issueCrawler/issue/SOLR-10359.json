{
    "id": "SOLR-10359",
    "title": "User Interactions Logging Module",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [],
        "type": "New Feature",
        "fix_versions": [],
        "affect_versions": "None",
        "resolution": "Unresolved",
        "status": "Open"
    },
    "description": "Introduction\nBeing able to evaluate the quality of your search engine is becoming more and more important day by day.\nThis issue is to put a milestone to integrate online evaluation metrics with Solr.\n\nScope\nScope of this issue is to provide a set of components able to :\n1) Collect Search Results impressions ( results shown per query)\n2) Collect Users interactions ( user interactions on the search results per query e.g. clicks, bookmarking,ect )\n3) Calculate evaluation metrics on demand, such as Click Through Rate, DCG ...\n\nTechnical Design\nA SearchComponent can be designed :\nUsersEventsLoggerComponent\nA property (such as storeDir) will define where the data collected will be stored.\nDifferent data structures can be explored, to keep it simple, a first implementation can be a Lucene Index.\nData Model\nThe user event can be modelled in the following way :\n<query> - the user query the event is related to\n<result_id> - the ID of the search result involved in the interaction\n<result_position> - the position in the ranking of the search result involved in the interaction\n<timestamp> - time when the interaction happened\n<relevancy_rating> - 0 for impressions, a value between 1-5 to identify the type of user event, the semantic will depend on the domain and use cases\n<test_group> - this can identify a variant, in A/B testing\n\nImpressions Logging\nWhen the SearchComponent  is assigned to a request handler, everytime it processes a request and return to the user a result set for a query, the component will collect the impressions ( results returned) and index them in the auxiliary lucene index.\nThis will happen in parallel as soon as you return the results to avoid affecting the query time.\nOf course an impact on CPU load and memory is expected, will be interesting to minimise it.\n\nUser Events Logging\nAn UpdateHandler will be exposed to accept POST requests and collect user events.\nEverytime a request is sent, the user event will be indexed in the underline auxiliary Lucene Index.\n\nStats Calculation\nA RequestHandler will be exposed to be able to calculate stats and aggregations for the metrics :\n/evaluation?metric=ctr&stats=query&compare=testA,testB\nThis request could calculate the CTR for our testA and testB to compare.\nShowing stats in total and per query ( to highlight the queries with lower/higher CTR).\nThe calculations will happen separating the <test_group> for an easy comparison.\n\nWill be important to keep it as simple as possible for a first version, to then extend it as much as we like",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "date": "2017-03-24T18:29:14+0000",
            "content": "There seem to be two things mixed in here:\n\n\n\tLogging the search queries and results received (either as count or as specific ids). And - maybe - statistics on that.\n\tUser interactions on front-end\n\n\n\nThe first item can probably be solved with a SearchComponent and I would love to see what that could look like. Especially if it is flexible enough to be also used for debugging.\n\nThe second one seems to be happening well out of Solr control (UI clicks, what user selected, etc). I am not sure if that fits into Solr itself. Commercial platforms (such as Fusion) might be integrating it, but they control more of a stack.\n ",
            "author": "Alexandre Rafalovitch",
            "id": "comment-15940882"
        },
        {
            "date": "2017-03-25T11:21:50+0000",
            "content": "Thanks for opening this item, I like the idea and I would be happy to help. \n\n@Alexandre Rafalovitch\n\nThe second one seems to be happening well out of Solr control (UI clicks, what user selected, etc). I am not sure if that fits into Solr itself. Commercial platforms (such as Fusion) might be integrating it, but they control more of a stack.\n\nSolr could expose an API (e.g. addUserInteraction) that could be called by the UI when the user interacts with the results. \n\nI like the idea of storeDir in the configuration, that would allow also to import/export the collection if there's the need to reindex the \ncollection. \n\nRandom thoughts/questions?:\n\n\thow to create a unique search id? (should be responsability of solr? I think yes)\n\tif I want to use metric like the CTR (i.e., Click Through Rate, number of clicks / number of impressions)  in the scoring formula how can I do that without joining the two collections? ( (maybe that could be a way to 'import' a particular metric into the main collection? )\n\thow this could work in case of multiple shards?\n\tit should be easy to implement complex metrics that are computed from simple metrics, some examples: 1. the click through rate: for a document,  or a document and a particular query, collect the number of clicks and divide by the number of impressions (ignoring multiple requests from the same user? 2. time spent on a document after a query: if a log time of click and time of closure of a document, I want to compute how much time the users spent on the document 3. number of clicks per query.\n\n\n\n\nwith respect to the data model, I would add: \n\n\ta user-id\n\ta blob containing an optional payload\n\tscore of the document\n\n\n\n ",
            "author": "Diego Ceccarelli",
            "id": "comment-15941694"
        },
        {
            "date": "2017-03-27T09:20:29+0000",
            "content": "Hi Alexandre Rafalovitch,\nlet me answer to your considerations :\n\nLogging the search queries and results received (either as count or as specific ids). And - maybe - statistics on that.\n\nMain intention here was to store \"impressions\" , the results we are showing to the users for each query.\nThis is a required component when calculating Click Through Rate.\nIn my opinion, logging queries could even be a third aspect, not strictly related to the scope of this Jira issue, but definetly related to the component.\nIndeed could end up in a sibling module, with also different storage and data structure, but I agree it is an aspect definitely worth to consider, I would love to have it as well.\n\nThe second one seems to be happening well out of Solr control (UI clicks, what user selected, etc).\n\n\nAbsolutely correct, and actually this is the main point of this new feature :\nallow Solr to process out of the box, users interactions with Solr results, to have a better evaluation of how the search engine behaves.\nSo it is actually a way of giving Solr the control over events happening outside, but strictly realted to relevancy measurement.\n\nThe second one seems to be happening well out of Solr control (UI clicks, what user selected, etc).\n\nMain point is to expose an easy REST endpoint out of the box, that will allow users to post events to Solr and then be able to evaluate their search engine ( and compare different A/B tests) through different evaluation metrics.\n\nI am not sure if that fits into Solr itself \n\nI do believe could be a really nice addition in Solr. I see a lot of Solr users struggling in identifying the quality of their search engine, and how good the system is behaving generally or per specific queries.\nGiving them an ability to evaluate and compare their system with a set of estabilished evaluation metrics could be very useful.\nThis will allow anyone to do it without installing additional software or building complicated collections or abstractions not really easy to do for everyone.\nThe main scope is to simplify the approach and make it super easy to do it out of the box.\n\nCommercial platforms (such as Fusion) might be integrating it, but they control more of a stack\n\nThis is correct, but according to what I know, if the data collected may be similar, the target is completely different.\nI think at the moment signals processing in Fusion is used as an additional factor for relevancy tuning ( basically pushing well clicked documents up the ranking).\nThe first scope of this new feature will be focused on evaluation of relevancy, not tuning it.\nI agree of course that as soon as the component(s) is/are in place, this will open the doors to a big new world and we could add additional ways of using the data collected ( LTR training set, relevancy tuning, ect ect).\nBut at the moment this is out of scope.\n\nAnswering Diego Ceccarelli :\n1) UserInteraction is probably a better name instead of Users Events, I like it !\n\nhow to create a unique search id? (should be responsability of solr? I think yes)\n\nIf I get what you refer to, I do believe Solr should be responsible to generate a query Id per user interaction but also store the original query \"plain\" as will be quite interesting to analyse the evaluation metrics on a query basis ( in a human readable way).  To perform the aggregations I do agree that a clever Id could make them more performant.\nWere you referring to this as \" search Id\" ?\n\nif I want to use metric like the CTR (i.e., Click Through Rate, number of clicks / number of impressions) in the scoring formula how can I do that without joining the two collections? ( (maybe that could be a way to 'import' a particular metric into the main collection? )??\n\nA) For a query time approach, the quickest thing that comes to my head is defining a custom function query, that will access the data structure we defined to store the users interactions and calculate the aggregation on a per document basis.\nThis could imply we need to design the underlying data structure in a different way, as I don't know if running those aggregations on a Lucene index will be fast enough ( as the function query will need to be calculate for every document).\n\nB) For an indexing time approach, we could :\n1) design an additional data structure in the index, specifically designed to map a docId to the metric value. This could potentially be in the docValues format with some tweak.\n2) design a demon ( I need to deeply take a look to them as I have not yet used them in Solr, but I saw them related to Streaming expressions) that from time to time, runs in background and generate this data structure ( from the main one that contains all the user interactions in the storeDir)\n3) at query time  the scorer could access the data structure and get the  value. ( potentially the function query in point A could be used together with this approach)\n\nhow this could work in case of multiple shards\n\nI would assume that moving to Solr Cloud will complicate the things.\nProbably we should route the interactions as we route the documents but then we could have a problem with the impressions ( as the result set a shard see will not coincide what the user finally sees).\nSo the component that will address the impressions collection, should be only able to collect the aggregated impressions ( as showed to the users) and route the impressions data as well to the correct shard.\nEach shard will then store locally in a storeDir the data structure.\n\nit should be easy to implement complex metrics that are computed from simple metrics, some examples: 1. the click through rate: for a document, or a document and a particular query, collect the number of clicks and divide by the number of impressions (ignoring multiple requests from the same user? 2. time spent on a document after a query: if a log time of click and time of closure of a document, I want to compute how much time the users spent on the document 3. number of clicks per query.\n\nI do agree, I would say probably to initially focus only on point 1, but I am super excited in adding the other metrics and data later .\n\nwith respect to the data model, I would add: a user-id, a blob containing an optional payload, score of the document \n\n+1\n\nQuite happy to discuss it, any additional feedback is welcome \n\n ",
            "author": "Alessandro Benedetti",
            "id": "comment-15942908"
        },
        {
            "date": "2017-03-27T23:46:55+0000",
            "content": "Solr could be used to process and store this data, but would it be better to think more about creating a \"spec\" for this sort of data and pluggable outputs, so that people can choose to push their data elsewhere, whether their own custom tooling or 3rd party services? ",
            "author": "Otis Gospodnetic",
            "id": "comment-15944247"
        },
        {
            "date": "2017-03-28T20:52:08+0000",
            "content": "The ideas in this ticket are definitely something everyone encounters when needing to evaluate how good their search is performing.  I think the scope of this enhancement, for a first cut, could be narrowed down a bit though.  \n\n1) If you are storing the user interactions + impressions in a parallel solr collection, you don't need a separate evaluation component initially.  You could use Solr JSON faceting, the analytics component, or streaming joins (which can work on databases too) to calculate the numbers instead.  The first cut could probably just provide documentation for the exact requests to send in order to calculate CTR, etc.\n\n2) Also, you probably won't want to auto-log results returned from Solr as the impressions at first.  As mentioned above, results returned from Solr are not always 1 to 1 with results displayed.  Just like you will be providing a way to store user interactions on demand via an endpoint, you should probably just expand that to allow storing user impressions on demand as well.\n\n3) You will need a way to link the user impressions with their interactions.  You could supply a unique search id with the initial result set and let the client pass that back to you when sending the save impressions request and save interactions request.  However, for the first cut you could make it the client's responsibility of generating the unique id to then pass back to you.\n\nFor the use cases of Solr that use a federated search across multiple collections and merge the results into 1 list, points 2 and 3 become more important.  I might query 10 results from each of 3 collections, for a total of 30 results, but only display the top 5 combined on my page.  If solr auto generates a search id, I will now have 3 ids instead of 1.  Also, there were only 5 total impressions, not 30 for the auto logging case. ",
            "author": "Michael Nilsson",
            "id": "comment-15945944"
        },
        {
            "date": "2017-03-29T15:02:41+0000",
            "content": "Otis Gospodnetic :\nThe scope of this Jira Issue is to implement an easy out of the box approach to evaluate Solr.\nIt must be as simple as possible to configure, we want to hide the complexity to the users and offer an easy way to evaluate their search engine reducing the expertise required as much as possible.\nArguably even a Solr admin with minimal knowledge about evaluation metrics work should be able to use it and have an idea of the quality is achieving.\nGiven that, I absolutely agree that the strategy we use to store the data collected should be pluggable.\nI would make an analogy with the way the Suggester Component manages lookup algorithms ( and data structures).\nSolr should give the best option out of the box, but should be possible to configure it ( and potentially use third party systems).\nI would say that this capability should not be in the first release of this functionality, but definitely later on \n\nMichael Nilsson\n1) the idea is actually not to use a separate, exposed collection, but to use an internal data structure ( potentially an auxiliary Lucene index ?) In my opinion it is vital to hide the complexity and give users an easy way to access it.\nInternally i definitely agree we will re-use components and modules used in the stats and faceting areas.\nI also agree that this is already achievable if we manually build the solr collection, model the data in a clever way and run specific stats/faceting queries.\nDefinitely a dcoumentation to do that would be useful.\n\n2)I agree, the exposed update endpoint can be used for impressions as well ( in the draft data model, they will be relevancy_rating=0).\nBut I would leave the component to do it automatically available as well, for all the users that are happy to capture what Solr returns immediately, this could ease the client job and volume of data transferred.\n\n3) Definitely a good idea\n\nRelated your last observation, I agree it is delicate. \nIn a cluster scenario where the aggregator instances are separate from the shards, it would be possible to potentially add the User Interaction Logging components only in the aggregator request handlers.\nIn Solrcloud, what happens if we define 2 request handlers per collection ( one for aggregation with user interactions tracking and one not) and then in the aggregation request handler we use the qt.shards=localRequestHandler  ?\nWe will call the aggregation request handler as the SolrCloud entrypoint ( with tracking) and then internally it will aggregates from the local request handlers ( not tracked).\nJust thinking loud so it may not work. ",
            "author": "Alessandro Benedetti",
            "id": "comment-15947289"
        }
    ]
}