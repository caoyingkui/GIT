{
    "id": "LUCENE-3366",
    "title": "StandardFilter only works with ClassicTokenizer and only when version < 3.1",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [
            "modules/analysis"
        ],
        "type": "Improvement",
        "fix_versions": [],
        "affect_versions": "3.3",
        "resolution": "Not A Problem",
        "status": "Resolved"
    },
    "description": "The StandardFilter used to remove periods from acronyms and apostrophes-S's where they occurred. And it used to work in conjunction with the StandardTokenizer.  Presently, it only does this with ClassicTokenizer and when the lucene match version is before 3.1. Here is a excerpt from the code:\n\n  public final boolean incrementToken() throws IOException {\n    if (matchVersion.onOrAfter(Version.LUCENE_31))\n      return input.incrementToken(); // TODO: add some niceties for the new grammar\n    else\n      return incrementTokenClassic();\n  }\n\n\n\nIt seems to me that in the great refactor of the standard tokenizer, LUCENE-2167, something was forgotten here. I think that if someone uses the ClassicTokenizer then no matter what the version is, this filter should do what it used to do. And the TODO suggests someone forgot to make this filter do something useful for the StandardTokenizer.  Or perhaps that idea should be discarded and this class should be named ClassicTokenFilter.\n\nIn any event, the javadocs for this class appear out of date as there is no mention of ClassicTokenizer, and the wiki is out of date too.",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "date": "2011-08-08T22:25:47+0000",
            "content": "Hi David, I think you want to use ClassicFilter. ",
            "author": "Robert Muir",
            "id": "comment-13081256"
        },
        {
            "date": "2011-08-09T01:57:35+0000",
            "content": "Doh! Yes, I didn't notice it, Rob.  But still... the purpose of StandardFilter in its current state seems to only exist to satisfy backwards compatibility for code that uses Lucene at a pre 3.x era; nothing more.  Shouldn't it be marked @Deprecated to warn people?.  Or, the \"TODO\" should be done to do something. However the current StandardTokenizer doesn't really have equivalent token types to ClassicTokenizer in order for StandardFilter to actually do something useful. So then there is no TODO to do. ",
            "author": "David Smiley",
            "id": "comment-13081363"
        },
        {
            "date": "2011-08-09T02:16:53+0000",
            "content": "the purpose of the filter is \"Normalizes tokens extracted with StandardTokenizer\".\n\ncurrently this is a no-op, but we can always improve it going with the spirit of the whole standard this thing implements.\n\nThe TODO currently refers to this statement:\n\"For Thai, Lao, Khmer, Myanmar, and other scripts that do not use typically use spaces between words, a good implementation should not depend on the default word boundary specification. It should use a more sophisticated mechanism ... Ideographic scripts such as Japanese and Chinese are even more complex\"\n\nThere is no problem having a TODO in this filter, we don't need to do a rush job for any reason... \n\nSome of the preparation for this (e.g. improving the default behavior for CJK) was already done in LUCENE-2911. We now tag all these special types,\nso in the meantime if someone wants to do their own downstream processing they can do this themselves. ",
            "author": "Robert Muir",
            "id": "comment-13081374"
        },
        {
            "date": "2011-08-09T02:52:42+0000",
            "content": "Ok.  (I've been in no hurry to rush anything)\n\nI updated the http://wiki.apache.org/solr/AnalyzersTokenizersTokenFilters page to fix references to StandardFilter that should have been to ClassicFilter, and I removed some uses of StandardFilter altogether because it doesn't do anything. I'm disinclined to mention this filter in the upcoming revision of my book, but I'll be sure to mention the Classic* variants.\n\nFeel free to close this issue if you feel it is appropriate. I created it as an \"improvement\" because StandardFilter seems unfinished, and you've acknowledged it is. So perhaps it should stay open until it actually does something some day.  ",
            "author": "David Smiley",
            "id": "comment-13081385"
        },
        {
            "date": "2011-08-09T02:58:19+0000",
            "content": "well its not \"unfinished\", the right decision might be to ultimately remove it.\n\nand we could deprecate it in 4.9 and remove it in 5.0 if this is the case, no one's indexes will be broken as it wouldnt have done anything.\n\nbut I don't like what happens with thai etc right now if someone uses StandardAnalyzer. ",
            "author": "Robert Muir",
            "id": "comment-13081388"
        },
        {
            "date": "2011-08-09T03:02:17+0000",
            "content": "use ClassicFilter if you want this behavior. ",
            "author": "Robert Muir",
            "id": "comment-13081390"
        }
    ]
}