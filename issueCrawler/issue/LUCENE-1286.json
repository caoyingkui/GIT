{
    "id": "LUCENE-1286",
    "title": "LargeDocHighlighter - another span highlighter optimized for large documents",
    "details": {
        "labels": "",
        "priority": "Minor",
        "components": [
            "modules/highlighter"
        ],
        "type": "Improvement",
        "fix_versions": [],
        "affect_versions": "2.4",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "The existing Highlighter API is rich and well designed, but the approach taken is not very efficient for large documents.\n\nI believe that this is because the current Highlighter rebuilds the document by running through and scoring every every token in the tokenstream.\n\nWith a break in the current API, an alternate approach can be taken: rebuild the document by running through the query terms by using their offsets. The benefit is clear - a large doc will have a large tokenstream, but a query will likely be very small in comparison.\n\nI expect this approach to be quite a bit faster for very large documents, while still supporting Phrase and Span queries.\n\nFirst rough patch to follow shortly.",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "date": "2008-11-10T05:40:51+0000",
            "content": "First rough patch to follow shortly.\n\nMark,\nI'm very interested in this. How is it going on? ",
            "author": "Koji Sekiguchi",
            "id": "comment-12646177"
        },
        {
            "date": "2008-11-10T14:11:14+0000",
            "content": "It didn't turn out as well as I had hoped. You had to pay too much for the Memory index / getting spans. I havn't closed the issue because I hope to keep trying, but I don't have anything great at the moment. If I have the time I'll get back into it though. Storing position/offset termvectors is the only helpful thing for large docs that I know of at the moment.\n\nThere is another highlighter by Ronnie something in JIRA that also takes this approach but  without Phrase/Span support and requiring stored termvectors. You might try it though. ",
            "author": "Mark Miller",
            "id": "comment-12646266"
        },
        {
            "date": "2008-11-28T03:19:04+0000",
            "content": "Thanks, Mark. I've tryed Ronnie's patch in LUCENE-644. It was great in speed, but phrase support is needed in our project.\n\nSo, I'd like to know your approach mentioned in above description. Can you elaborate this - \"rebuild the document by running through the query terms by using their offsets\"? ",
            "author": "Koji Sekiguchi",
            "id": "comment-12651452"
        },
        {
            "date": "2008-12-04T12:39:14+0000",
            "content": "Hey Koji, I actually have some ideas to come back to this with, but no time for some time to actually work on it.\n\nCan you elaborate this - \"rebuild the document by running through the query terms by using their offsets\"?\n\nPart of the problem with the Highlighter and large docs is that it runs through every token in the doc and scores that token, building the original highlighted doc as it goes. For a large doc, that can be a bit slow. What Ronnies highlighter did was just look at the offsets of the query terms (hence the need for term vectors) which allows you to rebuild the original highlighted document in big quick chunks (stitching things together between query term offsets).\n\nI was attempting a similar thing here with phrase and span support, but I couldn't match the speed of what the current Span highlighter has - this is because the current Span Highlighter can highlight non position sensitive terms very fast. My method required getting non position sensitive terms from the MemoryIndex as well (via getSpans) and the cost ruined any benefit. I came up with a few things to try since then but havn't had the time to dedicate to it yet. Its hard to get around requiring term vectors (for the offsets), and I'd like to avoid that. At the same time, if you don't require term vectors, its probably going to be pretty slow re-analyzing the documents anyway... ",
            "author": "Mark Miller",
            "id": "comment-12653283"
        },
        {
            "date": "2009-12-08T04:02:29+0000",
            "content": "This isn't likely to go anywhere anytime soon - Koji's FastVectorHighlighter, while requiring termvectors, accomplishes this pretty nicely. ",
            "author": "Mark Miller",
            "id": "comment-12787293"
        }
    ]
}