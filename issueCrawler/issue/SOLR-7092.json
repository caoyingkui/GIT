{
    "id": "SOLR-7092",
    "title": "Stop the HDFS lease recovery retries on HdfsTransactionLog on close and try to avoid lease recovery on closed files.",
    "details": {
        "components": [],
        "type": "Bug",
        "labels": "",
        "fix_versions": [
            "5.1",
            "6.0"
        ],
        "affect_versions": "None",
        "status": "Closed",
        "resolution": "Fixed",
        "priority": "Major"
    },
    "description": "",
    "attachments": {
        "SOLR-7092.patch": "https://issues.apache.org/jira/secure/attachment/12700970/SOLR-7092.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2015-02-26T05:02:40+0000",
            "author": "Mark Miller",
            "content": "Patch to stop retrying if the log is closed. Previously would retry for like 15 min even after close. ",
            "id": "comment-14337877"
        },
        {
            "date": "2015-03-21T17:30:27+0000",
            "author": "Mark Miller",
            "content": "Patch that seems to behave better. ",
            "id": "comment-14372911"
        },
        {
            "date": "2015-03-21T17:36:01+0000",
            "author": "Mark Miller",
            "content": "There still appears to be an internal HDFS lease renewer that I don't see how to stop, but with the latest patch, I've had good results so far.\n\n\n [junit4]   2> 504053 T130 oahh.LeaseRenewer.run WARN Failed to renew lease for [DFSClient_NONMAPREDUCE_-1506464199_13] for 429 seconds.  Will retry shortly ... java.net.ConnectException: Call From totalmetal/127.0.1.1 to localhost:43747 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n   [junit4]   2> \tat sun.reflect.GeneratedConstructorAccessor179.newInstance(Unknown Source)\n   [junit4]   2> \tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n   [junit4]   2> \tat java.lang.reflect.Constructor.newInstance(Constructor.java:422)\n   [junit4]   2> \tat org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)\n   [junit4]   2> \tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)\n   [junit4]   2> \tat org.apache.hadoop.ipc.Client.call(Client.java:1410)\n   [junit4]   2> \tat org.apache.hadoop.ipc.Client.call(Client.java:1359)\n   [junit4]   2> \tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)\n   [junit4]   2> \tat com.sun.proxy.$Proxy39.renewLease(Unknown Source)\n   [junit4]   2> \tat sun.reflect.GeneratedMethodAccessor34.invoke(Unknown Source)\n   [junit4]   2> \tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n   [junit4]   2> \tat java.lang.reflect.Method.invoke(Method.java:497)\n   [junit4]   2> \tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)\n   [junit4]   2> \tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\n   [junit4]   2> \tat com.sun.proxy.$Proxy39.renewLease(Unknown Source)\n   [junit4]   2> \tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:519)\n   [junit4]   2> \tat org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:773)\n   [junit4]   2> \tat org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)\n   [junit4]   2> \tat org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)\n   [junit4]   2> \tat org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)\n   [junit4]   2> \tat org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)\n   [junit4]   2> \tat java.lang.Thread.run(Thread.java:745)\n   [junit4]   2> Caused by: java.net.ConnectException: Connection refused\n ",
            "id": "comment-14372913"
        },
        {
            "date": "2015-03-21T19:08:55+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1668311 from Mark Miller in branch 'dev/trunk'\n[ https://svn.apache.org/r1668311 ]\n\nSOLR-7092: Stop the HDFS lease recovery retries in HdfsTransactionLog on close and try to avoid lease recovery on closed files. ",
            "id": "comment-14372968"
        },
        {
            "date": "2015-03-21T20:16:15+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1668313 from Mark Miller in branch 'dev/branches/branch_5x'\n[ https://svn.apache.org/r1668313 ]\n\nSOLR-7092: Stop the HDFS lease recovery retries in HdfsTransactionLog on close and try to avoid lease recovery on closed files. ",
            "id": "comment-14372986"
        },
        {
            "date": "2015-03-21T20:23:47+0000",
            "author": "Mark Miller",
            "content": "I'm still looking into this area of the code, but that should improve some of the current stdout / stderr errors that have grown more common. ",
            "id": "comment-14372991"
        },
        {
            "date": "2015-03-22T17:12:08+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1668412 from Mark Miller in branch 'dev/trunk'\n[ https://svn.apache.org/r1668412 ]\n\nSOLR-7092: Do a little better at clean up in new test code. ",
            "id": "comment-14375057"
        },
        {
            "date": "2015-03-24T12:38:41+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1668862 from Mark Miller in branch 'dev/branches/branch_5x'\n[ https://svn.apache.org/r1668862 ]\n\nSOLR-7092: Do a little better at clean up in new test code. ",
            "id": "comment-14377782"
        },
        {
            "date": "2015-03-24T12:41:35+0000",
            "author": "Mark Miller",
            "content": "This should be fixed now. I've improved the 'thread leak' handling situation with SOLR-7289 as well so that it's more difficult for this to sneak by. ",
            "id": "comment-14377784"
        },
        {
            "date": "2015-03-25T19:21:42+0000",
            "author": "Mark Miller",
            "content": "and try to avoid lease recovery on closed files.\n\nThis was added to this issue to reduce how often we were starting up lease recovery stuff when we did not need to.\n\nIt was also something I wanted to do because I had seen a situation where recovery of leases on closed files was taking a very long time and causing odd issues with Solr. So I rolled in this change.\n\nIt seems that sometimes HDFS does not like it when you make a bunch of lease recovery calls (hopefully just because they are all on files that don't even need it). Usually, trying to recover a lease on a closed file just returns - but on larger indexes something problematic seems to happen instead. I've got more to find out in that area, but this improves the situation. ",
            "id": "comment-14380577"
        },
        {
            "date": "2015-04-15T00:30:19+0000",
            "author": "Timothy Potter",
            "content": "Bulk close after 5.1 release ",
            "id": "comment-14495262"
        }
    ]
}