{
    "id": "SOLR-5821",
    "title": "Search inconsistency on SolrCloud replicas",
    "details": {
        "affect_versions": "4.6.1,                                            4.7.1",
        "status": "Reopened",
        "fix_versions": [],
        "components": [
            "SolrCloud"
        ],
        "type": "Bug",
        "priority": "Critical",
        "labels": "",
        "resolution": "Unresolved"
    },
    "description": "We use the following infrastructure:\n\nSolrCloud with 1 shard and 2 replicas. The index is built using DataImportHandler (importing data from the database). The number of items in the index can vary from 100 to 100,000,000.\n\nAfter indexing part of the data (not necessarily all the data, it is enough to have a small number of items in the search index), we can observe that Solr instances (replicas) return different results for the same search queries. I believe it happens because some of the results have the same scores, and Solr instances return those in a random order.\n\nPS This is a critical issue for us as we use a load balancer to scale Solr through replicas, and as a result of this issue, we retrieve various results for the same queries all the time. They are not necessarily completely different, but even a couple of items that differ is a deal breaker.\n\nThe expected behaviour would be to always get identical results for the same search queries from all replicas. Otherwise, this \"cloud\" thing works just unreliably.",
    "attachments": {
        "Screen Shot 2014-04-05 at 2.26.41 AM.png": "https://issues.apache.org/jira/secure/attachment/12638854/Screen%20Shot%202014-04-05%20at%202.26.41%20AM.png",
        "Screen Shot 2014-04-05 at 2.26.26 AM.png": "https://issues.apache.org/jira/secure/attachment/12638853/Screen%20Shot%202014-04-05%20at%202.26.26%20AM.png"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Erick Erickson",
            "id": "comment-13924094",
            "date": "2014-03-07T17:40:20+0000",
            "content": "First, please raise issues like this on the user's before\nraising a JIRA to be sure you are really seeing a bug \nrather than simply misunderstanding.\n\nIf your hypothesis is true, try specifying a secondary\nknown ordering. If scores are tied, then Solr/Lucene\nwill return the document in internal Lucene ID order,\nand you're quite correct that the internal order may be\ndifferent in different shards.\n\nTesting this should be as simple as specifying something\nsimilar to \n&sort=score desc, id asc "
        },
        {
            "author": "Maxim Novikov",
            "id": "comment-13924107",
            "date": "2014-03-07T17:50:11+0000",
            "content": "Will this additional ordering not impact the performance of search? Considering 100,000,000 records indexed from the database, and having about 400 search requests per second per 1 Solr instance. "
        },
        {
            "author": "Maxim Novikov",
            "id": "comment-13924127",
            "date": "2014-03-07T18:05:03+0000",
            "content": "PS Regarding \"misunderstanding\" and stuff like that... This behavior is unexpected for me. As I wrote, I have a load balancer that redirects queries to Solr's replicas having the only shard, and running the same query (even not specifying any additional parameters), I expect to retrieve the same results. You can tell anything about how Solr is implemented internally, but from the perspective of Solr's user (search's user) I should not care about that at all. That was the point. If you disagree and think that this is sort of a \"feature\", not a bug/issue, that is still good to keep this stuff in JIRA. The other people who face the same issue will be able to find it, read Solr developers' responses, and judge for themselves whether this \"feature\" fits the search solution they want to get or not. "
        },
        {
            "author": "Maxim Novikov",
            "id": "comment-13961024",
            "date": "2014-04-05T09:29:11+0000",
            "content": "I have to reopen this issue as the inconsistency still exists regardless of the queries. I am adding details and screenshots in comments. "
        },
        {
            "author": "Maxim Novikov",
            "id": "comment-13961026",
            "date": "2014-04-05T09:36:29+0000",
            "content": "SolrCloud infrastructure:\n\n3 ZooKeeper nodes + 3 Solr replicas (1 shard) on Tomcat 7.\n\nWhen importing the data from the database through one of the Solr instances (DataImportHandler) another Solr instance was down (had to be restarted). The result of that you can see in the screenshots. The number of items on 1st machine is 9,812,001 items, on that one that was down for a couple of seconds is 9,811,987.\n\nPS And the worst thing is that I can't see a way to synchronize them now, as replication requests via HTTP don't seem to be working as in SolrCloud all the nodes behave like \"masters\" and HTTP replication request (pulling data from the master to a slave) just fails. But even if it worked, it wouldn't be really appropriate. That way you would need to perform consistent checks all the time (as data continues coming), and do something on your own... "
        },
        {
            "author": "Markus Jelsma",
            "id": "comment-13962715",
            "date": "2014-04-08T08:48:46+0000",
            "content": "Smells like SOLR-4260. It should be resolved though. "
        },
        {
            "author": "Christian Schramm",
            "id": "comment-14235336",
            "date": "2014-12-05T10:22:17+0000",
            "content": "I confirm that the problem still exists in 4.10.1.\nI've created a cluster consisting of 8 servers, a set of 9 cores dispatchted on 4 shards, having 4 replica's (so numShards=16).\nThe 8 solr servers were running tomcat7 and using a Zookeeper Cluster 3.4.6 (3 nodes).\nI was justing a loadbalancer to dispatch incoming queries across the 8 servers.\nThe cluster was running fine for a few hours, but when having a lot of commits, the replica's get quickly out of sync.\nSo searching in the same core on different hosts gave different results.\nNo errors however in Zookeeper or in the SOLR logs.\nI guess and hope that this is not expected behaviour though....? "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-14235725",
            "date": "2014-12-05T16:57:07+0000",
            "content": "Well, \"it depends\". SolrCloud is designed for eventual consistency.\n\nThere are two ways to interpret \"different results\"\n1> the docs returned by different replicas for the same shard\n     aren't identically ordered\n2> the number of docs found varies depending on which replica\n     is queried.\n\nFor <2>, in the absence of ongoing indexing and after the last\nsoft commit (or hard commit with openSearcher = true) has fired\non all replicas, that would be a bug.\n\nConsider the autocommit intervals on your replicas. They wont\nall fire at the same instant. Say you index a doc and\nreplica A's autocommit trigger happens immediately after that\ndoc hits it, but replica B's autocommit happens to trip\njust before the doc arrived there. The doc will not be visible\nfrom replica B until after the next autocommit happens there.\n\nSo if you stop indexing and wait until all the replica's autocommits\nhave surely fired and still have different numFounds from different\nreplicas, we need to know about that as it's unexpected.\n\nBTW, you can insure you get data from only one node by appending\n&distrib=false to a query.\n\nFor <1> it's a little different. Depending on the vagaries of merging,\nthe internal Lucene doc ID for the same two docs may be different\non different machines. If the sort criteria (score by default) happens\nto be identical for two docs, the tiebreaker is the internal Lucene\ndoc ID. So depending on the shard, doc1 might sort before or after\ndoc 2, so the same query on a corpus with no indexing going on\nmay appear in different orders. \n\nYou can cure this by specifying a secondary sort that you control.\nThis case, however, should NOT return different numFound "
        }
    ]
}