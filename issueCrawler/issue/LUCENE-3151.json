{
    "id": "LUCENE-3151",
    "title": "Make all of Analysis completely independent from Lucene Core",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [],
        "type": "Improvement",
        "fix_versions": [
            "4.9",
            "6.0"
        ],
        "affect_versions": "4.0-ALPHA",
        "resolution": "Unresolved",
        "status": "Open"
    },
    "description": "Lucene's analysis package, including the definitions of Attribute, TokenStream, etc. are quite useful outside of Lucene (for instance, Mahout uses them) for text processing.  I'd like to move the definitions, or at least their packaging, to a separate JAR file so that one can consume them w/o needing Lucene core.  My draft idea is to have a definition area that Lucene core is dependent on and the rest of the analysis package can then be dependent on the definition area.  (I'm open to other ideas as well)",
    "attachments": {
        "LUCENE-3151.patch": "https://issues.apache.org/jira/secure/attachment/12480754/LUCENE-3151.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2011-05-28T17:52:59+0000",
            "content": "+1 ",
            "author": "Michael McCandless",
            "id": "comment-13040640"
        },
        {
            "date": "2011-05-28T17:54:11+0000",
            "content": "I agree, and wanted to mention we shouldn't limit ourselves based on packaging.\n\nfor example we can have analyzers-def and analyzers-impl, but actually shove the analyzers-def into the lucene-core jar for simplicity/packaging purposes if we want.\n\nbut this way you could still use the analyzers without the lucene core if you wanted. ",
            "author": "Robert Muir",
            "id": "comment-13040641"
        },
        {
            "date": "2011-05-28T18:07:10+0000",
            "content": "Analysis could even be released independently.  I've got a start to a patch that I hope to put up today as a POC. ",
            "author": "Grant Ingersoll",
            "id": "comment-13040644"
        },
        {
            "date": "2011-05-28T20:10:49+0000",
            "content": "I would propose to add:\nlucene/src/analysis-defs that would contain all of the analysis declarations (including attributes) and that the main build would depend on it being built first.  I thought about moving it to modules/analysis, but that makes for some clunky Ant, IMO (although, I'm not sure if this is less clunky.)\n\nbut actually shove the analyzers-def into the lucene-core jar for simplicity/packaging purposes if we want.\nI'm not sure on shoving them into lucene-core just b/c I wonder if people might think they need both jars then b/c they don't know if it's in core.  Not sure on that one, so I'm not ruling it out. ",
            "author": "Grant Ingersoll",
            "id": "comment-13040668"
        },
        {
            "date": "2011-05-28T22:54:21+0000",
            "content": "doesn't fully compile yet (but core does) due to our recursive build system, but at least fleshes out the proposed directory layout.  I may, however, change src/declarations to src/common and then we would have lucene-common.jar.  I was surprised by how much I needed to move out of core (e.g. BytesRef) ",
            "author": "Grant Ingersoll",
            "id": "comment-13040689"
        },
        {
            "date": "2011-05-29T01:35:12+0000",
            "content": "Looks like it makes sense that we would have to pull out these classes to do it now... but here are a few thoughts maybe for discussion... this stuff certainly should not block this issue, its hard refactorings and a lot of work, but just ideas for the future.\n\nAs far as analyzers:\n\n\tdoes the lucene-core/common jar need to have all the tokenAttributes? Maybe it should only have the ones that the indexer etc actually consume, and things like TypeAttribute, FlagsAttribute, KeywordAttribute, Token, etc should simply be moved to the analysis module?\n\tdoes the lucene-core/common jar need to have Tokenizer/TokenFilter/CharFilter/CharReader/etc. Seems like it really only needs TokenStream and those could also be moved to the analysis module.\n\tcurrently I think its bad that the analyzers depend upon so many of lucene's util package (some internal)... long term we want to get rid of the cumbersome backwards compatibility methods like Version and ideally have a very minimal interface between core and analysis so that you could safely just use your old analyzers jar file, etc... maybe we should see how hard it is to remove some of these util dependencies?\n\n\n\nSo in a way, this issue is related to LUCENE-2309...\n ",
            "author": "Robert Muir",
            "id": "comment-13040718"
        },
        {
            "date": "2011-06-04T12:18:47+0000",
            "content": "\n\n\nIt's not too bad, except for the build system's recursive nature.  Not sure how to get around that yet.\n\n\nI did it for Token.  I think the others are useful at the definition layer if someone wants just this piece of analysis, but not all of Lucene's implementations.  But, could be persuaded otherwise.\n\n\nQueryParserBase has a dep. here, so if we could fix that, then we might be able to do this.   That being said, they are useful constructs for someone who wants them w/o all of Lucene's implementations.\n\n\nI've got a new patch that helps here w/ some, but some of those utils are pretty useful in the context of a common area, I guess.\n\n ",
            "author": "Grant Ingersoll",
            "id": "comment-13044282"
        },
        {
            "date": "2011-07-19T01:21:35+0000",
            "content": "Architects remove dependencies\n\nFor external use, this locksteps the external user (Mahout for example) to changes in these data structures. It's a direct coupling. This is how you get conflicting dependencies, what the Linux people call \"RPM Hell\". \n\nIf you can make a minimal class for export, then have Lucene use a larger class, that might work. Here is a semi-coupled design:\npublic class ITerm\n\n\tA really minimal API that will never be changed, only added onto.\n\tCode that uses this API will always work- that is the contract.\n\t\n\t\tclone() is banned (via UnsupportedOperationException).\n\t\tIf a class implements clone(), all subclasses must also implement it.\n\t\n\t\n\tI would also ban equals & hashCode- if you want these, make your own subclass that delegates to a real Term subclass.\n\n\n\npublic class Term extends ITerm\n\n\tThis is what Lucene uses.\n\tIt can be versioned.\n\tIf you code to this, you lock your binaries to Lucene release jars.\n\n\n\nHere is a fully-decoupled design:\n\n\tSeparate suite of main Lucene objects, with minimal features as above.\n\tSeparate Lucene library that xlates/wraps/etc. between this parallel suite and the Lucene versions. Lucene exports this jar and works very hard to avoid version changes.\n\n\n\nIt's a hard problem all around, and different solutions have failed in their own ways. Error-handling is a particularly big problem. Using these objects in parallel brings its own funkiness. ",
            "author": "Lance Norskog",
            "id": "comment-13067432"
        },
        {
            "date": "2012-07-18T12:50:00+0000",
            "content": "I'm resurrecting this.  I'm now thinking that we just put some build targets into Lucene that make it easy to build this, instead of rearranging the packaging. ",
            "author": "Grant Ingersoll",
            "id": "comment-13417048"
        },
        {
            "date": "2012-07-18T21:13:24+0000",
            "content": "Hmm, this gets wonky with some of the dependencies.  Ideally, I'd like to keep this isolated to just the analysis package in core and util (ideally not even that, but do need things like ArrayUtil, BytesRef, etc.), however not sure that can be done w/o some refactoring.  For instance, Analyzer has a dependency on IndexableField, all so that it can check to see whether it is tokenized or not.  Could it just take in a boolean for getOffsetGap indicating whether it is tokenized or not?  It also has a dependency on AlreadyClosedException, which, I suppose could be moved to Util.\n\nThere also a number of imports for Javadocs which are probably useful, but a bit odd in terms of packaging for this particular thing. ",
            "author": "Grant Ingersoll",
            "id": "comment-13417685"
        },
        {
            "date": "2012-07-18T22:48:34+0000",
            "content": "Grant: I agree.\n\nI guess it would be good to figure out exactly what the desired goals are:\n\n\tis the goal to just use analyzers.jar without having lucene core.jar for aesthetic reasons (no lucene jar file)\n\tis instead the goal to be able to depend on an analyzers.jar without causing classpath hell for users that might want to use a different version of lucene in their app, when all you need is the analyzers?\n\n\n\nIf its just the second, maybe we just need some fancy jar-jar packing. We would have to target\na different package name or something like that so there are no conflicts: then again this might be something the end\nuser could just do themselves without us doing anything (maven has plugins for this type of thing, etc?). Then\nthey could deal with what the renamed packages should be etc? ",
            "author": "Robert Muir",
            "id": "comment-13417791"
        },
        {
            "date": "2012-07-19T11:21:29+0000",
            "content": "My goal is #1 (I have the same goal for the FST package).  I want to be able to use analyzers independently of Lucene and I don't want to have to bring in whatever dependencies other parts of Lucene might have (which is admittedly small at the moment).  Doing this also achieves #2, I suppose.  I've almost got a patch ready that just makes this build sugar, but I wonder if it is better to separate out the code if #1 is the goal. ",
            "author": "Grant Ingersoll",
            "id": "comment-13418221"
        },
        {
            "date": "2012-07-19T12:26:11+0000",
            "content": "I don think it is from my perspective. Really this isnt a common use case of lucene and \nwill make things awkward and confusing (harder to use) to have a lots of jar files. ",
            "author": "Robert Muir",
            "id": "comment-13418248"
        },
        {
            "date": "2012-07-20T10:29:41+0000",
            "content": "Here's a first draft at this.  The packaging looks more or less right, but I haven't fully tested it yet.  The main downsides to this approach are:\n\n\tMinor loss of Javadoc due to references to things like IndexWriter, DoubleField, etc.  I kept the references, just removed the @link, which allowed me to drop the import statement\n\tWe need to somehow document that this jar is for standalone use only.  It's probably a minor issue, but going forward, people could get into classloader hell with this if they are mixing versions.  Of course, that's always the case in Java, so caveat emptor.\n\n ",
            "author": "Grant Ingersoll",
            "id": "comment-13419043"
        },
        {
            "date": "2012-07-20T10:32:57+0000",
            "content": "I should add: to run this, for now, do \n\nant jar-analyzer-definition\n\n.  Still need to make sure it fully hooks into the rest of the build correctly, too. ",
            "author": "Grant Ingersoll",
            "id": "comment-13419045"
        },
        {
            "date": "2012-07-20T13:00:55+0000",
            "content": "Hey Grant: I know it sounds silly but can we split out the getOffsetGap API change into a separate issue?\nThis would be nice to fix ASAP.\n\nI dont understand why it takes IndexableField or took Fieldable. All the other methods here like\ngetPositionIncrementGap take \"String fieldName\". I think this one should too.\n\nI dont think it needs a boolean for tokenized either: returning a 0 for NOT_ANALYZED fields. \nIf you choose NOT_ANALYZED, that should mean the Analyzer is not invoked!\n\nIf you want to do expert stuff control the offset gaps between values for NOT_ANALYZED fields, \nthen just analyze it instead, with keyword tokenizer!\n ",
            "author": "Robert Muir",
            "id": "comment-13419106"
        },
        {
            "date": "2012-07-20T14:05:42+0000",
            "content": "LUCENE-4240 ",
            "author": "Grant Ingersoll",
            "id": "comment-13419163"
        },
        {
            "date": "2012-07-20T21:55:57+0000",
            "content": "Updated version for trunk.  Updated packaging to now include all of Util, as it was getting ridiculous trying to get the exact list.  I tested this setup by taking the jar produced here, plus the common analyzers jar and put them in a standalone project and tested them and it seemed to work.\n\nThus, I think this is mostly done and ready to commit.  I'd say the only issue left is to say how we want to document this so that people aren't confused.  My suggestion would be to collocate a file name README-analyzers-def.txt alongside the jar that explains it.  Otherwise, we could just put it in the README. ",
            "author": "Grant Ingersoll",
            "id": "comment-13419605"
        },
        {
            "date": "2012-07-20T22:05:25+0000",
            "content": "\nI tested this setup by taking the jar produced here, plus the common analyzers jar and put them in a standalone project and tested them and it seemed to work.\n\nPersonally I dont feel comfortable with that as a testing strategy. There is nothing to prevent someone from breaking this jar in the future (e.g. if i import something from o.a.l.index into an analyzer for some reason).\n\nIf we cannot test this, can we just make it an optional target (e.g. not part of package). Generally this is pretty expert to do (it must be, it has no javadocs, etc etc), so I think its fair the people who need this could just run the ant target from the source release.\n\n\n ",
            "author": "Robert Muir",
            "id": "comment-13419610"
        },
        {
            "date": "2012-07-20T22:08:45+0000",
            "content": "For example, I just searched for org.apache.lucene.index in the analyzers-common source and there is code using IndexReader, TermsEnum, etc. ",
            "author": "Robert Muir",
            "id": "comment-13419621"
        },
        {
            "date": "2012-07-21T10:13:25+0000",
            "content": "For example, I just searched for org.apache.lucene.index in the analyzers-common source and there is code using IndexReader, TermsEnum, etc.\n\nUgh.  I wonder if that just makes all of this a moot point.  I'll take a look.  I was thinking about how to more reliably test it yesterday, but didn't implement it.    I guess ideally we could exercise all the analyzers independently on some content, or just run the analyzers test suite somehow. ",
            "author": "Grant Ingersoll",
            "id": "comment-13419790"
        },
        {
            "date": "2012-07-21T21:38:29+0000",
            "content": "For:\n\n\n\tIndexReader \u2013 It's mostly just in tests, except the QueryStopWordAnalyzer\n\tTermsEnum \u2013 Same thing, a test and the QueryStopWordAnalyzer\n\tSynonym package has dependency on DataOutput and ByteArray* from store (which can be added to the base packaging)\n\n\n\nSo, basically, the issue would be with the QueryStopWordAnalyzer (the tests aren't an issue) ",
            "author": "Grant Ingersoll",
            "id": "comment-13419955"
        },
        {
            "date": "2012-07-21T22:00:56+0000",
            "content": "Is it intended to support jars from different Lucene versions? Would a \"unit test\" for this project include old versions of jars retained as binaries? ",
            "author": "Lance Norskog",
            "id": "comment-13419957"
        },
        {
            "date": "2012-07-22T11:30:36+0000",
            "content": "Why didn't the compiler catch these things? ",
            "author": "Robert Muir",
            "id": "comment-13420146"
        },
        {
            "date": "2012-07-22T11:38:42+0000",
            "content": "How about using a tools to collect all realy needed dependencies from core and package it as lucene-core4analysis-min.jar? JARJAR can do this (as ANT task, without renaming classes, just to collect the dependent ones from core). We would then also not need to remove the Javadocs (NRQ,...), Grant's patch removed. ",
            "author": "Uwe Schindler",
            "id": "comment-13420147"
        },
        {
            "date": "2012-07-22T17:31:24+0000",
            "content": "Why didn't the compiler catch these things?\n\nNot sure I follow.  There really isn't compilation involved at this point and they are runtime dependencies that fail.\n\n@Uwe:  it's possible, but I suspect the IndexReader dep. is going to bring in a lot, which seems a little silly given it is all just used in the QueryStopWordAnalyzer, which could easily be collapsed into just using the StopFilter and some example code for people.  I'm not that familiar w/ JARJAR, but if you want to try it and we can compare. ",
            "author": "Grant Ingersoll",
            "id": "comment-13420248"
        },
        {
            "date": "2012-07-26T14:06:48+0000",
            "content": "@Robert, @Uwe, any more thoughts on this one?  I hate to see this derailed by one single little used Analyzer that has a workaround solution anyway.  I'm going to try to get more tests in place this weekend, or at least soon. ",
            "author": "Grant Ingersoll",
            "id": "comment-13423089"
        },
        {
            "date": "2012-07-26T14:09:48+0000",
            "content": "For the long term I like Uwe's idea better I think rather than restricting which javadocs \nin core can link to what and restricting which files the analyzers can use.\n\nSeparately we should fix that Analyzer  ",
            "author": "Robert Muir",
            "id": "comment-13423090"
        },
        {
            "date": "2013-07-23T18:44:50+0000",
            "content": "Bulk move 4.4 issues to 4.5 and 5.0 ",
            "author": "Steve Rowe",
            "id": "comment-13717074"
        },
        {
            "date": "2014-04-16T12:54:33+0000",
            "content": "Move issue to Lucene 4.9. ",
            "author": "Uwe Schindler",
            "id": "comment-13970796"
        }
    ]
}