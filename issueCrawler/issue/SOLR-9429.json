{
    "id": "SOLR-9429",
    "title": "Spellcheck Token Filter",
    "details": {
        "components": [
            "Schema and Analysis"
        ],
        "type": "New Feature",
        "labels": "",
        "fix_versions": [],
        "affect_versions": "None",
        "status": "Open",
        "resolution": "Unresolved",
        "priority": "Minor"
    },
    "description": "This issue is about the design and implementation of a new token filter called : SpellcheckTokenFilter\n\nThis new token filter takes in input the token stream and return collated tokens, based on a Dictionary.\nThe aim of the token filter is to fix mispelled word and index the correct token.\n\ne.g.\nGiven dictionary d1 :\ngaming\ngamer\n\nGiven text t1 for the field f1 :\ngamign is a strong industry\n\nThe token filter will return in output :\ngaming is a strong industry\n\nA first possible design is to mimic the approach used in the spellchecker.\nBuilding an FST for the dictionary, then building the levenstein FST for each token and doing the intersection .\n\nPossible application could be for OCR generated text and other use cases when misspelled words are common and we want to clean them up at indexing time.\nThis can possibly be used in a complex analyser adding a stemmer afterward.\n\nThis is draft idea coming from a blog comment of Shyamsunder.\nFeedback and additional ideas are welcome!",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "date": "2016-08-23T22:24:20+0000",
            "author": "David Smiley",
            "content": "Please provide a link the the blog post when you have it; I'm not sure what this issue is about. ",
            "id": "comment-15433755"
        },
        {
            "date": "2016-08-24T08:47:04+0000",
            "author": "Alessandro Benedetti",
            "content": "Hi David, I updated the description, unfortunately It is not an entire blog post but only a blog comment, it is related a possible application at autocompletion time.\n\nI was checking in Solr and Lucene token filters to see if any of them was doing this out of the box, but I didn't find one.\nBlog post ( related autocompletion) :\n\nhttp://alexbenedetti.blogspot.co.uk/2015/07/solr-you-complete-me.html\n\nThe original conversation :\n\"About getting matches for \"Video gamign\" using FuzzyLookupFactory, what if we apply analysis on spelling correction of \"gamign\", i.e., \"gaming\" to get stemmed tokens. This way we get results.\n\nAlessandro Benedetti23 August 2016 at 10:52\nHi Shyamsunder, you mean using an analyzer that performs spell correction ( dictionary based ? ) and then stemming ?\nIt could be possible.\nFirst we define a TokenFilter that does the spell correction based on a dictionary ( it is actually a good idea, but I think it doesn't exist out of the box).\nThen we can specify a stemming token filter, and the game is done.\n\nThis is actually a good idea, and can be potentially useful is a number of use cases :\n\nhttps://issues.apache.org/jira/browse/SOLR-9429\n\nShyamsunder23 August 2016 at 23:14\nYou got it. Thanks for considering my idea. \"\n ",
            "id": "comment-15434509"
        },
        {
            "date": "2016-08-24T13:13:18+0000",
            "author": "David Smiley",
            "content": "Ha! Neat idea.  I have no idea if in-practice it's actually a good idea or not but it's clever nonetheless.  I suspect one would want only very high confidence typos resolved in this way.... and that you might want the original uncorrected word somehow stored in some way, perhaps in a payload or perhaps index both such that this proposed token filter introduces synonyms, leaving the original dubious word in place.\n\nSomething like this could be contributed to the Lucene spellcheck module. ",
            "id": "comment-15434901"
        }
    ]
}