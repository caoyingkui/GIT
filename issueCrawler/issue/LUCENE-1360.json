{
    "id": "LUCENE-1360",
    "title": "A Similarity class which has unique length norms for numTerms <= 10",
    "details": {
        "labels": "",
        "priority": "Trivial",
        "components": [
            "core/query/scoring"
        ],
        "type": "Improvement",
        "fix_versions": [],
        "affect_versions": "None",
        "resolution": "Fixed",
        "status": "Resolved"
    },
    "description": "A Similarity class which extends DefaultSimilarity and simply overrides lengthNorm.  lengthNorm is implemented as a lookup for numTerms <= 10, else as 1/sqrt(numTerms). This is to avoid term counts below 11 from having the same lengthNorm after stored as a single byte in the index.\n\nThis is useful if your search is only on short fields such as titles or product descriptions.\n\nSee mailing list discussion: http://www.nabble.com/How-to-boost-the-score-higher-in-case-user-query-matches-entire-field-value-than-just-some-words-within-a-field-td19079221.html",
    "attachments": {
        "ShortFieldNormSimilarity.java": "https://issues.apache.org/jira/secure/attachment/12388688/ShortFieldNormSimilarity.java",
        "LUCENE-1380 visualization.pdf": "https://issues.apache.org/jira/secure/attachment/12425700/LUCENE-1380%20visualization.pdf",
        "LUCENE-1360.patch": "https://issues.apache.org/jira/secure/attachment/12469602/LUCENE-1360.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2009-09-24T01:52:56+0000",
            "content": "Is this code still interesting? That is, are there newer tools in Lucene that handle this problem? \n\nI have found searching movie titles, product descriptions etc. difficult to manage really well. Mainstream text retrieval research & applied tech is very strongly biased towards bodies of text.\n ",
            "author": "Lance Norskog",
            "id": "comment-12758966"
        },
        {
            "date": "2009-09-24T07:54:12+0000",
            "content": "I'm interested in this issue as well. ",
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12759054"
        },
        {
            "date": "2009-11-21T02:55:35+0000",
            "content": "This is a graph of the standard norms against the results of this patch. The orange/red dots at the left are the elevated values for boosting short documents.\n\nBoth displays show the norms after the 8-bit encode/decode process, rather than raw 1/x. Here is the code for the generator:\n\n\npublic class FloatEncode {\n\tprivate static float ARR[] = { 0.0f, 1.5f, 1.25f, 1.0f, 0.875f, 0.75f, \n\t\t\t0.625f, 0.5f, 0.4375f, 0.375f, 0.3125f};\n\n\tpublic static void main(String[] args) {\n\t\tfor(int i = 1; i < 100; i++) {\n\t\t\tfloat f = i;\n\t\t\tf = 1/f;\n\t\t\tbyte b = SmallFloat.floatToByte315(f);\n\t\t\tfloat f2 = SmallFloat.byte315ToFloat(b);\n\t\t\tfloat ff = f2;\n\t\t\tif (i < ARR.length)\n\t\t\t\tff = ARR[i];\n\t\t\tSystem.out.println(i + \",\" + f2 + \",\" + ff);\n\t\t}\n\n\t}\n}\n\n\n\n(Please pretend I named it LUCENE-1360 instead of LUCENE-1380.) ",
            "author": "Lance Norskog",
            "id": "comment-12780897"
        },
        {
            "date": "2011-01-25T13:25:33+0000",
            "content": "Now that we have custom norm encoders, is this one obselete? \nyou can just use SmallFloat.floatToByte52 to enc/dec your norms? ",
            "author": "Robert Muir",
            "id": "comment-12986378"
        },
        {
            "date": "2011-01-27T20:26:34+0000",
            "content": "The current default Solr configuration uses the standard academic formula for indexed field norms. Unfortunately, that value is packed in such a way that it gives the same value for 1-10 words in a field. This makes it useless with short fields like book & movie titles.\n\nHere's the high-level request: the Solr default configuration should supply field norms that work well with very short fields. We should not need to change the configuration at all.\n ",
            "author": "Lance Norskog",
            "id": "comment-12987742"
        },
        {
            "date": "2011-01-27T21:04:56+0000",
            "content": "Unfortunately, that value is packed in such a way that it gives the same value for 1-10 words in a field.\n\nLance, this is a bit misleading. only lengths \n{3,4}\n , \n{6,7}\n, and \n{8,9,10}\n share the same values.\n\nFor most uses, this isn't really that big of a deal that a few numbers quantize to the same bytes.\n\nIf you care about this, use SmallFloat.floatToByte52/byteToFloat52 as I suggested. Then they are all unique.\n\nYou can also do this on a per-field basis now, e.g. only for your small-fields... thats why I recommended we close this issue as obselete. ",
            "author": "Robert Muir",
            "id": "comment-12987757"
        },
        {
            "date": "2011-01-27T21:13:48+0000",
            "content": "Lance, this is a bit misleading. only lengths {3,4} , {6,7}, and {8,9,10} share the same values.\nI thought I got them all the same when I tested with Lucene 2.9, but ok.\nFor most uses, this isn't really that big of a deal that a few numbers quantize to the same bytes.\nThe problem is then the curve of how much field norms affect boosting. \n\nSure, close this. My goal is to make Solr work smoothly in all environments.\n\nLance ",
            "author": "Lance Norskog",
            "id": "comment-12987763"
        },
        {
            "date": "2011-01-27T21:21:20+0000",
            "content": "In my opinion, the best thing to do would be to open an issue\nfor better per-field Similarity integration into the solr schema.\n\nCurrently you can pass a SimProvider to the 'global' SimilarityFactory for the entire schema.\nin this java code you would have to e.g. make a hashset with \"smallfield1\", \"smallfield2\", \"smallfield3\",\nand return SmallFloatSimilarity for these.\n\nInstead, it would be better if the FieldType? (dunno if this is even the best)\ncould simply have similarity=SmallFloatSimilarity or whatever, so that the specification is more declarative.\n\nThen solr could have an example 'short field type' FieldType in the example schema.\n(with the tradeoffs of the fact floatToByte52 maxes out at 1984, so don't use for large fields or big boosts).\n\nThis way, people could make their metadata fields of this smalltype, but their large document fields\nstill use the ordinary text type (e.g. guys like Hathitrust with some enormous fields), and everything in \ntheir application works, they just get quantization that makes sense for each field...  ",
            "author": "Robert Muir",
            "id": "comment-12987766"
        },
        {
            "date": "2011-01-27T21:52:27+0000",
            "content": "Lance, here's a patch with the similarity i suggested, for lucene's contrib with a unit test.\n\nThen, i think as i mentioned earlier (also on LUCENE-2236), we should create a Solr\nissue to make per-field similarity more declarative and add an example short field type. ",
            "author": "Robert Muir",
            "id": "comment-12987781"
        },
        {
            "date": "2011-01-27T22:58:58+0000",
            "content": "Cool! Looks great.\n ",
            "author": "Lance Norskog",
            "id": "comment-12987813"
        },
        {
            "date": "2011-01-27T23:28:35+0000",
            "content": "The only issue i have with the floatToByte52 is its a 'trap' so to speak,\nthat if you use it on a too-long field (or maybe too-small boost), you end\nout with a norm of zero.\n\nIn my opinion, the whole purpose of per-field support is so that you don't\nhave to make these sort of tradeoffs, but i imagine someone could\nuse an inappropriate similarity/schema sometime (misconfiguration)\n\nto degrade better in this case, I suggest this change, which decodes 0-byte norms\nas if they were 1-byte, so that scores won't be zeroed in the misconfiguration case...\n\nchange:\n\n\n  static {\n    for (int i = 0; i < 256; i++)\n      NORM_TABLE[i] = SmallFloat.byte52ToFloat((byte)i);\n  }\n\n\n\nto:\n\n\n  static {\n    NORM_TABLE[0] = SmallFloat.byte52ToFloat((byte)1);\n    for (int i = 1; i < 256; i++)\n      NORM_TABLE[i] = SmallFloat.byte52ToFloat((byte)i);\n  }\n\n ",
            "author": "Robert Muir",
            "id": "comment-12987824"
        },
        {
            "date": "2018-09-19T13:42:06+0000",
            "content": "Lengths are recorded accurately up to a length of 40 since 7.0 thanks to LUCENE-7730. ",
            "author": "Adrien Grand",
            "id": "comment-16620597"
        }
    ]
}