{
    "id": "SOLR-9552",
    "title": "Upgrade to Tika 1.14 when available",
    "details": {
        "components": [
            "contrib - DataImportHandler"
        ],
        "type": "Improvement",
        "labels": "",
        "fix_versions": [],
        "affect_versions": "None",
        "status": "Resolved",
        "resolution": "Duplicate",
        "priority": "Major"
    },
    "description": "Let's upgrade Solr as soon as 1.14 is available.\n\nP.S. I think we're soon to wrap up work on 1.14.  Any last requests?",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "date": "2016-11-10T15:16:20+0000",
            "author": "Tim Allison",
            "content": "Tika 1.14 is now available.  We should upgrade soon because of a CVE in Tika (<1.14)'s Matlab parser. ",
            "id": "comment-15654302"
        },
        {
            "date": "2016-11-11T01:15:38+0000",
            "author": "Tim Allison",
            "content": "For those who want to turn off the Matlab parser in versions before 1.14, try something like this with your tika-config file:\n\n\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<properties>\n  <parsers>\n    <parser class=\"org.apache.tika.parser.DefaultParser\">\n      <parser-exclude class=\"org.apache.tika.parser.mat.MatParser\"/>\n    </parser>\n  </parsers>\n</properties>\n\n ",
            "id": "comment-15655740"
        },
        {
            "date": "2016-11-11T02:09:47+0000",
            "author": "Alexandre Rafalovitch",
            "content": "Does Solr actually exposes configuration of Tika via tika-config? I am not sure I've seen any examples of that. ",
            "id": "comment-15655865"
        },
        {
            "date": "2016-11-11T02:53:39+0000",
            "author": "Tim Allison",
            "content": "https://wiki.apache.org/solr/TikaEntityProcessor See tika-config. ",
            "id": "comment-15655934"
        },
        {
            "date": "2016-11-16T12:31:16+0000",
            "author": "Tim Allison",
            "content": "Make sure not to include the grobid parser because of change in ASF's determination on json.org.  See this on user@ and TIKA-1804. ",
            "id": "comment-15670318"
        },
        {
            "date": "2017-02-06T16:53:48+0000",
            "author": "Tim Allison",
            "content": "Make sure to include curvesapi ",
            "id": "comment-15854344"
        },
        {
            "date": "2017-03-21T04:20:44+0000",
            "author": "Yasufumi Mizoguchi",
            "content": "I wanna know the blocker of this.\nBecause this is required to avoid CVE-2017-5644 of Apache POI, I think. ",
            "id": "comment-15934075"
        },
        {
            "date": "2017-03-21T12:09:48+0000",
            "author": "Shawn Heisey",
            "content": "Yasufumi Mizoguchi, Inclusion of Tika in Solr is only a convenience.  The extracting request handler is not intended for intense production usage.\n\nBecause Tika can be unstable and can cause Solr to crash or misbehave, we strongly recommend that production installs incorporate Tika into a client indexing program that you write yourself, so that when Tika inevitably self-destructs, your search engine will not be affected.\n\nTim Allison, I do apologize for any disparagement of your work, but I think you might agree with the idea that Tika belongs outside critical infrastructure software. ",
            "id": "comment-15934531"
        },
        {
            "date": "2017-03-21T12:38:40+0000",
            "author": "Tim Allison",
            "content": "Shawn Heisey, thank you for your kind words, but I don't take that as disparagement at all.  I take that as respect for my consistent message.  \n\nTo quote myself:\n\nI concur with Erick and Upayavira that it is best to keep Tika in a separate JVM...well, ideally a separate box or rack or even data center.  \n\nThat said, I think we could do a better job in Solr of warning users that embedded Tika is there to make indexing look easy...ease the learning curve.  \n\nI strongly support all of Alexandre Rafalovitch's work to simplify the Tika integration.\n\nTo Yasufumi Mizoguchi's point, Tika 1.13 which is in Solr now, uses POI 3.15-beta1, which is after that particular CVE (\"prior to version 3.15\").  If I understand correctly, that vulnerability was fixed when we switched out the piccolo parser for xerces in r1734182.  This fix made it into POI 3.15-beta1. Dominik Stadler, please confirm.\n\nSo, y, we should upgrade to Tika 1.14 ASAP, but more for the MATLAB CVE and general improvements, not because of: CVE-2017-5644. ",
            "id": "comment-15934556"
        },
        {
            "date": "2017-03-21T12:43:51+0000",
            "author": "Tim Allison",
            "content": "Would have been quicker to put together the patch...sorry.  Will turn to that today or tomorrow. ",
            "id": "comment-15934566"
        },
        {
            "date": "2017-03-21T16:22:52+0000",
            "author": "ASF GitHub Bot",
            "content": "GitHub user tballison opened a pull request:\n\n    https://github.com/apache/lucene-solr/pull/172\n\n    SOLR-9552\n\n    Upgrade to Tika 1.14\n\nYou can merge this pull request into a Git repository by running:\n\n    $ git pull https://github.com/tballison/lucene-solr SOLR-9552\n\nAlternatively you can review and apply these changes as the patch at:\n\n    https://github.com/apache/lucene-solr/pull/172.patch\n\nTo close this pull request, make a commit to your master/trunk branch\nwith (at least) the following in the commit message:\n\n    This closes #172\n\n\ncommit 1f42a1553b51bfff6a07683853a2ca7be5164c18\nAuthor: tballison <tallison@mitre.org>\nDate:   2017-03-21T16:22:01Z\n\n    SOLR-9552 - upgrade Tika to 1.14, first pass\n\n ",
            "id": "comment-15934826"
        },
        {
            "date": "2017-03-21T16:26:11+0000",
            "author": "Tim Allison",
            "content": "Now I remember why I had been putting this off (SOLR-8981)\n\nMany thanks to Uwe Schindler for holding my hand last time!\n\nI haven't yet tested this on Linux...er, I haven't fully tested this yet.\n\nant precommit appeared to go into a permanent hang when checking for broken html, but the earlier steps passed \n\nAs before, I didn't touch bouncycastle.  ",
            "id": "comment-15934832"
        },
        {
            "date": "2017-03-21T17:20:00+0000",
            "author": "Alexandre Rafalovitch",
            "content": "Question on the Integration: how much of \"Tika\" is actually shipped with Solr. I am guessing Tika has a bunch of extension libraries that Solr does not include by default. So, is there an easy way to figure out what IS included? I am mostly thinking of it in terms of exposing more recent/cool Tika functionality in Solr examples better, but also to just understand the situation more generally. ",
            "id": "comment-15934920"
        },
        {
            "date": "2017-03-21T17:40:53+0000",
            "author": "Tim Allison",
            "content": "So, is there an easy way to figure out what IS included?\n\nNo.  That's another aspect of the Solr integration that unsettles me.  Users think they're getting the full Tika, but they aren't.\n\nWith each update, the committer decides which dependencies and therefore which parsers to include.  From what I can tell, Solr does not include:\n1) Anything with \"optional\" dependencies that are not consistent with Apache 2.0 (makes complete sense)\n2) Anything with native libs\n3) Image parsers (webp), except when it does, e.g. drewnoakes' metadata-extractor or Tesseract if the user has it installed.\n\nI'm frankly not sure what happens with Grobid or some of the \"advanced\" parsers. See below.\n\nI am guessing Tika has a bunch of extension libraries that Solr does not include by default.\nTo be fair to Solr, there aren't that many parsers that are missing.\n\n\n\tSqlite \u2013 native libs, users of Tika have to remember to add xerial's jar to their classpath anyhow...So do Solr users.\n\tImage types that require non-ASL friendly licenses (see PDFBox); again, Tika users have to put those on their classpath, too\n\tWebp, mentioned above\n\tGrobid \n\tCTakes \n\tenvi, gdal, geo.topic, geoinfo (??)\n\tPooledTimeSeriesParser (??)\n\tTensorflow object recognizer (??)\n\n\n\nChris A. Mattmann, any idea what happens to these in Solr? ",
            "id": "comment-15934966"
        },
        {
            "date": "2017-03-21T17:46:01+0000",
            "author": "Alexandre Rafalovitch",
            "content": "Is this something that could be improved with a GSOC2017 project? I'd be happy to be the secondary mentor on the Solr side. ",
            "id": "comment-15934971"
        },
        {
            "date": "2017-03-21T17:47:10+0000",
            "author": "Karl Wright",
            "content": "Tim Allison: We have exactly the same problem in the ManifoldCF project.  The Tika dependencies are a nightmare to maintain for Apache projects that embed Tika.\n\nI would love to have a bright line between parsers that are well-behaved, pure java, and Apache license compatible, and parsers that place special requirements on Tika users.  Maybe a separate jar for the latter? ",
            "id": "comment-15934973"
        },
        {
            "date": "2017-03-21T18:05:07+0000",
            "author": "Tim Allison",
            "content": "Um, sure, we call it Tika 2.0. Do take a look at that branch and please do contribute to the design.  Let us know if that will meet your needs.\n\nShawn Heisey already mentioned the key problem.  Even if there is a clean break in the design between native libs and non-native libs, and even though we're now running Tika against a TB of data (3 million files) from Common Crawl before we do a release, and even though we try to be as responsive as we possibly can to JIRA issues about Tika behaving badly, some parser at some point is going to do something awful (OOM blow out, permanent hang, execute malicious code, slow burning memory leak, etc...things that cannot be handled by catch blocks and asking a Thread to kindly stop), so it is better to keep Tika in a separate JVM via tika-server or encapsulate it in another way: tika-batch (spawns a child process) or ForkParser (child jar and child process).\n\nIn short, Karl Wright, I regret that there is no bright line between well-behaved and ill-behaved parsers.  There is a bright line between native libs and non-Apache friendly parsers...users have to know about them and \"opt in\".  But anything else we can do to help ManifoldCF, let us know!\n\nThere are a few things that are holding up 2.0 (e.g., I've chosen to work on tactical issues instead of the more strategic 2.0 stuff), but take a look at the architecture and see if it's something that makes sense.\n\nAs for GSOC, yes, please, please, please let a bright GSOC'er figure out how to integrate Tika at a distance, whether that's through tika-server (SOLR-7632) or some other means.\n\nAnd, y, please let the same or another GSOC'er figure out how allow handling of child documents and their metadata (SOLR-7229).\n\nOh, and if you have some extra GSOC cycles, there's always TIKA-1443. \n\nI'm more than happy to chip in on all of the above. ",
            "id": "comment-15934996"
        },
        {
            "date": "2017-03-21T18:24:56+0000",
            "author": "Tim Allison",
            "content": "Back to SOLR-9552, ant precommit worked on my PR in both Windows and Linux.\n\nI didn't even bother with a full build in Windows.  The full build ant clean test jar had a failure in Linux, but I can't imagine that the PR caused this problem.\n\n\nTests with failures [seed: 4FCAE095E1FD28E8]:\n   [junit4]   - org.apache.solr.cloud.ZkSolrClientTest.testMultipleWatchesAsync\n\ncommon-build.xml:985: There were test failures: 701 suites (8 ignored), 3145 tests, 1 failure, 115 ignored (101 assumptions) [seed: 4FCAE095E1FD28E8]\n\n ",
            "id": "comment-15935023"
        },
        {
            "date": "2017-03-21T18:32:32+0000",
            "author": "Karl Wright",
            "content": "[~Tim Allison] ManifoldCF is actually well suited to dealing with Tika as a service.  Tika-core is currently included in the base framework, but tika-parsers is referenced only by a transformation connector, which could well be \"remoted\" to such a service.  If there was a \"get up and running fast\" service install that used streaming and didn't require large chunks of data or extracted text to hit memory, that might well be the ideal operating mode for MCF users.\n\nI'll try to look at Tika 2.0 and give feedback as time permits.  Thanks! ",
            "id": "comment-15935077"
        },
        {
            "date": "2017-03-22T00:55:12+0000",
            "author": "Yasufumi Mizoguchi",
            "content": "Shawn Heisey, Thank you for your valuable advice. \n\n[~tallison@mitre.org], Thank you. I'll check whether POI 3.15-beta1 contains r1734182, and whether that resolve the vulnerability. ",
            "id": "comment-15935595"
        },
        {
            "date": "2017-03-22T11:37:48+0000",
            "author": "Tim Allison",
            "content": "Yasufumi Mizoguchi, y, Shawn's advice is very valuable.  See Erick Erickson's excellent post on writing your own indexer with Solrj: https://lucidworks.com/2012/02/14/indexing-with-solrj/  ",
            "id": "comment-15936155"
        },
        {
            "date": "2017-03-22T12:33:11+0000",
            "author": "David Smiley",
            "content": "BTW, sporadic build failures are unfortunately kinda normal.  If you feel confident the test that failed is completely unrelated then you might just dismiss it.  Bonus points for trying to repeat the failed test to see if it reproduces (see the \"ant test ...\" line), and then file a JIRA (see if there's an existing issue of course) if it does.  There is some heroic work Mark Miller is doing to bring more sanity to the situation. ",
            "id": "comment-15936216"
        },
        {
            "date": "2017-03-22T12:41:27+0000",
            "author": "Tim Allison",
            "content": "Thank you, David, that was my memory.  And I'm still right not even to bother with a full build on Windows, right? ",
            "id": "comment-15936221"
        },
        {
            "date": "2017-03-22T12:57:35+0000",
            "author": "David Smiley",
            "content": "It doesn't matter what build platform you test with in general. If you think this issue is prone to have platform specific considerations, then testing more broadly would be great.\n\nCanonical contribution info is here:  https://wiki.apache.org/solr/HowToContribute  It includes info about the sporadic failing tests.  I tweaked this page a bit today. ",
            "id": "comment-15936250"
        }
    ]
}