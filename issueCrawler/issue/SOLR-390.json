{
    "id": "SOLR-390",
    "title": "HashDocSet initialization of internal array is not efficient",
    "details": {
        "affect_versions": "None",
        "status": "Closed",
        "fix_versions": [],
        "components": [
            "search"
        ],
        "type": "Bug",
        "priority": "Major",
        "labels": "",
        "resolution": "Cannot Reproduce"
    },
    "description": "HashDocSet initializes the internal array but iterating it instead of using Arrays.fill which is much faster. Patch included",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "author": "John Wang",
            "id": "comment-12537051",
            "date": "2007-10-23T16:00:30+0000",
            "content": "I am having problems with \"Attach file\"\nFollowing is the patch:\nIndex: /Users/john/plum/solr-trunk/src/java/org/apache/solr/search/HashDocSet.java\n===================================================================\n\u2014 /Users/john/plum/solr-trunk/src/java/org/apache/solr/search/HashDocSet.java (revision 587538)\n+++ /Users/john/plum/solr-trunk/src/java/org/apache/solr/search/HashDocSet.java (working copy)\n@@ -17,6 +17,8 @@\n\n package org.apache.solr.search;\n\n+import java.util.Arrays;\n+\n import org.apache.solr.util.BitUtil;\n\n\n@@ -63,8 +65,8 @@\n     mask=tsize-1;\n\n     table = new int[tsize];\n\n\tfor (int i=tsize-1; i>=0; i--) table[i]=EMPTY;\n-\n+    //for (int i=tsize-1; i>=0; i--) table[i]=EMPTY;\n+    Arrays.fill(table, EMPTY);\n     for (int i=offset; i<len; i++) \n{\n       put(docs[i]);\n     }\n\n\n "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12537055",
            "date": "2007-10-23T16:15:52+0000",
            "content": "That's interesting... does it actually test as faster for you?  Have any JVMs finally done specific optimizations for it?\nIn the past, my version was always a little faster because counting down to zero can be slightly faster (no explicit compare needed in many instruction sets because the flags are often set by arithmetic operations anyway). "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12537062",
            "date": "2007-10-23T16:39:27+0000",
            "content": "As I suspected, it doesn't look like there is yet any JVM acceleration for Arrays.fill() (and I wouldn't hold my breath).\nI just tested with Java 1.6 -server, and my current method appears about 88% faster (on a P4 at least).\n\nI used an array size of 1000 (since HashDocSet will normally be between 1 and 3000),\nand 10,000,000 iterations.\n\nexplicit loop countdown =>  9281 msec\nArrays.fill => 17515 msec\n\n\npublic class TestPerf {\n\n  private static int VAL=-1;\n\n  private static void fill(int[] x) {\n/*\n    for (int i=x.length-1; i>=0; i--) {\n      x[i] = VAL;\n    }\n*/\n    Arrays.fill(x,VAL);\n  }\n\n\n  public static void main(String[] args) {\n    int a=0;\n    int sz = Integer.parseInt(args[a++]);\n    int iter = Integer.parseInt(args[a++]);\n    int[] x = new int[sz];\n    int ret=0;\n    long start = System.currentTimeMillis();\n    for (int i=0; i<iter; i++) {\n      fill(x);\n      ret = ret + x[0];  // use results\n    }\n    long end = System.currentTimeMillis();\n    System.out.println(\"result=\" + ret);\n    System.out.println(\"time=\" +(end-start));\n  }\n}\n\n "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12537171",
            "date": "2007-10-23T23:49:01+0000",
            "content": "I did some further tests with mixed results...\nAfter modifying the test program to do fill() on multiple arrays per iteration (and using an element from each array to try and prevent any dead code elimination), the benefit of the inlined loop vanishes (sneaky hotspot). Sometimes the Arrays.fill() version was faster, and sometimes it wasn't.  So perhaps a real test is needed here.\n "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12537179",
            "date": "2007-10-24T00:24:33+0000",
            "content": "Doing a quick HashDocSet construction test (below) showed the loop to be slightly faster on average than Arrays.fill()... I have no idea why, but I'll close this bug for now and it can be reopened if someone comes up with a better test (or tests on different JVMs, etc).\n\n\npublic class TestPerf {\n\n  private static int VAL=-1;\n\n  private static int go(int[] x) {\n    HashDocSet ds = new HashDocSet(x,0,x.length);\n    return ds.exists(1) ? 1 : 0;\n  }\n\n\n  public static void main(String[] args) {\n    int a=0;\n    int sz = Integer.parseInt(args[a++]);\n    int iter = Integer.parseInt(args[a++]);\n    int[] x = new int[sz];\n    int[] x2 = new int[sz];\n    for (int ii=0; ii<sz; ii++) {\n      x[ii]=ii*1234567891;\n      x2[ii]=ii*987654323;\n    }\n\n    int ret=0;\n    long start = System.currentTimeMillis();\n    int num=0;\n    for (int i=0; i<iter; i++) {\n      if (++num>=sz) num=0;\n      x[num] += go(x)+ret+x2[num];\n      ret += go(x2) + x2[num]++;\n    }\n    long end = System.currentTimeMillis();\n    System.out.println(\"result=\" + ret);\n    System.out.println(\"time=\" +(end-start));\n  }\n}\n\n "
        },
        {
            "author": "John Wang",
            "id": "comment-12539863",
            "date": "2007-11-03T05:42:40+0000",
            "content": "Hi Yonik:\n    With my tests, for large arrays, e.g. 2M entries, there is a 14% gain.\nBut it is 14% out of a small number, so I guess it is not a big deal. Sorry\nfor the false alarm.\n\n-John\n "
        }
    ]
}