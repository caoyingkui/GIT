{
    "id": "SOLR-3716",
    "title": "Make SolrResourceLoaders ClassLoader available as context class loader",
    "details": {
        "affect_versions": "None",
        "status": "Open",
        "fix_versions": [],
        "components": [
            "scripts and tools"
        ],
        "type": "Bug",
        "priority": "Major",
        "labels": "",
        "resolution": "Unresolved"
    },
    "description": "SOLR-1725 and other issues (recent changes to analysis factories and codecs) make it possible to plug in extensions like analyzer factories, codecs, scripting engines or TIKA parsers (TIKA extraction plugin!!!) as SPIs. The current problem (we solved this alreeady for codecs and analyzer factories with a classloader-reload hack: LUCENE-4259) is the following:\n\nYou have to unpack WAR file and repack with the missing JAR files. If you would do it the \"solr way\" and put those jars into the $SOLR_HOME/lib folder like plugins, they are not seen. The problem is that plugins loaded by solr are loaded using SolrResourceLoader's classloader (configureable via solrconfig.xml), but as this classloader is not also context classloader, SPI does not look into it, so scripting engines, TIKA plugins, (previously codecs) are not seen.\n\nWe should investigate how to manage setting the context classloader of all threads solr ever sees to point to our own solr classloader.\n\nWhen we do this, I also suggest to only ship with TIKA core libs but not tika-parsers and the big dependency hell. TIKA parsers are also loaded via SPI, so user can download the TIKA parser distribution and drop into $SOLR_HOME/lib. By that a user can also use only those extraction plugins really needed. The current solr distribution only consists of mostly useless JAR files (for many users) for Solr Extraction handler. We dont need to ship with all of them, we can just tell the user how to \"install\" the needed SPIs. The same for analysis-extras (user only needs to copy morphologic JAR or smartchinese JAR into $SOLR_HOME/lib - this works already!!!). No need for the \"hull contrib\". Scripting engines is the same.\n\nWe should just ship with some scripts (ANT based) to download the JAR files into $SOLR_HOME.",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "author": "Lance Norskog",
            "id": "comment-13429653",
            "date": "2012-08-07T01:37:08+0000",
            "content": "Thanks for flushing out another problem in how classpaths work.\n\nI have a small question: how would I add a Java SecurityManager class into this mix? I would like to set a security manager object for each core that governs the activities of code in that core: loading a 3-megabyte synonym file, loading a jar file that calls out to the DHS, whatever. (Why? A hosted Solr business is a lot easier if you can run someone's collection configs in a sandbox.) "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13429802",
            "date": "2012-08-07T03:43:10+0000",
            "content": "rmuir20120906-bulk-40-change "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13451183",
            "date": "2012-09-08T00:35:19+0000",
            "content": "removing fixVersion=4.0 since there is no evidence that anyone is currently working on this issue.  (this can certainly be revisited if volunteers step forward)\n\n "
        },
        {
            "author": "Lance Norskog",
            "id": "comment-13490429",
            "date": "2012-11-05T03:37:57+0000",
            "content": "SOLR-4007 appears to be a fix for this problem only for the Polish-language Morfologik toolkit.\n "
        }
    ]
}