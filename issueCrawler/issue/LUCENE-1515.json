{
    "id": "LUCENE-1515",
    "title": "Improved(?) Swedish snowball stemmer",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [
            "modules/analysis"
        ],
        "type": "New Feature",
        "fix_versions": [],
        "affect_versions": "2.4",
        "resolution": "Unresolved",
        "status": "Reopened"
    },
    "description": "Snowball stemmer for Swedish lacks support for '-an' and '-ans' related suffix stripping, ending up with non compatible stems for example \"klocka\", \"klockor\", \"klockornas\", \"klockAN\", \"klockANS\".  Complete list of new suffix stripping rules:\n\n{pre}\n            'an' 'anen' 'anens' 'anare' 'aner' 'anerna' 'anernas'\n            'ans' 'ansen' 'ansens' 'anser' 'ansera'  'anserar' 'anserna' 'ansernas'\n            'iera'\n                (delete){pre}\n\nThe problem is all the exceptions (e.g. svans|svan, finans|fin, nyans|ny) and this is an attempt at solving that problem. The rules and exceptions are based on the SAOL entries suffixed with 'an' and 'ans'. There a few known problematic stemming rules but seems to work quite a bit better than the current SwedishStemmer. It would not be a bad idea to check all of SAOL entries in order to make sure the integrity of the rules.\n\nMy Snowball syntax skills are rather limited so I'm certain the code could be optimized quite a bit.\n\nThe code is released under BSD and not ASL. I've been posting a bit in the Snowball forum and privatly to Martin Porter himself but never got any response so now I post it here instead in hope for some momentum.",
    "attachments": {
        "LUCENE-1515.txt": "https://issues.apache.org/jira/secure/attachment/12397546/LUCENE-1515.txt"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2009-01-09T18:48:18+0000",
            "content": "snowball code, generated java class and unit test. ",
            "author": "Karl Wettin",
            "id": "comment-12662468"
        },
        {
            "date": "2010-01-03T12:43:18+0000",
            "content": "I've added a few more rules. I'll have to add a few more tests etc before I post a new patch.\n\n\n    define main_suffix as (\n        setlimit tomark p1 for ([substring])\n        among(\n            'a' 'arna' 'erna' 'heterna' 'orna' 'ad' 'e' 'ade' 'ande' 'arne'\n            'are' 'aste' 'en' 'anden' 'aren' 'heten' 'ern' 'ar' 'er' 'heter'\n            'or' 'as' 'arnas' 'ernas' 'ornas' 'es' 'ades' 'andes' 'ens' 'arens'\n            'hetens' 'erns' 'at' 'andet' 'het' 'ast'\n            'era' 'erar' 'erarna' 'erarnas' \n            // augmentation starts here\n            'an' 'anen' 'anens' 'anare' 'aner' 'anerna' 'anernas'\n            'ans' 'ansen' 'ansens' 'anser' 'ansera'  'anserar' 'anserna' 'ansernas'\n            'iera' 'ierat' 'ierats' 'ierad' 'ierade' 'ierades'\n            'ikation'\n            'ikat' 'ikatet' 'ikatets' 'ikaten' 'ikatens'\n            // augmentation ends here\n                (delete)\n                \n            's'\n                (s_ending delete)\n\n\n ",
            "author": "Karl Wettin",
            "id": "comment-12795967"
        },
        {
            "date": "2010-01-03T12:44:38+0000",
            "content": "I just posted this to the Snowball users list:\n\nThe Swedish Snowball stemmer does a terrible job according to <http://web.jhu.edu/bin/q/b/p75-mcnamee.pdf>. It even claims that lfs5, i.e. substring(0,5), does a better job. (It also says that 5-grams cracks the nut.)\n\nThis didn't come as surprise to me as I've identified problems in the past and implemented my own augmentation that's been posted to this list before, now living at <http://issues.apache.org/jira/browse/LUCENE-1515>.\n\nReading the paper made me take a closer look at what's wrong.\n\n    define main_suffix as (\n        setlimit tomark p1 for ([substring])\n        among(\n            'a' 'arna' 'erna' 'heterna' 'orna' 'ad' 'e' 'ade' 'ande' 'arne'\n            'are' 'aste' 'en' 'anden' 'aren' 'heten' 'ern' 'ar' 'er' 'heter'\n            'or' 'as' 'arnas' 'ernas' 'ornas' 'es' 'ades' 'andes' 'ens' 'arens'\n            'hetens' 'erns' 'at' 'andet' 'het' 'ast'\n            'era' 'erar' 'erarna' 'erarnas' \n            // augmentation starts here\n            'an' 'anen' 'anens' 'anare' 'aner' 'anerna' 'anernas'\n            'ans' 'ansen' 'ansens' 'anser' 'ansera'  'anserar' 'anserna' 'ansernas'\n            'iera' 'ierat' 'ierats' 'ierad' 'ierade' 'ierades'\n            'ikation'\n            'ikat' 'ikatet' 'ikatets' 'ikaten' 'ikatens'\n            // augmentation ends here\n                (delete)\n\n            's'\n                (s_ending delete)\n\n\n\nIn conjunction with ~200 exception rules these additions help. There are however quite a bit of problems with many of the old rules.\n\n\nE.g. 's' (s_ending delete) is a pluralis rule but have ~5300 exceptions where words ends with s is nominative case singularis. The problem is when written in other form than nominative case. \n\nkurs (course)\nkursen (the course)\nkursens (the [undefined noun] of the course)\nkurser (courses)\nkurserna (the courses)\nkursernas (the [undefined noun] of the courses)\n\nKurs is stemmed to \"kur\" (which by the way will missmatch with kur as in remedy) while all the others are correctly stemmed as \"kurs\".\n\nAll together there are, according to my estimation, some 10 000 words that will create incompatible stems between nominative case singularis and any other form. That is about 8% of the official language. \n\nOne rather simple solution is to always use both unstemmed and stemmed words, e.g. as synonyms in an inverted index. But if only using the stemmed output (from the official stemmer or my augmentation) I'd argue it's better to skip stemming all together.\n\nA better solution would be to set up the stemmer to ignore the 10 000 exceptions. What would be the best way to implement this? I'd like the generated Java code to simply contain a HashSet<String> noStemExceptions; that was checked first, or something like that. ",
            "author": "Karl Wettin",
            "id": "comment-12795968"
        },
        {
            "date": "2010-01-04T03:39:53+0000",
            "content": "A better solution would be to set up the stemmer to ignore the 10 000 exceptions. What would be the best way to implement this? I'd like the generated Java code to simply contain a HashSet<String> noStemExceptions; that was checked first, or something like that.\n\nHi Karl, in my opinion the best way to handle this would be outside of Snowball itself. This is really a problem beyond swedish and even the snowball stemmers: I think for many cases (other languages) people might have a list of 'protected words' they do not want the stemmer to mess with. Examples are common proper names, things like that.\n\nThis is currently a mess in my opinion:\n\n\tSolr has this functionality, but only for snowball, etc because they do not actually use lucene's snowballfilter! Instead they have their own implementation (duplicate code)\n\tin some cases, our non-snowball stemmers support this: take a look at BrazilianStemmer, it has Set<?> stemExclusionSet, but this is inconsistent, most of our stemmers do not actually support this.\n\n\n\nI think I would like to propose the following as a potential idea:\nJust like Simon did with the inconsistent stopword handling, we could refactor some handling into all Stemming TokenFilters (and probably also hooks into the analyzers, too) that simply allows the system to use a CharArraySet for 'stem ignore words', loaded via WordListLoader from a text file, or however.\n\nWith this, you could create a text file with these 10,000 words as a default for swedish.\nThis would remove the 'protected words' duplication from solr too in the future, and allow for protected words functionality across all stemmers. ",
            "author": "Robert Muir",
            "id": "comment-12796068"
        },
        {
            "date": "2013-11-30T13:15:01+0000",
            "content": "2013 Old JIRA cleanup ",
            "author": "Erick Erickson",
            "id": "comment-13835685"
        },
        {
            "date": "2013-11-30T13:22:15+0000",
            "content": "This is actually a rather nice stemmer if you ask me. It's semi-expensive due to the rule-set but does a much better job compared to the standard Swedish Snowball stemmer and I've successfully used it in several projects. ",
            "author": "Karl Wettin",
            "id": "comment-13835704"
        }
    ]
}