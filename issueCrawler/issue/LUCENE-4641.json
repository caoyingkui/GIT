{
    "id": "LUCENE-4641",
    "title": "Fix analyzer bugs documented in TestRandomChains",
    "details": {
        "components": [
            "modules/analysis"
        ],
        "fix_versions": [],
        "affect_versions": "None",
        "priority": "Major",
        "labels": "",
        "type": "Bug",
        "resolution": "Unresolved",
        "status": "Open"
    },
    "description": "TestRandomChains.java found a lot of bugs, some of which are hard to fix. So we blacklisted certain analysis components from the test.\n\nBut we really need to fix these, some of these bugs are bad, and they impact users with e.g. highlighting (SOLR-4137 and so on):\n\n  // TODO: fix those and remove\n  private static final Set<Class<?>> brokenComponents = Collections.newSetFromMap(new IdentityHashMap<Class<?>,Boolean>());\n  static {\n    // TODO: can we promote some of these to be only\n    // offsets offenders?\n    Collections.<Class<?>>addAll(brokenComponents,\n      // TODO: fix basetokenstreamtestcase not to trip because this one has no CharTermAtt\n      EmptyTokenizer.class,\n      // doesn't actual reset itself!\n      CachingTokenFilter.class,\n      // doesn't consume whole stream!\n      LimitTokenCountFilter.class,\n      // Not broken: we forcefully add this, so we shouldn't\n      // also randomly pick it:\n      ValidatingTokenFilter.class,\n      // NOTE: these by themselves won't cause any 'basic assertions' to fail.\n      // but see https://issues.apache.org/jira/browse/LUCENE-3920, if any \n      // tokenfilter that combines words (e.g. shingles) comes after them,\n      // this will create bogus offsets because their 'offsets go backwards',\n      // causing shingle or whatever to make a single token with a \n      // startOffset thats > its endOffset\n      // (see LUCENE-3738 for a list of other offenders here)\n      // broken!\n      NGramTokenizer.class,\n      // broken!\n      NGramTokenFilter.class,\n      // broken!\n      EdgeNGramTokenizer.class,\n      // broken!\n      EdgeNGramTokenFilter.class,\n      // broken!\n      WordDelimiterFilter.class,\n      // broken!\n      TrimFilter.class\n    );\n  }\n\n  // TODO: also fix these and remove (maybe):\n  // Classes that don't produce consistent graph offsets:\n  private static final Set<Class<?>> brokenOffsetsComponents = Collections.newSetFromMap(new IdentityHashMap<Class<?>,Boolean>());\n  static {\n    Collections.<Class<?>>addAll(brokenOffsetsComponents,\n      ReversePathHierarchyTokenizer.class,\n      PathHierarchyTokenizer.class,\n      HyphenationCompoundWordTokenFilter.class,\n      DictionaryCompoundWordTokenFilter.class,\n      // TODO: corrumpts graphs (offset consistency check):\n      PositionFilter.class,\n      // TODO: it seems to mess up offsets!?\n      WikipediaTokenizer.class,\n      // TODO: doesn't handle graph inputs\n      ThaiWordFilter.class,\n      // TODO: doesn't handle graph inputs\n      CJKBigramFilter.class,\n      // TODO: doesn't handle graph inputs (or even look at positionIncrement)\n      HyphenatedWordsFilter.class,\n      // LUCENE-4065: only if you pass 'false' to enablePositionIncrements!\n      TypeTokenFilter.class,\n      // TODO: doesn't handle graph inputs\n      CommonGramsQueryFilter.class\n    );\n  }",
    "attachments": {
        "LUCENE-4641_tests.patch": "https://issues.apache.org/jira/secure/attachment/12635494/LUCENE-4641_tests.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2014-03-19T05:40:32+0000",
            "content": "unfortunately the situation looks better than it really is.\n\nSomehow in the test framework we conflated 'broken offsets' with 'doesn't respect position length/graphs'. The former is serious (causes people today exceptions when e.g. highlighting), the latter not so much.\n\nThis castrated TestRandomChains, because it is never really checking the stuff we care about today. I fixed it in this patch, and things are angry, it seems to fail about 20% of the time. So there is more work to do. ",
            "author": "Robert Muir",
            "id": "comment-13940203"
        }
    ]
}