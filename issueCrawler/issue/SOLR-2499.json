{
    "id": "SOLR-2499",
    "title": "Index-time boosts for multivalue fields are consolidated",
    "details": {
        "affect_versions": "3.1,                                            3.2,                                            4.0-ALPHA",
        "status": "Closed",
        "fix_versions": [],
        "components": [],
        "type": "Improvement",
        "priority": "Major",
        "labels": "",
        "resolution": "Not A Problem"
    },
    "description": "Currently, if you boost a value in a multivalue field during index time, the boosts are consolidated for every field, and the individual values are lost.\n\nSo, for example, given a list of photos with a multivalue field \"keywords\", and a boost for a keyword assigned to a photo corresponds to the number of times that photo was downloaded after searching for that particular keyword, we have documents like this:\n\n\nphoto1: Photo of a cat by itself\nkeywords: [ cat:600 feline:100 ]\n=> boost total = 700\n\nphoto2: Photo of a cat driving a truck\nkeywords: [ cat:100 feline:90 animal:80 truck:1000 ]\n=> boost total = 1270\n\n\n\nIf you search for \"cat feline\", photo2 will rank higher, since the boost of \"cat-like\" words was consolidated with the \"truck\" boost anomaly. Whereas photo1, which has more downloads for \"cat\" and \"feline\", ranks lower with a lower consolidated boost, even though the total boost for the relevant keywords is higher than for photo1.\n\nIntuitively, the boosts should be separate, so only the boosts for the terms searched will be counted.\n\nGiven the current behaviour, you are forced to do one of the following:\n1. Assemble all of the multi-values into a string, and use payloads in place of boosts.\n2. Use dynamic fields, such as keyword_*, and boost them independently.\n\nNeither of these solutions are ideal, as using payloads requires writing your own BoostingTermQuery, and defining a new dynamic field per multi-value makes searching more difficult than with multivalue fields.\n\nThere's a blog entry that describes the current behaviour:\nhttp://blog.kapilchhabra.com/2008/01/solr-index-time-boost-facts-2",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "author": "Solomon",
            "id": "comment-15399216",
            "date": "2016-07-29T12:07:47+0000",
            "content": "Has this been resolved on Solr 4+ ? I believe it is still an issue. "
        },
        {
            "author": "David Smiley",
            "id": "comment-15399372",
            "date": "2016-07-29T13:59:18+0000",
            "content": "Sorry but Solr is working as-designed here \u2013 boosts are consolidated.  Lucene, which underlies Solr, works in this way.  Index time boosts go into the \"norm\" for a field which is fundamentally a single value per document (per-field).\n\nThat said, I understand what you're trying to do, and you will have to get there a different way.  \n\nOne way would be to \"fake\" the term frequency somehow to in-effect be your boost.  You could do this perhaps with a custom analysis chain that emits the same term a bunch of times. You would then likely want to customize the Similarity for this field... although even if you don't, you should see the effect of of this, as greater TF means a greater score.  You might also want to disable norms for this field.  Personally I think this is the best route to take.\n\nAnother route is to provide the boosts to be encoded as payloads.  There is already a TokenFilter that will do that for you, so this is easy.  But then you need to customize the Similarity decode the payload and use it in the score.  I am not certain but you probably also need to generate your query using a custom SpanQuery instead of using one of Solr's existing QueryParser's.  Those latter two things \u2013 custom Similarity, custom QParser might not necessarily be things you both need to do... maybe just one.  Not sure without digging in further.  This might be less work than the previous option I listed but I like that the previous one \"frequency\", an existing stat, vs payloads. "
        },
        {
            "author": "Solomon",
            "id": "comment-15403656",
            "date": "2016-08-02T09:02:44+0000",
            "content": "Thank you for your explanations. If I understand it correctly, you would suggest to index the values to be boosted with a higher frequency (e.g. index the value twice)?\n\nA useful resource to achieve it with payloads: https://lucidworks.com/blog/2009/08/05/getting-started-with-payloads/ "
        },
        {
            "author": "David Smiley",
            "id": "comment-15403967",
            "date": "2016-08-02T13:36:13+0000",
            "content": "(e.g. index the value twice)\n\nSure, and that's an easy way to do it albeit resulting in a stored-value potentially very large if you need to repeat tokens a lot.  A custom analyzer (i.e. analysis components generally) would allow you to parse custom syntax like cat|600 feline|100. You might take the code for DelimitedPayloadTokenFilter and modify it substantially to do what we're talking about here, and not use payloads. "
        }
    ]
}