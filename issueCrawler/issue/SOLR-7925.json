{
    "id": "SOLR-7925",
    "title": "Implement indexing from gzip format file",
    "details": {
        "components": [
            "update"
        ],
        "type": "Improvement",
        "labels": "",
        "fix_versions": [],
        "affect_versions": "5.2.1",
        "status": "Open",
        "resolution": "Unresolved",
        "priority": "Minor"
    },
    "description": "This will support the update of gzipped format file of Json, Xml and CSV.\nThe request path will use \"update/compress/gzip\" instead of \"update\" with \"update.contentType\" parameter  and  \"Content-Type: application/gzip\" as Header field.\n\nThe following is sample request using curl command. (use not --data but --data-binary)\n\ncurl \"http://localhost:8080/solr/collection1/update/compress/gzip?update.contentType=application/json&commit=true\" -H 'Content-Type: application/gzip' --data-binary @data.json.gz\n\nTo activate this function need to add following request handler information to solrconfig.xml\n\n  <requestHandler name=\"/update/compress/gzip\" class=\"org.apache.solr.handler.CompressedUpdateRequestHandler\">\n    <lst name=\"defaults\">\n      <str name=\"stream.contentType\">application/gzip</str>\n    </lst>\n  </requestHandler>",
    "attachments": {
        "SOLR-7925.patch": "https://issues.apache.org/jira/secure/attachment/12755068/SOLR-7925.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2015-09-10T05:46:52+0000",
            "author": "Song\u3000Hyonwoo",
            "content": "Some of test files were missing in previous patch.\nThis patch will fix the missing file problem. ",
            "id": "comment-14738210"
        },
        {
            "date": "2015-09-10T06:43:50+0000",
            "author": "Song\u3000Hyonwoo",
            "content": "This patch will help to save network bandwidth when you update file to remote solr server.\nIf you need to update big file frequently to remote solr, you can update the file as gzipped format with this patch. \nIf your system's network traffic is quite busy, this patch is useful to save network bandwidth.\n\nYou can test it like this.\n$ cd solr/core\n$ ant test -Dtestcase=GZipCompressedUpdateRequestHandlerTest\n\nThanks. ",
            "id": "comment-14738274"
        },
        {
            "date": "2015-09-15T21:22:10+0000",
            "author": "Chris Eldredge",
            "content": "Sounds potentially very useful when posting large amount of data to Solr. ",
            "id": "comment-14746241"
        },
        {
            "date": "2015-09-16T13:02:28+0000",
            "author": "Jan H\u00f8ydahl",
            "content": "Not sure if I agree that this belongs in Solr. Clients should handle streaming from various sources, including compressed files...\nOne option could be to add this to SimplePostTool (bin/post.sh)? ",
            "id": "comment-14768899"
        },
        {
            "date": "2015-09-17T08:17:58+0000",
            "author": "Song\u3000Hyonwoo",
            "content": "For simplicity, maybe it is better that Clients handle this kind of functionality, but benefit of indexing with gzipped file is saving network resource for transferring data to remote Solr.\n\nAs our test, indexing with gzipped file is 25% faster than original file on limited network bandwidth. ",
            "id": "comment-14791768"
        },
        {
            "date": "2015-09-17T08:18:48+0000",
            "author": "Song\u3000Hyonwoo",
            "content": "Thanks for your comment. ",
            "id": "comment-14791771"
        },
        {
            "date": "2015-09-17T14:46:53+0000",
            "author": "Jan H\u00f8ydahl",
            "content": "It could also be possible to add a Servlet Filter to Jetty which handles the decompression generically if the correct HTTP header is set on the request... ",
            "id": "comment-14803012"
        },
        {
            "date": "2016-01-28T15:42:40+0000",
            "author": "Jan H\u00f8ydahl",
            "content": "Anyone know if it is easy to configure Jetty to automatically deflate a gzip stream, before it even hits Solr? ",
            "id": "comment-15121725"
        },
        {
            "date": "2016-01-28T16:21:17+0000",
            "author": "Uwe Schindler",
            "content": "Unfortunately, the official support for gzip/deflate \"Content-Encoding\" (not to be confused with Content Type), only allows to compress responses: https://www.eclipse.org/jetty/documentation/current/gzip-filter.html\n\nThe HTTP standard does not have an official way that the client can send compressed content (as far as I know). The reason is that the server cannot announce this possibility before the client sends data. When serving responses, client sends Accept-Encoding header containing the supported compression formats and server responds with one from this list (after finding the intersection of  his capabilities with clients request).\n\nThis is different with HTTP 2.0, where there is compression part of the game (also when sending the HTTP headers). ",
            "id": "comment-15121815"
        },
        {
            "date": "2016-01-28T21:25:31+0000",
            "author": "Jan H\u00f8ydahl",
            "content": "Thanks for clarifying Uwe!\n\nCould not find any reference to request body compression in the HTTP 2.0 spec, only request headers...\nHowever, httpd's mod_deflate also provides a filter to decompress compressed requests: \"The mod_deflate module also provides a filter for decompressing a gzip compressed request body . In order to activate this feature you have to insert the DEFLATE filter into the input filter chain\", see https://httpd.apache.org/docs/2.4/mod/mod_deflate.html. \n\nGuess that's why I started looking for a Jetty filter or plugin doing the same. The Solr client could then post the request using Content-Encoding: gzip ",
            "id": "comment-15122333"
        },
        {
            "date": "2016-05-19T15:54:11+0000",
            "author": "Wendy Tao",
            "content": "Hi Song\u3000Hyonwoo,\n\nDo you have  sample .xml.gz files that I can try? \n\nI tried this patch for .xml.gz file. I exported your classes into a .jar file and placed under the following directory:\n/opt/solr-5.3.0/server/solr-webapp/webapp/WEB-INF/lib\n\nBut for some reason, it didn't index data. Here is the command and response.  Thanks!\n\n$ curl \"http://localhost:8983/solr/rcsb/update/compress/gzip?update.contentType=application/xml&commit=true\" -H 'Content-Type: application/gzip' --data-binary @1hhq-noatom.xml.gz\n\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<response>\n<lst name=\"responseHeader\"><int name=\"status\">0</int><int name=\"QTime\">106</int></lst>\n</response> ",
            "id": "comment-15291355"
        },
        {
            "date": "2017-06-30T19:43:07+0000",
            "author": "Jan H\u00f8ydahl",
            "content": "See SOLR-10981 which probably has a smoother solution using Content-Encoding: gzip header ",
            "id": "comment-16070624"
        },
        {
            "date": "2017-06-30T20:46:10+0000",
            "author": "Wendy Tao",
            "content": "Hi Jan,\n\nThank you for keeping posted with new update. I finally switched to index database and gave up on indexing gzip files.  Thanks!  ",
            "id": "comment-16070693"
        }
    ]
}