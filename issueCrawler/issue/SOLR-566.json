{
    "id": "SOLR-566",
    "title": "Incorporate Lucene's CheckIndex tool into Solr",
    "details": {
        "affect_versions": "None",
        "status": "Open",
        "fix_versions": [],
        "components": [],
        "type": "New Feature",
        "priority": "Minor",
        "labels": "",
        "resolution": "Unresolved"
    },
    "description": "Not sure how to just yet, but I think it would be good to somehow incorporate Lucene's CheckIndex tool into Solr.  I imagine it can be done nicely through the admin, but I suspect it makes sense to also do it on startup or even as a request handler.",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "author": "Hoss Man",
            "id": "comment-12595838",
            "date": "2008-05-10T16:46:56+0000",
            "content": "the main method will need some refactoring before it's a little more useful besides on the command line.\n\nA request handler would be a relaly straightforward way to do this, but another cool way to use it would be in the init code where we check for an existing lock file \u2013 if we find one, even if unlockOnStartup==true we should run CheckIndex. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-12619737",
            "date": "2008-08-04T23:12:21+0000",
            "content": "I think you have to be real careful putting it in the startup. I've seen even just 2 million doc indexes where the thing just takes forever to run on the box being used. That would be quite the surprisingly slow startup. "
        },
        {
            "author": "Brian Whitman",
            "id": "comment-12619738",
            "date": "2008-08-04T23:18:18+0000",
            "content": "-1 on running it on startup with any default. To be specific on mark's \"forever,\" I killed one that was actively processing index files after 12 hours (it wasn't hung or anything)\n "
        },
        {
            "author": "Luca Cavanna",
            "id": "comment-13155174",
            "date": "2011-11-22T14:33:21+0000",
            "content": "I would be willing to work on this. \nI agree that running it on startup isn't so handy, but it would be useful to have this feature available in my opinion. I see this as a request handler. \nFurthermore, actually we have a backup command available on the replication handler, I guess it would be useful to add an option to check the backup at the end of the process.\nAny thoughts? "
        },
        {
            "author": "Simon Willnauer",
            "id": "comment-13155185",
            "date": "2011-11-22T14:55:50+0000",
            "content": "I agree that running it on startup isn't so handy, but it would be useful to have this feature available in my opinion. I see this as a request handler. \n+1 "
        },
        {
            "author": "Luca Cavanna",
            "id": "comment-13166138",
            "date": "2011-12-09T13:06:27+0000",
            "content": "I'm working on a new handler called CheckIndexHandler. It saves the commitpoint before checking the index, then checks that saved commit points. This requires a few changes (I've almost done) on the way CheckIndex reads the SegmentInfos, since actually it doesn't read from a specific commitpoint.\nLast but not least, should the check process be synchronous or not? If not, how can we provide the results at the end of the process?\n\nCould you please let me know what you think? Am I on the right track? "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13167704",
            "date": "2011-12-12T19:36:55+0000",
            "content": "Luca: making CheckIndex work off a specified commit point sounds like a great idea \u2013 although i think (particularly in the case of your CheckIndexhandler) there would need to be some sanity checking and clear error messages if that commit point gets deleted in the middle of the CheckIndex.\n\nI think an async operation is the way to go \u2013 check index is something you want to see work even if the index is really large and it takes a long time \u2013 but i don't have a silver bullet suggestion for how to do it.   You could follow the model DIH currently uses, where you specify a \"command\" to run, an then on subsequent calls you can ask for the \"status\" of the most recently run command (and if i remember correctly: attempts to have it run a command while one is already in progress return info that a command is already running and you have to wait).\n\nAlternately you could go with a \"ticket\" type system, where you can either ask it to \"run\" and it immediately returns an id that you can later use to ask for status about that run \u2013 which would allow multiple concurrent runs with independent result status info ... but i'm not sure if that's important for CheckIndex (would have definitely been nice for DIH though).  The one potential problem there s where you maintain that status state (ram? disk?), and how long you keep it (ie: what frees the ram or removes the data from disk?)\n\nI would go with whatever seems simplest, and we can think about refactoring as needed. "
        },
        {
            "author": "Luca Cavanna",
            "id": "comment-13187543",
            "date": "2012-01-17T09:10:35+0000",
            "content": "Thanks for your answer Hoss, I created a specific issue about making CheckIndex work within a specified commit point (LUCENE-3702). "
        }
    ]
}