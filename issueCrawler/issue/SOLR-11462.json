{
    "id": "SOLR-11462",
    "title": "TokenizerChain's normalize() doesn't work",
    "details": {
        "labels": "",
        "priority": "Trivial",
        "components": [],
        "type": "Bug",
        "fix_versions": [],
        "affect_versions": "master (8.0)",
        "resolution": "Unresolved",
        "status": "Open"
    },
    "description": "TokenizerChain's normalize() is not currently used so this doesn't currently have any negative effects on search.  However, there is a bug, and we should fix it.\n\nIf applied to a TokenizerChain with filters.length > 1, only the last would apply. \n\n\n @Override\n  protected TokenStream normalize(String fieldName, TokenStream in) {\n    TokenStream result = in;\n    for (TokenFilterFactory filter : filters) {\n      if (filter instanceof MultiTermAwareComponent) {\n        filter = (TokenFilterFactory) ((MultiTermAwareComponent) filter).getMultiTermComponent();\n        result = filter.create(in);\n      }\n    }\n    return result;\n  }\n\n\n\nThe fix is trivial:\n\n-        result = filter.create(in);\n+        result = filter.create(result);\n\n\n\nIf you'd like to swap out TextField#analyzeMultiTerm() with, say:\n\n\n  public static BytesRef analyzeMultiTerm(String field, String part, Analyzer analyzerIn) {\n    if (part == null || analyzerIn == null) return null;\n    return analyzerIn.normalize(field, part);\n  }\n\n\n\nI'm happy to submit a PR with unit tests.  Let me know.",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "date": "2017-10-10T19:36:11+0000",
            "content": "Could also submit PR for getting rid of TokenizerChain in favor of CustomAnalyzer.  ",
            "author": "Tim Allison",
            "id": "comment-16199244"
        }
    ]
}