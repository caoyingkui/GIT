{
    "id": "SOLR-3673",
    "title": "Random variate functions",
    "details": {
        "affect_versions": "4.0-BETA,                                            6.0",
        "status": "Open",
        "fix_versions": [],
        "components": [],
        "type": "Improvement",
        "priority": "Major",
        "labels": "",
        "resolution": "Unresolved"
    },
    "description": "Hi all\n\nAt my $DAYJOB I have been asked to build a few random variate functions that return random numbers bound to a distribution.\n\nI think these can be added to solr.\n\nI have a hesitation in that the code as written uses / needs uncommons math (because we want a far better RNG than java's and because I am lazy and did not want to write distributions)\n\nuncommons math is apache license so we are good on that front\n\nanyone have any thoughts on this ?\n\nFor reference the functions are:\n\n\nrgaussian(mean, stddev) -> Random value aligned to gaussian distribution\nrpoisson(mean) -> Random value aligned to poisson distribution\nrbinomial(n, prob) -> Random value aligned to binomial distribtion\nrcontinous(min ,max) -> random continuous value between min and max\nrdiscrete(min, max) -> Random discrete value between min and max\nrexponential(rate) -> Random value from the exponential distribution",
    "attachments": {
        "SOLR-3673.patch": "https://issues.apache.org/jira/secure/attachment/12537787/SOLR-3673.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Greg Bowyer",
            "id": "comment-13421918",
            "date": "2012-07-25T01:21:30+0000",
            "content": "Initial attempt at random functions "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13421942",
            "date": "2012-07-25T02:06:20+0000",
            "content": "Greg: for non-math folks like me, can you explain the utility of this?  ie: what is an example use case that this helps solve?\n\n\nOne thing that jumps out at me is that the usage of the Random generators seems completely non-deterministic \u2013 which may seem desirable in code dealing with random numbers, but in the case of a solr function i don't think so.  \n\nIn particular it looks like the values returned for each doc by the intVal/floatVal/etc... methods on the anonymous FunctionValues instance returned by your RandomFunction class are dependent on the order that they are called, and won't return consistent values if they are called multiple times for the same docid.  So not only will multiple (identical) requests get different random values for the same document, but within a single request asking for the value of a single document multiple times will give you different values \u2013 which i believe will wreck havock on any attempts to sort by these functions (and could easily cause problems if they are wrapped in other functions that expect determinism)\n\ndoes that make sense?\n\nI think at a minimum we should probably add a \"seed\" argument to all of these functions (similar to how RandomSortField uses the field name as a seed) so that people can get consistent values from consistent input \u2013 if they want it, if they don't they just pass in a new seed (assuming all other things about the request and the index are equal of course)\n\nEven if we do that though, I'm still worried about intVal(docid) returning different values if it's called multiple times in a single request though ... it may make sense to (precompute and) cache the random values \u2013 if not long term then at least in the lifespan of the FunctionValues instance.\n\nwhat do you think? "
        },
        {
            "author": "Greg Bowyer",
            "id": "comment-13421965",
            "date": "2012-07-25T03:04:03+0000",
            "content": "\nGreg: for non-math folks like me, can you explain the utility of this? ie: what is an example use case that this helps solve?\nLet me get back to you on that one, I will try to find out what the data \nscientist who asked me for this has in mind\n\n\nOne thing that jumps out at me is that the usage of the Random generators seems completely non-deterministic \u2013 which may seem desirable in code dealing with random numbers, but in the case of a solr function i don't think so.\nIn particular it looks like the values returned for each doc by the intVal/floatVal/etc... methods on the anonymous FunctionValues instance returned by your RandomFunction class are dependent on the order that they are called, and won't return consistent values if they are called multiple times for the same docid. So not only will multiple (identical) requests get different random values for the same document, but within a single request asking for the value of a single document multiple times will give you different values \u2013 which i believe will wreck havock on any attempts to sort by these functions (and could easily cause problems if they are wrapped in other functions that expect determinism)\ndoes that make sense?\nThat makes perfect sense and is stupidly thought out on my part, I will look into caching the results in the scope of the FunctionValues instance. I will talk to the person who asked me for this in case he really does want it none deterministic, if that is the case I will try to get him to rationalise the behaviour and codify a memoization function for introducing determinism to the mix.\n\nFrom your viewpoint of breaking sort yes that is really bad.\n\n\nI think at a minimum we should probably add a \"seed\" argument to all of these functions (similar to how RandomSortField uses the field name as a seed) so that people can get consistent values from consistent input \u2013 if they want it, if they don't they just pass in a new seed (assuming all other things about the request and the index are equal of course) \nThat mostly makes sense, I am not sure what to do if an RNG is used that needs more seed data than the end user provides, at the moment I am using the Mersenne Twister which requires 128-bits of seed data, I am nervous about exposing the particulars of the underlying RNG, or its seeding. I will however update the patch to provide seed data\n\n\nEven if we do that though, I'm still worried about intVal(docid) returning different values if it's called multiple times in a single request though ... it may make sense to (precompute and) cache the random values \u2013 if not long term then at least in the lifespan of the FunctionValues instance.\nwhat do you think?\nAs above, stashing the values for each document ID seems to make sense. "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13422023",
            "date": "2012-07-25T05:50:51+0000",
            "content": "\nI think at a minimum we should probably add a \"seed\" argument to all of these functions \n...\nThat mostly makes sense, I am not sure what to do if an RNG is used that needs more seed data than the end user provides, at the moment I am using the Mersenne Twister which requires 128-bits of seed data, I am nervous about exposing the particulars of the underlying RNG, or its seeding.\n\nThis is where my total ignorance of these random generators and how they use comes in: it looked to me like these generators in your patch just took in a java.util.Random as input \u2013 is there a particular reason why this Mrs. Twister random needs to be used? what does that give us that java.util.Random doesn't?\n\nFWIW: 128bits isn't that much if you let the seed argument to the function be an arbitrary String - even if you ignore the high bits the user just needs to give you 16 chars (less if we include stuff like the index version)\n\nThis is kind of where my \"use case\" question comes into play as well ... if the goal is just to use these generators to get a \"biased\" shuffling of the docs (ie: maybe you use certain random distribution and then frange filter on it get a set of documents with a roughly predictable size) then it's not that bad if the seeds aren't very complex \u2013 throw in the SolrCore start time to get a few more bits, etc....  But if there is some sort of cryptography goal then obviously having a \"good\" random seed that is unpredictable is a lot more important.\n "
        },
        {
            "author": "Greg Bowyer",
            "id": "comment-13422029",
            "date": "2012-07-25T06:14:59+0000",
            "content": "\nThis is where my total ignorance of these random generators and how they use comes in: it looked to me like these generators in your patch just took in a java.util.Random as input \u2013 is there a particular reason why this Mrs. Twister random needs to be used? what does that give us that java.util.Random doesn't?\n\nThey can take anything that extends java.util.Random, the only issue that exists with the inbuilt one is that its chance of repeating itself is outstandingly low, it has some properties with the numbers it generates that make it generate that are statistically poor and its slightly slower.\n\nI dont lay claim to being an expert on this stuff, I am going on what I have been told, the usage of MT is a side benefit of cheating on the distributions and using the ones that come out of the box in uncommons-math - since I had a better RNG available I used it \n\n\nFWIW: 128bits isn't that much if you let the seed argument to the function be an arbitrary String - even if you ignore the high bits the user just needs to give you 16 chars (less if we include stuff like the index version)\n\nYeah its not a lot and manageable, I was more thinking about avoiding it being too configurable (for example I think saying rguassian(1, 0.5, \"some very long seed with lots of data\", \"XORShift\") .... would be too far)\n\nI will implement the passing in of a seed value for sure (thats pretty sensible), I was more worried about making sure that the seed was just random (ha!) data the user passed in, and that there is not expectation over whats happening under the hood. \n\n\nThis is kind of where my \"use case\" question comes into play as well ... if the goal is just to use these generators to get a \"biased\" shuffling of the docs (ie: maybe you use certain random distribution and then frange filter on it get a set of documents with a roughly predictable size) then it's not that bad if the seeds aren't very complex \u2013 throw in the SolrCore start time to get a few more bits, etc.... But if there is some sort of cryptography goal then obviously having a \"good\" random seed that is unpredictable is a lot more important.\n\nThe first use case, also use cases involving bending things towards distributions to act as cheap models. \n\nThis stuff is useless as it stands for crypto anyhow since these RNG's are fairly predictable. "
        },
        {
            "author": "Lance Norskog",
            "id": "comment-13422053",
            "date": "2012-07-25T07:20:16+0000",
            "content": "You might want to ask the Mahout people about good random numbers and packaging them. They went to a lot of work to get this stuff right for packaged software. Determinism is really important for writing unit tests, and Mahout has a weird hack to make this easy.\n\nSecureRandom might be better than dragging in uncommons.\n\n(Java.util.Random's double generator always gives something less than 20% away from the previous value.) "
        },
        {
            "author": "Greg Bowyer",
            "id": "comment-13422451",
            "date": "2012-07-25T17:44:59+0000",
            "content": "Good idea, although interestingly I have noticed (from some brief source diving) that mahout actual embeds uncommons math :S\n\nAs for secure random, its aimed at crypto and so reads from high quality entropy like /dev/random (which blocks), whilst this can be changed around it gets more complex than it needs to be. "
        }
    ]
}