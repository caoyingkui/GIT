{
    "id": "SOLR-466",
    "title": "Update SynonymFilter to new Token APIs",
    "details": {
        "affect_versions": "None",
        "status": "Closed",
        "fix_versions": [],
        "components": [
            "search"
        ],
        "type": "Improvement",
        "priority": "Minor",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "Take advantage of new Lucene 2.3 Token APIs that use char[] and token reuse.",
    "attachments": {
        "synonymfilter.patch": "https://issues.apache.org/jira/secure/attachment/12373868/synonymfilter.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Yonik Seeley",
            "id": "comment-12561937",
            "date": "2008-01-24T04:41:56+0000",
            "content": "committed. "
        },
        {
            "author": "Stu Hood",
            "id": "comment-12561957",
            "date": "2008-01-24T06:32:34+0000",
            "content": "How much of a (speed) improvement is this? Any figures? "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12562075",
            "date": "2008-01-24T14:25:28+0000",
            "content": "From the Lucene side, Mike saw a 21% increase in analysis performance.\nhttps://issues.apache.org/jira/browse/LUCENE-969\n\nHowever, due to backward compatibility code in Term, I think we would see a slowdown if all our filters aren't switched to char[] (switching back and forth in a chain will be expensive). "
        }
    ]
}