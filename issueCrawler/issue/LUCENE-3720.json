{
    "id": "LUCENE-3720",
    "title": "OOM in TestBeiderMorseFilter.testRandom",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [
            "modules/analysis"
        ],
        "type": "Test",
        "fix_versions": [
            "4.0",
            "6.0"
        ],
        "affect_versions": "3.6,                                            4.0-ALPHA",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "This has been OOM'ing a lot... we should see why, its likely a real bug.\n\nant test -Dtestcase=TestBeiderMorseFilter -Dtestmethod=testRandom -Dtests.seed=2e18f456e714be89:310bba5e8404100d:-3bd11277c22f4591 -Dtests.multiplier=3 -Dargs=\"-Dfile.encoding=ISO8859-1\"",
    "attachments": {
        "LUCENE-3720.patch": "https://issues.apache.org/jira/secure/attachment/12545277/LUCENE-3720.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2012-01-26T16:17:33+0000",
            "content": "I'm still working on a testcase for this.\n\nI think the underlying commons-codec algorithm \"blows up\" on some inputs, especially those from randomHtmlIshString.\nThen given multiple threads its easy for it to OOM.\n\nSo far the best i have is: (ant test -Dtestcase=TestBeiderMorseFilter -Dtestmethod=testOOM -Dtests.seed=320e23c1f5dbf9c5:-766b86e7dc5e81df:148a8a4955f89b5e -Dargs=\"-Dfile.encoding=UTF-8\" -Dtests.heapsize=64M\n\nThis blows up, so I just have to get it to log the string that blows up I think, and we have a start to a testcase.\n\n\n  public void testOOM() throws Exception {\n    int numIter = 100000;\n    int numTokens = 0;\n    for (int i = 0; i < numIter; i++) {\n      String s = _TestUtil.randomHtmlishString(random, 30);\n      TokenStream ts = analyzer.tokenStream(\"bogus\", new StringReader(s));\n      ts.reset();\n      while (ts.incrementToken()) {\n        numTokens++;\n      }\n      ts.end();\n      ts.close();\n    }\n    System.out.println(numTokens);\n  }\n\n ",
            "author": "Robert Muir",
            "id": "comment-13193937"
        },
        {
            "date": "2012-01-26T16:46:11+0000",
            "content": "Here's an initial test:\n\n  public void testOOM2() throws Exception {\n    String test = \"200697900'-->&#1913348150;</  bceaeef >aadaabcf\\\"aedfbff<!--\\'-->?>cae\" +\n        \"cfaaa><?&#<!--</script>&lang&fc;aadeaf?>>&bdquo<    cc =\\\"abff\\\"    /></   afe  >\" +\n        \"<script><!-- f(';<    cf aefbeef = \\\"bfabadcf\\\" ebbfeedd = fccabeb >\";\n    TokenStream ts = analyzer.tokenStream(\"bogus\", new StringReader(test));\n    ts.reset();\n    while (ts.incrementToken()) {\n      ;\n    }\n    ts.end();\n    ts.close();\n  }\n\n\n\nIll see if i can make it blow up with a smaller string, and then port the test to just use commons-codec apis (not lucene ones). ",
            "author": "Robert Muir",
            "id": "comment-13193955"
        },
        {
            "date": "2012-01-26T17:31:46+0000",
            "content": "Linking this issue to CODEC-132, I attached a test case to that issue. ",
            "author": "Robert Muir",
            "id": "comment-13194008"
        },
        {
            "date": "2012-01-26T18:28:19+0000",
            "content": "For now I added a big red bold warning and disabled the test. ",
            "author": "Robert Muir",
            "id": "comment-13194053"
        },
        {
            "date": "2012-01-26T18:46:29+0000",
            "content": "I think we should disable the whole TokenFilter for now until this is fixed. It was not yet released as far as I know. So I would suggest to temporary \"svn rm\" it and revert this once this is fixed. This makes it disappear from 3.6 Release, but it's not lost. We should keep this issue open, until the root cause is fixed. ",
            "author": "Uwe Schindler",
            "id": "comment-13194071"
        },
        {
            "date": "2012-01-26T19:05:18+0000",
            "content": "I don't think we need to remove the Tokenfilter just because it has a known bug.  It could be this is rarely hit in practice / on more normal input.  All software has bugs... ",
            "author": "Michael McCandless",
            "id": "comment-13194087"
        },
        {
            "date": "2012-01-26T19:24:41+0000",
            "content": "I suspect (as noted on CODEC-132) that this is caused by certain punctuation. I can dig a little, could be we apply a temporary\nworkaround sanitising the offending character (and long term/better, create a fix for CODEC-132) ",
            "author": "Robert Muir",
            "id": "comment-13194106"
        },
        {
            "date": "2012-03-07T19:28:26+0000",
            "content": "There is now a patch on CODEC-132 , I haven't had the time to try to apply-rebuild-test with it, but it seems like the right fix. ",
            "author": "Robert Muir",
            "id": "comment-13224628"
        },
        {
            "date": "2012-03-16T21:12:13+0000",
            "content": "Hi,\n\nI looked at the testcase and it runs through with the patched commons-codec, but I received an assertion:\n\n\n    [junit] Testcase: testRandom(org.apache.lucene.analysis.phonetic.TestBeiderMorseFilter):\tFAILED\n    [junit] term 8 expected:<skript[Skriptsk]ript> but was:<skript[dZriptdZ]ript>\n    [junit] junit.framework.AssertionFailedError: term 8 expected:<skript[Skriptsk]ript> but was:<skript[dZriptdZ]ript>\n\n ",
            "author": "Thomas Neidhart",
            "id": "comment-13231634"
        },
        {
            "date": "2012-03-16T21:22:16+0000",
            "content": "Hmm i havent tested the patched version yet myself, but thats probably where we check that\nthe output is deterministic (we replay the same random strings again and check the output is the same as before). ",
            "author": "Robert Muir",
            "id": "comment-13231641"
        },
        {
            "date": "2012-03-17T10:31:02+0000",
            "content": "The test starts multiple threads for the analysis, so maybe there is a concurrency problem in the BeiderMorseCodec.\nWhen doing a similar test sequentially, the result is always the same.\n\nI will look further into this. ",
            "author": "Thomas Neidhart",
            "id": "comment-13231907"
        },
        {
            "date": "2012-03-17T17:21:16+0000",
            "content": "The BeiderMorseFilter uses internally a java.util.regex.Matcher which is not supposed to be thread-safe. When doing the random test, the same analyzer is used by different threads, so my first guess would be that the problems are related to this somehow. ",
            "author": "Thomas Neidhart",
            "id": "comment-13232021"
        },
        {
            "date": "2012-03-18T12:32:02+0000",
            "content": "Thomas: the filter is ok, it does not need to be thread safe.\nAnalyzer has as threadlocal for the tokenizer chain, each\nthread gets its own filter. ",
            "author": "Robert Muir",
            "id": "comment-13232264"
        },
        {
            "date": "2012-03-18T18:28:48+0000",
            "content": "Ok, it took me some time to understand the test and filter code. In fact my original statement was wrong, the output order of phoneme tokens from the codec was not deterministic. This has been fixed in commons-codec, and the test runs through now.\n\nbtw. the next release will happen quite soon afaik and will also include a new phonetic encoder called Nysiis, which should perform slightly better than Soundex (see https://issues.apache.org/jira/browse/CODEC-63). Any feedback is very welcome! ",
            "author": "Thomas Neidhart",
            "id": "comment-13232325"
        },
        {
            "date": "2012-03-19T17:16:35+0000",
            "content": "Thanks so much for digging into this Thomas!\n\nWhen the release comes out we can add support and tests for the new encoder too. ",
            "author": "Robert Muir",
            "id": "comment-13232738"
        },
        {
            "date": "2012-09-15T13:32:20+0000",
            "content": "Commons-codec 1.7 has been released with fixes. I'm testing them out now. ",
            "author": "Robert Muir",
            "id": "comment-13456408"
        },
        {
            "date": "2012-09-15T13:43:47+0000",
            "content": "patch upgrading the jar, re-enabling the test, and removing the warnings.\n\nI ran the following 100 times from a shell script with no fails:\n\nant test -Dtestcase=TestBeiderMorseFilter -Dtests.multiplier=3 -Dtests.nightly=true -Dtestmethod=testRandom ",
            "author": "Robert Muir",
            "id": "comment-13456410"
        },
        {
            "date": "2012-09-15T13:47:54+0000",
            "content": "I looked, it seems they are still in the release process (its just that 1.7 is starting to appear on mirrors).\n\nwe should wait until the official release announcement for the upgrade. ",
            "author": "Robert Muir",
            "id": "comment-13456411"
        },
        {
            "date": "2012-09-17T15:17:23+0000",
            "content": "Release is officially out: http://mail-archives.apache.org/mod_mbox/www-announce/201209.mbox/%3CCACZkXPz4wOAzRVf41h6PSVDp9PV-3uj%3D8e2ZViByeX5EpmYWzw%40mail.gmail.com%3E\n\nI'll run tests/checks with the patch and commit shortly. ",
            "author": "Robert Muir",
            "id": "comment-13457075"
        },
        {
            "date": "2012-09-17T15:49:15+0000",
            "content": "Thanks for fixing this Thomas!\n\nI opened LUCENE-4400 to add support for the new 1.7 encoder. ",
            "author": "Robert Muir",
            "id": "comment-13457102"
        },
        {
            "date": "2013-03-22T16:37:53+0000",
            "content": "[branch_4x commit] Robert Muir\nhttp://svn.apache.org/viewvc?view=revision&revision=1386670\n\nLUCENE-3720: fix BeiderMorseFilter OOM issues ",
            "author": "Commit Tag Bot",
            "id": "comment-13610822"
        },
        {
            "date": "2013-05-10T10:33:43+0000",
            "content": "Closed after release. ",
            "author": "Uwe Schindler",
            "id": "comment-13654006"
        }
    ]
}