{
    "id": "SOLR-10123",
    "title": "Analytics Component 2.0",
    "details": {
        "labels": "",
        "priority": "Blocker",
        "components": [],
        "type": "New Feature",
        "fix_versions": [
            "7.0"
        ],
        "affect_versions": "7.0",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "A completely redesigned Analytics Component, introducing the following features:\n\n\tSupport for distributed collections\n\tNew JSON request language, and response format that fits JSON better.\n\tFaceting over mapping functions in addition to fields (Value Faceting)\n\tPivotFaceting with ValueFacets\n\tMore advanced facet sorting\n\tSupport for PointField types\n\tExpressions over multi-valued fields\n\tNew types of mapping functions\n\t\n\t\tLogical\n\t\tConditional\n\t\tComparison\n\t\n\t\n\tConcurrent request execution\n\tCustom user functions, defined within the request\n\n\n\nFully backwards compatible with the orifinal Analytics Component with the following exceptions:\n\n\tAll fields used must have doc-values enabled\n\tExpression results can no longer be used when defining Range and Query facets\n\tThe reverse(string) mapping function is no longer a native function",
    "attachments": {
        "SOLR-10123.patch": "https://issues.apache.org/jira/secure/attachment/12869534/SOLR-10123.patch",
        "SOLR-10123.patch.bugfixes": "https://issues.apache.org/jira/secure/attachment/12875904/SOLR-10123.patch.bugfixes"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2017-02-13T05:31:29+0000",
            "content": "We are finishing up some internal review/testing and will have a patch up shortly Christine Poerschke Ramkumar Aiyengar  ",
            "author": "Steven Bower",
            "id": "comment-15863230"
        },
        {
            "date": "2017-06-27T02:27:55+0000",
            "content": "This is the current patch. It appears to have failing tests and precommit issues. Houston is working on both. ",
            "author": "Dennis Gove",
            "id": "comment-16064151"
        },
        {
            "date": "2017-06-28T18:18:53+0000",
            "content": "This patch version has been applied to master. Houston will be updating this ticket with additional documentation and comments describing this change. ",
            "author": "Dennis Gove",
            "id": "comment-16066987"
        },
        {
            "date": "2017-06-28T18:27:49+0000",
            "content": "We had some issues with some completely unrelated tests failing when running \n\nant clean test\n\n Sometimes when we ran the full test suite varied sets of tests would fail, but re-running with the seed would see those tests then pass. Both Houston and I are of the opinion that because Analytics is a contrib module, there was no rhyme or reason to which tests failed or why, and that the failures we'd see are completely unrelated to analytics that the failures are unrelated to this code change. We did also see many full test suite runs which showed no failures.\n\nI cannot say for 100%, however, so I want to document it here. Houston will be watching the daily build/test log and will investigate any related failures.\n\n\nant precommit\n\n does pass. ",
            "author": "Dennis Gove",
            "id": "comment-16067007"
        },
        {
            "date": "2017-06-28T20:43:55+0000",
            "content": "Dennis: at first glance, commit d5963bebc43bdb712f2f1e9a29f944370f079b5f has effectively negated a lot of the work done in SOLR-10947 by adding a brand new configset/schema that only use Trie numeric fields instead of randomizing in Point numeric fields...\n\nhttps://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;a=commit;h=d5963bebc43bdb712f2f1e9a29f944370f079b5f\n\nIt's also not clear if this new code still suffers from SOLR-10949 ... i see code paths that are specific to PointFields, but w/o any Point field in the new test schema how can we know? ",
            "author": "Hoss Man",
            "id": "comment-16067188"
        },
        {
            "date": "2017-06-28T21:25:00+0000",
            "content": "Hoss, the commit does seem to have overwritten it. I can add the randomizing Point numeric fields back into the test.\n\nThe new code did suffer from SOLR-10949, but less than the old code. I made a small fix and now all tests pass. \n\nHowever I tried adding the randomized point fields to the cloud schema (test-files/solr/configsets/cloud-analytics/conf/schema.xml) and that didn't work. Does it support cloud schemas? ",
            "author": "Houston Putman",
            "id": "comment-16067256"
        },
        {
            "date": "2017-06-28T21:33:22+0000",
            "content": "the system properties are randomized by SolrTestCaseJ4 in an @BeforeClass method \u2013 see changes made by SOLR-10864...\n\nhttps://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=38f29b2\n\nSome core \"cloud\" tests extend LuceneTestCase directly for no good reason (see SOLR-10916) and have to call the neccessary methods in SolrTestCaseJ4 directly until they are fixed \u2013 but at a glance that doesn't seem to be a problem with any of the new analytics tests.\n\nw/o more details on what exactly you tried and what you mean by \"didn't work\" it's hard to guess what problem you might have encountered.\n ",
            "author": "Hoss Man",
            "id": "comment-16067271"
        },
        {
            "date": "2017-06-29T15:54:29+0000",
            "content": "Okay, so I have updated the cloud and non-cloud schemas to add the randomized numeric fields. However the randomized doc-values cannot be used since docValues are required for almost all Analytics Component functionality.\n\nAlmost all tests pass now, however there is a difference between SortedSetDocValues (TrieField) and SortedNumericDocValues (PointField) that might make this impossible. SortedSetDocValues only store the unique set of values for a multi-valued field, however SortedNumericDocValues can store the same value multiple times for a field on the same document. Therefore analytics results can vary between the two. \n\nImagine you have the following document\n\n{\n  id=\"1\", \n  multi_valued_int_field=[1,1,2,2,3], \n  float_field=3\n}\n\n\n\nand were executing a facet over multi_valued_int_field, and calculating the sum of float_field. Ie, for every unique value in multi_valued_int_field, calculate the sum of float_field.\n\nIf multi_valued_int_field is of type IntPointField, then the following results appear\n\n\n\n\nFacet Value\nCalculation\nResult\nReason\n\n\n1\n3 + 3\n6\nvalue 1 appears 2 times in the multivalued field so 2 instances of 3 are summed\n\n\n2\n3 + 3\n6\nvalue 2 appears 2 times in the multivalued field so 2 instances of 3 are summed\n\n\n3\n3\n3\nvalue 3 appears 1 time in the multivalued field so 3 is the result\n\n\n\n\n\nIf multi_valued_int_field is of type TrieIntField, then the following results appear\n\n\n\n\nFacet Value\nCalculation\nResult\nReason\n\n\n1\n3\n3\nvalue 1 appears 1 time in the multivalued field so 3 is the result\n\n\n2\n3\n3\nvalue 2 appears 1 time in the multivalued field so 3 is the result\n\n\n3\n3\n3\nvalue 3 appears 1 time in the multivalued field so 3 is the result\n\n\n\n\n\nThe difference here is how IntPointField and TrieIntField are stored. IntPointField does not deduplicate the values in the array while TrieIntField does.\n\nThe same thing would occur when a multi-valued numeric field was used in an expression, but that is not included in the unit tests. ",
            "author": "Houston Putman",
            "id": "comment-16068518"
        },
        {
            "date": "2017-06-29T18:37:35+0000",
            "content": "(FWIW Houston, attaching patches showing your progress/attempts makes it easier for people to follow along with exactly what you're doing and offer meaningful ideas/suggestions)\n\nHowever the randomized doc-values cannot be used since docValues are required for almost all Analytics Component functionality.\n\nThat's fine \u2013 if the feature requires docValues it requires docValues.  The main reasons the docValue randomization was added was:\n\n\tto help catch bugs/assumptions in code related to docValues\n\tso tests for things like facets (which work with non-dv tries, but require dv's for points) could do this...\n\n@BeforeClass\npublic static void beforeClass() throws Exception {\n  // we need DVs on point fields to compute stats & facets\n  if (Boolean.getBoolean(NUMERIC_POINTS_SYSPROP)) System.setProperty(NUMERIC_DOCVALUES_SYSPROP,\"true\");\n\n\n\n\n\nAlmost all tests pass now, however there is a difference between SortedSetDocValues (TrieField) and SortedNumericDocValues (PointField) that might make this impossible. ...\n\nWhat you're talking about is noted in SOLR-10924.  Personally i consider it a feature of Points fields.  \n\nHow we deal with it depends largely on what folks think the \"right\" behavior is and how it should be documented.  From an end user standpoint i think it's great \u2013 they'll have an accurate statistical representation of the data they put in, and if they don't wnat duplicate values considered they shouldn't put the dups in. (ie: document it as a limitation of using Trie numerics, not a \"bug\" in Points)\n\nHow it affects the tests and what should be done there is a harder question because I have no idea how much this impacts the existing tests with your current working changes.\n\nOne approach is to leave the test data in place, leave the duplicate values in place, and account for the discrepancy in the assertions \u2013 ala TestExportWriter.testDuplicates()\n\nA diff approach would be to change the tests to ensure it didn't use duplicates in it's tests data, so the numbers are equivalent regardless of the underlying implementation.\n\nA third option, is to eliminate the points randomization completley \u2013 i wouldn't advise this unless tthe other options are for some reason completley impossible \u2013 and systematically test both Trie fields and Point fields with diff tests that know about the diff behavior.\n\nBut as things stand right now, this jira claims the new code works with Point fields, but this claim is not backed up by any new testing, so something needs to change.\n\n\n ",
            "author": "Hoss Man",
            "id": "comment-16068767"
        },
        {
            "date": "2017-06-29T18:39:13+0000",
            "content": "The same thing would occur when a multi-valued numeric field was used in an expression, but that is not included in the unit tests.\n\nshouldn't it be??? ",
            "author": "Hoss Man",
            "id": "comment-16068771"
        },
        {
            "date": "2017-06-29T20:23:13+0000",
            "content": "GitHub user HoustonPutman opened a pull request:\n\n    https://github.com/apache/lucene-solr/pull/215\n\n    SOLR-10123: Fix to better support numeric PointFields in Analytics.\n\n    Unit tests now use randomized numeric fields.\n\nYou can merge this pull request into a Git repository by running:\n\n    $ git pull https://github.com/HoustonPutman/lucene-solr analytics-points\n\nAlternatively you can review and apply these changes as the patch at:\n\n    https://github.com/apache/lucene-solr/pull/215.patch\n\nTo close this pull request, make a commit to your master/trunk branch\nwith (at least) the following in the commit message:\n\n    This closes #215\n\n\ncommit c66d149b491bb47baac5f29101f5383aa93df280\nAuthor: Houston Putman <hputman1@bloomberg.net>\nDate:   2017-06-29T19:52:08Z\n\n    SOLR-10123: Fix to better support numeric PointFields. Unit tests now use randomized numeric fields.\n\n ",
            "author": "ASF GitHub Bot",
            "id": "comment-16068930"
        },
        {
            "date": "2017-06-29T20:23:59+0000",
            "content": "(FWIW Houston, attaching patches showing your progress/attempts makes it easier for people to follow along with exactly what you're doing and offer meaningful ideas/suggestions)\nI understand, I'm pretty new to this so I don't really know how this is done. I've unsuccessfully tried to do the patch thing before, so I'll just make a pull request this time.\n\nPersonally i consider it a feature of Points fields\n\nI completely agree, and I'm glad that this is finally possible. My comment was more to describe how the tests would be affected by it. However it does introduce an interesting problem where String & Boolean fields cannot have duplicate values, but Numeric fields can. But that is not a huge issue.\n\nI have changed the tests to check whether point fields are being used and to test accordingly, and they now pass with the randomized numeric fields in the schemas.\n\nThe changes are in the following pull request: https://github.com/apache/lucene-solr/pull/215\n\nshouldn't it be???\nYes, it should be tested. There are a lot of new features in this release and it is going to take a while to add unit tests for all of them. ",
            "author": "Houston Putman",
            "id": "comment-16068931"
        },
        {
            "date": "2017-07-05T01:15:29+0000",
            "content": "Github user dennisgove commented on the issue:\n\n    https://github.com/apache/lucene-solr/pull/215\n\n    Where are point fields specifically handled, or do they not need to be specifically handled like other Trie fields? ",
            "author": "ASF GitHub Bot",
            "id": "comment-16074149"
        },
        {
            "date": "2017-07-05T14:10:22+0000",
            "content": "Github user HoustonPutman commented on the issue:\n\n    https://github.com/apache/lucene-solr/pull/215\n\n    If you are asking where in the component are they handled, it's in the ExpressionFactory.createField() method where Trie and Point fields are separated.\n\n    If you are asking about the tests, they work with both Trie and Point fields. ",
            "author": "ASF GitHub Bot",
            "id": "comment-16074819"
        },
        {
            "date": "2017-07-05T19:22:19+0000",
            "content": "Github user dennisgove commented on the issue:\n\n    https://github.com/apache/lucene-solr/pull/215\n\n    This all looks good to me so far\n\n    `%> ant precommit` passes\n    `%> ant test` passes\n\n    Houston is working on a new batch of tests that will specifically test the new analytics expression language. I'm going to wait until those are added (and checked) before merging this PR.\n\n    @hossman, do you have any other concerns about this and/or possible ramifications of this change? ",
            "author": "ASF GitHub Bot",
            "id": "comment-16075269"
        },
        {
            "date": "2017-07-05T22:24:15+0000",
            "content": "\nHouston is working on a new batch of tests that will specifically test the new analytics expression language. I'm going to wait until those are added (and checked) before merging this PR.\n\nI haven't reviewed the patch in depth, but since it appears to fix some genuine bugs with point field handling (see changes to existing \"instanceof TrieField\") in addition to already improving the test coverage of points, i would urge you to commit ASAP if you think it's good enough \u2013 a \"bug fix with tests\" patch shouldn't be blocked waiting on more tests.\n\n...do you have any other concerns about this and/or possible ramifications of this change?\n\nMy chief concern was that points be tested if the new code was going to claim it works with points \u2013 either that or file some \"known issues\" bugs documenting the problems and use @SuppressPointFields to indicate them \u2013 as opposed to how this issue currently exists on master: w/o any attempt at testing points at all.  If the tests already committed by this issue can be made to work with points by committing the PR, then i (personally) have no concerns ",
            "author": "Hoss Man",
            "id": "comment-16075535"
        },
        {
            "date": "2017-07-06T10:43:36+0000",
            "content": "Commit 88b7ed1d463f396932071102814363a3a300294f in lucene-solr's branch refs/heads/master from Houston Putman\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=88b7ed1 ]\n\nSOLR-10123: Fix to better support numeric PointFields. Unit tests now use randomized numeric fields.\n\nCloses #215 ",
            "author": "ASF subversion and git services",
            "id": "comment-16076339"
        },
        {
            "date": "2017-07-06T10:44:46+0000",
            "content": "Github user asfgit closed the pull request at:\n\n    https://github.com/apache/lucene-solr/pull/215 ",
            "author": "ASF GitHub Bot",
            "id": "comment-16076342"
        },
        {
            "date": "2017-07-06T10:47:18+0000",
            "content": "This patch contains only the changes on commit 88b7ed1. It will need to be applied to branches 7x and 7.0. ",
            "author": "Dennis Gove",
            "id": "comment-16076348"
        },
        {
            "date": "2017-07-06T10:50:21+0000",
            "content": "Commit 54d43c35f1ca281768b168e597fabad510ebbd55 in lucene-solr's branch refs/heads/branch_7x from Dennis Gove\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=54d43c3 ]\n\nSOLR-10123: Fix to better support numeric PointFields. Unit tests now use randomized numeric fields.\n\nCloses #215 ",
            "author": "ASF subversion and git services",
            "id": "comment-16076351"
        },
        {
            "date": "2017-07-06T10:53:38+0000",
            "content": "Commit 7dfc0d4efb5b90c0cf1ddc891e73217d1e5f1031 in lucene-solr's branch refs/heads/branch_7_0 from Dennis Gove\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=7dfc0d4 ]\n\nSOLR-10123: Fix to better support numeric PointFields. Unit tests now use randomized numeric fields. ",
            "author": "ASF subversion and git services",
            "id": "comment-16076354"
        },
        {
            "date": "2017-07-10T16:43:39+0000",
            "content": "Non-reproducing failure from https://jenkins.thetaphi.de/job/Lucene-Solr-7.x-Linux/38/:\n\nChecking out Revision 5ba509dbd267d28f616d20c195b7fad70fc6064b (refs/remotes/origin/branch_7x)\n[...]\n   [junit4]   2> NOTE: test params are: codec=HighCompressionCompressingStoredFields(storedFieldsFormat=CompressingStoredFieldsFormat(compressionMode=HIGH_COMPRESSION, chunkSize=6, maxDocsPerChunk=997, blockSize=6), termVectorsFormat=CompressingTermVectorsFormat(compressionMode=HIGH_COMPRESSION, chunkSize=6, blockSize=6)), sim=RandomSimilarity(queryNorm=false): {}, locale=en-SG, timezone=Etc/GMT-10\n   [junit4]   2> NOTE: Linux 4.10.0-21-generic i386/Oracle Corporation 1.8.0_131 (32-bit)/cpus=8,threads=1,free=31874992,total=63266816\n   [junit4]   2> NOTE: All tests run in this JVM: [AbstractAnalyticsFacetTest, FieldFacetExtrasCloudTest, AbstractAnalyticsStatsTest, NoFacetTest, FacetSortingTest, FieldFacetExtrasTest, QueryFacetCloudTest]\n   [junit4]   2> NOTE: reproduce with: ant test  -Dtestcase=QueryFacetCloudTest -Dtests.seed=F3E68F7CEEE0C86C -Dtests.multiplier=3 -Dtests.slow=true -Dtests.locale=en-SG -Dtests.timezone=Etc/GMT-10 -Dtests.asserts=true -Dtests.file.encoding=US-ASCII\n   [junit4] ERROR   0.00s J1 | QueryFacetCloudTest (suite) <<<\n   [junit4]    > Throwable #1: org.apache.solr.client.solrj.impl.CloudSolrClient$RouteException: org.apache.http.ParseException: Invalid content type: \n   [junit4]    > \tat __randomizedtesting.SeedInfo.seed([F3E68F7CEEE0C86C]:0)\n   [junit4]    > \tat org.apache.solr.client.solrj.impl.CloudSolrClient.directUpdate(CloudSolrClient.java:541)\n   [junit4]    > \tat org.apache.solr.client.solrj.impl.CloudSolrClient.sendRequest(CloudSolrClient.java:993)\n   [junit4]    > \tat org.apache.solr.client.solrj.impl.CloudSolrClient.requestWithRetryOnStaleState(CloudSolrClient.java:862)\n   [junit4]    > \tat org.apache.solr.client.solrj.impl.CloudSolrClient.request(CloudSolrClient.java:793)\n   [junit4]    > \tat org.apache.solr.client.solrj.SolrRequest.process(SolrRequest.java:178)\n   [junit4]    > \tat org.apache.solr.client.solrj.request.UpdateRequest.commit(UpdateRequest.java:233)\n   [junit4]    > \tat org.apache.solr.analytics.facet.QueryFacetCloudTest.beforeClass(QueryFacetCloudTest.java:102)\n   [junit4]    > \tat java.lang.Thread.run(Thread.java:748)\n   [junit4]    > Caused by: org.apache.solr.client.solrj.SolrServerException: org.apache.http.ParseException: Invalid content type: \n   [junit4]    > \tat org.apache.solr.client.solrj.impl.LBHttpSolrClient.doRequest(LBHttpSolrClient.java:523)\n   [junit4]    > \tat org.apache.solr.client.solrj.impl.LBHttpSolrClient.request(LBHttpSolrClient.java:413)\n   [junit4]    > \tat org.apache.solr.client.solrj.impl.CloudSolrClient.lambda$directUpdate$0(CloudSolrClient.java:516)\n   [junit4]    > \tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n   [junit4]    > \tat org.apache.solr.common.util.ExecutorUtil$MDCAwareThreadPoolExecutor.lambda$execute$0(ExecutorUtil.java:188)\n   [junit4]    > \tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n   [junit4]    > \tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n   [junit4]    > \t... 1 more\n   [junit4]    > Caused by: org.apache.http.ParseException: Invalid content type: \n   [junit4]    > \tat org.apache.http.entity.ContentType.parse(ContentType.java:273)\n   [junit4]    > \tat org.apache.solr.client.solrj.impl.HttpSolrClient.executeMethod(HttpSolrClient.java:572)\n   [junit4]    > \tat org.apache.solr.client.solrj.impl.HttpSolrClient.request(HttpSolrClient.java:252)\n   [junit4]    > \tat org.apache.solr.client.solrj.impl.HttpSolrClient.request(HttpSolrClient.java:241)\n   [junit4]    > \tat org.apache.solr.client.solrj.impl.LBHttpSolrClient.doRequest(LBHttpSolrClient.java:483)\n   [junit4]    > \t... 7 more\n\n ",
            "author": "Steve Rowe",
            "id": "comment-16080624"
        },
        {
            "date": "2017-07-20T17:28:40+0000",
            "content": "setting as blocker since this issue is still listed as \"open\" but work has already been committed to the 7.0 branch but: 1) it's not clear if this feature is considered \"done\"; 2) the new tests have some concerning test failures as noted by sarowe.\n\nDennis Gove can you please assess the state of this issue? (and the linked SOLR-10949) ",
            "author": "Hoss Man",
            "id": "comment-16095038"
        },
        {
            "date": "2017-07-20T19:23:09+0000",
            "content": "Hoss Man and Steve Rowe,\n\nI've been trying to reproduce this failure using the test command given above but I can't. I also can't really solve it without reproduction, because it seems like the error has nothing to do with the analytics component. The error comes from filling a test collection with data before running analytics on that data. If the test fails because of this, it stands to reason that a lot of other tests would also fail for similar reasons. Especially the other analytics tests. I think this was a one-off failure that didn't have to do with the analytics component.\n\nOn a side note, I have a lot of new tests I can push out sometime next week that will provide a lot assurance that the component is \"done\".  ",
            "author": "Houston Putman",
            "id": "comment-16095226"
        },
        {
            "date": "2017-07-20T19:36:39+0000",
            "content": "In my opinion this ticket is done and can be marked as such. The feature is in. I'm not convinced that the test failure above (Steve Rowe) is related. And, while additional tests would be nice, I believe they should be added under another ticket all together.\n\nHoss Man, what are your thoughts on me closing this ticket? ",
            "author": "Dennis Gove",
            "id": "comment-16095247"
        },
        {
            "date": "2017-07-20T23:10:03+0000",
            "content": "i have no opinions \u2013 i just wanted to make sure it didn't get lost in the shuffle.\n\nFWIW: If the failure is coming from a cloud based test when trying to add the initial data, then a very likely possibility is that the main tests thread is trying to add docs before the all the nodes have fully come online ... many cloud tests use a helper method (waitForThingsToLevelOut i think?) to check for this first.\n\nsomething to consider. ",
            "author": "Hoss Man",
            "id": "comment-16095533"
        },
        {
            "date": "2017-07-20T23:48:56+0000",
            "content": "I thought it might be something related to the cloud not yet being ready, but QueryFacetCloudTest extends AbstractAnalyticsFacetCloudTest and calls `setupCluster` which calls `AbstractDistribZkTestBase.waitForRecoveriesToFinish`.\n\nI think after that call the cloud is ready for documents to be added. ",
            "author": "Dennis Gove",
            "id": "comment-16095572"
        },
        {
            "date": "2017-07-20T23:49:55+0000",
            "content": "Work related to this ticket is complete. ",
            "author": "Dennis Gove",
            "id": "comment-16095575"
        }
    ]
}