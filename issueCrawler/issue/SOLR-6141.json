{
    "id": "SOLR-6141",
    "title": "Schema API: Remove fields, dynamic fields, field types and copy fields; and replace fields, dynamic fields and field types",
    "details": {
        "affect_versions": "None",
        "status": "Closed",
        "fix_versions": [
            "5.1",
            "6.0"
        ],
        "components": [
            "Schema and Analysis"
        ],
        "type": "Sub-task",
        "priority": "Major",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "It should be possible, via the bulk schema API, to remove and replace the following: \n\n\tfields\n\tdynamic fields\n\tfield types\n\tcopy field directives (note: replacement is not applicable to copy fields)\n\n\n\nRemoving schema elements that are referred to elsewhere in the schema must be guarded against:\n\n\tRemoving a field type should be disallowed when there are fields or dynamic fields of that type.\n\tRemoving a field should be disallowed when there are copy field directives that use the field as source or destination.\n\tRemoving a dynamic field should be disallowed when it is the only possible match for a copy field source or destination.",
    "attachments": {
        "SOLR-6141.patch": "https://issues.apache.org/jira/secure/attachment/12704450/SOLR-6141.patch",
        "SOLR-6141-fix-TestBulkSchemaConcurrent.patch": "https://issues.apache.org/jira/secure/attachment/12707147/SOLR-6141-fix-TestBulkSchemaConcurrent.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Noble Paul",
            "id": "comment-14168240",
            "date": "2014-10-11T16:30:44+0000",
            "content": "Do we plan to do the same functionality in he bulk mode as well as the REST api ? "
        },
        {
            "author": "Steve Rowe",
            "id": "comment-14360543",
            "date": "2015-03-13T16:04:02+0000",
            "content": "Patch.\n\nThe following commands are added to the bulk schema API:\n\n\n\tdelete-field\n\tdelete-dynamic-field\n\tdelete-field-type\n\tdelete-copy-field\n\treplace-field\n\treplace-dynamic-field\n\treplace-field-type\n\n\n\nI think this is ready. "
        },
        {
            "author": "Steve Rowe",
            "id": "comment-14360546",
            "date": "2015-03-13T16:05:43+0000",
            "content": "Do we plan to do the same functionality in he bulk mode as well as the REST api ?\n\nNoble Paul, I only implemented these change in bulk mode, not in the REST api. "
        },
        {
            "author": "Steve Rowe",
            "id": "comment-14360584",
            "date": "2015-03-13T16:30:40+0000",
            "content": "FYI, replacement (as opposed to just using separate delete and add commands) is necessary when other schema elements refer to an element to be replaced - e.g. if you try to delete a field type that is used by existing fields or dynamic fields, you'll get errors.  \n\nAt first I thought this could be special-cased - we could relax checking when removing then re-adding a schema element (though figuring out that this is happening would be an interesting exercise given the bulk command structure), but that wouldn't clean up the data structure bindings (fields and dynamic fields -> field types; and copy fields -> fields and dynamic fields).\n\nSo in the implementation in the patch, when replacing a schema element, bindings are found and refreshed. "
        },
        {
            "author": "Steve Rowe",
            "id": "comment-14364590",
            "date": "2015-03-17T05:11:31+0000",
            "content": "This version of the patch modifies ZkIndexSchemaReader.updateSchema() to fully parse the remote changed schema rather than merging the local copy with the remote copy - now that the schema is (almost) fully addressable with the schema API, we can't reliably do such merges. "
        },
        {
            "author": "Steve Rowe",
            "id": "comment-14364592",
            "date": "2015-03-17T05:12:18+0000",
            "content": "I'll commit this to trunk now and let it bake for a day or two before backporting to branch_5x. "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14364594",
            "date": "2015-03-17T05:13:38+0000",
            "content": "Commit 1667175 from Steve Rowe in branch 'dev/trunk'\n[ https://svn.apache.org/r1667175 ]\n\nSOLR-6141: Schema API: Remove fields, dynamic fields, field types and copy fields; and replace fields, dynamic fields and field types "
        },
        {
            "author": "Steve Rowe",
            "id": "comment-14367264",
            "date": "2015-03-18T15:06:14+0000",
            "content": "Shalin Shekhar Mangar alerted me to TestCloudSchemaless fails he was seeing 25-30% of the time on trunk - I was able to get the same failures too, and I see there is a Policeman Jenkins failure here: http://jenkins.thetaphi.de/job/Lucene-Solr-trunk-Linux/11998/.\n\nThere is also a new TestBulkSchemaConcurrent fail: http://jenkins.thetaphi.de/job/Lucene-Solr-trunk-MacOSX/2061/.\n\nI backed out the above-described change to fully parse the remote changed schema in ZkIndexSchemaReader, and I couldn't get TestCloudSchemaless to fail.  I think this is due to a change in the schema update lock - in the old code, the schema update lock is shared by the old and new schema, but in the new code, I created a new lock with the new schema.\n\nI see the same pattern in the bulk schema api, at SchemaManager.getFreshManagedSchema(), so I suspect that this is the source of both test failures.\n\nI'll switch both to sharing the schema update lock with the old schema and beast them. "
        },
        {
            "author": "Steve Rowe",
            "id": "comment-14367347",
            "date": "2015-03-18T15:53:01+0000",
            "content": "Each of the two tests successfully passed 25 iterations of beasting each with this patch:\n\n\nIndex: solr/core/src/java/org/apache/solr/schema/SchemaManager.java\n===================================================================\n--- solr/core/src/java/org/apache/solr/schema/SchemaManager.java\t(revision 1667433)\n+++ solr/core/src/java/org/apache/solr/schema/SchemaManager.java\t(working copy)\n@@ -421,11 +421,9 @@\n       if (in instanceof ZkSolrResourceLoader.ZkByteArrayInputStream) {\n         int version = ((ZkSolrResourceLoader.ZkByteArrayInputStream) in).getStat().getVersion();\n         log.info(\"managed schema loaded . version : {} \", version);\n-        return new ManagedIndexSchema(req.getCore().getSolrConfig(),\n-            req.getSchema().getResourceName() ,new InputSource(in),\n-            true,\n-            req.getSchema().getResourceName(),\n-            version,new Object());\n+        return new ManagedIndexSchema\n+            (req.getCore().getSolrConfig(), req.getSchema().getResourceName(), new InputSource(in), \n+                true, req.getSchema().getResourceName(), version, req.getSchema().getSchemaUpdateLock());\n       } else {\n         return (ManagedIndexSchema) req.getCore().getLatestSchema();\n       }\nIndex: solr/core/src/java/org/apache/solr/schema/ZkIndexSchemaReader.java\n===================================================================\n--- solr/core/src/java/org/apache/solr/schema/ZkIndexSchemaReader.java\t(revision 1667433)\n+++ solr/core/src/java/org/apache/solr/schema/ZkIndexSchemaReader.java\t(working copy)\n@@ -108,8 +108,8 @@\n           InputSource inputSource = new InputSource(new ByteArrayInputStream(data));\n           String resourceName = managedIndexSchemaFactory.getManagedSchemaResourceName();\n           ManagedIndexSchema newSchema = new ManagedIndexSchema\n-              (managedIndexSchemaFactory.getConfig(), resourceName, inputSource,\n-                  managedIndexSchemaFactory.isMutable(), resourceName, stat.getVersion(), new Object());\n+              (managedIndexSchemaFactory.getConfig(), resourceName, inputSource, managedIndexSchemaFactory.isMutable(), \n+                  resourceName, stat.getVersion(), oldSchema.getSchemaUpdateLock());\n           managedIndexSchemaFactory.setSchema(newSchema);\n           long stop = System.nanoTime();\n           log.info(\"Finished refreshing schema in \" + TimeUnit.MILLISECONDS.convert(stop - start, TimeUnit.NANOSECONDS) + \" ms\");\n\n\n\nCommitting shortly. "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14367351",
            "date": "2015-03-18T15:54:49+0000",
            "content": "Commit 1667579 from Steve Rowe in branch 'dev/trunk'\n[ https://svn.apache.org/r1667579 ]\n\nSOLR-6141: fix schema update lock usage "
        },
        {
            "author": "Steve Rowe",
            "id": "comment-14373100",
            "date": "2015-03-22T00:38:07+0000",
            "content": "I haven't seen any more Jenkins failures.  Backporting to branch_5x shortly. "
        },
        {
            "author": "Steve Rowe",
            "id": "comment-14376782",
            "date": "2015-03-23T22:28:05+0000",
            "content": "I haven't seen any more Jenkins failures. Backporting to branch_5x shortly.\n\nI spoke too soon - both tests are still failing:\n\nTestBulkSchemaConcurrent:\nhttp://jenkins.thetaphi.de/job/Lucene-Solr-trunk-MacOSX/2076/\nhttp://jenkins.thetaphi.de/job/Lucene-Solr-trunk-MacOSX/2084/\n\nTestCloudSchemaless:\nhttp://jenkins.thetaphi.de/job/Lucene-Solr-5.x-MacOSX/2039/\n\nI'm investigating. "
        },
        {
            "author": "Steve Rowe",
            "id": "comment-14379366",
            "date": "2015-03-25T06:20:57+0000",
            "content": "\nI spoke too soon - both tests are still failing:\nTestBulkSchemaConcurrent:\nhttp://jenkins.thetaphi.de/job/Lucene-Solr-trunk-MacOSX/2076/\nhttp://jenkins.thetaphi.de/job/Lucene-Solr-trunk-MacOSX/2084/\n\nThe attached patch fixes this test.  The failures were a combination of incorrect test sequencing (attempting to delete a field and a dynamic field before deleting a copy field directive that refers to them); a couple of unwarranted attempts to access non-existent entries in copyFieldTargetCounts; and failing to fail a field deletion when a dynamic copy field directive has it as its source.\n\nI've beasted this test with 50 iterations, no failures.  Committing shortly.\n\n\nTestCloudSchemaless:\nhttp://jenkins.thetaphi.de/job/Lucene-Solr-5.x-MacOSX/2039/\n\nI can't get this one to reproduce "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14379370",
            "date": "2015-03-25T06:25:26+0000",
            "content": "Commit 1669055 from Steve Rowe in branch 'dev/trunk'\n[ https://svn.apache.org/r1669055 ]\n\nSOLR-6141: fix TestBulkSchemaConcurrent; fix field deletion to fail when a dynamic copy field directive has the field as its source; don't attempt to decrement a SchemaField's count in copyFieldTargetCounts if it's not present in the map. "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14380312",
            "date": "2015-03-25T17:32:31+0000",
            "content": "Commit 1669173 from Steve Rowe in branch 'dev/trunk'\n[ https://svn.apache.org/r1669173 ]\n\nSOLR-6141: fix TestBulkSchemaAPI (expected exception message changed) "
        },
        {
            "author": "Steve Rowe",
            "id": "comment-14380409",
            "date": "2015-03-25T18:21:09+0000",
            "content": "I plan on backporting to branch_5x today. "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14382467",
            "date": "2015-03-26T19:11:37+0000",
            "content": "Commit 1669413 from Steve Rowe in branch 'dev/branches/branch_5x'\n[ https://svn.apache.org/r1669413 ]\n\nSOLR-6141: Schema API: Remove fields, dynamic fields, field types and copy fields; and replace fields, dynamic fields and field types (merged trunk r1667175,r1667579,r1669055,r1669173) "
        },
        {
            "author": "Steve Rowe",
            "id": "comment-14382471",
            "date": "2015-03-26T19:13:15+0000",
            "content": "Committed to trunk and branch_5x. "
        },
        {
            "author": "Timothy Potter",
            "id": "comment-14495325",
            "date": "2015-04-15T00:30:37+0000",
            "content": "Bulk close after 5.1 release "
        }
    ]
}