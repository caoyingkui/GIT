{
    "id": "LUCENE-4161",
    "title": "Make PackedInts usable by codecs",
    "details": {
        "labels": "",
        "priority": "Minor",
        "components": [
            "core/store"
        ],
        "type": "Improvement",
        "fix_versions": [
            "4.0-ALPHA"
        ],
        "affect_versions": "None",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "Some codecs might be interested in using PackedInts.\n{Writer,Reader,ReaderIterator}\n to read and write fixed-size values efficiently.\n\nThe problem is that the serialization format is self contained, and always writes the name of the codec, its version, its number of bits per value and its format. For example, if you want to use packed ints to store your postings list, this is a lot of overhead (at least ~60 bytes per term, in case you only use one Writer per term, more otherwise).\n\nUsers should be able to externalize the storage of metadata to save space. For example, to use PackedInts to store a postings list, one should be able to store the codec name, its version and the number of bits per doc in the header of the terms+postings list instead of having to write it once (or more!) per term.",
    "attachments": {
        "LUCENE-4161.patch": "https://issues.apache.org/jira/secure/attachment/12533344/LUCENE-4161.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2012-06-21T15:01:58+0000",
            "content": "+1\n\nWe could really use this on LUCENE-3892 where the FOR postings format is really just packed ints.  Would be best if we could simply efficiently use oal.util.packed.* for this. ",
            "author": "Michael McCandless",
            "id": "comment-13398473"
        },
        {
            "date": "2012-06-25T17:50:34+0000",
            "content": "First version of the patch.\n\nA few things that were internal now need to be exposed, so I tried to do some clean up:\n\n\tCODEC_NAME and CODEC_VERSION\n{START,CURRENT}\n are public,\n\tthe format is an enum (PackedInts.Format.\n{PACKED,PACKED_SINGLE_BLOCK}\n),\n\timproved docs overall.\n\n\n\nThere are new factory methods get\n{Reader,ReaderIterator,Writer}NoHeader that do the same as their get{Reader,ReaderIterator,Writer}\n counterpart, but with no header writing/checking.\n\nImproved performance of Reader/Mutable bulk methods (using code generation, see http://people.apache.org/~jpountz/packed_ints.html vs. http://people.apache.org/~jpountz/packed_ints2.html).\n\nReaderIterator and Writer now use the same code as Reader/Mutable bulk methods so they are likely to be much faster too. In addition, ReaderIterator now allows consumers to retrieve several values at the same time.\n\nDirect* and Packed*ThreeBlocks had a lot of duplicate code that was not factorizable so I created scripts to generate them.\n\nSomething that might still slow down ReaderIterator (probably the most useful class for codecs) a bit is that ReaderIterator always reads one long at a time. Adding a method to bulk-read longs to DataInput (similarly to readBytes) might improve performance. This probably deserves an other issue in JIRA and can be done later. ",
            "author": "Adrien Grand",
            "id": "comment-13400720"
        },
        {
            "date": "2012-06-29T11:35:21+0000",
            "content": "Wow, this patch is impressive!  Lots of amazing changes... very cool\nhow you factored out a simple common API for bulk write/read of all\nthe formats.\n\nShould computeN be non-static method on BulkOperation base class?\n(Just seems odd to make a static method whose first arg is an instance\nof that class anyway...).\n\nCan we find a better name for computeN?  I think n is the number of\nblocks we can buffer up given the RAM \"budget\"?  computeNumBlocks?\ncomputeNumBufferedBlocks?  computeBufferedBlocksCount?  Something\nelse...?\n\nI suspect, to use these for codecs, we will want to have versions that\nwork on int[] values instead (everything we encode are ints:\ndocIDs/deltas, term freqs, offsets, positions).\n\nCode styling: can we use three lines, ie:\n\n-    if (valueCount > MAX_SIZE) {\n-      throw new ArrayIndexOutOfBoundsException(\"MAX_SIZE exceeded\");\n-    }\n\n\ninstead of one line:\n\n+    if (valueCount > MAX_SIZE) { throw new ArrayIndexOutOfBoundsException(\"MAX_SIZE exceeded\"); }\n\n\nin general?\n\nDoes this change the on-disk format?  I think no?  (if those\nFormat.getId()s match?)  If it does change we need back compat (4.0.0 alpha\nhas left the station...). ",
            "author": "Michael McCandless",
            "id": "comment-13403843"
        },
        {
            "date": "2012-06-29T13:57:10+0000",
            "content": "Can we find a better name for computeN?\n\nThe meaning of n is actually a bit complicated. For every number of bits per value, there is a minimum number of blocks (b) / values (v) you need to write in order to reach the next block boundary:\n\n\t16 bits per value -> b=1, v=4\n\t24 bits per value -> b=3, v=8\n\t50 bits per value -> b=25, v=32\n\t63 bits per value -> b=63, v = 64\n\t...\n\n\n\nA bulk read consists in copying n*v values that are contained in n*b blocks into a long[] (higher values of n are likely to yield a better throughput) => this requires n * (b + v) longs in memory, this is why I compute n as ramBudget / (8 * (b + v)) (since a long is 8 bytes). I called it n in the method name because I have no idea how to name it... \"iterations\", maybe?\n\nI suspect, to use these for codecs, we will want to have versions that work on int[] values instead (everything we encode are ints: docIDs/deltas, term freqs, offsets, positions).\n\nI hesitated to do this since it would involve some code duplication, but I guess it can't be avoided if we want this API to be actually used... What additional methods do you think we need?\n\n\tPackedReaderIterator.nextInts(int count)\n\tothers?\n\n\n\n[static computeN], [code style]\n\nYou are right, I will fix it!\n\nDoes this change the on-disk format?\n\nNo, it doesn't. I will add unit tests for that... ",
            "author": "Adrien Grand",
            "id": "comment-13403910"
        },
        {
            "date": "2012-06-30T23:59:51+0000",
            "content": "The meaning of n is actually a bit complicated.\n\nThank you for the explanation!  That makes sense.  I think \"iterations\" is good?  Or ... maybe we simply leave it as n and then put this nice explanation in there as a comment?\n\nNaming is the hardest part \n\nWhat additional methods do you think we need?\n\nI'm not sure off-hand yet ... we've been iterating in LUCENE-3892 to find the least-cost way to decode from the underlying byte based storage from the IndexInput, but with no real clear fastest solution yet.  Logically we are currently storing an int[] and decoding into int[], so I guess encode/decode to/from int[]?  We should probably try long[] as the backing too ... but, I think we should explore this (adding int[] based methods) under a new issue?  This patch is already great progress. ",
            "author": "Michael McCandless",
            "id": "comment-13404656"
        },
        {
            "date": "2012-07-03T22:57:04+0000",
            "content": "New patch. I renamed 'n' to 'iterations', fixed the style issues and improved documentation. All core tests pass, including the backward-compatibility tests I added in r1356228.\n\nI think this is a good idea to work on int[] encoding/decoding in a separate issue given how big this patch already is. ",
            "author": "Adrien Grand",
            "id": "comment-13406144"
        },
        {
            "date": "2012-07-04T00:03:57+0000",
            "content": "+1, patch looks great! ",
            "author": "Michael McCandless",
            "id": "comment-13406190"
        },
        {
            "date": "2012-07-04T09:41:41+0000",
            "content": "Thanks, Mike! Committed (r1357159 on trunk and r1357166 on branch 4.x). ",
            "author": "Adrien Grand",
            "id": "comment-13406397"
        },
        {
            "date": "2012-07-18T12:27:28+0000",
            "content": "Hi Adrien, we're trying to use PackedInts in LUCENE-3892 to compress/decompress an int array. Currently, to support block skipping, we need to know the on-disk size of a compressed block before it is written into output stream. Seems that PackedInts.Reader.ramBytesUsed() doesn't meet the requirement? Do we have other methods to solve this problem? ",
            "author": "Han Jiang",
            "id": "comment-13417027"
        },
        {
            "date": "2012-07-18T13:07:22+0000",
            "content": "Hi! I think PackedInts.Format.PACKED.nblocks(bitsPerValue, n) should help. It returns the number of long blocks required to store n bitsPerValue-bits values.\n\nOn your pfor branch, I'm afraid instantiating a PackedInts.ReaderIterator for every block would hurt performance since blocks only contain 128 values. Maybe the easiest way to go would be to try to replace calls to PackedIntsDecompress.decode* with calls to PackedInts.BulkOperation.get/set. These methods are not exposed yet and only work with longs but if it looks good to you, I should be able to come up with something in the next few days...\n ",
            "author": "Adrien Grand",
            "id": "comment-13417054"
        }
    ]
}