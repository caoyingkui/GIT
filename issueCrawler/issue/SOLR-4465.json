{
    "id": "SOLR-4465",
    "title": "Configurable Collectors",
    "details": {
        "affect_versions": "4.1",
        "status": "Closed",
        "fix_versions": [
            "4.8"
        ],
        "components": [
            "search"
        ],
        "type": "New Feature",
        "priority": "Major",
        "labels": "",
        "resolution": "Unresolved"
    },
    "description": "This ticket provides a patch to add pluggable collectors to Solr. This patch was generated and tested with Solr 4.1.\n\nThis is how the patch functions:\n\nCollectors are plugged into Solr in the solconfig.xml using the new collectorFactory element. For example:\n\n<collectorFactory name=\"default\" class=\"solr.CollectorFactory\"/>\n<collectorFactory name=\"sum\" class=\"solr.SumCollectorFactory\"/>\n\nThe elements above define two collector factories. The first one is the \"default\" collectorFactory. The class attribute points to org.apache.solr.handler.component.CollectorFactory, which implements logic that returns the default TopScoreDocCollector and TopFieldCollector. \n\nTo create your own collectorFactory you must subclass the default CollectorFactory and at a minimum override the getCollector method to return your new collector. \n\n\nThe parameter \"cl\" turns on pluggable collectors:\n\ncl=true\n\nIf cl is not in the parameters, Solr will automatically use the default collectorFactory.\n\n\nPluggable Doclist Sorting With the Docs Collector\n\n\nYou can specify two types of pluggable collectors. The first type is the docs collector. For example:\n\ncl.docs=<name>\n\nThe above param points to a named collectorFactory in the solrconfig.xml to construct the collector. The docs collectorFactorys must return a collector that extends the TopDocsCollector base class. Docs collectors are responsible for collecting the doclist.\n\nYou can specify only one docs collector per query.\n\nYou can pass parameters to the docs collector using local params syntax. For example:\n\ncl.docs={! sort=mycustomesort}mycollector\n\nIf cl=true and a docs collector is not specified, Solr will use the default collectorFactory to create the docs collector.\n\n\nPluggable Custom Analytics With Delegating Collectors\n\nYou can also specify any number of custom analytic collectors with the \"cl.analytic\" parameter. Analytic collectors are designed to collect something else besides the doclist. Typically this would be some type of custom analytic. For example:\n\ncl.analytic=sum\n\nThe parameter above specifies a analytic collector named sum. Like the docs collectors, \"sum\" points to a named collectorFactory in the solrconfig.xml. You can specificy any number of analytic collectors by adding additional cl.analytic parameters.\n\nAnalytic collector factories must return Collector instances that extend DelegatingCollector. \n\nA sample analytic collector is provided in the patch through the org.apache.solr.handler.component.SumCollectorFactory.\n\nThis collectorFactory provides a very simple DelegatingCollector that groups by a field and sums a column of floats. The sum collector is not designed to be a fully functional sum function but to be a proof of concept for pluggable analytics through delegating collectors.\n\nYou can send parameters to analytic collectors with solr local param syntax.\n\nFor example:\n\ncl.analytic={! id=1 groupby=field1 column=field2}sum\n\nThe \"id\" parameter is mandatory for analytic collectors and is used to identify the output from the collector. In this example the \"groupby\" and \"column\" params tell the sum collector which field to group by and sum.\n\nAnalytic collectors are passed a reference to the ResponseBuilder and can place maps with analytic output directory into the SolrQueryResponse with the add() method.\n\nMaps that are placed in the SolrQueryResponse are automatically added to the outgoing response. The response will include a list named cl.analytic.<id>, where id is specified in the local param.\n\n\nDistributed Search\n\nThe CollectorFactory also has a method called merge(). This method aggregates the results from each of the shards during distributed search. The \"default\" CollectoryFactory implements the default merge logic for merging documents from each shard. If you define a different docs collector you can override the default merge method to merge documents in accordance with how they are collected at the shard level.\n\nWith analytic collectors, you'll need to override the merge method to merge the analytic output from the shards. An example of how this works is provided in the SumCollectorFactory.\n\nEach collectorFactory, that is specified in the http parameters, will have its merge method applied by the Solr aggregator node.\n\nTesting the Patch With Sample Data\n\n1) Apply patch to Solr 4.1\n2) Load sample data\n3) Send the http command:\n\nhttp://localhost:8983/solr/select?q=*:*&cl=true&facet=true&facet.field=manu_id_s&cl.analytic=%7B!+id=%271%27+groupby=%27manu_id_s%27+column=%27price%27%7Dsum",
    "attachments": {
        "SOLR-4465.patch": "https://issues.apache.org/jira/secure/attachment/12570181/SOLR-4465.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Joel Bernstein",
            "id": "comment-13582514",
            "date": "2013-02-20T21:02:24+0000",
            "content": "First patch which adds the code to read the collectorFactory element from the solrconfig.xml. This will be iterated to add more detail. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13582520",
            "date": "2013-02-20T21:12:46+0000",
            "content": "Added CollectorFactory.java to patch "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13582573",
            "date": "2013-02-20T22:01:59+0000",
            "content": "Added CollectorParams.java to hold the http collector parameters. Using the prefix \"cl\" collector parameters. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13583167",
            "date": "2013-02-21T13:15:00+0000",
            "content": "Gathering up the collector http parameters and setting the collectorSpec on the QueryCommand. Ready for use in the SolrIndexSearcher. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13583339",
            "date": "2013-02-21T16:41:46+0000",
            "content": "Added custom collectors to: SolrIndexSearcher.getDocListNC, SolrIndexSearcher.getDocListAndSetNC\n "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13584307",
            "date": "2013-02-22T14:32:10+0000",
            "content": "Refactored SolrIndexSearcher.getDocListNC and SolrIndexSearch.getDocListAndSet to clean up Collector creation. The CollectorFactory now has default logic for choosing between TopScoreDocCollector and TopFieldCollector.\n\nThis patch is a full (untested) implementation of configurable collectors at the shard level. Design description to follow. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13584447",
            "date": "2013-02-22T17:13:31+0000",
            "content": "Here is how custom collectors work:\n\nThere is a new \"collectorFactory\" element in solrconfing.xml. The design was deliberately kept very simple:\n\n<collectorFactory name=\"default\" class=\"solr.CollectorFactory\"/>\n\nThere can be multiple collectorFactory elements defined. The \"name\" attribute is used as a handle to dynamically select a specific CollectorFactory implementation at query time. The \"class\" attribute is a subclass of org.apache.solr.core.CollectorFactory which defines the logic for creating the collector used for a specific query. The base class provides an implementation with default logic for choosing between the TopScoreDocCollector and TopFieldCollector. \n\nThere are also new collector parameters that allow the user to select a collector factory by name with the following syntax:\n\ncl.name=<name>\n\nAll parameters that begin with \"cl.\" will be gathered up and passed to the CollectorFactory through the QueryCommand. These parameters can be used to dynamically configure collector algorithms at query time.\n\n\n "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13586834",
            "date": "2013-02-26T06:10:21+0000",
            "content": "This patch moves QueryComponent.mergeIds to the CollectorFactory. This allows the CollectorFactory to control both the shard level collection of results and the merging of distributed results.\n\nThe CollectorFactory was also moved from org.apache.solr.core in previous patches to org.apache.solr.handler.component.\n\nThis patch is a full (untested) configurable collector implementation at the shard level and at the distributed search level.\n\nTesting and test cases will follow. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13586851",
            "date": "2013-02-26T06:31:15+0000",
            "content": "Looking good Joel! One early comment - can you format new code to the lucene style guide? http://wiki.apache.org/lucene-java/HowToContribute#Helpful_Resources\n\nIt's fine to leave existing breakages from it, but we should stick to it for new code. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13587138",
            "date": "2013-02-26T14:04:39+0000",
            "content": "Sure, I'll take a look at the style guide and reformat the code. Thanks for the feedback. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13587362",
            "date": "2013-02-26T18:31:23+0000",
            "content": "Code reformatted to Lucene style. Seems to look good in intellij and vi. "
        },
        {
            "author": "Markus Jelsma",
            "id": "comment-13587409",
            "date": "2013-02-26T19:07:57+0000",
            "content": "This is very cool Joel! I'm sure to rewrite our SolrIndexSearcher and custom collections to use this factory. Will you also allow collectors to return a numeric value which will be written to the output in response builder? "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13587469",
            "date": "2013-02-26T19:58:09+0000",
            "content": "Could you share some of the use cases for this feature?\nWe already have the ability to insert collectors via a custom query that implements the PostFilter interface. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13587519",
            "date": "2013-02-26T20:43:14+0000",
            "content": "Sure.\n\nOne use case would be to control distribution of document types within a result set. For example if you wanted to ensure that each page had 10% of content type A and 50% of type B and 40% of type C.\n\nYou could insert a custom collector that would manage this. The mergeIds() method would becomes part of the collectorFactory so that the algorithm used at the shard level could be maintained over distributed search.\n "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13587611",
            "date": "2013-02-26T21:58:23+0000",
            "content": "Markus, returning numeric values from the collector would be great. The custom collector could optionally implement a method that returns an Object that could become part of the response. This would allow custom analytics to be included with docLists. This opens up a whole range of possible use cases.  "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13587652",
            "date": "2013-02-26T22:17:21+0000",
            "content": "Yonik, I took a look at the PostFilter interface and I think it serves a different purpose. It appears that post filters run before the sorting, ranking collectors and are used to filter out results.\n\nThe configurable custom collector replaces the ranking and sorting collectors, are used to sort, rank and aggregate in custom ways.\n "
        },
        {
            "author": "Markus Jelsma",
            "id": "comment-13587653",
            "date": "2013-02-26T22:17:26+0000",
            "content": "Yes Joel, that would be very welcome indeed. We already add up statistics returned by custom collectors in the QueryComponent. With the current patch this is still an issue for us. I'd love to implement an interface and provide a Map<String, Float> getStats() method which would then be summed up.\n\nThe most relevant use case for us is that we do online result deduplication, but still need the total number for numRows without deduplication as well ass the real number of (deduplicated) results. "
        },
        {
            "author": "Varun",
            "id": "comment-13587709",
            "date": "2013-02-26T23:01:48+0000",
            "content": "This is great .. One usecase we have is collector collects the document depending upon some parameters which we pass, e.g. score cutoff ( fq with score doesn't work as score function doesn't work if you have custom Query classes)  "
        },
        {
            "author": "Greg Bowyer",
            "id": "comment-13587815",
            "date": "2013-02-27T00:58:04+0000",
            "content": "The tests are giving me null pointer exceptions inside SolrIndexSearcher for this, as for the stats part I was looking at this patch and giving some thought about providing that on the QueryCommand object, but I feel that it is not the correct place for this information. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13587855",
            "date": "2013-02-27T01:40:14+0000",
            "content": "Greg, haven't had a chance to test out the patch yet, so right now it's just for review purposes. I plan on testing and adding test cases next week. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13587918",
            "date": "2013-02-27T02:25:06+0000",
            "content": "Just applied the patch on Solr 4.1 and it runs fine for basic scoring and ranking searches using the default CollectorFactory. \n\nAs Greg mentioned, tests will fail because it expects solrconfig.xml to have a default collectorFactory defined. Code will have to be added to make it gracefully use the default collectorfactory if it's undefined in solrconfig.xml.\n\nSo the patch is ready to be played with. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13588271",
            "date": "2013-02-27T12:49:06+0000",
            "content": "New patch that gives the QueryCommand a reference to the ResponseBuilder.\n\nThe QueryCommand is passed to the CollectorFactory so custom collectors now have direct access to the ResponseBuilder and can add objects directly to the response. "
        },
        {
            "author": "Dan Rosher",
            "id": "comment-13589637",
            "date": "2013-02-28T16:20:32+0000",
            "content": "How will this work with grouping? "
        },
        {
            "author": "Dan Rosher",
            "id": "comment-13590382",
            "date": "2013-03-01T09:46:59+0000",
            "content": "Looking at the patch I think that \"default\" needs to be in the solrconfig otherwise it would result in a npe. Perhaps replace \"default\" with new DefaultCollectorFactory(...) ? Also if the user requests a collector that dosen't exist, this results in a npe too, Would it be better to throw an exception in this case? The other option is to fall back to a default but this would give unexpected results. \n\nAdditionally since the collector is free to alter results between requests, I think it should be used to create the QueryResultKey object for caching docSets, otherwise you going to get unexpected results. Perhaps CollectorFactory should be an interface with signatures for getCollector,getDocSetCollector and hashCode and equals. QueryResultKey can then delegate to CollectorFactory.hashCode. Then have a default implementation implementing the current hashCode for QueryResultKey. This would ensure CollectorFactory implementors have thought about hashCode and are free to simply extend the default CollectorFactory if they wish.  "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13592576",
            "date": "2013-03-04T20:05:09+0000",
            "content": "Dan,\n\nThis patch doesn't work with grouping because grouping is done within a separate flow with a separate set of collectors. SOLR-1680 was a custom collectors patch that was meant to allow grouping to be merged into the main flow, but was never committed. Possibly grouping could be implemented using a collector factory but that would be a follow-on to getting this as part of the core.\n\nI'll work on resolving the npe with the default collector in the next patch.\n\nAs you mentioned the caching implications here need to be fully understood. Perhaps you could elaborate on \"Additionally since the collector is free to alter results between requests\". Can you explain the use case where this would occur?\n "
        },
        {
            "author": "Dan Rosher",
            "id": "comment-13593265",
            "date": "2013-03-05T09:44:33+0000",
            "content": "We have a use case where docSets change depending on certain querytime request parameters, in addition to query and filters. A custom sort won't do for us since we need to know things after collection, hence we'd return the custom docset via TopCollector.topDocs. "
        },
        {
            "author": "David Smiley",
            "id": "comment-13593505",
            "date": "2013-03-05T15:49:02+0000",
            "content": "I have a need for this too.  I'd like to find out the maximum value of the score and of a couple separate function queries, and then after use those 3 metrics in a relevancy formula to sort the results on.  My tentative approach today is to write a custom search component that will calculate those metrics by executing the search before the QueryComponent, and then by the time the QC gets it at least the filter queries will already be cached by then. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13594122",
            "date": "2013-03-06T00:01:15+0000",
            "content": "Dan, it does look like the CollectorFactory is going to have to play a role in creating the QueryResultKey. The same query executed with different collectors will have different result sets. But with the current patch they would have the same QueryResultKey. I will try to work this into the next patch.\n "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13594852",
            "date": "2013-03-06T16:42:19+0000",
            "content": "New patch with a couple of additions:\n\n1) Added code during initialization of the collectorFactories to handle condition where default collectorFactory is not defined in solrconfig.xml. This makes this patch backwords compatible with 4.* solrconfigs.\n\nTests now run without null pointers.\n\n2) Added the CollectorSpec class to hold the collector http parameters. This class will implement hashCode and equals and will be added to QueryResultKey. The QueryResultKey implementation is not in this patch so more work still needs be done on getting this cache ready.\n\nThis patch has been tested with the default collector factory with sorting and ranking queries and in distributed mode. "
        },
        {
            "author": "Andy Laird",
            "id": "comment-13595658",
            "date": "2013-03-07T08:00:03+0000",
            "content": "Thanks Joel,\nThis is the exact use case that we need.  We have 100 or so different brands (high-end to low-end) and we want to provide results containing a configurable mixture of documents from each brand \u2013 for \"big spenders\", for example, we'd like to showcase more high-end brands.  We'd also like to mix up the results by other dimensions, too.  It's almost guaranteed that the results for a given query contain docs that have lower score than subsequent ones (from a Lucene scoring point-of-view), only so we can provide variety.  It's more than just a sort algorithm \u2013 the pathological case is a query for 100 results where all of the top scores are from a single brand.  We clearly will have to think about some sort of \"slop factor\" (how many documents to consider before giving up, etc.) to make this work, but this gives us a great starting point. "
        },
        {
            "author": "David Smiley",
            "id": "comment-13596027",
            "date": "2013-03-07T16:26:56+0000",
            "content": "Andy, have you considered using Result Grouping / Field Collapsing for your use-case? "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13596252",
            "date": "2013-03-07T19:32:29+0000",
            "content": "QueryResultKey now uses the CollectorSpec to compute hashCode() and equals().\n\nThis still needs lots of testing, but collectorFactories now play nicely with caching.\n "
        },
        {
            "author": "Andy Laird",
            "id": "comment-13597840",
            "date": "2013-03-09T04:26:58+0000",
            "content": "Thanks, David...\n\nYes, we are actually already using FieldCollapse for other purposes.  In our schema different groupings of docs \u2013 we call them \"stacks\" \u2013 share the same value for a field X.  For a given query we only want one \"best result\" (the so-called \"hero\" doc) from a bunch of docs that score high but have the same value for X. "
        },
        {
            "author": "Greg Bowyer",
            "id": "comment-13600324",
            "date": "2013-03-12T18:50:27+0000",
            "content": "Does the CollectorSpec serve the same purpose as say the GroupingSpecification, that is to provide underlying collectors (and the search in general) with the right requirements information.\n\nI ask because maybe it would be easier to make the CollectorSpec support a map of String -> Object or String -> CollectorProperty\n\nI am trying to think how we can do grouping with this.\n\n.... but I might have misinterpreted what its for "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13600410",
            "date": "2013-03-12T20:07:39+0000",
            "content": "Added support for delegating collectors.\n\nThis design specifies a single \"topdocs\" collector and any number of \"delegating\" collectors.\n\nThe \"topdocs\" collector collects the doclist and docset. The delegating collectors are designed to collect aggregate data of some kind.\n\nAccordingly there are two collector parameters:\n\ncl.topdocs=<topdocs collector name>\ncl.delegating=<comma separated list of delegating collectors>\n\nBoth of these parameters refer to collectorFactories configured in the solrconfig.xml.\n\nParameters are passed to the collectors by name. For example:\n\ncl.topdocs=default&cl.delegating=sum&cl.sum.groupby=field1&cl.sum.column=field2\n\nIn this example the topdocs collector is the \"default\" collector. The delegating collector is the \"sum\" collector. Both of these refer to named collectorFactories in solrconfig.xml. The sum collector is being passed two parameters \"groupby\" and \"column\", telling it to groupby field1 and sum field2. \n\n\nThe delegating collectors have access to the ResponseBuilder and through that can add Maps directly to the SolrQueryResponse.\n\nBoth the topdocs collector and the delegating collectors take part in the merge of distributed results from shards through the collectorFactory merge method.\n\nThis paves the way for pluggable distributed analytics to be included with search results.\n\nTODO: I believe Maps that are placed in the SolrQueryResponse are automatically output but some work needs to be done get them read in the solrj QueryResponse class so they can be merged.\n\nA simple example delegating collector to test the entire flow needs to be created. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13601215",
            "date": "2013-03-13T15:06:38+0000",
            "content": "Added a very simple delegating collector through the class SumCollectorFactory.\n\nThis is a proof of concept for pluggable analytics using delegating collectors.\n\nThis patch was created from the Solr 4.1 tag.\n\nTo test it, apply the patch to Solr 4.1, load the sample data and issue the following query\n\nhttp://localhost:8983/solr/collection1/select?q=*:*&wt=xml&indent=true&cl=on&cl.topdocs=default&cl.delegating=sum&cl.sum.groupby=manu_id_s&cl.sum.column=price\n\nYour output will include a lst called sum which contains the output for grouping on the manu_id_s field and summing the price field.\n\nNOTE: If you reload the page the sum list will go away. This is because delegating collectors at this point don't support the query result cache.\n\n\nTODO:\n\nThe distributed support for this still needs to be added. \n\nCollector parameters need to support Solr local params syntax.\n\nDeal with the query result cache issue. Most likely it's easiest just to add a flag to turn off query result caching if delegating collectors are being used. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13602838",
            "date": "2013-03-14T22:30:45+0000",
            "content": "Added the merge() method to the SumCollectorFactory. This adds the distributed support for the proof of concept for pluggable analytics using delegating collectors.\n\nAlso changed the parameter spec to use ordinals to send parameters to the correct collector. For example if three delegating collectors are specified as:\n\ncl.delegating=sum,ave,min\n\nThe ordinals for the three collectors would be 0,1,2.\n\nTo pass parameters to sum collector factory you include the ordinal after the \"cl\".\n\nFor example:\n\ncl.0.groupby=manu\n\nTells the collector at ordinal 0 (sum) to groupby the manu field.\n\nAlso changed caching logic so that if delegating collectors are used QueryResultCaching is turned off.\n\nTODO: \n\nTest, Test cases.\n\nUpdate the Description of this ticket to include full specification. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13605481",
            "date": "2013-03-18T19:03:21+0000",
            "content": "Changed the CollectorSpec to hold a string->object map. \n\nGreg, hopefully this will help bring it in line with the grouping needs. The CollectorSpec is used to pass parameters at query time to the collectors.\n\nAlso formalized the parameter passing to delegating collectors. Now you use both the name and the ordinal in the parameter. For example:\n\ncl.delegating=sum&cl.sum.0.column=price\n\nThis tells the \"sum\" collector at ordinal 0 to sum the column \"price\".\n\nWill update the description of this ticket to have a detailed description of how pluggable collectors work. "
        },
        {
            "author": "Erik Hatcher",
            "id": "comment-13606252",
            "date": "2013-03-19T11:43:08+0000",
            "content": "Joel - nice work!\n\nA few comments:\n\n\n\tBefore trying the exact link you provided in the description to a working example, I tried http://localhost:8983/solr/select?q=*:*&cl=on&cl.delegating=sum&cl.sum.0.column=price without specifying cl.topdocs=default and got an error.  Maybe if there is no cl.topdocs specified, it should automatically use the \"default\"?\n\n\n\n\n\tThe additional info in the response (<lst name=\"cl.sum.0\"> in this example) is coming out before/above the results (<result name=\"response\"...>).  This should probably come out after the results to avoid any issues with clients that are looking for the results in a particular spot (which of course they shouldn't be, but if we can easily move it after the results that would be better)\n\n\n\n\n\tI'm not fond of the ordinals.  Seems like we can do away with them somehow, leveraging local params.  I'm not sure how that would look just yet, and maybe ordinals is the best way here but it's a new kind of syntax for parameters that would be nice to avoid if possible.\n\n "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13609016",
            "date": "2013-03-21T15:06:34+0000",
            "content": "Switched to local param syntax for collectors. \n\nTODO:\nUpdate the description "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13610263",
            "date": "2013-03-22T13:38:41+0000",
            "content": "Changed the parameter names to be more user friendly. Description will be updated with new parameter names shortly. "
        },
        {
            "author": "Greg Bowyer",
            "id": "comment-13664722",
            "date": "2013-05-23T00:07:56+0000",
            "content": "Is there anything remaining for this ?  "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13665204",
            "date": "2013-05-23T14:11:27+0000",
            "content": "Greg, I had some feedback offline from Yonik about this ticket. He had concerns in two areas. \n\nThe first was that allowing collectors to be specified as a query parameter was picking low level components for Solr to use. He preferred that the interface change to something less low level and more high level like \"custom ranking\". This would mean providing an interface that wouldn't reference collectors directly but instead reference a ranking configuration in solrconfig. The ranking config would include a collector and other parameters that would be needed to make it work. So this is mainly a cosmetic change.\n\nThe second concern was that using delegating collectors for pluggable analytics clashed with both grouping and queryResultCaching, and more thought needed to be put into a generic pluggable analytics framework. My plan was to remove this capability and create a separate \"collector\" search component that would allow people to collect anything they wanted based on the resulting DocSet of a search. This wouldn't clash with grouping or queryResultCaching.\n\nCurious to hear your thoughts on this ticket and where you'd like to see it go. "
        },
        {
            "author": "Greg Bowyer",
            "id": "comment-13665319",
            "date": "2013-05-23T16:26:57+0000",
            "content": "I agree with both of Yonik's points, I would be tempted to split this patch into two, and cover the first part here, with analytic / aggregation functions in a follow up patch.\n\nDo you want any help with this patch? cutting it up, testing etc ? "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13665947",
            "date": "2013-05-24T01:56:02+0000",
            "content": "I think that this makes sense. I also like the idea of moving the grouping code into a configurable ranking module, possibly as a third ticket.\n\nThere are a couple of other tickets that I'm close to finishing up and then I can revisit this one. \n\nIf you'd like to jump in and create one of the other tickets that would be great and I'll join in soon.\n "
        },
        {
            "author": "Greg Bowyer",
            "id": "comment-13693251",
            "date": "2013-06-25T18:37:37+0000",
            "content": "Life keeps getting in the way, I have crafted two sub-tasks on this, I would be interested in working through this with you. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13693926",
            "date": "2013-06-26T11:49:27+0000",
            "content": "Greg,\n\nOn task number two I'm wondering if we could use the standard post filter approach to inject new collectors. Then all we would need is a search component that handles the merge from the shards. This approach could be done with plugins so we wouldn't have to alter the core. The main work then would be a search component that would allow for pluggable merging algorithms. This could be useful in many contexts. We'd need to see how this component would fit in the distributed flow.\n\nJoel   "
        },
        {
            "author": "Otis Gospodnetic",
            "id": "comment-13694984",
            "date": "2013-06-27T19:33:07+0000",
            "content": "Joel,\n\nThe CollectorFactory also has a method called merge(). This method aggregates the results from each of the shards during distributed search. The \"default\" CollectoryFactory implements the default merge logic for merging documents from each shard. If you define a different docs collector you can override the default merge method to merge documents in accordance with how they are collected at the shard level.\n\nand\n\nThen all we would need is a search component that handles the merge from the shards. .... We'd need to see how this component would fit in the distributed flow.\n\nCould this be used for http://search-lucene.com/m/F11c122nSe81&subj=Querying+across+multiple+identical+Collections as well?\n "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13695001",
            "date": "2013-06-27T19:52:49+0000",
            "content": "Otis,\n\nYou can query across multiple collections with the \"collection\" parameter:\n\nhttp://localhost:8983/solr/collection1/select?collection=collection1_NY,collection1_NJ,collection1_CT\n\nYou can also setup an alias for multiple collections and then search the alias.\n\nThis is a nice approach because you can simply change the alias to point to a different set of collections and it will be transparent to you're application.  "
        },
        {
            "author": "Greg Bowyer",
            "id": "comment-13697035",
            "date": "2013-07-01T18:15:57+0000",
            "content": "\nOn task number two I'm wondering if we could use the standard post filter approach to inject new collectors. Then all we would need is a search component that handles the merge from the shards. This approach could be done with plugins so we wouldn't have to alter the core. The main work then would be a search component that would allow for pluggable merging algorithms. This could be useful in many contexts. We'd need to see how this component would fit in the distributed flow.\n\nSounds resonable, although I am not quite sure what you mean by plugins in this context "
        },
        {
            "author": "Otis Gospodnetic",
            "id": "comment-13697457",
            "date": "2013-07-02T03:20:07+0000",
            "content": "Can we have this for Solr 4.4? \nHm, any unit tests?\n\nI spotted a few typos:\n\n\tEMPTY_DELGATING\n\tsigniture, topDocsSigniture, maybe more variations on the theme...\n\n\n\nAlso:\n\n\tnoticed new classes use 4 spaces instead of 2 and don't have any class-level javadoc\n\tspotted a few public methods with no javadocs (e.g. merge\n\ta mixture of spacing styles - sometimes space between if and (, sometimes now, sometimes space before {, sometimes not.... sometimes { on a new line, sometimes on the same line, sometimes space around = sign, sometimes not... \n\tleft over System.out.println(\n\tt.printStackTrace(new PrintWriter(trace)); - should that be there? Or should it be logged?\n\n "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13702039",
            "date": "2013-07-08T14:51:37+0000",
            "content": "Otis,\n\nThe implementation in this ticket is a POC to explore how pluggable collectors could be used. I think the best mechanism for expanding collector functionality though is through expanded use of PostFilters.\n\nIn order to make this approach viable two things need to be done. First, grouping needs to be revamped so that it plays nicely with the PostFilter framework. Second, in a distributed environment we need a way to merge the output from PostFilters. \n\nHere are three tickets that are likely to come out of these requirements:   \n\n1) Create a field collapsing PostFilter. This will involve a small change to the PostFilter api so it might best be done in Solr 5. This PostFilter will handle only the collapsing part of the grouping functionality.\n\n2) Add a Grouping search component to handle the rest of the grouping functionality. This component will work with the collapsed docList generated by the field collapsing PostFilter. Breaking up the grouping functionality like this should make it more flexible and easier to maintain.\n\n3) Add a Search component that allows for pluggable merging of output from shards. This would allow aggregating PostFilters to be developed and used with distributed search. It would also likely allow custom ranking collectors to be inserted through the PostFilter mechanism.\n\n\n\n\n "
        },
        {
            "author": "Steve Rowe",
            "id": "comment-13717465",
            "date": "2013-07-23T18:48:19+0000",
            "content": "Bulk move 4.4 issues to 4.5 and 5.0 "
        },
        {
            "author": "Kranti Parisa",
            "id": "comment-13757041",
            "date": "2013-09-03T20:37:26+0000",
            "content": "Anyone applied this patch on 4.4 branch? "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13757058",
            "date": "2013-09-03T20:55:14+0000",
            "content": "This ticket has been split into smaller tickets with a different design. See the related issues for more info. "
        },
        {
            "author": "Kranti Parisa",
            "id": "comment-13761604",
            "date": "2013-09-09T04:17:16+0000",
            "content": "Does any of those tickets support configurable collectors and choosing them dynamically thru request params? Is SOLR-5045 the one to use? If so, how does it work if I don't want to aggregate by any field, but want to do custom collecting/mixing. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13761802",
            "date": "2013-09-09T12:38:39+0000",
            "content": "The collecting/mixing ticket is still to come. It is going to be similar to SOLR-5045, accept you'll be able to plugin Rankers using the PostFilter mechanism. Still need to work out some of the details of this though. "
        },
        {
            "author": "Kranti Parisa",
            "id": "comment-13771332",
            "date": "2013-09-18T22:36:56+0000",
            "content": "For custom collectors: do we need to update SolrIndexSearcher to set the TopDocsCollector dynamically? "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13787784",
            "date": "2013-10-06T21:51:47+0000",
            "content": "Prabha,\n\nThis patch is no longer under development. Part of the functionality has been split into smaller tickets, SOLR-5027 and SOLR-5047, which are still in development.\n\nTake a look at Solr grouping (http://wiki.apache.org/solr/FieldCollapsing) and the stats component (http://wiki.apache.org/solr/StatsComponent) which are available now and sound like they may meet your needs.  "
        },
        {
            "author": "Markus Jelsma",
            "id": "comment-13787968",
            "date": "2013-10-07T07:41:23+0000",
            "content": "Joel, does that mean that the base functionality of having configurable collector is gone now? I don't see, for example, a CollectorFactory in the related issues. Having the ability to provide custom collectors via config as described here is a powerful feature. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13788105",
            "date": "2013-10-07T12:33:36+0000",
            "content": "Markus,\n\nSOLR-5045 allows for configurable aggregating collectors through an expansion of the PostFilter mechanisim. Configurable ranking collectors may be possible through a similar design. So I hope to be able to achieve the main goals of this ticket through a less intrusive design. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13963255",
            "date": "2014-04-08T18:12:13+0000",
            "content": "Going to be closing this is shortly. This proof of concept has been broken into several different tickets. The latest being SOLR-5973. "
        },
        {
            "author": "Otis Gospodnetic",
            "id": "comment-13995249",
            "date": "2014-05-12T17:05:30+0000",
            "content": "Joel Bernstein maybe this should be closed so it's not confusing people (because there have been a LOT of JIRAs in this post-filter/configurable collector/pluggable ranking collector space) "
        },
        {
            "author": "Otis Gospodnetic",
            "id": "comment-13995250",
            "date": "2014-05-12T17:05:54+0000",
            "content": "Oops, already closed, ignore me! "
        }
    ]
}