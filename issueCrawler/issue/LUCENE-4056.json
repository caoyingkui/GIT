{
    "id": "LUCENE-4056",
    "title": "Japanese Tokenizer (Kuromoji) cannot build UniDic dictionary",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [
            "modules/analysis"
        ],
        "type": "Improvement",
        "fix_versions": [],
        "affect_versions": "3.6",
        "resolution": "Unresolved",
        "status": "Open"
    },
    "description": "I tried to build a UniDic dictionary for using it along with Kuromoji on Solr 3.6. I think UniDic is a good dictionary than IPA dictionary, so Kuromoji for Lucene/Solr should support UniDic dictionary as standalone Kuromoji does.\n\nThe following is my procedure:\nModified build.xml under lucene/contrib/analyzers/kuromoji directory and run 'ant build-dict', I got the error as the below.\n\nbuild-dict:\n     [java] dictionary builder\n     [java] \n     [java] dictionary format: UNIDIC\n     [java] input directory: /home/kazu/Work/src/solr/brunch_3_6/lucene/build/contrib/analyzers/kuromoji/unidic-mecab1312src\n     [java] output directory: /home/kazu/Work/src/solr/brunch_3_6/lucene/contrib/analyzers/kuromoji/src/resources\n     [java] input encoding: utf-8\n     [java] normalize entries: false\n     [java] \n     [java] building tokeninfo dict...\n     [java]   parse...\n     [java]   sort...\n     [java] Exception in thread \"main\" java.lang.AssertionError\n     [java]   encode...\n     [java] \tat org.apache.lucene.analysis.ja.util.BinaryDictionaryWriter.put(BinaryDictionaryWriter.java:113)\n     [java] \tat org.apache.lucene.analysis.ja.util.TokenInfoDictionaryBuilder.buildDictionary(TokenInfoDictionaryBuilder.java:141)\n     [java] \tat org.apache.lucene.analysis.ja.util.TokenInfoDictionaryBuilder.build(TokenInfoDictionaryBuilder.java:76)\n     [java] \tat org.apache.lucene.analysis.ja.util.DictionaryBuilder.build(DictionaryBuilder.java:37)\n     [java] \tat org.apache.lucene.analysis.ja.util.DictionaryBuilder.main(DictionaryBuilder.java:82)\n\n\n\nAnd the diff of build.xml:\n\n===================================================================\n\u2014 build.xml\t(revision 1338023)\n+++ build.xml\t(working copy)\n@@ -28,19 +28,31 @@\n   <property name=\"maven.dist.dir\" location=\"../../../dist/maven\" />\n\n   <!-- default configuration: uses mecab-ipadic -->\n+  <!--\n   <property name=\"ipadic.version\" value=\"mecab-ipadic-2.7.0-20070801\" />\n   <property name=\"dict.src.file\" value=\"${ipadic.version}.tar.gz\" />\n   <property name=\"dict.url\" value=\"http://mecab.googlecode.com/files/${dict.src.file}\"/>\n+  -->\n\n   <!-- alternative configuration: uses mecab-naist-jdic\n   <property name=\"ipadic.version\" value=\"mecab-naist-jdic-0.6.3b-20111013\" />\n   <property name=\"dict.src.file\" value=\"${ipadic.version}.tar.gz\" />\n   <property name=\"dict.url\" value=\"http://sourceforge.jp/frs/redir.php?m=iij&f=/naist-jdic/53500/${dict.src.file}\"/>\n   -->\n\n\t+\n+  <!-- alternative configuration: uses UniDic -->\n+  <property name=\"ipadic.version\" value=\"unidic-mecab1312src\" />\n+  <property name=\"dict.src.file\" value=\"unidic-mecab1312src.tar.gz\" />\n+  <property name=\"dict.loc.dir\" value=\"/home/kazu/Work/src/nlp/unidic/_archive\"/>\n+\n   <property name=\"dict.src.dir\" value=\"${build.dir}/${ipadic.version}\" />\n+  <!--\n   <property name=\"dict.encoding\" value=\"euc-jp\"/>\n   <property name=\"dict.format\" value=\"ipadic\"/>\n+  -->\n+  <property name=\"dict.encoding\" value=\"utf-8\"/>\n+  <property name=\"dict.format\" value=\"unidic\"/>\n+\n   <property name=\"dict.normalize\" value=\"false\"/>\n   <property name=\"dict.target.dir\" location=\"./src/resources\"/>\n\n\n\n@@ -58,7 +70,8 @@\n\n   <target name=\"compile-core\" depends=\"jar-analyzers-common, common.compile-core\" />\n   <target name=\"download-dict\" unless=\"dict.available\">\n\n\t<get src=\"${dict.url}\" dest=\"${build.dir}/${dict.src.file}\"/>\n+     <!-- get src=\"${dict.url}\" dest=\"${build.dir}/${dict.src.file}\"/ -->\n+     <copy file=\"${dict.loc.dir}/${dict.src.file}\" tofile=\"${build.dir}/${dict.src.file}\"/>\n      <gunzip src=\"${build.dir}/${dict.src.file}\"/>\n      <untar src=\"${build.dir}/${ipadic.version}.tar\" dest=\"${build.dir}\"/>\n   </target>",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "date": "2012-05-14T07:29:38+0000",
            "content": "Hello Kazu,\n\nOnly the IPA dictionary is currently supported.\n\nAdding support for UniDic shouldn't be a big technical issue, but I think we perhaps should introduce some notion of dictionary concept in Kuromoji if we add support for other dictionaries since weights for the search mode heuristic needs to be tuned on a per-dictionary basis.\n\nAlso note that the stop tag set used by JapanesePartOfSpeechStopFilter also needs to be aligned with the relevant POS tag set of UniDic and we might also want to update the stop words list based on UniDic segmentation in order to properly support it end-to-end.  (I'd expect it to be the same or nearly the same as with IPA, though.)\n\nHence, adding UniDic support end-to-end creates a cascade of changes.\n\nEven though UniDic is indeed a good dictionary, its license is quite restrictive and doesn't allow redistribution, requires a license for commercial use, only permits personal use, etc.  This is from license.txt (in Japanese):\n\n\nUniDic ver.1.3.12 \u5229\u7528\u6761\u4ef6\n\n1. UniDic ver.1.3.12 \u306e\u8457\u4f5c\u6a29\u306f\uff0c\u4f1d\u5eb7\u6674\u30fb\u5c71\u7530\u7be4\u30fb\u5c0f\u690b\u79c0\u6a39\u30fb\u5c0f\u78ef\u82b1\u7d75\u30fb\u5c0f\u6728\u66fd\u667a\u4fe1\u304c\u4fdd\u6301\u3059\u308b\u3002\n2. UniDic ver.1.3.12 \u3092\u8907\u88fd\u53c8\u306f\u6539\u5909\u3059\u308b\u3053\u3068\u306f\uff0c\u500b\u4eba\u7684\u306a\u5229\u7528\u306b\u9650\u308a\u8a8d\u3081\u308b\u3002\n3. UniDic ver.1.3.12 \u53ca\u3073\u3053\u308c\u3092\u6539\u5909\u3057\u305f\u3082\u306e\u3092\u518d\u914d\u5e03\u3057\u3066\u306f\u306a\u3089\u306a\u3044\u3002\n4. UniDic ver.1.3.12 \u3092\u5229\u7528\u3057\u3066\u884c\u3063\u305f\u7814\u7a76\u7b49\u306e\u6210\u679c\u3092\u516c\u8868\u3059\u308b\u5834\u5408\u306f\uff0cUniDic ver.1.3.12 \u3092\u5229\u7528\u3057\u305f\u3053\u3068\u3092\u660e\u8a18\u3059\u308b\u3053\u3068\u3002\n5. \u55b6\u5229\u3092\u76ee\u7684\u3068\u3057\u3066\uff0cUniDic ver.1.3.12 \u3092\u5229\u7528\u3059\u308b\u5834\u5408\u306f\uff0c\u4e8b\u524d\u306b\u8457\u4f5c\u6a29\u8005\u3068\u5354\u8b70\u3059\u308b\u3053\u3068\u3002\n6. UniDic ver.1.3.12 \u3092\u5229\u7528\u3059\u308b\u3053\u3068\u306b\u3088\u3063\u3066\uff0c\u76f4\u63a5\u7684\u30fb\u9593\u63a5\u7684\u306b\u751f\u3058\u305f\u3044\u304b\u306a\u308b\u640d\u5bb3\u306b\u3064\u3044\u3066\u3082\uff0c\u8457\u4f5c\u6a29\u8005\u306f\u8ce0\u511f\u3059\u308b\u8cac\u4efb\u3092\u8ca0\u308f\u306a\u3044\u3002\n7. \u672c\u6587\u66f8\u306b\u5b9a\u3081\u306e\u306a\u3044\u4e8b\u9805\u306b\u3064\u3044\u3066\u306f\uff0c\u8457\u4f5c\u6a29\u8005\u3068\u5354\u8b70\u3059\u308b\u3053\u3068\u3002\n\n\n\nAs a result, we won't be able to redistribute it and support it out-of-the-box with Lucene/Solr, and using it will most likely require a custom dictionary build that you have attempted.\n\nWould fixing the dictionary builder for UniDic be a useful starting point in your case?\n\nDo you have any information you can share regarding what sort of improvements you expect to see with UniDic?  Does it relate to compound segmentation in general or katakana compounds?  If you can also share some information on how you think we should support UniDic and how big the demand for such support is, that would be very useful.  Thanks. ",
            "author": "Christian Moen",
            "id": "comment-13274485"
        },
        {
            "date": "2012-05-16T04:00:02+0000",
            "content": "Hi Christian,\n\nThank you for your comment.\n\nI understand the situation. I didn't expect that UniDic is bundled and shipped with Kuromoji. For the time being, I just want to buiild and use it with Kuromoji for lucene/Solr.\n\nWe just started evaluation of UniDic but it's a very early stage, so We don't have any conclusion that We have to or need to use UniDic instead of IPA dictionary. However we haven't finished our evaluation of UniDic, I like the concept and policy of UniDic that strictly define how to specify the tokens. And I am satisfied with the result of tokenization. I think It's better than IPA dictionary regarding the Katakana segmentation and compound segmentation.\n\nOn the other hand, I understand there's a license issue that We have to resolve if we decide to use it in our internal services. Thanks for reminding me.\n\nThanks. ",
            "author": "Kazuaki Hiraga",
            "id": "comment-13276429"
        },
        {
            "date": "2012-05-16T04:32:42+0000",
            "content": "\nWould fixing the dictionary builder for UniDic be a useful starting point in your case?\n\nThat assert from the stacktrace would probably be pretty tricky. Its an optimization that works for \nipadic and naist-jdic, and I knew i was making an assumption doing it, but it saves a bunch because\nit exploits a redundancy in the model (see LUCENE-3699).\n\nTo fix it, this optimization would have to either be conditionalized or pulled into a subclass for\nipadic and naist-jdic, and unidic would have to be encoded with a different strategy.\n\nStill, unidic support seems pretty tricky to maintain because if we want to share any code at all,\nthere is always the possibility it will break in the future (and due to license, not possible to\nintegrate into automatic tests).\n\nAnyway, thats the background for that particular assert, its my fault but I don't have an easy fix! ",
            "author": "Robert Muir",
            "id": "comment-13276449"
        },
        {
            "date": "2017-03-27T02:22:58+0000",
            "content": "Hello Robert Muir Christian Moen,\n\nI found support of UNIDIC dictionary at,\nhttps://github.com/apache/lucene-solr/blob/53981795fd73e85aae1892c3c72344af7c57083a/lucene/analysis/kuromoji/src/tools/java/org/apache/lucene/analysis/ja/util/DictionaryBuilder.java\n\nIts reading dictionary format as UNIDIC but later not using it while creating UnknownDictionaryWriter.\nAs a result build is failing with ArrayIndexOutOfBoundsException,\nas IPADIC's unk.def is having 11 columns whereas UNIDIC's unk.def is having 10 columns.\n\nAny update on this ? ",
            "author": "Prashant Pol",
            "id": "comment-15942539"
        }
    ]
}