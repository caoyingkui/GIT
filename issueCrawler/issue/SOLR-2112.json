{
    "id": "SOLR-2112",
    "title": "Solrj should support streaming response",
    "details": {
        "affect_versions": "None",
        "status": "Closed",
        "fix_versions": [
            "4.0-ALPHA"
        ],
        "components": [
            "clients - java"
        ],
        "type": "New Feature",
        "priority": "Major",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "The solrj API should optionally support streaming documents.\n\nRather then putting all results into a SolrDocumentList, sorlj should be able to call a callback function after each document is parsed.  This would allow someone to call query.setRows( Integer.MAX_INT ) and get each result to the client without loading them all into memory.\n\nFor starters, I think the important things to stream are SolrDocuments, but down the road, this could also stream other things (consider reading all terms from the index)",
    "attachments": {
        "SOLR-2112-StreamingSolrj.patch": "https://issues.apache.org/jira/secure/attachment/12454132/SOLR-2112-StreamingSolrj.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Ryan McKinley",
            "id": "comment-12907348",
            "date": "2010-09-08T18:22:37+0000",
            "content": "Here is a patch to add streaming.  It adds this top level function to solrServer:\n\n  QueryResponse queryAndStreamResponse( SolrParams params, StreamingResponseCallback callback ) \n\n\n\n\npublic interface StreamingResponseCallback {\n  public void documentRead( SolrDocument doc );\n  public void documentListInfo( long numFound, long start, Float maxScore );\n}\n\n\n\nThis is implemented by hacking the BinaryResponseWriter (embedded) and JavaBinCodec (http) to send events rather then write/read documents.\n\n "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-12907355",
            "date": "2010-09-08T18:36:57+0000",
            "content": "this patch has better comments and includes some missing files  "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-12908838",
            "date": "2010-09-13T15:57:19+0000",
            "content": "I would like to commit this soon (just to /trunk) unless there are objections "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12908894",
            "date": "2010-09-13T18:21:10+0000",
            "content": "Can StreamingResponseCallback be an abstract class for easier back compat?\nI imagine we could want to stream other stuff in the future (output from terms component, facet component, term vector component, etc). "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-12908976",
            "date": "2010-09-13T20:03:26+0000",
            "content": "ah yes, good point.\n\nHere is an updated patch using:\n\npublic abstract class StreamingResponseCallback {\n  /*\n   * Called for each SolrDocument in the response\n   */\n  public abstract void streamSolrDocument( SolrDocument doc );\n\n  /*\n   * Called at the beginning of each DocList (and SolrDocumentList)\n   */\n  public abstract void streamDocListInfo( long numFound, long start, Float maxScore );\n}\n\n "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-12909009",
            "date": "2010-09-13T21:32:40+0000",
            "content": "added in r996693\n\nI'm not sure what the 3.x release schedule looks like... so i'm not sure if back porting makes sense.  I think keeping it on /trunk for a while makes sense till we know this is the API we want.\n "
        },
        {
            "author": "Mikhail Khludnev",
            "id": "comment-13701317",
            "date": "2013-07-06T11:00:54+0000",
            "content": "fwiw, \nserver side streaming is out-of scope of this issue. Some time ago I did a hack to allow streaming response during collecting results, if somebody need it, feel free to raise an issue. there is the code https://github.com/m-khl/solr-patches/compare/streaming  "
        },
        {
            "author": "Otis Gospodnetic",
            "id": "comment-13705432",
            "date": "2013-07-11T03:30:21+0000",
            "content": "Mikhail Khludnev - are you using it somewhere? Does it work well? Is it \"contributable\"? "
        },
        {
            "author": "Mikhail Khludnev",
            "id": "comment-13705656",
            "date": "2013-07-11T10:16:23+0000",
            "content": "I don't run it, just played with it a year ago up to passing distributed search test, see github. I'm ready to collaborate if anyone is interested. The most questionable thing is the overall design. To discuss it we need to have two separate issues, I suppose, for core ability and distributed support. \nIIRC there is a special component, which injects own delegating collector which writes into ServletResponse while search is going. It needs to require sort=docid&rows=0 (to avoid buffering results). \nThen for distributed search index should be presorted to keep internal and external ids monotonic. I didn't cover index sorting. \nBut passing all these traps we've got yet another one MapReduce platform! Sounds cool isn't it!   "
        }
    ]
}