{
    "id": "LUCENE-4598",
    "title": "Change PayloadIterator to not use top-level reader API",
    "details": {
        "components": [
            "modules/facet"
        ],
        "fix_versions": [
            "4.1",
            "6.0"
        ],
        "affect_versions": "None",
        "priority": "Major",
        "labels": "",
        "type": "Improvement",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "Currently the facet module uses MultiFields.* to pull the D&PEnum in PayloadIterator, to access the payloads that store the facet ords.\n\nIt then makes heavy use of .advance and .getPayload to visit all docIDs in the result set.\n\nI think we should get some speedup if we go segment by segment instead ...",
    "attachments": {
        "LUCENE-4598.patch": "https://issues.apache.org/jira/secure/attachment/12560066/LUCENE-4598.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2012-12-07T18:23:48+0000",
            "content": "Is this really an issue? I thought that pulling a top-level D&PEnum on a single posting won't gain much by iterating per segment? The per-segment iteration is more complicated (code-wise) ...\n\nAnyway, I think that either in this issue or another one, we should explore a Collector that aggregates the ordinals during collection, and not after collection has finished. That will save substantial RAM consumed by the bitset (not critical) and potential float[] (for scores), which is the size of the result set. ",
            "author": "Shai Erera",
            "id": "comment-13526602"
        },
        {
            "date": "2012-12-07T18:34:36+0000",
            "content": "Is this really an issue? I thought that pulling a top-level D&PEnum on a single posting won't gain much by iterating per segment? The per-segment iteration is more complicated (code-wise) ...\n\nI think it should help somewhat ... I don't expect the gains to be earth shattering though \n\nAnyway, I think that either in this issue or another one, we should explore a Collector that aggregates the ordinals during collection, and not after collection has finished. That will save substantial RAM consumed by the bitset (not critical) and potential float[] (for scores), which is the size of the result set.\n\n+1, I'll open a new issue for that. ",
            "author": "Michael McCandless",
            "id": "comment-13526618"
        },
        {
            "date": "2012-12-07T18:37:51+0000",
            "content": "OK I opened LUCENE-4600 for single-pass collection + aggregation. ",
            "author": "Michael McCandless",
            "id": "comment-13526622"
        },
        {
            "date": "2012-12-07T18:41:45+0000",
            "content": "That will save substantial RAM consumed by the bitset (not critical)\n\n\"not critical\" can become very critical for very large indexes. I am now talking to a team who index 1B documents with Lucene (very small documents). A bitset that size will consume 128MB RAM, that's substantial !\n\nThanks for opening the issue. Though, if we move to only during-collection aggregation, I don't think that this issue will still be valid. Only if we keep ScoredDocIdsCollector, and perhaps the two-pass is efficient in some cases. ",
            "author": "Shai Erera",
            "id": "comment-13526627"
        },
        {
            "date": "2012-12-07T19:20:48+0000",
            "content": "Though, if we move to only during-collection aggregation, I don't think that this issue will still be valid.\n\nAhh good point.  So we should do the other issue first  ",
            "author": "Michael McCandless",
            "id": "comment-13526674"
        },
        {
            "date": "2012-12-07T19:42:45+0000",
            "content": "not necessarily . These are not either-or IMO. We've spent a lot of time addressing different faceting scenarios in this module. There are plenty of extension points ranging from simple configuration to writing your own facets collection algorithm.\n\nThis issue is quite simple - you propose to fix a specific class to not use MultiFields. Let's do it, even before LUCENE-4600. Since it's a low hanging fruit, and I'm not sure that we'll never need to do a post-collection aggregation, so this class will probably be needed still. ",
            "author": "Shai Erera",
            "id": "comment-13526704"
        },
        {
            "date": "2012-12-07T19:48:27+0000",
            "content": "Since it's a low hanging fruit,\n\nWait, before you said:\n\nThe per-segment iteration is more complicated (code-wise) ...\n\nwhich sort of spooked me out \n\nIf it really is easy to prototype we should test and see if perf gains are worth it or not ... ",
            "author": "Michael McCandless",
            "id": "comment-13526715"
        },
        {
            "date": "2012-12-07T19:54:31+0000",
            "content": "I said that because I was bitten by it (when implemented ParallelTaxonomyArrays.initParents). The scenario is that you have a FixedBitSet over r.maxDoc(). You then get an iterator from it, by global docIDs. So it's very easy to pull a top-level IR and skip by these global docIDs.\n\nIf instead you need to pull it per-segment, you need to do some math in the code, handle the case where a segment is entirely irrelevant ... stuff like that. Basically, I would imagine that we'll duplicate the MultiFields version for D&PEnum?\n\nWhen I thought about making this class per-segment, I was thinking about LUCENE-4600 \u2013 i.e. if we do in-collection aggregation, that class only needs to iterate within a single segment, on local docIDs. No complications. ",
            "author": "Shai Erera",
            "id": "comment-13526726"
        },
        {
            "date": "2012-12-09T09:53:59+0000",
            "content": "Hmm ... if you pass liveDocs, then I think this becomes expensive, because of how MultiBits is implemented (doing binary search on every lookup). So two options:\n\n\n\tPass liveDocs=null, this class is used for matching documents, and should traverse whatever the query matched. If it matched deleted docs, we should traverse them too?\n\t\n\t\tMaybe even now it's a bug that it always passes liveDocs?\n\t\n\t\n\tModify the class impl to work on the leaves(). But then, we'll just duplicate the code of MultiDocsAndPositionsEnum?\n\n\n\nMike, if we pass liveDocs=null, how much difference would it make if the class iterated on the leaves(), vs. iterating through MultiDocsAndPositionsEnum? ",
            "author": "Shai Erera",
            "id": "comment-13527389"
        },
        {
            "date": "2012-12-09T10:53:05+0000",
            "content": "Patch sets liveDocs=null with a comment and proper javadocs.\n\nWhile not related to this issue, I noticed that PayloadIterator copies the payload BytesRef to its own buffer. This, I think, is a remnant from the days where TP.getPayload took a byte[]. This is a redundant copy which must be eliminated.\n\nMike, I wonder if that'd speed things up (only a bit, I know)?\n\nAnyway, I'm not at all sure that it's worth duplicating MultiDAPE's logic into this class. But at any rate, I think that this patch needs to be committed, to remove the redundant byte[] copies.\n\nAlso, I noticed that CategoryListIterator (and PayloadIterator) define an init() method which must be called prior to using them, and there's even a jdoc comment saying that calling it twice may skip over documents ... I don't think that we need it? Can't CLI impls initialize at ctor? At least, PayloadIterator can. I'll open a separate issue for that. ",
            "author": "Shai Erera",
            "id": "comment-13527401"
        },
        {
            "date": "2012-12-09T11:16:39+0000",
            "content": "I noticed that CategoryListIterator (and PayloadIterator) define an init() method which must be called prior to using them\n\nMaybe it's not useless after all. That way, impls can do some checks at init(), and not repeat them in skipTo. So for now I think that I'll just leave it. ",
            "author": "Shai Erera",
            "id": "comment-13527408"
        },
        {
            "date": "2012-12-09T16:08:38+0000",
            "content": "+1 to pass liveDocs=null.\n\nI'm seeing some test failures (org.apache.lucene.facet.enhancements.EnhancementsPayloadIteratorTest) with this patch ...\n\nI ran quick perf test on 10M doc index, with 5% deleted docs:\n\n\n                    Task    QPS base      StdDev    QPS comp      StdDev                Pct diff\n                 LowTerm       28.51      (1.3%)       29.07      (0.8%)    2.0% (   0% -    4%)\n                HighTerm        2.46      (0.8%)        2.52      (0.6%)    2.6% (   1% -    3%)\n                 MedTerm       13.17      (1.2%)       13.62      (0.8%)    3.5% (   1% -    5%)\n\n\n\nNice little performance improvement ... ",
            "author": "Michael McCandless",
            "id": "comment-13527515"
        },
        {
            "date": "2012-12-09T20:45:30+0000",
            "content": "I'm seeing some test failures (org.apache.lucene.facet.enhancements.EnhancementsPayloadIteratorTest) with this patch ...\n\nThanks ! I didn't yet run all the tests (I thought that I had), but anyway this problem wasn't always reproducible. Easy fix, need to start from BytesRef.offset, where before it was just 0, because the array was copied.\n\nI think that I'll commit that, and separately try to avoid MultiFields for this class.\n\nTests pass, but I'll run few more times before I commit. ",
            "author": "Shai Erera",
            "id": "comment-13527627"
        },
        {
            "date": "2012-12-10T08:54:28+0000",
            "content": "I've decided to not do two commits. So attached patch covers the previous one + moves to using per-segment posting iteration.\n\nI'd appreciate if someone can review the changes, especially PayloadIterator.nextSegment and .setdoc().\n\nI ran tests w/ many iters, all seem ok so far. ",
            "author": "Shai Erera",
            "id": "comment-13527789"
        },
        {
            "date": "2012-12-10T10:05:05+0000",
            "content": "Nice that PayloadIterator now returns a direct reference to payloads instead of copying data! ",
            "author": "Adrien Grand",
            "id": "comment-13527826"
        },
        {
            "date": "2012-12-10T10:08:31+0000",
            "content": "Yes ... well in the past TermPositions didn't maintain a byte[] for payloads, you had to give it one. Now that it does, it's stupid to copy the array again  ",
            "author": "Shai Erera",
            "id": "comment-13527831"
        },
        {
            "date": "2012-12-10T12:27:02+0000",
            "content": "+1, looks great!\n\nAnd it looks like it's a bit faster than before:\n\n\n                    Task    QPS base      StdDev    QPS comp      StdDev                Pct diff\n                 LowTerm       28.35      (1.4%)       29.42      (0.8%)    3.8% (   1% -    6%)\n                HighTerm        2.46      (0.6%)        2.57      (0.5%)    4.8% (   3% -    5%)\n                 MedTerm       13.09      (1.4%)       13.92      (0.5%)    6.4% (   4% -    8%)\n\n\n\nI think we could speed things up more if this code \"owned\" the iteration, eg with some sort of \"bulk accumulate\" method, rather than StandardFacetAccumulator going through CategoryListIterator down to PayloadIterator, per hit. This way it could first iterate by segment (on the outer loop), then, inside iterate on all docs in that segment, etc.  But save that for another day ... ",
            "author": "Michael McCandless",
            "id": "comment-13527905"
        },
        {
            "date": "2012-12-10T12:41:31+0000",
            "content": "Thanks, I'll run tests again just to make sure and commit.\n\nI'm glad that it sped things up. I was skeptic that duplicating MultiDPE logic into PayloadIterator will improve anything, but perhaps these results show that people should consider moving to the per-segment API. Maybe we need a separate benchmark to prove that ...\n\nPayloadIterator is just a utility class that encapsulates a logic that is similar to TermsEnum.seekExact. I.e., if DISI had an advanceExact(doc), I'm quite sure that we wouldn't need that class. I think that DISI.advanceExact is not that complicated to implement, and possibly even as a final method (so it doesn't affect any DISI out there), by calling advance() and docID(). I'll think about it and perhaps open an issue for it.\n\nThen, PayloadIterator could be annihilated completely, and maybe we can make CLI a per-segment thing too, and FacetsAccumulator will iterate per-segment. It's a bigger change though, so I agree with \"save that for another day\" . ",
            "author": "Shai Erera",
            "id": "comment-13527910"
        },
        {
            "date": "2012-12-10T13:00:10+0000",
            "content": "[trunk commit] Shai Erera\nhttp://svn.apache.org/viewvc?view=revision&revision=1419397\n\nLUCENE-4598: Change PayloadIterator to not use top-level reader API ",
            "author": "Commit Tag Bot",
            "id": "comment-13527918"
        },
        {
            "date": "2012-12-10T13:36:38+0000",
            "content": "Committed to trunk and 4x. Thanks Mike ! ",
            "author": "Shai Erera",
            "id": "comment-13527925"
        },
        {
            "date": "2012-12-10T13:42:11+0000",
            "content": "[branch_4x commit] Shai Erera\nhttp://svn.apache.org/viewvc?view=revision&revision=1419446\n\nLUCENE-4598: Change PayloadIterator to not use top-level reader API ",
            "author": "Commit Tag Bot",
            "id": "comment-13527929"
        },
        {
            "date": "2012-12-11T11:19:59+0000",
            "content": "Got a nice ~5-6% bump in the nightly facet perf from this fix: http://people.apache.org/~mikemccand/lucenebench/TermDateFacets.html\n\nI added an annotation. ",
            "author": "Michael McCandless",
            "id": "comment-13528889"
        },
        {
            "date": "2012-12-11T12:26:55+0000",
            "content": "nice !\n\nI expect a higher gain when indexing multiple facets per document, since the payload will be bigger. I think that not copying the payload would show a bigger gain than in this benchmark. ",
            "author": "Shai Erera",
            "id": "comment-13528911"
        },
        {
            "date": "2012-12-11T23:18:24+0000",
            "content": "I made a hacked up patch to test how a specialized (payloads, dgap/vint, counting) 2nd pass aggregation would perform (attached):\n\n                    Task    QPS base      StdDev    QPS comp      StdDev                Pct diff\n                 LowTerm       29.28      (1.2%)       31.01      (1.4%)    5.9% (   3% -    8%)\n                 MedTerm       14.28      (1.5%)       16.19      (1.4%)   13.4% (  10% -   16%)\n                HighTerm        4.05      (2.4%)        5.05      (1.5%)   24.6% (  20% -   29%)\n\n\n\nSo ... I think we should provide specialized impls for the common cases, and make it easy to for users to use (eg FacetsCollector.create(FSP) or something).\n\nThese results are similar to what I saw with the single-valued DocValue collector at https://issues.apache.org/jira/browse/LUCENE-4600?focusedCommentId=13527566&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13527566 ",
            "author": "Michael McCandless",
            "id": "comment-13529468"
        }
    ]
}