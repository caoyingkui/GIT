{
    "id": "SOLR-6769",
    "title": "Election bug",
    "details": {
        "components": [],
        "type": "Bug",
        "labels": "",
        "fix_versions": [],
        "affect_versions": "None",
        "status": "Closed",
        "resolution": "Cannot Reproduce",
        "priority": "Major"
    },
    "description": "Hello, I have a very simple set up: 2 shards and 2 replicas (4 nodes in total).\n\nWhat I did is just stopped the shards, but if first shard stopped immediately the second one took about 5 minutes to stop. You can see on the screenshot what happened next. In short:\n1. Shard 1 stopped normally\n3. Replica 1 became a leader\n2. Shard 2 still was performing some job but wasn't accepting connection\n4. Replica 2 did not became a leader because Shard 2 is still there but doesn't work\n5. Entire cluster went down until Shard 2 stopped and Replica 2 became a leader\n\nMarked as critical because this shuts down the entire cluster. Please adjust if I am wrong.",
    "attachments": {
        "Screenshot 876.png": "https://issues.apache.org/jira/secure/attachment/12682612/Screenshot%20876.png"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2014-11-20T10:24:57+0000",
            "author": "Alexander S.",
            "content": "Screenshot 876.png ",
            "id": "comment-14219204"
        },
        {
            "date": "2014-12-08T23:46:22+0000",
            "author": "Anshum Gupta",
            "content": "Alexander S. I would recommend you to post such issues on the user-list before creating a JIRA. This would come in handy:\nhttps://wiki.apache.org/solr/UsingMailingLists\n\nThough I think it's not really an issue, I'm not closing this issue for now. However, I'll reduce the Priority on this one primarily due to lack of information on the issue.\n\n\tWhat version of Solr were you running?\n\tWhat version of Java? Web server?\n\tHow were you running it? External ZK?\n\tWhat do you mean by \"stopped normally\"? Shard is a logical entity, replica is a physical one. Do you mean you stopped the leader of Shard1?\n\tWhat did you expect should have happened?\n..\n\n ",
            "id": "comment-14238693"
        },
        {
            "date": "2014-12-09T09:46:34+0000",
            "author": "Alexander S.",
            "content": "Hi, yes, my terminology about shards and replicas wasn't clear, let me explain this better.\n\n\n\tSolr: 4.8.1\n\tJava:\njava version \"1.7.0_51\"\nJava(TM) SE Runtime Environment (build 1.7.0_51-b13)\nJava HotSpot(TM) 64-Bit Server VM (build 24.51-b03, mixed mode)\n\tWe have 5 servers, 2 of which are big (16 CPU cores, 48G of RAM each) and 3 others are small (1 CPU and 1G of RAM). All servers have rapid SSD RAID 10. Each server runs a ZK instance, so we have 5 ZK instances in total. Those big servers also run Solr: the first one runs 2 instances and the second one also runs 2 replicas (so each shard has 2 replicas, the simplest SolrCloud setup from the wiki).\n\n\n\nSo the cluster looks like this:\n\n* Small 1G node: ZK\n* Small 1G node: ZK\n* Small 1G node: ZK\n* Big 16G node: ZK, Solr1, Solr2\n* Big 16G node: ZK, Solr1.1, Solr2.1\n\n\n\n\"Stopped manually\" means I tried to manually stop Solr1 and Solr2, which were the leaders, by sending a TERM signal (we have service files so I did \"service stop\" and was expecting a graceful shut down). This was working for Solr1 and it went down normally and Solr1.1 became the leader instantly. Then I tried to do the same for Solr2, but once I sent the TERM it became not operable but didn't exit completely (orange on the screenshot), the process was still running for \u2248 5-10 minutes and the election didn't happen. As a result I get \"no node hosting shard\" errors, but was expecting Solr2.1 to become the leader instantly as it was with Solr1.1.\n\nAs I understand this, the Solr2 didn't shut down instantly because there could be some background jobs, e.g. index merging, an \"in process\" commit, etc, but then it should not stop accepting connections and should not change its status to \"down\" until all background jobs are finished and it s really ready to go down and pass leadership to the Solr2.1.\n\nIt seems like a bug in Solr, because all services were working normally, all ZK instances were up and operable, and Solr itself wasn't under a heavy load. Otherwise could you please point me where to look for any information about how to gracefully shut down instances? It would be good to have a button in the web UI to be able to force a replica to become the leader with one click. So then I would be able to force Solr1.1 and Solr 2.1 to become the leaders, wait until this happen and safely reboot Solr1 and solr2 instances.\n\nBest,\nAlexander ",
            "id": "comment-14239203"
        },
        {
            "date": "2014-12-18T22:38:40+0000",
            "author": "Alexander S.",
            "content": "This might be related: http://lucene.472066.n3.nabble.com/Endless-100-CPU-usage-on-searcherExecutor-thread-td4175088.html ",
            "id": "comment-14252440"
        },
        {
            "date": "2014-12-21T12:42:09+0000",
            "author": "Alexander S.",
            "content": "Correct, an endless warming was causing this problem. So this is a bug in Solr, it waits for searchers to end warming, which could take up to 5 minutes in some cases. The node itself goes down and does not accept connections but the ellection does not happen. ",
            "id": "comment-14255146"
        },
        {
            "date": "2016-10-02T03:25:11+0000",
            "author": "Alexandre Rafalovitch",
            "content": "There has been some fixes related to that, I believe.\n\nIs this reproducible against latest version of Solr? If yes, the case can be updated with more details so it is more visible. \n\nIf not, let's close it and see if somebody will see it again. ",
            "id": "comment-15539639"
        }
    ]
}