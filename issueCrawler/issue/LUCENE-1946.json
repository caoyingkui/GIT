{
    "id": "LUCENE-1946",
    "title": "Remove deprecated TokenStream API",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [
            "modules/analysis"
        ],
        "type": "Task",
        "fix_versions": [
            "3.0"
        ],
        "affect_versions": "None",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "I looked into clover analysis: It seems to be no longer used since I removed the tests yesterday - I am happy!",
    "attachments": {
        "LUCENE-1946.patch": "https://issues.apache.org/jira/secure/attachment/12421223/LUCENE-1946.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2009-10-04T09:00:15+0000",
            "content": "Short and simple patch for Lucene core. The tests were modified yesterday to no longer call deprecated TS methods and no longer use setOnlyUseNewAPI() ",
            "author": "Uwe Schindler",
            "id": "comment-12762008"
        },
        {
            "date": "2009-10-04T12:50:17+0000",
            "content": "One general question:\n\nMy last patch also removes the ISOLatin1AccentFilter, because it is deprecated. The problem with removing this filter is, that current indexes cannot be used anymore, because you have no possibility to add new documents using this filter in 3.0 or do queries with accents against it. Maybe we should leave this class deprecated alive or move it to contrib? Or we force people to reindex.\n\nThe same applies to DateField from the o.a.l.document package. It is deprecated, so no one should use it, but we cannot remove it, because existing indexes need this support. This is different for e.g. Field.Store.COMPRESS, because you can still read the indexes (decompression is automatically), and can add new content without compression. Or reindex and use a own compression using byte[] stored field (as suggested). ",
            "author": "Uwe Schindler",
            "id": "comment-12762024"
        },
        {
            "date": "2009-10-04T13:32:56+0000",
            "content": "Some more changes and additional tests (removed by the backwards-testcase removal). It now also fixes contrib/analyzers.\n\nThere are still some problems in contrib like tests or old-style consumers. ",
            "author": "Uwe Schindler",
            "id": "comment-12762027"
        },
        {
            "date": "2009-10-05T19:52:10+0000",
            "content": "In case the change in our backwards-compatibility policy happens (see LUCENE-1698) we could think about removing the old TokenStream API in 3.1, considering how central this API is.  ",
            "author": "Michael Busch",
            "id": "comment-12762330"
        },
        {
            "date": "2009-10-05T21:12:04+0000",
            "content": "I already promoted (and also Grant in his webinar) that Lucene 3.0 will not contain the old TokenStream API anymore. Nobody had problems with it (even the UIMA people were very happy about the new API, because it fits better to the UIMA architecture [they also have such things like Attribute but called different] - there was a conference about UIMA in Potsdam).\n\nI keep this patch pending (only the generics changes are submitted), but all tests for the BW compatibility were removed in my deprecated cleanup, so there are no tests for the old api anymore in trunk. ",
            "author": "Uwe Schindler",
            "id": "comment-12762375"
        },
        {
            "date": "2009-10-05T21:23:44+0000",
            "content": "\neven the UIMA people were very happy about the new API, because it fits better to the UIMA architecture\n\nYeah, I had the feeling they like it too (had lunch with them a couple weeks ago when I was working from Boeblingen).\n\nI'm personally ok with removing the old API; just thought Grant and others mentioned concerns about removing it too soon, because lots of users have their own TokenStreams. ",
            "author": "Michael Busch",
            "id": "comment-12762386"
        },
        {
            "date": "2009-10-11T05:18:29+0000",
            "content": "This patch was sitting here for a week now and it seems like nobody objects removing the old API in 3.0.\n\nSo my +1 for committing this! ",
            "author": "Michael Busch",
            "id": "comment-12764420"
        },
        {
            "date": "2009-10-11T08:32:39+0000",
            "content": "+1 from me too. The patch needs some more work, as I stopped somewhere in contrib to remove, as it was not clear to remove it for 3.0I will do the rest now. They only problem is InstantiatedIndexWriter, which still uses the old API to consume. I will try to modify it. But maybe this contrib will get removed (see other issue LUCENE-1948).\n\nSo I will find out what to do. ",
            "author": "Uwe Schindler",
            "id": "comment-12764431"
        },
        {
            "date": "2009-10-11T15:39:01+0000",
            "content": "Here the patch with all contrib's fixed:\n\n\tPrecedenceQueryParser was missing new TokenStream API, I fixed it somehow with States and restoreState. I also added a javacc-target, which was missing\n\tInstantiatedIndexWriter was also changed to use the new TokenStream API. The fix is very hackish, but works for the beginning. The class uses lots of Lists/Sets with cloned Token instances inside, so I simple used an AttributeImpl iterator and used copyTo(token). This works most cases (other cases are ignored by a empty Exception catch block). But this should really be fixed or the whole class removed (as suggested)\n\n\n\nThere is one question: I removed IsoLatin1Filter. Thismay be a backwards break, so that old indexes using this filter in the analyzer need to be reindexed. But for most cases the AccentFilter would also work, but some hits may be missing when you query such an index. What should we do. Leave the deprecated analyzer in and remove it with 4.0 when all old indexes cannot be read anymore? ",
            "author": "Uwe Schindler",
            "id": "comment-12764466"
        },
        {
            "date": "2009-10-11T15:43:35+0000",
            "content": "\nThere is one question: I removed IsoLatin1Filter. Thismay be a backwards break, so that old indexes using this filter in the analyzer need to be reindexed. But for most cases the AccentFilter would also work, but some hits may be missing when you query such an index. What should we do. Leave the deprecated analyzer in and remove it with 4.0 when all old indexes cannot be read anymore?\n\nI do not think this is a backwards break, because IsoLatin1Filter is deprecated?\n\n\n * @deprecated in favor of {@link ASCIIFoldingFilter} which covers a superset \n * of Latin 1. This class will be removed in Lucene 3.0.\n\n ",
            "author": "Robert Muir",
            "id": "comment-12764467"
        },
        {
            "date": "2009-10-11T15:49:40+0000",
            "content": "This is correct. But e.g. NumberTools and DateTools will also stay deprecated in 3.0, because you need them to use Indexes from previous versions.\n\nSo there is a difference between deprecated APIs and deprecated functionality that is maybe needed, as long as old indexes are available. With 4.0 we will change the index format and then the problem is gone.\n\nBut I agree with you, the differences between both classes are so minimal and only western european languages would have used the ISO filter. The superset does not hurt, only when extended chars (>255) are involved. ",
            "author": "Uwe Schindler",
            "id": "comment-12764472"
        },
        {
            "date": "2009-10-11T15:52:27+0000",
            "content": "Uwe, well this class already uses new tokenstream API, so it is not hurting anything right?\nmaybe follow what Mark said and keep it, change the javadoc to say 'this class will be removed in Lucene 4.0' ?\n\nedit. also maybe another option, you could move it to contrib? ",
            "author": "Robert Muir",
            "id": "comment-12764473"
        },
        {
            "date": "2009-10-11T16:03:01+0000",
            "content": "Cool idea. I move it to contrib/analyzers/common. But the class name will stay, the same so it will be in the top-level dir (without language suffix) as the only one.\n\nWith NumberTools/DateField/DateTools we can do the same? This would be good in misc or somewhere else. But we then have to remove support for them from core's query parser? \u2014 mhhm bad idea for the beginning. I leave it there  ",
            "author": "Uwe Schindler",
            "id": "comment-12764474"
        },
        {
            "date": "2009-10-11T16:06:46+0000",
            "content": "Cool idea. I move it to contrib/analyzers/common. But the class name will stay, the same so it will be in the top-level dir (without language suffix) as the only one. \n\nor maybe put it in misc also? I don't understand the Number/Date issues like you do, so maybe contrib is a bad idea... just throwing it out there. ",
            "author": "Robert Muir",
            "id": "comment-12764476"
        },
        {
            "date": "2009-10-11T17:23:54+0000",
            "content": "Patch with ISOLatin1Filter deprecated with a hint to 4.0 and additional text. I also made the missing TokenStreams (intended not to be extended) final (see LUCENE-1753).\n\nAll test pass. I will commit soon. ",
            "author": "Uwe Schindler",
            "id": "comment-12764494"
        },
        {
            "date": "2009-10-11T17:35:33+0000",
            "content": "Committed revision: 824116 ",
            "author": "Uwe Schindler",
            "id": "comment-12764497"
        }
    ]
}