{
    "id": "LUCENE-871",
    "title": "ISOLatin1AccentFilter a bit slow",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [
            "modules/analysis"
        ],
        "type": "Bug",
        "fix_versions": [
            "2.3"
        ],
        "affect_versions": "1.9,                                            2.0.0,                                            2.1,                                            2.2",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "The ISOLatin1AccentFilter is a bit slow giving 300+ ms responses when used in a highligher for output responses.\n\nPatch to follow",
    "attachments": {
        "ISOLatin1AccentFilterAlt.java": "https://issues.apache.org/jira/secure/attachment/12364214/ISOLatin1AccentFilterAlt.java",
        "fasterisoremove2.patch": "https://issues.apache.org/jira/secure/attachment/12362474/fasterisoremove2.patch",
        "ISOLatin1AccentFilter.java.patch": "https://issues.apache.org/jira/secure/attachment/12356484/ISOLatin1AccentFilter.java.patch",
        "fasterisoremove1.patch": "https://issues.apache.org/jira/secure/attachment/12362471/fasterisoremove1.patch",
        "LUCENE-871.take4.patch": "https://issues.apache.org/jira/secure/attachment/12363967/LUCENE-871.take4.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2007-04-29T15:41:08+0000",
            "content": "Patch to improve performance,\n\nThis was re-created form the improved source, and although I dont think I have made any transcription mistakes, I might have, please check that it builds and works. Ok. ",
            "author": "Ian Boston",
            "id": "comment-12492577"
        },
        {
            "date": "2007-04-29T15:51:03+0000",
            "content": "Patch looks fine after a quick review.\n\nTo speed things up a bit more in the case that there are few accented chars in a large field, one could start the second loop at the place where the first loop found a char in the range of accented chars.  The first part could be efficiently copied via String.getChars() ",
            "author": "Yonik Seeley",
            "id": "comment-12492578"
        },
        {
            "date": "2007-07-24T17:12:12+0000",
            "content": "It would be a nice courtesy to document that this thing is over 2 times faster if you use a StringBuilder rather than a StringBuffer. Up to 2.8 times faster in my measurements.\n\n\n\tMark\n\n ",
            "author": "Mark Miller",
            "id": "comment-12515032"
        },
        {
            "date": "2007-07-24T18:11:17+0000",
            "content": "Right, but StringBuilder is 1.5.  Sigh... ",
            "author": "Grant Ingersoll",
            "id": "comment-12515053"
        },
        {
            "date": "2007-07-24T18:38:43+0000",
            "content": "Yes, I feel that sigh. So perhaps the point is moot. I was just thinking that a lot of code runs on 1.5 or > and while its obviously crazy to point out every class that could be changed to a StringBuilder, i thought it might be nice to warn somehow that this thing is like twice as fast if you can use StringBuilder. Even this sped up version takes more than its fair share in my filter chain.\n\n\n\tMark\n\n ",
            "author": "Mark Miller",
            "id": "comment-12515060"
        },
        {
            "date": "2007-07-24T19:51:16+0000",
            "content": "I think we can likely get a sizable speedup here by using the char[] termBuffer in Token plus the new \"re-use single Token\" API being discussed here:\n\n    http://www.gossamer-threads.com/lists/lucene/java-dev/51283 ",
            "author": "Michael McCandless",
            "id": "comment-12515077"
        },
        {
            "date": "2007-07-24T22:00:29+0000",
            "content": "Here is a 1.4 solution using a char array. Doesn't yet use termbuffer or create only a single token.\n\nAlmost twice as fast.\n\n\n\tMark\n\n ",
            "author": "Mark Miller",
            "id": "comment-12515101"
        },
        {
            "date": "2007-07-24T22:05:08+0000",
            "content": "Woah! I thought I was seeing this patch on the trunk already. Should have looked more closely at the patch file. I basically just duplicated the patch. Belay all previous. ",
            "author": "Mark Miller",
            "id": "comment-12515103"
        },
        {
            "date": "2007-07-24T22:50:36+0000",
            "content": "Since I prefer my char array handling to the current, I have taken the fail fast pre-scan loop and yoniks suggestion and incorporated them into my patch. Two choices now.\n\n\n\tMark\n\n ",
            "author": "Mark Miller",
            "id": "comment-12515111"
        },
        {
            "date": "2007-07-30T14:39:49+0000",
            "content": "OK, for LUCENE-969 I made yet a 3rd option for optimizing\nISOLatin1AccentFilter.\n\nIn that patch I reuse the Token instance, using the char[] API for the\nToken's text instead of String, and I also re-use a single TokenStream\ninstance (I did this for all core tokenizers).\n\nI just tested total time to tokenize all wikipedia content with\ncurrent trunk (1116 sec) vs with LUCENE-969 (500 sec), with a\nWhitespaceTokenizer -> ISOLatin1AccentFilter chain.\n\nI separately timed just creating the documents at 112 sec, to subtract\nit off from the above times (so I can measure only cost of\ntokenization).\n\nThis gives net speedup of this filter is 2.97X faster (1004 sec -> 388\nsec). ",
            "author": "Michael McCandless",
            "id": "comment-12516403"
        },
        {
            "date": "2007-08-16T09:19:27+0000",
            "content": "I think the changes that were part of LUCENE-969 (giving 2.97X speedup of ISOLatin1AccentFilter) has resolved this issue? ",
            "author": "Michael McCandless",
            "id": "comment-12520182"
        },
        {
            "date": "2007-08-16T13:09:49+0000",
            "content": "Pretty sure you still want this guys patch. It avoids a slow StringBuffer and has a fail fast check before switching each char against a rather large list. In the case that there are not that many accents it is much faster, and in either case the replacement of StringBuffer is much faster. Probably complements 969. ",
            "author": "Mark Miller",
            "id": "comment-12520234"
        },
        {
            "date": "2007-08-16T14:30:26+0000",
            "content": "Ahh, OK, thanks.  I will re-open and merge in the fail-fast part; I've already replaced StringBuffer with char[] as part of LUCENE-969. ",
            "author": "Michael McCandless",
            "id": "comment-12520262"
        },
        {
            "date": "2007-08-16T21:57:43+0000",
            "content": "OK I merged the original patch with my commit from LUCENE-969.  I\nplan to commit tomorrow.  Thanks Ian! ",
            "author": "Michael McCandless",
            "id": "comment-12520386"
        },
        {
            "date": "2007-08-17T09:10:32+0000",
            "content": "My pleasure, for once to give something back to Lucene \nFYI, this is used for searching the texts of Charles Darwins letters at \nhttp://www.darwinproject.ac.uk/darwin/search/advanced , once again \nLucene saved us 1000's of hours of work.\nThank you.\nIan\n\n ",
            "author": "Ian Boston",
            "id": "comment-12520499"
        },
        {
            "date": "2007-08-17T16:58:50+0000",
            "content": "I just committed this.  Thanks Ian! ",
            "author": "Michael McCandless",
            "id": "comment-12520605"
        },
        {
            "date": "2007-08-20T13:45:42+0000",
            "content": "One possible (and probably large) speed up for this code would be replacing the switch / case structure (which for most characters needs to be evaluated down to the \"default\", which is lots of comparisons) with a plain static char[65536][] table. The cost for this is roughly 130kB of memory, but the speed-up should be pretty good. If lots of people are using this filter and the memory cost is acceptable, later this week I can try to prepare another patch. ",
            "author": "Stanislaw Osinski",
            "id": "comment-12521089"
        },
        {
            "date": "2007-08-20T18:51:49+0000",
            "content": "The switch statement is not equivalent to a list of sequential ifelses--it is implemented as a O(1) branch already. ",
            "author": "Mike Klaas",
            "id": "comment-12521191"
        },
        {
            "date": "2007-08-20T19:17:19+0000",
            "content": "Not exactly true, Mike. Switch statements are implemented as table lookups (tableswitch opcode) or binary sort switches (lookupswitch) \u2013 depending on the sparseness of keys used in the case clauses I'm sure, don't have the time to dig out my copy of the JVM spec right now.\n\nIn any case, I'm pretty sure what Staszek says is correct and will be more efficient \u2013 I've had that in practice and doing manual lookup instead of a switch (with multiple branches, wide spectrum) was much faster (an order of magnitude in my case). ",
            "author": "Dawid Weiss",
            "id": "comment-12521201"
        },
        {
            "date": "2007-08-20T19:40:56+0000",
            "content": "It seems that any table based approach would need to take up 256 slots at most... one could get away with 64 too (0xff-0xc0+1).\nIn any case, with normal latin1 text with an average amount of accents and a normal analyzer, does the current version really slow things down anymore?\n\nDawid: a lookupswitch is O(1), no? ",
            "author": "Yonik Seeley",
            "id": "comment-12521211"
        },
        {
            "date": "2007-08-21T07:22:43+0000",
            "content": "I guess it's a matter of just writing down two versions and comparing them against each other. \n\nYonik: I don't think lookupswitch is O(1) \u2013 my belief is that lookupswitch is a binary search through the key set http://java.sun.com/docs/books/jvms/second_edition/html/Compiling.doc.html#14942. I guess you could make it O(1) with perfect hashing, for example, but if I were to guess it's not the reality. It's a good question though \u2013 I'll have a look at SUN's JVM sources in a spare moment. ",
            "author": "Dawid Weiss",
            "id": "comment-12521340"
        },
        {
            "date": "2007-08-21T07:31:01+0000",
            "content": "I've just quickly decompiled the ISOLatin1AccentFilter.class from lucene 2.2.0 distribution \u2013 the switch statement got compiled into a tableswitch \u2013 the faster of the two options (but with larger code size).\n\nYonik: from what I understand from the JVM spec, it is the tableswitch that is O(1) and lookupswitch should be at least O(log(N)) (binary search through N case values). ",
            "author": "Stanislaw Osinski",
            "id": "comment-12521344"
        },
        {
            "date": "2007-08-21T07:51:48+0000",
            "content": "Funny \u2013 I just did the same, but my compiler (Eclipse JDT) generated a lookupswitch from head \u2013 \n\n    //*  52   93:iload           7\n                {\n    //*  53   95:lookupswitch    65: default 1275\n    //                   192: 624\n    //                   193: 624\n    //                   194: 624\n\nI also peeked at JVM's sources. Lookupswitches can be compiled (in hotspot mode) into two internal JVM instructions \u2013 fast_linearswitch or fast_binaryswitch. Depending on the selection you either get the O(1) acceleration or not. I still think it could be worthwhile to try to boost the performance of this method, although the gain might be minimal. ",
            "author": "Dawid Weiss",
            "id": "comment-12521350"
        },
        {
            "date": "2007-08-21T08:01:05+0000",
            "content": "To clarify: depending on the compiler/ hotspot you may get linear time (tableswitch), O(log(N)) (binarysearch) or O(N) (linearsearch). The exact checks which route is followed is beyond me, but the JVM sources are out there, so I guess it's possible to check. ",
            "author": "Dawid Weiss",
            "id": "comment-12521353"
        },
        {
            "date": "2007-08-21T08:50:12+0000",
            "content": "I was a bit curious about it, so I decided to write a table-lookup version. It does come out faster, but only by a small margin (especially on \"server\", hotspot JVMs). \n\nTimings are in milliseconds, the round consisted of 100000 repetitions of parsing the test string \"Des mot cl\u00e9s \u00c0 LA CHA\u00ceNE \u00c0 \u00c1 \u00c2 \u00c3 \u00c4 \u00c5 \u00c6 \u00c7 \u00c8 \u00c9 \u00ca \u00cb \u00cc \u00cd \u00ce \u00cf \u00d0 \u00d1 \u00d2 \u00d3 \u00d4 \u00d5 \u00d6 \u00d8 \u0152 \u00de \u00d9 \u00da \u00db \u00dc \u00dd \u0178 \u00e0 \u00e1 \u00e2 \u00e3 \u00e4 \u00e5 \u00e6 \u00e7 \u00e8 \u00e9 \u00ea \u00eb \u00ec \u00ed \u00ee \u00ef \u00f0 \u00f1 \u00f2 \u00f3 \u00f4 \u00f5 \u00f6 \u00f8 \u0153 \u00df \u00fe \u00f9 \u00fa \u00fb \u00fc \u00fd \u00ff\". Note it is biased since most characters do have accents, which will not be the case in real life I gues... but still:\n\n// SUN JVM build 1.6.0-b105, -server mode\nRound (old): 1922\nRound (old): 1688\nRound (old): 1656\nRound (old): 1687\nRound (old): 1641\nRound (old): 1703\nRound (old): 1672\nRound (old): 1672\nRound (old): 1687\nRound (old): 1719\nRound (new): 1719\nRound (new): 1609\nRound (new): 1609\nRound (new): 1594\nRound (new): 1625\nRound (new): 1578\nRound (new): 1625\nRound (new): 1594\nRound (new): 1625\nRound (new): 1656\n\n// SUN JVM, 1.6.0, interpreted (-client)\n\nRound (old): 2391\nRound (old): 2453\nRound (old): 2359\nRound (old): 2375\nRound (old): 2391\nRound (old): 2359\nRound (old): 2156\nRound (old): 2532\nRound (old): 2422\nRound (old): 2359\nRound (new): 1969\nRound (new): 1906\nRound (new): 1922\nRound (new): 1937\nRound (new): 1985\nRound (new): 1922\nRound (new): 1906\nRound (new): 1937\nRound (new): 1985\nRound (new): 1922\n\n// IBM JVM 1.5.0 (don't know why it's so sluggish, really).\n\nRound (old): 7906\nRound (old): 7188\nRound (old): 7625\nRound (old): 7312\nRound (old): 7266\nRound (old): 7141\nRound (old): 7015\nRound (old): 5641\nRound (old): 5578\nRound (old): 5672\nRound (new): 4656\nRound (new): 4406\nRound (new): 4516\nRound (new): 4516\nRound (new): 4375\nRound (new): 4375\nRound (new): 4343\nRound (new): 4297\nRound (new): 4344\nRound (new): 4266\n\n// IBM 1.5.0, -server (note the speed improvement when the old version is hotspot-optimized).\n\nRound (old): 5922\nRound (old): 5078\nRound (old): 5078\nRound (old): 5062\nRound (old): 4985\nRound (old): 4875\nRound (old): 4953\nRound (old): 4641\nRound (old): 3640\nRound (old): 3735\nRound (new): 3750\nRound (new): 3781\nRound (new): 3656\nRound (new): 3516\nRound (new): 3515\nRound (new): 3594\nRound (new): 3547\nRound (new): 3562\nRound (new): 3532\nRound (new): 3531\n\nSo... it does come out a bit faster. Whether it makes sense to waste 130 kb of memory for this improvement.... don't know, really. I'll upload the table-lookup version for your reference. ",
            "author": "Dawid Weiss",
            "id": "comment-12521361"
        },
        {
            "date": "2007-08-21T08:51:51+0000",
            "content": "A table-lookup version of ISO latin filter (this is not a patch, it's a renamed class so that you can compare the two). ",
            "author": "Dawid Weiss",
            "id": "comment-12521362"
        },
        {
            "date": "2007-08-21T15:39:35+0000",
            "content": "I guess there's no better way than to verify the sources as Dawid did, but here's a post that also explains the behaviour of the -server HotSpot JIT when it comes to switch statements:\n\nhttp://forums.java.net/jive/message.jspa?messageID=204492#204492  ",
            "author": "Ismael Juma",
            "id": "comment-12521505"
        }
    ]
}