{
    "id": "LUCENE-6111",
    "title": "Add Chinese Word Segmentation Analyzer with Ansj implementation",
    "details": {
        "resolution": "Unresolved",
        "affect_versions": "4.6",
        "components": [
            "modules/analysis"
        ],
        "labels": "",
        "fix_versions": [
            "4.6"
        ],
        "priority": "Minor",
        "status": "Open",
        "type": "Improvement"
    },
    "description": "When I use mahout-0.9 depending on lucene-4.6 to run Kmeans clustering algorithm, I find that the default word segmentation analyzer class named 'org.apache.lucene.analysis.standard.StandardAnalyzer' is very ugly, only single word could be splitted.However, ansj Chinese word segmentation tool is widely used in Chinese document-tokenizer, and I am willing to add it to support lucene.",
    "attachments": {},
    "issue_links": {},
    "comments": []
}