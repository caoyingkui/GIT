{
    "id": "LUCENE-7921",
    "title": "More efficient way to transform a RegExp to an Automaton",
    "details": {
        "labels": "",
        "priority": "Minor",
        "resolution": "Unresolved",
        "affect_versions": "6.5.1",
        "status": "Open",
        "type": "Improvement",
        "components": [],
        "fix_versions": []
    },
    "description": "Consider the following example:\n\nToAutomatonExample.java\n    public static void main(String[] args) {\n        org.apache.lucene.util.automaton.RegExp regExp =\n                new org.apache.lucene.util.automaton.RegExp(\"[a-z]{1,13}x[a-z][a-z]?[a-z]?[a-z]?[a-z]?[a-z]{0,8}\");\n        org.apache.lucene.util.automaton.Automaton automaton = regExp.toAutomaton();\n        System.out.println(\"states: \" + automaton.getNumStates());\n        System.out.println(\"transitions: \" + automaton.getNumTransitions());\n        System.out.println(\"-------------------------------\");\n\n        try {\n            regExp = new org.apache.lucene.util.automaton.RegExp(\"[a-z]{1,13}x[a-z]{1,13}\");\n            automaton = regExp.toAutomaton();\n            System.out.println(\"Will not happen...\");\n        } catch (org.apache.lucene.util.automaton.TooComplexToDeterminizeException e) {\n            automaton = regExp.toAutomaton(1_000_000);\n            System.out.println(\"states: \" + automaton.getNumStates());\n            System.out.println(\"transitions: \" + automaton.getNumTransitions());\n            System.out.println(\"-------------------------------\");\n        }\n    }\n\n\n\nBoth regular expressions are equivalent, but it's much more efficient to \"unroll\" the repetition.  It might be possible to optimize the Regex#toAutomaton() method to handle this repetition without going over the default number of determinized states, and using less memory and CPU?",
    "attachments": {
        "capture-7.png": "https://issues.apache.org/jira/secure/attachment/12880978/capture-7.png",
        "capture-8.png": "https://issues.apache.org/jira/secure/attachment/12880977/capture-8.png"
    },
    "issue_links": {},
    "comments": [
        {
            "id": "comment-16119512",
            "date": "2017-08-09T07:09:50+0000",
            "content": "Two identical regexps have an identical minimal deterministic automaton, so no unrolling will get you a benefit? I don't quite understand why you get the the \"too complex\" exception in one case vs. another, but it has to be a side effect of how this check is implemented (didn't look at the code); in the general sense both should be throwing the exception I think. ",
            "author": "Dawid Weiss"
        },
        {
            "id": "comment-16119523",
            "date": "2017-08-09T07:29:51+0000",
            "content": "It's the opposite: unrolling gets you the benefit.  I was hoping more for the conclusion that none of the cases should be throwing the exception - as the regexp is not that complex, and neither is the resulting automaton.  Elasticsearch has no problems executing it (in the unrolled variant). ",
            "author": "Thomas Poppe"
        },
        {
            "id": "comment-16119534",
            "date": "2017-08-09T07:45:28+0000",
            "content": "No, what I meant is this:\n\nstates: 118\ntransitions: 319\n-------------------------------\nstates: 118\ntransitions: 319\n-------------------------------\n\n\nAs you see the two final minimal representations are identical \u2013 the code that converts the automaton to a minimal deterministic automaton should be looked into as to why it explodes in the second case; the state count check shouldn't explode then, just as in the first example. So I'm not saying you're wrong, but it's not about optimizing or rewriting the regexp, it's about fixing the determinization routine.\n\nElasticsearch has no problems executing it (in the unrolled variant).\n\nES uses Lucene code underneath (correct me if I'm wrong) so if you use the same Lucene version you should observe the same result. There were some recent commits to this expansion check \u2013 perhaps it's a regression. ",
            "author": "Dawid Weiss"
        },
        {
            "id": "comment-16119540",
            "date": "2017-08-09T07:54:31+0000",
            "content": "Thanks for your comment Dawid.  One more thing I would like to note: the second case also takes more memory and CPU to convert to an automaton, so there might be an opportunity to optimize - but I guess you were already suggesting that. ",
            "author": "Thomas Poppe"
        },
        {
            "id": "comment-16119548",
            "date": "2017-08-09T08:07:26+0000",
            "content": "Automaton determinisation is a long topic... And has been for a long time too. \n\nI quickly looked at the code - the difference is in:\n\n  private Automaton toAutomatonInternal(Map<String,Automaton> automata,\n      AutomatonProvider automaton_provider, int maxDeterminizedStates)\n\n\n\nthe two representations will undergo different paths. I wonder if we could minimize subautomatons before we apply repeat, for example here (but in multiple places, really):\n\n      case REGEXP_REPEAT_MINMAX:\n        a = Operations.repeat(\n          exp1.toAutomatonInternal(automata, automaton_provider,\n            maxDeterminizedStates),\n          min,\n          max);\n        a = MinimizationOperations.minimize(a, maxDeterminizedStates);\n        break;\n\n\n ",
            "author": "Dawid Weiss"
        },
        {
            "id": "comment-16119564",
            "date": "2017-08-09T08:23:23+0000",
            "content": "Ooops, sorry \u2013 it calls toAutomatonInternal so it's already minimized. Still, your observation is right: the minimization there should be handled more efficiently for this type of automata (so that it's not fully expanded). ",
            "author": "Dawid Weiss"
        },
        {
            "id": "comment-16119573",
            "date": "2017-08-09T08:32:38+0000",
            "content": "A smaller example that shows what's going on. REGEXP_CONCATENATION expands elements of a concatenated regexp; the repeated-min-max on its own is much larger than a sequence of optionals. ",
            "author": "Dawid Weiss"
        },
        {
            "id": "comment-16119580",
            "date": "2017-08-09T08:41:07+0000",
            "content": "I think we should optimize Operations.repeat so that it produces saner input for minimization (single start state and epsilon arcs if x>=1 in {x,y}). It still wouldn't be the same behavior (concatenation would see different input clauses of a larger regexp), but it should be less costly (fewer states). ",
            "author": "Dawid Weiss"
        }
    ]
}