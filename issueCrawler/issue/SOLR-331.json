{
    "id": "SOLR-331",
    "title": "StringIndexOutOfBoundsException when using synonyms and highlighting",
    "details": {
        "affect_versions": "1.2",
        "status": "Closed",
        "fix_versions": [
            "1.2"
        ],
        "components": [
            "search"
        ],
        "type": "Bug",
        "priority": "Major",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "When searching index using highlighting and synonyms we get the following exception:\n\njava.lang.StringIndexOutOfBoundsException: String index out of range: 42\n\tat java.lang.String.substring(String.java:1935)\n\tat org.apache.lucene.search.highlight.Highlighter.getBestTextFragments(Highlighter.java:271)\n\tat org.apache.solr.util.HighlightingUtils.doHighlighting(HighlightingUtils.java:266)\n\tat org.apache.solr.request.StandardRequestHandler.handleRequest(StandardRequestHandler.java:164)\n\tat org.apache.solr.core.SolrCore.execute(SolrCore.java:595)\n\tat org.apache.solr.servlet.SolrServlet.doGet(SolrServlet.java:92)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:697)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:810)\n\tat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:252)\n\tat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:173)\n\tat org.jboss.web.tomcat.filters.ReplyHeaderFilter.doFilter(ReplyHeaderFilter.java:96)\n\tat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:202)\n\tat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:173)\n\tat org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:213)\n\tat org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:178)\n\tat org.jboss.web.tomcat.security.SecurityAssociationValve.invoke(SecurityAssociationValve.java:175)\n\tat org.jboss.web.tomcat.security.JaccContextValve.invoke(JaccContextValve.java:74)\n\tat org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:126)\n\tat org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:105)\n\tat org.jboss.web.tomcat.tc5.jca.CachedConnectionValve.invoke(CachedConnectionValve.java:156)\n\tat org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:107)\n\tat org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:148)\n\tat org.apache.coyote.http11.Http11Processor.process(Http11Processor.java:869)\n\tat org.apache.coyote.http11.Http11BaseProtocol$Http11ConnectionHandler.processConnection(Http11BaseProtocol.java:664)\n\tat org.apache.tomcat.util.net.PoolTcpEndpoint.processSocket(PoolTcpEndpoint.java:527)\n\tat org.apache.tomcat.util.net.MasterSlaveWorkerThread.run(MasterSlaveWorkerThread.java:112)\n\tat java.lang.Thread.run(Thread.java:619)\n\nthe problem is reproduceable and permanent with the attached files to this issue. Just use SOLR internal \n\"Make a Query[Full Interface]\" Admin Interface option and search for:\nStatement: adhs\nEnable Highlighting: X\nFields to Highlight: content\n\ne.g.\nhttp://127.0.0.1:8080/solr/select?indent=on&version=2.2&q=adhs&start=0&rows=10&fl=*%2Cscore&qt=standard&wt=standard&explainOther=&hl=on&hl.fl=content\n\nThank you in advance!\n\nOliver",
    "attachments": {
        "adhs_small.xml": "https://issues.apache.org/jira/secure/attachment/12363492/adhs_small.xml",
        "schema.xml": "https://issues.apache.org/jira/secure/attachment/12363491/schema.xml",
        "synonyms.txt": "https://issues.apache.org/jira/secure/attachment/12363490/synonyms.txt",
        "WordDelimiterFilter.patch": "https://issues.apache.org/jira/secure/attachment/12363549/WordDelimiterFilter.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Oliver Kuhn",
            "id": "comment-12518724",
            "date": "2007-08-09T14:34:43+0000",
            "content": "to create index with our data we used: \n\ncurl http://127.0.0.1:8080/solr/update --data-binary @adhs_small.xml -H \"Content-type:text/xml; charset=utf-8\"\ncurl http://127.0.0.1:8080/solr/update --data-binary \"<commit />\"\n\nadhs_small.xml contains our content. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12518769",
            "date": "2007-08-09T17:34:15+0000",
            "content": "Thanks for the very clear report.\nIt looks like WordDelimiterFilter is messing up the offsets.\n\nhttp://localhost:8983/solr/admin/analysis.jsp?nt=name&name=content&highlight=on&val=&qverbose=on&qval=dummy+dummy+dummy+ADHS+dummy\n\nAs a side note, you probably don't want to be expanding the same synonym list at both index and query time.  And expanding multi-word synonyms (of differing numbers of tokens) at query time doesn't really work... see the wiki for details on that. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12518782",
            "date": "2007-08-09T17:55:01+0000",
            "content": "OK, the issue is the offsets for subwords.  For example, WordDelimiterFilter is looking at\nAufmerksamkeits-Defizite, and it doesn't know that it's not part of the original text, so when it creates the sub-token\nAufmerksamkeits, it sets the offsets to match the length of \"Aufmerksamkeits\" (which is bigger than the original).\n\nSome ideas to fix:\n\n\tMake sure that generated offsets never exceed original offsets (this we should always do).  That will eliminate the exception, but generate highlighting mismatches in some cases.\n\ttry to recognize non-original tokens like synonyms\n  1) by token type???  but not everyone uses that\n  2) by seeing that the offsets don't match the token... stemming would cause this, but stemming should always be after WordDelimiterFilter.  Anything else that would cause \"length != end-start\"?\n\n "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12518890",
            "date": "2007-08-10T02:11:36+0000",
            "content": "This patch seems to work fine (not adjusting offsets if they don't match the original token length) "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12519053",
            "date": "2007-08-10T15:58:32+0000",
            "content": "committed. "
        },
        {
            "author": "Oliver Kuhn",
            "id": "comment-12519055",
            "date": "2007-08-10T16:26:38+0000",
            "content": "Hi Yonik, thanks for the quick answer.. we will try this patch in the near future! "
        }
    ]
}