{
    "id": "SOLR-5658",
    "title": "commitWithin does not reflect the new documents added",
    "details": {
        "affect_versions": "4.6,                                            6.0",
        "status": "Closed",
        "fix_versions": [
            "4.6.1",
            "4.7",
            "6.0"
        ],
        "components": [],
        "type": "Bug",
        "priority": "Critical",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "I start 4 nodes using the setup mentioned on - https://cwiki.apache.org/confluence/display/solr/Getting+Started+with+SolrCloud\n\nI added a document using - \ncurl http://localhost:8983/solr/update?commitWithin=10000 -H \"Content-Type: text/xml\" --data-binary '<add><doc><field name=\"id\">testdoc</field></doc></add>'\n\nIn Solr 4.5.1 there is 1 soft commit with openSearcher=true and 1 hard commit with openSearcher=false\nIn Solr 4.6.x there is there is only one commit hard commit with openSearcher=false\n\nSo even after 10 seconds queries on none of the shards reflect the added document. \n\nThis was also reported on the solr-user list ( http://lucene.472066.n3.nabble.com/Possible-regression-for-Solr-4-6-0-commitWithin-does-not-work-with-replicas-td4106102.html )\n\nHere are the relevant logs \n\nLogs from Solr 4.5.1\nNode 1:\n\n420021 [qtp619011445-12] INFO  org.apache.solr.update.processor.LogUpdateProcessor  \u2013 [collection1] webapp=/solr path=/update params={commitWithin=10000} {add=[testdoc]} 0 45\n\n\n\nNode 2:\n\n119896 [qtp1608701025-10] INFO  org.apache.solr.update.processor.LogUpdateProcessor  \u2013 [collection1] webapp=/solr path=/update params={distrib.from=http://192.168.1.103:8983/solr/collection1/&update.distrib=TOLEADER&wt=javabin&version=2} {add=[testdoc (1458003295513608192)]} 0 348\n129648 [commitScheduler-8-thread-1] INFO  org.apache.solr.update.UpdateHandler  \u2013 start commit{,optimize=false,openSearcher=true,waitSearcher=true,expungeDeletes=false,softCommit=true,prepareCommit=false}\n129679 [commitScheduler-8-thread-1] INFO  org.apache.solr.search.SolrIndexSearcher  \u2013 Opening Searcher@e174f70 main\n129680 [commitScheduler-8-thread-1] INFO  org.apache.solr.update.UpdateHandler  \u2013 end_commit_flush\n129681 [searcherExecutor-5-thread-1] INFO  org.apache.solr.core.SolrCore  \u2013 QuerySenderListener sending requests to Searcher@e174f70 main{StandardDirectoryReader(segments_3:11:nrt _2(4.5.1):C1)}\n129681 [searcherExecutor-5-thread-1] INFO  org.apache.solr.core.SolrCore  \u2013 QuerySenderListener done.\n129681 [searcherExecutor-5-thread-1] INFO  org.apache.solr.core.SolrCore  \u2013 [collection1] Registered new searcher Searcher@e174f70 main{StandardDirectoryReader(segments_3:11:nrt _2(4.5.1):C1)}\n134648 [commitScheduler-7-thread-1] INFO  org.apache.solr.update.UpdateHandler  \u2013 start commit{,optimize=false,openSearcher=false,waitSearcher=true,expungeDeletes=false,softCommit=false,prepareCommit=false}\n134658 [commitScheduler-7-thread-1] INFO  org.apache.solr.core.SolrCore  \u2013 SolrDeletionPolicy.onCommit: commits: num=2\n\tcommit{dir=NRTCachingDirectory(org.apache.lucene.store.NIOFSDirectory@/Users/varun/solr-4.5.1/node2/solr/collection1/data/index lockFactory=org.apache.lucene.store.NativeFSLockFactory@66a394a3; maxCacheMB=48.0 maxMergeSizeMB=4.0),segFN=segments_3,generation=3}\n\tcommit{dir=NRTCachingDirectory(org.apache.lucene.store.NIOFSDirectory@/Users/varun/solr-4.5.1/node2/solr/collection1/data/index lockFactory=org.apache.lucene.store.NativeFSLockFactory@66a394a3; maxCacheMB=48.0 maxMergeSizeMB=4.0),segFN=segments_4,generation=4}\n134658 [commitScheduler-7-thread-1] INFO  org.apache.solr.core.SolrCore  \u2013 newest commit generation = 4\n134660 [commitScheduler-7-thread-1] INFO  org.apache.solr.update.UpdateHandler  \u2013 end_commit_flush\n \n\n\nNode 3:\n\nNode 4:\n\n374545 [qtp1608701025-16] INFO  org.apache.solr.update.processor.LogUpdateProcessor  \u2013 [collection1] webapp=/solr path=/update params={distrib.from=http://192.168.1.103:7574/solr/collection1/&update.distrib=FROMLEADER&wt=javabin&version=2} {add=[testdoc (1458002133233172480)]} 0 20\n384545 [commitScheduler-8-thread-1] INFO  org.apache.solr.update.UpdateHandler  \u2013 start commit{,optimize=false,openSearcher=true,waitSearcher=true,expungeDeletes=false,softCommit=true,prepareCommit=false}\n384552 [commitScheduler-8-thread-1] INFO  org.apache.solr.search.SolrIndexSearcher  \u2013 Opening Searcher@36137e08 main\n384553 [commitScheduler-8-thread-1] INFO  org.apache.solr.update.UpdateHandler  \u2013 end_commit_flush\n384553 [searcherExecutor-5-thread-1] INFO  org.apache.solr.core.SolrCore  \u2013 QuerySenderListener sending requests to Searcher@36137e08 main{StandardDirectoryReader(segments_2:7:nrt _1(4.5.1):C1)}\n384553 [searcherExecutor-5-thread-1] INFO  org.apache.solr.core.SolrCore  \u2013 QuerySenderListener done.\n384554 [searcherExecutor-5-thread-1] INFO  org.apache.solr.core.SolrCore  \u2013 [collection1] Registered new searcher Searcher@36137e08 main{StandardDirectoryReader(segments_2:7:nrt _1(4.5.1):C1)}\n389545 [commitScheduler-7-thread-1] INFO  org.apache.solr.update.UpdateHandler  \u2013 start commit{,optimize=false,openSearcher=false,waitSearcher=true,expungeDeletes=false,softCommit=false,prepareCommit=false}\n389549 [commitScheduler-7-thread-1] INFO  org.apache.solr.core.SolrCore  \u2013 SolrDeletionPolicy.onCommit: commits: num=2\n\tcommit{dir=NRTCachingDirectory(org.apache.lucene.store.NIOFSDirectory@/Users/varun/solr-4.5.1/node4/solr/collection1/data/index lockFactory=org.apache.lucene.store.NativeFSLockFactory@6e4d4c84; maxCacheMB=48.0 maxMergeSizeMB=4.0),segFN=segments_2,generation=2}\n\tcommit{dir=NRTCachingDirectory(org.apache.lucene.store.NIOFSDirectory@/Users/varun/solr-4.5.1/node4/solr/collection1/data/index lockFactory=org.apache.lucene.store.NativeFSLockFactory@6e4d4c84; maxCacheMB=48.0 maxMergeSizeMB=4.0),segFN=segments_3,generation=3}\n389550 [commitScheduler-7-thread-1] INFO  org.apache.solr.core.SolrCore  \u2013 newest commit generation = 3\n389551 [commitScheduler-7-thread-1] INFO  org.apache.solr.update.UpdateHandler  \u2013 end_commit_flush\n\n\n\n\nUsing Solr 4.6\n\nNode 1:\n\n124513 [qtp1314570047-13] INFO  org.apache.solr.update.processor.LogUpdateProcessor  \u2013 [collection1] webapp=/solr path=/update params={commitWithin=10000} {add=[testdoc]} 0 348\n\n\n\nNode 2:\n\n101586 [qtp1608701025-13] INFO  org.apache.solr.update.processor.LogUpdateProcessor  \u2013 [collection1] webapp=/solr path=/update params={distrib.from=http://192.168.1.103:8983/solr/collection1/&update.distrib=TOLEADER&wt=javabin&version=2} {add=[testdoc (1458003613357965312)]} 0 217\n116407 [commitScheduler-7-thread-1] INFO  org.apache.solr.update.UpdateHandler  \u2013 start commit{,optimize=false,openSearcher=false,waitSearcher=true,expungeDeletes=false,softCommit=false,prepareCommit=false}\n116429 [commitScheduler-7-thread-1] INFO  org.apache.solr.core.SolrCore  \u2013 SolrDeletionPolicy.onCommit: commits: num=2\n\tcommit{dir=NRTCachingDirectory(org.apache.lucene.store.NIOFSDirectory@/Users/varun/solr-4.6.0/node2/solr/collection1/data/index lockFactory=org.apache.lucene.store.NativeFSLockFactory@245e7588; maxCacheMB=48.0 maxMergeSizeMB=4.0),segFN=segments_1,generation=1}\n\tcommit{dir=NRTCachingDirectory(org.apache.lucene.store.NIOFSDirectory@/Users/varun/solr-4.6.0/node2/solr/collection1/data/index lockFactory=org.apache.lucene.store.NativeFSLockFactory@245e7588; maxCacheMB=48.0 maxMergeSizeMB=4.0),segFN=segments_2,generation=2}\n116430 [commitScheduler-7-thread-1] INFO  org.apache.solr.core.SolrCore  \u2013 newest commit generation = 2\n116444 [commitScheduler-7-thread-1] INFO  org.apache.solr.search.SolrIndexSearcher  \u2013 Opening Searcher@75e32318 realtime\n116445 [commitScheduler-7-thread-1] INFO  org.apache.solr.update.UpdateHandler  \u2013 end_commit_flush\n \n\n\nNode 3:\n\n\nNode 4:\n\n68183 [qtp1338008566-14] INFO  org.apache.solr.update.processor.LogUpdateProcessor  \u2013 [collection1] webapp=/solr path=/update params={distrib.from=http://192.168.1.103:7574/solr/collection1/&update.distrib=FROMLEADER&wt=javabin&version=2} {add=[testdoc (1458003613357965312)]} 0 43\n83183 [commitScheduler-7-thread-1] INFO  org.apache.solr.update.UpdateHandler  \u2013 start commit{,optimize=false,openSearcher=false,waitSearcher=true,expungeDeletes=false,softCommit=false,prepareCommit=false}\n83207 [commitScheduler-7-thread-1] INFO  org.apache.solr.core.SolrCore  \u2013 SolrDeletionPolicy.onCommit: commits: num=2\n\tcommit{dir=NRTCachingDirectory(org.apache.lucene.store.NIOFSDirectory@/Users/varun/solr-4.6.0/node4/solr/collection1/data/index lockFactory=org.apache.lucene.store.NativeFSLockFactory@69c9fc69; maxCacheMB=48.0 maxMergeSizeMB=4.0),segFN=segments_1,generation=1}\n\tcommit{dir=NRTCachingDirectory(org.apache.lucene.store.NIOFSDirectory@/Users/varun/solr-4.6.0/node4/solr/collection1/data/index lockFactory=org.apache.lucene.store.NativeFSLockFactory@69c9fc69; maxCacheMB=48.0 maxMergeSizeMB=4.0),segFN=segments_2,generation=2}\n83208 [commitScheduler-7-thread-1] INFO  org.apache.solr.core.SolrCore  \u2013 newest commit generation = 2\n83220 [commitScheduler-7-thread-1] INFO  org.apache.solr.search.SolrIndexSearcher  \u2013 Opening Searcher@326f944c realtime\n83220 [commitScheduler-7-thread-1] INFO  org.apache.solr.update.UpdateHandler  \u2013 end_commit_flush\n \n\n\nUsing Solr 4.6.1\n\nNode 1:\n\n301363 [qtp619011445-15] INFO  org.apache.solr.update.processor.LogUpdateProcessor  \u2013 [collection1] webapp=/solr path=/update params={commitWithin=10000} {add=[testdoc]} 0 32\n\n\n\nNode 2:\n\n207000 [qtp619011445-17] INFO  org.apache.solr.update.processor.LogUpdateProcessor  \u2013 [collection1] webapp=/solr path=/update params={distrib.from=http://192.168.1.103:8983/solr/collection1/&update.distrib=TOLEADER&wt=javabin&version=2} {add=[testdoc (1458004563169640448)]} 0 28\n221974 [commitScheduler-7-thread-1] INFO  org.apache.solr.update.UpdateHandler  \u2013 start commit{,optimize=false,openSearcher=false,waitSearcher=true,expungeDeletes=false,softCommit=false,prepareCommit=false}\n221987 [commitScheduler-7-thread-1] INFO  org.apache.solr.core.SolrCore  \u2013 SolrDeletionPolicy.onCommit: commits: num=2\n\tcommit{dir=NRTCachingDirectory(org.apache.lucene.store.NIOFSDirectory@/Users/varun/Downloads/search-downloads/solr-4.6.1/solr/node2/solr/collection1/data/index lockFactory=org.apache.lucene.store.NativeFSLockFactory@352b9aeb; maxCacheMB=48.0 maxMergeSizeMB=4.0),segFN=segments_2,generation=2}\n\tcommit{dir=NRTCachingDirectory(org.apache.lucene.store.NIOFSDirectory@/Users/varun/Downloads/search-downloads/solr-4.6.1/solr/node2/solr/collection1/data/index lockFactory=org.apache.lucene.store.NativeFSLockFactory@352b9aeb; maxCacheMB=48.0 maxMergeSizeMB=4.0),segFN=segments_3,generation=3}\n221987 [commitScheduler-7-thread-1] INFO  org.apache.solr.core.SolrCore  \u2013 newest commit generation = 3\n221989 [commitScheduler-7-thread-1] INFO  org.apache.solr.search.SolrIndexSearcher  \u2013 Opening Searcher@132713fa realtime\n221990 [commitScheduler-7-thread-1] INFO  org.apache.solr.update.UpdateHandler  \u2013 end_commit_flush\n\n\n\nNode 3:\n\nNode 4:\n\n193133 [qtp1608701025-16] INFO  org.apache.solr.update.processor.LogUpdateProcessor  \u2013 [collection1] webapp=/solr path=/update params={distrib.from=http://192.168.1.103:7574/solr/collection1/&update.distrib=FROMLEADER&wt=javabin&version=2} {add=[testdoc (1458004563169640448)]} 0 23\n208133 [commitScheduler-7-thread-1] INFO  org.apache.solr.update.UpdateHandler  \u2013 start commit{,optimize=false,openSearcher=false,waitSearcher=true,expungeDeletes=false,softCommit=false,prepareCommit=false}\n208141 [commitScheduler-7-thread-1] INFO  org.apache.solr.core.SolrCore  \u2013 SolrDeletionPolicy.onCommit: commits: num=2\n\tcommit{dir=NRTCachingDirectory(org.apache.lucene.store.NIOFSDirectory@/Users/varun/Downloads/search-downloads/solr-4.6.1/solr/node4/solr/collection1/data/index lockFactory=org.apache.lucene.store.NativeFSLockFactory@3f83dcf3; maxCacheMB=48.0 maxMergeSizeMB=4.0),segFN=segments_2,generation=2}\n\tcommit{dir=NRTCachingDirectory(org.apache.lucene.store.NIOFSDirectory@/Users/varun/Downloads/search-downloads/solr-4.6.1/solr/node4/solr/collection1/data/index lockFactory=org.apache.lucene.store.NativeFSLockFactory@3f83dcf3; maxCacheMB=48.0 maxMergeSizeMB=4.0),segFN=segments_3,generation=3}\n208141 [commitScheduler-7-thread-1] INFO  org.apache.solr.core.SolrCore  \u2013 newest commit generation = 3\n208144 [commitScheduler-7-thread-1] INFO  org.apache.solr.search.SolrIndexSearcher  \u2013 Opening Searcher@3171c7df realtime\n208146 [commitScheduler-7-thread-1] INFO  org.apache.solr.update.UpdateHandler  \u2013 end_commit_flush",
    "attachments": {
        "SOLR-5658.patch": "https://issues.apache.org/jira/secure/attachment/12624816/SOLR-5658.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-13879844",
            "date": "2014-01-23T10:56:47+0000",
            "content": "Thanks for reporting this Varun.\n\nThe thing to note between the 4.5 logs and the 4.6.x logs is that in 4.5, there are two commit statements per node (1 soft commit with openSearcher=true and another hard commit with openSearcher=false) whereas in 4.6.x there is only one commit (hard commit with openSearcher=false). We need to find out why. "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-13879849",
            "date": "2014-01-23T10:59:26+0000",
            "content": "Also reported by a user (thanks Varun for pointing it out to me privately):\n\nhttp://lucene.472066.n3.nabble.com/Possible-regression-for-Solr-4-6-0-commitWithin-does-not-work-with-replicas-td4106102.html "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13879998",
            "date": "2014-01-23T15:46:12+0000",
            "content": "This is probably related to what params we pass on and which we filter out in DistributedUpdateProcessor. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13880013",
            "date": "2014-01-23T16:07:55+0000",
            "content": "Patch adds a test and forwards on the commitWithin param. "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-13880073",
            "date": "2014-01-23T16:57:07+0000",
            "content": "Thanks Mark. Should we re-spin 4.6.1 for this? "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13880086",
            "date": "2014-01-23T17:05:47+0000",
            "content": "I don't know. If there is support for it, I'm certainly willing to do it, but I'm not sure it's worth an RC4 myself. I think this issue has been around a very long time, and it's just random luck something seemed like it worked on 4.5.1 or older in any simple testing. "
        },
        {
            "author": "Daniel Collins",
            "id": "comment-13880114",
            "date": "2014-01-23T17:37:28+0000",
            "content": "Mark, what's the impact of this issue? Are you saying that CommitWithin was never distributed (which seems quite a big deal!), or is it more subtle than that? "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13880117",
            "date": "2014-01-23T17:39:56+0000",
            "content": "Right - it was not distributed. Not since we started filtering most parameters, which was a very long time ago. "
        },
        {
            "author": "Daniel Collins",
            "id": "comment-13880139",
            "date": "2014-01-23T18:00:11+0000",
            "content": "Ok, was just puzzled about how our system is working then (4.4.0), we consistently see softCommits running on the replicas, maybe it is autoCommit firing instead... "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-13880226",
            "date": "2014-01-23T19:03:52+0000",
            "content": "I think this issue has been around a very long time, and it's just random luck something seemed like it worked on 4.5.1 or older in any simple testing.\n\nI'm not sure about that. The commitWithin is also set in the AddUpdateCommand in addition to the request params. I ran your test against 4.5 without the fix for 5 times and it didn't fail. But it never passes with trunk (without the fix) so I think there may be another bug introduced with the streaming changes. I'll look at this again tomorrow my time. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13880244",
            "date": "2014-01-23T19:13:53+0000",
            "content": "I think it just depends on if it's a request wide or document level commitWithin? If it was request level, the only way it would have worked previously is if there was some code that looked for the commitWithin param explicitly and set the commitWithin on the AddUpdateCommand - I don't recall something like that. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13880253",
            "date": "2014-01-23T19:21:38+0000",
            "content": "Okay, outside of the distributed code, Solr does setup the cmd object with a request level commitWithin. That is how this used to work, that is why we didn't have to propagate the param.\n\nPerhaps the commitWithin is being lost when parsing the javabin. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13880256",
            "date": "2014-01-23T19:24:50+0000",
            "content": "I see the bug. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13880298",
            "date": "2014-01-23T20:03:40+0000",
            "content": "I'm still look at the details, but the cause in the change of behavior is the switch from xml to binary update requests. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13880472",
            "date": "2014-01-23T22:49:26+0000",
            "content": "Kind of ugly - the real fix will take a bit of work. The patch might be a decent partial fix / workaround for 4.6.1 if we respin. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13880548",
            "date": "2014-01-24T00:31:47+0000",
            "content": "Here is a full fix patch.\n\nSo previously, we still didn't propagate request level commitWithin at the request level, but each document add would pick up the request level commitWithin.\n\nThis per document level commitWithin support was not working with javabin.\n\nThis has to do with how javabin handles adds for streaming, and some funny code that I have improved with a comment and cleanup. "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-13880569",
            "date": "2014-01-24T00:53:08+0000",
            "content": "Commit 1560859 from Mark Miller in branch 'dev/trunk'\n[ https://svn.apache.org/r1560859 ]\n\nSOLR-5658: commitWithin and overwrite are not being distributed to replicas now that SolrCloud uses javabin to distribute updates. "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-13880573",
            "date": "2014-01-24T00:55:54+0000",
            "content": "Commit 1560860 from Mark Miller in branch 'dev/branches/branch_4x'\n[ https://svn.apache.org/r1560860 ]\n\nSOLR-5658: commitWithin and overwrite are not being distributed to replicas now that SolrCloud uses javabin to distribute updates. "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-13880588",
            "date": "2014-01-24T01:09:59+0000",
            "content": "Commit 1560866 from Mark Miller in branch 'dev/branches/lucene_solr_4_6'\n[ https://svn.apache.org/r1560866 ]\n\nSOLR-5658: commitWithin and overwrite are not being distributed to replicas now that SolrCloud uses javabin to distribute updates. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13880692",
            "date": "2014-01-24T03:13:35+0000",
            "content": "As a separate issue, it probably makes sense to send request level commitWithin as a param rather than setting it per doc - that would mean less repeated data in the request. We still need to properly support per doc like this as well though, because that is the level cmd objects support and we are distributing cmd objects. "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-13880716",
            "date": "2014-01-24T04:50:51+0000",
            "content": "This was nasty. Thanks for fixing and back-porting this, Mark!\n\nI opened SOLR-5660 to send request level commitWithin as a param. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13880726",
            "date": "2014-01-24T05:15:45+0000",
            "content": "Another issue this fixed is that the documents were being serialized and sent twice - though they were not processed twice, so just wasteful and not functionally problematic. "
        },
        {
            "author": "Erik Hatcher",
            "id": "comment-13882849",
            "date": "2014-01-27T14:46:50+0000",
            "content": "[~markmiller@gmail.com] Is this ticket complete as of Solr 4.6.1?  Just wondering if it can be closed.  Thanks! "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-13886604",
            "date": "2014-01-30T14:20:29+0000",
            "content": "Commit 1562836 from shalin@apache.org in branch 'dev/trunk'\n[ https://svn.apache.org/r1562836 ]\n\nSOLR-5658: Removing System.out.println in JavaBinUpdatedRequestCodec added for debugging "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-13886608",
            "date": "2014-01-30T14:23:47+0000",
            "content": "Perhaps I should remove this println as another issue because this has already been released? "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-13886676",
            "date": "2014-01-30T15:45:19+0000",
            "content": "Commit 1562860 from shalin@apache.org in branch 'dev/branches/branch_4x'\n[ https://svn.apache.org/r1562860 ]\n\nSOLR-5658: Removing System.out.println in JavaBinUpdatedRequestCodec added for debugging "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13887802",
            "date": "2014-01-31T14:45:52+0000",
            "content": "Thanks Shalin! Your call on the new issue or not. "
        },
        {
            "author": "Jessica Cheng Mallet",
            "id": "comment-13891608",
            "date": "2014-02-05T02:12:01+0000",
            "content": "Hi Mark,\n\nIs the change of serialization of docMap from Map to List necessary? Looks like the unmarshaled docMap isn't used anymore either, but the casting there is causing a \"ClassCastException: java.util.LinkedHashMap cannot be cast to java.util.List\" when interacting with an older solrj client.\n\nThanks,\nJessica "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13891613",
            "date": "2014-02-05T02:29:12+0000",
            "content": "Ah, this explains the issue our partner was having testing out HDS 4.6.1 - he didn't upgrade the entire cluster from 4.6.0 at once and got an exception in JavaBinCodec complaining about \"Unknown type 19\"\n\nNot sure if there is much we can do about it now given that 4.6.1 has been released. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13891636",
            "date": "2014-02-05T02:57:29+0000",
            "content": "Oh darn, that's no good. Need to fix that for 4.7. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13891637",
            "date": "2014-02-05T02:59:42+0000",
            "content": "Is the change of serialization of docMap from Map to List necessary?\n\nIt's part of supporting the iterator/streaming case. It's needed because of how things currently work. However, we shouldn't break with a class cast exception when using an older client - we should have the same old bad behavior. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13891643",
            "date": "2014-02-05T03:07:17+0000",
            "content": "We should probably add the ability to configure what format distributed updates will use internally so that you can tmp flip to xml or something for this type of issue. "
        },
        {
            "author": "Jessica Cheng Mallet",
            "id": "comment-13891647",
            "date": "2014-02-05T03:11:41+0000",
            "content": "Thanks for looking at it Mark!\n\nIf you don't mind me asking, the one thing I didn't understand is why docMap is needed. The line in unmarshal\n\n<quote>docMap =  (List<Entry<SolrInputDocument,Map<Object,Object>>>) namedList[0].get(\"docsMap\");</quote>\n\nloads docMap from the named list but the docMap variable doesn't seem to be used anywhere. Also, a text search of \"docsMap\" seems to indicate that JavaBinUpdateRequestCodec is the only class using it. What am I missing?\n\nThanks,\nJessica "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13891649",
            "date": "2014-02-05T03:15:05+0000",
            "content": "exception in JavaBinCodec complaining about \"Unknown type 19\"\n\nI hadn't considered going the other way - new client to old.\n\nThat's a bummer. Sucks this was implemented wrong first. "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13893461",
            "date": "2014-02-06T15:49:46+0000",
            "content": "mark: since this issue was recorded as \"fixed\" in 4.6.1 changes, re-opening now to address the problem it may have caused seems like a bad idea from an accountability standpoint \u2013 since if/when it's fixed, it will be confusing to users if it gets \"re-recorded\" in CHANGES under 4.7 (or whatever)\n\nSuggest you re-resolve this, and open a new linked (\"Broken By\") issue for the newly discovered problem in 4.6.1. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13893483",
            "date": "2014-02-06T16:08:34+0000",
            "content": "Reopen is just so its not lost until we figure what if anything we do. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13909523",
            "date": "2014-02-22T20:40:12+0000",
            "content": "The backcompat issue was moved to SOLR-5658. Resolving this. "
        }
    ]
}