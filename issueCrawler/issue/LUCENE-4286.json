{
    "id": "LUCENE-4286",
    "title": "Add flag to CJKBigramFilter to allow indexing unigrams as well as bigrams",
    "details": {
        "labels": "",
        "priority": "Minor",
        "components": [],
        "type": "Improvement",
        "fix_versions": [
            "4.0-BETA",
            "6.0"
        ],
        "affect_versions": "4.0-ALPHA,                                            3.6.1",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "Add an optional  flag to the CJKBigramFilter to tell it to also output unigrams.   This would allow indexing of both bigrams and unigrams and at query time the analyzer could analyze queries as bigrams unless the query contained a single Han unigram.\n\nAs an example here is a configuration a Solr fieldType with the analyzer for indexing with the \"indexUnigrams\" flag set and the analyzer for querying without the flag. \n\n<fieldType name=\"CJK\" autoGeneratePhraseQueries=\"false\">\n\u2212\n<analyzer type=\"index\">\n   <tokenizer class=\"solr.ICUTokenizerFactory\"/>\n   <filter class=\"solr.CJKBigramFilterFactory\" indexUnigrams=\"true\" han=\"true\"/>\n</analyzer>\n\n<analyzer type=\"query\">\n   <tokenizer class=\"solr.ICUTokenizerFactory\"/>\n   <filter class=\"solr.CJKBigramFilterFactory\" han=\"true\"/>\n</analyzer>\n</fieldType>\n\nUse case: About 10% of our queries that contain Han characters are single character queries.   The CJKBigram filter only outputs single characters when there are no adjacent bigrammable characters in the input.  This means we have to create a separate field to index Han unigrams in order to address single character queries and then write application code to search that separate field if we detect a single character Han query.  This is rather kludgey.  With the optional flag, we could configure Solr as above  \n\nThis is somewhat analogous to the flags in LUCENE-1370 for the ShingleFilter used to allow single word queries (although that uses word n-grams rather than character n-grams.)",
    "attachments": {
        "LUCENE-4286.patch": "https://issues.apache.org/jira/secure/attachment/12539126/LUCENE-4286.patch",
        "LUCENE-4286.patch_3.x": "https://issues.apache.org/jira/secure/attachment/12555377/LUCENE-4286.patch_3.x"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2012-08-04T00:22:49+0000",
            "content": "first stab at a patch. I think its ok, but needs more tests just to be sure. ",
            "author": "Robert Muir",
            "id": "comment-13428496"
        },
        {
            "date": "2012-08-04T01:54:00+0000",
            "content": "Updated patch with additional docs and tests.\n\nThis is ready to commit. ",
            "author": "Robert Muir",
            "id": "comment-13428528"
        },
        {
            "date": "2012-08-04T23:32:35+0000",
            "content": "Is this a request by Han language readers?\n ",
            "author": "Lance Norskog",
            "id": "comment-13428702"
        },
        {
            "date": "2012-08-06T16:06:17+0000",
            "content": "We haven't had a request for this specific feature from readers, we are just assuming that the 10% of Han queries in our logs that consist of a single character represent real use cases and we don't want such queries to produce zero results or produce misleading results.\n\nTom ",
            "author": "Tom Burton-West",
            "id": "comment-13429217"
        },
        {
            "date": "2012-08-06T16:20:09+0000",
            "content": "The combined unigram+bigram technique is a general technique, which I think is useful to support.\n\nFor examples see:\nhttp://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.12.6782\nhttp://members.unine.ch/jacques.savoy/Papers/NTCIR6.pdf\n\nThere are more references and studies linked from those.\n\nTom would have to do tests for his \"index-time-only\" approach: I can't speak for that. ",
            "author": "Robert Muir",
            "id": "comment-13429228"
        },
        {
            "date": "2012-08-06T22:05:11+0000",
            "content": "If you do unigrams and bigrams in separate fields, you can bias bigrams over unigrams. We did that with one customer and it really helped. Our text was technical and tended towards \"long\" words: lots of bigrams & trigrams. Have you tried the Smart Chinese toolkit? It produces a lot less bigrams. Our project worked well with it. I would try that, with misfires further broken into bigrams, over general bigramming. C.f. SOLR-3653 about the \"misfires\" part.\n\nIn general we found Chinese-language search a really hard problem, and doubly so when nobody on the team speaks Chinese.  ",
            "author": "Lance Norskog",
            "id": "comment-13429480"
        },
        {
            "date": "2012-08-08T19:04:45+0000",
            "content": "Thanks Robert for all your work on non-English searching and for your quick response on this issue.\n\n>>If you do unigrams and bigrams in separate fields, you can bias bigrams over unigrams.\nThat was our original intention. \n\n>>The combined unigram+bigram technique is a general technique, which I think is useful to support. ...Tom would have to do tests for his \"index-time-only\" approach: I can't speak for that.\n\nOriginally I was going to use the combined unigram+bigram technique (with a boost for the bigram fields) and wrote some custom code to implement it.  However, I started thinking about the size of our documents. With one exception, all the literature I found that got better results with a combination of bigrams and unigrams used newswire size documents (somewhere in the range of a few hundred words).  Our documents are several orders of magnitude larger (around 100,000 words).  \n\nMy understanding is that the main reason adding unigrams to bigrams increases relevance is that often the unigram will have a related meaning to the larger word.  So using unigrams is somewhat analogous to decompounding or stemming.  I haven't done any tests, but my guess is that with our very large documents the additional recall added by unigrams will be offset by a decrease in precision.\n\nAfter I get a test suite set up for relevance ranking in English, I'll take a look at testing CJK \n\nTom ",
            "author": "Tom Burton-West",
            "id": "comment-13431297"
        },
        {
            "date": "2012-08-09T00:57:27+0000",
            "content": "\nMy understanding is that the main reason adding unigrams to bigrams increases relevance is that often the unigram will have a related meaning to the larger word. So using unigrams is somewhat analogous to decompounding or stemming. I haven't done any tests, but my guess is that with our very large documents the additional recall added by unigrams will be offset by a decrease in precision.\n\nAfter I get a test suite set up for relevance ranking in English, I'll take a look at testing CJK \n\nWell for your use case (doing this only at indexing time), I think it should work well.\nThe 10% of your queries that are single-character will get reasonable results versus no/garbage results.\nThe rest of your queries are essentially unchanged: IDF remains the same for the bigrams, and document length will be ~ the same,\nthe \"additional\" bigrams do not count towards length normalization by default since they are synonyms over the unigrams.\n\nBut you will pay an indexing performance/disk penalty to some extent since you are indexing more tokens for these documents.\n\nHowever if you decide to also always turn on unigrams at query-time too, this might be prohibitively expensive: you would have to test.\nIf you do that, I don't think you need to do any special boosting: I'd first just let IDF take care of it  ",
            "author": "Robert Muir",
            "id": "comment-13431520"
        },
        {
            "date": "2012-11-29T18:03:02+0000",
            "content": "We are still using Solr 3.6 in production so I backported the patch to Lucene/Solr 3.6.  Attached as LUCENE-4286.patch_3.x ",
            "author": "Tom Burton-West",
            "id": "comment-13506628"
        },
        {
            "date": "2012-12-04T00:26:21+0000",
            "content": "I have just tried the indexUnigrams=\"true\" on branch_4x checked out 2012/11/28 and it doesn't seem to be working.  The analysis page (indexing) shows the bigrams, but no unigrams.  Am I doing something wrong?\n\nmy fieldType:\n\n\n    <fieldType name=\"genText\" class=\"solr.TextField\" sortMissingLast=\"true\" positionIncrementGap=\"100\">\n      <analyzer type=\"index\">\n        <tokenizer class=\"solr.ICUTokenizerFactory\"/>\n        <filter class=\"solr.PatternReplaceFilterFactory\"\n          pattern=\"^(\\p{Punct}*)(.*?)(\\p{Punct}*)$\"\n          replacement=\"$2\"\n          allowempty=\"false\"\n        />\n        <filter class=\"solr.WordDelimiterFilterFactory\"\n          splitOnCaseChange=\"1\"\n          splitOnNumerics=\"1\"\n          stemEnglishPossessive=\"1\"\n          generateWordParts=\"1\"\n          generateNumberParts=\"1\"\n          catenateWords=\"1\"\n          catenateNumbers=\"1\"\n          catenateAll=\"0\"\n          preserveOriginal=\"1\"\n        />\n        <filter class=\"solr.ICUFoldingFilterFactory\"/>\n        <filter class=\"solr.CJKBigramFilterFactory\" indexUnigrams=\"true\"/>\n        <filter class=\"solr.LengthFilterFactory\" min=\"1\" max=\"512\"/>\n      </analyzer>\n      <analyzer type=\"query\">\n        <tokenizer class=\"solr.ICUTokenizerFactory\"/>\n        <filter class=\"solr.PatternReplaceFilterFactory\"\n          pattern=\"^(\\p{Punct}*)(.*?)(\\p{Punct}*)$\"\n          replacement=\"$2\"\n          allowempty=\"false\"\n        />\n        <filter class=\"solr.WordDelimiterFilterFactory\"\n          splitOnCaseChange=\"1\"\n          splitOnNumerics=\"1\"\n          stemEnglishPossessive=\"1\"\n          generateWordParts=\"1\"\n          generateNumberParts=\"1\"\n          catenateWords=\"0\"\n          catenateNumbers=\"0\"\n          catenateAll=\"0\"\n          preserveOriginal=\"1\"\n        />\n        <filter class=\"solr.ICUFoldingFilterFactory\"/>\n        <filter class=\"solr.CJKBigramFilterFactory\" indexUnigrams=\"false\"/>\n        <filter class=\"solr.LengthFilterFactory\" min=\"1\" max=\"512\"/>\n      </analyzer>\n    </fieldType>\n\n ",
            "author": "Shawn Heisey",
            "id": "comment-13509373"
        },
        {
            "date": "2012-12-04T01:53:23+0000",
            "content": "There is no such option as \"indexUnigrams\".\n\nI think you mean outputUnigrams. See the documentation at http://lucene.apache.org/core/4_0_0/analyzers-common/org/apache/lucene/analysis/cjk/CJKBigramFilterFactory.html ",
            "author": "Robert Muir",
            "id": "comment-13509426"
        }
    ]
}