{
    "id": "SOLR-1057",
    "title": "PathTokenizerFactory",
    "details": {
        "affect_versions": "None",
        "status": "Closed",
        "fix_versions": [
            "3.1",
            "4.0-ALPHA"
        ],
        "components": [
            "Schema and Analysis"
        ],
        "type": "New Feature",
        "priority": "Minor",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "This is a Tokenizer that splits the input string into a series of paths.  For example:\n\n /aaa/bbb/ccc\n\nbecomes:\n\n /aaa/\n /aaa/bbb/\n /aaa/bbb/ccc",
    "attachments": {
        "SOLR-1057.patch": "https://issues.apache.org/jira/secure/attachment/12470014/SOLR-1057.patch",
        "SOLR-1057-PathTokenizerFactory.patch": "https://issues.apache.org/jira/secure/attachment/12401774/SOLR-1057-PathTokenizerFactory.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Ryan McKinley",
            "id": "comment-12747081",
            "date": "2009-08-24T21:14:02+0000",
            "content": "updated to use reusable token stuff "
        },
        {
            "author": "Lance Norskog",
            "id": "comment-12747127",
            "date": "2009-08-24T22:53:34+0000",
            "content": "It is also useful to generate the reverse:\n/\n/ccc/bbb/aaa\n\nWhen /aaa/bbb/ccc is a tree- (or directed graph-) structured taxonomy, it is useful in a UI to start and the bottom and find all of the paths it is part of. For example, orange is both a fruit and a color:\n\n/color/warm/orange\n/food/fruit/orange\n\nI would want to say /orange* and get both of the above paths. I may or may not want to generate these:\n/ccc\n/ccc/bbb/\n\nSo that should probably be another option.\n "
        },
        {
            "author": "Lance Norskog",
            "id": "comment-12747137",
            "date": "2009-08-24T23:25:08+0000",
            "content": "Also, the field must be multi-valued. This should be added to the Factory. "
        },
        {
            "author": "Dave Craft",
            "id": "comment-12860736",
            "date": "2010-04-25T19:05:30+0000",
            "content": "Hey.. any update on this one? I'm looking for a way for Solr to store a tree structure category. E.g. a taxonomy. Perhaps there is a way to do this already? If someone could point me in the right direction that would be great.\n\nThanks\n\nDave "
        },
        {
            "author": "Koji Sekiguchi",
            "id": "comment-12988706",
            "date": "2011-01-31T09:29:28+0000",
            "content": "I think this can be used for SOLR-64. I'll take it.\n\nTODO:\n\n\tmove PathTokenizer to modules/analysis/common/src/java/org/apache/lucene/analysis/path/ (4.0) or lucene/src/java/org/apache/lucene/analysis/ (3.1)\n\tmake test cases\n\trespect the original path delimiter (seems current patch outputs backslash even if the input uses slash)\n\taccept an arbitrary delimiter and replacement\n\tadd offset correction\n\n "
        },
        {
            "author": "Koji Sekiguchi",
            "id": "comment-12989501",
            "date": "2011-02-02T03:06:33+0000",
            "content": "A new patch added. "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-12989527",
            "date": "2011-02-02T06:07:33+0000",
            "content": "looks good!  I like the tests and configurable delimiter, but maybe we should allow multiple values?\n\nIn my app, I need to apply this filter to windows paths (C:\\path) urls, and unix paths... \n\nMaybe this could take a string as an argument with  max length 2?  then keep delimiter1 and delimiter2, and use:\n\nif( c == delimiter1 || c == delimiter2 ) {\n\n\n\nalso the javadoc should replace 'somethine' with 'something'\n "
        },
        {
            "author": "Koji Sekiguchi",
            "id": "comment-12989643",
            "date": "2011-02-02T14:19:10+0000",
            "content": "Can you use MappingCharFilter to normalize backslash to slash? "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-12989687",
            "date": "2011-02-02T16:06:31+0000",
            "content": "that would work if this were a filter... but I would need to run the MappingCharFilter before the path tokenizer.\n\nPerhaps we should change this to a Filter, and use the KeywordTokenizer to start? "
        },
        {
            "author": "Robert Muir",
            "id": "comment-12989693",
            "date": "2011-02-02T16:15:24+0000",
            "content": "I'm a little confused about the use of the tokenizer (i have no problems technically, its maybe a naming issue?)\n\nIs this intended for tokenizing file pathnames as its name would suggest? In this case I think the path should have positions, e.g. /foo/bar/whatever.txt is foo(1), bar(1), whatever.txt(1)?\n\nIt seems instead, this one is intended for representing hierarchies, as it creates synonyms of /foo, /foo/bar, /foo/bar/whatever.txt... with position increments of zero.\n\nI guess I'm just being picky about naming, but i think this hierarchical case is more specific than 'tokenizing file pathnames' and maybe a name like HierarchyTokenizer (this one too probably isn't the best!) would better represent what it does? "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-12989701",
            "date": "2011-02-02T16:32:34+0000",
            "content": "Maybe PathHierarchyTokenizer?\n\nYes, the point is to preserve the folder/path structure.  "
        },
        {
            "author": "Koji Sekiguchi",
            "id": "comment-12989706",
            "date": "2011-02-02T16:48:07+0000",
            "content": "that would work if this were a filter... but I would need to run the MappingCharFilter before the path tokenizer.\n\nCharFilters run before Tokenizer.\n\nMaybe PathHierarchyTokenizer?\n\n+1. "
        },
        {
            "author": "Koji Sekiguchi",
            "id": "comment-12989956",
            "date": "2011-02-03T04:41:06+0000",
            "content": "New patch. renamed it to PathHierarchyTokenizer. "
        },
        {
            "author": "Koji Sekiguchi",
            "id": "comment-12990425",
            "date": "2011-02-04T01:58:10+0000",
            "content": "A new patch. To respond Ryan's requirement, I added the following test:\n\n\npublic void testNormalizeWinDelimToLinuxDelim() throws Exception {\n  NormalizeCharMap normMap = new NormalizeCharMap();\n  normMap.add(\"\\\\\", \"/\");\n  String path = \"c:\\\\a\\\\b\\\\c\";\n  CharStream cs = new MappingCharFilter(normMap, new StringReader(path));\n  PathHierarchyTokenizer t = new PathHierarchyTokenizer( cs );\n  assertTokenStreamContents(t,\n      new String[]{\"c:\", \"c:/a\", \"c:/a/b\", \"c:/a/b/c\"},\n      new int[]{0, 0, 0, 0},\n      new int[]{2, 4, 6, 8},\n      new int[]{1, 0, 0, 0},\n      path.length());\n}\n\n "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-12990463",
            "date": "2011-02-04T06:24:16+0000",
            "content": "I was totally unaware of CharFilters and how they are called before the Tokenizer.\n\nthanks Koji! "
        },
        {
            "author": "Koji Sekiguchi",
            "id": "comment-12990504",
            "date": "2011-02-04T10:21:31+0000",
            "content": "Committed revision 1067131 (trunk). I'll back port to 3x tomorrow because I have to move now. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12990594",
            "date": "2011-02-04T16:13:21+0000",
            "content": "Is this generally applicable enough we should add an entry in\nhttp://wiki.apache.org/solr/AnalyzersTokenizersTokenFilters\nor is there a better place? "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-12990596",
            "date": "2011-02-04T16:16:45+0000",
            "content": "I think it will warrant its own page... in combination with SOLR-64\n\nbut should probably also be linked on the main analyzer page. "
        },
        {
            "author": "Koji Sekiguchi",
            "id": "comment-12990843",
            "date": "2011-02-05T00:13:17+0000",
            "content": "Committed revision 1067352 (3x). "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-13013057",
            "date": "2011-03-30T15:45:25+0000",
            "content": "Bulk close for 3.1.0 release "
        }
    ]
}