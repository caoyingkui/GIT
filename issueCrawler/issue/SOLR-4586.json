{
    "id": "SOLR-4586",
    "title": "Eliminate the maxBooleanClauses limit",
    "details": {
        "affect_versions": "4.2",
        "status": "Open",
        "fix_versions": [
            "7.0"
        ],
        "components": [
            "search"
        ],
        "type": "Improvement",
        "priority": "Major",
        "labels": "",
        "resolution": "Unresolved"
    },
    "description": "In the #solr IRC channel, I mentioned the maxBooleanClauses limitation to someone asking a question about queries.  Mark Miller told me that maxBooleanClauses no longer applies, that the limitation was removed from Lucene sometime in the 3.x series.  The config still shows up in the example even in the just-released 4.2.\n\nChecking through the source code, I found that the config option is parsed and the value stored in objects, but does not actually seem to be used by anything.  I removed every trace of it that I could find, and all tests still pass.",
    "attachments": {
        "SOLR-4586.patch": "https://issues.apache.org/jira/secure/attachment/12573826/SOLR-4586.patch",
        "SOLR-4586_verify_maxClauses.patch": "https://issues.apache.org/jira/secure/attachment/12578249/SOLR-4586_verify_maxClauses.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Shawn Heisey",
            "id": "comment-13603085",
            "date": "2013-03-15T03:47:28+0000",
            "content": "Patch implementing issue.  18 config files and 2 java files updated.  Aside from reordering the imports on one java file, the patch is all removal, no changes or additions.\n\nPatch passes precommit on branch_4x, and applies cleanly to both trunk and branch_4x. "
        },
        {
            "author": "Mikhail Khludnev",
            "id": "comment-13603338",
            "date": "2013-03-15T12:58:33+0000",
            "content": "maxBooleanClauses no longer applies, that the limitation was removed from Lucene sometime in the 3.x series.\n\nreally? "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-13603725",
            "date": "2013-03-15T19:18:48+0000",
            "content": "Mikhail, I was just going by what a committer told me in IRC.  If that's wrong, then the patch shouldn't be applied and this issue can be closed.  I tried the patched Solr out after removed maxBooleanClauses from my config, and a 1500-clause query fails, saying too many clauses.  Dropping that to 1024 allows the query to complete.  There were no results found, but it parsed and said numFound=0.\n\nIf the information about Lucene no longer having such a limitation is correct, perhaps Solr's code needs updating? "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13603749",
            "date": "2013-03-15T19:40:53+0000",
            "content": "It's been a long time, but as far as I remember, this isn't supposed to be a problem anymore. \n\nIt's still used to limit BQ's in Lucene, but Solr shouldn't be creating those large BQ's - I think it's possibly a bug if we are. I think for all normal cases we should be using the smart multi term queries that were made to avoid this problem?\n\nI'd have to dig to be sure. I also thought I remember shawn saying in irc that he confirmed that no code was reading this setting in solr anymore. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13603751",
            "date": "2013-03-15T19:42:10+0000",
            "content": "Basically, the idea is that a user should not need this setting or we still have work to do. "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-13603762",
            "date": "2013-03-15T19:50:31+0000",
            "content": "I'd have to dig to be sure. I also thought I remember shawn saying in irc that he confirmed that no code was reading this setting in solr anymore.\n\nI was wrong about the value not actually being used anywhere.  I think that can be attributed to not grokking Lucene internals and having only a short history with Java.  I have since located the following bit of code that is removed from SolrCore.java by my patch.  At the time it didn't look like anything important.\n\n\nBooleanQuery.setMaxClauseCount(boolean_query_max_clause_count);\n\n "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13603770",
            "date": "2013-03-15T19:57:09+0000",
            "content": "Yup - that's the one.\n\nI tried finding a jira issue i was involved in from years ago about this setting, but couldn't dig it/them up.\n\nWe worked hard to limit the problems it was causing lucene and solr users. I think it's kind of a crappy setting, always have, and it used to be a very common pain point before things got better.\n\nAnywhere sane should be using multi term queries that switch over to contant score and don't have this limitation.\n\nWhat did you do to trip this Shawn? "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-13603784",
            "date": "2013-03-15T20:04:25+0000",
            "content": "What did you do to trip this Shawn?\n\nI was just warning someone on IRC about the existence of the 1024-clause limit, then you mentioned it doesn't exist any more.  After that we discussed whether or not to remove it from Solr.\n\n\"And then there's us escaping now.\" \u2013 Wheatley "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13603795",
            "date": "2013-03-15T20:16:18+0000",
            "content": "I mean this:\n\nI tried the patched Solr out after removed maxBooleanClauses from my config, and a 1500-clause query fails, saying too many clauses. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13603799",
            "date": "2013-03-15T20:19:08+0000",
            "content": "I guess you just explicitly put in 1500 clauses?\n\nWe fixed the situation for the multi term queries - queries that rewrote themselves into BQ's. They were the scary, surprise stuff.\n\nI guess there is still a limit if you are explicit. I'll make the same argument i made a long time ago but i guess never wrapped up - this limit should be MAX_INT for explicit stuff! Yes, the more BQ's you explicity put, the worse your perf will be. We shouldn't cut this off at some arbitrary number! We should just as soon throw expcetions in Solr when too many QPS are reached. "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-13603807",
            "date": "2013-03-15T20:25:07+0000",
            "content": "I just created a simple query URL, q.op included because the default on my index is AND.  I allow headers up to 32K, so the size of the query URL was not a problem:\n\n\nq.op=OR&field:(1 2 3 4 ... 1499 1500)\n\n\n\nAs a shortcut for creating that, I did this at a bash shell and used copy/paste in PuTTY:\n\n\n'echo {1..1500}'\n\n "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-13603821",
            "date": "2013-03-15T20:41:28+0000",
            "content": "Changing the limit to Integer.MAX_VALUE is a one-line change, and allows my 1500-clause query to work, but that is probably better as a separate LUCENE issue rather than wrapped up in this issue for SOLR.\n\nI like this idea.  From a support perspective, there will still be questions from people who include thousands of clauses, but there will be no artificial roadblocks.  They will just want to know how they can make it faster. "
        },
        {
            "author": "Jack Krupansky",
            "id": "comment-13603823",
            "date": "2013-03-15T20:41:57+0000",
            "content": "Several years ago when I looked at this, there was only a check in BooleanQuery to see if the limit was exceeded, but otherwise Lucene was in no way dependent on the value of that limit.\n\nSo, I recommend removing support for the limit from Lucene as well.\n\nActually, I would recommend deprecating the maxBooleanClauses feature of both Lucene and Solr in 4.3, and removing the feature from trunk, 5.0.\n\nAs a backup plan, if the Lucene guys don't want to remove the limit, Solr should simply set the limit to Integer.MAX_VALUE, but otherwise remove all references to the \"feature\" in Solr itself. "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-13603855",
            "date": "2013-03-15T21:10:10+0000",
            "content": "Jack, are you saying that you want to keep parsing and enforcing the limit in 4.3, then do my current patch in 5.0?\n\nAssuming that the default limit is removed (either here or in Lucene), my preference would be exactly what the attached patch does - don't parse the option and remove it from examples.  Your approach is more conservative, and I can understand that it might be preferred. "
        },
        {
            "author": "Jack Krupansky",
            "id": "comment-13603886",
            "date": "2013-03-15T21:38:39+0000",
            "content": "... keep parsing and enforcing the limit in 4.3, then do my current patch in 5.0?\n\nYeah, a normal approach to deprecation - mark it in the solrconfig.xml  and Javadoc for 4.x as deprecated, but not remove until 5.0.\n\nOne additional twist: Raise the limit in the solrconfig.xml to 10,000 or 100,000 or 2 billion, or whatever to effectively remove/relax the limit in 4.x before final removal in trunk/5.0. "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-13603950",
            "date": "2013-03-15T22:54:45+0000",
            "content": "A new patch that changes the maxBooleanClauses default in Solr to 1048576 (2^20).  Parsing of maxBooleanClauses is still there, but it is effectively ignored if the value is lower than the new default.  Patch is against 4.x but applies cleanly to the latest revision (1457154) of trunk.\n\nIf deprecation is the preferred route for 4.x, I'll someone more experienced create that patch. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13603954",
            "date": "2013-03-15T22:57:33+0000",
            "content": "Why disallow a user from setting a lower limit? If someone wants to set 1024, let them. "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-13603965",
            "date": "2013-03-15T23:08:30+0000",
            "content": "Why disallow a user from setting a lower limit? If someone wants to set 1024, let them.\n\nGood point, and I thought of that right as I was uploading.  I'll cook up a new patch after my commute home.  I'll still let it find the highest value in any config, assuming they all contain the value.  The way I'm planning to do it, if the first core's config is missing the value, it'll start off with the new default, which might ignore any values in the other configs. "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-13605897",
            "date": "2013-03-19T01:09:26+0000",
            "content": "New patch (and issue title).  It compiles, and the logic looks clean, but I haven't actually tried to break it yet.  I will do so.  I will probably need some assistance in writing a test.\n\nAt just over 1 million, the new Solr default is huge, but nowhere near Integer.MAX_VALUE.  The new default is only used if the first solrconfig.xml loaded during startup does NOT have maxBooleanClauses.\n\nIf the first solrconfig.xml has maxBooleanClauses, the Solr default is ignored and the config value will be used.  If that value is lower than the Lucene default, the Lucene default is used.  Should I not put a lower bound on it like that \u2013 allow insanely low values?\n\nSubsequent solrconfig.xml files and re-reads through core reloading can only increase the value, so going lower would require a full restart. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13605943",
            "date": "2013-03-19T01:59:17+0000",
            "content": "Instead of the hair involving reloading and stuff, why not move it to solr.xml? Isn't that where it belongs (not per-core)? "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-13606058",
            "date": "2013-03-19T04:43:25+0000",
            "content": "Instead of the hair involving reloading and stuff, why not move it to solr.xml? Isn't that where it belongs (not per-core)?\n\nThat seems like a good idea to me.  It'll take me a while to figure out how. "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-13611252",
            "date": "2013-03-22T21:06:30+0000",
            "content": "A new patch for 4x that allows setting maxBooleanClauses on the solr tag in solr.xml as well as each solrconfig.xml.  If solr.xml has the config, the others will be ignored.\n\nThe only way that the new 1 million plus default will actually get used is if the config option is missing entirely from both solr.xml and the first solrconfig.xml.\n\nThis is probably not the final patch.  I'd like to have it reviewed to see if used a good approach.\n\nI still need to make some tests, but I will need help with that.  In particular, I do not know how to fire up a Jetty instance with custom configs - where to put the configs and how to tell the test to use them.  I can be easily reached on irc.\n\nOnce I come up with a final 4x patch, I will make a different one for trunk that removes the solrconfig.xml config option and only allows it to be set on the solr.xml/solr.properties, and modify the test(s) to match. "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-13611368",
            "date": "2013-03-22T22:32:13+0000",
            "content": "Side note: I notice that the default value for persistent in solr.xml when it's not present is false.  Shouldn't that be true, particularly with increased reliance on API changes from SolrCloud?  Is this no longer applicable with the new properties file replacement for solr.xml? "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13611383",
            "date": "2013-03-22T22:40:33+0000",
            "content": "Yeah, it probably would be a good change except it will be irrelevant with the new stuff. "
        },
        {
            "author": "Jack Krupansky",
            "id": "comment-13611411",
            "date": "2013-03-22T23:17:48+0000",
            "content": "This issue has morphed more than a bit since the original proposal to simply remove the maxBooleanClauses limit from Solr.\n\nAt this stage, I'd be more in favor of simply increasing the default maxBooleanClauses in Solr to 1 million (or whatever), but keeping all of the other semantics the exact same so that nobody sees any change other than the larger default limit, and all the rules (crazy as they are) for when and how the limit gets set remain unchanged. In other words, nobody needs to dig and try to understand \"What does this really mean??\" because the new default limit means quite simply \"Don't worry about it.\"\n\nI'm tempted to push for deprecation and removal of the limit, but I can see some merit in an artificial limit for testing and to limit resource consumption.\n\nIn short, the main goals here are: 1) Make the old limit a non-issue for typical applications, 2) don't mess with the semantics or create new rules for where or when or how to set the limit, and 3) preserve the limit capability for special situations where it is desirable to REUDCE the limit, as opposed to being forced to increase the limit as some applications need today. "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-13611537",
            "date": "2013-03-23T03:01:35+0000",
            "content": "Yes, it has morphed quite a lot.  I had some fundamental misunderstandings early on.  I suppose a true long-term goal would be to have Solr stop creating BooleanQuery objects whenever possible and use newer query objects.  I don't know enough about the low-level details to know if that IS possible.\n\nIn the 4.x short term, we probably need to support setting a low limit as mentioned in existing configs, and set a high limit if it's not configured.  That's what I've attempted to do in the newest patches.\n\nExactly what to do for 5.x and beyond is something I'm not sure about.  If we're going to support a user setting a low limit, Robert's idea of putting it into solr.xml or its replacement strikes me as the right thing to do.  We could also set a very high limit and not let the user configure it.\n\nIs there any consensus to be found here? "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13611735",
            "date": "2013-03-23T15:20:56+0000",
            "content": "My recommendation at solr.xml was to fix the bugs and not have complicated logic.\n\nI look at the issue differently: to me the important thing is that its bogus and confusing today to have this configuration parameter in solrconfig.xml, when it really should be in solr.xml, since it cannot be applied per-core. This is just a straight up bug! And I dont think the limit should be adjusted until this bug is fixed: otherwise it will just create more bugs (or at least confusing logic, like the last one or highest one or whatever is picked).\n\nSo it should be in solr.xml, and no one gets confused, and there is no need for confusing logic (picking the last one, or the highest one, or whatever). If someone has it specified in solrconfig.xml, some action should be taken: a nice person might argue for just a warning or similar in 4.x and just a straight up error (refuse to start) in 5.x. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13611742",
            "date": "2013-03-23T15:51:37+0000",
            "content": "when it really should be in solr.xml, since it cannot be applied per-core.\n\nIf it were truly a limit that one would want applied to all cores, then it should be in solr.xml\nBut I don't think that's the case.  The real bug here is this global static (max clauses) that has always had far reaching effects.\n\nI'd like to just set the limit to Integer.MAX_VALUE (essentially removing the limit), but it's not clear if that has any negative effects.\nI'm not concerned with any user queries that explicitly have many terms, but am concerned about MultiTerm queries or other things that Lucene may do internally based on this number.\n\nFor example, in TopTermsRewrite:\n\n  /** return the maximum size of the priority queue (for boolean rewrites this is BooleanQuery#getMaxClauseCount). */\n  protected abstract int getMaxSize();\n\n\n "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13611744",
            "date": "2013-03-23T15:57:57+0000",
            "content": "I disagree with Integer.MAX_VALUE (as i said on LUCENE-4835), and I disagree with removing the limit completely too.\n\nToday the way its implemented though, its a bug. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13611757",
            "date": "2013-03-23T16:22:17+0000",
            "content": "I disagree with Integer.MAX_VALUE (as i said on LUCENE-4835)\n\nThe argument there seemed to be more about Lucene (a programmer bug that kept adding clauses), although this is an extremely weird way to help catch such an error.\nPut another way... if the static max clauses had never existed, would it be added today?  I don't think so.  It was added in the past for historical reasons (auto-expanding queries) that hopefully no longer apply today.\n\nAnyway, for Solr-land, if we want to enforce on a per-core basis then we can do that at the Solr query parser level.  I see no reason to do that though.  I think we should just remove the limit altogether at the solr level. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13611760",
            "date": "2013-03-23T16:27:25+0000",
            "content": "Like i said: I disagree. if someone has more than 1024 terms in their query, more often than not: something is wrong and not being done efficiently.\n\nThey hit the limit and realize that, and its useful for that reason. If they want to increase/decrease the limit with some configuration parameter, then that configuration parameter should actually work and not be buggy. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13611764",
            "date": "2013-03-23T16:34:50+0000",
            "content": "We've seen tons of instances of people wanting to send in queries of more than 1024 terms.   Making them edit a config file first is very unfriendly.  It's really unfriendly if the system is already in production.\n\nWe don't limit the size of a query in bytes, the number of prefix queries, or fuzzy queries, or range queries, or any other query clauses that can take a large amount of resources.  We shouldn't limit the number of clauses in general either - it made sense in the past, but it no longer does. "
        },
        {
            "author": "Jack Krupansky",
            "id": "comment-13611842",
            "date": "2013-03-23T20:08:22+0000",
            "content": "I would note that neither SpanOrQuery or SpanMultiTermQueryWrapper implements a limit as BooleanQuery does. Shouldn't there be a consistent limit policy between BooleanQuery and SpanOrQuery, both of which take an arbitrary number of clauses?\n\nSo, I'm back to the proposal that:\n\n1. The boolean query caluse limit be deprecated in 4.x and removed in 5.0, in both Solr and Lucene.\n2. Solr define a default boolean clause limit in 4.x that is much higher than the Lucene limit.\n3. We otherwise preserve the semantics of clause limits for 4.x.\n4. Separately consider a query parser option to limit the maximum query size, in both source length and number of terms.\n\nI would classify the current Solr core-related semantics for the clause limit as \"messy\" rather than \"buggy\". If there is a clear and indisputable \"bug\" in the current semantics, fine, let's fix it. The current semantics are a holdover from the old single-core days when it made no difference that the solrconfig limit was \"for the core\" since that was all there was. Sure, that semantics should have been refined when multiple collections became the norm, but this is essentially a \"by design\" by default rather than an outright logic flaw. Besides, if you know the current semantics and have an app that depends on them, changing the rules would be a compatibility issue. Easier just to \"leave well enough alone\", and properly fix the semantics in 5.0 by completely removing the unnecessary \"feature\" - that SpanOrQuery proves is not necessary.\n\nI would agree that there is some (limited) value in specifying a limit to catch buggy code, but I just don't find it truly persuasive. Or at least not as persuasive as the annoyance of having the artificially low default and the need for a user-level config setting that is global for all Lucene indexes in the same JVM. (Why not make the limit be a Lucene IndexConfig setting? Please Don't!!). "
        },
        {
            "author": "David Smiley",
            "id": "comment-13611972",
            "date": "2013-03-24T04:57:01+0000",
            "content": "FWIW My opinion is consistent with Yonik & Jack's.\n\nBTW, when I see code that creates a massive BooleanQuery, it's always been of TermsQueries in a situation where the BooleanQuery could have been replaced with a ConstantScoreQuery wrapping a TermsFilter \u2013 which runs faster too.  Of course no scores but, again, the use-cases where I've seen BQ's limit hit don't actually care about the score.  It'd be nice if Solr had a QParser for that. "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-13614407",
            "date": "2013-03-26T18:35:11+0000",
            "content": "Here's my proposal:\n\nThe current 4x patch goes in largely as it is now.  Changes:\n1) Remove the solr.xml additions.\n2) Log a deprecation warning when maxBooleanClauses is found in solrconfig.xml, but honor it.\n2a) Should we make it possible to go lower than Lucene's default?  The current patch won't.\n3) Make some tests to verify behavior.  I'm willing to do this, but I will need a little guidance.\n\nWith the current POST buffer default size of 2MiB, you could include just under 2^20 boolean clauses, if each clause were only 1 byte, a highly contrived and illogical query.  For that reason, I think that 2^20 is a reasonable default value.  Also, I think that performance would become intolerable long before you reached that many clauses, and I think that will continue to be the case for the foreseeable future.\n\nFor 5.0, we remove the maxBooleanClauses config entirely.  If someone really did have a viable use case for more than 2^20 clauses, they would very likely have the expertise required to modify Solr code.\n\nWould it be a good idea to file another issue to have Solr use a better solution than BooleanQuery when possible? "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13615068",
            "date": "2013-03-27T09:40:16+0000",
            "content": "\n1) Remove the solr.xml additions.\n\n-1. thats where it belongs. its not a per-core thing.\n\n\n2) Log a deprecation warning when maxBooleanClauses is found in solrconfig.xml, but honor it.\n\n-1. As i stated, I want to keep this parameter. its useful.\n\n\n2a) Should we make it possible to go lower than Lucene's default? The current patch won't.\n\nDude. it should be nothing more than doing what the config file says. Seriously, anything else is a bug.\nIf i want to have a max of 5, thats my choice. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13615267",
            "date": "2013-03-27T13:52:36+0000",
            "content": "-1 to put maxBooleanClauses in solr.xml, it does not belong there.\nThis is arguably a Lucene bug (for being a system-wide static) and this problem should not be propagated into Solr. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13615312",
            "date": "2013-03-27T14:29:35+0000",
            "content": "if the static max clauses had never existed, would it be added today? I don't think so.\n\nAgreed. An ugly relic of the past that wouldn't get through the door today. "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-13622910",
            "date": "2013-04-04T22:37:23+0000",
            "content": "I have been working on a new patch.  Here's my current plan:\n\n4x:\nSupport maxBooleanClauses in solrconfig.xml.  The highest value found wins.  If the first core loaded is missing the config option, the new CoreContainer.DEFAULT_MAX_BOOLEAN_CLAUSES constant (1048576) will be used, and is therefore likely to be that winner.  Robert's theoretical value of 5 is doable by putting it in the first core config, or in all of them.  The example solrconfig.xml for collection1 has some comments.  The maxBooleanClauses section is entirely removed from all other solrconfig.xml files in the source tree, which mostly means configs for tests.\n\n\n    <!-- Max Boolean Clauses\n\n         Maximum number of clauses in each BooleanQuery, an exception\n         is thrown if a query exceeds this.\n\n         ** WARNING **\n         \n         This option actually modifies a global Lucene property that\n         will affect all SolrCores.  If multiple solrconfig.xml files\n         disagree on this property, the highest value found will be\n         the one that applies.  As of Solr 4.3, if the first solrconfig.xml\n         file loaded does not have this specified, a default of 1048576\n         will be used.  The default in older versions was 1024.\n\n      -->\n    <!--\n    <maxBooleanClauses>1024</maxBooleanClauses>\n     -->\n\n\n\ntrunk:\nSet maxBooleanClauses to DEFAULT_MAX_BOOLEAN_CLAUSES constant in CoreContainer.  All other code for maxBooleanClauses is gone.  If someone needs more than 1048576 clauses, they'll have to modify the source.\n\nI hope the 4x direction is correct.  The trunk change seems right to me, but I can make them the same if that would be better.  If any existing tests are affected, I will fix them.  I would like to build some tests specifically for this issue, but as I said before, I'll need help with that.\n\nIf trunk and 4x do end up being different, should they be entirely separate commits?  I have learned that standard practice is to commit to trunk, then merge the trunk commit into the release branch and do any necessary cleanup. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13622924",
            "date": "2013-04-04T22:59:35+0000",
            "content": "I already stated i dont think it should be completely removed. doing it in trunk only doesnt make it any better.\n\nI think its fine to carefully increase the default, but its also useful to have limits rather than performance traps (I fundamentally disagree with the entire idea of just letting things be \"slow\" instead of catching errors).\n\nI don't think its going to be any easier to commit this as a solr issue vs. as lucene one just because I'm being a pain in the ass. I can be a pain in the ass on this issue, too.\n\nJust increasing the default isnt enough anyway, its a must to ensure that priority queues of size 1m arent being created by default where they were 1k before, too. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13622994",
            "date": "2013-04-04T23:35:51+0000",
            "content": "(I fundamentally disagree with the entire idea of just letting things be \"slow\" instead of catching errors).\n\nIt's extremely \"trappy\" to fail hard at a low arbitrary limit (and it's silly calling it an error if it goes above that limit).\nmaxBooleanClauses should be removed from Solr (or effectively removed via setting it to MAX_INT) provided there are no bugs in Lucene that create any priority queues of this size.\n\n\nAll other code for maxBooleanClauses is gone.\n\n+1 "
        },
        {
            "author": "David Smiley",
            "id": "comment-13623383",
            "date": "2013-04-05T05:52:55+0000",
            "content": "Rob, how would you feel if the BooleanQuery instead logged a one-time warning if it gets used with > 1024 clauses?  And if assertions are enabled then fail.  The idea here is to try and alert the developer that they are most likely using BooleanQuery incorrectly, and suggest TermsFilter might be suitable instead.  At least then, the application won't experience an avoidable failure in production \u2013 the primary concern of everyone else on this thread. "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-13623631",
            "date": "2013-04-05T13:46:17+0000",
            "content": "Even before someone was crazy enough to make me a committer, I developed a lot of respect for Robert, watching the dev list in general and Jira in particular.  He knows most of this code backwards and forwards, and often keeps the rest of us from doing things we'll regret later.  Is this one of those things?  I can't tell.\n\nMy gut tells me that we need to increase the value and take the choice away from non-savvy users.  MAX_INT seems too high.  Even the default I've proposed is probably too high, but what value will work?  I haven't done any experimenting to know when performance becomes unacceptable.  Would 16K be better?  32K?  256K?  IMHO, if we choose a value low enough that pathological user code will easily result in a \"too many clauses\" exception, there will be a significant subset of Solr users that will legitimately need more.  We've got potential support issues either way.  Perhaps my 4x solution needs to be left in place long-term, and we need a little more discussion about the default value.\n\nif the BooleanQuery instead logged a one-time warning if it gets used with > 1024 clauses?  And if assertions are enabled then fail.  The idea here is to try and alert the developer that they are most likely using BooleanQuery incorrectly, and suggest TermsFilter might be suitable instead.\n\nFor Lucene, choosing TermsFilter is probably a viable solution much of the time, but this issue is for Solr.  It's linked to a similar issue for Lucene.  My Lucene knowledge is very pitiful, I know enough to be dangerous but not useful.  In my head, I imagine that reworking Solr to eliminate/reduce the use of BooleanQuery is a monumental task.  Am I right about that? "
        },
        {
            "author": "David Smiley",
            "id": "comment-13623654",
            "date": "2013-04-05T14:12:34+0000",
            "content": "For Lucene, choosing TermsFilter is probably a viable solution much of the time, but this issue is for Solr. It's linked to a similar issue for Lucene. My Lucene knowledge is very pitiful, I know enough to be dangerous but not useful. In my head, I imagine that reworking Solr to eliminate/reduce the use of BooleanQuery is a monumental task. Am I right about that?\n\nThe solr user would be un-impacted because they very well may choose to ignore the warning.  If they have some basic Lucene knowledge, they could write a QParser that builds a ConstantScoreQuery from a TermsFilter.  It's a piece of cake and if I wasn't so darned busy I'd do it myself because it's something Solr should have. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13623682",
            "date": "2013-04-05T14:55:35+0000",
            "content": "Even the default I've proposed is probably too high, but what value will work? \n\nI don't think it's a very good argument because of this silly guessing. We could try and protect a user from these silly situations everywhere. Should we also limit the number of filters allowed in an analyzer? Should we watch how many docs you are putting into the index? Should we make sure you don't add a query filter thats too long and crazy? It's a silly direction to go down. And that's why you won't find it anywhere else. This is an aberration thats been around before pretty much any of us showed up. The idea that this is helpful to users is absurd - I've been around lucene and solr and users for too long to fall for that. "
        },
        {
            "author": "Jack Krupansky",
            "id": "comment-13623691",
            "date": "2013-04-05T15:04:50+0000",
            "content": "My revised proposal:\n\n1. Unless the Lucene guys cave, leave it in Lucene. Same Lucene default.\n2. Leave it in Solr as well, on the theory that if Lucene has a setting, Solr should provide access to it.\n3. Raise the Solr default to 100K - both in the code and example solrconfig. 1 million is too scary.\n4. Change the Solr semantics so that the Lucene limit is raised whenever a collection is loaded that has a higher limit. First collection sets the low water mark.\n5. Change in both trunk and 4x since it won't impact existing apps.\n\nToday, if you want to change the limit, you must shutdown and reload the Solr server since only the initial core load will set it.\n\nMy proposal is trying to satisfy three goals:\n\n1. A higher default limit.\n2. Can change the value, at least to raise it, without a full Solr server shutdown and restart.\n3. Somewhat simpler semantics - you don't need to read the fine print to use it, and rarely would you need to use it. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13623852",
            "date": "2013-04-05T17:51:26+0000",
            "content": "Leave it in Solr as well, on the theory that if Lucene has a setting, Solr should provide access to it.\n\nSolr isn't a \"Lucene configuration engine\" - we don't allow for all of the flexibility that lucene provides, and never will.\nA setting should make sense on it's own.  This particular setting no longer makes sense.  I don't think it makes sense for Lucene or Solr, but the arguments need not be the same for both since the use cases are different. "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-13629036",
            "date": "2013-04-11T15:53:12+0000",
            "content": "In situations where true consensus cannot be found, but most people agree work is needed, how do we decide what to do?\n\nBack to the issue - is there a way in Lucene to specify something like the following query (using all of the different kinds of boolean logic) without BooleanQuery?\n\n\n(+author:tolkien -title:hobbit) isbn:( ... 200000 different ISBNs ...)\n\n\n\nIf so, how's the performance compared to BooleanQuery, and could Solr reliably construct such a query?  That would be the ideal long-term fix, if it's possible, and that would make this issue a band-aid until the real fix can happen. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13629048",
            "date": "2013-04-11T16:02:18+0000",
            "content": "FYI, I'm currently working on testing that setting Integer.MAX_VALUE has no unintended side-effects (i.e. no huge priority queues should be created, etc.) "
        },
        {
            "author": "Jack Krupansky",
            "id": "comment-13629052",
            "date": "2013-04-11T16:06:19+0000",
            "content": "\n is there a way in Lucene to specify something like the following query (using all of the different kinds of boolean logic) without BooleanQuery?\n\n\n(+author:tolkien -title:hobbit) isbn:( ... 200000 different ISBNs ...)\n\n\n\nSure, just break it up into 1024-term chunks:\n\n\n(+author:tolkien -title:hobbit) isbn:( ( ... 1024 ISBNs ... ) ( ... 1024 ISBNs ...) ... repeat 200 times ... )\n\n\n\nThe parentheses for the sub-queries should cause the query parser to generate a nested BooleanQuery for each sub-query. "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-13629068",
            "date": "2013-04-11T16:19:58+0000",
            "content": "My specific query example might have been bad, as it would exceed a 2MB POST buffer, but ignore that and focus on the idea. "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-13629080",
            "date": "2013-04-11T16:29:29+0000",
            "content": "Sure, just break it up into 1024-term chunks:\n\nI didn't know that was possible.  I thought I had remembered (using debugQuery) that Solr parses nested queries down to remove nesting, but I could be wrong about that.\n\nI was actually asking if it was possible to do it without BooleanQuery at all.  I'm glad to have the knowledge you've imparted, though. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13629096",
            "date": "2013-04-11T16:41:44+0000",
            "content": "Sure, just break it up into 1024-term chunks:\n\nRight.  This will be slightly less efficient than one bigger boolean query, but it does work around the arbitrary limit.  The other workaround is to remove the arbitrary limit \n\nFor those that might not have the historical context: in the past, some auto-expanding term queries (like fuzzy queries) would generate more and more terms to search until \"max clauses\" was hit - so the limit had a purpose.  If you go back far enough, other queries (like prefix queries) generated unbounded boolean queries, and an exception would be thrown when too many terms were generated.  The latter was very bad (things worked in production until your index grew and then would blow up).  Solr luckily never had this issue as it used constant scoring techniques with no limits for both prefix and range queries from the beginning.\n\nThe historical reasons for this limit no longer apply.  No multi-term queries that solr uses explode into a huge boolean query if you remove the limit (this is what I'm busy verifying with tests right now).  This only affects explicitly created queries, where it's very bad to have an artificial limit like this set since it may work in testing and initially in production, and then blow up in the future because the arbitrary limit was crossed.\n "
        },
        {
            "author": "Jack Krupansky",
            "id": "comment-13629098",
            "date": "2013-04-11T16:46:10+0000",
            "content": "And, technically, the query parser's query generator could generate daisy-chained BooleanQuery's, where every 1024th clause is a reference to a nested BQ that has than same form. Or, the query parser could generate every 1024 clauses down at a second level and reference them from the main BQ, so that you could have a single BQ that could have 1024 clauses, each of each is either a term or BQ, with the second level of BQ being terms only, which would let you have 1024x1024 or 1M terms.\n\nNot that I am proposing any of this, and I suspect that Lucene will perform better if it sees all the clauses in one, single group rather than scattered into multiple BQ's. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13629181",
            "date": "2013-04-11T18:04:52+0000",
            "content": "OK, here's a patch I used to verify that nothing bad was going to happen if we switch to using Integer.MAX_VALUE in Solr.\n\nBasically it changes BooleanQuery.getMaxClauseCount() to throw an exception, and then comments out where it won't take effect if max clauses is high, or changes it to use a different method if the check is harmless.\n "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13629285",
            "date": "2013-04-11T20:02:04+0000",
            "content": "Here's a simple patch that removes the max clauses limitation from Solr.\n\nI considered going the deprecation route, but in this instance I believe most users would be best served by outright removal of this trap since maxClauses was set by default in the example solrconfig.xml.  Further, anyone who did actually explicitly set the value is most likely just looking to avoid hitting exceptions. "
        },
        {
            "author": "Jack Krupansky",
            "id": "comment-13629301",
            "date": "2013-04-11T20:15:36+0000",
            "content": "I was thinking that maybe there should be a \"tombstone\" deprecated comment in solrconfig for maxBooleanClauses so that somebody doing a file compare could know that they can/should clean up their pre-4.3 solrconfig as opposed to some feature that may have simply disappeared or moved.\n\nOtherwise, +1 for moving forward towards closure on this. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13629302",
            "date": "2013-04-11T20:15:47+0000",
            "content": "I'm still -1 to removing the limit. Its even more bogus to just silently ignore a configuration parameter that used to exist completely: i guess this is typical Solr though.\n\n\nBack to the issue - is there a way in Lucene to specify something like the following query (using all of the different kinds of boolean logic) without BooleanQuery?\n\n(+author:tolkien -title:hobbit) isbn:( ... 200000 different ISBNs ...)\n\n\n\nThis is a fantastic example of why the limit can still be useful. it forces you to think about what is going on here... why do your queries have 200,000 terms? "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13629336",
            "date": "2013-04-11T20:42:34+0000",
            "content": "Its even more bogus to just silently ignore a configuration parameter \n\nThat's part of the problem - most people will not have explicitly configured it (except those trying to avoid exceptions), but just got it by virtue of copying the example solrconfig.xml as a starting point.\n\n> (+author:tolkien -title:hobbit) isbn ... 200000 different ISBNs ...)\nThis is a fantastic example of why the limit can still be useful. it forces you to think about what is going on here..\n\nUnfortunately, it doesn't force anyone to think about those issues early on.  Maybe setting a very low limit like 10 or 20 terms would... but 1024 definitely does not.\nWhat happens is that you can have a working, tested application that constructs queries like this, and it only breaks at some undetermined future point in time when the magic limit is exceeded (caused by index growth or whatever).  There is no warning to the user that the query structure that they are using will break hard after going over this magic limit (that no longer serves a purpose).  It's simply a trap, and we should remove it. "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-13629399",
            "date": "2013-04-11T21:13:29+0000",
            "content": "Here's a simple patch that removes the max clauses limitation from Solr.\n\nI would also remove maxBooleanClauses from the many test-related solrconfig.xml files that have included it.  If you don't have the time right now, I am willing to make a new patch.  I like Jack's idea for a tombstone comment in the example solrconfig.xml file. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13629427",
            "date": "2013-04-11T21:36:00+0000",
            "content": "I would also remove maxBooleanClauses from the many test-related solrconfig.xml files that have included it. If you don't have the time right now, I am willing to make a new patch.\n\nThanks, I had missed that. "
        },
        {
            "author": "Jack Krupansky",
            "id": "comment-13714848",
            "date": "2013-07-22T00:20:24+0000",
            "content": "Huh... I though we had settled this for 4.4. Oh well.\n\nMy latest thoughts.\n\n1. For BooleanQuery, remove it. People writing or generating Solr queries are very aware when they are doing something big.\n\n2. For \"rewrite\" of queries, have a warning and cutoff of the generated terms, rather than a hard fail. With FSTs, do we still have a rewriting problem?\n\n3. Any query that can generate lots of terms should have an additional constructor parameter to specify the limit, or -1 if unlimited. No more global limit. Each query parser should have a \"term expansion limit\" parameter.\n\n4. The default for the \"term expansion limit\" parameter should be expanded as hardware capabilities expand. Say 10,000 for a proposed Lucene limit and Solr config default limit as well.\n "
        },
        {
            "author": "Bragadeesh",
            "id": "comment-14103900",
            "date": "2014-08-20T14:04:56+0000",
            "content": "I bumped through this issue recently. Is this something planned for a release sooner ?  "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-14104249",
            "date": "2014-08-20T18:07:35+0000",
            "content": "Bragadeesh:\n\nYou can set it in Solr via a setting in solrconfig.xml, and in Lucene by the appropriate setter method.\n\nThis is just a default, not a hard limit.\n "
        },
        {
            "author": "Robert Parker",
            "id": "comment-14195112",
            "date": "2014-11-03T21:21:18+0000",
            "content": "Under Solr 4.10.2 in solrcloud configuration, if I upload a change to solrconfig.xml to zookeeper that raises maxBooleanClauses from 1024 to 2048 and then reload the collection, the cores do not recongnize a new value for maxBooleanClauses unlike other changes to schema.xml and solrconfig.xml.  I have to bounce Solr on each node before queries will honor the new value for maxBooleanClauses.  This seems like unintentional behavior.  I should be able to make any change to schema.xml and solrconfig.xml, then upload those to zookeeper and have each node in the cluster instantly honor all new values after a core/collection reload. "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-14195223",
            "date": "2014-11-03T22:20:39+0000",
            "content": "Robert Parker, maxBooleanClauses is a global Lucene setting across the entire application, and the last thing to set that value will \"win\" every time.\n\nIf you have any configs with the default of 1024 and you reload any of those cores after reloading the one that sets it to 2048, then it will be changed back \u2013 for the entire application.  The best option is to set the higher limit in every solrconfig.xml file, or remove the setting from all of them except one.\n\nThe javadocs for the Lucene setter method do not indicate this global nature, but I assure you that I have looked at the code, and it is indeed global.\n\nhttp://lucene.apache.org/core/4_10_0/core/org/apache/lucene/search/BooleanQuery.html#setMaxClauseCount%28int%29 "
        },
        {
            "author": "Robert Parker",
            "id": "comment-14195233",
            "date": "2014-11-03T22:27:05+0000",
            "content": "Ive only got one collection and one config in zookeeper, and thats the one that is being changed.  Each core had its solrconfig.xml updated on disk, but since its a SolrCloud config, only the zookeeper version should matter, correct?   "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-14195253",
            "date": "2014-11-03T22:36:22+0000",
            "content": "That's correct.\n\nIt is entirely possible that this is one config setting that does not get re-handled on a core reload.  I'd have to trace the code to know for sure, and I'm not very familiar with it, so it could take quite a while to trace.  I don't have the time for that at the moment. "
        },
        {
            "author": "Robert Parker",
            "id": "comment-14196180",
            "date": "2014-11-04T15:02:46+0000",
            "content": "I've opened a bug in response to this behavior:  https://issues.apache.org/jira/browse/SOLR-6695 "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-14196210",
            "date": "2014-11-04T15:18:17+0000",
            "content": "IMO, maxBooleanClauses should just go away for 5.0.\nIt's a no-brainer... one of the first things I fixed in Heliosearch: http://heliosearch.org/download/#0.04 "
        },
        {
            "author": "David Smiley",
            "id": "comment-14196212",
            "date": "2014-11-04T15:20:48+0000",
            "content": "I'd like to point out that if you are submitting queries with a lot of terms then you really should be using the new Terms QParser in 4.10.  That said, I continue to think maxBooleanClauses ought to be unlimited by default. "
        },
        {
            "author": "Jack Krupansky",
            "id": "comment-14196260",
            "date": "2014-11-04T15:48:47+0000",
            "content": "Yonik Seeley, I think you just stumbled upon the single most compelling reason for releasing and attracting people to Solr 5.0 - No more Max Boolean Clauses! "
        },
        {
            "author": "Jack Krupansky",
            "id": "comment-14196266",
            "date": "2014-11-04T15:51:01+0000",
            "content": "Robert Parker, yeah, this is the known behavior - the first core loaded sets this setting and any subsequent core loads ignore any new setting. So, yes, you need the bounce to change it. "
        },
        {
            "author": "Ramkumar Aiyengar",
            "id": "comment-14196963",
            "date": "2014-11-04T22:21:42+0000",
            "content": "Since it's been mentioned somewhere above in this issue that maxBooleanClauses mainly serves the purpose of not tripping users from creating bad queries, wanted to point out that we recently enountered a case where it was impossible to control this setting.\n\nComplexPhraseQuery rewrites queries like \"foo* bar*\" to BQs (because it needs visibility into the structure of the query), and there's no way to properly set maxClauses without actually knowing term distribution (to make things worse, per shard in a distributed setup, such a query could fail in some shards and succeed in others). "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-14197467",
            "date": "2014-11-05T04:23:04+0000",
            "content": "yeah, this is the known behavior - the first core loaded sets this setting and any subsequent core loads ignore any new setting. So, yes, you need the bounce to change it.\n\nThe way I read the code, it shouldn't behave in exactly that way.  For every core that gets loaded, it will read the maxBooleanClauses value out of the config and set the global limitation, overwriting any value set by any previously parsed configs.  If the setting is missing from the config during SolrCore initialization, Solr asks BooleanQuery what the current setting is and uses that.  This effectively means that the last initialized config (not the first) will set the value for all cores.  From what I've seen in the logs during Solr startup, the exact core load order may not be completely predictable.\n\nGetting rid of the limit entirely as Yonik did for Heliosearch seems like the best option to me.  There are a lot of people that legitimately need to create queries with a very large number of boolean clauses.  The users who ask for help with this are probably the tip of the iceberg.  I think that many users who exceed maxBooleanClauses are able to figure out on their own how to fix the problem.\n\nThe advice to use the terms qparser is reasonable, but I see that as a performance option ... Solr should honor any valid query syntax, even if the performance sucks. "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-14197627",
            "date": "2014-11-05T05:04:08+0000",
            "content": "Jack Krupansky, you were right and I was wrong.  I found the code that does exactly what you described ... and the same code also causes SOLR-6695. "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-14197692",
            "date": "2014-11-05T06:53:07+0000",
            "content": "Currently this limit is set in the SolrConfig constructor.  This will get executed multiple times on a multicore installation.  That's probably not a performance issue, but it aggravates my \"unclean code\" sense, so I was hoping to put it someplace that only gets executed once.  A likely candidate is the CoreContainer constructor, but I'm not sure whether it would be a good idea to introduce a dependency on a lucene class into solr code at that level. "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-14197887",
            "date": "2014-11-05T08:36:03+0000",
            "content": "I located the heliosearch commit that eliminated the clause limit.  The work I had started was fairly similar, so I kept my work but pulled the static code block and the additional test from HS.  Indirectly this will also fix SOLR-6695.\n\nI set the log message about the deprecated parameter at info ... should that be moved to warn? "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-14197896",
            "date": "2014-11-05T08:41:35+0000",
            "content": "If this looks acceptable, my plan is to commit to 5x, then merge to trunk and remove the config parsing and deprecation log message. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-14198367",
            "date": "2014-11-05T13:34:27+0000",
            "content": "Unfortunately this issue never got consensus as Robert reiterated his -1 "
        },
        {
            "author": "David Smiley",
            "id": "comment-14198371",
            "date": "2014-11-05T13:38:33+0000",
            "content": "Robert Muir now has a conflict-of-interest that he didn't have at the time he voted.\n\n+1 to commit to 5x. "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-14202048",
            "date": "2014-11-07T13:53:04+0000",
            "content": "The new test (org.apache.solr.search.TestSolrQueryParser.testManyClauses) fails with my patch.  At this moment I need to commute to work, I will look into the failure when I have a spare moment, which may not be until this evening. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-14202115",
            "date": "2014-11-07T15:01:18+0000",
            "content": "The new test (org.apache.solr.search.TestSolrQueryParser.testManyClauses) fails with my patch.\n\nI have this problem with Heliosearch too... it's intermittent (it fails maybe 25% of the time for me) and I believe it's only a test framework issue.  I've verified that there is no other place in the Solr code base that sets the value, and when I tried by hand with a real server, it always worked.\n\nIt may have something to do with this:\n\n./lucene/test-framework/src/java/org/apache/lucene/util/TestRuleSetupAndRestoreInstanceEnv.java:    BooleanQuery.setMaxClauseCount(savedBoolMaxClauseCount);\n\n "
        },
        {
            "author": "Michael McCandless",
            "id": "comment-14202665",
            "date": "2014-11-07T21:01:18+0000",
            "content": "Robert Muir now has a conflict-of-interest that he didn't have at the time he voted.\n\nPlease don't make such unhelpful blanket statements.\n\nIn fact, we all have on-paper conflicts of interest here, different\nmotivations for favoring one change over another, etc., but then we\ntrust one another to wear the right hat at the right time and to do\nwhat we feel is best for the project.  Each of us argues our point of\nview on issues such as this based on technical merit/tradeoffs of the\ndifferent approaches. "
        },
        {
            "author": "David Smiley",
            "id": "comment-14202693",
            "date": "2014-11-07T21:14:37+0000",
            "content": "Michael McCandless My point is merely that it would be quite inappropriate for employees of competing search platforms to vote on Solr matters, even if we assume the best technical intentions/motivations of everyone.  Surely we can agree on this point.  I don't believe there is anything but best intentions to everyone who has commented here (including Rob), and my statements haven't implied otherwise, at least I don't think they have.  I'm sorry if it came off differently than I intended. "
        },
        {
            "author": "Mike Murphy",
            "id": "comment-14293532",
            "date": "2015-01-27T13:46:40+0000",
            "content": "My point is merely that it would be quite inappropriate for employees of competing search platforms to vote on Solr matters, even if we assume the best technical intentions/motivations of everyone. Surely we can agree on this point. \n\n+1\nThe presence of a conflict of interest is independent of the occurrence of impropriety.\nhttp://en.wikipedia.org/wiki/Conflict_of_interest "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-14293615",
            "date": "2015-01-27T14:37:50+0000",
            "content": "I believe that Rob's recent job change does present a conflict of interest when it comes to Solr, although he's a really intelligent person and when he's got a strong technical argument, I'm inclined to listen.  His concerns on LUCENE-4835 stand, although I think the issue notes do leave room for further discussion on an increase in the default value, just not to Integer.MAX_VALUE, and I've brought it up there.\n\nAs the head of this project in Jira, my thinking is that Yonik Seeley is the deciding vote.  Given that he's already removed the limit in heliosearch, I think I know where that vote would land.\n\nI stand ready for the following changes, if/when we can reach consensus:\n\n\n\tIn Solr 5.1, default maxBooleanClauses to MAX_VALUE and ignore the config value.\n\tIn Solr 6.0, throw an error if maxBooleanClauses is found in solrconfig.xml. (not strongly tied to this one)\n\n\n\nIf that test still shows intermittent failures, I don't know if I can fix the problem, but I can definitely try.\n\nIf we don't remove the limit, the error message in Solr when the count is exceeded should probably say \"consider using the terms query parser instead.\"  I'm inclined to have it point at the wiki or reference guide also. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-14293616",
            "date": "2015-01-27T14:41:55+0000",
            "content": "My technical veto still stands as a member of the PMC.\nIt does not matter who i work for.\n\nA million people can say +1 its a conflict, that doesnt matter. Developing at apache is a conflict of interest by definition.\n\nhttp://www.apache.org/foundation/voting.html "
        },
        {
            "author": "Mike Murphy",
            "id": "comment-14293652",
            "date": "2015-01-27T15:05:05+0000",
            "content": "But Robert ignored a veto from Hoss Man and refused a call to revert based on conflict of interest.\nHe said \"I'm not going to revert it. You just want to make Lucene harder to use, so more people will use apache solr instead.\"\n\nhttps://issues.apache.org/jira/browse/LUCENE-5859?focusedCommentId=14080242&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14080242 "
        },
        {
            "author": "David Smiley",
            "id": "comment-14293855",
            "date": "2015-01-27T17:38:28+0000",
            "content": "Instead of eliminating the limit on the Solr side, which Rob insists on wielding is veto power to block, I propose here a low value \u2013 a value low enough that is very likely to be hit in testing/development before production if BooleanQuery is being abused for cases where the TermsFilter (via terms QParser) should be used.  We can further add comments in solrconfig.xml that the app is advised to use the \"terms\" qparser which is designed for large number of terms \u2013 BooleanQuery just plain isn't.  I suggest 64 be the new low limit.  The app/user can decide if end-users shouldn't query with more than 64 terms and raise that number to what they feel is right.  But machine-generated queries shouldn't use BooleanQuery for such use-cases. "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-14298703",
            "date": "2015-01-30T14:46:09+0000",
            "content": "Instead of eliminating the limit on the Solr side, which Rob insists on wielding is veto power to block, I propose here a low value\n\nI like this idea, despite the pain I know it will cause.  Most people who have existing configs based on the example will already have a config that sets the value to 1024, so the pain will be mostly felt by new users ... but it will be felt early enough that they will probably have it fixed before they deploy to production.\n\nMy technical veto still stands as a member of the PMC.  It does not matter who i work for.\n\nI'm aware of the rights that Apache gives you, but just because you have the power doesn't mean you must use it.\n\n\n\nIf eliminating the limit isn't going to happen, then I have the following proposal, in addition to lowering the default to 64.  I think I built this idea into some of the patch work I did for this issue, but I can no longer remember for sure:  I propose that we include code so that the highest maxBooleanClauses value seen during core loading become the global value, preventing a lower value seen later during the load process from overriding it. "
        },
        {
            "author": "David Smiley",
            "id": "comment-14298708",
            "date": "2015-01-30T14:55:59+0000",
            "content": "If eliminating the limit isn't going to happen, then I have the following proposal, in addition to lowering the default to 64. I think I built this idea into some of the patch work I did for this issue, but I can no longer remember for sure: I propose that we include code so that the highest maxBooleanClauses value seen during core loading become the global value, preventing a lower value seen later during the load process from overriding it.\n\n+1 !\n\nAnd the low value is I think a reasonable value.  If you hit this, it is likely you should be using {!terms}; and the docs near the config value should say this. If a user query hits this... well 64 is plenty for what most apps might reasonable expect of a user (but not all apps, I realize).\n\nIt would be neat to modify the query parser to automatically introduce Terms filter in place of a BooleanQuery that is getting too big, so long as the clauses are all OR clauses.  That would be a separate issue though. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-14298731",
            "date": "2015-01-30T15:08:57+0000",
            "content": "Technical vetoes don't just stand like a guardian in the road forever. Once someone has withdrawn from helping address the issue or working with a group of people still working down the issue, if they insist on holding a veto, it starts to move to capricious. We can deal with it at the PMC or board level if we have to, but it's not how veto power works.  "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-14307050",
            "date": "2015-02-05T10:56:22+0000",
            "content": "\nIf eliminating the limit isn't going to happen, then I have the following proposal, in addition to lowering the default to 64. I think I built this idea into some of the patch work I did for this issue, but I can no longer remember for sure: I propose that we include code so that the highest maxBooleanClauses value seen during core loading become the global value, preventing a lower value seen later during the load process from overriding it.\n+1 !\n+1 - Just had a customer tripped by this due to multi core where one core did not have the tag at all.\nThis proposal would fix users' issues, not introduce any new configs, and keep the option open for a future per-core setting! "
        },
        {
            "author": "Robert Muir",
            "id": "comment-14307161",
            "date": "2015-02-05T12:48:13+0000",
            "content": "\nI'm aware of the rights that Apache gives you, but just because you have the power doesn't mean you must use it.\n\nAnd you guys should not have proposed discrimination against elasticsearch employees on this issue.\n\nThis will never be forgiven. "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-15405920",
            "date": "2016-08-03T13:35:18+0000",
            "content": "I'd still like to make some improvements in this area for Solr, even if I can't completely eliminate the limit.  I hope that certain parties will recognize a potential conflict of interest and stay out of it.\n\nI'll cook up a new patch. "
        },
        {
            "author": "Yago Riveiro",
            "id": "comment-15406072",
            "date": "2016-08-03T15:34:01+0000",
            "content": "This parameter should be unlimited by default, if the user wants a limit, it's user responsibility to set a limit.\n\nI hit this limit several times, and it's illogical since If I have resources to do a 10K boolean clause, why Can't I do it without tweak some weird param?\n\n+1 "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-15687572",
            "date": "2016-11-22T19:00:38+0000",
            "content": "One step in the right direction... SOLR-9786 now produces TermsQueries (and hence avoids the maxBooleanClauses limit) from strings or numerics when called from a filter context.\nSo something like fq=foo_s:(term1 term2 term3 ... term2000) should now work.\nI added a modified test from this JIRA (TestSolrQueryParser.testManyClauses) that changed the \"q\" to an \"fq\". "
        },
        {
            "author": "Varun Thacker",
            "id": "comment-15688174",
            "date": "2016-11-22T22:46:50+0000",
            "content": "Hi Yonik,\n\nCorrect me if I am wrong , but you meant to reference SOLR-9786 in your comment instead of SOLR-4586 right? "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-15688197",
            "date": "2016-11-22T22:54:06+0000",
            "content": "Heh... yep.  I'll edit/fix. "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-16050212",
            "date": "2017-06-15T09:17:31+0000",
            "content": "Hi there, perhaps a candidate for 7.0.0?\n\n+1 to remove this completely from all solrconfigs and set default to MAX_INT\nIf we MUST have it configurable somewhere, it belongs in solr.xml or clusterprop. "
        },
        {
            "author": "David Smiley",
            "id": "comment-16050407",
            "date": "2017-06-15T12:35:57+0000",
            "content": "remove this completely from all solrconfigs and set default to MAX_INT\nIf we MUST have it configurable somewhere, it belongs in solr.xml or clusterprop.\n\n+1 definitely.  We still have a limit to those that want it.  I appreciate both arguments.  The current situation is a bit awkward though \u2013 we should either default to fairly low, or to effectively unlimited. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-16052121",
            "date": "2017-06-16T16:44:14+0000",
            "content": "+1 to moving it to solr.xml and/or clusterprop (although stand-alone .vs. SolrCloud makes clusterprop tricky).\n\nJust thinking about this in terms of some of the autoscaling and we really must fix this for that effort. If we start moving replicas around we have the problem of a particular JVM being configured so all the solrconfigs have bumped this limit, then moving a replica from some other collection to that JVM with a lower limit and it suddenly starts failing....\n "
        },
        {
            "author": "Andrzej Bialecki",
            "id": "comment-16052352",
            "date": "2017-06-16T20:35:10+0000",
            "content": ".bq ...although stand-alone .vs. SolrCloud makes clusterprop tricky...\n+1 to a solr.xml setting. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-16052377",
            "date": "2017-06-16T20:51:40+0000",
            "content": "+1 to remove this completely from all solrconfigs and set default to MAX_INT\n\n+1, that's the easiest solution, and the least likely to trip anything up.\nIf we need something that throws an exception at some points, then it should be re-implemented as something that isn't a static. "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-16052414",
            "date": "2017-06-16T21:30:36+0000",
            "content": "Cool. Keep it simple. Get rid of the thing in 7.0 (that would warrant a blog post about this 4-year long saga) and fill the void later if needed!\nPS: I don't intend to write the patch, just wanted to ping "
        },
        {
            "author": "Robert Muir",
            "id": "comment-16052428",
            "date": "2017-06-16T21:53:43+0000",
            "content": "Sorry, I'm still -1 to that MAX_INT default. That hasn't changed.\n\n "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-16052496",
            "date": "2017-06-16T23:09:24+0000",
            "content": "I opened LUCENE-7880 to try and at least remove the static-ness of this unfortunate setting. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-16052529",
            "date": "2017-06-16T23:43:02+0000",
            "content": "Making it per-core would go a long way to making it easier to support clients. Having a default limit isn't the problem, it's perfectly supportable to tell a client \"This a built in safety valve to prevent runaway queries that you can change at need, we just want it be a conscious decision on your part\".\n\nWhat's not so supportable (or explainable for that matter) is that the last core loaded wins, and I can't tell them which one would win. Or even that the same one will win all the time. We have multiple threads loading cores in Solr, so the order of execution of a node with a bunch of cores isn't determinant.\n\nOr worse, it works on one node but not another because cores using a different config file happened to be loaded last on the machines. Or, much worse, \"Search just stopped working with too many boolean clauses exceptions\".\n\nIf we have any limit, I'd prefer it to be left in the solrconfig files we  distribute. Clients can find it themselves that way.\n "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-16052994",
            "date": "2017-06-17T20:48:41+0000",
            "content": "OK one more try: We can get the effect of LUCENE-7880 (elimination of the static nature of this setting), if we set the static to MAX_INT and do the max_clause checking ourselves (this can still default to 1024 in the solrconfig.xml for the core).\n\nThis would mean that going over 1024 clauses would still throw an exception by default (that would be unchanged), but max_clauses would truly become a per-core setting, or even a per-handler setting in the future if someone wants to implement that.\n\nSince this fixes the \"last-core-wins\" staticness bug, while otherwise preserving existing behavior, I assume no one would be against this? "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-16053019",
            "date": "2017-06-17T22:37:11+0000",
            "content": "bq: Since this fixes the \"last-core-wins\" staticness bug, while otherwise preserving existing behavior, I assume no one would be against this?\n\nWorks for me. "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-16055341",
            "date": "2017-06-20T08:23:24+0000",
            "content": "Pri 1 is to resolve the \"last-core-wins\" bug, whether it happens through LUCENE-7880 or some other means. Not entirely sure what this statement means though:\nif we set the static to MAX_INT and do the max_clause checking ourselves\nWhere exactly would we add that new max_clause check? In the query parsers? "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-16055769",
            "date": "2017-06-20T13:44:10+0000",
            "content": "Where exactly would we add that new max_clause check? In the query parsers?\n\nYep. Solr QParsers have access to the request object which has access to schema/core/config.\nThrowing our own exceptions means that the message can be more targeted as well... we can point them directly to the maxBooleanClauses entry in solrconfig.xml\n\nI've opened SOLR-10921 for this since this issue is about removing the limit altogether. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-16055882",
            "date": "2017-06-20T14:54:39+0000",
            "content": "Jan H\u00f8ydahl \n\"last core wins\" is my shorthand for the fact that this is static in Lucene. So when a core loads and it encounters a <maxBooleanClauses> entry it sets this static. \n\nSo let's say core1 has a value of 64 and core2 has a value of 100,000.\nIf core2 loads last both core1 and core2 have a limit of 100,000. \nIf core1 loads last both core1 and core2 have a limit of 64.\n\nAnd since you can load cores in parallel it's not even determinate which one will always load last.\n\nThis is especially problematic in SolrCloud when you have heterogeneous collections sharing JVMs and users are left wondering why they got this exception after bumping the limit up. Not to mention adding a replica to some core someplace may suddenly cause the replicas on that JVM to fail. Imagine my limit is 100,000 for collection1 and all the replicas on a particular JVM are from collection1. Now I create a new collection with a different config set. BOOM. "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-16056217",
            "date": "2017-06-20T18:16:34+0000",
            "content": "Erick Erickson yes I know the bug, experienced it myself. What I meant to say is that we should fix that, either by making it a truly per-core setting or by moving the (still global) config up to solr.xml. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-16056255",
            "date": "2017-06-20T18:35:20+0000",
            "content": "Jan:\n\nGot it. I think moving it to solr.xml is sub-optimal, but much better than what we do now. Putting it in solr.xml conveys that it's an instance-wide setting much better than putting it in solrconfig.xml. \n\nAnd functionally this is no different than what we do currently in the sense that to be useful all the solrconfig files for all the cores in the JVM need to have the same setting. Which means you can't have one core respect one limit and another core respect another limit.\n\nWhich would be just what putting it in solr.xml would do too. The solr.xml option makes it a lot less trappy. "
        }
    ]
}