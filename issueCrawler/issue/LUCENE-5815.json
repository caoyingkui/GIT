{
    "id": "LUCENE-5815",
    "title": "Add TermAutomatonQuery, for proximity matching that generalizes MultiPhraseQuery/SpanNearQuery",
    "details": {
        "type": "New Feature",
        "priority": "Major",
        "labels": "",
        "resolution": "Fixed",
        "components": [],
        "affect_versions": "None",
        "status": "Resolved",
        "fix_versions": [
            "4.10",
            "6.0"
        ]
    },
    "description": "I created a new query, called TermAutomatonQuery, that's a proximity\nquery to generalize MultiPhraseQuery/SpanNearQuery: it lets you\nconstruct an arbitrary automaton whose transitions are whole terms, and\nthen find all documents that the automaton matches.  This is different\nfrom a \"normal\" automaton whose transitions are usually\nbytes/characters within a term/s.\n\nSo, if the automaton has just 1 transition, it's just an expensive\nTermQuery.  If you have two transitions in sequence, it's a phrase\nquery of two terms.  You can express synonyms by using transitions\nthat overlap one another but the automaton doesn't have to be a\n\"sausage\" (as MultiPhraseQuery requires) i.e. it \"respects\" posLength\n(at query time).\n\nIt also allows \"any\" transitions, to match any term, so you can do\nsloppy matching and span-like queries, e.g. find \"lucene\" and \"python\"\nwith up to 3 other terms in between.\n\nI also added a class to convert a TokenStream directly to the\nautomaton for this query, preserving posLength.  (Of course, the index\ncan't store posLength, so the matching won't be fully correct if any\nindexed tokens has posLength != 1).  But if you do query-time-only\nsynonyms then the matching should finally be correct.\n\nI haven't tested performance but I suspect it's quite slowish ... its\ncost is O(sum-totalTF) of all terms \"used\" in the automaton.  There\nare some optimizations we could do, e.g. detecting that some terms in\nthe automaton can be upgraded to MUST (right now they are all\neffectively SHOULD).\n\nI'm not sure how it should assign scores (punted on that for now), but\nthe matching seems to be working.",
    "attachments": {
        "LUCENE-5815.patch": "https://issues.apache.org/jira/secure/attachment/12655197/LUCENE-5815.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "id": "comment-14058662",
            "author": "Michael McCandless",
            "content": "Patch, work in progress, lots of nocommits... ",
            "date": "2014-07-11T11:30:26+0000"
        },
        {
            "id": "comment-14058730",
            "author": "Robert Muir",
            "content": "\n (Of course, the index\ncan't store posLength, so the matching won't be fully correct if any\nindexed tokens has posLength != 1).\n\nWhy not? Cant we just have a tokenfilter that encodes positionLengthAttribute as a vInt payload (will always be one byte, unless you are crazy)? The custom scorer here could optionally support it.\n\nPersonally: not sure its worth it. I think its better to fix QP to parse correctly in common cases like word-delimiter etc (first: those tokenfilters must be fixed!).\n\nAnd I'm a little confused if this approach is faster than rewrite() to booleans of phrase queries? ",
            "date": "2014-07-11T12:53:23+0000"
        },
        {
            "id": "comment-14058749",
            "author": "Michael McCandless",
            "content": "Cant we just have a tokenfilter that encodes positionLengthAttribute as a vInt payload (will always be one byte, unless you are crazy)? The custom scorer here could optionally support it.\n\nYes, I think that would work!  And would be pretty simple to build... and the changes to this scorer would be simple: right now it just hardwires that a given token goes from pos to pos+1, but with this vInt in the payload it would decode that and use it instead of +1.\n\nI think its better to fix QP to parse correctly in common cases like word-delimiter etc (first: those tokenfilters must be fixed!).\n\nRight, QP needs to use posLength to build the correct queries... this new query just makes it \"easy\" since any arbitrary graph TokenStream can be directly translated into the equivalent query.\n\nAnd I'm a little confused if this approach is faster than rewrite() to booleans of phrase queries?\n\nWe can only rewrite to BQ of PQ if the automaton doesn't use the ANY token transition, and if it's finite, right?  Or maybe we could somehow take ANY and map it to slop on the phrase queries?\n\nBut in those restricted cases, it's probably faster, I guess depending on what the automaton looks like.  Ie, you could make a biggish automaton that rewrites to many many phrase queries.  I'll add a TODO to maybe do this rewriting for this query ... ",
            "date": "2014-07-11T13:19:20+0000"
        },
        {
            "id": "comment-14058754",
            "author": "Robert Muir",
            "content": "\nWe can only rewrite to BQ of PQ if the automaton doesn't use the ANY token transition, and if it's finite, right? Or maybe we could somehow take ANY and map it to slop on the phrase queries?\n\nHmm, ok i see what you are getting at.\n\nI guess I was immediately only considering the case where the automaton is actually coming from query analysis chain: it would always be finite and so on in this case... right? ",
            "date": "2014-07-11T13:25:09+0000"
        },
        {
            "id": "comment-14058755",
            "author": "Michael McCandless",
            "content": "I guess I was immediately only considering the case where the automaton is actually coming from query analysis chain: it would always be finite and so on in this case... right?\n\nAhh, yes it would!  We could always use BQ(PQ) in that case, and \"typically\" the Automaton would be smallish, unless app makes crazy synonyms, etc.? ",
            "date": "2014-07-11T13:26:49+0000"
        },
        {
            "id": "comment-14060665",
            "author": "Michael McCandless",
            "content": "New patch, I think it's ready.  I stopped using RollingBuffer: it was\noverkill.  For scoring I just did what PhraseQuery does; this is\nclearly not \"right\" since an app could make an automaton that matches\nwildly different \"phrases\", but I think it's OK for starters.\n\nI added a testRandom, it does [simulated] index-time synonyms, applies\nfilters (so we test .advance), even tests ANY transitions, etc.\n\nI think performance will be not-so-great: this query does a\ndisjunction for all terms when often you could make some or all of the\nterms MUST'd.  We can easily detect simple cases (startswith /\nendswith a fixed phrase) so we could start with that ... but I think\nwe pursue that later.\n\nAlso I didn't explore putting posLength into the index (in a payload)\nand then using it at search time, but that should be pretty easy\nfuture improvement too. ",
            "date": "2014-07-14T14:10:51+0000"
        },
        {
            "id": "comment-14067892",
            "author": "ASF subversion and git services",
            "content": "Commit 1612076 from Michael McCandless in branch 'dev/trunk'\n[ https://svn.apache.org/r1612076 ]\n\nLUCENE-5815: add TermAutomatonQuery ",
            "date": "2014-07-20T11:36:15+0000"
        },
        {
            "id": "comment-14067893",
            "author": "ASF subversion and git services",
            "content": "Commit 1612077 from Michael McCandless in branch 'dev/branches/branch_4x'\n[ https://svn.apache.org/r1612077 ]\n\nLUCENE-5815: add TermAutomatonQuery ",
            "date": "2014-07-20T11:42:59+0000"
        }
    ]
}