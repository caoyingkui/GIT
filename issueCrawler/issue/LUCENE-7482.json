{
    "id": "LUCENE-7482",
    "title": "Faster sorted index search for reverse order search",
    "details": {
        "resolution": "Unresolved",
        "affect_versions": "None",
        "components": [],
        "labels": "",
        "fix_versions": [],
        "priority": "Minor",
        "status": "Reopened",
        "type": "New Feature"
    },
    "description": "We are currently using Lucene here in my company for our main product.\nOur search functionnality is quite basic and the results are always sorted given a predefined field. The user is only able to choose the sort order (Asc/Desc).\n\nI am currently investigating using the index sort feature with EarlyTerminationSortingCollector. \nThis is quite a shame searching on a sorted index in reverse order do not have any optimization and was wondering if it would be possible to make it faster by creating a special \"ReverseSortingCollector\" for this purpose.\n\nI am aware the posting list is designed to be always iterated in the same order, so it is not about early-terminating the search but more about filtering-out unneeded documents more efficiently.\n\nIf a segment is sorted in reverse order, we just have to delegate collection of the last matched documents.\n\nHere is a sample quick code:\n\nReverseSortingCollector.java\npublic class ReverseSortingCollector extends FilterCollector {\n\n\t/** Sort used to sort the search results */\n\tprotected final Sort sort;\n\t/** Number of documents to collect in each segment */\n\tprotected final int numDocsToCollect;\n  \n[...]\n\n    private List<FlushData> flushList = new ArrayList<>();\n\n\n    private static final class FlushData {\n        // ring buffer\n\tint[] buffer;\n        \n\t// index of the first element in the buffer\n\tint index;\n\t\t\n        LeafCollector leafCollector;\n\n        FlushData(int[] buffer, LeafCollector leafCollector) {\n            super();\n            this.buffer = buffer;\n            this.leafCollector = leafCollector;\n        }\n    }\n\n    @Override\n    public LeafCollector getLeafCollector(LeafReaderContext context) throws IOException {\n        \n\t//flush previous data if any\n\tflush();\n\t\t\n\tLeafReader reader = context.reader();\n        Sort segmentSort = reader.getIndexSort();\n        if (isReverseOrder(sort, segmentSort)) {//segment is sorted in reverse order than the search sort\n            int[] buffer = new int[numDocsToCollect];\n            Arrays.fill(buffer, -1);\n            FlushData flushData = new FlushData(buffer, in.getLeafCollector(context));\n            flushList.add(flushData);\n            return new LeafCollector() {\n                @Override\n                public void setScorer(Scorer scorer) throws IOException {\n                }\n                \n                @Override\n                public void collect(int doc) throws IOException {\n\t\t\t\t    //we remember the last `numDocsToCollect` documents that matched\n                    buffer[flushData.index % buffer.length] = doc;\n                    flushData.index++;\n                }\n            };\n        } else {\n        \t    return in.getLeafCollector(context);\n \t}\n    }\n\n\t//flush the last `numDocsToCollect` collected documents do the delegated Collector\n    public void flush() throws IOException {\n        for (FlushData flushData : flushList) {\n            for (int i = 0; i < flushData.buffer.length; i++) {\n                int doc = flushData.buffer[(flushData.index + i) % flushData.buffer.length];\n                if (doc != -1) {\n                    flushData.leafCollector.collect(doc);\n                }\n            }\n        }\n        flushList.clear();\n    }\n\t\n}\n\n\n\nThis is specially efficient when used along with TopFieldCollector as a lot of docValue lookup would not take place. \nIn my experiment it reduced search time up to 90%.\n\nNote 1: Does not support paging.\nNote 2: Current implementation probably not thread safe",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "id": "comment-15553946",
            "author": "Martin Amirault",
            "date": "2016-10-07T03:03:20+0000",
            "content": "Sorry, just realized that actually my implementation assumed that all documents match, which most of the time is not the case. "
        },
        {
            "id": "comment-15554014",
            "author": "Martin Amirault",
            "date": "2016-10-07T03:47:02+0000",
            "content": "A more correct implementation: keep the last 'numDocsToCollect' docIds collected for each LeafCollector and flush them to delegated LeafCollectors once the search is finished. Will experiment a bit more (With less than 100% match this time!) and post a new proposal. "
        },
        {
            "id": "comment-15554549",
            "author": "Adrien Grand",
            "date": "2016-10-07T08:43:18+0000",
            "content": "This is an interesting idea! Index time sorting was just made a core feature in 6.2, but there are still plenty of things to do in order to leverage it at search time. For now, IndexSearcher does not leverage it at all. "
        },
        {
            "id": "comment-15554763",
            "author": "Michael McCandless",
            "date": "2016-10-07T10:35:41+0000",
            "content": "but there are still plenty of things to do in order to leverage it at search time.\n\n+1\n\nI think there are some powerful things IndexSearcher could now do if it notices the incoming query sort is \"congruent\" with the index sort (or, exactly opposite, i.e. this issue).  Possibly a TermQuery on a field that the index was sorted by could efficiently jump to the slice of docIDs that matched that term (though this would require that the field was identically indexed into postings and doc values, which Lucene cannot know today). "
        }
    ]
}