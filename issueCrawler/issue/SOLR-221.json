{
    "id": "SOLR-221",
    "title": "faceting memory and performance improvement",
    "details": {
        "affect_versions": "None",
        "status": "Closed",
        "fix_versions": [
            "1.2"
        ],
        "components": [],
        "type": "Improvement",
        "priority": "Major",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "1) compare minimum count currently needed to the term df and avoid unnecessary intersection count\n2) set a minimum term df in order to use the filterCache, otherwise iterate over TermDocs",
    "attachments": {
        "facet.patch": "https://issues.apache.org/jira/secure/attachment/12356473/facet.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Yonik Seeley",
            "id": "comment-12492543",
            "date": "2007-04-29T05:00:17+0000",
            "content": "The results are slightly surprising.\n\nI made up an index, and each document contained 4 random numbers between 1 and 500,000\nThis is not the distribution one would expect to see in a real index. but we can still learn much.\n\nThe synthetic index:\n maxDoc=500,000\n numDocs=393,566\n number of segments = 5\n number of unique facet terms = 490903\n filterCache max size = 1,000,000 entries (more than enough)\n JVM=1.5.0_09 -server -Xmx200M\n System=WinXP, 3GHz P4, hyperthreaded, 1GB dual channel RAM\n facet type = facet.field, facet.sort=true, facet.limit=10\n maximum df of any term = 15\n warming times were not included... queries were run many times and the lowest time recorded.\n\nNumber of documents that match test \"base\" queries (for example, base query #1 matches 175K docs):\n1) 175000,  \n2) 43000\n3) 8682\n4) 2179\n5) 422\n6) 1\n\nWITHOUT PATCH (milliseconds to facet each base query):\n1578, 1578, 1547, 1485, 1484,1422\n\nWITH PATCH (min df comparison w/ term df,  minDfFilterCache=0) (all field cache)\n 984,  1203, 1391, 1437, 1484, 1420\n\nWITH PATCH (min df comp, minDfFilterCache=30)  (no fieldCache at all)\n1406, 2344, 3125, 3015, 3172, 3172\n\nCONCLUSION1: min df comparison increases faceting speed 60% when the base query matches many documents.  With a real term distribution, this could be even greater.\n\nCONCLUSION2: opting to not use the fieldCache for smaller df terms can save a lot of memory, but it hurts performance up to 200% for our non-optimized index.\n\nCONCLUSION3: using the field cache less can significantly speed up warming time (times not shown, but a full warming of the fieldCache took 33 sec)\n\n======== now the same index, but optimized ===========\nWITH PATCH (optimized, min df comparison w/ term df,  minDfFilterCache=0) (all field cache)\n 172,  312,  485,  578,  610,  656\n\nWITH PATCH (optimized, min df comp, minDfFilterCache=30)  (no fieldCache at all)\n 265,  344,  422,  468,  500,  484  \n\nCONCLUSION3: An optimized index increased performance 200-500%\n\nCONCLUSION4:  The fact that an all-fieldcache option was significantly faster on an optimized probably cannot totally be explained by accurate dfs (no deleted documents to inflate the term df values), means that just iterating over the terms is much faster in an optimized index (a potential Lucene area to look into) "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12492579",
            "date": "2007-04-29T16:00:35+0000",
            "content": "Perhaps minDfFilterCache could be automatically tuned depending on if the index is optimized or not...\nCould allow specification of both in solrconfig.xml perhaps...\n\n<faceting>\n  <minDfFilterCache>0</minDfFilterCache>  <!-- always use filterCache in non-optimized index -->\n  <minDfFilterCache index=\"optimized\">50</minDfFilterCache>  <!-- if optimized, only use filterCache when df>=50 -->\n</faceting> "
        },
        {
            "author": "Hoss Man",
            "id": "comment-12495204",
            "date": "2007-05-11T23:33:10+0000",
            "content": "it might be worth trying to clarify if the performance cliff really results from being optimized or if it's just a result of one of the two traits of an optimized index: being a single segment, having no deletions.\n\ntuning the behavior based on either of those traits is just as easy as tuning based on both traits.\n\n\nMinor point: if we're going to add facet config options, i'd prefer they stay as standard standard SolrParms that can be defaulted i the handler config (and theoretically overridden per request)  it just seems cleaner to have all options in one place, and there's not a lot of reason not to when dealing with options tha don't *need8 to be identicle for every request. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12495222",
            "date": "2007-05-12T02:15:34+0000",
            "content": "> it might be worth trying to clarify if the performance cliff really results from being optimized or if it's just a result of one of the two traits of an optimized index: being a single segment, having no deletions. \n\nThe large performance differences even when TermDocs weren't used (all fieldcache) strongly suggests that it's a SegmentReader vs MultiReader issue more than deleted docs, since I doubt the larger maxDoc would account for much time.   It would be nice to know for sure though.\n\n> Minor point: if we're going to add facet config options, i'd prefer they stay as standard standard SolrParms\n\nI think we may need to look at it on a per-option basis (but I agree, these look like a candidate).  Once 1.2 gets out the door, I'll probably get back to my facet cache work, and that will have some parameters that don't make sense to be able to tune per-request (or wouldn't even be possible). "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12495844",
            "date": "2007-05-15T02:59:17+0000",
            "content": "So for configuration, how about a SolrParam of\nfacet.minDfFilterCache  (can anyone think of a better name?), probably per-field.\nWe can defer more complex configuration in order to fit this into Solr 1.2, as long as we don't think this single parameter is a mistake. "
        },
        {
            "author": "J.J. Larrea",
            "id": "comment-12496046",
            "date": "2007-05-15T16:32:35+0000",
            "content": "Clearly Solr is going to end up with more than 2 algorithms for computing facets, and there's no reason to think they won't be able to happily coexist in SimpleFacets.  And we will surely need additional control parameters even for the 2.5 (with your patch) algorithms now in place.  So I think we should establish a convention for separating algorithm-specific parameters so we don't end up with a jumble of top-level parameters.\n\nSo rather than facet.minDfFilterCache, how about:\n    facet.enum.cache.minDF (enable term enum cache for terms with docFreq > minDF)\n    f.<field>.facet.enum.cache.minDF\n\nMight it not be useful to turn off term enum caching when the number of terms was above a certain maximum, even if the minDF criterion is met, to trade cycles for memory when neither the field cache nor filter cache is practicable?  In that case, it could be:\n    facet.enum.cache.maxTerm  (enable term enum cache for fields where numTerms <= maxTerm) "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12496374",
            "date": "2007-05-16T19:04:56+0000",
            "content": "Yeah, facet.enum.cache.minDf seems reasonable (if a bit long).\n\n> Might it not be useful to turn off term enum caching when the number of terms was above a certain maximum  [...]  trade cycles for memory\n\nIf one expects a really high number of terms, I think the right approach is to pick a minDf to cut down the cache size (and trade cycles for memory).  Also, Solr doesn't currently know the number of terms in a field unless it's traversed all of them. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12496404",
            "date": "2007-05-16T20:53:59+0000",
            "content": "Changed config to a SolrParam facet.enum.cache.minDf\nand added some tests. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12496409",
            "date": "2007-05-16T21:17:38+0000",
            "content": "TODO: after committed, document warming tips due to change #1 \"compare minimum count currently needed to the term df and avoid unnecessary intersection count\" "
        },
        {
            "author": "Hoss Man",
            "id": "comment-12589326",
            "date": "2008-04-15T23:44:45+0000",
            "content": "This bug was modified as part of a bulk update using the criteria...\n\n\n\tMarked (\"Resolved\" or \"Closed\") and \"Fixed\"\n\tHad no \"Fix Version\" versions\n\tWas listed in the CHANGES.txt for 1.2\n\n\n\nThe Fix Version for all 39 issues found was set to 1.2, email notification\nwas suppressed to prevent excessive email.\n\nFor a list of all the issues modified, search jira comments for this\n(hopefully) unique string: 20080415hossman2 "
        }
    ]
}