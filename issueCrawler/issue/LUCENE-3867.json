{
    "id": "LUCENE-3867",
    "title": "RamUsageEstimator.NUM_BYTES_ARRAY_HEADER and other constants are incorrect",
    "details": {
        "labels": "",
        "priority": "Trivial",
        "components": [
            "core/index"
        ],
        "type": "Bug",
        "fix_versions": [
            "3.6",
            "4.0-ALPHA"
        ],
        "affect_versions": "None",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "RamUsageEstimator.NUM_BYTES_ARRAY_HEADER is computed like that: NUM_BYTES_OBJECT_HEADER + NUM_BYTES_INT + NUM_BYTES_OBJECT_REF. The NUM_BYTES_OBJECT_REF part should not be included, at least not according to this page: http://www.javamex.com/tutorials/memory/array_memory_usage.shtml\n\n\nA single-dimension array is a single object. As expected, the array has the usual object header. However, this object head is 12 bytes to accommodate a four-byte array length. Then comes the actual array data which, as you might expect, consists of the number of elements multiplied by the number of bytes required for one element, depending on its type. The memory usage for one element is 4 bytes for an object reference ...\n\nWhile on it, I wrote a sizeOf(String) impl, and I wonder how do people feel about including such helper methods in RUE, as static, stateless, methods? It's not perfect, there's some room for improvement I'm sure, here it is:\n\n\n\t/**\n\t * Computes the approximate size of a String object. Note that if this object\n\t * is also referenced by another object, you should add\n\t * {@link RamUsageEstimator#NUM_BYTES_OBJECT_REF} to the result of this\n\t * method.\n\t */\n\tpublic static int sizeOf(String str) {\n\t\treturn 2 * str.length() + 6 // chars + additional safeness for arrays alignment\n\t\t\t\t+ 3 * RamUsageEstimator.NUM_BYTES_INT // String maintains 3 integers\n\t\t\t\t+ RamUsageEstimator.NUM_BYTES_ARRAY_HEADER // char[] array\n\t\t\t\t+ RamUsageEstimator.NUM_BYTES_OBJECT_HEADER; // String object\n\t}\n\n\n\nIf people are not against it, I'd like to also add sizeOf(int[] / byte[] / long[] / double[] ... and String[]).",
    "attachments": {
        "LUCENE-3867-compressedOops.patch": "https://issues.apache.org/jira/secure/attachment/12518315/LUCENE-3867-compressedOops.patch",
        "LUCENE-3867-3.x.patch": "https://issues.apache.org/jira/secure/attachment/12518837/LUCENE-3867-3.x.patch",
        "LUCENE-3867.patch": "https://issues.apache.org/jira/secure/attachment/12518317/LUCENE-3867.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2012-03-14T07:42:03+0000",
            "content": "One can provide exact object allocation size (including alignments) by running with an agent (acquired from Instrumentation). This is shown here, for example:\n\nhttp://www.javaspecialists.eu/archive/Issue142.html\n\nI don't think it makes sense to be \"perfect\" here because there is a tradeoff between being accurate and being fast. One thing to possibly improve would be to handle reference size (4 vs. 8 bytes; in particular with compact references while running under 64 bit jvms). ",
            "author": "Dawid Weiss",
            "id": "comment-13229061"
        },
        {
            "date": "2012-03-14T07:43:33+0000",
            "content": "Oh, one thing that I had in the back of my mind was to run a side-by-side comparison of Lucene's memory estimator and \"exact\" memory occupation via agent and see what the real difference is (on various vms and with compact vs. non-compact refs).\n\nThis would be a 2 hour effort I guess, fun, but I don't have the time for it. ",
            "author": "Dawid Weiss",
            "id": "comment-13229062"
        },
        {
            "date": "2012-03-14T08:02:03+0000",
            "content": "I was talking with Shai already about the OBJECT_REF size of 8, in RamUsageEstimator it is:\n\n\npublic final static int NUM_BYTES_OBJECT_REF = Constants.JRE_IS_64BIT ? 8 : 4;\n\n\n\n...which does not take the CompressedOops into account. Can we detect those oops, so we can change the above ternary to return 4 on newer JVMs with compressed oops enabled? ",
            "author": "Uwe Schindler",
            "id": "comment-13229066"
        },
        {
            "date": "2012-03-14T08:06:58+0000",
            "content": "If you're running with an agent then it will tell you many bytes a reference is, so this would fix the issue. I don't think you can test this from within Java VM itself, but this is an interesting question. What you could do is spawn a child VM process with identical arguments (and an agent) and check it there, but this is quite awful... \n\nI'll ask on hotspot mailing list, maybe they know how to do this. ",
            "author": "Dawid Weiss",
            "id": "comment-13229067"
        },
        {
            "date": "2012-03-14T09:26:29+0000",
            "content": "I don't think it makes sense to be \"perfect\" here because there is a tradeoff between being accurate and being fast.\n\nI agree. We should be fast, and \"as accurate as we can get while preserving speed\".\n\nI will fix the constant's value as it's wrong. The helper methods are just that - helper. Someone can use other techniques to compute the size of objects.\n\nWill post a patch shortly. ",
            "author": "Shai Erera",
            "id": "comment-13229093"
        },
        {
            "date": "2012-03-14T10:42:47+0000",
            "content": "Nice catch on the overcounting of array's RAM usage!\n\nAnd +1 for additional sizeOf(...) methods. ",
            "author": "Michael McCandless",
            "id": "comment-13229125"
        },
        {
            "date": "2012-03-14T10:51:54+0000",
            "content": "Hi Mike,\n\nDawid and I were already contacting Hotspot list. There is an easy way to get the compressedOoooooops setting from inside the JVM using MXBeans from the ManagementFactory. I think we will provide a patch later! I think by that we could also optimize the check for 64 bit, because that one should also be reported by the MXBean without looking into strange sysprops (see the TODO in the code for JRE_IS_64BIT).\n\nUwe ",
            "author": "Uwe Schindler",
            "id": "comment-13229127"
        },
        {
            "date": "2012-03-14T10:56:28+0000",
            "content": "Sysprops should be a fallback though because (to be verified) they're supported by other vendors whereas the mx bean may not be.\n\nIt needs to be verified by running under j9, jrockit, etc. ",
            "author": "Dawid Weiss",
            "id": "comment-13229128"
        },
        {
            "date": "2012-03-14T12:52:23+0000",
            "content": "Consulting MXBean sounds great?\n\nSysprops should be a fallback though \n\n+1 ",
            "author": "Michael McCandless",
            "id": "comment-13229160"
        },
        {
            "date": "2012-03-14T13:04:44+0000",
            "content": "Here the patch for detecting compressesOops in Sun JVMs. For other JVMs it will simply use false, so the object refs will be guessed to have 64 bits, which is fine as upper memory limit.\n\nThe code does only use public Java APIs and falls back if anything fails to false. ",
            "author": "Uwe Schindler",
            "id": "comment-13229163"
        },
        {
            "date": "2012-03-14T13:27:11+0000",
            "content": "Patch adds RUE.sizeOf(String) and various sizeOf(arr[]) methods. Also fixes the ARRAY_HEADER.\n\nUwe, I merged with your patch, with one difference \u2013 the System.out prints in the test are printed only if VERBOSE. ",
            "author": "Shai Erera",
            "id": "comment-13229176"
        },
        {
            "date": "2012-03-14T13:34:54+0000",
            "content": "Shai: Thanks! I am in a train at the moment, so internet is slow/not working. I will later find out what MXBeans we can use to detect 64bit without looking at strange sysprops (which may have been modified by user code, so not really secure to use...).\n\nI left the non-verbose printlns in it, so people reviewing the patch can quickly see by running that test what happens on their JVM. It would be interesting to see what your jRockit does...  ",
            "author": "Uwe Schindler",
            "id": "comment-13229182"
        },
        {
            "date": "2012-03-14T13:45:01+0000",
            "content": "I tried IBM and Oracle 1.6 JVMs, and both printed the same:\n\n\n    [junit] ------------- Standard Output ---------------\n    [junit] NOTE: This JVM is 64bit: true\n    [junit] NOTE: This JVM uses CompressedOops: false\n    [junit] ------------- ---------------- ---------------\n\n\n\nSo no CompressedOops for me .\n\nI will later find out what MXBeans we can use to detect 64bit without looking at strange sysprops\n\nOk. If you'll make it, we can add these changes to that patch, otherwise we can also do them in a separate issue. ",
            "author": "Shai Erera",
            "id": "comment-13229188"
        },
        {
            "date": "2012-03-14T13:46:19+0000",
            "content": "Hm, for me (1.6.0_31, 7u3) it prints true. What JVMs are you using and what settings? ",
            "author": "Uwe Schindler",
            "id": "comment-13229191"
        },
        {
            "date": "2012-03-14T13:54:17+0000",
            "content": "Here my results:\n\n\n*****************************************************\nJAVA_HOME = C:\\Program Files\\Java\\jdk1.7.0_03\njava version \"1.7.0_03\"\nJava(TM) SE Runtime Environment (build 1.7.0_03-b05)\nJava HotSpot(TM) 64-Bit Server VM (build 22.1-b02, mixed mode)\n*****************************************************\n\nC:\\Users\\Uwe Schindler\\Projects\\lucene\\trunk-lusolr1\\lucene\\core>ant test -Dtestcase=TestRam*\n[junit] Testsuite: org.apache.lucene.util.TestRamUsageEstimator\n[junit] Tests run: 2, Failures: 0, Errors: 0, Time elapsed: 0,561 sec\n[junit]\n[junit] ------------- Standard Output ---------------\n[junit] NOTE: This JVM is 64bit: true\n[junit] NOTE: This JVM uses CompressedOops: true\n[junit] ------------- ---------------- ---------------\n\nC:\\Users\\Uwe Schindler\\Projects\\lucene\\trunk-lusolr1\\lucene\\core>ant test -Dtestcase=TestRam* -Dargs=-XX:-UseCompressedOops\n[junit] Testsuite: org.apache.lucene.util.TestRamUsageEstimator\n[junit] Tests run: 2, Failures: 0, Errors: 0, Time elapsed: 0,5 sec\n[junit]\n[junit] ------------- Standard Output ---------------\n[junit] NOTE: This JVM is 64bit: true\n[junit] NOTE: This JVM uses CompressedOops: false\n[junit] ------------- ---------------- ---------------\n\n*****************************************************\nJAVA_HOME = C:\\Program Files\\Java\\jdk1.6.0_31\njava version \"1.6.0_31\"\nJava(TM) SE Runtime Environment (build 1.6.0_31-b05)\nJava HotSpot(TM) 64-Bit Server VM (build 20.6-b01, mixed mode)\n*****************************************************\n\nC:\\Users\\Uwe Schindler\\Projects\\lucene\\trunk-lusolr1\\lucene\\core>ant test -Dtestcase=TestRam*\n[junit] Testsuite: org.apache.lucene.util.TestRamUsageEstimator\n[junit] Tests run: 2, Failures: 0, Errors: 0, Time elapsed: 0,453 sec\n[junit]\n[junit] ------------- Standard Output ---------------\n[junit] NOTE: This JVM is 64bit: true\n[junit] NOTE: This JVM uses CompressedOops: true\n[junit] ------------- ---------------- ---------------\n\nC:\\Users\\Uwe Schindler\\Projects\\lucene\\trunk-lusolr1\\lucene\\core>ant test -Dtestcase=TestRam* -Dargs=-XX:-UseCompressedOops\n[junit] Testsuite: org.apache.lucene.util.TestRamUsageEstimator\n[junit] Tests run: 2, Failures: 0, Errors: 0, Time elapsed: 0,421 sec\n[junit]\n[junit] ------------- Standard Output ---------------\n[junit] NOTE: This JVM is 64bit: true\n[junit] NOTE: This JVM uses CompressedOops: false\n[junit] ------------- ---------------- ---------------\n\nC:\\Users\\Uwe Schindler\\Projects\\lucene\\trunk-lusolr1\\lucene\\core>ant test -Dtestcase=TestRam* -Dargs=-XX:+UseCompressedOops\n[junit] Testsuite: org.apache.lucene.util.TestRamUsageEstimator\n[junit] Tests run: 2, Failures: 0, Errors: 0, Time elapsed: 0,422 sec\n[junit]\n[junit] ------------- Standard Output ---------------\n[junit] NOTE: This JVM is 64bit: true\n[junit] NOTE: This JVM uses CompressedOops: true\n[junit] ------------- ---------------- ---------------\n\n ",
            "author": "Uwe Schindler",
            "id": "comment-13229200"
        },
        {
            "date": "2012-03-14T14:05:56+0000",
            "content": "Oracle:\n\n\njava version \"1.6.0_21\"\nJava(TM) SE Runtime Environment (build 1.6.0_21-b07)\nJava HotSpot(TM) 64-Bit Server VM (build 17.0-b17, mixed mode)\n\n\n\nIBM:\n\n\njava version \"1.6.0\"\nJava(TM) SE Runtime Environment (build pwa6460sr9fp3-20111122_05(SR9 FP3))\nIBM J9 VM (build 2.4, JRE 1.6.0 IBM J9 2.4 Windows 7 amd64-64 jvmwa6460sr9-20111111_94827 (JIT enabled, AOT enabled)\nJ9VM - 20111111_094827\nJIT  - r9_20101028_17488ifx45\nGC   - 20101027_AA)\nJCL  - 20110727_07\n\n ",
            "author": "Shai Erera",
            "id": "comment-13229211"
        },
        {
            "date": "2012-03-14T14:09:03+0000",
            "content": "I ran \"ant test-core -Dtestcase=TestRam* -Dtests.verbose=true -Dargs=-XX:+UseCompressedOops\" and with the Oracle JVM I get \"Compressed Oops: true\" but with IBM JVM I still get 'false'. ",
            "author": "Shai Erera",
            "id": "comment-13229215"
        },
        {
            "date": "2012-03-14T14:15:26+0000",
            "content": "OK, that is expected. 1.6.0_21 does not enable compressedOops by default, so false is correct. If you manually enable, it gets true.\n\njRockit is jRockit and not Sun/Oracle, so the result is somehow expected. It seems to nor have that MXBrean. But the code does not produce strange exceptions, so at least in the Sun VM we can detect compressed Oops and guess the reference size better. 8 is still not bad as it gives an upper limit. ",
            "author": "Uwe Schindler",
            "id": "comment-13229217"
        },
        {
            "date": "2012-03-14T14:18:28+0000",
            "content": "By the way, here is the code from the hotspot mailing list member (my code is based on it), it also shows the outputs for different JVMs:\n\nhttps://gist.github.com/1333043\n\n(I just removed the com.sun.* imports and replaced by reflection) ",
            "author": "Uwe Schindler",
            "id": "comment-13229218"
        },
        {
            "date": "2012-03-14T14:25:53+0000",
            "content": "8 is still not bad as it gives an upper limit.\n\nI agree. Better to over-estimate here, than under-estimate.\n\nWould appreciate if someone can take a look at the sizeOf() impls before I commit. ",
            "author": "Shai Erera",
            "id": "comment-13229226"
        },
        {
            "date": "2012-03-14T15:01:08+0000",
            "content": "On Hotspot Mailing list some people also seem to have an idea about jRockit and IBM J9:\n\n\nFrom: Krystal Mok\nSent: Wednesday, March 14, 2012 3:46 PM\nTo: Uwe Schindler\nCc: Dawid Weiss; hotspot compiler\nSubject: Re: How to detect if the VM is running with compact refs from within the VM (no agent)?\n\nHi,\n\nJust in case you'd care, the same MXBean could be used to detect compressed references on JRockit, too. It's probably available starting from JRockit R28.\n\nInstead of \"UseCompressedOops\", use \"CompressedRefs\" as the VM option name on JRockit.\n\nDon't know how to extract this information for J9 without another whole bunch of hackeries...well, you could try this, on a \"best-effort\" basis for platform detection:\nIBM J9's VM version string contains the compressed reference information. Example:\n\n$ export JAVA_OPTS='-Xcompressedrefs'\n$ groovysh\nGroovy Shell (1.7.7, JVM: 1.7.0)\nType 'help' or '\\h' for help.\n----------------------------------------------------------------------------------------------------------------------------\ngroovy:000> System.getProperty 'java.vm.info'\n===> JRE 1.7.0 Linux amd64-64 Compressed References 20110810_88604 (JIT enabled, AOT enabled)\nJ9VM - R26_Java726_GA_20110810_1208_B88592\nJIT  - r11_20110810_20466\nGC   - R26_Java726_GA_20110810_1208_B88592_CMPRSS\nJ9CL - 20110810_88604\ngroovy:000> quit\n\nSo grepping for \"Compressed References\" in the \"java.vm.info\" system property gives you the clue.\n\n\n\tKris\n\n ",
            "author": "Uwe Schindler",
            "id": "comment-13229244"
        },
        {
            "date": "2012-03-14T15:37:56+0000",
            "content": "Patch looks good!\n\nMaybe just explain in sizeOf(String) javadoc that this method assumes the String is \"standalone\" (ie, does not reference a larger char[] than itself)?\n\nBecause... if you call String.substring, the returned string references a slice the char[] of the original one... and so technically the RAM it's tying up could be (much) larger than expected.  (At least, this used to be the case... not sure if it's changed...). ",
            "author": "Michael McCandless",
            "id": "comment-13229264"
        },
        {
            "date": "2012-03-14T15:50:51+0000",
            "content": "Good point. I clarified the jdocs with this:\n\n\n  /**\n   * Returns the approximate size of a String object. This computation relies on\n   * {@link String#length()} to compute the number of bytes held by the char[].\n   * However, if the String object passed to this method is the result of e.g.\n   * {@link String#substring}, the computation may be entirely inaccurate\n   * (depending on the difference between length() and the actual char[]\n   * length).\n   */\n\n\n\nIf there are no objections, I'd like to commit this. ",
            "author": "Shai Erera",
            "id": "comment-13229273"
        },
        {
            "date": "2012-03-14T15:52:51+0000",
            "content": "I would opt for sizeOf to return the actual size of the object, including underlying string buffers... We can take into account interning buffers but other than that I wouldn't skew the result because it can be misleading. ",
            "author": "Dawid Weiss",
            "id": "comment-13229275"
        },
        {
            "date": "2012-03-14T15:56:01+0000",
            "content": "I don't like this special handling of Strings, to be honest. Why do we need/do it? ",
            "author": "Dawid Weiss",
            "id": "comment-13229279"
        },
        {
            "date": "2012-03-14T16:02:07+0000",
            "content": "I don't like this special handling of Strings, to be honest. Why do we need/do it?\n\nBecause I wrote it, and it seemed useful to me, so why not? We know how Strings look like, at least in their worse case. If there will be a better implementation, we can fix it in RUE, rather than having many impls try to do it on their own? ",
            "author": "Shai Erera",
            "id": "comment-13229286"
        },
        {
            "date": "2012-03-14T16:18:41+0000",
            "content": "I don't like this special handling of Strings, to be honest. \n\nI'm confused: what special handling of Strings are we talking about...?\n\nYou mean that sizeOf(String) doesn't return the correct answer if the string came from a previous .substring (.split too) call...?\n\nIf so, how can we actually fix that?  Is there some way to ask a string for the true length of its char[]? ",
            "author": "Michael McCandless",
            "id": "comment-13229296"
        },
        {
            "date": "2012-03-14T16:32:47+0000",
            "content": "\n+  /** Returns the size in bytes of the String[] object. */\n+  public static int sizeOf(String[] arr) {\n+    int size = alignObjectSize(NUM_BYTES_ARRAY_HEADER + NUM_BYTES_OBJECT_REF * arr.length);\n+    for (String s : arr) {\n+      size += sizeOf(s);\n+    }\n+    return size;\n+  }\n+\n+  /** Returns the approximate size of a String object. */\n+  public static int sizeOf(String str) {\n+    // String's char[] size\n+    int arraySize = alignObjectSize(NUM_BYTES_ARRAY_HEADER + NUM_BYTES_CHAR * str.length());\n+\n+    // String's row object size    \n+    int objectSize = alignObjectSize(NUM_BYTES_OBJECT_REF /* array reference */\n+        + 3 * NUM_BYTES_INT /* String holds 3 integers */\n+        + NUM_BYTES_OBJECT_HEADER /* String object header */);\n+    \n+    return objectSize + arraySize;\n+  }\n\n\n\nWhat I mean is that without looking at the code I would expect sizeOf(String[] N) to return the actual memory taken by an array of strings. If they point to a single char[], this should simple count the object overhead, not count every character N times as it would do now. This isn't sizeOf(), this is sum(string lengths * 2) + epsilon to me.\n\nI'd keep RamUsageEstimator exactly what the name says \u2013 an estimation of the actual memory taken by a given object. A string can point to a char[] and if so this should be traversed as an object and counted once. ",
            "author": "Dawid Weiss",
            "id": "comment-13229311"
        },
        {
            "date": "2012-03-14T16:34:05+0000",
            "content": "If so, how can we actually fix that? Is there some way to ask a string for the true length of its char[]?\n\nSame as with other objects \u2013 traverse its fields and count them (once, building an identity set for all objects reachable from the root)? ",
            "author": "Dawid Weiss",
            "id": "comment-13229313"
        },
        {
            "date": "2012-03-14T16:46:24+0000",
            "content": "What I mean is that without looking at the code I would expect sizeOf(String[] N) to return the actual memory taken by an array of strings.\n\nSo you mean you'd want sizeOf(String[]) be just that?\n\n\nreturn alignObjectSize(NUM_BYTES_ARRAY_HEADER + NUM_BYTES_OBJECT_REF * arr.length);\n\n\n\nI don't mind. I just thought that since we know how to compute sizeOf(String), we can use that. It's an extreme case, I think, that someone will want to compute the size of String[] which share same char[] instance ... but I don't mind if it bothers you that much, to simplify it and document that it computes the raw size of the String[].\n\nBut I don't think that we should change sizeOf(String) to not count the char[] size. It's part of the object, and really it's String, not like we're trying to compute the size of a general object.\n\nSame as with other objects \u2013 traverse its fields and count them\n\nRUE already has .estimateRamUsage(Object) which does that through reflection. I think that sizeOf(String) can remain fast as it is now, with the comment that it my over-estimate if the String is actually a sub-string of one original larger string. In the worse case, we'll just be over-estimating. ",
            "author": "Shai Erera",
            "id": "comment-13229332"
        },
        {
            "date": "2012-03-14T16:53:17+0000",
            "content": "Hi Shai,\n\ncan ypou try this patch with J9 or maybe JRockit (Robert)? If yozu use one of those JVMs you may have to explicitely enable  compressed Oops/refs! ",
            "author": "Uwe Schindler",
            "id": "comment-13229336"
        },
        {
            "date": "2012-03-14T16:56:30+0000",
            "content": "RUE already has .estimateRamUsage(Object) which does that through reflection. I think that sizeOf(String) can remain fast as it is now, with the comment that it my over-estimate if the String is actually a sub-string of one original larger string. In the worse case, we'll just be over-estimating.\n\nYeah, that's exactly what I didn't like. All the primitive/ primitive array methods are fine, but why make things inconsistent with sizeOf(String)? I'd rather have the reflection-based method estimate the size of a String/String[]. Like we mentioned it's always a matter of speed/accuracy but here I'd opt for accuracy because the output can be off by a lot if you make substrings along the way (not to mention it assumes details about String internal implementation which may or may not be true, depending on the vendor).\n\nDo you have a need for this method, Shai? If you don't then why not wait (with this part) until such a need arises? ",
            "author": "Dawid Weiss",
            "id": "comment-13229339"
        },
        {
            "date": "2012-03-14T17:01:39+0000",
            "content": "Do you have a need for this method, Shai?\n\nI actually started this issue because of this method . I wrote the method for my own code, then spotted the bug in the ARRAY_HEADER, and on the go thought that it will be good if RUE would offer it for me / other people can benefit from it. Because from my experience, after I put code in Lucene, very smart people improve and optimize it, and I benefit from it in new releases.\n\nSo while I could keep sizeOf(String) in my own code, I know that Uwe/Robert/Mike/You will make it more efficient when Java 7/8/9 will be out, while I'll totally forget about it ! . ",
            "author": "Shai Erera",
            "id": "comment-13229344"
        },
        {
            "date": "2012-03-14T17:10:22+0000",
            "content": "Yeah... well... I'm flattered  I'm still -1 for adding this particular method because I don't like being surprised at how a method works and this is surprising behavior to me, especially in this class (even if it's documented in the javadoc, but who reads it anyway, right?).\n\nIf others don't share my opinion then can we at least rename this method to sizeOfBlah(..) where Blah is something that would indicate it's not actually taking into account char buffer sharing or sub-slicing (suggestions for Blah welcome)? ",
            "author": "Dawid Weiss",
            "id": "comment-13229363"
        },
        {
            "date": "2012-03-14T17:23:50+0000",
            "content": "estimateSizeOf(..)\nguessSizeOf(..)\nwildGuessSizeOf(..)\nincorrectSizeOf(..)\nsizeOfWeiss(..)\nweissSize(..)\nsizeOfButWithoutTakingIntoAccountCharBufferSharingOrSubSlicingSeeJavaDoc(..) ",
            "author": "Mark Miller",
            "id": "comment-13229400"
        },
        {
            "date": "2012-03-14T17:35:10+0000",
            "content": "\nIf so, how can we actually fix that? Is there some way to ask a string for the true length of its char[]?\n\nSame as with other objects \u2013 traverse its fields and count them (once, building an identity set for all objects reachable from the root)?\n\nAha, cool!  I hadn't realized RUE can crawl into the private char[] inside string and count up the RAM usage correctly.  That's nice.\n\nMaybe lowerBoundSizeOf(...)?\n\nOr maybe we don't add the new string methods (sizeOf(String), sizeOf(String[])) and somewhere document that you should do new RUE().size(String/String[]) instead...?  Hmm or maybe we do add the methods, but implement them under-the-hood w/ that? ",
            "author": "Michael McCandless",
            "id": "comment-13229410"
        },
        {
            "date": "2012-03-14T18:02:24+0000",
            "content": "sizeOfWeiss(..)\n\nWe're talking some serious dimensions here, beware of buffer overflows!\n\nOr maybe we don't add the new string methods (sizeOf(String), sizeOf(String[])) and somewhere document that you should do new RUE().size(String/String[]) instead..\n\nThis is something I would go for \u2013 it's consistent with what I would consider this class's logic. I would even change it to sizeOf(Object) \u2013 this would be a static shortcut to just measure an object's size, no strings attached?\n\nKabutz's code also distinguishes interned strings/ cached boxed integers and enums. This could be a switch much like it is now with interned Strings. Then this would really be either an upper (why lower, Mike?) bound or something that would try to be close to the exact memory consumption.\n\nA fun way to determine if we're right would be to run a benchmark with -Xmx20mb and test how close we can get to the main memory pool's maximum value before OOM is thrown.  ",
            "author": "Dawid Weiss",
            "id": "comment-13229440"
        },
        {
            "date": "2012-03-14T18:13:25+0000",
            "content": "(why lower, Mike?)\n\nOh I just meant the sizeOf(String) impl in the current patch is a lower bound (since it \"guesses\" the private char[] length by calling String.length(), which is a lower bound on the actual char[] length). ",
            "author": "Michael McCandless",
            "id": "comment-13229456"
        },
        {
            "date": "2012-03-14T18:18:51+0000",
            "content": "John Rose just replied to my question \u2013 there are fields in Unsafe that allow array scaling (1.7). Check these out:\n\n\n        ARRAY_BOOLEAN_INDEX_SCALE = theUnsafe.arrayIndexScale([Z);\n        ARRAY_BYTE_INDEX_SCALE = theUnsafe.arrayIndexScale([B);\n        ARRAY_SHORT_INDEX_SCALE = theUnsafe.arrayIndexScale([S);\n        ARRAY_CHAR_INDEX_SCALE = theUnsafe.arrayIndexScale([C);\n        ARRAY_INT_INDEX_SCALE = theUnsafe.arrayIndexScale([I);\n        ARRAY_LONG_INDEX_SCALE = theUnsafe.arrayIndexScale([J);\n        ARRAY_FLOAT_INDEX_SCALE = theUnsafe.arrayIndexScale([F);\n        ARRAY_DOUBLE_INDEX_SCALE = theUnsafe.arrayIndexScale([D);\n        ARRAY_OBJECT_INDEX_SCALE = theUnsafe.arrayIndexScale([Ljava/lang/Object;);\n        ADDRESS_SIZE = theUnsafe.addressSize();\n\n\n\nSo... there is a (theoretical?) possibility that, say, byte[] is machine word-aligned  I bet any RAM estimator written so far will be screwed if this happens  ",
            "author": "Dawid Weiss",
            "id": "comment-13229460"
        },
        {
            "date": "2012-03-14T20:19:25+0000",
            "content": "So the whole Oops MBean magic is obsolete... ADDRESS_SIZE = theUnsafe.addressSize(); woooah, so simple - works on more platforms for guessing!\n\nI will check this out with the usual reflection magic  ",
            "author": "Uwe Schindler",
            "id": "comment-13229579"
        },
        {
            "date": "2012-03-15T09:40:47+0000",
            "content": "Hi,\nhere new patch using Unsafe to get the bitness (with the well-known fallback) and for compressedOops detection. Looks much cleaner.\nI also like it more, that the addressSize is now detected natively and not from sysprops.\n\nThe constants mentioned by Dawid are only availabe in Java 7, so i reflected the underlying methods from theUnsafe. I also changed the boolean JRE_USES_COMPRESSED_OOPS to an integer JRE_REFERENCE_SIZE that is used by RamUsageEstimator. We might do the same for all other native types... (this is just a start).\n\nShai: Can you test with your JVMs and also enable/disable compressed oops/refs? ",
            "author": "Uwe Schindler",
            "id": "comment-13230023"
        },
        {
            "date": "2012-03-15T12:56:35+0000",
            "content": "Thanks Uwe !\n\nI ran the test, and now with both J9 (IBM) and Oracle, I get this print (without enabling any flag):\n\n\n    [junit] NOTE: running test testReferenceSize\n    [junit] NOTE: This JVM is 64bit: true\n    [junit] NOTE: Reference size in this JVM: 8\n\n\n\n\n\tI modified the test name to testReferenceSize (was testCompressedOops).\n\n\n\nI wrote this small test to print the differences between sizeOf(String) and estimateRamUsage(String):\n\n\n  public void testSizeOfString() throws Exception {\n    String s = \"abcdefgkjdfkdsjdskljfdskfjdsf\";\n    String sub = s.substring(0, 4);\n    System.out.println(\"original=\" + RamUsageEstimator.sizeOf(s));\n    System.out.println(\"sub=\" + RamUsageEstimator.sizeOf(sub));\n    System.out.println(\"checkInterned=true(orig): \" + new RamUsageEstimator().estimateRamUsage(s));\n    System.out.println(\"checkInterned=false(orig): \" + new RamUsageEstimator(false).estimateRamUsage(s));\n    System.out.println(\"checkInterned=false(sub): \" + new RamUsageEstimator(false).estimateRamUsage(sub));\n  }\n\n\n\nIt prints:\n\noriginal=104\nsub=56\ncheckInterned=true(orig): 0\ncheckInterned=false(orig): 98\ncheckInterned=false(sub): 98\n\n\n\nSo clearly estimateRamUsage factors in the sub-string's larger char[]. The difference in sizes of 'orig' stem from AverageGuessMemoryModel which computes the reference size to be 4 (hardcoded), and array size to be 16 (hardcoded). I modified AverageGuess to use constants from RUE (they are best guesses themselves). Still the test prints a difference, but now I think it's because sizeOf(String) aligns the size to mod 8, while estimateRamUsage isn't. I fixed that in size(Object), and now the prints are the same.\n\n\n\tI also fixed sizeOfArray \u2013 if the array.length == 0, it returned 0, but it should return its header, and aligned to mod 8 as well.\n\n\n\n\n\tI modified sizeOf(String[]) to sizeOf(Object[]) and compute its raw size only. I started to add sizeOf(String), fastSizeOf(String) and deepSizeOf(String[]), but reverted to avoid the hassle \u2013 the documentation confuses even me .\n\n\n\n\n\tChanged all sizeOf() to return long, and align() to take and return long.\n\n\n\nI think this is ready to commit, though I'd appreciate a second look on the MemoryModel and size(Obj) changes.\n\nAlso, how about renaming MemoryModel methods to: arrayHeaderSize(), classHeaderSize(), objReferenceSize() to make them more clear and accurate? For instance, getArraySize does not return the size of an array, but its object header ... ",
            "author": "Shai Erera",
            "id": "comment-13230126"
        },
        {
            "date": "2012-03-15T13:56:57+0000",
            "content": "-1 to mixing shallow and deep sizeofs \u2013 sizeOf(Object[] arr) is shallow and just feels wrong to me. All the other methods yield the deep total, why make an exception? If anything, make it explicit and then do it for any type of object \u2013 \n\n\nshallowSizeOf(Object t);\nsizeOf(Object t);\n\n\n\nI'm not complaining just because my sense of taste is feeling bad. I am actually using this class in my own projects and I would hate to look into the JavaDoc every time to make sure what a given method does (especially with multiple overloads). In other words, I would hate to see this:\n\n\nObject [] o1 = new Object [] {1, 2, 3};\nObject o2 = o1;\nif (sizeOf(o1) != sizeOf(o2)) throw new WtfException();\n\n\n\n\n ",
            "author": "Dawid Weiss",
            "id": "comment-13230171"
        },
        {
            "date": "2012-03-15T14:02:43+0000",
            "content": "\n\nI ran the test, and now with both J9 (IBM) and Oracle, I get this print (without enabling any flag):\n\n\n    [junit] NOTE: running test testReferenceSize\n    [junit] NOTE: This JVM is 64bit: true\n    [junit] NOTE: Reference size in this JVM: 8\n\n\n\nI hope with compressedOops explicitely enabled (or however they call them), you get a reference size of 4 in J9 and pre-1.6.0_23 Oracle? ",
            "author": "Uwe Schindler",
            "id": "comment-13230181"
        },
        {
            "date": "2012-03-15T14:07:32+0000",
            "content": "Ok removed sizeOf(Object[]). One can compute it by using RUE.estimateRamSize to do a deep calculation.\n\nGeez Dawid, you took away all the reasons I originally opened the issue for .\n\nBut at least AvgGuessMemoryModel and RUE.size() are more accurate now. And we have some useful utility methods. ",
            "author": "Shai Erera",
            "id": "comment-13230184"
        },
        {
            "date": "2012-03-15T14:12:46+0000",
            "content": "I ran \"ant test-core -Dtestcase=TestRam* -Dtests.verbose=true -Dargs=-XX:+UseCompressedOops\" and \"ant test-core -Dtestcase=TestRam* -Dtests.verbose=true -Dargs=-XX:-UseCompressedOops\" and get 8 and 4 (with CompressedOops). ",
            "author": "Shai Erera",
            "id": "comment-13230187"
        },
        {
            "date": "2012-03-15T14:36:37+0000",
            "content": "Oh, bummer - looks like we lost the whole history of this class...such a bummer. I really wanted to take a look at how this class had evolved since I last looked at it. I've missed the conversations around the history loss - is that gone, gone, gone, or is there still some way to find it? ",
            "author": "Mark Miller",
            "id": "comment-13230202"
        },
        {
            "date": "2012-03-15T14:40:53+0000",
            "content": "Scratch that - I was trying to look back from the apache git clone using git - assumed it's history matched svn - but I get a clean full history using svn. ",
            "author": "Mark Miller",
            "id": "comment-13230206"
        },
        {
            "date": "2012-03-15T14:42:08+0000",
            "content": "Die, GIT, die!  (as usual) ",
            "author": "Uwe Schindler",
            "id": "comment-13230208"
        },
        {
            "date": "2012-03-15T14:53:47+0000",
            "content": "I ran \"ant test-core -Dtestcase=TestRam* -Dtests.verbose=true -Dargs=-XX:+UseCompressedOops\" and \"ant test-core -Dtestcase=TestRam* -Dtests.verbose=true -Dargs=-XX:-UseCompressedOops\" and get 8 and 4 (with CompressedOops).\n\nOK, thanks. So it seems to work at least with Oracle/Sun and IBM J9. I have no other updates to this detection code. ",
            "author": "Uwe Schindler",
            "id": "comment-13230214"
        },
        {
            "date": "2012-03-15T15:00:18+0000",
            "content": "Geez Dawid, you took away all the reasons I originally opened the issue for \n\nThis is by no means wasted time. I think the improvements are clear?\n\nDie, GIT, die!\n\nI disagree here \u2013 git is a great tool, even if the learning curve may be steep at first. git-svn is a whole different story (it's a great hack but just a hack). ",
            "author": "Dawid Weiss",
            "id": "comment-13230219"
        },
        {
            "date": "2012-03-15T15:05:33+0000",
            "content": "I disagree here\n\nCalm down, was just my well-known standard answer  ",
            "author": "Uwe Schindler",
            "id": "comment-13230222"
        },
        {
            "date": "2012-03-15T15:08:21+0000",
            "content": "Oh, I am calm, I just know people do hate git (and I used to as well, until I started using it frequently). Robert has a strong opinion about git, for example. \n\nBesides, there's nothing wrong in having a strong opinion \u2013 it's great people can choose what they like and still collaborate via patches (and this seems to be the common ground between all vcs's). ",
            "author": "Dawid Weiss",
            "id": "comment-13230228"
        },
        {
            "date": "2012-03-15T15:09:03+0000",
            "content": "This is by no means wasted time. I think the improvements are clear?\n\nYes, yes. It was a joke.\n\nOk so can I proceed with the commit, or does someone intend to review the patch later? ",
            "author": "Shai Erera",
            "id": "comment-13230229"
        },
        {
            "date": "2012-03-15T15:09:09+0000",
            "content": "With unsafe we also get all those information like size of array header we have hardcoded. Should we not try to get these in the same way like I did for bitness and reference size - using Unsafe.theUnsafe.arrayBaseOffset()? And fallback to our hardcoded defaults? ",
            "author": "Uwe Schindler",
            "id": "comment-13230230"
        },
        {
            "date": "2012-03-15T15:16:19+0000",
            "content": "using Unsafe.theUnsafe.arrayBaseOffset()? And fallback to our hardcoded defaults?\n\n+1. \n\nI will also try on OpenJDK with various jits but I'll do it in the evening.\n\nYes, yes. It was a joke.\n\nJoke or no joke the truth is I did complain a lot.  ",
            "author": "Dawid Weiss",
            "id": "comment-13230235"
        },
        {
            "date": "2012-03-15T20:14:32+0000",
            "content": "I just peeked at OpenJDK sources and addressSize() is defined as this:\n\n// See comment at file start about UNSAFE_LEAF\n//UNSAFE_LEAF(jint, Unsafe_AddressSize())\nUNSAFE_ENTRY(jint, Unsafe_AddressSize(JNIEnv *env, jobject unsafe))\n  UnsafeWrapper(\"Unsafe_AddressSize\");\n  return sizeof(void*);\nUNSAFE_END\n\n\n\nIn this light this switch:\n\nswitch (addressSize) {\n  case 4:\n    is64Bit = Boolean.FALSE;\n    break;\n  case 8:\n    is64Bit = Boolean.TRUE;\n    break;\n}\n\n\nBecomes interesting. Do you know of any architecture with pointers different than 4 or 8 bytes?  ",
            "author": "Dawid Weiss",
            "id": "comment-13230503"
        },
        {
            "date": "2012-03-15T20:49:45+0000",
            "content": "A few more exotic jits from OpenJDK (all seem to be using explicit 8 byte ref size on 64-bit:\n\n> ant test-core -Dtestcase=TestRam* -Dtests.verbose=true \"-Dargs=-jamvm\"\n    [junit] JVM: OpenJDK Runtime Environment, JamVM, Robert Lougher, 1.6.0-devel, Java Virtual Machine Specification, Sun Microsystems Inc., 1.6.0_23, Sun Microsystems Inc., null,\n    [junit] NOTE: This JVM is 64bit: true\n    [junit] NOTE: Reference size in this JVM: 8\n\n> ant test-core -Dtestcase=TestRam* -Dtests.verbose=true \"-Dargs=-jamvm -XX:+UseCompressedOops\"\n    [junit] JVM: OpenJDK Runtime Environment, JamVM, Robert Lougher, 1.6.0-devel, Java Virtual Machine Specification, Sun Microsystems Inc., 1.6.0_23, Sun Microsystems Inc., null,\n    [junit] NOTE: This JVM is 64bit: true\n    [junit] NOTE: Reference size in this JVM: 8\n\n> ant test-core -Dtestcase=TestRam* -Dtests.verbose=true \"-Dargs=-cacao\"\n    [junit] JVM: OpenJDK Runtime Environment, CACAO, CACAOVM - Verein zur Foerderung der freien virtuellen Maschine CACAO, 1.1.0pre2, Java Virtual Machine Specification, Sun Microsystems Inc., 1.6.0_23, Sun Microsystems Inc., null,\n    [junit] NOTE: This JVM is 64bit: true\n    [junit] NOTE: Reference size in this JVM: 8\n\n> ant test-core -Dtestcase=TestRam* -Dtests.verbose=true \"-Dargs=-server\"\n    [junit] JVM: OpenJDK Runtime Environment, OpenJDK 64-Bit Server VM, Sun Microsystems Inc., 20.0-b11, Java Virtual Machine Specification, Sun Microsystems Inc., 1.6.0_23, Sun Microsystems Inc., null,\n    [junit] NOTE: This JVM is 64bit: true\n    [junit] NOTE: Reference size in this JVM: 4\n\n> ant test-core -Dtestcase=TestRam* -Dtests.verbose=true \"-Dargs=-server -XX:-UseCompressedOops\"\n    [junit] JVM: OpenJDK Runtime Environment, OpenJDK 64-Bit Server VM, Sun Microsystems Inc., 20.0-b11, Java Virtual Machine Specification, Sun Microsystems Inc., 1.6.0_23, Sun Microsystems Inc., null,\n    [junit] NOTE: This JVM is 64bit: true\n    [junit] NOTE: Reference size in this JVM: 8\n\n ",
            "author": "Dawid Weiss",
            "id": "comment-13230529"
        },
        {
            "date": "2012-03-15T20:57:49+0000",
            "content": "Mac:\n\n> ant test-core -Dtestcase=TestRam* -Dtests.verbose=true\n    [junit] JVM: Java(TM) SE Runtime Environment, Java HotSpot(TM) 64-Bit Server VM, Apple Inc., 20.4-b02-402, Java Virtual Machine Specification, Sun Microsystems Inc., 1.6.0_29, Apple Inc., null, \n    [junit] NOTE: This JVM is 64bit: true\n    [junit] NOTE: Reference size in this JVM: 4\n\n> ant test-core -Dtestcase=TestRam* -Dtests.verbose=true \"-Dargs=-server -XX:-UseCompressedOops\"\n    [junit] JVM: Java(TM) SE Runtime Environment, Java HotSpot(TM) 64-Bit Server VM, Apple Inc., 20.4-b02-402, Java Virtual Machine Specification, Sun Microsystems Inc., 1.6.0_29, Apple Inc., null, \n    [junit] NOTE: This JVM is 64bit: true\n    [junit] NOTE: Reference size in this JVM: 8\n\n ",
            "author": "Dawid Weiss",
            "id": "comment-13230535"
        },
        {
            "date": "2012-03-15T21:05:17+0000",
            "content": "Nooo!!! My eyes!!!! I'm pretty sure my liver has just been virally licensed! ",
            "author": "Mark Miller",
            "id": "comment-13230543"
        },
        {
            "date": "2012-03-15T21:27:02+0000",
            "content": "Ok, right, sorry, let me scramble for intellectual property protection reasons:\n\n// See cemnmot at flie sratt abuot U_ANEESAFLF \n/\n/ ULAAFEN_SEF (jnit, UfdAsnerS_zsiaedse ())\nUEATERSNFN_Y (jint, UnidsdserSAasfe_ze (JNnEIv * env, jcbjeot unfsae))\nUesWrpfapaner (\" UdenfsSseAazs_drie \"); \nrreutn seiozf (void *\n;)\nUNEF_SNEAD\n\n ",
            "author": "Dawid Weiss",
            "id": "comment-13230572"
        },
        {
            "date": "2012-03-15T22:13:54+0000",
            "content": "Becomes interesting. Do you know of any architecture with pointers different than 4 or 8 bytes? \n\nWhen I was writing that code, I was thinking a very long time about: Hm, should I add a \"default\" case saying:\n\n\ndefault:\n  throw new Error(\"Lucene does not like architectures with pointer size \" + addressSize)\n\n\n\nBut then I decided: If there is an architecture with a pointer size of 6, does this break Lucene really? Hm, maybe I should have added a comment there:\n\n\ndefault:\n  // this is the philosophical case of Lucene reaching an architecture returning something different here\n\n ",
            "author": "Uwe Schindler",
            "id": "comment-13230631"
        },
        {
            "date": "2012-03-15T22:28:53+0000",
            "content": "Maybe this for @UweSays:\n\n\ndefault:\n  throw new Error(\"Your processor(*) hit me with his \" + addressSize + \" inch dick\");\n  // (*)Dawid\n\n ",
            "author": "Uwe Schindler",
            "id": "comment-13230644"
        },
        {
            "date": "2012-03-15T22:32:18+0000",
            "content": "I would throw an exception just so that we can hear about those architectures nobody has ever heard of  ",
            "author": "Dawid Weiss",
            "id": "comment-13230647"
        },
        {
            "date": "2012-03-15T22:33:24+0000",
            "content": "fyi. http://en.wikipedia.org/wiki/48-bit ",
            "author": "Dawid Weiss",
            "id": "comment-13230652"
        },
        {
            "date": "2012-03-15T22:37:09+0000",
            "content": "http://en.wikipedia.org/wiki/Quadruple_precision_floating-point_format ",
            "author": "Uwe Schindler",
            "id": "comment-13230655"
        },
        {
            "date": "2012-03-16T07:46:49+0000",
            "content": "Yep, but I'm talking about address registers and addressing in general. 48 bit addressing aligning would be inconvenient if you take into account that any index scaling addressing modes would have to do a shift and an addition (*3) instead of just a shift. Interesting stuff. ",
            "author": "Dawid Weiss",
            "id": "comment-13230950"
        },
        {
            "date": "2012-03-16T07:55:51+0000",
            "content": "I agree, was just a joke. The comment before was more about suddenly appearing 128 bit architectures. That ones would have an addressSize of 16, still a power of 2 \n\nI will now look into the unsafe array offsets... ",
            "author": "Uwe Schindler",
            "id": "comment-13230956"
        },
        {
            "date": "2012-03-16T08:01:31+0000",
            "content": "Nice. All of a sudden you could enumerate all the atoms in the universe  I love Wolfram Alpha...\nhttp://www.wolframalpha.com/input/?i=is+number+of+atoms+in+the+universe+greater+than+2%5E128%3F ",
            "author": "Dawid Weiss",
            "id": "comment-13230959"
        },
        {
            "date": "2012-03-16T08:48:13+0000",
            "content": "I played around: Unsafe.arrayBaseOffset always returns 16 on my 64bit JVM, so it seems that NUM_BYTES_ARRAY_HEADER is wrong in our case (we have it as 12). It seems that the JVM aligns the array data to be multiple of 8 bytes on 64 bit machines?\n\nFor normal objects, is there a way with unsafe to get the NUM_BYTES_OBJECT_HEADER? ",
            "author": "Uwe Schindler",
            "id": "comment-13230977"
        },
        {
            "date": "2012-03-16T09:03:20+0000",
            "content": "For normal objects, is there a way with unsafe to get the NUM_BYTES_OBJECT_HEADER?\n\nI don't know and I don't know if it varies between vendors. As for aligning \u2013 I bet this holds for anything, not only arrays. So fields of an object will be reordered and packed on their own boundary but entire themselves will be aligned on machine word boundaries for efficiency. Did you try running with Instrumentation (an agent)? What does it say about object/ array sizes? ",
            "author": "Dawid Weiss",
            "id": "comment-13230979"
        },
        {
            "date": "2012-03-16T09:33:51+0000",
            "content": "Interestingly the ARRAY header seems to be much bigger on 64 bit platforms without compact refs, so I have the feeling that somehow thre is still some space needed for an object ref, so the original definition of the size was more correct? https://gist.github.com/2038305\n\nUsing the original definition:\n\npublic final static int NUM_BYTES_ARRAY_HEADER = NUM_BYTES_OBJECT_HEADER + NUM_BYTES_INT + NUM_BYTES_OBJECT_REF;\n\n\n\nThis looks much more like the above size, aligned to 8 bytes.\n\nDid you try running with Instrumentation (an agent)? What does it say about object/ array sizes?\n\nHave to try out and set this up first. ",
            "author": "Uwe Schindler",
            "id": "comment-13230994"
        },
        {
            "date": "2012-03-16T09:43:20+0000",
            "content": "This is also in line with this instumentation page:\nhttp://www.javaspecialists.eu/archive/Issue142.html\n\nWhich prints:\n\nmeasureSize(new byte[1000]);\nbyte[], shallow=1016, deep=1016\nmeasureSize(new boolean[1000]);\nboolean[], shallow=1016, deep=1016\n\n ",
            "author": "Uwe Schindler",
            "id": "comment-13231001"
        },
        {
            "date": "2012-03-16T09:45:49+0000",
            "content": "Array header is still 12 bytes but it is aligned to the next multiple-8 boundary? Looks like it. ",
            "author": "Dawid Weiss",
            "id": "comment-13231002"
        },
        {
            "date": "2012-03-16T09:48:55+0000",
            "content": "But how does that explain that with non-compact refs the arrayBaseOffset is 24? ",
            "author": "Uwe Schindler",
            "id": "comment-13231003"
        },
        {
            "date": "2012-03-16T10:02:54+0000",
            "content": "Can you check what size does Object[] report vs. for example Integer[]? I think the difference may be because typed arrays need to know the type of their component. ",
            "author": "Dawid Weiss",
            "id": "comment-13231017"
        },
        {
            "date": "2012-03-16T10:42:49+0000",
            "content": "We peeked at the forbidden a bit again. The difference 12 vs. 16 bytes is a result of how ordinary object pointers (OOPs) are defined \u2013 they are a combination of object header information (oopMark) and class pointer. The class pointer is a compile time union of either a regular pointer or a compact pointer. oopMark is either 4 bytes (32 bit jvms) or 8 bytes (64 bit jvms). So:\n\n64 bit jvm, full oops: 8 + 8 = 16\n64 bit jvm, compact oops: 8 + 4 = 12\n32 bit jvm: 4 + 4 = 8 ",
            "author": "Dawid Weiss",
            "id": "comment-13231045"
        },
        {
            "date": "2012-03-16T12:07:46+0000",
            "content": "With the help of Dawid (inspecting forbidden C code g), we checked the actual size and how they are calculated. Based on that I changed the defaults depending on bitness (Object header is 16 on 64 bit without compact refs, array header is 24 on 64 bit).\n\nThe attached patch will use the above defaults, but tries to update them using sun.misc.Unsafe. The trick to get the object header from usafe is by declaring a dummy class extending Object with one single field. We are then using unsafe to get the fieldOffset of that field. As Dawid pointed out, the return value is identical to his investigations (8 bytes on 32 bit archs, 16 bytes on 64 bit archs and 12 bytes on compact ref 64bit archs). So RamUsageEstimator was completely wrong in the past for 64 bit architectures.\n\nI also changed the funny switch statement (\"the \" + adressSize + \" inch dick\") to assume 64 bits architecture, if addressSize >= 8. ",
            "author": "Uwe Schindler",
            "id": "comment-13231096"
        },
        {
            "date": "2012-03-16T12:09:27+0000",
            "content": "I would like to remove the AverageBlabla memotry model. The code inside is simply no longer useful. RamUsageEstimator simply uses the sizes returned by the JVM. ",
            "author": "Uwe Schindler",
            "id": "comment-13231097"
        },
        {
            "date": "2012-03-16T12:54:01+0000",
            "content": "Updated patch with the abstract and now useless MemoryModel removed. ",
            "author": "Uwe Schindler",
            "id": "comment-13231119"
        },
        {
            "date": "2012-03-16T13:04:34+0000",
            "content": "Robert reminded me that there is also a heavily broken custom memory estimator in MemoryIndex, too. I will look into it, too. ",
            "author": "Uwe Schindler",
            "id": "comment-13231134"
        },
        {
            "date": "2012-03-16T16:53:53+0000",
            "content": "Attached is a patch fixing several bugs and more:\n\n\tRemoved the MemoryIndex VM class and the completely outdated and incorrect estimation there.\n\tUsed Shai's new added methods also in Lucene's PackedInt classes\n\tFixes overflows in Shai's new methods, as they can overflow if arrays are greater than 2 GB (casts to long missing)\n\tFixed the up-rounding to multiples of 8 to work with longs\n\n\n\nWhat's the reason why this rounding up to 8 bytes was added? I assume this information comes from somewhere, but it was added by Shai without any explanation. Is this not also dependent on the 64bitness if its 8 or 4?\n\nOtherwise patch is ready. ",
            "author": "Uwe Schindler",
            "id": "comment-13231379"
        },
        {
            "date": "2012-03-16T17:00:05+0000",
            "content": "\nRemoved the MemoryIndex VM class and the completely outdated and incorrect estimation there.\n\nthank you!!! ",
            "author": "Robert Muir",
            "id": "comment-13231388"
        },
        {
            "date": "2012-03-16T17:34:33+0000",
            "content": "Awesome job, Uwe. I think I wasn't right about that alignment of arrays \u2013 sizeof(int) should't come up to 8. I will look into this again in the evening, it got me interested. I'll also check out the alignments, so if this patch can wait until tomorrow then we'll be more confident we get the estimates right. ",
            "author": "Dawid Weiss",
            "id": "comment-13231413"
        },
        {
            "date": "2012-03-16T21:00:38+0000",
            "content": "This is very interesting indeed. \n\nSo, I used the agent hook into a running VM to dump some of the internal diagnostics, including OOP sizes, heap word alignments, etc. Here's a scoop of the results (with client-side indicated sizes on the right):\n\n\n# 1.7, 64 bit, OOPS compressed            (client)\ngetOopSize: 8                             ref size = 4         \nAddress size: 8                           array header = 16    \nBytes per long: 8                         object header = 12   \nCPU: amd64\nHeapOopSize: 4\nHeapWordSize: 8\nIntSize: 4\ngetMinObjAlignmentInBytes: 8\ngetObjectAlignmentInBytes: 8\nisCompressedOopsEnabled: true\nisLP64: true\n\n\n# 1.7, 64 bit, full\ngetOopSize: 8                             ref size = 8     \nAddress size: 8                           array header = 24\nBytes per long: 8                         object header = 16\nCPU: amd64\nHeapOopSize: 8\nHeapWordSize: 8\nIntSize: 4\ngetMinObjAlignmentInBytes: 8\ngetObjectAlignmentInBytes: 8\nisCompressedOopsEnabled: false\nisLP64: true\n\n# 1.7, 32 bit  \ngetOopSize: 4                             ref size = 4     \nAddress size: 4                           array header = 12\nBytes per long: 8                         object header = 8\nCPU: x86\nHeapOopSize: 4\nHeapWordSize: 4\nIntSize: 4\ngetMinObjAlignmentInBytes: 8\ngetObjectAlignmentInBytes: 8\nisCompressedOopsEnabled: false\nisLP64: false\n\n\n\nThe question we asked ourselves with Uwe is why an empty array takes 24 bytes without OOP compression (that's object overhead and an int length, so should be 16 + 4 = 20)? The answer seems to be in how base offsets are calculated for arrays \u2013 they seem to be enforced on HeapWordSize boundary and this is 8, even with OOP compressed:\n\n  // Returns the offset of the first element.\n  static int base_offset_in_bytes(BasicType type) {\n    return header_size(type) * HeapWordSize;\n  }\n\n\nI'll spare you the detailed code but the rounding to next HeapWordSize multiple seems evident in all cases. What's even more interesting, this \"wasted\" space is not (and cannot) be used for data so even a single integer pushes the array size to the next available bound:\n\nint[0] = 24\nint[1] = 32   (*)\nint[2] = 32\nint[3] = 40\n\n\n\nFinally, I could not resist to mention that object alignments... are adjustable, at least to 2^n boundaries. So you can also do this:\n\n> java  -XX:-UseCompressedOops -XX:ObjectAlignmentInBytes=32 ...\nObject = 32\nint[0] = 32\nint[1] = 32\nint[2] = 32\nint[3] = 64\n\n\nNice, huh?  I don't think the JVM has been tested heavily for this possibility though because the code hung on me a few times if executed in that mode. ",
            "author": "Dawid Weiss",
            "id": "comment-13231625"
        },
        {
            "date": "2012-03-16T22:07:42+0000",
            "content": "He, he, he... this is fun, haven't been playing with Unsafe for a while and forgot how enjoyable this can be.\n\n            Unsafe us = ...;\n            byte [] dummy  = {0x11, 0x22, 0x33, 0x44};\n            int []  dummy2 = {0}; // match length above.\n            // Change the class of dummy to int[]...\n            int klazz = us.getInt(dummy2, 8);\n                        us.putInt( dummy, 8, klazz);\n            // this will be ok.\n            dummy2 = (int[])(Object) dummy;\n            // and we can run native int accessors on a byte[] now...\n            System.out.println(\"> \" + Integer.toHexString(dummy2[0]));\n\n ",
            "author": "Dawid Weiss",
            "id": "comment-13231668"
        },
        {
            "date": "2012-03-16T22:08:49+0000",
            "content": "I think Yonik once mentioned he wanted a fast hash over byte[] \u2013 this could be it (temporarily cast to a long[] and then revert after computations are over). Go for it, Yonik  ",
            "author": "Dawid Weiss",
            "id": "comment-13231673"
        },
        {
            "date": "2012-03-16T22:14:32+0000",
            "content": "Thanks for investigation. The 8 byte object size multiplier is fixed, so the round-up method is fine.\n\nI have been thinking about alignment things. Its a good possibility to get the object size by suming up the field sizes, but it can even be done better.\n\nIf unsafe is available and useable, we can simply get the object size (including all headers), by finding the Math.max(field offset + field type length). So the object size is the offset of the last field (with biggest offset) + its size. This value is finally rounded up to multiples of 8.\n\nThe attached patch does this. ",
            "author": "Uwe Schindler",
            "id": "comment-13231679"
        },
        {
            "date": "2012-03-16T22:19:52+0000",
            "content": "The 8 byte object size multiplier is fixed, so the round-up method is fine.\n\nI don't think it's \"fixed\" \u2013 see the -XX:ObjectAlignmentInBytes=32 above. But the defaults seem to be the same on all systems. ",
            "author": "Dawid Weiss",
            "id": "comment-13231682"
        },
        {
            "date": "2012-03-16T22:57:44+0000",
            "content": "I don't think it's \"fixed\" \u2013 see the -XX:ObjectAlignmentInBytes=32 above. But the defaults seem to be the same on all systems.\n\nI would like to have the rounding also dynamic, but this is not possible to find out with Unsafe, at least for this I have no idea  ",
            "author": "Uwe Schindler",
            "id": "comment-13231719"
        },
        {
            "date": "2012-03-17T08:04:33+0000",
            "content": "at least for this I have no idea\n\nThe management factory trick mentioned by Kris works for object alignment as well:\n\npackage spikes;\n\nimport java.io.IOException;\nimport java.lang.management.ManagementFactory;\nimport java.lang.reflect.Method;\nimport java.util.List;\n\nimport com.sun.management.HotSpotDiagnosticMXBean;\nimport com.sun.management.VMOption;\n\npublic class ObAlignment\n{\n    private static final String HOTSPOT_BEAN_NAME = \"com.sun.management:type=HotSpotDiagnostic\";\n    private static HotSpotDiagnosticMXBean hotspotMBean;\n    \n    private static HotSpotDiagnosticMXBean getHotSpotMBean() {\n      if (hotspotMBean == null) {\n        try {\n          hotspotMBean = ManagementFactory.newPlatformMXBeanProxy(\n            ManagementFactory.getPlatformMBeanServer(),\n            HOTSPOT_BEAN_NAME,\n            HotSpotDiagnosticMXBean.class);\n        } catch (IOException e) {\n          e.printStackTrace();\n        }\n      }\n      return hotspotMBean;\n    }\n\n    public static void main(String [] args)\n        throws Exception\n    {\n        // Just the object alignment.\n        System.out.println(getHotSpotMBean().getVMOption(\"ObjectAlignmentInBytes\"));\n\n        // Everything.\n        Class<?> fc = Class.forName(\"sun.management.Flag\");\n        System.out.println(fc);\n        Method m = fc.getDeclaredMethod(\"getAllFlags\");\n        m.setAccessible(true);\n        List<Object> flags = (List<Object>) m.invoke(null);\n        for (Object f : flags) {\n            Method dm = f.getClass().getDeclaredMethod(\"getVMOption\");\n            dm.setAccessible(true);\n            VMOption option = (VMOption) dm.invoke(f);\n            System.out.println(option);\n        }\n    }\n}\n\n\n\nI don't think it is of much practical use for now (object alignment seems to be constant everywhere), but we could as well probe it \u2013 if it's available why not use it.\n\nI'd also like to add a shallow size method (which wouldn't follow the fields, just return the aligned object size). I'll be able to work on it in the evening though, not sooner. ",
            "author": "Dawid Weiss",
            "id": "comment-13231889"
        },
        {
            "date": "2012-03-17T08:26:29+0000",
            "content": "Too funny,\nI had the same idea while at breakfast and started to implement it when you were writing your comment \n\nI will post patch soon (also with other improvements)! ",
            "author": "Uwe Schindler",
            "id": "comment-13231893"
        },
        {
            "date": "2012-03-17T08:31:08+0000",
            "content": "I will add a shallow parameter to the estimate method, we just dont have to dig into, so it's a simple if check. ",
            "author": "Uwe Schindler",
            "id": "comment-13231894"
        },
        {
            "date": "2012-03-17T08:56:32+0000",
            "content": "New patch:\n\n\tretrieve object alignment (default 8, e.g. 32bit JVMs don't report it)\n\tadd shallow object size measurement\n\tadd some security checks to possibly handle the \"cookie\" warning in Unsafe.objectFieldOffset() (the offsets may be \"scaled\"). Current JVMs never do this, but the documentation explicitely states that the offsets may not be byte-aligned.\n\n ",
            "author": "Uwe Schindler",
            "id": "comment-13231901"
        },
        {
            "date": "2012-03-17T10:56:42+0000",
            "content": "Minor improvements. ",
            "author": "Uwe Schindler",
            "id": "comment-13231916"
        },
        {
            "date": "2012-03-17T14:11:45+0000",
            "content": "The patch looks good. I don't know if decorating IdentityHashMap to be a set adds any overhead... I was also thinking about doing a custom set impl. for this so that we know how much memory we allocate during the checking itself, but it seems to be very specific to what I need, so no worries.\n\nOne thing:\n\n(size % NUM_BYTES_OBJECT_ALIGNMENT);\n\n\nByte alignment will be a power of 2 (that option to change it even enforces it when you start the JVM) so you can do a bitmask instead of modulo - should be slighly faster. ",
            "author": "Dawid Weiss",
            "id": "comment-13231981"
        },
        {
            "date": "2012-03-17T14:53:21+0000",
            "content": "I separated the shallow Object inspection to a static method, which is more cheap (no RamUsageEstimator instance is needed). The static method now only takes a Class<?> parameter and returns the size (an instance is not even needed).\n\nI also added a diagnostic boolean, so you can query RamUsageEstimator, if the used JVM is supported (supports Hotspot diagnostics, sum.misc.Unsafe). If that is not the case, our testcase will print a warning so users cam report back (if they run the tests).\n\nI think this is ready to commit. ",
            "author": "Uwe Schindler",
            "id": "comment-13231986"
        },
        {
            "date": "2012-03-17T14:58:17+0000",
            "content": "\nOne thing:\n\n(size % NUM_BYTES_OBJECT_ALIGNMENT);\n\n\nByte alignment will be a power of 2 (that option to change it even enforces it when you start the JVM) so you can do a bitmask instead of modulo - should be slighly faster.\n\nI don't think thats really needed here  Speed is limited by reflection in most cases and this one calculation should not matter. Also the number is not reported back as power of 2, so I have to calc the log2 first (ok, ntz &co.), but I don't think we should actually limit that to powers of 2. Maybe another vendor has the ultimate answer of 42 for his objects? ",
            "author": "Uwe Schindler",
            "id": "comment-13231988"
        },
        {
            "date": "2012-03-17T15:02:27+0000",
            "content": "I don't know if decorating IdentityHashMap to be a set adds any overhead\n\nThe whole problem is more that it might happen that the IdentityHashMap takes horrible amounts of memory while inspecting (think of a boxed numbers array like Byte[50000]). Speed is not important, reflection is slow \n\nI have no better idea about how to detect duplicates, unfortunately. The old trick from Arrays.deepEquals() to stop when the parameter itsself is seen again, is not enough here. ",
            "author": "Uwe Schindler",
            "id": "comment-13231989"
        },
        {
            "date": "2012-03-17T15:25:06+0000",
            "content": "One more improvement:\nThe shallow Class inspection can ignore superclasses, if Unsafe is in use. As additional fields are always added at the end (otherwise casting of classes and later field access would not work inside the JVM), to find the maximum field offset we don't need to go to superclasses.\n\nI want to commit and backport this to 3.x during the weekend. ",
            "author": "Uwe Schindler",
            "id": "comment-13231992"
        },
        {
            "date": "2012-03-17T16:40:52+0000",
            "content": "Reflection don't need to cost you much if you make a cache along the way. Retrieving an object's class is virtually zero cost so this would make it very efficient and the number of classes in the system is much smaller than the number of objects so it shouldn't be a problem.\n\nto find the maximum field offset we don't need to go to superclasses.\n\nI can't imagine a situation where this wouldn't be the case although an assertion here would be nice just to make sure we're not assuming something that isn't true.\n\n\nI will take a closer look at the patch again this evening and do some testing/ API flexibility based on what I have in my project. Will report on the results. ",
            "author": "Dawid Weiss",
            "id": "comment-13232006"
        },
        {
            "date": "2012-03-17T17:30:53+0000",
            "content": "Reflection don't need to cost you much if you make a cache along the way. Retrieving an object's class is virtually zero cost so this would make it very efficient and the number of classes in the system is much smaller than the number of objects so it shouldn't be a problem.\n\nWould be like the reflection  cache in AttributeSource  But yes I was also thinking about a second IdentityHashMap<Class<?>,Long> along the way.\n\nI can't imagine a situation where this wouldn't be the case although an assertion here would be nice just to make sure we're not assuming something that isn't true.\n\nThats already checked in the test, who has 2 subclasses, one with no additional fields (size must be identical) and one with 2 more fields (should be >=). ",
            "author": "Uwe Schindler",
            "id": "comment-13232024"
        },
        {
            "date": "2012-03-17T17:50:59+0000",
            "content": "Wow, what awesome improvements you guys have added !\n\nUwe, +1 to commit. I unassigned myself - you and Dawid definitely deserve the credit! ",
            "author": "Shai Erera",
            "id": "comment-13232030"
        },
        {
            "date": "2012-03-17T21:53:22+0000",
            "content": "Modified method naming convention: any sizeOf  is \"deep\", shallowSizeOf* is \"shallow\". Methods in RUE are now static; didn't hide the constructor though (maybe we should?).\n\nMore comments in a minute. ",
            "author": "Dawid Weiss",
            "id": "comment-13232077"
        },
        {
            "date": "2012-03-17T22:06:35+0000",
            "content": "Thanks for cleanup!\n\ndidn't hide the constructor though (maybe we should?).\n\nWe must. Class is final and has no instance methods -> useless to have ctor. Also as previous versions in 3.x allowed instances, we should prevent this to fix incorrect usage. ",
            "author": "Uwe Schindler",
            "id": "comment-13232078"
        },
        {
            "date": "2012-03-17T22:07:15+0000",
            "content": "I've played with the code a bit and I've been trying to figure out a way to determine empirically \"how far off\" is the estimation from real life usage. It's not easy because RUE itself allocates memory (and not small quantities in case of complex object graphs!). I left these experiments in StressRamUsageEstimator; it is a test case \u2013 maybe we should add @Ignore and rename it to Test*, don't know.\n\nAnyway, the allocation seems to be measured pretty accurately. When tlabs are disabled this is a result of allocating small byte arrays for example:\n\n committed           max        estimated(allocation)\n      2 MB\t   48.4 MB\t  16 bytes\n    1.7 MB\t   48.4 MB\t  262.4 KB\n      2 MB\t   48.4 MB\t  524.6 KB\n    2.2 MB\t   48.4 MB\t    787 KB\n    2.5 MB\t   48.4 MB\t      1 MB\n    2.7 MB\t   48.4 MB\t    1.3 MB\n      3 MB\t   48.4 MB\t    1.5 MB\n    3.3 MB\t   48.4 MB\t    1.8 MB\n....\n   46.9 MB\t   48.4 MB\t   45.6 MB\n   47.1 MB\t   48.4 MB\t   45.9 MB\n   47.4 MB\t   48.4 MB\t   46.1 MB\n   47.6 MB\t   48.4 MB\t   46.4 MB\n   47.9 MB\t   48.4 MB\t   46.6 MB\n   48.1 MB\t   48.4 MB\t   46.9 MB\n\n\n\nSo it's fairly ideal (committed memory is all committed memory so I assume additional data structures, classes, etc. also count in).\n\nUnfortunately it's not always so smooth, for example jrockit's mx beans seem not to return the actual memory allocation state (and if they do, I don't understand it):\n\n committed           max        estimated(allocation)\n   29.4 MB\t     50 MB\t  16 bytes\n   29.8 MB\t     50 MB\t  262.5 KB\n   30.2 MB\t     50 MB\t  524.9 KB\n   30.4 MB\t     50 MB\t  787.3 KB\n   30.8 MB\t     50 MB\t      1 MB\n   31.1 MB\t     50 MB\t    1.3 MB\n   31.4 MB\t     50 MB\t    1.5 MB\n   31.7 MB\t     50 MB\t    1.8 MB\n     32 MB\t     50 MB\t      2 MB\n   32.4 MB\t     50 MB\t    2.3 MB\n   32.7 MB\t     50 MB\t    2.6 MB\n   33.1 MB\t     50 MB\t    2.8 MB\n   33.5 MB\t     50 MB\t    3.1 MB\n   33.8 MB\t     50 MB\t    3.3 MB\n   34.2 MB\t     50 MB\t    3.6 MB\n   34.5 MB\t     50 MB\t    3.8 MB\n   34.8 MB\t     50 MB\t    4.1 MB\n   35.2 MB\t     50 MB\t    4.4 MB\n   35.5 MB\t     50 MB\t    4.6 MB\n   35.7 MB\t     50 MB\t    4.9 MB\n   36.2 MB\t     50 MB\t    5.1 MB\n   36.4 MB\t     50 MB\t    5.4 MB\n...\n   49.6 MB\t     50 MB\t   47.6 MB\n     50 MB\t     50 MB\t   47.9 MB\n   49.6 MB\t     50 MB\t   48.2 MB\n   49.9 MB\t     50 MB\t   48.4 MB\n\n\n\nA snapshot from 32 bit HotSpot:\n\n...\n   25.5 MB\t   48.4 MB\t   24.7 MB\n   25.7 MB\t   48.4 MB\t   24.9 MB\n   25.9 MB\t   48.4 MB\t   25.1 MB\n   26.1 MB\t   48.4 MB\t   25.3 MB\n   26.3 MB\t   48.4 MB\t   25.5 MB\n   26.5 MB\t   48.4 MB\t   25.7 MB\n   26.7 MB\t   48.4 MB\t   25.9 MB\n   26.8 MB\t   48.4 MB\t   26.1 MB\n     27 MB\t   48.4 MB\t   26.4 MB\n   27.2 MB\t   48.4 MB\t   26.6 MB\n   27.4 MB\t   48.4 MB\t   26.8 MB\n   27.7 MB\t   48.4 MB\t     27 MB\n...\n\n\n\nI see two problems that remain, but I don't think they're urgent enough to be addressed now:\n\n\tthe stack easily overflows if the graph of objects has long chains. This is demonstrated in the test case (uncomment ignore annotation).\n\tthere is a fair amount of memory allocation going on in the RUE itself. If one knows the graph of an object's dependencies is a tree then the memory cost could be decreased to zero (because we wouldn't need to remember which objects we've seen so far).\n\twe could make RUE an object again (resign from static methods) and have a cache of classes and class-fields to avoid reflective accesses over and over. If one performed estimations over and over then such a  RUE instance would have an initial cost, but then would be running smoother.\n\n\n\nHaving said that, I'm +1 for committing this in if you agree with the changes I've made (I will be a pain in the arse about that naming convention discriminating between shallow vs. deep sizeOf though . ",
            "author": "Dawid Weiss",
            "id": "comment-13232079"
        },
        {
            "date": "2012-03-17T22:10:58+0000",
            "content": "Oh, one thing that springs to my mind is that we could have an automatically generated class with nested static classes with a random arrangement of all sorts of fields (in all sorts of configurations) and use a similar empirical benchmark to the one I did on small byte arrays but on these objects. This would show if we're estimating object field offsets and sizes correctly. \n\nI wouldn't go into deep object structures though \u2013 I've tried this and it's hard to tell what the allocation is and what the overhead/ noise of measurement is. ",
            "author": "Dawid Weiss",
            "id": "comment-13232082"
        },
        {
            "date": "2012-03-17T22:43:51+0000",
            "content": "Hi,\n\nI am fine with the patch for now, changed in this patch:\n\n\tHidden ctor\n\tCleaned up test to use static import consequently\n\n\n\nThe stress test is an testcase, but not automatically executed (you have to explicitely do that with -Dtestcase=...). I think thats wanted, right? Otherwise we should rename, but its also noisy and slow. ",
            "author": "Uwe Schindler",
            "id": "comment-13232090"
        },
        {
            "date": "2012-03-18T10:53:13+0000",
            "content": "Final patch: I removed some code duplication and improved exception handling for the reflection while iterating class tree. Simply  suppressing is a bad idea, as the resulting size would be underdetermined.\n\nI will commit this later this evening and then backport to 3.x. ",
            "author": "Uwe Schindler",
            "id": "comment-13232252"
        },
        {
            "date": "2012-03-18T11:15:18+0000",
            "content": "Thanks Uwe ! ",
            "author": "Shai Erera",
            "id": "comment-13232257"
        },
        {
            "date": "2012-03-18T11:58:33+0000",
            "content": "Javadocs fixes. ",
            "author": "Uwe Schindler",
            "id": "comment-13232261"
        },
        {
            "date": "2012-03-18T14:28:03+0000",
            "content": "Looks good to me, thanks Uwe. ",
            "author": "Dawid Weiss",
            "id": "comment-13232279"
        },
        {
            "date": "2012-03-18T14:59:51+0000",
            "content": "Committed trunk revision: 1302133\n\nI will now backport with deprecations and add CHANGES.txt later! ",
            "author": "Uwe Schindler",
            "id": "comment-13232281"
        },
        {
            "date": "2012-03-18T15:56:11+0000",
            "content": "Patch for 3.x including backwards layer (deprecated instances of RUE + string interning support). MemoryModels were nuked completely (will add comment to backwards changes). ",
            "author": "Uwe Schindler",
            "id": "comment-13232291"
        },
        {
            "date": "2012-03-18T16:20:54+0000",
            "content": "Committed 3.x revision: 1302152\n\nCHANGES.txt committed in revisions: 1302155 (3.x), 1302156 (trunk)\n\nThanks Dawid and Shai!\n\nDawid and I will now look into donating this masterpiece to maybe Apache Commons Lang or similar, as it's of general use. ",
            "author": "Uwe Schindler",
            "id": "comment-13232294"
        },
        {
            "date": "2012-03-22T10:29:18+0000",
            "content": "I've been experimenting a bit with the new code. Field offsets for three classes in a hierarchy with unalignable fields (byte, long combinations at all levels). Note unaligned reordering of byte field in JRockit - nice.\n\n\nJVM: [JVM: HotSpot, Sun Microsystems Inc., 1.6.0_31] (compressed OOPs)\n@12  4 Super.superByte\n@16  8 Super.subLong\n@24  8 Sub.subLong\n@32  4 Sub.subByte\n@36  4 SubSub.subSubByte\n@40  8 SubSub.subSubLong\n@48    sizeOf(SubSub.class instance)\n\nJVM: [JVM: HotSpot, Sun Microsystems Inc., 1.6.0_31] (normal OOPs)\n@16  8 Super.subLong\n@24  8 Super.superByte\n@32  8 Sub.subLong\n@40  8 Sub.subByte\n@48  8 SubSub.subSubLong\n@56  8 SubSub.subSubByte\n@64    sizeOf(SubSub.class instance)\n\n\nJVM: [JVM: J9, IBM Corporation, 1.6.0]\n@24  8 Super.subLong\n@32  4 Super.superByte\n@36  4 Sub.subByte\n@40  8 Sub.subLong\n@48  8 SubSub.subSubLong\n@56  8 SubSub.subSubByte\n@64    sizeOf(SubSub.class instance)\n\nJVM: [JVM: JRockit, Oracle Corporation, 1.6.0_26] (64-bit JVM!)\n@ 8  8 Super.subLong\n@16  1 Super.superByte\n@17  7 Sub.subByte\n@24  8 Sub.subLong\n@32  8 SubSub.subSubLong\n@40  8 SubSub.subSubByte\n@48    sizeOf(SubSub.class instance)\n\n ",
            "author": "Dawid Weiss",
            "id": "comment-13235494"
        },
        {
            "date": "2012-03-22T11:02:33+0000",
            "content": "Thanks for the insight.\n\nWhen thinking about the reordering, I am a littel bit afraid about the \"optimization\" in the shallow sizeOf(Class<?>). This optimiaztion does not recurse to superclasses, as it assumes, that all field offsets are greater than those of the superclass, so finding the maximum does not need to recurse up (so it early exits).\n\nThis is generally true (also in the above printout), but not guaranteed. E.g. JRockit does it partly (it reuses space inside the superclass area to locate the byte from the subclass). In the above example still the order of fields is always Super-Sub-SubSub, but if the ordeing in the JRockit example would be like:\n\n\n@ 8  1 Super.superByte\n@ 9  7 Sub.subByte\n@16  8 Super.subLong\n@24  8 Sub.subLong\n@32  8 SubSub.subSubLong\n@40  8 SubSub.subSubByte\n@48    sizeOf(SubSub.class instance)\n\n\n\nThe only thing the JVM cannot change is field offsets between sub classes (so the field offset of the superclass is inherited), but it could happen that new fields are located between super's fields (see above - it's unused space). This would also allow casting and so on (it's unused space in superclass). Unfortunately with that reordering the maximum field offset in the subclass is no longer guaranteed to be greater.\n\nI would suggest that we remove the \"optimization\" in the shallow class size method. It's too risky in my opinion to underdetermine the size, because the maximum offset in the subclass is < the maximum offset in the superclass.\n\nI hope my explanation was understandable... \n\nDawid, what do you thing, should we remove the \"optimization\"? Patch is easy. ",
            "author": "Uwe Schindler",
            "id": "comment-13235500"
        },
        {
            "date": "2012-03-22T11:09:53+0000",
            "content": "I hope my explanation was understandable... \n\nPerfectly well. Yes, I agree, it's possible to fill in the \"holes\" packing them with fields from subclasses. It would be a nice vm-level optimization in fact! \n\nI'm still experimenting on this code and cleaning/ adding javadocs \u2013 I'll patch this and provide a complete patch once I'm done, ok? ",
            "author": "Dawid Weiss",
            "id": "comment-13235501"
        },
        {
            "date": "2012-03-22T11:11:45+0000",
            "content": "OK. All you have to remove is the if (fieldFound && useUnsafe) check and always recurse. fieldFound itsself can also be removed. ",
            "author": "Uwe Schindler",
            "id": "comment-13235502"
        },
        {
            "date": "2012-03-22T11:17:35+0000",
            "content": "JRockit could even compress like this, it would still allow casting as all holes are solely used by one sub-class:\n\n\n@ 8  1 Super.superByte\n@ 9  1 Sub.subByte\n@10  6 SubSub.subSubByte\n@16  8 Super.subLong\n@24  8 Sub.subLong\n@32  8 SubSub.subSubLong\n@40    sizeOf(SubSub.class instance)\n\n ",
            "author": "Uwe Schindler",
            "id": "comment-13235505"
        },
        {
            "date": "2012-03-22T11:24:20+0000",
            "content": "Maybe it does such things already. I didn't check extensively. ",
            "author": "Dawid Weiss",
            "id": "comment-13235506"
        },
        {
            "date": "2012-03-22T11:26:27+0000",
            "content": "We have to remove the shallow size optimization in 3.x and trunk. ",
            "author": "Uwe Schindler",
            "id": "comment-13235508"
        },
        {
            "date": "2012-03-22T13:20:37+0000",
            "content": "I confirmed that this packing indeed takes place. Wrote a pseudo-random test with lots of classes and fields. Here's an offender on J9 for example (Wild_\n{inheritance-level}\n_\n{field-number}\n):\n\n@24  4 Wild_0_92.fld_0_0_92\n@28  4 Wild_0_92.fld_1_0_92\n@32  4 Wild_0_92.fld_2_0_92\n@36  4 Wild_0_92.fld_3_0_92\n@40  4 Wild_0_92.fld_4_0_92\n@44  4 Wild_0_92.fld_5_0_92\n@48  4 Wild_0_92.fld_6_0_92\n@52  4 Wild_2_5.fld_0_2_5\n@56  8 Wild_1_85.fld_0_1_85\n@64  8 Wild_1_85.fld_1_1_85\n@72    sizeOf(Wild_2_5 instance)\n\n\n\nHotSpot and JRockit don't seem to do this (at least it didn't fail on the example). ",
            "author": "Dawid Weiss",
            "id": "comment-13235570"
        },
        {
            "date": "2012-03-22T13:45:05+0000",
            "content": "Thanks, in that case shallowSizeOf(Wild_2_5.class) would incorrectly return 56 because of the short-circuit - so let's fix this. ",
            "author": "Uwe Schindler",
            "id": "comment-13235577"
        },
        {
            "date": "2012-03-22T14:07:34+0000",
            "content": "Yep, that assumption was wrong \u2013 indeed:\n\nWildClasses.Wild_2_5 wc = new WildClasses.Wild_2_5();\nwc.fld_6_0_92 = 0x1122;\nwc.fld_0_2_5 = Float.intBitsToFloat(0xa1a2a3a4);\nwc.fld_0_1_85 = Double.longBitsToDouble(0xb1b2b3b4b5b6b7L);\nSystem.out.println(ExpMemoryDumper.dumpObjectMem(wc));\n\n\nresults in:\n\n0x0000 b0 3d 6f 01 00 00 00 00 0e 80 79 01 00 00 00 00\n0x0010 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00\n0x0020 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00\n0x0030 22 11 00 00 a4 a3 a2 a1 b7 b6 b5 b4 b3 b2 b1 00\n0x0040 00 00 00 00 00 00 00 00\n\n\nAnd you can see they are reordered and longs are aligned.\n\nI'll provide a cumulative patch of changes in the evening, there's one more thing I wanted to add (cache of fields) because this affects processing speed. ",
            "author": "Dawid Weiss",
            "id": "comment-13235588"
        },
        {
            "date": "2012-03-22T20:59:52+0000",
            "content": "Ok, I admit J9 is fascinating...  How much memory does this take?\n\nclass X {\n  byte a = 0x11;\n  byte b = 0x22;\n}\n\n\nHere is the memory layout:\n\n[JVM: IBM J9 VM, 2.6, IBM Corporation, IBM Corporation, 1.7.0]\n0x0000 00 b8 21 c4 5f 7f 00 00 00 00 00 00 00 00 00 00\n0x0010 11 00 00 00 22 00 00 00\n@16  4 Super.b1\n@20  4 Super.b2\n@24    sizeOf(Super instance)\n\n\n\nI don't think I screwed up anything. It really is 4 byte alignment on all fields. ",
            "author": "Dawid Weiss",
            "id": "comment-13236028"
        },
        {
            "date": "2012-03-23T10:40:54+0000",
            "content": "Don't be scared by the size of this patch \u2013 it contains a lot of generated code in WildClasses.\n\nImprovements:\n\n\tsize estimation is not recursive (which led to stack overflows quite easily on more complex object graphs),\n\tdecreased memory consumption by using a custom impl. of an identity object set.\n\tadded a cache of resolved class information (ref. fields, shallow size).\n\tremoved the optimization of counting only subclass field offsets because fields can be packed (J9).\n\tadded more verbose information about unsupported JVM features. J9 doesn't have the MX bean for example (and does dump this).\n\n\n\nThe above changes also speed up the entire processing. ",
            "author": "Dawid Weiss",
            "id": "comment-13236504"
        },
        {
            "date": "2012-03-23T12:24:10+0000",
            "content": "Added a test case for identity has set, removed constants, removed wild classes. ",
            "author": "Dawid Weiss",
            "id": "comment-13236537"
        },
        {
            "date": "2012-03-23T12:59:29+0000",
            "content": "I think the patch is now fine! I will commit it later and backport to 3.x. ",
            "author": "Uwe Schindler",
            "id": "comment-13236557"
        },
        {
            "date": "2012-03-23T14:29:16+0000",
            "content": "Thanks Uwe. I'll be working in the evening again but if you're faster go ahead and commit it in. ",
            "author": "Dawid Weiss",
            "id": "comment-13236626"
        },
        {
            "date": "2012-03-23T19:17:44+0000",
            "content": "Committed trunk revision: 1304485, 1304513, 1304564\nCommitted 3.x revision: 1304565 ",
            "author": "Uwe Schindler",
            "id": "comment-13236964"
        },
        {
            "date": "2012-03-23T21:47:32+0000",
            "content": "I've been thinking how one can assess the estimation quality of the new code. I came up with this:\n\n\tI allocate an Object[] half the size of estimated maximum available RAM (just to make sure all objects will fit without the need to reallocate),\n\tI precompute shallow sizes for instances of all \"wild classes\" (classes with random fields, including arrays).\n\tI then fill in the \"vault\" array above with random instances of wild classes, summing up the estimated size UNTIL I HIT OOM.\n\tOnce I git OOM I know how much we actually allocated vs. how much space we thought we did allocate.\n\n\n\nThe results are very accurate on HotSpot if one is using serial GC. For example:\n\n[JVM: Java HotSpot(TM) 64-Bit Server VM, 20.4-b02, Sun Microsystems Inc., Sun Microsystems Inc., 1.6.0_29]\nMax: 483.4 MB, Used: 698.9 KB, Committed: 123.8 MB\nExpected free: 240.9 MB, Allocated estimation: 240.8 MB, Difference: -0.05% (113.6 KB)\n\n\n\nIf one runs with a parallel GC things do get out of hand because the GC is not keeping up with allocations (although I'm not sure how I should interpret this because we only allocate; it's not possible to free any space \u2013 maybe there are different GC pools or something):\n\n[JVM: Java HotSpot(TM) 64-Bit Server VM, 20.4-b02, Sun Microsystems Inc., Sun Microsystems Inc., 1.6.0_29]\nMax: 444.5 MB, Used: 655.4 KB, Committed: 122.7 MB\nExpected free: 221.5 MB, Allocated estimation: 174.2 MB, Difference: -21.34% (47.3 MB)\n\n\n\nJRockit:\n\n[JVM: Oracle JRockit(R), R28.1.4-7-144370-1.6.0_26-20110617-2130-windows-x86_64, Oracle Corporation, Oracle Corporation, 1.6.0_26]\nMax: 500 MB, Used: 3.5 MB, Committed: 64 MB\nExpected free: 247.7 MB, Allocated estimation: 249.5 MB, Difference: 0.74% (1.8 MB)\n\n\n\nI think we're good. If somebody wishes to experiment, the spike is here:\nhttps://github.com/dweiss/java-sizeof\n\nmvn test\nmvn dependency:copy-dependencies\njava -cp target\\classes:target\\test-classes:target\\dependency\\junit-4.10.jar \\\n  com.carrotsearch.sizeof.TestEstimationQuality\n\n ",
            "author": "Dawid Weiss",
            "id": "comment-13237172"
        },
        {
            "date": "2012-03-26T08:27:51+0000",
            "content": "For historical records: the previous implementation of RamUsageEstimator was off by anything between 3% (random size objects, including arrays) to 20% (objects smaller than 80 bytes). Again \u2013 these are \"perfect scenario\" measurements with empty heap and max. allocation until OOM, with a serial GC. With a concurrent and parallel GCs the memory consumption estimation is still accurate but it's nearly impossible to tell when an OOM will occur or how the GC will manage the heap space.  ",
            "author": "Dawid Weiss",
            "id": "comment-13238203"
        },
        {
            "date": "2012-03-26T08:32:43+0000",
            "content": "That's true. But you can still get the \"unreleaseable allocation\", so the size of the non-gc-able object graph. If GC does not free the objects after release fast-enough, it will still do it once memory gets low. But the allocated objects with hard refs are not releaseable.\n\nSo I think it's fine for memory requirement purposes. If you want real heap allocation, you must use instrumentation. ",
            "author": "Uwe Schindler",
            "id": "comment-13238206"
        },
        {
            "date": "2012-03-26T08:45:41+0000",
            "content": "I didn't say it's wrong \u2013 it is fine and accurate. What I'm saying is that it's not really suitable for predictions; for answering questions like: how many objects of a given type/ types can I allocate before an OOM hits me? It doesn't really surprise me that much, but it would be nice. For measuring already allocated stuff it's more than fine of course. ",
            "author": "Dawid Weiss",
            "id": "comment-13238208"
        }
    ]
}