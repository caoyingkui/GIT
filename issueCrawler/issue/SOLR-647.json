{
    "id": "SOLR-647",
    "title": "Do SolrCore.close() in a refcounted way",
    "details": {
        "affect_versions": "1.3",
        "status": "Closed",
        "fix_versions": [
            "1.3"
        ],
        "components": [],
        "type": "Bug",
        "priority": "Major",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "The method SolrCore.close() directly closes the core . It can cause Exceptions for in-flight requests. The close() method should just do a decrement on refcount and the actual close must happen when the last request being processed by that core instance is completed",
    "attachments": {
        "SOLR-647.patch": "https://issues.apache.org/jira/secure/attachment/12386940/SOLR-647.patch",
        "refcount_example.patch": "https://issues.apache.org/jira/secure/attachment/12388069/refcount_example.patch",
        "solr-647.patch": "https://issues.apache.org/jira/secure/attachment/12387659/solr-647.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12617434",
            "date": "2008-07-28T14:17:10+0000",
            "content": "Yonik, what do you feel about adding to to 1.3? Although it's immediate use is in SOLR-561 but it is still an unsafe existing API call. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12617435",
            "date": "2008-07-28T14:29:13+0000",
            "content": "I took a quick peek.... looks like there are probably race conditions.\nA core could be obtained in thread A, then decRef() could be called in thread B that triggers a real close, then incRef() would be called in thread A (oops). "
        },
        {
            "author": "Noble Paul",
            "id": "comment-12617760",
            "date": "2008-07-29T10:24:25+0000",
            "content": "I hope this fixes the race condition  "
        },
        {
            "author": "Henri Biestro",
            "id": "comment-12620276",
            "date": "2008-08-06T15:08:25+0000",
            "content": "Looking at both versions of the patch, it seems you did not upload the intended one.. "
        },
        {
            "author": "Henri Biestro",
            "id": "comment-12620331",
            "date": "2008-08-06T17:27:08+0000",
            "content": "Being hit by the same core issue swapping/closing cores, here is another take at it. "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12620416",
            "date": "2008-08-06T20:27:30+0000",
            "content": "Quick glance suggests it needs unit tests. "
        },
        {
            "author": "Henri Biestro",
            "id": "comment-12620441",
            "date": "2008-08-06T21:55:15+0000",
            "content": "Will do (tomorrow); might be the opportunity to align EmbeddedSolrServer & SolrDispatchFilter behaviors. "
        },
        {
            "author": "Henri Biestro",
            "id": "comment-12620572",
            "date": "2008-08-07T09:43:17+0000",
            "content": "A few modifications to make things (hopefully) a little clearer & tests (single & multi threaded).\nThis new patch version solely deals with reference counting implementation (not its usage).\nSolrDispatchFilter/EmbeddedSolrServer should be patched through solr-545.\nCoreDescriptor (the reloadCore() method) might be better patched through solr-561 (this is easy to reintroduce if needed though). "
        },
        {
            "author": "Henri Biestro",
            "id": "comment-12620764",
            "date": "2008-08-07T21:53:25+0000",
            "content": "Hopefully last version of it.\nI goofed the MT test on the previous one.\nRe-added CoreDescriptor.reloadCore().\nNote that the same code is included in solr-545. "
        },
        {
            "author": "Henri Biestro",
            "id": "comment-12620997",
            "date": "2008-08-08T18:07:35+0000",
            "content": "new version based on Yonik's comment in solr-545. "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12621597",
            "date": "2008-08-11T20:57:45+0000",
            "content": "This doesn't compile.  The TimeUnit.MINUTES in SolrCoreTest is a 1.6 constant.\n "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12621598",
            "date": "2008-08-11T20:58:58+0000",
            "content": "But, I changed it to awaitTermination(60, TimeUnit.SECONDS) and that's just fine...   "
        },
        {
            "author": "Henri Biestro",
            "id": "comment-12621629",
            "date": "2008-08-11T22:08:39+0000",
            "content": "fixed 1.6 dependency (sorry & thanks Grant);\nupdated to trunk;\nfixed a bug in SolrDispatchFilter (Multicore.getAdminCore can return a null core);\nintroduced calls to acquire/release instead and modified EmbeddedSolrServer (for completeness). "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12621812",
            "date": "2008-08-12T13:23:30+0000",
            "content": "I'd like to see some more documentation on this.  Namely, when should SolrCore.Reference be used, etc.  This may just be for my own edification.  For instance, what's the relationship in MultiCore between getCore and acquireCore and openCore?  (Since openCore just calls acquireCore w/ a null reference, we probably should just call it acquireCore as well.)\n\nAlso, when do would I call Reference.release() versus core.close()?\n\nHow does CoreDescriptor.reloadCore factor in?   I don't see that it is used.  Why would I call that instead of MultiCore.reload()?\n\nPart of these questions may just be bigger questions related to Multicore all together. "
        },
        {
            "author": "Noble Paul",
            "id": "comment-12621817",
            "date": "2008-08-12T13:47:49+0000",
            "content": "How does CoreDescriptor.reloadCore factor in? I don't see that it is used. Why would I call that instead of MultiCore.reload()?\n\nHow else can I reload the core in a single core deployment? "
        },
        {
            "author": "Henri Biestro",
            "id": "comment-12621837",
            "date": "2008-08-12T14:47:37+0000",
            "content": "\nGrant;\ngetCore() does not protect the core from being closed by another thread (it must either be protected by another mean or earlier or it does not matter).\n\nFor the other cases, calls should be used in pairs with the following convention; if you call an \"open\", you should call a \"close\", if you call an \"acquire\", you should call a \"release\".\n\nopenCore()/openAdminCore() do protect from the core from a // close and core.close() should be used to decrease the refcount.\nacquireCore()/acquireAdminCore() use a SolrCore.Reference and decreasing the refcount should be done through the ref via ref.release().\n\nThe only difference between openCore()/close() or acquireCore()/release() is the usage of a reference which is just a convenience (at least to me: avoiding to test for null, assigning to final, etc).\n\nHope this makes sense. "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12621849",
            "date": "2008-08-12T15:12:17+0000",
            "content": "\nHow else can I reload the core in a single core deployment?\n\nIn email, I said, \"OK, I'll buy that, maybe I just don't get Multicore/Single Core relationship.  Also, reload is not used anywhere and we've never had the notion of reloading in the single core case, AFAICT.\"\n\nBut, thinking about it some more, I guess I don't.  The descriptor up until this patch, was merely a container for storing core information, hence the name.  Now all of a sudden it has reload capabilities (but, it doesn't have open/close capabilities to go with it) so it just doesn't fit in my mind. "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12621853",
            "date": "2008-08-12T15:32:16+0000",
            "content": "Henri,\n\nAt a minimum, all that should be documented, but I must admit to still being confused (but I'm no expert in the multicore stuff so, please bear with me)\n\n\ngetCore() does not protect the core from being closed by another thread (it must either be protected by another mean or earlier or it does not matter).\n\nYes, but there appears to be mixed uses, the MultiCoreHandler uses getCore() in places, while the SolrDispatchFilter uses the Reference.  Isn't it possible for the core to then be closed behind the MultiCoreHandler? "
        },
        {
            "author": "Henri Biestro",
            "id": "comment-12621867",
            "date": "2008-08-12T16:06:55+0000",
            "content": "Grant,\n\nAt a minimum, all that should be documented\n\nI'll adapt the previous comments accordingly to make the Javadoc more obvious.\n\nthe MultiCoreHandler uses getCore() in places, while the SolrDispatchFilter uses the Reference\n\nGood catch; the admin core (the one used to generate output) is protected but is this enough?\nThe MultiCoreHandler only deals with CoreDescriptor (not SolrCore); it does not perform \"real\" queries although getStatus comes close to it.\nHowever, it would seem preferable to avoid manipulating the (multicore) cores map while we are are processing such requests.\n\n I'll fix it in the next upload.\nThanks for reviewing this. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12621900",
            "date": "2008-08-12T17:49:19+0000",
            "content": "It seems like some simplifications could be made... see attached refcount_example.patch.\n\nI think we need to be able to describe in simple terms how the mechanism works:\nCores are created with a reference count of 1 and put in multicore.  As long as a core can\nbe obtained from the map, it will have at least a reference count of 1.  Thus, if we increment the core's reference during a time when we know that no other core is modifying multicore, we know we have a core that is safe from being asynchronously closed.\n\nTo destroy a core, simply remove it from the map and call close on it.\n\nThere are other issues that are still a bit muddled IMO... like the whole role of CoreDescriptor. "
        },
        {
            "author": "Noble Paul",
            "id": "comment-12621909",
            "date": "2008-08-12T18:07:57+0000",
            "content": "This patch is very clear as to what it is doing (and simple). \n "
        },
        {
            "author": "Henri Biestro",
            "id": "comment-12622568",
            "date": "2008-08-14T14:40:33+0000",
            "content": "My apologies to all for cluttering the issue. \n\nNew simplified version based on Yonik's example for trunk 685913 (post solr-695 commit), dont let the patch size fool you:\nCoreContainer.getCore() & CoreContainer.getAdminCore() now return an incref-ed (\"opened\") core;\ncore.close() must be called when these 2 have been used.\nSolrCore.Reference is gone.\n\nSolrCore.open() & SolrCore.close() method are kept because we can retrieve cores in 3 \"close-unprotected\" ways:\n1 - a call to CoreDescriptor.getCore(), descriptors that can be retrieved through CoreContainer.getCoreDescriptors())\n2 - a list of close-unprotected cores through CoreContainer.getCores().\n3 - SolrCore.getCore() - which is deprecated\nThe first 2 can be used in a user-defined filter/servlet after the SolrDispatchFilter falls through the filter-chain, the CoreContainer being\nset as an attribute of the request (\"org.apache.solr.CoreContainer\"). \n\nBecause of this, we are not always synchronized by the CoreContainer#cores when we incref/decref.\nWe can thus try to open() a core which is closed and cant use a simple refCount.incrementAndGet().\nThus the refCount.get()/refCount.compareAndSet() pattern in both open & close.\n\nThe TestHarness is modified to always create a CoreContainer that contains the \"unnamed\" core so testCoreMT uses\nCoreContainer.getCore(\"\").\nAlso touched some tests that were using SolrCore.getCore() when they can use the TestHarness core. "
        },
        {
            "author": "Noble Paul",
            "id": "comment-12622575",
            "date": "2008-08-14T15:21:15+0000",
            "content": "I fail to see the need for this code in SolrCore#close()\n\n    int count;\n    do {\n      count = refCount.get();\n      if (count <= 0)\n        return;\n    } while (!refCount.compareAndSet(count, count - 1));\n\n\n\nIf you do refCount.decrementAndGet() it should be fine. \n\nsimilarly in SolrCore$open() also\n\nyou can do a refCount.incrementAndGet() and will be fine. \nWhat you have written is a duplication of code in AtomicInteger\n\nEven the RefCounted class does increment and decrement in the same way\n\nYonik's patch does it simply and I do not see anything wrong with that. "
        },
        {
            "author": "Henri Biestro",
            "id": "comment-12622579",
            "date": "2008-08-14T15:30:52+0000",
            "content": "Based on Ryan's comment, simplified the patch to strictly focus on the matter at hand. "
        },
        {
            "author": "Henri Biestro",
            "id": "comment-12622583",
            "date": "2008-08-14T15:41:51+0000",
            "content": "About the SolrCore.open() & close():\n\nIf we were to do an incrementAndGet(), we could end up opening a closed core;\nWe thus must check the refcount is not <=0 first.\nThe close could use a decrementAndGet() but the current code ensures the count will never go < 0 and is symmetrical to open.\nIn both cases, it is the test in between the get() & compareAndSet() that makes the whole difference with {in,de]crementAndGet.\n\nMy understanding of Yonik's version is that, as a premise, opening a core is always performed under the CoreContainer#cores synchronized protection; as I explained in a previous comment, the assumption can not be strictly met.  "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12622586",
            "date": "2008-08-14T15:48:14+0000",
            "content": "he close could use a decrementAndGet() but the current code ensures the count will never go < 0.\n\nI don't think we should cover this error case up since it could lead to premature closure in other cases.\nI think we should do a simple decrementAndGet() followed by a logged error if the current count is less than zero. "
        },
        {
            "author": "Henri Biestro",
            "id": "comment-12622592",
            "date": "2008-08-14T16:13:05+0000",
            "content": "Yonik;\nAbout the close(), you're right: the refcount < 0 being an error, shouldn't we go all the way and throw a runtime exception ?\nAre you in agreement about open()? "
        },
        {
            "author": "Henri Biestro",
            "id": "comment-12622610",
            "date": "2008-08-14T17:18:31+0000",
            "content": "updated to reflect Yonik's last suggestion.\nfixed test attempting to close closed core.\n(throwing an exception was useful for quick detection). "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12622613",
            "date": "2008-08-14T17:26:41+0000",
            "content": "Are you in agreement about open()?\n\nYes, if cores obtained through other methods need to be open for some reason, then open() would need to be called.  I'm not sure if we have any cases like that. "
        },
        {
            "author": "Noble Paul",
            "id": "comment-12622614",
            "date": "2008-08-14T17:31:25+0000",
            "content": "About the close(), you're right: the refcount < 0 being an error, shouldn't we go all the way and throw a runtime exception ?\n refcount < 0 is an error . but should it throw an exception?  I am not too sure. logging a severe error should be fine. because that should not be a reason to crash a server\n\nAre you in agreement about open()?\neven open() does not need a compareAndSet. just do a refCount.incrementAndget(). if count <=1 return null .because it is already closed or being closed . "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12622618",
            "date": "2008-08-14T17:37:51+0000",
            "content": "refcount < 0 is an error . but should it throw an exception? I am not too sure. logging a severe error should be fine. because that should not be a reason to crash a server\n\nRight... on one hand an exception brings more visibility, but on the other hand it's a recoverable error that's not necessarily tied to the request that would get the exception.\n\neven open() does not need a compareAndSet. just do a refCount.incrementAndget(). if count <=1 return null .because it is already closed or being closed .\n\nAnd then if another thread calls open() at the same time, count will be 2 and it would incorrectly return a closing core.  If open() is needed, Henri has the right impl there. "
        },
        {
            "author": "Otis Gospodnetic",
            "id": "comment-12622628",
            "date": "2008-08-14T18:14:25+0000",
            "content": "Right... on one hand an exception brings more visibility, but on the other hand it's a recoverable error that's not necessarily tied to the request that would get the exception.\n\nShould we then do:\nLOG.severe(\"XYZ happened.  Please report this problem on solr-user@lucene.apache.org\"); "
        },
        {
            "author": "Noble Paul",
            "id": "comment-12622632",
            "date": "2008-08-14T18:27:21+0000",
            "content": "The CoreContainer#create(CoreDescriptor dcore)  must close the old core after creating the new one "
        },
        {
            "author": "Henri Biestro",
            "id": "comment-12622735",
            "date": "2008-08-14T23:20:41+0000",
            "content": "Yes, if cores obtained through other methods need to be open for some reason, then open() would need to be called.\nI'm not sure if we have any cases like that.\nNo, we don't have any cases today. It could have been useful to someone implementing another filter or servlet.\nSince the same effect can be obtained with:\n\nCoreDescriptor dcore;\nCoreContainer container;\n...\nSolrCore opened = container.getCore(dcore.getName());\n\n\n\nopen() can just be incrementAndGet(). (finally!)\n\nLOG.severe(\"XYZ happened. Please report this problem on solr-user@lucene.apache.org\")\nSeems to be the consensus; updated.\n\nThe CoreContainer#create(CoreDescriptor dcore) must close the old core after creating the new one \nCorrect, fixed. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12623000",
            "date": "2008-08-15T19:48:35+0000",
            "content": "I'm thinking of changing the cores map to <String,SolrCore> (from <String,CoreDescriptor>)\nand removing getCore() from CoreDescriptor.  Thoughts? "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12623001",
            "date": "2008-08-15T19:53:23+0000",
            "content": "Also, is there any reason not to allow the same core to be registered more than once if desired?  It really seems like CoreContainer should just map from a String to a SolrCore and not worry about some of the other stuff. "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-12623003",
            "date": "2008-08-15T20:08:38+0000",
            "content": "I'm thinking of changing the cores map to <String,SolrCore> (from <String,CoreDescriptor>) and removing getCore() from CoreDescriptor. Thoughts? \n\nsince every core has a CoreDescriptor, this seems much cleaner then have the (existing) double link.\n\n\nis there any reason not to allow the same core to be registered more than once if desired?\n\nsounds good. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12623007",
            "date": "2008-08-15T20:27:56+0000",
            "content": "FYI, I'm also overhauling some of the synchronization... the lock is held far too long in some cases (like reload when it's held the whole time a new core is being created). "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12623019",
            "date": "2008-08-15T20:54:51+0000",
            "content": "Also, persistFile looks like it would take enough time that I'm going to change it to synchronize on a separate lock so it doesn't block requests in the meantime. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12623142",
            "date": "2008-08-16T16:50:08+0000",
            "content": "Here's an updated patch:\n\n\tcores is a Map<String,SolrCore>\n\tno prohibition of adding a SolrCore to the CoreContainer multiple times (to be able to access it from multiple URLs, for back compatible migration for example)\n\n\n\nI was going to remove the SolrCore name altogether.... but things like JMX and logging use it.\nThat's a weakness in both the way multicore worked (core swap wouldn't swap JMX) and the current patch (core name is independent of how it's mapped via CoreContainer).\n\nOne resolution would be to have a callback on SolrCore whenever it's name is changed, so JMX and logging strings could be appropriately adjusted. "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-12623173",
            "date": "2008-08-17T01:07:59+0000",
            "content": "I was going to remove the SolrCore name altogether.... but things like JMX and logging use it.\n\nCan we remove it and always access the name via the CoreDescriptor?  Having a name on the core made sense before we added the descriptor... "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12623190",
            "date": "2008-08-17T13:22:54+0000",
            "content": "Here's a slight update:\n\n\tremoves the SolrCore finalizer to prevent too many closes exception (we could do a refcount check too)\n\tcalls SolrCore.setName() when a core is added or renamed in the CoreContainer (it was just too wierd to do a core swap and not have the names change).  This does not affect JMX.\n\n\n\nI was going to remove the SolrCore name altogether.... but things like JMX and logging use it.\n\nCan we remove it and always access the name via the CoreDescriptor? Having a name on the core made sense before we added the descriptor...\n\nIf we did want to change JMX or other things on a name change, it seems like the call needs to be on the SolrCore.  Currently this does change the logging string too (probably good for avoiding confusion on a core swap)\n\nUnless there are objections, I think this is close enough to commit soon and then propose smaller patches off of trunk. "
        },
        {
            "author": "Noble Paul",
            "id": "comment-12623201",
            "date": "2008-08-17T15:56:30+0000",
            "content": "Also, is there any reason not to allow the same core to be registered more than once if desired? \n\nHow will SolrCore#getCoreDescriptor() work. what will it return?\n\nshould the getCore() have synchronized block? \n\ncan we manage with a ConcurrentHashMap? A lock to be obtained per request looks like too much of a price . The only problem with concurrent map is that if you remove while an iteration is going on you may get an exception (correct me if I am wrong). If we can have a separate lock for just that we can have synchronization only in those places and we can spare the getCore()\n "
        },
        {
            "author": "Henri Biestro",
            "id": "comment-12623204",
            "date": "2008-08-17T16:27:44+0000",
            "content": "Small err that  would affect reload() in CoreContainer.register, ~line 261, it seems this should be:\n\nlog.info( \"replacing core: \"+name );\nif (!returnPrev) {\n        old.close(); // not core.close()\n}\n\n\n\nHarmless, the \"alias\" attribute feature is folded into \"name\" so:\n\nString aliasesStr = DOMUtil.getAttr(node, \"aliases\", null);\n\n\ncan go. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12623379",
            "date": "2008-08-18T15:30:11+0000",
            "content": "How will SolrCore#getCoreDescriptor() work. what will it return?\n\nThe original core descriptor (the original name).\n\nshould the getCore() have synchronized block?\n\nCoreContainer.getCore() does.\nI removed CoreDescriptor.getCore()\n\ncan we manage with a ConcurrentHashMap? A lock to be obtained per request looks like too much of a price .\n\nIt could be reworked in the future, but a single synchronized map lookup per top-level request is certainly nothing to worry about - there are probably at least hundreds of synchronized calls per average request. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12623380",
            "date": "2008-08-18T15:32:40+0000",
            "content": "I've committed this patch.\nThere is probably some more multicore work to be done, but they can get their own issues. "
        }
    ]
}