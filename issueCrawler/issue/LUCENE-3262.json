{
    "id": "LUCENE-3262",
    "title": "Facet benchmarking",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [
            "modules/benchmark",
            "modules/facet"
        ],
        "type": "New Feature",
        "fix_versions": [],
        "affect_versions": "None",
        "resolution": "Unresolved",
        "status": "Open"
    },
    "description": "A spin off from LUCENE-3079. We should define few benchmarks for faceting scenarios, so we can evaluate the new faceting module as well as any improvement we'd like to consider in the future (such as cutting over to docvalues, implement FST-based caches etc.).\n\nToke attached a preliminary test case to LUCENE-3079, so I'll attach it here as a starting point.\n\nWe've also done some preliminary job for extending Benchmark for faceting, so I'll attach it here as well.\n\nWe should perhaps create a Wiki page where we clearly describe the benchmark scenarios, then include results of 'default settings' and 'optimized settings', or something like that.",
    "attachments": {
        "LUCENE-3262.patch": "https://issues.apache.org/jira/secure/attachment/12497802/LUCENE-3262.patch",
        "TestPerformanceHack.java": "https://issues.apache.org/jira/secure/attachment/12485546/TestPerformanceHack.java",
        "CorpusGenerator.java": "https://issues.apache.org/jira/secure/attachment/12485545/CorpusGenerator.java"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2011-07-07T07:55:04+0000",
            "content": "I've attached a second shot at faceting performance testing. It separates the taxonomy generation into a CorpusGenerator (maybe similar to the RandomTaxonomyWriter that Robert calls for in LUCENE-3264?).\n\nProper setup of faceting tweaks for the new faceting module is not done at all and not something I find myself qualified for. ",
            "author": "Toke Eskildsen",
            "id": "comment-13061114"
        },
        {
            "date": "2011-10-04T10:58:51+0000",
            "content": "I am working on a patch for this, much in the lines of the Solr benchmark patch in SOLR-2646.\nCurrently the direction is:\n\n\n\tAdd to PerfRunData:\n\t\n\t\tTaxonomy Directory\n\t\tTaxonomy Writer\n\t\tTaxonomy Reader\n\t\n\t\n\n\n\n\n\tAdd tasks for manipulating facets and taxonomies:\n\t\n\t\tcreate/open/commit/close Taxonomy Index\n\t\topen/close Taxonomy Reader\n\t\tAddDocWith facets\n\t\n\t\n\n\n\n\n\tFacetDocMaker will also build the categories into the document\n\tFacetSource will bring back categories to be added to current doc\n\n\n\n\n\tReadTask will be extended to also support faceted search.\n  This is different from the Solr benchmark approach, where a SolrSearchTask is not extending ReadTask but rather extending PerfTask.\n  Not sure yet if this is the way to go - still work to be done here.\n\n\n\nShould have a start patch in a day or two. ",
            "author": "Doron Cohen",
            "id": "comment-13120003"
        },
        {
            "date": "2011-10-05T16:00:47+0000",
            "content": "Patch (3x)  with working facets indexing benchmark.\nIt follows the outline above, except that: \n\n\tthere is no FacetDocMaker - only FacetSource\n\tthere is no AddDocWithFacet - instead, AddDoc takes an additional config param: with.facet\n\n\n\n'ant run-task -Dtask.alg=conf/facets.alg' will run an algorithm that indexes facets.\n\nNot ready to commit yet - need some testing and docs. Also, only covers indexing for now, though perhaps search with facets can go in a separate issue. ",
            "author": "Doron Cohen",
            "id": "comment-13121071"
        },
        {
            "date": "2011-10-06T05:14:56+0000",
            "content": "Patch looks good ! I have a couple of initial comments:\n\n\n\tfacets.alg: as I often find these .alg files as examples, I think it would be good if it declares facet.source (to random) explicitly.\n\n\n\n\n\tOpenTaxonomyReaderTask: I see that since PerfRunData incRef() the incoming taxonomy, you decRef(). I also see that setIndexReader behaves the same way. But I find it confusing. Personally, since this is not an application, I don't think we should 'hold a reference to IR/LTR just in case the one who set it closes it'. But if we do that, can we at least document on setIR/LTR that this is the case? I can certainly see myself opening IR/LTR, setting on PerfRunData without decRef()/close(). It would not occur to me that I should ...\n\n\n\n\n\tThe abstraction of ItemSource is nice. But it's jdocs still contain content.source.. Since we're not committed to backwards compatibility in benchmark, and in the interest of clarity, perhaps we should rename them to item.source.?\n\n\n\n\n\tItemSource.resetInputs has a @SuppressWarnings(\"unused\") \u2013 is it a leftover from when it was private?\n\n\n\n\n\tIn PerfRunData ctor you do a Class.forName using the String name of RandomFacetSource. Why not use RandomFacetSource.class.getName()?\n\n\n\nLooks very good. Now with FacetSource we can generate facets per the case we want to test (dense hierarchies, Zipf'ian ...) ",
            "author": "Shai Erera",
            "id": "comment-13121728"
        },
        {
            "date": "2011-10-06T11:10:50+0000",
            "content": "Thanks for reviewing Shai!\n\n\n\tfacets.alg: I agree, and added that specific facet source setting. With also modified the algorithm to have several rounds, some with facets, some without, so the effect of adding facets on performance is measured.\n\n\n\n\n\tPFD.readers.incRef() - once the task (e.g. OpenReaderTask) opened the reader that task is gone and the reader really is maintained by the PFD, therefore IMO it is important that the PFD maintains its ref count as it does today. I agree that more documentation for this can help and added something in this spirit to both setReader()'s:\n\n\n\n\n  /**\n   * Set the taxonomy reader. Takes ownership of that taxonomy reader, that is,\n   * internally performs taxoReader.incRef(). \n   * @param indexReader The indexReader to set.\n   */\n  public synchronized void setTaxonomyReader(TaxonomyReader taxoReader) throws IOException {\n\n  }\n\n  /**\n   * Set the index reader. Takes ownership of that index reader, that is,\n   * internally performs indexReader.incRef(). \n   * @param indexReader The indexReader to set.\n   */\n  public synchronized void setIndexReader(IndexReader indexReader) throws IOException {\n  }\n\n\n\n\n\tItemSource and config props \"source.xyz\" - I am afraid there might be algorithms out there that will silently stop working, as the props names are not safe types or something like that. So I would rather to not alter these property names. Instead, following your comment, I renamed ItemSource to ContentItemsSource which is still extended by both ContentSource and FacetSource. So it is not that bad now that the property names start with \"content.\" (these properties apply to all content-item-sources - that is both doc-content and facets).\n\n\n\n\n\tItemSource.resetInputs @SuppressWarnings(\"unused\") - this is for the IOException which is not really thrown by that code (though it might be thrown by subclasses). Perhaps just a misconfiguration of my IDE? (I assume you have that warning disabled or stg?)\n\n\n\n\n\tPerfRunData Class.forName on String rather than class.getName() - this is in fact the code pattern for all reflection actions in PerfRunData, so I just repeated for the new code whatever was there for the existing code. However, in fact, I thought about the same thing when adding this code. I think the difference is that if config contains a specification of another class, the default class would not even be loaded when using strings, but it will be loaded (though not used) when using Class.getName(). It is not a big performance issue, but it does seem \"cleaner\" to not load classes that are not going to be used. In any case, if we would like to change that, should revisit all the .forName(String) of default impls in the benchmark (and I think there are a few) and it seems to not belong to this issue.\n\n\n\nThanks for the review, working on a new patch - there are several copy/paste errors in the code where a CloseTaxonomyReader by mistake sets the PFD IndexReader to null... ",
            "author": "Doron Cohen",
            "id": "comment-13121844"
        },
        {
            "date": "2011-10-06T11:21:41+0000",
            "content": "ItemSource.resetInputs\n\nI don't have that warning turned on in Eclipse. I disabled it for exactly this reason .\n\nItemSource rename\n\nThe new name is ok, and the properties better fit it. BTW, if you wanted to have the .algs out there to not silently fail, you could add some code to setConfig that checks for these outdated properties, and throw a proper exception. But I'm ok with the solution you chose.\n\nPFD.readers.incRef()\n\nThe javadocs are good. I'd also add \"<b>NOTE:</b> if you no longer need that IndexReader/TaxoReader, you should decRef()/close() after calling this method\". Otherwise, the IR/TR will just stay open ... ",
            "author": "Shai Erera",
            "id": "comment-13121852"
        },
        {
            "date": "2011-10-06T16:07:15+0000",
            "content": "Updated patch with a test, more javadocs, and a comment as Shai suggested.\n\nI think this is ready to commit.\n\nMore tests are needed, and also Search with facets is missing, but that can go in a separate issue. ",
            "author": "Doron Cohen",
            "id": "comment-13122032"
        },
        {
            "date": "2011-10-06T18:24:14+0000",
            "content": "I think this is ready to commit.\n\n+1. Perhaps just add a CHANGES entry?\n\nbut that can go in a separate issue\n\nI think it's better if we resolve it in that issue, and maybe rename the issue to \"Facet benchmarking framework\". You can still commit the current progress because it is 'whole' - covering the indexing side. I've worked on issues before that had several commits, so this will not be the first one.\n\nWe should also run some benchmark tests, describing clearly the data sets, but this can be done under a separate issue. ",
            "author": "Shai Erera",
            "id": "comment-13122134"
        },
        {
            "date": "2011-10-07T07:14:35+0000",
            "content": "changes entry\nRight, I always forget to include it in the patch, and add it only afterwords, should change that...\n\nAlso, I am not comfortable with the use of a config property in AddDocTask to tell that facets should be added. Seems too implicit to me, all of the sudden... So I think it would be better to refactor the doc creation in AddDoc into a method, and add AddFacetedDocTask that extends AddDoc and overrides the creation of the doc to be added, calling super, and then add the facets into it. ",
            "author": "Doron Cohen",
            "id": "comment-13122580"
        },
        {
            "date": "2011-10-07T07:53:32+0000",
            "content": "Actually, since the doc is created at setup() it is sufficient to make the doc protected (was private). Also that with.facets property is useful for comparisons, so I kept it (now used only in AddFacetedDocTask) but modified its default to true. ",
            "author": "Doron Cohen",
            "id": "comment-13122598"
        },
        {
            "date": "2011-10-07T13:19:23+0000",
            "content": "Also that with.facets property is useful for comparisons\n\nWhat do you mean? Someone can use AddFacetedDocTask w/ and w/o facets? What for? (sorry, but you didn't post a patch, so I cannot see what this is about) ",
            "author": "Shai Erera",
            "id": "comment-13122770"
        },
        {
            "date": "2011-10-07T20:06:33+0000",
            "content": "Someone can use AddFacetedDocTask w/ and w/o facets? What for? \n\nIt is useful for specifying the property like this:\n\n\nwith.facets=facets:true:false\n...\n{ \"MAddDocs\" AddFacetedDoc > : 400\n\n\n\nand then getting in the report something like this:\n\n\n------------> Report sum by Prefix (MAddDocs) and Round (4 about 4 out of 42)\nOperation    round facets   runCnt   recsPerRun        rec/s  elapsedSec\nMAddDocs_400     0   true        1          400       246.61        1.62\nMAddDocs_400 -   1  false -  -   1 -  -  -  400 -   1,801.80 -  -   0.22\nMAddDocs_400     2   true        1          400       412.80        0.97\nMAddDocs_400 -   3  false -  -   1 -  -  -  400 -   2,139.04 -  -   0.19\n\n ",
            "author": "Doron Cohen",
            "id": "comment-13123134"
        },
        {
            "date": "2011-10-07T20:08:19+0000",
            "content": "Updated patch according to Shai's comments and with AddFacetedDoc task. ",
            "author": "Doron Cohen",
            "id": "comment-13123137"
        },
        {
            "date": "2011-10-07T21:13:25+0000",
            "content": "Ahh, forgot about iterations. It does indeed look useful then.\n\nPerhaps mention facet.source in AddFacetedDocTask?\n\nI'm +1 for committing the current progress, but keep this issue open for the search side (to complete the framework). ",
            "author": "Shai Erera",
            "id": "comment-13123205"
        },
        {
            "date": "2011-10-09T09:26:06+0000",
            "content": "Doron, great patch!\n\nI ran it and was somewhat surprised at the large overhead of the facet indexing. Digging deeper, I found the number of random facets to be 1-120 per document, with depth of 1-8. I believe those are overkill requirements. I reduced those to 1-20 per document with depth of 1-3 and got results I could live with.\nThose number are scenario dependent but I think most cases I encountered are closer to my proposed numbers. What do you think?\n\nAlso, I changed the alg to consume the entire content source.\n\nI would suggest renaming max.facet.length (in the alg) & maxFacetLengh (in the code) to max.facet.depth and maxFacetDepth. Depth seems more appropriate. \n\nOther than that - I'm thrilled to have a working benchmark with facets - thanks! ",
            "author": "Gilad Barkai",
            "id": "comment-13123650"
        },
        {
            "date": "2011-10-09T09:36:05+0000",
            "content": "Those number are scenario dependent but I think most cases I encountered are closer to my proposed numbers\n\nI think we should maybe have a Wiki page or something with several .alg files that test different scenarios. I don't think that 1-120 is an example we shouldn't test. Rather, we should describe, either in a Wiki or a JIRA issue, the performance results for each scenario. And if the results are suspicious for a particular scenario, dig deeper and understand why.\n\nSo given that you know the numbers from above were run with that many facets per document, do the numbers make sense? Or you still think they're high?\n\nI would suggest renaming max.facet.length (in the alg) & maxFacetLengh (in the code) to max.facet.depth and maxFacetDepth\n\n+1. ",
            "author": "Shai Erera",
            "id": "comment-13123654"
        },
        {
            "date": "2011-10-09T16:03:25+0000",
            "content": "I reduced those to 1-20 per document with depth of 1-3 and got results I could live with.\n\nI agree, tried this too now and the comparison is more reasonable. \nPerhaps what are reasonable numbers (for #facets/doc and their depth) is debatable, but I agree that 200 facets per document is too many.\n\nChanging the defaults to 20/3 and preparing to commit.  ",
            "author": "Doron Cohen",
            "id": "comment-13123714"
        },
        {
            "date": "2011-10-09T17:28:18+0000",
            "content": "Committed to 3x in r1180637, thanks Gilad!\nNow porting to trunk, it is more involved than anticipated, because of contrib/modules differences.\nManaged to make the tests pass, and the benchmark alg of choice to run.\nHowever I noticed that in 3x that alg - when indexing reuters - added the entire collection, that is 21578 docs, while in trunk it only added about 400 docs.  Might be something in my set-up, digging... ",
            "author": "Doron Cohen",
            "id": "comment-13123735"
        },
        {
            "date": "2011-10-09T18:03:10+0000",
            "content": "After manually removing benchmark/\n{work,temp}\n reuters collection was correctly extracted and in trunk the alg runs same as in 3x.\nCommitted to trunk: r1180674.\nKeeping issue open to handle faceted search benchmarking. ",
            "author": "Doron Cohen",
            "id": "comment-13123742"
        }
    ]
}