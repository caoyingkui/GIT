{
    "id": "SOLR-10515",
    "title": "Persist intermediate trigger state in ZK to continue tracking information across overseer restarts",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [
            "SolrCloud"
        ],
        "type": "Sub-task",
        "fix_versions": [
            "7.0"
        ],
        "affect_versions": "None",
        "resolution": "Fixed",
        "status": "Resolved"
    },
    "description": "The current trigger design is simplistic and keeps all the intermediate state in memory. But this presents two problems when the overseer itself fails:\n\n\tWe lose tracking state such as which node was added before the overseer restarted\n\tA nodeLost trigger can never really fire for the overseer node itself\n\n\n\nSo we need a way, preferably in the trigger API itself to save intermediate state or checkpoints so that it can seamlessly continue on overseer restarts.",
    "attachments": {
        "SOLR-10515.patch": "https://issues.apache.org/jira/secure/attachment/12869670/SOLR-10515.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2017-05-20T07:15:48+0000",
            "content": "Thanks Andrzej. I reviewed the changes at jira/SOLR-10515 branch. A few comments:\n\n\tThe ScheduledTrigger.run does not take care of the return value of the triggerFired() method. So when a event is being replayed, and there are pending actions, the event will be lost because it has already been polled from the queue. We should peek from the queue, attempt to fire the listener and poll only if the fire was successful.\n\tIf an event is not in the replaying state, then we enqueue it as well as try to execute it immediately. It looks like it can lead to duplicate executions of the same event, once by the trigger actually firing and again from the trigger.run() method? I think we can simplify it in two ways:\n\t\n\t\tScheduledTrigger.run() tries to fire queued events only on first run i.e. when the overseer first starts up. This is akin to how the work queue is used in overseer i.e. tasks are queued before execution and removed post execution and the work queue is only ever read/polled on overseer startup.\n\t\tThe event listener can queue items to ZK but does not submit them to the action executor. The ScheduledTrigger.run peeks from the event queue, submits them to the action executor and polls if successful. Basically this splits the complex logic of queuing, and submitting from the same event listener being set in the ScheduledTriggers.add method into two places.\n\t\n\t\n\tThe TriggerIntegrationTest.testEventQueue method has a await = actionStarted.await(600, TimeUnit.SECONDS);. That's way too much time. I ran the test only once and it timed out.\n\tThis design ensures that events once generated by a trigger aren't lost but it doesn't protect the trigger from losing the tracking information in the first place. For example, a node added trigger might detect the addition of a new node, put that node into its tracking map and then the overseer node goes down. The new overseer node will never detect that a new node was ever added and the event queue will of course be empty because no event was ever generated. Same applies for node lost events. I think we need to do something fundamentally different for cluster events such as these. Perhaps a node when registering itself with /live_nodes should do a multi write to the nodeAdded trigger queue? For nodeLost, what if every node (or a subset, say the top 3 in overseer election queue) tried to add the lost node's name to a fixed znode, say /autoscaling/events/nodeLost/actual_node_name:port_ctx. In future for metrics, we should think about adding rolled up metrics to the .system collection so we don't lose them or perhaps they can re-calculated from leader?\n\n\n\nWhat do you think? ",
            "author": "Shalin Shekhar Mangar",
            "id": "comment-16018350"
        },
        {
            "date": "2017-05-24T15:00:42+0000",
            "content": "Patch for review:\n\n\tadded ZK persistence of internal trigger state, to be able to re-generate events that were not yet fired (eg. due to waitFor limit).\n\tcleanup of TriggerEvent hierarchy and generics (basically, we don't need generics here).\n\tadded unit tests for re-playing events from queue, and for re-creating events from restored internal state.\n\n\n\nI left a lot of debug logging in this version, this will be cleaned up before merging. ",
            "author": "Andrzej Bialecki",
            "id": "comment-16023052"
        },
        {
            "date": "2017-05-25T09:10:51+0000",
            "content": "Thanks Andrzej. There were a few conflicts in the tests because of my last commit on SOLR-10738 so I fixed those in this patch. It should apply cleanly on the autoscaling branch.\n\nA few comments:\n\n\tYou need to add SuppressForbidden annotation on IdUtils, NodeAddedTrigger and NodeLostTrigger and their tests due to the use of System.currentTimeMillis otherwise precommit will complain\n\tWhy TreeSet and TreeMap instead of HashSet and HashMap in the triggers? I tried to find where we rely on the order anywhere but couldn't.\n\tWhile replaying, ScheduledTrigger should check for hasPendingActions first otherwise it will discard the event for no reason\n\tTriggerEvent.getEventTime() now returns System.currentTimeMillis but the NodeAddedTriggerTest (and NodeLostTriggerTest) still compare with System.nanoTime\n\tOverseerTriggerThread uses while (!isClosed) but this usage of isClosed is without obtaining the update lock so the right value may not be visible. I'd rather keep it as while(true)\n\tThe removal of triggerState should probably be moved from OverseerTriggerThread to ScheduledTriggers.remove after trigger is closed otherwise NoNodeException will be needlessly logged if the removed trigger was executing concurrently. Also I don't see the corresponding removal of the events path anywhere.\n\tWhen a trigger is replaced, we call restoreState(old.trigger) and then when the trigger is run for the first time, it restores (the same data) from ZK again. Not a big deal, just something I noticed. We can solve it setting replay to false if we want to.\n\tAfter we deque the event we assert that its id is same as the event we expected. Can we log if they don't match in addition to the assert?\n\tThe use isClosed in ScheduledTrigger is not safe because the close() method will always be called by a different thread than the one executing the run() method. So either make isClosed volatile or an AtomicBoolean.\n\n ",
            "author": "Shalin Shekhar Mangar",
            "id": "comment-16024435"
        },
        {
            "date": "2017-05-25T09:22:06+0000",
            "content": "Thanks for the review - I'll fix these shortly.\n\nRe. #2 - I used sorted variants to make iteration order predictable, so that the primitive caching of byte[] data in TriggerBase works better - otherwise, even if their content was identical their iteration order could have been different  (depending on insertion order and internal bucket collisions in HashSet / HashMap). ",
            "author": "Andrzej Bialecki",
            "id": "comment-16024444"
        },
        {
            "date": "2017-05-25T13:21:10+0000",
            "content": "Re. #2 - I used sorted variants to make iteration order predictable, so that the primitive caching of byte[] data in TriggerBase works better - otherwise, even if their content was identical their iteration order could have been different (depending on insertion order and internal bucket collisions in HashSet / HashMap).\n\nI see. I'd favor keeping the lastState as a map in TriggerBase and compare using equals() instead of an array \u2013 it seems a bit fragile. Alternately, please add javadocs to getState to indicate that any collections used as values must have a fixed iteration order. ",
            "author": "Shalin Shekhar Mangar",
            "id": "comment-16024721"
        },
        {
            "date": "2017-05-25T16:21:01+0000",
            "content": "Keeping a map would require a deep clone to avoid in-place modifications, but I agree it would be less fragile. I'll look into it. ",
            "author": "Andrzej Bialecki",
            "id": "comment-16024954"
        },
        {
            "date": "2017-05-25T18:35:33+0000",
            "content": "Merged to feature/autoscaling branch. ",
            "author": "Andrzej Bialecki",
            "id": "comment-16025179"
        }
    ]
}