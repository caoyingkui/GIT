{
    "id": "LUCENE-7916",
    "title": "CompositeBreakIterator is brittle under ICU4J upgrade.",
    "details": {
        "labels": "",
        "priority": "Major",
        "resolution": "Fixed",
        "affect_versions": "6.6",
        "status": "Closed",
        "type": "Bug",
        "components": [
            "modules/analysis"
        ],
        "fix_versions": [
            "7.1",
            "master (8.0)"
        ]
    },
    "description": "We use lucene-analyzers-icu version 6.6.0 in our project. Lucene 6.6.0 is built against ICU4J version 56.1, but our use case requires us to use the latest version of ICU4J, 59.1.\n\nThe problem that we have encountered is that CompositeBreakIterator.getBreakIterator(int scriptCode) throws an ArrayIndexOutOfBoundsException for script codes higher than 167. In ICU4J 56.1 the highest possible script code is 166, but in ICU4j 59.1 it is 174.\n\nInternally, CompositeBreakIterator is creating an array of size UScript.CODE_LIMIT, but the value of CODE_LIMIT from ICU4J 56.1 is being baked into the bytecode by the compiler. So even after overriding the version of the ICU4J dependency to 59.1 in our project, this array will still be size 167, which is too small.\n\n\nfinal class CompositeBreakIterator {\n  private final ICUTokenizerConfig config;\n  private final BreakIteratorWrapper wordBreakers[] = new BreakIteratorWrapper[UScript.CODE_LIMIT];\n\n\n\nOutput of javap run on CompositeBreakIterator.class from lucene-analyzers-icu-6.6.0.jar\n\nCompiled from \"CompositeBreakIterator.java\"\nfinal class org.apache.lucene.analysis.icu.segmentation.CompositeBreakIterator {\n  org.apache.lucene.analysis.icu.segmentation.CompositeBreakIterator(org.apache.lucene.analysis.icu.segmentation.ICUTokenizerConfig);\n    descriptor: (Lorg/apache/lucene/analysis/icu/segmentation/ICUTokenizerConfig;)V\n    Code:\n       0: aload_0\n       1: invokespecial #1                  // Method java/lang/Object.\"<init>\":()V\n       4: aload_0\n       5: sipush        167\n       8: anewarray     #3                  // class org/apache/lucene/analysis/icu/segmentation/BreakIteratorWrapper\n\n\nIn our case, the ArrayIndexOutOfBoundsException was triggered when we encountered a stray character of the Bhaiksuki script (script code 168) in a chunk of text that we processed.\n\nCompositeBreakIterator can be made more resilient by changing the type of wordBreakers from an array to a Map and no longer relying on the value of UScript.CODE_LIMIT.",
    "attachments": {
        "LUCENE-7916.patch": "https://issues.apache.org/jira/secure/attachment/12879878/LUCENE-7916.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "id": "comment-16109384",
            "date": "2017-08-01T17:41:10+0000",
            "content": "We use lots of version-dependent stuff (such as precompiled RBBI, .NRM files, etc) that can easily break across a release. Because of this, we can only support the version of ICU that we specify.\n\nSo instead i think we should hard-check that the version of ICU is the one we are supposed to have and fail if its not. ",
            "author": "Robert Muir"
        },
        {
            "id": "comment-16109390",
            "date": "2017-08-01T17:43:47+0000",
            "content": "adding patch that changes the type of CompositeBreakIterator.wordBreakers to a Map and removes the reference to UScript.CODE_LIMIT ",
            "author": "Chris Koenig"
        },
        {
            "id": "comment-16110213",
            "date": "2017-08-02T03:22:21+0000",
            "content": "We should not change datastructures when all that is needed is to use UCharacter.getIntPropertyMaxValue(UProperty.SCRIPT)\n\nSee: http://icu-project.org/apiref/icu4j/com/ibm/icu/lang/UScript.html#CODE_LIMIT\n\nBut separately, this wont solve all problems. Other things will probably fail if you use a different icu4j version than the one supported. ",
            "author": "Robert Muir"
        },
        {
            "id": "comment-16111438",
            "date": "2017-08-02T18:05:11+0000",
            "content": "Thanks for your feedback. I didn't realize how tightly coupled Lucene is to a particular ICU release.\n\nIn our case, we are using ICUTokenizer but we have modified the default ruleset of RuleBasedBreakIterator to break on emoji characters so that we can search for emoji in text. The unicode properties for emoji that our rules depend on were added to UProperty starting with ICU 57. Because we are compiling our own RBBI rules, we are not exposed to any breakage that might occur due to a binary rule encoding change on upgrade of ICU. We are not making use of the Normalizer or Folding filters so we lack exposure there as well. After thorough A/B testing, this is working well for us in production with the exception of the issue reported above, which has only occurred once so far.\n\nThe underlying issue for us is that Lucene 6.6.0 is pegged to a fairly old version of ICU. In hindsight it might have been safer for us to fork lucene-analyzers-icu temporarily to build our own internal release against ICU 59.1.\n\nFrom what I've seen in JIRA and the git repo, it looks like 6.7 is targeted at ICU 59.1. Is there an ETA for the release of 6.7? ",
            "author": "Chris Koenig"
        },
        {
            "id": "comment-16111970",
            "date": "2017-08-03T00:27:44+0000",
            "content": "Attached is my patch. We need to remove the deprecated constant anyway, to prevent trouble in the future.\n\nI added TODO's where we load data files with ICU formats. I don't have suggested logic here yet, esp since I think the stuff is considered internal, so could theoretically break with any version that isn't exactly the one we test with. ",
            "author": "Robert Muir"
        },
        {
            "id": "comment-16111977",
            "date": "2017-08-03T00:35:56+0000",
            "content": "\nIn our case, we are using ICUTokenizer but we have modified the default ruleset of RuleBasedBreakIterator to break on emoji characters so that we can search for emoji in text.\n\nCool!\n\n\nThe underlying issue for us is that Lucene 6.6.0 is pegged to a fairly old version of ICU. In hindsight it might have been safer for us to fork lucene-analyzers-icu temporarily to build our own internal release against ICU 59.1.\n\nYeah, when we upgrade ICU versions we run a script the regenerates normalization and segmentation datafiles for that specific ICU jar / unicode version: ant regenerate from lucene/analyzers/icu. So at the minimum this should really be done (followed of course by ant test) so that things work correctly. \n\n\nFrom what I've seen in JIRA and the git repo, it looks like 6.7 is targeted at ICU 59.1. Is there an ETA for the release of 6.7?\n\nI'm not sure, maybe ask the dev list about this? But it seems most work is towards 7.0 and onwards. \n\nThe real problem was falling so far behind on ICU versions. You can see why if you look at the ticket: LUCENE-7540. Mainly, a bug (http://bugs.icu-project.org/trac/ticket/12873) was introduced into ICU that our test suite detected but we didn't know why. This was fixed in ICU 59.1 so we were then able to upgrade. ",
            "author": "Robert Muir"
        },
        {
            "id": "comment-16114375",
            "date": "2017-08-04T13:42:28+0000",
            "content": "+1 to Robert Muir's patch: that's what ICU docs recommend instead. ",
            "author": "Michael McCandless"
        },
        {
            "id": "comment-16117625",
            "date": "2017-08-08T00:39:06+0000",
            "content": "My patch needs a minor correction when committing, we need to replace UScript.CODE_LIMIT with UCharacter.getIntPropertyMaxValue(UProperty.SCRIPT)+1, because the former is a limit (one plus the maximum value: 175) and the latter is a maximum value (174). Tests do not detect this, but that might only be happenchance due to the property values/rules/random string generation for the SYMBOLS_EMOJI script. ",
            "author": "Robert Muir"
        },
        {
            "id": "comment-16117635",
            "date": "2017-08-08T00:48:35+0000",
            "content": "Commit a4db6ce3e681d96fd05f6814818b3270ca527821 in lucene-solr's branch refs/heads/master from Robert Muir\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=a4db6ce ]\n\nLUCENE-7916: Remove use of deprecated UScript.CODE_LIMIT in ICUTokenizer ",
            "author": "ASF subversion and git services"
        },
        {
            "id": "comment-16117699",
            "date": "2017-08-08T01:32:02+0000",
            "content": "Commit 95af49e5882226be52141a26565d8d2f99b76aaf in lucene-solr's branch refs/heads/branch_7x from Robert Muir\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=95af49e ]\n\nLUCENE-7916: Remove use of deprecated UScript.CODE_LIMIT in ICUTokenizer ",
            "author": "ASF subversion and git services"
        },
        {
            "id": "comment-16117700",
            "date": "2017-08-08T01:33:10+0000",
            "content": "Thanks Chris Koenig ! ",
            "author": "Robert Muir"
        },
        {
            "id": "comment-16207314",
            "date": "2017-10-17T11:03:26+0000",
            "content": "Bulk close after 7.1.0 release ",
            "author": "Shalin Shekhar Mangar"
        }
    ]
}