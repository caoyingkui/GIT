{
    "id": "SOLR-6351",
    "title": "Let Stats Hang off of Pivots (via 'tag')",
    "details": {
        "affect_versions": "None",
        "status": "Closed",
        "fix_versions": [
            "5.0",
            "6.0"
        ],
        "components": [],
        "type": "Sub-task",
        "priority": "Major",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "he goal here is basically flip the notion of \"stats.facet\" on it's head, so that instead of asking the stats component to also do some faceting (something that's never worked well with the variety of field types and has never worked in distributed mode) we instead ask the PivotFacet code to compute some stats X for each leaf in a pivot.  We'll do this with the existing stats.field params, but we'll leverage the tag local param of the stats.field instances to be able to associate which stats we want hanging off of which facet.pivot\n\nExample...\n\nfacet.pivot={!stats=s1}category,manufacturer\nstats.field={!key=avg_price tag=s1 mean=true}price\nstats.field={!tag=s1 min=true max=true}user_rating\n\n\n\n...with the request above, in addition to computing the min/max user_rating and mean price (labeled \"avg_price\") over the entire result set, the PivotFacet component will also include those stats for every node of the tree it builds up when generating a pivot of the fields \"category,manufacturer\"",
    "attachments": {
        "SOLR-6351.patch": "https://issues.apache.org/jira/secure/attachment/12671706/SOLR-6351.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Hoss Man",
            "id": "comment-14091538",
            "date": "2014-08-09T01:21:18+0000",
            "content": "\nProposed implementation...\n\n\n\tModify the Pivot facet code to check for a \"stats\" local param\n\tif a stats tag name is specified, each time a NamedList<Integer> of \"top\" terms is computed at a given level of the pivot tree (either single node or on an initial shard request, or as part of a refinement request), each of those terms should be applied as a filter on the main doc set - the result should be used to construct a SimpleStats\n\tthe SimpleStats class should then be asked to compute the neccessary stats based on the tags\n\t\n\t\tSimpleStats will need refactored: probably with a new StatsField class for modeling each stats.field param (and the StatsValues that hang off of it) and new accessor methods to get the list of all {{StatsField}}s so the pivot facet class can find the ones it needs by tag\n\t\tin single node mode, just ask each StatsField to compute the stats\n\t\tin cloud mode:\n\t\t\n\t\t\tin the shard requests, ask each StatsField to compute it's distributed stats based on the params it knows about\n\t\t\tin the coordinator request, once the pivot constraints are merged & refined, the refinement phase should merge all of the StatsValues at the same time it's summing up the facet counts.\n\t\t\n\t\t\n\t\n\t\n\twe need to think carefully about \"exclusions\" because they might be different\n\t\n\t\tie: facet.pivot{!ex=some_fq stats=s1}foo,bar&stats.field={!ex=other_fq}price\n\t\ti think what we want in general is for the \"ex\" localparam of the stats.field to be ignored when hanging off of a facet.pivot\n\t\tOR: we union the exclusions (so the computed stats are over more docs then what the facet count returns)\n\t\tOR: we fail if they both specify \"ex\" and they aren't identical\n\t\n\t\n\n "
        },
        {
            "author": "Hoss Man",
            "id": "comment-14130904",
            "date": "2014-09-12T00:10:01+0000",
            "content": "SimpleStats will need refactored: ...\n\nFWIW: I've started incorporating some of these ideas into the bug fix i'm doing in SOLR-6507 since it addresses the root problem in that bug and gives us a better place to build on for issues like this. "
        },
        {
            "author": "Hoss Man",
            "id": "comment-14144161",
            "date": "2014-09-23T01:12:01+0000",
            "content": "\nI'm headed out of town for a week, but before i go \u2013 while it's fresh in my head \u2013 i wanted to post some notes on what the next steps need to be for this based on the current state of trunk (after the refactoring & cleanup done in recent issues like SOLR-6354 & SOLR-6507)\n\nnext steps\nSingle Node Pivot Tests...\n\n\n\taparently we've managed to go this far w/o any simple single-node pivot tests other then SolrExampleTests \u2013 which requires solrj support.  Since it would be nice to start with some simple proof that single node pivots+stats work, we need to start iwth some tests\n\twe should add simple  FacetPivotSmallTest that uses the same basic data and assertions as DistributedFacetPivotSmallTest but with a single solr node and using xpath (instead of depending on solrj).\n\n\n\nLocal Pivots + stats...\n\n\n\tadd some logic & a getter to StatsField to make public a list of the \"tags\" in it's local params\n\tadd a Map<String,List<StatsField>> to StatsInfo to support a new method for looking up the List<StatsField>> corrisponding to a given tag string.\n\tModify the Pivot facet code to check for a \"stats\" local param:\n\t\n\t\tthe value of which may be a comma seperated list of \"tags\" to lookup with the StatsInfo instance of the current ResponseBuilder to get the StatsField instances we want to hang of of our pivots.\n\t\tif there are some StatsFields to hang off of our pivot, then any code in PivotFacetProcessor which currently calls getSubsetSize() should call getSubset(); and after any call (existing or new) to getSubset() the code should (in addition to adding the set size to the response) pass that DocSet to the StatsField.computeLocalStatsValues and include the resulting StatsValues in the response.\n\t\n\t\n\tupdate the previously created FacetPivotSmallTest to also test hanging some stats off of pivots\n\n\n\nSolrJ\n\n\n\tupdate the SolrJ PivotField to support having a List<FieldStatsInfo> in it\n\tupdate the solrj codecs to know how to populate those if/when the data exists in the response\n\tadd some unit tests for this in solrj (no existing unit tests of the pivot or stats object creation from responses???)\n\tupdate SolrExampleTests to do some pivots+stats and verify that they can be parsed correctly by solrj\n\n\n\nDistributed Pivot + Stats\n\n\n\tPivotFacetValue needs to know if/when it hsould have one or more StatsValues in it and get an empty instance from StatsValuesFactory for each of the applicable StatsField instances.\n\tPivotFacetValue.createFromNamedLists needs to recognize when a shard is including a a sub-NamedList of stats data, and for merge in each of those children into the appropriate StatsValues.accumulate(NamedList) (based on StatsField.getKey())\n\tat this point we should be able to update DistributedFacetPivotSmallTest to include the same types of pivot+stats additions that were made to FacetPivotSmallTest for checking the sngle node case, and see distributed pivot+stats working.\n\n\n\nTest, Test, Test\n\n\n\tat this point we should be able to update the other distribute pivot tests with pivot + stats cases to make sure we don't find new bugs\n\tadding in stats params & assertions to DistributedFacetPivotLargeTest and DistributedFacetPivotLongTailTest should be straight forward\n\tTestCloudPivotFacet will be more interesting due to the randomization...\n\t\n\t\tadding new randomized stats.field params is trival given all the interesting fields already included in the docs\n\t\twith a little record keeping of what stats.field params we add, we can easily tweak the facet.pivot params to includes a {{stats=...} local param to ask for them\n\t\twe'll want a trace param to to know if/when to expect stats in the response (so we don't overlook bugs where stats are never computed/returned)\n\t\tin assertPivotCountsAreCorrect, if stats are expected, then instead of a simple assertNumFound on each of the pivot values, we can actaully assert that when filtering on that pivot value, the stats we get back for the entire (filtered) request match the stats we got back as part of the pivot (ie: don't just check the pivot[count]==numFound, also check pivot[stats][foo][min]==stats[foo][min] and pivot[stats][foo][max]==stats[foo][max], etc...\n\t\t\n\t\t\tthe merge logic should be exact for the min/max/missing/count stats, but we may need some leniency here for the comparisons of some of the computed stats values like sum/mean/stddev/etc... since the order of operations involved in the merge may cause intermediate precision loss\n\t\t\n\t\t\n\t\n\t\n\n\n\nOne final note...\n\nwe need to think carefully about \"exclusions\" because they might be different \n\nMy current thinking (reflected in the steps i've outlined above) is that we should go this route...\n\ni think what we want in general is for the \"ex\" localparam of the stats.field to be ignored when hanging off of a facet.pivot\n\nOf the 2 alternatives i proposed before: \n\n\n\t\"union the exclusions\" \u2013 extremeley impractical.\n\t\"fail if they both specify 'ex' and they aren't identical\" \u2013 very possible/easy to do if people think it's less confusing, it just requires a bit more code.  we can easily go this route if we run into problems and decide it makes the API cleaner.\n\n\n "
        },
        {
            "author": "Vitaliy Zhovtyuk",
            "id": "comment-14151142",
            "date": "2014-09-28T17:07:40+0000",
            "content": "Intermediate results:\n\n1. Added pivot facet test to SolrExampleTests, extended org.apache.solr.client.solrj.SolrQuery to provide multipls stats.field parameter\n2. Added FacetPivotSmallTest and moved all asserts from DistributedFacetPivotSmallTest to XPath assertions, separated it to few test methods\n3. \"tag\" local parameter parsing added \n4. added org.apache.solr.handler.component.StatsInfo#tagToStatsFields and org.apache.solr.handler.component.StatsInfo#getStatsFieldsByTag \nto lookup list of stats fields by tag\n5. Modified PivotFacetProcessor to collect and put StatValues for ever pivot field, added test to assert stats value of pivots\n6. Updated PivotField and org.apache.solr.client.solrj.response.QueryResponse to read stats values on pivots "
        },
        {
            "author": "Hoss Man",
            "id": "comment-14156877",
            "date": "2014-10-02T17:56:43+0000",
            "content": "Vitaliy: i haven't had a chance to look in depth at your patch, but when i tried to run the tests all of the pivot code seemed to fail with an NPE?\n\n\n   [junit4] ERROR   30.8s J2 | DistributedFacetPivotSmallTest.testDistribSearch <<<\n   [junit4]    > Throwable #1: org.apache.solr.client.solrj.impl.HttpSolrServer$RemoteSolrException: java.lang.NullPointerException\n   [junit4]    > \tat org.apache.solr.handler.component.PivotFacetProcessor.getStatsFields(PivotFacetProcessor.java:158)\n   [junit4]    > \tat org.apache.solr.handler.component.PivotFacetProcessor.processSingle(PivotFacetProcessor.java:121)\n   [junit4]    > \tat org.apache.solr.handler.component.PivotFacetProcessor.process(PivotFacetProcessor.java:97)\n   [junit4]    > \tat org.apache.solr.handler.component.FacetComponent.process(FacetComponent.java:112)\n   [junit4]    > \tat org.apache.solr.handler.component.SearchHandler.handleRequestBody(SearchHandler.java:226)\n\n...\n\n   [junit4] ERROR   0.07s | FacetPivotSmallTest.testPivotFacetIndexSortMincountLimitAndOffsetPermutations <<<\n   [junit4]    > Throwable #1: java.lang.RuntimeException: Exception during query\n   [junit4]    > \tat __randomizedtesting.SeedInfo.seed([79673644714434B5:6E2351EE52D41611]:0)\n   [junit4]    > \tat org.apache.solr.SolrTestCaseJ4.assertQ(SolrTestCaseJ4.java:723)\n   [junit4]    > \tat org.apache.solr.SolrTestCaseJ4.assertQ(SolrTestCaseJ4.java:690)\n   [junit4]    > \tat org.apache.solr.handler.component.FacetPivotSmallTest.testPivotFacetIndexSortMincountLimitAndOffsetPermutations(FacetPivotSmallTest.java:425)\n   [junit4]    > \tat java.lang.Thread.run(Thread.java:745)\n   [junit4]    > Caused by: java.lang.NullPointerException\n   [junit4]    > \tat org.apache.solr.handler.component.PivotFacetProcessor.getStatsFields(PivotFacetProcessor.java:158)\n   [junit4]    > \tat org.apache.solr.handler.component.PivotFacetProcessor.processSingle(PivotFacetProcessor.java:121)\n\n...\n\n\n "
        },
        {
            "author": "Steve Molloy",
            "id": "comment-14156887",
            "date": "2014-10-02T18:00:25+0000",
            "content": "Adapted patch a bit to avoid NPE when no stats are asked, modified PivotFacetValue to propagate info and other small tweaks. Tests seem to be happy and got some requests to work, so I am too...  "
        },
        {
            "author": "Vitaliy Zhovtyuk",
            "id": "comment-14156943",
            "date": "2014-10-02T18:32:56+0000",
            "content": "Combined with previous patch.\n1. Added more solrj tests for stats on pivots\n2. Fixed stats result\n3. Minor tweaks "
        },
        {
            "author": "Steve Molloy",
            "id": "comment-14157129",
            "date": "2014-10-02T20:32:48+0000",
            "content": "Vitaliy Zhovtyuk Does your patch contain changes form mine? There were some NPE as Hoss mentioned which I think I got fixed. I like the addition of tests though, so hope to get the best of both. I don't mind providing a patch combining both patches, just want to avoid us posting at about the same time again.  "
        },
        {
            "author": "Steve Molloy",
            "id": "comment-14157990",
            "date": "2014-10-03T13:59:10+0000",
            "content": "Ok, applied locally and see that most is combined. One thing though, what is expected behavior for pivots where count is 0? Currently, you'll get the full entry with NaN, infinity and such in it. Should it be null or empty instead? Or should it even show up at all? "
        },
        {
            "author": "Hoss Man",
            "id": "comment-14158244",
            "date": "2014-10-03T17:53:39+0000",
            "content": "One thing though, what is expected behavior for pivots where count is 0? Currently, you'll get the full entry with NaN, infinity and such in it. Should it be null or empty instead? Or should it even show up at all?\n\nGreat question. \n\nI think in this case we should leave out \"stats\" subsection completely for brevity \u2013 similar to how the \"pivot\" subsection is left out whenever there are no sub-pivots to report counts for.  it's also mostly consistent with the common case of sub-pivots when the parent count is 0 in distributed pivots since mincount=0 isn't really viable (SOLR-6329).\n\nBut i could be persuaded that we should leave in an empty 'stats' section ... a stats section full of fields reporting a bunch of NaN and Infinity counts seems likeit's just asking for causing user error though.\n\n "
        },
        {
            "author": "Steve Molloy",
            "id": "comment-14158495",
            "date": "2014-10-03T20:35:31+0000",
            "content": "Augmented previous 3 patches, added logic to not include stats entry if it's empty, fixed distributed logic by actually merging stats from shards. Currently have unit tests failing in solrj that I need to look at. "
        },
        {
            "author": "Hoss Man",
            "id": "comment-14158661",
            "date": "2014-10-03T23:11:48+0000",
            "content": "i haven't done an extensive review, but here's some quick comments/questions based on skim of the latest patch...\n\n1) this block of new code in PivotFacetProcessor (which pops up twice at diff points in the patch?) doesn't make any sense to me ... the StatsValues returned from computeLocalStatsValues() is totally ignored ?\n\n+      for(StatsField statsField : statsFields) {\n+         statsField.computeLocalStatsValues(docSet);\n+      }\n\n\n\n2) i don't think StatsValues.hasValues() really makes sense ... we shouldn't be computing StatsValues against the subset and then adding them to the response if and only if they hasValues()  \u2013 we should instead be skipping the computation of the StatsValues completely unless the pivot subset is non-empty.\n\nthis isn't just a question of optimizing away the stats computation \u2013 it's a very real difference in the fundamental logic.  there could be a non-empty set of documents (ie: pivot count > 0), but the stats we've been asked to compute (ie: over some field X) might result in a stats count that's 0 (if none of hte docs in that set have a value in field X) in which case we should still include the stats in the response.\n\n3) why is a CommonParams.STATS constant being added?  isn't this what StatsParams.STATS is for?\n\n4) i'm not really understanding the point of the two new SolrExampleTests.testPivotFacetsStatsNotSupported* methods ... what's the goal behind having these tests?\nIf nothing else, as things stand right now, these seem like they make really brittle assumptions about the exact error message they expect \u2013 we should change them to use substring/regex to sanity check just the key pieces of information we care about finding in the error message.\nWe should also assert that the error code on these exceptions is definitely a 4xx error and not a 5xx "
        },
        {
            "author": "Steve Molloy",
            "id": "comment-14159265",
            "date": "2014-10-04T19:41:47+0000",
            "content": "Addressing some comments. Remove unused for-loop and CommonParams.STATS. Didn't touch the notSupprted test methods, will let Vitaliy a chance to speak for their usefulness. Also reverted the hasValues logic to replace it with checking if current pivot has positive count. Although it does produce some stats entries with Infinity minimum/maximum and NaN mean. This is what I was asking about before, I think I misunderstood the answer, but it still seems error-prone to have such entries...\n\nFinally, I updated some of the outputs to use NamedList instead of maps so that solrj binary works better. Did have to sort fields in QueryResponse to get tests to pass. Not sure this is the best way, but would sometimes get them out of order if I didn't. "
        },
        {
            "author": "Vitaliy Zhovtyuk",
            "id": "comment-14159648",
            "date": "2014-10-05T19:19:20+0000",
            "content": "1. Added stats fields pivot distribution to DistributedFacetPivotSmallTest (same data and values from org.apache.solr.handler.component.FacetPivotSmallTest used)\n2. Fixed \"LinkedHashMap cannot be casted to NamedList\" exception, occurring on stats distribution (changed org.apache.solr.handler.component.PivotFacetHelper#convertStatsValuesToNamedList)\n\n3. About Testing for not supported types, i think we need to cover/document limitations as well.I'm not happy with asserting error message.\n Added http code 400 assertion and error message substring assertion. "
        },
        {
            "author": "Steve Molloy",
            "id": "comment-14160413",
            "date": "2014-10-06T15:48:21+0000",
            "content": "One more question around this, which applies for SOLR-6353 and SOLR-4212 as well. Should we have a syntax to apply stats/queries/ranges only at specific levels in the pivot hierarchy? It would reduce amount of computation and size of response for cases where you only need it at a specific level (usually last level I guess). Something like:\nfacet.pivot=\n{!stats=s1,s2}\nfield1,field2\nWe could us * for all levels, or something like:\nfacet.pivot=\n{!stats=,,s3}\nfield1,field2,field3 \nto only apply at 3rd level. "
        },
        {
            "author": "Hoss Man",
            "id": "comment-14160658",
            "date": "2014-10-06T18:34:55+0000",
            "content": "\nI haven't had a chance to look at the recent patches, and i probably won't today, but i wanted to post some quick replies to a few comments/questions...\n\n\n\nAlso reverted the hasValues logic to replace it with checking if current pivot has positive count. Although it does produce some stats entries with Infinity minimum/maximum and NaN mean. This is what I was asking about before, I think I misunderstood the answer, but it still seems error-prone to have such entries...\n\nYou may be right ... lemme talk through my thinking on this and see where we wind up:\n\nForgeting about pivots for a moment, and just think about the idea of computing some arbitrary stat over a set of documents.  ie: you've got N documents that match some arbitrary query, and then you want to compute stats on the \"price\" and \"popularity\" fields .. what should happen if none of those documents has a \"popularity\" field at all?\n\nmy thinking, was that:\n\n\tthe behavior when hanging stats off pivots should mirror that of regular stats\n\tif you ask for a stats block , you should always get that block, so the client doesn't have to conditionally check if it's there before looking at the values.\n\tthe included stat values matter even if no doc has the stats.field, becuase one of the stats is in fact \"missing\" and that if you ask for stats, you should be able to look at that missing count. (and it should match up with your doc set size if the field is completely missing, etc...)\n\n\n\nbut looking at an example of this now, i see that for simple field stats (w/o pivots), that's not even how it currently works \u2013 consider this URL using hte example data...\n\nhttp://localhost:8983/solr/select?rows=0&q=name:utf&stats.field=foo_d&stats.field=popularity&stats=true\n\n\n\tfoo_d doesn't exist in the index.\n\tpopularity does exist in the index, but the one doc matching the query doesn't have a value in that field.\n\n\n\nI thought (and still think) that the \"correct\" behavior for this query would be to get a stats block back for those fields where things like min/max/mean are \"null\", count==0, and missing=1 ... but that's not how it currently works.\n\nso i guess the question is: is the current general stats behavior a \"bug\" that should be fixed, or is this the \"correct\" way to deal with stats when none of the documents have a value (and thus: the behavior of your \"hasValue\" logic was correct) ?\n\ni'm leaning towards\" bug\" ... but i'd like to think about it more and hear how others feel..\n\n\n\nOne more question around this, which applies for SOLR-6353 and SOLR-4212 as well. Should we have a syntax to apply stats/queries/ranges only at specific levels in the pivot hierarchy? It would reduce amount of computation and size of response for cases where you only need it at a specific level (usually last level I guess).\n\nThat's a great question ... honestly it's not something i ever really thought about.  \n\nOne quick thing i will point out: the size of the response shouldn't really be a huge factor in our decisions here, because with SOLR-6349 (which i'll hopefully have a patch for in the next day or so) the response will only need to include the stats people actually care about, andsask for, so the typical result size should be much smaller.\n\nBut you've got a good point about amount of computation done/returned at levels that people may not care about ... in my head, it seemed to make sense that the stats (and ranges, etc...) should be computed at every level just like the pivot count size \u2013 but at the intermediate levels that count is a \"free\" computation based on the size of the subset, and but i suspect you are correct: may people may only care about having these new stats/ranges/query on the leaves in the common case.\n\nI'm not really following your suggested syntax though ... you seem to be saying that in the \"stats\" local param, commas would be used to delimit \"levels\" of the pivot (corresponding to the commas in the list of pivot fields) but then i'm not really clear what you mean about using \"*\" (if that means all levels, how do you know what tag name to use?\n\nin the original examples i porposed, i was thinking that a comma seperated list could refer to multiple tag names, wimilar to how the \"exlcusions\" work \u2013 ie..\n\n\nfacet.pivot={!stats=prices,ratings}category,manufacturer\nfacet.pivot={!stats=prices,pop}reseller\nstats.field={!key=avg_list_price tag=prices mean=true}list_price\nstats.field={!tag=ratings min=true max=true}user_rating\nstats.field={!tag=ratings min=true max=true}editors_rating\nstats.field={!tag=prices min=true max=true}sale_price\nstats.field={!tag=pop}weekly_tweets\nstats.field={!tag=pop}weekly_page_views\n\n\n\n...would result in the \"category,manufacturer\" pivot having stats on \"avg_list_price, sale_price, user_rating, & editors_rating\" while the \"reseller\" pivot would have stats on \"avg_list_price, sale_price, weekly_tweets, & weekly_page_views\"\n\nThinking about it now though, if we support multiple tag names on stats.field, the same thing could be supported like this...\n\n\nfacet.pivot={!stats=cm_s}category,manufacturer\nfacet.pivot={!stats=r_s}reseller\nstats.field={!key=avg_list_price tag=cm_s,r_s mean=true}list_price\nstats.field={!tag=cm_s min=true max=true}user_rating\nstats.field={!tag=cm_s min=true max=true}editors_rating\nstats.field={!tag=cm_s,r_s min=true max=true}sale_price\nstats.field={!tag=r_s}weekly_tweets\nstats.field={!tag=r_s}weekly_page_views\n\n\n\nSo ... if we did that, then we could start using \"position\" info in a comma seperated list of tag names to refer to where in the pivot \"depth\" those stats/ranges/queries should be computed ... the question i have is \"should we\" ? .. in the context of a facet.pivot param, will it be obvious to folks that there is a maping between the commas in these local params and hte commas in hte bod of the facet.pivot param, or will it confuse people who are use to seeing comma as just a way of delimiting multiple values in tag/ex params?\n\nmy opinion: no freaking clue at the moment ... need to let it soak in my brain. "
        },
        {
            "author": "Hoss Man",
            "id": "comment-14165864",
            "date": "2014-10-09T22:17:59+0000",
            "content": "\nso i guess the question is: is the current general stats behavior a \"bug\" that should be fixed, or is this the \"correct\" way to deal with stats when none of the documents have a value (and thus: the behavior of your \"hasValue\" logic was correct) ?\n\ni'm leaning towards\" bug\" ... but i'd like to think about it more and hear how others feel..\n\nMore on this here: https://issues.apache.org/jira/browse/SOLR-6349?focusedCommentId=14165856&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14165856\n\nThe \"right thing to do\" for now is almost certainly to make the new code in SOLR-6351 for handing stats off pivots consistent with the existing code in StatsComponent...\n\n\nif (isShard == true || (Long) stv.get(\"count\") > 0) {\n  stats_fields.add(statsField.getOutputKey(), stv);\n} else {\n  stats_fields.add(statsField.getOutputKey(), null);\n}\n\n\n\n...then later, probably in SOLR-6349 where depending on the \"count\" stat to return other stats is going to be a blocker problem, we can revisit the question. "
        },
        {
            "author": "Vitaliy Zhovtyuk",
            "id": "comment-14168818",
            "date": "2014-10-12T22:25:04+0000",
            "content": "During work on \n\norg.apache.solr.handler.component.DistributedFacetPivotLargeTest found:\njunit.framework.AssertionFailedError: .facet_counts.facet_pivot.place_s,company_t[0].stats!=pivot (unordered or missing)\n\tat __randomizedtesting.SeedInfo.seed([705F7E1C2B9679AA:F1B9F0045CC91996]:0)\n\tat org.apache.solr.BaseDistributedSearchTestCase.compareSolrResponses(BaseDistributedSearchTestCase.java:842)\n\tat org.apache.solr.BaseDistributedSearchTestCase.compareResponses(BaseDistributedSearchTestCase.java:861)\n\tat org.apache.solr.BaseDistributedSearchTestCase.query(BaseDistributedSearchTestCase.java:562)\n\t\n\nThis mean difference in named list order between control shard and random shard.\nFound the reason in org.apache.solr.handler.component.PivotFacetValue#convertToNamedList\n\nDue to this reason also updated DistributedFacetPivotSmallTest to use call org.apache.solr.BaseDistributedSearchTestCase#query(org.apache.solr.common.params.SolrParams) with response comparison.\n\nTest org.apache.solr.handler.component.DistributedFacetPivotLongTailTest works only on string fields, added int field to make stats on it.\n\norg.apache.solr.cloud.TestCloudPivotFacet: added buildRandomPivotStatsFields to build stats.filed list, this methods skip fields of string and boolean type since they are not supported. \nadded tag string random generation on stat fields generated and if stats active tags also added to pivot fields.\n\nAdded handling for not present controls stats (count=0) in TestCloudPivotFacet.\nAbout skipping stats if count=0, it is not really good cause we losing missing stats distribution.\nCase with count=0, but missing=1 is real.\nThere are still some failures for TestCloudPivotFacet for date and double (precision?). Will check it tomorrow. "
        },
        {
            "author": "Vitaliy Zhovtyuk",
            "id": "comment-14176123",
            "date": "2014-10-18T21:10:59+0000",
            "content": "Fixed TestCloudPivotFacet. The reason for previous random test failures were facet.limit, facet.offset, facet.overrequest.count, facet.overrequest.ratio parameters generated randomly,\nthis was leading to inconsistent stats with pivot stats. Added cleanup for those parameters before stats on pivots test. All tests are passing. "
        },
        {
            "author": "Hoss Man",
            "id": "comment-14177564",
            "date": "2014-10-20T22:25:11+0000",
            "content": "\nThe reason for previous random test failures were facet.limit, facet.offset, facet.overrequest.count, facet.overrequest.ratio parameters generated randomly, this was leading to inconsistent stats with pivot stats.\n\n...that comment didn't really make sense to me based on how the code (should) work, so i asked Vitaliy about it on IRC this morning.  Talking it through with him neatiher one of us could explain conceptually why it should matter if those params were used \u2013 once a given pivot constraint is selected to be returned to the client, the \"sausage\" of why/how that constraint was selected shouldn't affect the \"stats\" associated with that constraint \u2013 from the point of view of the stats code, there's just a DocSet (on each shard) representing a subset of the full set of matches constrained by a term filter (the pivot constraint), and those (per-pivot-constrain) stats can then be merged on the coordinator node just like the top level stats.\n\nSo we ended the conversation with the assumption that there must either be a bug in the test code that validates the randomly generated pivots+stats, or there must be a bug in the actual pivot+stats logic.\n\nAfter reading over the changes to TestCloudPivotFacets i couldn't spot any obvious test flaws, so i started doing some manual testing and i think i've uncovered the problem: It looks like Vitaliy's new code doesn't account for stats returned by a shard in response to refinement requests.\n\nThis is pretty easy to reproduce if you spin up a 2 node system (ports 7777 & 8888) using hte example configs, then...\n\n\n\tadd few docs to each node\n\ncurl -sS 'http://localhost:7777/solr/collection1/update?commit=true' -H 'Content-Type: application/json' --data-binary '\n[{\"id\": 71, \"foo_s\": \"aaa\", \"bar_i\": 1}, \n {\"id\": 72, \"foo_s\": \"aaa\", \"bar_i\": 20}, \n {'id': 73, \"foo_s\": \"bbb\", \"bar_i\": 300}]\n'\ncurl -sS 'http://localhost:8888/solr/collection1/update?commit=true' -H 'Content-Type: application/json' --data-binary '\n[{\"id\": 81, \"foo_s\": \"bbb\", \"bar_i\": 4000}, \n {\"id\": 82, \"foo_s\": \"bbb\", \"bar_i\": 50000}, \n {'id': 83, \"foo_s\": \"aaa\", \"bar_i\": 600000}]\n'\n\n\n...note that \"aaa\" is the dominant term in the 7777 node, but \"bbb\" is the dominant term in the 8888 node.\n\tdo a simple pivot query + stats \u2013 the default over request is more then enough to resolve pivots fuly in a single pass...\n\ncurl -sS 'http://localhost:8888/solr/collection1/select?q=*:*&shards=localhost:8888/solr,localhost:7777/solr&facet.pivot=\\{!stats=sss\\}foo_s&stats.field=\\{!tag=sss\\}bar_i&facet=true&stats=true&wt=json&indent=true&rows=0'\n\n{\n  \"responseHeader\":{\n    \"status\":0,\n    \"QTime\":182,\n    \"params\":{\n      \"facet\":\"true\",\n      \"shards\":\"localhost:8888/solr,localhost:7777/solr\",\n      \"indent\":\"true\",\n      \"stats\":\"true\",\n      \"stats.field\":\"{!tag=sss}bar_i\",\n      \"q\":\"*:*\",\n      \"wt\":\"json\",\n      \"facet.pivot\":\"{!stats=sss}foo_s\",\n      \"rows\":\"0\"}},\n  \"response\":{\"numFound\":6,\"start\":0,\"maxScore\":1.0,\"docs\":[]\n  },\n  \"facet_counts\":{\n    \"facet_queries\":{},\n    \"facet_fields\":{},\n    \"facet_dates\":{},\n    \"facet_ranges\":{},\n    \"facet_intervals\":{},\n    \"facet_pivot\":{\n      \"foo_s\":[{\n          \"field\":\"foo_s\",\n          \"value\":\"aaa\",\n          \"count\":3,\n          \"stats\":{\n            \"stats_fields\":{\n              \"bar_i\":{\n                \"min\":1.0,\n                \"max\":600000.0,\n                \"count\":3,\n                \"missing\":0,\n                \"sum\":600021.0,\n                \"sumOfSquares\":3.60000000401E11,\n                \"mean\":200007.0,\n                \"stddev\":346404.0994662159,\n                \"facets\":{}}}}},\n        {\n          \"field\":\"foo_s\",\n          \"value\":\"bbb\",\n          \"count\":3,\n          \"stats\":{\n            \"stats_fields\":{\n              \"bar_i\":{\n                \"min\":300.0,\n                \"max\":50000.0,\n                \"count\":3,\n                \"missing\":0,\n                \"sum\":54300.0,\n                \"sumOfSquares\":2.51609E9,\n                \"mean\":18100.0,\n                \"stddev\":27688.08407961808,\n                \"facets\":{}}}}}]}},\n    ....\n\n\n...note that the stats for \"bar_i\" under pivot constraints \"aaa\" and \"bbb\" look correct (at least min/max/count/sum do ... i'm assuming the rest are as well)\n\tdo the same query again, but set facet.limit=1 \u2013 note the stats for 'aaa' are exactly the same as before due to the default overrequest values still resulting in no refinement queries needed...\n\ncurl -sS 'http://localhost:8888/solr/collection1/select?q=*:*&shards=localhost:8888/solr,localhost:7777/solr&facet.pivot=\\{!stats=sss\\}foo_s&stats.field=\\{!tag=sss\\}bar_i&facet=true&stats=true&wt=json&indent=true&rows=0&facet.limit=1\n\n{\n  \"responseHeader\":{\n    \"status\":0,\n    \"QTime\":14,\n    \"params\":{\n      \"facet\":\"true\",\n      \"shards\":\"localhost:8888/solr,localhost:7777/solr\",\n      \"indent\":\"true\",\n      \"stats\":\"true\",\n      \"stats.field\":\"{!tag=sss}bar_i\",\n      \"q\":\"*:*\",\n      \"facet.limit\":\"1\",\n      \"wt\":\"json\",\n      \"facet.pivot\":\"{!stats=sss}foo_s\",\n      \"rows\":\"0\"}},\n  \"response\":{\"numFound\":6,\"start\":0,\"maxScore\":1.0,\"docs\":[]\n  },\n  \"facet_counts\":{\n    \"facet_queries\":{},\n    \"facet_fields\":{},\n    \"facet_dates\":{},\n    \"facet_ranges\":{},\n    \"facet_intervals\":{},\n    \"facet_pivot\":{\n      \"foo_s\":[{\n          \"field\":\"foo_s\",\n          \"value\":\"aaa\",\n          \"count\":3,\n          \"stats\":{\n            \"stats_fields\":{\n              \"bar_i\":{\n                \"min\":1.0,\n                \"max\":600000.0,\n                \"count\":3,\n                \"missing\":0,\n                \"sum\":600021.0,\n                \"sumOfSquares\":3.60000000401E11,\n                \"mean\":200007.0,\n                \"stddev\":346404.0994662159,\n                \"facets\":{}}}}}]}},\n    ....\n\n\n\tnow disable overrequesting, so that a refinement request must happen \u2013 now the numbers are wrong.  it's obvious from the min/max/sum that the stats are only coming from the node '7777' that returned 'aaa' as a pivot constraint on the initial request, and no new stats were merged in after the refinement request to localhost:8888...\n\ncurl -sS 'http://localhost:8888/solr/collection1/select?q=*:*&shards=localhost:8888/solr,localhost:7777/solr&facet.pivot=\\{!stats=sss\\}foo_s&stats.field=\\{!tag=sss\\}bar_i&facet=true&stats=true&wt=json&indent=true&rows=0&facet.limit=1&facet.overrequest.count=0&facet.overrequest.ratio=0'\n\n{\n  \"responseHeader\":{\n    \"status\":0,\n    \"QTime\":29,\n    \"params\":{\n      \"facet.overrequest.count\":\"0\",\n      \"facet\":\"true\",\n      \"shards\":\"localhost:8888/solr,localhost:7777/solr\",\n      \"indent\":\"true\",\n      \"stats\":\"true\",\n      \"stats.field\":\"{!tag=sss}bar_i\",\n      \"q\":\"*:*\",\n      \"facet.limit\":\"1\",\n      \"facet.overrequest.ratio\":\"0\",\n      \"wt\":\"json\",\n      \"facet.pivot\":\"{!stats=sss}foo_s\",\n      \"rows\":\"0\"}},\n  \"response\":{\"numFound\":6,\"start\":0,\"maxScore\":1.0,\"docs\":[]\n  },\n  \"facet_counts\":{\n    \"facet_queries\":{},\n    \"facet_fields\":{},\n    \"facet_dates\":{},\n    \"facet_ranges\":{},\n    \"facet_intervals\":{},\n    \"facet_pivot\":{\n      \"foo_s\":[{\n          \"field\":\"foo_s\",\n          \"value\":\"aaa\",\n          \"count\":3,\n          \"stats\":{\n            \"stats_fields\":{\n              \"bar_i\":{\n                \"min\":1.0,\n                \"max\":20.0,\n                \"count\":2,\n                \"missing\":0,\n                \"sum\":21.0,\n                \"sumOfSquares\":401.0,\n                \"mean\":10.5,\n                \"stddev\":13.435028842544403,\n                \"facets\":{}}}}}]}},\n    ....\n\n\n\n\n\n\n\nI know some of the existing pivot tests (like DistributedFacetPivotLongTailTest & DistributedFacetPivotLargeTest) have sections that ensure refinement is working \u2013 if we update those sections to also include some stats & assertions on those stats we should be able to reliably reproduce this bug and then work on fixing it. "
        },
        {
            "author": "Hoss Man",
            "id": "comment-14179301",
            "date": "2014-10-21T23:21:44+0000",
            "content": "\nIt looks like Vitaliy's new code doesn't account for stats returned by a shard in response to refinement requests.\n\nI updated DistributedFacetPivotLongTailTest to check stats on a request where refinement was required for correct results and was able to reliable reproduce.\n\nLooking at the logs i realized that in the refinement requests \"stats=false\" was explicitly set, and traced this to an optimization in StatsComponent \u2013 it was assuming that only the initial (PURPOSE_GET_TOP_IDS) shard request needed stats computed, so i modified that to recognize (PURPOSE_REFINE_PIVOT_FACETS) as another situation where we need to leave stats=true\n\nThis gets the tests to pass (still hammering on TestCloudPivot, but so far looks good) but i'm not really liking this solution, for reasons i noted in a StatsComponent nocommi comment...\n\n\n// nocommit: PURPOSE_REFINE_PIVOT_FACETS by itself shouldn't be enough for this...\n//\n// we need to check if the pivots actually have stats hanging off of them,\n// if they don't then we still should supress the stats param\n// (no need to compute the top level stats over and over)\n//\n// actually ... even if we do have stats hanging off of pivots,\n// we need to make stats component smart enough not to waste time re-computing\n// top level stats on every refinement request.\n//\n// so maybe StatsCOmponent should be left alone, and FacetComponent's prepare method \n// should be modified so that *if* isShard && there are pivot refine params && those \n// pivots have stats, then set some variable so that stats logic happens even if stats=false?\n\n\n\nI also made a few other various changes as i was reviewing the test (noted below).\n\nMy plan is to move forward and continue reviewing more of the patch, starting with the other tests, and then dig into the code changes \u2013 writting additional test cases if/when i notice things that looks like they may not be adequately covered \u2013 and then come back and revist the question of the \"stats=false\" during refinement requests later (i'm certainly open to suggestions)\n\nchanges in this iteration of the patch\n\n\tTestCloudPivots\n\t\n\t\tremoved the bogus param \"cleanup\" vitaliy mentioned\n\t\tadded some nocommits as reminders for the future\n\t\n\t\n\tDistributedFacetPivotLongTailTest\n\t\n\t\trefactored query + assertFieldStats into \"doTestDeepPivotStats\"\n\t\t\n\t\t\tonly called once, and wasn't general in anyway - only usable for checking one specific query\n\t\t\n\t\t\n\t\trenamed \"foo_i\" to \"stat_i\" so it's a bit more obvious why that field is there\n\t\tadded stat_i to some long tail docs & updated the existing stats assertions\n\t\tmodified existing query that required refinement to show stats aren't correct\n\t\t\n\t\t\t\"bbb0\" on shard2 only gets included with refinement, but the \"min\" stat trivially demonstrates that the \"-1\" from shard2 isn't included\n\t\t\n\t\t\n\t\n\t\n\tStatsComponent\n\t\n\t\tcheck for PURPOSE_REFINE_PIVOT_FACETS in modifyRequest.\n\t\n\t\n\n\n\nNOTE: This patch is significantly smaller then the last one because i generated it using \"svn diff -x --ignore-all-space\" to supress a bunch of small formatted changes from the previous patches.\n "
        },
        {
            "author": "Hoss Man",
            "id": "comment-14179307",
            "date": "2014-10-21T23:27:21+0000",
            "content": "...we need to make stats component smart enough not to waste time re-computing top level stats on every refinement request.\n\nactually, thinking about it a bit more - with my change to StatsComponent, it's is probably even worse then wasting work on the shards \u2013 since i've set the purpose to include PURPOSE_GET_STATS, StatsComponent on the coordinator node is going to merge those top-level stats in again every time a pivot refinement response is returned to the coordinator, so the top level stats will be totally wrong. ... gotta make sure our \"final\" fix accounts for that as well. "
        },
        {
            "author": "Hoss Man",
            "id": "comment-14180880",
            "date": "2014-10-23T01:32:56+0000",
            "content": "small bits of progress on the patch review...\n\n\n\tPivotField\n\t\n\t\tfixed backcompt with constructor\n\t\tsimplified write method & fixed NPE risk + indenting\n\t\n\t\n\n\n\n\n\tDistributedFacetPivotLargeTest\n\t\n\t\trefactored query + assertFieldStats into \"doTestDeepPivotStats\"\n\t\t\n\t\t\tonly called once, and wasn't general in anyway - only usable for checking one specific query\n\t\t\n\t\t\n\t\tmade the epsilon used in assertEqual(double) a tiny float (0.1E-7) instead of a large float, so we don't overlook any bugs\n\t\n\t\n\n\n\n\n\tDistributedFacetPivotSmallTest\n\t\n\t\tsimplified ComparablePivotField\n\t\t\n\t\t\tit isn't used with stat assertions, and didn't check stats when it was used, so it doesn't need to know about stats in it's constructor\n\t\t\n\t\t\n\t\trefactored query + assertFieldStats into \"doTestDeepPivotStats\"\n\t\t\n\t\t\tonly called once, and wasn't general in anyway - only usable for checking one specific query\n\t\t\tsimplified params (no need to muck with setDistributedParams\n\t\t\n\t\t\n\t\tmade the epsilon used in assertEqual(double) a tiny float (0.1E-7) instead of a large float, so we don't overlook any bugs\n\t\n\t\n\n\n\n\n\tDistributedFacetPivotLongTailTest\n\t\n\t\tdid the match to fill in the expected values of the remaining nocommits\n\t\tmade the epsilon used in assertEqual(double) a tiny float (0.1E-7) instead of a large float, so we don't overlook any bugs\n\t\n\t\n\n "
        },
        {
            "author": "Hoss Man",
            "id": "comment-14183776",
            "date": "2014-10-25T00:12:40+0000",
            "content": "quick question for Vitaliy Zhovtyuk: in an earlier comment, you mentioned creating a new \"FacetPivotSmallTest.java\" test based on my earlier outline of how to move forward \u2013 but in later patches that test wasn't included.  was there a reason for removing it ? or was that just an oversight when generating the later patches?  Can we resurect that test from some of your earlier patches?\n\n\n\nBeen focusing on TestCloudPivotFacet.  One particularly larg change to note...\n\nAfter doing a bit of refactoring of some stuff i've mentioned in previous comments, i realized that buildRandomPivotStatsFields & buildStatsTagString didn't really make a lot of sense \u2013 notably due to some leftover cut/paste comment cruft.  digging in a bit, i realized that the way buildStatsTagString was being called, we were only ever using the first stats tag w/ the first facet.pivot \u2013 and obliterating the second pivot from the params if there was one.\n\nSo i ripped those methods out, and re-vamped the way the random stats.field params were generated, and how the tags were associated with the pivots using some slightly diff helper methods.\n\nchanges since last patch\n\n\tTestCloudPivotFacet\n\t\n\t\tmoved stats & stats.field params from pivotP to baseP\n\t\t\n\t\t\tthis simplified a lot of request logic in assertPivotStats\n\t\t\n\t\t\n\t\tbuildRandomPivotStatsFields & buildStatsTagString\n\t\t\n\t\t\treplaced with simpler logic via pickRandomStatsFields & buildPivotParamValue\n\t\t\t\n\t\t\t\tthis uncovered an NPE in StatsInfo.getStatsFieldsByTag (see below)\n\t\t\t\n\t\t\t\n\t\t\tfixed pickRandomStatsFields to include strings (not sure why they were excluded - string stats work fine in StatsComponent)\n\t\t\n\t\t\n\t\tassertPivotStats\n\t\t\n\t\t\tswitched from one verification query per stat field, to a single verification query that loops over each stats\n\t\t\tshortened some variable names & simplified assert msgs\n\t\t\tadded some hack-ish sanity checks on which stats were found for each pivot\n\t\t\n\t\t\n\t\tassertPivotData\n\t\t\n\t\t\twrapped up both assertNumFound & assertPivotStats so that a single query is executed and then each of those methods validates the data in the response that they care about\n\t\t\n\t\t\n\t\tadded \"assertDoubles()\" and \"sanityCheckAssertDoubles()\"\n\t\t\n\t\t\thammering on the test lead to a situation where stddev's were off due to double rounding because of the order that the sumOfQuares were accumulated from each shared (expected:<2.3005390038169265E9> but was:<2.300539003816927E9>)\n\t\t\tso i added a helper method to compare these types of stats with a \"small\" epsilon relative to the size of the expected value, and a simple sanity checker to test-the-test.\n\t\t\n\t\t\n\t\n\t\n\n\n\n\n\tQueryResponse\n\t\n\t\trefactored & tightened up the pivot case statement a bit to assert on unexpected keys or value types\n\t\n\t\n\n\n\n\n\tStatsComponent\n\t\n\t\tfixed NPE in StatsInfo.getStatsFieldsByTag - if someone asks for \"facet.pivot={!stats=bogus}foo\" (where 'bogus' is not a valid tag on a stats.field) that was causing an NPE - should be ignored just like ex=bogus\n\t\n\t\n\n "
        },
        {
            "author": "Hoss Man",
            "id": "comment-14186209",
            "date": "2014-10-28T01:48:32+0000",
            "content": "\n...Should we have a syntax to apply stats/queries/ranges only at specific levels in the pivot hierarchy?...\n\nI spun this off into it's own issue: SOLR-6663\n\nFor now, i think we should focus on requiring example one tag value in the \"stats\" local param \u2013 i incorporated that into some of the code/tests as i was reviewing...\n\n\nchanges since last patch\n\n\tPivotFacetProcessor\n\t\n\t\tbrought back getSubsetSize - it gives us a nice optimization in the cases where the actual subset isn't needed.\n\t\tgetStatsFields\n\t\t\n\t\t\trenamed getTaggedStatsFields so it's a little more clear it's a subset relative this pivot\n\t\t\tmade static so it's use of localparams wasn't soo obtuse (i hate how much \"stateful\" variables there are in SimpleFacets)\n\t\t\tadded error throwing if/when user specifies multiple tags seperated by commas since we want to reserve for now and may use it for controlling where in the pivot tree stats are computed (SOLR-6663)\n\t\t\tjavadocs\n\t\t\n\t\t\n\t\tdoPivots\n\t\t\n\t\t\trefactored the new stats logic to all be in one place, and not to do anything (or allocate any extra objects) unless there are docs to compute stats over, and stats to compute for those docs\n\t\t\n\t\t\n\t\n\t\n\n\n\n\n\tSolrExampleTests\n\t\n\t\tmerged testPivotFacetsStatsParsed into testPivotFacetsStats\n\t\t\n\t\t\ttestPivotFacetsStats didn't need any distinct setup from what testPivotFacetsStatsParsed, so i just moved the querys/assertions done by testPivotFacetsStats into testPivotFacetsStatsParsed and simplified the name\n\t\t\tremoved the SOLR-6349 style local params from the stats.fields \u2013 not supported yet, and if/when it is this test asserts that more stats are there then what those params were asking for, so we don't want it to suddenly break in the future.\n\t\t\tenhance the test a bit to sanity check these assertions still pass even when extra levels of pivots are requested.\n\t\t\n\t\t\n\t\tmerge testPivotFacetsStatsNotSupportedBoolean + testPivotFacetsStatsNotSupportedString => testPivotFacetsStatsNotSupported\n\t\t\n\t\t\t\"String\" was not accurate, TextField is more specific\n\t\t\talso simplified the setup - no need for so many docs, and no need for it to be diff between the two diff checks\n\t\t\tadded ignoreException \u2013 the junit logs shouldn't misslead the user when an exception is expected\n\t\t\tadded some additional assertions about the error messages\n\t\t\tadded another assertion if multiple tags seperated by commas (SOLR-6663)\n\t\t\n\t\t\n\t\n\t\n\n\n\n\n\tTestCloudPivots\n\t\n\t\treplaced nocommit comment with a comment refering to SOLR-6663\n\t\n\t\n\n\n\n "
        },
        {
            "author": "Vitaliy Zhovtyuk",
            "id": "comment-14187765",
            "date": "2014-10-29T00:15:59+0000",
            "content": "Restored FacetPivotSmallTest, was lost between patches.\nAdded distributed test org.apache.solr.handler.component.DistributedFacetPivotSmallAdvancedTestcovering 3additional cases\n 1. Getting pivot stats in string stats field\n 2. Getting top level stats on pivot stats\n 3. Pivot stats on each shard are not the same \n\nAdded getter to check stats values presence on org.apache.solr.handler.component.PivotFacetValue#getStatsValues\n Whitebox test assertions are not yet completed. Still working on it. "
        },
        {
            "author": "Hoss Man",
            "id": "comment-14189440",
            "date": "2014-10-30T01:28:12+0000",
            "content": "\nMy main focus the last day or so has been reviewing PivotFacetHelper & PivotFacetValue with an eye towards simplifying the amount of redundent code between them and StatsComponent.  Some details posted below but one key thing i wanted to point out...\n\nEven as (relatively) familiar as i am with the exsting Pivot code, it took me a long time to understand how PivotFacetHelper.getStats + PivotListEntry.STATS were working in the case of leaf level pivot values \u2013 short answer: PivotFacetHelper.getStats totally ignores the Enum value of PivotListEntry.STATS and uses \"0\" (something PivotFacetHelper.getPivots also does that i've never noticed before).  \n\nGiven that we plan to add more data to pivots in issues like SOLR-4212 & SOLR-6353, i really wanted to come up with a pattern for dealing with this that was less likeely to trip people up when looking at the code.\n\n\n\nChanges in this patch\n\n\tStatsComponent\n\t\n\t\trefactored out tiny little reusable \"unwrapStats\" utility\n\t\trefactored out reusable \"convertToResponse\" utility\n\t\t\n\t\t\ti was hoping this would help encapsulate & simplify the way the count==0 rules are applied, to make top level consistent with pivots, but that lead me down a rabbit hole of pain as far as testing and backcompat and solrj - so i just captured it in a 'force' method param.\n\t\t\tBut at least now, the method is consistently called everywhere that outputs stats, so if/when we change the rules for how \"empty\" stats are returned (see comments in SOLR-6349) we won't need to audit/change multiple pieces of code, we can just focus on callers of this method\n\t\t\n\t\t\n\t\tAdded a StatsInfo.getStatsField(key) method for use by PivotFacetHelper.mergeStats so it wouldn't need to constantly loop over every possible stats.field\n\t\n\t\n\n\n\n\n\tPivotFacetValue\n\t\n\t\tremoved an unneccessary level of wrapping arround the Map<String,StatsValues>\n\t\tswitched to using StatsComponent.convertToResponse directly instead of PivotFacetHelper.convertStatsValuesToNamedList\n\t\n\t\n\n\n\n\n\tPivotListEntry\n\t\n\t\trenamed \"index\" to \"minIndex\"\n\t\tadded an extract method that knows how to correctly deal with the diff between \"optional\" entries that may exist starting at the minIndex, and mandatory entires (field,value,count) that must exist at the expected index.\n\t\n\t\n\n\n\n\n\tPivotFacetHelper\n\t\n\t\tchanged the various \"getFoo\" methods to use PivotListEntry.FOO.extract\n\t\t\n\t\t\tthese methods now exact mainly just for convinience with the Object casting\n\t\t\tthis also ment the \"retrieve\" method could be removed\n\t\t\n\t\t\n\t\tsimplified mergeStats via:\n\t\t\n\t\t\tStatsComponent.unwrapStats\n\t\t\tStatsInfo.getStatsField\n\t\t\n\t\t\n\t\tmergeStats javadocs\n\t\tremoved convertStatsValuesToNamedList\n\t\n\t\n\n\n\n\n\tPivotFacetProcessor\n\t\n\t\tswitch using StatsComponent.convertToResponse\n\t\n\t\n\n\n\n\n\tTestCloudPivots\n\t\n\t\tupdate nocommit comment regarding 'null' actualStats based on pain encountered working on StastComponent.convertToResponse\n\t\t\n\t\t\tadded some more sanity check assertions in this case as well\n\t\t\n\t\t\n\t\n\t\n\n\n\n\n\tDistributedFacetPivotSmallTest\n\t\n\t\tadded doTestPivotStatsFromOneShard to account for an edge case in merging that occured to me while reviewing PivotFacetHelper.mergeStats\n\t\t\n\t\t\tthis fails because of how +/-Infinity are treated as the min/max - i'll working on fixing this next\n\t\t\tcurrently commented out + has some nocommits to beef up this test w/other types\n\t\t\n\t\t\n\t\n\t\n\n\n\n\n\tmerged my working changes with Vitaliy's additions (but have not yet actually reviewed the new tests)...\n\t\n\t\tFacetPivotSmallTest\n\t\tDistributedFacetPivotSmallAdvancedTest\n\t\tPivotFacetValue.getStatsValues ... allthough it's not clear to me yet what purpose/value this adds?\n\t\n\t\n\n "
        },
        {
            "author": "Hoss Man",
            "id": "comment-14190961",
            "date": "2014-10-30T22:37:07+0000",
            "content": "\nI started out focusing on fixing the +/-Infinity issue i mentioned yesterday, but while working on beefing up the asserts for this in DistributedFacetPivotSmallTest i realized the PivotField.getStatsInfos() method was returning List<FieldStatsInfo> which didn't really make a lot of sense - so i changed that to return Map<String,FieldStatsInfo> and tweaked the method name (consistent with how top level stats method works/is-named) and updated all of the affected code/tests as well.\n\nsummay of patch changes\n\n\tStatsValuesFactory\n\t\n\t\tfixed NumericStatsValues so that min/max are 'null' when no values accumulated\n\t\n\t\n\n\n\n\n\tchanged PivotField.getStatsInfos() to getFieldStatsInfos() and made it return a map \u2013 updated the following classes...\n\t\n\t\tPivotField\n\t\tQueryResponse\n\t\tSolrExampleTests\n\t\tTestCloudPivotFacet\n\t\tDistributedFacetPivotSmallTest\n\t\tDistributedFacetPivotLargeTest\n\t\tDistributedFacetPivotLongTailTest\n\t\tDistributedFacetPivotSmallAdvancedTest\n\t\n\t\n\n\n\n\n\tDistributedFacetPivotSmallTest\n\t\n\t\tfixed some +/-Infinity assumptions based on NumericStatsValues fixes\n\t\tbeefed up testing of diff data types in doTestPivotStatsFromOneShard\n\t\n\t\n\n\n\n\n\tFacetPivotSmallTest\n\t\n\t\tfixed some +/-Infinity assumptions based on NumericStatsValues fixes\n\t\n\t\n\n\n "
        },
        {
            "author": "Hoss Man",
            "id": "comment-14192844",
            "date": "2014-11-01T00:58:52+0000",
            "content": "review & some updates to the the latest tests Vitaliy added.\n\nOn monday i'll dig into how we're dealing with stas in pivot refinements (the last remaining \"nocommit\" ... i can't understand how/why \nDistributedFacetPivotSmallAdvancedTest.doTestTopStatsWithRefinement passes in this patch, and that scares me (the refinement call should pollute the top level stats, double counting at least one shard) so i really want to get to the bottom of it.\n\npatch changes\n\n\tFacetPivotSmallTest\n\t\n\t\tnew testBogusStatsTag: check that a bogus stats tag is ignored\n\t\tnew testStatsTagHasComma: check that comma causes error for now (SOLR-6663)\n\t\n\t\n\n\n\n\n\tSolrExampleTests\n\t\n\t\tswap two comments that were on the wrong asserts\n\t\n\t\n\n\n\n\n\tDistributedFacetPivotSmallAdvancedTest\n\t\n\t\tcleaned up some formatting\n\t\tdoTestTopStats\n\t\t\n\t\t\tbeefed up the assertions\n\t\t\tadded sanity checks that refinement really was happening in these requests\n\t\t\tsuprisingly this test still passes ... based on the \"nocommit\" hack i put in StatsComponent, I was farily certain this was going to fail ... i need to dig in more and make sure i understand why it doesn't fail.\n\t\t\trenamed to doTestTopStatsWithRefinement to make it a bit more clear what it's doing\n\t\t\n\t\t\n\t\tdoTestDeepPivotStatsOnOverrequest\n\t\t\n\t\t\tremoved this test - i wasn't really clear on the purpose, and in asking Vitaliy about it on IRC we realized he had missunderstood some advice i'd given him on IRC a few days ago about how to \"sanity check\" that refinement was happening (ie: what i just added to doTestTopStatsWithRefinement) so it wasn't given us any value add.\n\t\t\n\t\t\n\t\n\t\n\n "
        },
        {
            "author": "Vitaliy Zhovtyuk",
            "id": "comment-14194016",
            "date": "2014-11-02T20:54:33+0000",
            "content": "Added \"whitebox\" DistributedFacetPivotWhiteBoxTest test simulating pivot stats shard requests in cases: get top level pivots and refinement requests. Both contains stats on pivots.  "
        },
        {
            "author": "Hoss Man",
            "id": "comment-14195540",
            "date": "2014-11-04T01:41:51+0000",
            "content": "\n...i can't understand how/why DistributedFacetPivotSmallAdvancedTest.doTestTopStatsWithRefinement passes in this patch, and that scares me (the refinement call should pollute the top level stats, double counting at least one shard) so i really want to get to the bottom of it.\n\nAfter doing a bunch of manual testing to confirm that the bug really did exist, i started pouring over the test logs and confirmed there was a stupid bug in the test itself...\n\n\n// i had...\nModifiableSolrParams facetForceRefineParams = new ModifiableSolrParams(coreParams);\n\n// should have been...\nModifiableSolrParams facetForceRefineParams = new ModifiableSolrParams(facetParams);\n\n\n\n...so in the request where i was trying to force facet refinement by adding FacetParams.FACET_OVERREQUEST_COUNT=0 to the params, i wasn't even faceting at all.\n\nOnce that silly mistake was fixed, the test started failing as expected.\n\nI then beefed up Vitaliy's new DistributedFacetPivotWhiteBoxTest to include some asserts on the top level stats, and confirmed those also failed because we're re-computing them on both the initial request, and the subsequent refinement request.\n\nOnce i had those tests failing in a satisfactory way, finding a solution was fairly straight forward:  stop including stats=true in pivot refinement requests, and instead make PivotFacetProcessor recognise when it needs to build up a StatsInfo object to handle refinement requests (rather then relying on StatsComponent to do it for us).\n\nI think this is basically ready to commit - i'm going to give the patch & issue comments another going over tomorrow to see if anything pops out at me while my laptop hammers away at the tests, but if no one has any other feedback i'll commit to trunk & start backporting.\n\nsummary of changes\n\n\tDistributedFacetPivotSmallAdvancedTest\n\t\n\t\tfixed broken test of top level stats\n\t\tadded some assertion msg strings\n\t\n\t\n\tStatsComponent\n\t\n\t\tremoved the last remaining \"nocommit\" hack that set stats=true on pivot refinements\n\t\n\t\n\tPivotFacetProcessor\n\t\n\t\tchanged process() method:\n\t\t\n\t\t\tinit a StatsInfo object on demand in cases where it's a refinement request & there is a stats local param\n\t\t\tcall getTaggedStatsFields() to build up the List<StatsField> once per facet.pivot param (was being redundently called once per refinement value in old code)\n\t\t\n\t\t\n\t\tchanged processSingle() to take in the List<StatsField> as a method param\n\t\ttweaked getTaggedStatsFields() method to take in just hte stats local param instead of the full set of localparams \u2013 simplified the parsing & error handling\n\t\n\t\n\tDistributedFacetPivotWhiteBoxTest\n\t\n\t\tbeefed up test to check top level stats\n\t\ttweaked refine params to set stats=false to match what the code now does\n\t\n\t\n\tTestCloudPivotFacet\n\t\n\t\tfixed javadoc (lint error)\n\t\n\t\n\tPivotField\n\t\n\t\tfixed javadoc (lint error)\n\t\n\t\n\n\n "
        },
        {
            "author": "Hoss Man",
            "id": "comment-14196993",
            "date": "2014-11-04T22:33:01+0000",
            "content": "small API tweak...\n\n\n\trenamed PivotField.getFieldStatsInfo_s_() to PivotField.getFieldStatsInfo()\n\t\n\t\tthis makes it consistent with the same method name in QueryResponse\n\t\tupdated all callers\n\t\n\t\n\n\n\n..planning to commit to trunk a little later today. "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14197079",
            "date": "2014-11-04T23:09:43+0000",
            "content": "Commit 1636772 from hossman@apache.org in branch 'dev/trunk'\n[ https://svn.apache.org/r1636772 ]\n\nSOLR-6351: Stats can now be nested under pivot values by adding a 'stats' local param "
        },
        {
            "author": "Hoss Man",
            "id": "comment-14197235",
            "date": "2014-11-05T00:44:22+0000",
            "content": "FWIW: backport to 5x was completely painless \u2013 no problems from \"ant precommit\" and all tests pass.\n\nAssuming jenkins doesn't find any problems on trunk I'll plan to commit the backport sometime on thursday. "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14200831",
            "date": "2014-11-06T20:15:53+0000",
            "content": "Commit 1637204 from hossman@apache.org in branch 'dev/branches/branch_5x'\n[ https://svn.apache.org/r1637204 ]\n\nSOLR-6351: Stats can now be nested under pivot values by adding a 'stats' local param (merge r1636772) "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14201078",
            "date": "2014-11-06T22:29:59+0000",
            "content": "Commit 1637248 from hossman@apache.org in branch 'dev/trunk'\n[ https://svn.apache.org/r1637248 ]\n\nSOLR-6351: fix CHANGES, forgot to credit Steve Molloy "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14201087",
            "date": "2014-11-06T22:32:33+0000",
            "content": "Commit 1637249 from hossman@apache.org in branch 'dev/branches/branch_5x'\n[ https://svn.apache.org/r1637249 ]\n\nSOLR-6351: fix CHANGES, forgot to credit Steve Molloy (merge r1637248) "
        },
        {
            "author": "Hoss Man",
            "id": "comment-14201091",
            "date": "2014-11-06T22:35:31+0000",
            "content": "backported to 5x earlier today, and updated the ref guide...\n\nhttps://cwiki.apache.org/confluence/display/solr/Faceting#Faceting-CombiningStatsComponentWithPivots\nhttps://cwiki.apache.org/confluence/display/solr/The+Stats+Component#TheStatsComponent-TheStatsComponentandFaceting\n\n...calling this done.\n\nBig thanks to Vitaliy & Steve for their contributions on this. "
        },
        {
            "author": "Ashish Shrowty",
            "id": "comment-14223635",
            "date": "2014-11-24T22:19:41+0000",
            "content": "Hi all,\n\nDoes this allow for requesting only specific stats such as an mean or countDistinct? For my use case, I don't really care about the actual distinct values. Is this what SOLR-6349 is about?\n\nAlso, any idea when 5.0 is going to go out? This patch would save a lot of code I would need to write myself. \n\nThanks for your help!\n\n-Ashish "
        },
        {
            "author": "Xu Zhang",
            "id": "comment-14223731",
            "date": "2014-11-24T23:10:42+0000",
            "content": "Solr-6349 is what you asking for.  "
        },
        {
            "author": "Anshum Gupta",
            "id": "comment-14332691",
            "date": "2015-02-23T05:01:21+0000",
            "content": "Bulk close after 5.0 release. "
        },
        {
            "author": "Pablo Anzorena",
            "id": "comment-15228353",
            "date": "2016-04-06T14:35:48+0000",
            "content": "Is there any way of requesting the facets order by the sum of price e.g.?  "
        },
        {
            "author": "Pablo Anzorena",
            "id": "comment-15228373",
            "date": "2016-04-06T14:41:17+0000",
            "content": "Is there any way of requesting limit 10 order by the sum of price e.g. within pivots?\n\nI know that in the json.facet I can do this, but it has a problem of consistency when querying across multiple shards. \nAnd given that pivot facets now supports distributed searching, I tried to make a similar request, but couldn't find how to do it.\n\nThanks in advance! "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-15229117",
            "date": "2016-04-06T21:09:05+0000",
            "content": "Please raise questions like this on the user's list rather than JIRAs, we try to reserve JIRA entries for code issues rather than usage questions. "
        }
    ]
}