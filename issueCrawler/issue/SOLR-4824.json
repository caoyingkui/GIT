{
    "id": "SOLR-4824",
    "title": "Fuzzy / Faceting results are changed after ingestion of documents past a certain number",
    "details": {
        "affect_versions": "4.2,                                            4.3",
        "status": "Open",
        "fix_versions": [],
        "components": [
            "search"
        ],
        "type": "Bug",
        "priority": "Major",
        "labels": "",
        "resolution": "Unresolved"
    },
    "description": "In upgrading from SOLR 3.6 to 4.2/4.3 and comparing results on fuzzy queries, I found that after a certain number of documents were ingested the fuzzy query had drastically lower number of results.  We have approximately 18,000 documents per day and after ingesting approximately 40 days of documents, the next incremental day of documents results in a lower number of results of a fuzzy search.\n\nThe query :  http://10.100.1.xx:8080/solr/corex/select?q=cc:worde~1&facet=on&facet.field=date&fl=date&facet.sort\n\nproduces the following result before the threshold is crossed\n\n<response><lst name=\"responseHeader\">\n<int name=\"status\">0</int><int name=\"QTime\">2349</int><lst name=\"params\"><str name=\"facet\">on</str><str name=\"fl\">date</str><str name=\"facet.sort\"/>\n<str name=\"q\">cc:worde~1</str><str name=\"facet.field\">date</str></lst></lst><result name=\"response\" numFound=\"362803\" start=\"0\"></result>\n<lst name=\"facet_counts\"><lst name=\"facet_queries\"/><lst name=\"facet_fields\"><lst name=\"date\">\n<int name=\"2012-12-31\">2866</int>\n<int name=\"2013-01-01\">11372</int>\n<int name=\"2013-01-02\">11514</int>\n<int name=\"2013-01-03\">12015</int>\n<int name=\"2013-01-04\">11746</int>\n<int name=\"2013-01-05\">10853</int>\n<int name=\"2013-01-06\">11053</int>\n<int name=\"2013-01-07\">11815</int>\n<int name=\"2013-01-08\">11427</int>\n<int name=\"2013-01-09\">11475</int>\n<int name=\"2013-01-10\">11461</int>\n<int name=\"2013-01-11\">12058</int>\n<int name=\"2013-01-12\">11335</int>\n<int name=\"2013-01-13\">12039</int>\n<int name=\"2013-01-14\">12064</int>\n<int name=\"2013-01-15\">12234</int>\n<int name=\"2013-01-16\">12545</int>\n<int name=\"2013-01-17\">11766</int>\n<int name=\"2013-01-18\">12197</int>\n<int name=\"2013-01-19\">11414</int>\n<int name=\"2013-01-20\">11633</int>\n<int name=\"2013-01-21\">12863</int>\n<int name=\"2013-01-22\">12378</int>\n<int name=\"2013-01-23\">11947</int>\n<int name=\"2013-01-24\">11822</int>\n<int name=\"2013-01-25\">11882</int>\n<int name=\"2013-01-26\">10474</int>\n<int name=\"2013-01-27\">11051</int>\n<int name=\"2013-01-28\">11776</int>\n<int name=\"2013-01-29\">11957</int>\n<int name=\"2013-01-30\">11260</int>\n<int name=\"2013-01-31\">8511</int>\n</lst></lst><lst name=\"facet_dates\"/><lst name=\"facet_ranges\"/></lst></response>\n\nOnce the 40 days of documents ingested threshold is crossed the results drop as show below for the same query\n\n<response><lst name=\"responseHeader\">\n<int name=\"status\">0</int><int name=\"QTime\">2</int><lst name=\"params\"><str name=\"facet\">on</str><str name=\"fl\">date</str><str name=\"facet.sort\"/><str name=\"q\">cc:worde~1</str><str name=\"facet.field\">date</str></lst></lst>\n<result name=\"response\" numFound=\"1338\" start=\"0\"></result>\n<lst name=\"facet_counts\"><lst name=\"facet_queries\"/><lst name=\"facet_fields\"><lst name=\"date\">\n<int name=\"2012-12-31\">0</int>\n<int name=\"2013-01-01\">41</int>\n<int name=\"2013-01-02\">21</int>\n<int name=\"2013-01-03\">24</int>\n<int name=\"2013-01-04\">19</int>\n<int name=\"2013-01-05\">9</int>\n<int name=\"2013-01-06\">11</int>\n<int name=\"2013-01-07\">17</int>\n<int name=\"2013-01-08\">14</int>\n<int name=\"2013-01-09\">24</int>\n<int name=\"2013-01-10\">43</int>\n<int name=\"2013-01-11\">14</int>\n<int name=\"2013-01-12\">52</int>\n<int name=\"2013-01-13\">57</int>\n<int name=\"2013-01-14\">25</int>\n<int name=\"2013-01-15\">17</int>\n<int name=\"2013-01-16\">34</int>\n<int name=\"2013-01-17\">11</int>\n<int name=\"2013-01-18\">16</int>\n<int name=\"2013-01-19\">121</int>\n<int name=\"2013-01-20\">33</int>\n<int name=\"2013-01-21\">26</int>\n<int name=\"2013-01-22\">59</int>\n<int name=\"2013-01-23\">27</int>\n<int name=\"2013-01-24\">10</int>\n<int name=\"2013-01-25\">9</int>\n<int name=\"2013-01-26\">6</int>\n<int name=\"2013-01-27\">16</int>\n<int name=\"2013-01-28\">11</int>\n<int name=\"2013-01-29\">15</int>\n<int name=\"2013-01-30\">21</int>\n<int name=\"2013-01-31\">109</int>\n<int name=\"2013-02-01\">11</int>\n<int name=\"2013-02-02\">7</int>\n<int name=\"2013-02-03\">10</int>\n<int name=\"2013-02-04\">8</int>\n<int name=\"2013-02-05\">13</int>\n<int name=\"2013-02-06\">75</int>\n<int name=\"2013-02-07\">77</int>\n<int name=\"2013-02-08\">31</int>\n<int name=\"2013-02-09\">35</int>\n<int name=\"2013-02-10\">22</int>\n<int name=\"2013-02-11\">18</int>\n<int name=\"2013-02-12\">11</int>\n<int name=\"2013-02-13\">68</int>\n<int name=\"2013-02-14\">40</int>\n</lst></lst><lst name=\"facet_dates\"/><lst name=\"facet_ranges\"/></lst></response>\n\nI have also tested this with different months of data and have seen the same issue  around the number of documents.",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "author": "Jack Krupansky",
            "id": "comment-13658718",
            "date": "2013-05-15T19:57:11+0000",
            "content": "Lucene FuzzyQuery has a parameter named \"maxExpansions\", which defaults to 50, which I believe is the largest number of candidate terms the fuzzy query will \"rewite\", so that once you have that many matches [of terms, not documents], I don't think any more will be found. Robert or one of the other Lucene experts can confirm.\n\nAt the Lucene level this can be changed, with the FuzzyQuery(Term term, int maxEdits, int prefixLength, int maxExpansions, boolean transpositions) constructor, but the Solr query parser uses the FuzzyQuery(Term term, int maxEdits, int prefixLength) constructor, so there is no provision for overriding that limit of 50.\nAlso note that even in Lucene maxExpansions is limited to maxBooleanQueries, which would be 1024 unless you override that in solrconfig. Not that that would do you any good unless you had a query parser that let you set maxExpansions.\n\nStill, that is a reasonable enhancement request. "
        },
        {
            "author": "Lakshmi Venkataswamy",
            "id": "comment-13658732",
            "date": "2013-05-15T20:12:33+0000",
            "content": "Not sure I understand.  When I have 30 days of data I get 362,803 results.  When I add another 11 days worth of data the same search returns 1,338 results.  Even if there is a maximum limit would I not see a capping of the results as opposed to a drastic drop ?   "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13663483",
            "date": "2013-05-21T22:20:45+0000",
            "content": "I'm not very familiar with the FuzzyQuery code in question, but i believe what Jack is referring to is a limit in the number of terms that fuzzy query will consider when it scans the indexed terms (via an automata i think?) looking for terms within a given edit distance of the input.\n\nso it's not a matter of increasing documents that can cause the results to change, it's a matter of increasing the number of terms that are \"close\" to the term used in the fuzzy query.\n\nHoss'ss Uninformed example/speculation\nAssume for a moment, that you have a small index, where there are less then 50 terms in the \"text\" field, and you ask for a fuzzy query matching \"abcdefg\"  the list of \"close\" terms might be...\n\n\n\tabcdeff\n\tabcdegg\n\tabcdegf\n\tzbcdefg\n\n\n\n...and there may be a total of 100 documents matching those 4 terms \u2013 1/2 of those matches may be because of the last term (\"zbcdefg\")\n\nIf you index a handful of additional documents, but those documents contain 1000+ new terms in the \"text\" field which are very \"close\" to the input term, then the next time you do the same fuzzy quey, the expanded query might become...\n\n\n\tabcdeff\n\tabcdegg\n\t...48 more terms that start with \"abcd...\"\n\n\n\nAnd \"zbcdefg\" will be excluded from the expanded query, because the expansion code will stop looking for additional terms as soon as it finds 50 that are \"close\".\n\nSo now you will get results based on this new expansion, which may be less documents then were previously found.\n\n\n "
        },
        {
            "author": "Lakshmi Venkataswamy",
            "id": "comment-13664179",
            "date": "2013-05-22T15:15:26+0000",
            "content": "That makes sense.  So as a test I tried to restrict the search query to only 30 days of data after I had ingested the additional 11 days.  This should have returned the same number 362,803 as before but it did not.  I got 1263 results. \n\nI also noticed something else.  We have a production system that is using Solr 3.5.  I also have test systems on Solr 3.6.2 and Solr 4.3 using a smaller subset of production data.  The physical size of the index is very different in 4.3 for the same data , number of fields, configuration etc.\n\nSolr 3.5     Averages 150 Kb / document \nSolr 3.6.2   Averages 148 KB / document\nSolr 4.3     Averages 75 KB / document "
        },
        {
            "author": "Jack Krupansky",
            "id": "comment-13665103",
            "date": "2013-05-23T12:22:59+0000",
            "content": "Any committer want to clarify whether this is truly a \"Bug\" as opposed to an \"Improvement\". I think it's the latter. Now, the question is how to resolve it.\n\nAlthough it might be nice to optionally specify a maxExpansions on every query term, maybe it would be sufficient to specify it as a query request parameter, maxExpansions=n or maxFuzzyExpansions=n. Maybe it would also be nice to specify a solrconfig setting, <maxFuzzyExpansions>n<maxFuzzyExpansions>. Or, maybe just set the default higher in Solr vs. Lucene, say to 100 or 250 or 500 or even 1000, plus the query request parameter. "
        },
        {
            "author": "Lakshmi Venkataswamy",
            "id": "comment-13792742",
            "date": "2013-10-11T15:58:02+0000",
            "content": "I have tested 4.5.0 version and the same behavior has been observed.  So we are staying with 3.6 in production for now. "
        }
    ]
}