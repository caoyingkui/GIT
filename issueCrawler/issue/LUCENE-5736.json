{
    "id": "LUCENE-5736",
    "title": "Separate the classifiers to online and caching where possible",
    "details": {
        "type": "Sub-task",
        "priority": "Major",
        "labels": "",
        "resolution": "Fixed",
        "components": [
            "modules/classification"
        ],
        "affect_versions": "None",
        "status": "Closed",
        "fix_versions": [
            "5.0"
        ]
    },
    "description": "The Lucene classifier implementations are now near onlines if they get a near realtime reader. It is good for the users whoes have a continously changing dataset, but slow for not changing datasets.\n\nThe idea is: What if we implement a cache and speed up the results where it is possible.",
    "attachments": {
        "CachingNaiveBayesClassifier.java": "https://issues.apache.org/jira/secure/attachment/12648862/CachingNaiveBayesClassifier.java",
        "0803-caching.patch": "https://issues.apache.org/jira/secure/attachment/12659571/0803-caching.patch",
        "0810-caching.patch": "https://issues.apache.org/jira/secure/attachment/12660846/0810-caching.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "id": "comment-14021162",
            "author": "Gerg\u0151 T\u00f6rcsv\u00e1ri",
            "content": "The attached class is a working copy!\n\nThis is a cache included version of the SimpleNaiveBayes classifier. The cache is a hash-map, if a word needed, we search it for the all class and take it to the hash. Next time, we pull out from the cache and not searching in the index again.\n\nThe cache (re)initialization is recalculating the docsWithClassSize, clear the hash-maps, and prepare new ones. 2 map needed, and a list, the first map will contains the term-classes-termInClassOccurrence (this is the cache), the list contains the classnames, and the second map contains the class-avgUniqueTermNumber. The last two is fully preloaded, the first is dynamically building in the searches.\n\nIf there are a lot term and/or class its need a lot memory so there is a build in possibility for cutting the cache size. If there are terms thats really rare we expect that they will rarely come out in the other documents too, and they are left out from the cache. There is a possibility to left them out full from the classification calculation too. ",
            "date": "2014-06-08T09:36:11+0000"
        },
        {
            "id": "comment-14021163",
            "author": "Gerg\u0151 T\u00f6rcsv\u00e1ri",
            "content": "The online modification of the SimpleNaiveBayesClassifier in the 5699 attachment and mentioned in the comment too.\nThe KNN classifier was online out of the box if the user use commit properly, or use a near-real-time writer. ",
            "date": "2014-06-08T09:39:28+0000"
        },
        {
            "id": "comment-14090493",
            "author": "Tommaso Teofili",
            "content": "the second patch looks better, the only thing I would change is extending from SimpleNaiveBayesClassifier and avoid rewriting the same methods that do not change in the caching version. ",
            "date": "2014-08-08T08:57:00+0000"
        },
        {
            "id": "comment-14105430",
            "author": "Tommaso Teofili",
            "content": "I have a doubt on CachingNaiveBayesClassifier#reInitCache method, there it seems the termList List is populated but never used, it seems that it's either useless so it can be removed or ignored by mistake so it has to be properly used, what is it? (to me the most likely seems the first, as there's already the frequencyMap object). ",
            "date": "2014-08-21T14:57:10+0000"
        },
        {
            "id": "comment-14105446",
            "author": "Gerg\u0151 T\u00f6rcsv\u00e1ri",
            "content": "Yes, I'm remembering now. It was used for iterating tough the frequencyMap, but I started to refactor that for cycle with the MapEntry way, and I mistakenly left the termList in. ",
            "date": "2014-08-21T15:11:26+0000"
        },
        {
            "id": "comment-14106608",
            "author": "Tommaso Teofili",
            "content": "ok thanks, I'll remove it and commit this. ",
            "date": "2014-08-22T07:59:18+0000"
        },
        {
            "id": "comment-14106614",
            "author": "ASF subversion and git services",
            "content": "Commit 1619700 from Tommaso Teofili in branch 'dev/trunk'\n[ https://svn.apache.org/r1619700 ]\n\nLUCENE-5736 - added caching version of NB classifier ",
            "date": "2014-08-22T08:04:17+0000"
        },
        {
            "id": "comment-14207815",
            "author": "ASF subversion and git services",
            "content": "Commit 1638717 from Tommaso Teofili in branch 'dev/trunk'\n[ https://svn.apache.org/r1638717 ]\n\nLUCENE-5736 - adding test for caching nb classifier ",
            "date": "2014-11-12T08:38:54+0000"
        },
        {
            "id": "comment-14207835",
            "author": "ASF subversion and git services",
            "content": "Commit 1638724 from Tommaso Teofili in branch 'dev/trunk'\n[ https://svn.apache.org/r1638724 ]\n\nLUCENE-5736 - fixed test javadoc ",
            "date": "2014-11-12T08:56:31+0000"
        },
        {
            "id": "comment-14332747",
            "author": "Anshum Gupta",
            "content": "Bulk close after 5.0 release. ",
            "date": "2015-02-23T05:01:41+0000"
        }
    ]
}