{
    "id": "LUCENE-1305",
    "title": "Assertion error in TermsInfoWriter",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [
            "core/store"
        ],
        "type": "Bug",
        "fix_versions": [],
        "affect_versions": "2.3.2",
        "resolution": "Invalid",
        "status": "Resolved"
    },
    "description": "The test passes on my local machine but fails on machine in our lab. Both are using JDK 6 and Ubuntu 8.04. Another interesting difference is that the directory that my input files are read from is an NFS share, but the index is written to a local disk. the indexing process is single-threaded. This test completes successfully with lucene 2.2.0 but fails with 2.3.2 (pulled from the maven2 repository).\n\n\nindexEnron(bob.IndexingTest)  Time elapsed: 41.285 sec  <<< FAILURE!\njava.lang.AssertionError: Terms are out of order: field=B_contentid (number 7) lastField=B_contentid (number 7) text=SHA_256  lastText=SHA_256 \n\tat org.apache.lucene.index.TermInfosWriter.add(TermInfosWriter.java:154)\n\tat org.apache.lucene.index.DocumentsWriter.appendPostings(DocumentsWriter.java:2320)\n\tat org.apache.lucene.index.DocumentsWriter.writeSegment(DocumentsWriter.java:2015)\n\tat org.apache.lucene.index.DocumentsWriter.flush(DocumentsWriter.java:552)\n\tat org.apache.lucene.index.IndexWriter.doFlush(IndexWriter.java:2623)\n\tat org.apache.lucene.index.IndexWriter.flush(IndexWriter.java:2523)\n\tat org.apache.lucene.index.IndexWriter.addDocument(IndexWriter.java:1484)\n\tat org.apache.lucene.index.IndexWriter.addDocument(IndexWriter.java:1442)",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "date": "2008-06-12T15:54:54+0000",
            "content": "Can you post the test case that hits this? ",
            "author": "Michael McCandless",
            "id": "comment-12604551"
        },
        {
            "date": "2008-06-12T16:01:21+0000",
            "content": "The test passes on my local machine but fails on machine in our lab.\n\nJust to clarify here: are you saying that using 2.3.2, and the same OS & JRE, that the test fails on the machine in your lab but passes on your local machine?\n\nWhich exact version of JDK 6 are you using?\n\nWhat are the differences between these two machines?\n\nWhen it fails on the machine in your lab, is it always at the same point (after same number of added docs)?  Or is there some randomness? ",
            "author": "Michael McCandless",
            "id": "comment-12604554"
        },
        {
            "date": "2008-06-12T16:07:56+0000",
            "content": "\nThe test case indexes the Enron corpus and exercises our applications Document creation stuff, which is quite a few classes, most of which I can't post here. \n\nI'm a long term Lucene user and I've never seen this kind of failure before, so I'm expecting it to be an environmental issue or some ugly combination of pieces. I noticed that jdk6 has many hotspot bugs that affect Lucene. We've had to disable hotstop for invertDocument because it does, eventually, segfault. \n\nOur java version is;\n\njava version \"1.6.0_04\"\nJava(TM) SE Runtime Environment (build 1.6.0_04-b12)\nJava HotSpot(TM) Client VM (build 10.0-b19, mixed mode, sharing)\n ",
            "author": "Robert Newson",
            "id": "comment-12604556"
        },
        {
            "date": "2008-06-12T16:13:03+0000",
            "content": "\nOk, new theory. It seems I have both 2.2.0 and 2.3.2 on my classpath. Maven 2, I curse you. ",
            "author": "Robert Newson",
            "id": "comment-12604558"
        },
        {
            "date": "2008-06-12T16:19:28+0000",
            "content": "\nWorks just fine with just 2.3.2 on the classpath, false alarm.  ",
            "author": "Robert Newson",
            "id": "comment-12604562"
        },
        {
            "date": "2008-06-12T16:21:02+0000",
            "content": "\nHad two versions of Lucene on my classpath (2.2.0 and 2.3.2), this doesn't work, nor should it. ",
            "author": "Robert Newson",
            "id": "comment-12604563"
        },
        {
            "date": "2008-06-12T17:01:48+0000",
            "content": "Had two versions of Lucene on my classpath (2.2.0 and 2.3.2), this doesn't work, nor should it.\n\nHmm, I would have expected that this would just mean you get one or the other (ie 2.2.0 or 2.3.2), but, not the above exception.  Are you really sure the exception is gone?\n\nI noticed that jdk6 has many hotspot bugs that affect Lucene\n\nHmm, I had only known about this one (from LUCENE-1282):\n\n    http://bugs.sun.com/bugdatabase/addVote.do?bug_id=6707044\n\nFeel free to go vote for it!\n\nYour case (a segfault) sounds like it could be something different.  If you can work that down to an example, or provide some details, maybe we can open a different bug with sun. ",
            "author": "Michael McCandless",
            "id": "comment-12604576"
        },
        {
            "date": "2008-06-12T17:16:12+0000",
            "content": "\nWell, it passes when I have only one of the two (either of them) and not with the mixture. So, between the two versions I expect it's the ordering of classes in ClassLoader. If there's a class that exists only in one, that might be the source.\n\nSo, I think the issue is resolved when only one version of Lucene exists. With the mixture it failed at document 7, without I can index all 520,631 documents.\n\nMy experience with Sun is that the bug parade is a nice place to visit to find out why the bug you've just encountered has been known, but not fixed, for 3 years. \n\nI'll ask the developer in question whether we can isolate the segfault, but it crops up with very low probability when we do mass indexing.  ",
            "author": "Robert Newson",
            "id": "comment-12604582"
        },
        {
            "date": "2008-06-12T18:48:10+0000",
            "content": "OK, that's odd, but since it's stopped the exception, that's good! ",
            "author": "Michael McCandless",
            "id": "comment-12604614"
        }
    ]
}