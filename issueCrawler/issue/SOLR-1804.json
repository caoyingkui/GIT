{
    "id": "SOLR-1804",
    "title": "Upgrade Carrot2 to 3.2.0",
    "details": {
        "affect_versions": "None",
        "status": "Closed",
        "fix_versions": [
            "3.1",
            "4.0-ALPHA"
        ],
        "components": [
            "contrib - Clustering"
        ],
        "type": "Improvement",
        "priority": "Major",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "http://project.carrot2.org/release-3.2.0-notes.html\n\nCarrot2 is now LGPL free, which means we should be able to bundle the binary!",
    "attachments": {
        "SOLR-1804-carrot2-3.4.0-dev-trunk.patch": "https://issues.apache.org/jira/secure/attachment/12450694/SOLR-1804-carrot2-3.4.0-dev-trunk.patch",
        "SOLR-1804-carrot2-3.4.0-libs.zip": "https://issues.apache.org/jira/secure/attachment/12452641/SOLR-1804-carrot2-3.4.0-libs.zip",
        "carrot2-core-3.4.0-jdk1.5.jar": "https://issues.apache.org/jira/secure/attachment/12452908/carrot2-core-3.4.0-jdk1.5.jar",
        "SOLR-1804.patch": "https://issues.apache.org/jira/secure/attachment/12452640/SOLR-1804.patch",
        "SOLR-1804-carrot2-3.4.0-dev.patch": "https://issues.apache.org/jira/secure/attachment/12450150/SOLR-1804-carrot2-3.4.0-dev.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Stanislaw Osinski",
            "id": "comment-12840670",
            "date": "2010-03-03T14:30:10+0000",
            "content": "Carrot2 3.2.0 uses Lucene 3.x API, so we'd need to wait until Solr upgrades too. A patch upgrading Carrot2 to 3.2.0 in Solr is here: http://issues.carrot2.org/browse/CARROT-623. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-12845301",
            "date": "2010-03-15T13:11:13+0000",
            "content": "I wonder if you guys have any insight why the results of this test may have changed from 16 to 15 between Lucene 3.0 and Lucene 3.1-dev: http://svn.apache.org/viewvc?view=revision&revision=923048\n\nIt did not change between Lucene 2.9 and Lucene 3.0, so I'm concerned about why the results would change between 3.0 and 3.1-dev. \n\nOne possible explanation would be if Carrot2 used Version.LUCENE_CURRENT somewhere in its code. Any ideas? "
        },
        {
            "author": "Stanislaw Osinski",
            "id": "comment-12845441",
            "date": "2010-03-15T18:24:31+0000",
            "content": "Hi Robert,\n\nLucene dependency is the only change, right? Or you also upgraded Carrot2 from e.g. 3.1 to 3.2? If the latter is the case, the number of cluster may have changed e.g. because we tuned stop words or other algorithm attributes.\n\nS.\n "
        },
        {
            "author": "Robert Muir",
            "id": "comment-12845451",
            "date": "2010-03-15T18:39:35+0000",
            "content": "Hi Stanislaw:\n\nCorrect, I did not upgrade anything else, just lucene. \n\nI'm sorry its not exactly related to this issue \n(although If we need to upgrade carrot2 to be compatible with Lucene 3.x, then thats ok)\n\nMy concern is more that we did something in Lucene between 3.0 \nand now that caused the results to be different... though again\nthis could be explained if somewhere in its code Carrot2 uses some\nLucene analysis component, but doesn't hardwire Version to LUCENE_29.\n\nIf all else fails I can try to seek out the svn rev # of Lucene that causes this change,\nby brute force binary search  "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12845453",
            "date": "2010-03-15T18:46:38+0000",
            "content": "Robert, instead of tracking it down by brute force, you might just dump out the clusters and see if they are still reasonable.  If they are, I wouldn't worry too much about it, as it is likely due to the issues Staszek mentioned. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-12845455",
            "date": "2010-03-15T18:58:17+0000",
            "content": "Grant  I am concerned about a possible BW break in Lucene trunk, that is all.\nI think its strange that 3.0 and 3.1 jars give different results.\n\nCan you tell me if the clusters are reasonable? here is the output.\n\n\njunit.framework.AssertionFailedError: number of clusters: [\n{labels=[Data Mining Applications], docs=[5, 13, 25, 12, 27],clusters=[]}, \n{labels=[Databases],docs=[15, 21, 7, 17, 11],clusters=[]}, \n{labels=[Knowledge Discovery],docs=[6, 18, 15, 17, 10],clusters=[]}, \n{labels=[Statistical Data Mining],docs=[28, 24, 2, 14],clusters=[]}, \n{labels=[Data Mining Solutions],docs=[5, 22, 8],clusters=[]}, \n{labels=[Data Mining Techniques],docs=[12, 2, 14],clusters=[]}, \n{labels=[Known as Data Mining],docs=[23, 17, 19],clusters=[]}, \n{labels=[Text Mining],docs=[6, 9, 29],clusters=[]}, \n{labels=[Dedicated],docs=[10, 11],clusters=[]}, \n{labels=[Extraction of Hidden Predictive],docs=[3, 11],clusters=[]}, \n{labels=[Information from Large],docs=[3, 7],clusters=[]}, \n{labels=[Neural Networks],docs=[12, 1],clusters=[]}, \n{labels=[Open],docs=[15, 20],clusters=[]}, \n{labels=[Research],docs=[26, 8],clusters=[]}, \n{labels=[Other Topics],docs=[16],clusters=[]}\n] expected:<16> but was:<15>\n\n "
        },
        {
            "author": "Stanislaw Osinski",
            "id": "comment-12845459",
            "date": "2010-03-15T19:00:56+0000",
            "content": "I was about to offer advice similar to Grant's, but wanted to wait to confirm the scope of changes.\n\nIf it was only Lucene dependency update, with the assumption that the update didn't change the documents fed to Carrot2 in tests, the results shouldn't change. Carrot2 uses Lucene interfaces internally, but the tokenizer is not the standard Lucene one; so no Version.LUCENE_* issues as far as I can tell.\n\nI haven't got Solr code handy, but maybe the test performs clustering on summaries generated from the original test documents and Lucene 3.x introduces some changes in the way summaries are generated?\n\nIf the clusters look reasonable, the problem is probably not critical, but still worth investigation to make sure it's not a bug of some kind.\n\nS. "
        },
        {
            "author": "Stanislaw Osinski",
            "id": "comment-12845462",
            "date": "2010-03-15T19:02:34+0000",
            "content": "Yeah, the clusters look good. When you're done with upgrading Lucene to 3.x, we could also upgrade Carrot2 to version 3.2.0, which is LGPL-free and could be distributed together with Solr.\n\nS. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-12845474",
            "date": "2010-03-15T19:25:30+0000",
            "content": "Thanks for the confirmation the clusters are ok.\n\nWell, this is embarrassing, it turns out it is a backwards break, \nthough documented, and the culprit is yours truly.\n\nThis is the reason it gets different results:\n\n* LUCENE-2286: Enabled DefaultSimilarity.setDiscountOverlaps by default.\n  This means that terms with a position increment gap of zero do not\n  affect the norms calculation by default.  (Robert Muir)\n\n\n\nI'll change the test to expect 15 clusters with Lucene 3.1, thanks  "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12850204",
            "date": "2010-03-26T16:35:17+0000",
            "content": "We should be able to go through with this now, right? "
        },
        {
            "author": "Stanislaw Osinski",
            "id": "comment-12890726",
            "date": "2010-07-21T13:40:14+0000",
            "content": "Hi,\n\nAs we're near the 3.4.0 release of Carrot2, I'm including a patch that upgrades the clustering plugin. The most notable changes are:\n\n\n\t[3.4.0] Carrot2 core no longer depends on Lucene APIs, so the build.xml can be enabled again. The only class that makes use of Lucene API, LuceneLanguageModelFactory, is now included in the plugin's code, so there shouldn't be any problems with refactoring. In fact, I've already updated LuceneLanguageModelFactory to remove the use of deprecated APIs.\n\t[3.3.0] The STC algorithm has seen some significant scalability improvements\n\t[3.2.0] Carrot2 core no longer depends on LGPL libraries, so all the JARs can now be included in Solr SVN and SOLR-2007 won't need fixing.\n\n\n\nIncluded is a patch against r966211. A ZIP with JARs will follow in a sec.\n\nA couple of notes:\n\n\n\tThe upgrade requires upgrading Google collections to Guava. This is a drop-in replacement, all tests pass for me after the upgrade, plus the upgrade is recommended on the original Google Collections site.\n\tThe patch includes Carrot2 3.4.0-dev JAR, but I guess it's worth committing already to avoid the library downloads hassle (SOLR-2007).\n\tOriginally, Carrot2 supports clustering of Chinese content based on the Smart Chinese Tokenizer. This tokenizer would have to be referenced from the LuceneLanguageModelFactory class in Solr. However, when compiling the code in Ant, this smartcn doesn't seem available in the classpath. Is it a matter of modifying the build files, or it's a policy on dependencies between plugins?\n\n\n\nLet me know if you have any problems applying the patch.\n\nThanks!\n\nS. "
        },
        {
            "author": "Stanislaw Osinski",
            "id": "comment-12890727",
            "date": "2010-07-21T13:42:46+0000",
            "content": "Libs required for the Carrot2 3.4.0 update. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-12890748",
            "date": "2010-07-21T15:08:48+0000",
            "content": "Hi Stanislaw: this looks cool! So, carrot2 jars don't depend directly on Lucene, and we can re-enable this component in trunk, and simply maintain the LuceneLanguageModelFactory?\n\nAs far as the smart chinese, its currently not included with Solr, so I think this is why you have trouble. But could we enable a carrot2 factory for it that reflects it, in case the user puts the jar in the classpath? "
        },
        {
            "author": "Stanislaw Osinski",
            "id": "comment-12890757",
            "date": "2010-07-21T15:56:10+0000",
            "content": "\nHi Stanislaw: this looks cool! So, carrot2 jars don't depend directly on Lucene, and we can re-enable this component in trunk, and simply maintain the LuceneLanguageModelFactory? \n\nCorrect. The only dependency on Lucene is LuceneLanguageModelFactory, which is now part of Solr code base. In fact, we could also try bringing back the clustering plugin to Solr trunk, though I haven't tried that yet.\n\n\nAs far as the smart chinese, its currently not included with Solr, so I think this is why you have trouble. But could we enable a carrot2 factory for it that reflects it, in case the user puts the jar in the classpath?\n\nEssentially, the dependency on the smart chinese is optional in a sense that the lack of it will degrade the quality of clustering in Chinese, but will not break it. Let me see if I can make it optionally loadable in LuceneLanguageModelFactory too. If not, we'll have to live with degraded clustering quality in case of Chinese. "
        },
        {
            "author": "Stanislaw Osinski",
            "id": "comment-12890848",
            "date": "2010-07-21T19:36:06+0000",
            "content": "\nEssentially, the dependency on the smart chinese is optional in a sense that the lack of it will degrade the quality of clustering in Chinese, but will not break it. Let me see if I can make it optionally loadable in LuceneLanguageModelFactory too.\n\nI think we could handle this in a similar way as in Carrot2: attempt to load chinese tokenizer and fall back to the default one in case of class loading exceptions. The easiest implementation route would be to include smart chinese as a dependency during compilation of the clustering plugin with an understanding that the library may or may not be available during runtime. Is that possible with the current Solr compilation scripts? "
        },
        {
            "author": "Stanislaw Osinski",
            "id": "comment-12891075",
            "date": "2010-07-22T09:36:44+0000",
            "content": "Ok, here's another shot. This time, the language model factory includes support for Chinese. To avoid compilation issues, the classes are loaded through reflection. Not pretty, but works. If there's a way to have access to smart chinese at compilation time, let me know, I can remove the reflection stuff, so that the refactoring is more reliable. "
        },
        {
            "author": "Stanislaw Osinski",
            "id": "comment-12891076",
            "date": "2010-07-22T09:38:27+0000",
            "content": "Updated dependencies. "
        },
        {
            "author": "Stanislaw Osinski",
            "id": "comment-12893163",
            "date": "2010-07-28T12:40:08+0000",
            "content": "A patch against solr trunk, the libs are the same as for the branch_3x patch. "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12900698",
            "date": "2010-08-20T14:13:47+0000",
            "content": "What's the status on this?  I'd like to commit, but is there a new C2 version out that we should go to? "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12900700",
            "date": "2010-08-20T14:18:44+0000",
            "content": "Also, why is the Guava lib in solr/lib as opposed to contrib/clustering/lib? "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12900701",
            "date": "2010-08-20T14:21:24+0000",
            "content": "Also, is the libs zip file the complete set of libraries or do I still need ehcache and some of the others? "
        },
        {
            "author": "Stanislaw Osinski",
            "id": "comment-12900715",
            "date": "2010-08-20T14:54:57+0000",
            "content": "Hi Grant,\n\nGood timing, Carrot2 3.4.0 stable release is being built right at this moment. When the stable JAR is available, I'll re-upload the ZIP with JARs. The ZIP contains all the dependencies you need, ehcache and others are now optional.\n\nAs I explained in some earlier comment, Google now recommends upgrading from Google Collections to Guava. The upgrade is a drop-in replacement, all Solr tests passed for me locally after the upgrade. We already switched Carrot2 to Guava and the reason it's in solr/lib rather than contrib/clustering/lib is to avoid class path conflicts and duplication. If it's not possible to upgrade Solr's Goolge Collections to Guava, please let me know, I'll come up with something.\n\nThanks!\n\nS. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-12900719",
            "date": "2010-08-20T15:00:17+0000",
            "content": "I think this is good to see, so we can re-enable the plugin in trunk.\n\nFor a future issue/discussion, I wonder if it would be possible to improve the language/analysis integration such that carrot2 gets the analysis defined from a Solr schema.xml instead of its own factory directly linked to lucene stemmers etc? This might be a dumb question but it just seems like it might be an easier way for a user to configure it, and it would provide more flexibility. "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12900746",
            "date": "2010-08-20T15:58:45+0000",
            "content": "Brings this up to date, fixing some build issues.  The Carrot test does not pass.  Stazsek, perhaps you can take this, upgrade to latest C2 and get the test to work?\n\nThen, I can commit. "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12900748",
            "date": "2010-08-20T15:59:18+0000",
            "content": "Also, Stazsek, please check yes for donating the libraries w/ the ASL. "
        },
        {
            "author": "Stanislaw Osinski",
            "id": "comment-12900754",
            "date": "2010-08-20T16:09:40+0000",
            "content": "Here are the libs with Carrot2 3.4.0 JAR.\n\n1. Apply the patch (the patch hasn't changed)\n2. Copy the libs from the ZIP overwriting the old ones\n3. Remove Google collections from solr/lib (it's replaced by Guava from the ZIP). If you don't do that, tests will fail due to class path conflicts.\n\nI've just tested this on my machine with the latest branch_3x (r966551) and all tests pass. If some tests fail for you, let me know and I'll investigate.\n\nS. "
        },
        {
            "author": "Stanislaw Osinski",
            "id": "comment-12900755",
            "date": "2010-08-20T16:25:23+0000",
            "content": "Hi Robert,\n\nSome initial work on tighter integration with Solr should be possible after applying the patch from this issue. The patch contains a Solr-specific implementation of Carrot2's ILanguageModel interface. My rough guess is that the implementation of that interface could be further tweaked to create  IStemmer and ITokenizer implementations based on the schema.xml settings. It could also implement the isCommonWord() method based on Solr's resources. A few notes though:\n\n\n\tCarrot2 is slightly different from typical IR in a sense that it doesn't completely discard stop words \u2013 the tokenizer does not remove them from the token stream. The reason for this is that the cluster labels are taken literally from the input text and if we discard stop words, the labels won't as readable.\n\n\n\n\n\tThe ILanguageModel#isStopLabel() method is another Carrot2-specific thing. It's a more fine-grained method of removing useless labels, especially useful for domain-specific content. Carrot2's default implementation is based on regular expressions similar to this. I'm not sure if there's a corresponding resource in Solr though.\n\n\n\nWe're thinking of restructuring Carrot2's language model a bit in one of the next releases, so it's a good chance to include some Solr-inspired improvements as well.\n\nS. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-12900791",
            "date": "2010-08-20T17:39:29+0000",
            "content": "Stanislaw: I looked at the ILanguageModel interface along with your other comments, and had these thoughts:\n\nFor these carrot2-specific things (isCommonWord, isStopLabel), the carrot2 integration could have TokenFilters that set Attributes. So for example a Carrot2CommonWordFilter would not remove tokens from the stream, it would simply mark a boolean attribute such as Carrot2CommonWordAttribute. Stop label processing could be done the same way.\n\nSo, carrot2 processing could be based upon a schema.xml declaration, but the configuration would use these special carrot2 filters to mark attributes that carrot2 needs. "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12901422",
            "date": "2010-08-23T14:47:44+0000",
            "content": "Trunk: Committed revision 988129.\n3.x: Committed revision 988137. "
        },
        {
            "author": "Stanislaw Osinski",
            "id": "comment-12901770",
            "date": "2010-08-24T08:22:34+0000",
            "content": "Hi Grant,\n\nThanks for committing the patches! I noticed that the 3.x branch build failed because Carrot2 JAR had classes in Java 1.6 format. I'm attaching a Java 1.5-compliant JAR. After replacing the original JAR with the attached one, all Solr tests passed on Java 1.5 on my machine. Apologies for not checking this earlier.\n\nAlso, I believe the last paragraph of contrib/clustering/README.txt does not hold any more as all JARs are now distributed with Solr.\n\nStaszek "
        },
        {
            "author": "Stanislaw Osinski",
            "id": "comment-12901791",
            "date": "2010-08-24T09:24:02+0000",
            "content": "One more thing: contrib/clustering in trunk seems to contain some leftovers from the time clustering was disabled: build.xml.disabled, DISABLED-README.txt and the LGPL-related paragraph in README.txt. I guess we could remove them too to avoid confusion.\n\nS. "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12901817",
            "date": "2010-08-24T10:55:26+0000",
            "content": "Applied.  Stupid OS X and it's refusal to properly support 1.5 "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-13013255",
            "date": "2011-03-30T15:46:00+0000",
            "content": "Bulk close for 3.1.0 release "
        },
        {
            "author": "David Smiley",
            "id": "comment-13046188",
            "date": "2011-06-08T20:16:51+0000",
            "content": "Quick question: Why is guava in solr/lib instead of solr/contrib/clustering/lib ? I did a search on trunk for use of Guava and it is strictly limited to this contrib module. Does placement of this lib here signal that use of Guava in other parts of Solr is okay?  (Guava is pretty cool so that would be nice) "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13046193",
            "date": "2011-06-08T20:28:19+0000",
            "content": "IIRC, Noble intended to use it and moved it to lib (see SOLR-1707 for one potential use).\nIMO, it's use in other parts of Solr are fine (just don't automatically assume it's faster/better \n "
        },
        {
            "author": "Dawid Weiss",
            "id": "comment-13046201",
            "date": "2011-06-08T20:41:04+0000",
            "content": "I agree with Yonik \u2013 Guava is compact and neat to use and we use it all the time, but I'd be careful with automatic replacement of certain constructs in performance-critical loops. It's well written, but certain methods sacrifice some performance for code beauty. "
        },
        {
            "author": "Steve Rowe",
            "id": "comment-13046210",
            "date": "2011-06-08T20:47:38+0000",
            "content": "FYI, Dawid's SOLR-2378 introduced use of Guava outside of the clustering contrib. "
        },
        {
            "author": "David Smiley",
            "id": "comment-13046211",
            "date": "2011-06-08T20:53:57+0000",
            "content": "Steve, the patch for SOLR-2378 did use Guava, but whoever committed to trunk must have backed it out because I went to the same class file I have on an updated trunk, FSTLookup.java, and there is no reference to an applicable import statement, but on the patch it was there.\n\nAgain, if you do a search for \"com.google.common\" on any .java file in trunk, you'll only find it in the clustering contrib module. "
        },
        {
            "author": "Dawid Weiss",
            "id": "comment-13046215",
            "date": "2011-06-08T20:58:49+0000",
            "content": "I honestly don't remember what was it I used Guava for in FSTLookup, but it's most likely the generic-less constructors for Lists or Maps... nothing fancy. And I think Robert might have removed the dependency when he moved FSTLookup to a module. "
        },
        {
            "author": "Steve Rowe",
            "id": "comment-13046228",
            "date": "2011-06-08T21:16:11+0000",
            "content": "if you do a search for \"com.google.common\" on any .java file in trunk, you'll only find it in the clustering contrib module.\n\nRight: grep 'com\\.google' $(find . -name '*.java') only returns files under solr/contrib/clustering/.\n\nI think Robert might have removed the dependency when he moved FSTLookup to a module.\n\nYup, e.g. Lists.newArrayList() -> new ArrayList<Entry>() : <http://svn.apache.org/viewvc/lucene/dev/trunk/modules/suggest/src/java/org/apache/lucene/search/suggest/fst/FSTLookup.java?r1=1097216&r2=1126642&diff_format=h#l154>.\n\nSo from April 14th through May 23rd, Solr did have a Guava dependency . "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13046266",
            "date": "2011-06-08T22:45:14+0000",
            "content": "\nYup, e.g. Lists.newArrayList() -> new ArrayList<Entry>() : <http://svn.apache.org/viewvc/lucene/dev/trunk/modules/suggest/src/java/org/apache/lucene/search/suggest/fst/FSTLookup.java?r1=1097216&r2=1126642&diff_format=h#l154>.\n\nWell not just that, e.g.:\n\nfinal List<String> input = Lists.newArrayList(Iterables.transform(benchmarkInput, new Function<TermFreq, String>() {\n  public String apply(TermFreq tf) {\n    return tf.term.substring(0, Math.min(tf.term.length(),\n        minPrefixLen + random.nextInt(maxPrefixLen - minPrefixLen + 1)));\n  }\n}));\n\n\n\nversus\n\n\nfinal List<String> input = new ArrayList<String>(benchmarkInput.size());\nfor (TermFreq tf : benchmarkInput) {\n  input.add(tf.term.substring(0, Math.min(tf.term.length(),\n      minPrefixLen + random.nextInt(maxPrefixLen - minPrefixLen + 1))));\n}\n\n\n\nOne of these any of us can look at instantly and know whats going on. The other is more like the C++ STL,\nsure if the developer is really cautious and it doesnt go out of hand it might stay understandable.\n\nI suppose in all this refactoring, I didn't see what Guava bought us at all, except extra method calls. Guess\nI'm just not a fan.\n\nhttp://svn.apache.org/viewvc/lucene/dev/trunk/modules/suggest/src/test/org/apache/lucene/search/suggest/LookupBenchmarkTest.java?r1=1097216&r2=1126642&diff_format=h\n "
        },
        {
            "author": "David Smiley",
            "id": "comment-13046545",
            "date": "2011-06-09T13:57:05+0000",
            "content": "Good point Rob. If any use of Guava in a patch to Solr core is going to get reverted, then we might as well recognize that now and move Guava from Solr's lib to clustering's lib directory. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13046973",
            "date": "2011-06-10T02:45:44+0000",
            "content": "well it wasnt 'reverted', but in general I think if we can simplify code, we should.\n\nNOTE: my complaint's aren't with Dawid's code, it was easy to see what was going on (though I did check guava code to make sure it wasnt doing anything really magic behind the scenes, aka we weren't losing anything)... but again my concern is the more general case, that by using external libraries like this, it makes it harder for others to work on the code, and makes us more prone to bugs (e.g. now we have to worry about bugs in guava too, we have a hard enough time with JRE bugs).\n\nIf its truly necessary, e.g. if Guava has a HuperDuper O(1)-for-all-operations datastructure, then go for it and use it, but if its just a thin veil around what java already provides, I think we should try to avoid it. "
        },
        {
            "author": "Dawid Weiss",
            "id": "comment-13047047",
            "date": "2011-06-10T07:14:09+0000",
            "content": "I am not considering changes to my code to be a personal attack, so no worries. And, since I'm a former assembly guy, straightforward code flow is what I understand and relate to \u2013 I use Guava from time to time to catch up with the young and hippie buzzwords (closures, abstraction, you know the like .\n\nAnd seriously, our 99% of Guava use is for instantiating lists and maps without providing generics (something that the new Java release will be able to infer from the code anyway \u2013 at least if I'm reading commit logs to the javac compiler right). The remaining 1% is for cascading list filters and sorting orders (which, after you get used to them a little bit, work out and read pretty nicely).\n\nI'm not by all means saying we should switch to Guava; I used it because I saw it was in global lib/ directory (and this happened after the patch to Carrot2 I believe). "
        }
    ]
}