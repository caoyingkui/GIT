{
    "id": "SOLR-5986",
    "title": "Don't allow runaway queries from harming Solr cluster health or search performance",
    "details": {
        "affect_versions": "None",
        "status": "Closed",
        "fix_versions": [
            "5.0"
        ],
        "components": [
            "search"
        ],
        "type": "Improvement",
        "priority": "Critical",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "The intent of this ticket is to have all distributed search requests stop wasting CPU cycles on requests that have already timed out or are so complicated that they won't be able to execute. We have come across a case where a nasty wildcard query within a proximity clause was causing the cluster to enumerate terms for hours even though the query timeout was set to minutes. This caused a noticeable slowdown within the system which made us restart the replicas that happened to service that one request, the worst case scenario are users with a relatively low zk timeout value will have nodes start dropping from the cluster due to long GC pauses.\n\nAaron McCurry Built a mechanism into Apache Blur to help with the issue in BLUR-142 (see commit comment for code, though look at the latest code on the trunk for newer bug fixes).\n\nSolr should be able to either prevent these problematic queries from running by some heuristic (possibly estimated size of heap usage) or be able to execute a thread interrupt on all query threads once the time threshold is met. This issue mirrors what others have discussed on the mailing list: http://mail-archives.apache.org/mod_mbox/lucene-solr-user/200903.mbox/%3C856ac15f0903272054q2dbdbd19kea3c5ba9e105b9d8@mail.gmail.com%3E",
    "attachments": {
        "SOLR-5986.patch": "https://issues.apache.org/jira/secure/attachment/12661936/SOLR-5986.patch",
        "SOLR-5986-fixtests.patch": "https://issues.apache.org/jira/secure/attachment/12673298/SOLR-5986-fixtests.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Steve Davids",
            "id": "comment-14033084",
            "date": "2014-06-16T22:08:06+0000",
            "content": "As a follow up, we are still experiencing frequent issues with this specific issue which is getting more and more frequent. Upon further research it looks like this is a somewhat common problem that afflicts various Lucene community members. As noted in the description Apache Blur has implemented a mechanism for coping but more recently Elastic Search has also implemented their own solution which performs an up-front query heap estimation and will pull the \"circuit breaker\" if it exceeds a threshold, thus not allowing the query to crash their cluster.\n\nDocumentation: http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/index-modules-fielddata.html#fielddata-circuit-breaker\nTicket: https://github.com/elasticsearch/elasticsearch/issues/2929 & https://github.com/elasticsearch/elasticsearch/pull/4261\n\nIf anyone has any suggestions on how we can limp by for the time being that would also be greatly appreciated (unfortunately our user base needs to keep using nested proximity wildcards but willing to have mechanisms in place to a kill subset of problematic queries). "
        },
        {
            "author": "Anshum Gupta",
            "id": "comment-14061722",
            "date": "2014-07-15T06:03:48+0000",
            "content": "I was trying to look at this. As far as I see, the 2 linked issues here are 2 completely different takes on handling compute intensive/resource sucking queries. The BLUR issue talks about killing the queries whereas the ES issue tries to do some heap estimation up-front.\n\nTo get things clear, we're only looking at this from the perspective of maintaining cluster health and are not worried about partial results. Correct me if I'm wrong on that one. "
        },
        {
            "author": "Steve Davids",
            "id": "comment-14062187",
            "date": "2014-07-15T15:11:21+0000",
            "content": "In an ideal world it would attempt to provide results for the shards that may be okay, but the end goal is to maintain the health of the cluster for queries that get out of hand. If you can know up front that there is no possible way that a query could complete then it would be reasonable to error out immediately (though that metric may be squishy to know if it will/will not complete). Hopefully that makes sense... "
        },
        {
            "author": "Jim Walker",
            "id": "comment-14062228",
            "date": "2014-07-15T15:56:42+0000",
            "content": "Steve, I wonder why you would have to restart the replica? I presume this is because that is your only recourse to stop a query that might take days to complete?\n\nIf a query takes that long and is ignoring a specified timeout, that seems like it's own issue that needs resolution.\n\nIMHO, the primary goal should be to make SolrCloud clusters more resilient to performance degradations caused by such nasty queries described above.\n\nThe circuit-breaker approach in the linked ES tickets is clever, but it does not seem to be as generally applicable as the ability to view all running queries with an option to stop them. For example, it seems the linked ES circuit breaker will only trigger for issues deriving from loading too much field data. The problem described above may result from this cause, or any number of other causes.\n\nMy preference would be to have a response mechanism that 1) applies broadly and 2) a dev-ops guy can execute in a UI like Solr Admin, or even by API. "
        },
        {
            "author": "Steve Davids",
            "id": "comment-14062250",
            "date": "2014-07-15T16:17:24+0000",
            "content": "I wonder why you would have to restart the replica? I presume this is because that is your only recourse to stop a query that might take days to complete?\nYes, that is correct, that is the easiest way to kill a run-away thread.\n\n\nIf a query takes that long and is ignoring a specified timeout, that seems like it's own issue that needs resolution.\nThe Solr instance that is distributing the requests to other shards honors the timeout value and stops the collection process once the threshold is met (and returns to the client with partial results if any are available), though the queries remain running on all of the shards that were initially searched in the overall distributed request. If the timeout value is honored on each shard that was used in the distributed request that would probably take care of the problem.\n\n\nIMHO, the primary goal should be to make SolrCloud clusters more resilient to performance degradations caused by such nasty queries described above.\n+1 resiliency to performance degradations is always a good thing \n\n\nThe circuit-breaker approach in the linked ES tickets is clever, but it does not seem to be as generally applicable as the ability to view all running queries with an option to stop them.\n+1 I actually prefer the BLUR route, though being able to see the current queries plus the ability to kill them off across the cluster would be great. Although it is crucial to be able to automatically have queries be killed off after a certain threshold (ideally the timeout value). This is necessary because I don't want to be monitoring the Solr admin page at all hours during the day (though I could create scripts to do the work if an API call is available, but not preferred).\n\n\nMy preference would be to have a response mechanism that 1) applies broadly and 2) a dev-ops guy can execute in a UI like Solr Admin, or even by API.\n+1 if \"applied broadly\" means ability to specify a threshold to start killing off queries. "
        },
        {
            "author": "Jim Walker",
            "id": "comment-14069225",
            "date": "2014-07-21T20:29:22+0000",
            "content": "Steve, good point regarding automation. That should come first.\n\nI just talked to Anshum who has this covered; he will know what needs to happen here best. Cheers "
        },
        {
            "author": "Anshum Gupta",
            "id": "comment-14079976",
            "date": "2014-07-30T21:06:21+0000",
            "content": "I'm trying to solve this problem a little differently. Just for the curious (before there's a patch), I intend to have a tracking thread that'd look up a list of requests at the core level and interrupt the requests that have timed out. I'm hoping that lucene would play well with it and respect the interrupt too solving the problem of a query running for hours/days.\nThat would keep this change at Solr level without being really intrusive and requiring change in all TermsEnum implementations out there. "
        },
        {
            "author": "Steve Davids",
            "id": "comment-14080124",
            "date": "2014-07-30T22:53:48+0000",
            "content": "There doesn't appear to be any Lucene code that is specifically honoring a thread interrupt, so if Solr/Lucene is busy enumerating terms in a continual for loop, sending an interrupt won't actually do anything. The Java code needs to check if the thread has been interrupted, if so, then bail on the current process.\n\nBlur does this by creating their own \"ExitableTerms\", \"ExitableTermsEnum\", etc where every time the enum next method is called, it will check to see if the thread has been interrupted, if it is then an exception is thrown which halts processing of the query. https://git-wip-us.apache.org/repos/asf?p=incubator-blur.git;a=blob;f=blur-store/src/main/java/org/apache/blur/index/ExitableReader.java;h=8321dd27d3537ee239f876448e56e8296407700b;hb=61480125dee51c469a4921004f6daf590410bca6\n\nPerforming the thread interrupt check within Lucene seems reasonable for things that may take a long time to complete, enumerating terms is one of them. "
        },
        {
            "author": "Anshum Gupta",
            "id": "comment-14081369",
            "date": "2014-07-31T20:06:04+0000",
            "content": "You're right Steve. Also, I tried something that I was taking a chance on solving this but it didn't.\nI'm back on the original plan to throw an exception and break during query expansion directly. Most probably, this JIRA would need to be moved to being a LUCENE issue for better tracking (will do that once I put up something).\n\nThings have changed and the same solution wouldn't really work and I think even BLUR has moved away from that implementation ever since. I'm trying to work out something on similar lines. "
        },
        {
            "author": "Anshum Gupta",
            "id": "comment-14097919",
            "date": "2014-08-14T23:47:31+0000",
            "content": "Working on adding more test and to decide on where the ExitableReader actually belongs. "
        },
        {
            "author": "Steve Davids",
            "id": "comment-14100991",
            "date": "2014-08-18T18:19:01+0000",
            "content": "We came across the issue again and added a lot more probes to get a grasp on what exactly is happening, I believe further tickets might be necessary to address various pieces.\n\n#1) We are setting the \"timeout\" request parameter which tells the TimeLimitingCollector to throw a TimeExceededException, though in our logs we see the error messages thrown after about an hour for one of the queries we tried, even though the timeout is set for a couple of minutes. This is presumably due to the query parsing taking about an hour and once the query is finally parsed and handed to the collector the TimeLimitingCollector immediately throws in exception. We should have something similar throw the same exception while in the query building phase (this way the partial results warnings will continue to just work). It looks like the current work is more in the realm of solving this issue which may fix the problems we saw described in #2.\n\n#2) We set socket read timeouts on HTTPClient which causes the same query to be sent into the cluster multiple times giving it a slow, painful death. This is even more problematic while using the SolrJ API, what ends up happening from SolrJ's LBHttpSolrServer is that it will loop through every host in the cluster and if a socket read timeout happens it tries the next item in the list. Internally every single request made to the cluster from an outside SolrJ client will try to gather the results for all shards in the cluster, once a socket read timeout happens internal to the cluster the same retry logic will attempt to gather results from the next replica in the list. So, if we hypothetically had 10 shards with 3 replicas, and made a request from an outside client it would make 30 (external SolrJ call to each host to request a distributed search) * 30 (each host will be called at least once for the internal distributed request) = 900 overall requests (each individual search host will handle 30 requests). This should probably become it's own ticket to track, to either a) don't retry on a socket read timeout or b) specify a retry timeout of some sort in the LBHttpSolrServer (this is something we did internally for simplicity sake). "
        },
        {
            "author": "Jim Walker",
            "id": "comment-14102715",
            "date": "2014-08-19T19:45:52+0000",
            "content": "Steve, your last post does not incorporate the patch from Anshum does it? "
        },
        {
            "author": "Steve Davids",
            "id": "comment-14102854",
            "date": "2014-08-19T21:12:49+0000",
            "content": "Correct, I was just providing additional insight into the issues we have been seeing. "
        },
        {
            "author": "Anshum Gupta",
            "id": "comment-14123517",
            "date": "2014-09-05T20:30:37+0000",
            "content": "New patch with the same approach but a few things fixed.\n\nThis uses timeAllowed (also used by the TimeLimitingCollector) to timeout queries during rewrite. Here's the fine print though, both the TimeLimitingCollected manage their own counter for the clock i.e. The maximum time that a query could run for is (2 * timeAllowed + Delta), where Delta is the time used for anything other than query expansion and collection.\n\nI think this should be ok, specially considering the intention is to make sure that the request is killed and doesn't run forever.\nThere's always room for improvement though and we might want to share the same counter/offset/timeout so it's more predictable.\n\nP.S: I'm still running the pre-commit to check if I'm missing something and would then run the solr+lucene tests again. "
        },
        {
            "author": "Anshum Gupta",
            "id": "comment-14127752",
            "date": "2014-09-09T23:08:39+0000",
            "content": "Updated patch with more things fixed and optimized. I still need to add more tests (working on them).\n\n\tRemoved unwanted Overrides\n\tChanged and fixed class names.\n\tInitialization of ThreadLocal variable to default value instead of a null check to make things easier to understand.\n\tSetting the log message for the ExitingReaderException().\n\tRemoved unwanted null check in the ExitObject.reset() method.\n\n "
        },
        {
            "author": "Steve Davids",
            "id": "comment-14127767",
            "date": "2014-09-09T23:21:59+0000",
            "content": "I think this should be ok, specially considering the intention is to make sure that the request is killed and doesn't run forever.\n+1, this is a good starting point and can be further refined in the future if need be.\n\nI went ahead and opened SOLR-6496 to account for the LBHttpSolrServer's continual retries. Also, I am a little concerned that the cursorMark doesn't honor the timeAllowed request parameter for some strange reason (the cursorMark ticket didn't provide any rational for it), we may want to revisit that decision in yet another ticket so people can be confident their cursor mark queries won't crash their clusters as well.\n\nThanks for taking this on Anshum! "
        },
        {
            "author": "Anshum Gupta",
            "id": "comment-14127785",
            "date": "2014-09-09T23:35:00+0000",
            "content": "I haven't looked at all of the implementation for the cursor mark but if it's query rewriting/expansion that takes time, this patch should fix the issue. I'll open another issue after I commit this one to use a single timeoutAt value. Ideally, it should be a single exitObject for a request that gets used by everything that needs to limit the processing time. "
        },
        {
            "author": "Anshum Gupta",
            "id": "comment-14128165",
            "date": "2014-09-10T07:09:55+0000",
            "content": "New patch with a little different approach.\n\n\tRenamed the ExitObject to QueryTimeout as it happens to actually be just a QueryTimeout.\n\tInstead of setting/resetting it inside the SolrIndexSearcher methods, I'm instead setting and resetting the QueryTimeout at the Handler level. I've made MLTHandler and the SearchHandler to work with this as I can't think of any other handler that would be affected by this.\n\tAs we'd now be setting the timeOut at a more global level, we can work towards (in another JIRA) using this value for different components and different stages e.g. TimeLimitingCollector etc.\n\n "
        },
        {
            "author": "Rich Cariens",
            "id": "comment-14131669",
            "date": "2014-09-12T15:42:15+0000",
            "content": "How does the group feel about adding interruption hooks into the ExitableTermsEnum.checkAndThrow() method? Something like:\n\n\n    private void checkAndThrow() {\n      if (QueryTimeout.shouldExit()) {\n        throw new ExitingReaderException(\"The request took too long to iterate over terms.\");\n      } else if (Thread.interrupted()) {\n        throw new ExitingReaderException(\"Interrupted while iterating over terms.\");\n      }\n    }\n\n\n\nSeems like this would expose another handy hook into the query life-cycle. "
        },
        {
            "author": "Anshum Gupta",
            "id": "comment-14134354",
            "date": "2014-09-15T19:23:28+0000",
            "content": "Added a Lucene test, fixed comments and renamed a few things.\nLooks fine to me other than the decision of what package/module does this belong to.\n\nI'm running the entire test suite now. It passes for the new tests but posting this before running the entire suite as that would be another 40 min. "
        },
        {
            "author": "Anshum Gupta",
            "id": "comment-14134358",
            "date": "2014-09-15T19:26:56+0000",
            "content": "Added the check for Thread.interrupted(). I wasn't sure how it'd work but I tested some random code (non-lucene/solr) and seems like it makes sense to add that there.\nThanks Rich Cariens. "
        },
        {
            "author": "Anshum Gupta",
            "id": "comment-14134400",
            "date": "2014-09-15T20:06:54+0000",
            "content": "Changed some java doc to make it easier for people to understand things.\n\nPerhaps a better way to review? https://reviews.apache.org/r/25658/\n\nP.S: Not sure how it should be done here but I uploaded the patch @ review board and pasted the link for the same here. Anyone here knows of a way to integrate the 2 so that I wouldn't have to upload at both places and paste the link? "
        },
        {
            "author": "Anshum Gupta",
            "id": "comment-14134487",
            "date": "2014-09-15T21:11:01+0000",
            "content": "Thanks Robert for the review. Updated the patch with most of your feedback + recommendations.\n\nI didn't change the design from using a ThreadLocal to passing the timeout in the constructor as the user might pre-construct and reuse the reader/searcher. (Solr specifically wouldn't play well with such a change).\n\nI did consider doing it that way but wasn't able figure out a way to do that. I'll just spend some more time to see if there's a clean way to do it (have the timeout be a passed parameter to the constructor instead of being ThreadLocal).\n\nAbout the test relying on system clock, not really that much as the sleep in wrapped up .next() and the timeout values are not even close.\n\nAlso, I can't figure out how to view the review on the review board (doesn't show up for me and the mail went to spam until Steve mentioned about the email). I've posted the updated patch there to make it easier for everyone to look at it. "
        },
        {
            "author": "Steve Rowe",
            "id": "comment-14134532",
            "date": "2014-09-15T21:37:04+0000",
            "content": "Anshum Gupta, you apparently created two review requests, and Robert Muir reviewed the first one: https://reviews.apache.org/r/25656/ - you can see his review there. "
        },
        {
            "author": "Anshum Gupta",
            "id": "comment-14134546",
            "date": "2014-09-15T21:49:49+0000",
            "content": "Ah ok, that makes sense. Just that I discarded the first request as soon as I created it.\nThe newer patches etc are on the newer request.\n\n https://reviews.apache.org/r/25658/ "
        },
        {
            "author": "Anshum Gupta",
            "id": "comment-14136295",
            "date": "2014-09-16T21:41:42+0000",
            "content": "https://reviews.apache.org/r/25658/\n\nChanged the design to have an abstract/base QueryTimeout class and implementations that use local var and ThreadLocal for Lucene/Solr.\n\nChanged the Lucene test to use the non-ThreadLocal implementation and SolrIndexSearcher uses the ThreadLocal implementation of QueryTimeout.\n\nAlso, had to change a few tests to increase the timeAllowed on existing grouping related tests.\nUntil now, the timeAllowed was only used while collecting the docs and so a q=: grouping query passed fine. With terms enumeration using the same timeAllowed param, requests time out more often than before this change (as expected). "
        },
        {
            "author": "Anshum Gupta",
            "id": "comment-14136822",
            "date": "2014-09-17T05:58:17+0000",
            "content": "Updated patch.\n\nHere are the changes:\n\n\tOverride the two cache methods getCoreCacheKey()/getCombinedCoreAndDeletesKey() to explicitly call super to support NRT.\n\tThe ExitingReaderException message now contains more information\n\tQueryTimeout() and SolrQueryTimeout.set() accept timeAllowed (in ms) instead of timeoutAt value. This makes things easier.\n\tQueryTimeoutBase is now an interface instead of being an abstract class. QueryTimeout and SolrQueryTimeout implement it.\n\n "
        },
        {
            "author": "Steve Davids",
            "id": "comment-14141216",
            "date": "2014-09-19T20:15:58+0000",
            "content": "Looks good to me, the only nit-picky thing I would say is the QueryTimeoutBase name for an interface is strange, you may consider renaming it to \"QueryTimeout\" and rename the current QueryTimeout class to something along the lines of LuceneQueryTimeout / DefaultQueryTimeout / SimpleQueryTimeout?  "
        },
        {
            "author": "Anshum Gupta",
            "id": "comment-14141451",
            "date": "2014-09-19T22:31:35+0000",
            "content": "Thanks for that feedback Steve. I think I overlooked it over the iterations and changes. I spoke to Steve Rowe and he's about to post an updated patch that would also include that change. "
        },
        {
            "author": "Steve Rowe",
            "id": "comment-14142529",
            "date": "2014-09-21T17:46:12+0000",
            "content": "Patch (see detailed info about my changes at a new review request I created: https://reviews.apache.org/r/25882/):\n\n\n\tRenamed QueryTimeoutBase to QueryTimeout, QueryTimeout to QueryTimeoutImpl, and SolrQueryTimeout to SolrQueryTimeoutImpl\n\tChanged timeout checks to use to use subtraction rather than direct comparison, to handle overflow (see nanoTime() javadocs)\n\tBeefed up javadocs\n\tNow parsing timeAllowed request param as a long (added this capability to SolrParams)\n\tAdded a cloud test\n\tAdded testing of very large timeAllowed values, and negative values too\n\n\n\nI beasted all 4 tests 20 times each, all are passed. "
        },
        {
            "author": "Anshum Gupta",
            "id": "comment-14142539",
            "date": "2014-09-21T18:00:18+0000",
            "content": "Thanks Steve. All these changes look great to me.\nI'd like to commit this sometime tomorrow if no one objects to this. "
        },
        {
            "author": "Anshum Gupta",
            "id": "comment-14148168",
            "date": "2014-09-25T19:18:25+0000",
            "content": "https://reviews.apache.org/r/25658/\n\nThe changes integrate Steve's changes and AtomicReader -> LeafReader refactor.\n\nI've run precommit and test on trunk so just about to commit this now. "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14148206",
            "date": "2014-09-25T19:42:08+0000",
            "content": "Commit 1627622 from Anshum Gupta in branch 'dev/trunk'\n[ https://svn.apache.org/r1627622 ]\n\nSOLR-5986: Add an ExitableDirectoryReader in Lucene and use that to support exiting of long running queries in Solr. "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14148226",
            "date": "2014-09-25T20:01:03+0000",
            "content": "Commit 1627635 from Anshum Gupta in branch 'dev/branches/branch_5x'\n[ https://svn.apache.org/r1627635 ]\n\nSOLR-5986: Add an ExitableDirectoryReader in Lucene and use that to support exiting of long running queries in Solr. (Merge from trunk r1627622) "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-14154618",
            "date": "2014-10-01T09:59:55+0000",
            "content": "Hi Anshum Gupta, the CloudExitableDirectoryReaderTest has been failing very frequently on jenkins, can you please take a look? "
        },
        {
            "author": "Anshum Gupta",
            "id": "comment-14155068",
            "date": "2014-10-01T16:31:15+0000",
            "content": "Shalin Shekhar Mangar, had planned to wrap this today.\nJust trying to minimize the variables involved in the test while I change it. "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14158577",
            "date": "2014-10-03T21:55:25+0000",
            "content": "Commit 1629329 from hossman@apache.org in branch 'dev/trunk'\n[ https://svn.apache.org/r1629329 ]\n\nSOLR-5986: comment out failing assertion in TestDistributedSearch until anshum can review/fix "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14158581",
            "date": "2014-10-03T22:00:08+0000",
            "content": "Commit 1629330 from hossman@apache.org in branch 'dev/branches/branch_5x'\n[ https://svn.apache.org/r1629330 ]\n\nSOLR-5986: comment out failing assertion in TestDistributedSearch until anshum can review/fix (merge r1629329) "
        },
        {
            "author": "Hoss Man",
            "id": "comment-14158609",
            "date": "2014-10-03T22:22:20+0000",
            "content": "FYI: this assertion (modified by r1627622/r1627635) has been failing in jenkins several times since committed...\n\n\n1498993     shalin       // test group query\n1627635     anshum       // TODO: Remove this? This doesn't make any real sense now that timeAllowed might trigger early\n1627635     anshum       //       termination of the request during Terms enumeration/Query expansion.\n1627635     anshum       //       During such an exit, partial results isn't supported as it wouldn't make any sense.\n1627635     anshum       // Increasing the timeAllowed from 1 to 100 for now.\n1498993     shalin       queryPartialResults(upShards, upClients,\n1498993     shalin           \"q\", \"*:*\",\n1498993     shalin           \"rows\", 100,\n1498993     shalin           \"fl\", \"id,\" + i1,\n1498993     shalin           \"group\", \"true\",\n1498993     shalin           \"group.query\", t1 + \":kings OR \" + t1 + \":eggs\",\n1498993     shalin           \"group.limit\", 10,\n1498993     shalin           \"sort\", i1 + \" asc, id asc\",\n1627635     anshum           CommonParams.TIME_ALLOWED, 100,\n1498993     shalin           ShardParams.SHARDS_INFO, \"true\",\n1498993     shalin           ShardParams.SHARDS_TOLERANT, \"true\");\n\n\n\nexample: http://jenkins.thetaphi.de/job/Lucene-Solr-5.x-Linux/11221/\n\nError Message:\nRequest took too long during query expansion. Terminating request.\n\nStack Trace:\norg.apache.solr.client.solrj.impl.HttpSolrServer$RemoteSolrException: Request took too long during query expansion. Terminating request.\n        at __randomizedtesting.SeedInfo.seed([377AFD4F005F159A:B69C7357770075A6]:0)\n        at org.apache.solr.client.solrj.impl.HttpSolrServer.executeMethod(HttpSolrServer.java:570)\n        at org.apache.solr.client.solrj.impl.HttpSolrServer.request(HttpSolrServer.java:215)\n        at org.apache.solr.client.solrj.impl.HttpSolrServer.request(HttpSolrServer.java:211)\n        at org.apache.solr.client.solrj.request.QueryRequest.process(QueryRequest.java:91)\n        at org.apache.solr.client.solrj.SolrServer.query(SolrServer.java:301)\n        at org.apache.solr.TestDistributedSearch.queryPartialResults(TestDistributedSearch.java:596)\n        at org.apache.solr.TestDistributedSearch.doTest(TestDistributedSearch.java:499)\n        at org.apache.solr.BaseDistributedSearchTestCase.testDistribSearch(BaseDistributedSearchTestCase.java:875)\n\n\n\nI'm not fully understanding what anshum ment by this TODO, and I think he's offline for the next few days, so i went ahead and comment this out with a link back to this jira for him to look at before resolving this jira. "
        },
        {
            "author": "Anshum Gupta",
            "id": "comment-14159197",
            "date": "2014-10-04T16:34:01+0000",
            "content": "Here's what I meant with that statement: This test should either be removed or modified to ensure that the timeAllowed is never hit during query expansion.\n\nHere's more of the context:\nUntil 5986 was committed, the timeAllowed parameter was only used during the collection stage. That stage also supported returning of partial matches if some shards returned responses and didn't time out.\n\nAfter this commit, the timeAllowed parameter could lead to early termination of a request way before the search actually happens i.e. during query expansion. At this stage, partial results aren't returned.\n\nThe current test tries to send a request assuming that the timeOut would happen only during the collection stage, leading to partial results being returned. BUT if, the request times out during query expansion, no partial results are returned, leading to a test failure.\n\nI'll remove the partial results test. I'll also think about adding something to replace this (I certainly don't want coverage to go down but this test isn't really a valid case anymore). May be add something that uses caching to avoid query expansion but times out during doc collection. "
        },
        {
            "author": "Steve Davids",
            "id": "comment-14159212",
            "date": "2014-10-04T16:59:42+0000",
            "content": "Why wouldn't it return partial results? When sending a distributed request if all but one return results but one shard lags behind at query expansion one would think that you would get the appropriate partial results message. Unless this is partially related to SOLR-6496 which would retry a different replica in the shard group and thus could cause a timeout at the Solr distributed aggregation layer. "
        },
        {
            "author": "Anshum Gupta",
            "id": "comment-14160374",
            "date": "2014-10-06T15:05:01+0000",
            "content": "The partial results option (from what I remember) is only set when a TimeExceededException is caught. For now, the intention behind this was to only keep the cluster healthy. I do have a few things on my mind as far as improving/iterating on this is concerned e.g. respect a global timer (per request), standardize the behavior, etc. "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-14160379",
            "date": "2014-10-06T15:09:26+0000",
            "content": "The partial results option (from what I remember) is only set when a TimeExceededException is caught. For now, the intention behind this was to only keep the cluster healthy\n\nDoes that mean that if I specify shards.tolerant=true and timeAllowed parameter and if the query on a shard is terminated because of this feature, then partialResults flag is not set on responses? "
        },
        {
            "author": "Anshum Gupta",
            "id": "comment-14160793",
            "date": "2014-10-06T19:30:16+0000",
            "content": "Shalin Shekhar Mangar Yes, as of now, an exception is expected in case a query fails due to timingOut while rewriting the query. "
        },
        {
            "author": "Anshum Gupta",
            "id": "comment-14161047",
            "date": "2014-10-06T21:58:03+0000",
            "content": "I'm considering returning partial results to make sure that we don't have to modify a lot of our tests (specially for grouping + timeAllowed). I'll put up a patch for that. "
        },
        {
            "author": "Tom\u00e1s Fern\u00e1ndez L\u00f6bbe",
            "id": "comment-14161108",
            "date": "2014-10-06T22:15:11+0000",
            "content": "My understanding is that there are two cases where \"partialResults=true\" is returned. If timeAllowed is specified and a TimeExceededException is caught as you said, but also when a shard request fails (for any exception) and \"shards.tolerant=true\". \nI guess in distributed request right now the second case will occur? "
        },
        {
            "author": "Anshum Gupta",
            "id": "comment-14161124",
            "date": "2014-10-06T22:24:19+0000",
            "content": "Correct, Tom\u00e1s Fern\u00e1ndez L\u00f6bbe.\n\nRight now, when a TimeExceededException is caught in SolrIndexSearcher.buildAndRunCollectorChain, it explicitly sets qr.setPartialResults(true). Nothing of this sort happens in case of an ExitingReaderException leading to different behavior between when a query takes too long to collect vs rewriting (even though it's the same parameter that gets used). I'll just change this so that ExitingReaderException is also caught and handled. "
        },
        {
            "author": "Anshum Gupta",
            "id": "comment-14161530",
            "date": "2014-10-07T06:17:29+0000",
            "content": "An attempt at fixing the tests. With this patch, the ExitingReaderException also sets partialResults as true in the response like the TimeExceededException.\n\nThis should get the behavior to be more similar than how it is now but the Exception in case of ExitingReader is re-thrown.  "
        },
        {
            "author": "Anshum Gupta",
            "id": "comment-14162151",
            "date": "2014-10-07T17:20:50+0000",
            "content": "Patch without the debug prints. Also, I'm trying to run the tests locally with these changes for a few hours. If I don't see any issues, I'll commit this patch. "
        },
        {
            "author": "Anshum Gupta",
            "id": "comment-14163158",
            "date": "2014-10-08T06:41:29+0000",
            "content": "A better patch for fixing the failures (though it's more invasive).\nThis changes the timeout response as now we don't return an exception but move on the lines of TimeLimitingCollector.\n\nThe presence of 'partialResults' in the 'responseHeader' would imply that timeAllowed kicked in and aborted processing of one or more shards (the way it happens right now). We log the exception in the logs though. Also changed things in the Grouping flow though I'll perhaps spend a couple of more hours on that. "
        },
        {
            "author": "Anshum Gupta",
            "id": "comment-14165448",
            "date": "2014-10-09T18:04:00+0000",
            "content": "Digging deeper into all of this, seems like there's a bigger problem to solve at hand. As of now, when timeAllowed is set, we never get back an exception but just partialResults in the response header is set to true in case of a shard failure. This translates to shards.tolerant being ignored in that case.\nOn the code level, the TimeExceededException never reaches ShardHandler and so the Exception is never set (similarly for ExitingReaderException) and/or returned to the client.\n\nI'll create another issue to handle all of that and take it up once this issue is resolved.\n\nFor this issue, I think we should just target sticking to the current behavior when timeAllowed is passed i.e. set partialResults in the header to true when either of the time limiting exceptions are hit. The last patch uploaded here should fix that. "
        },
        {
            "author": "Steve Rowe",
            "id": "comment-14165454",
            "date": "2014-10-09T18:09:18+0000",
            "content": "For this issue, I think we should just target sticking to the current behavior when timeAllowed is passed i.e. set partialResults in the header to true when either of the time limiting exceptions are hit. The last patch uploaded here should fix that.\n\n+1 to commit the last patch. "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14165654",
            "date": "2014-10-09T20:07:47+0000",
            "content": "Commit 1630583 from Anshum Gupta in branch 'dev/trunk'\n[ https://svn.apache.org/r1630583 ]\n\nSOLR-5986: Fix tests and start returning partial results in case of ExitingReaderException "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14165917",
            "date": "2014-10-09T22:48:17+0000",
            "content": "Commit 1630611 from Anshum Gupta in branch 'dev/branches/branch_5x'\n[ https://svn.apache.org/r1630611 ]\n\nSOLR-5986: Fix tests and start returning partial results in case of ExitingReaderException (Merge from trunk r1630583) "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14168516",
            "date": "2014-10-12T04:16:02+0000",
            "content": "Commit 1631145 from Anshum Gupta in branch 'dev/trunk'\n[ https://svn.apache.org/r1631145 ]\n\nSOLR-5986: Removing a todo that was introduced with a prior commit. It doesn't make any sense now as partialResults are now returned in all cases where timeAllowed kicks in "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14168517",
            "date": "2014-10-12T04:16:55+0000",
            "content": "Commit 1631146 from Anshum Gupta in branch 'dev/branches/branch_5x'\n[ https://svn.apache.org/r1631146 ]\n\nSOLR-5986: Removing a todo that was introduced with a prior commit. It doesn't make any sense now as partialResults are now returned in all cases where timeAllowed kicks in (merge from trunk) "
        },
        {
            "author": "Anshum Gupta",
            "id": "comment-14168522",
            "date": "2014-10-12T04:32:30+0000",
            "content": "I'm marking this issues as resolved now as all tests pass, also, no todo(s) is/are left unresolved.\nI've opened another issue (SOLR-6616) that is related but open for discussion.  "
        },
        {
            "author": "Anshum Gupta",
            "id": "comment-14332626",
            "date": "2015-02-23T05:01:02+0000",
            "content": "Bulk close after 5.0 release. "
        }
    ]
}