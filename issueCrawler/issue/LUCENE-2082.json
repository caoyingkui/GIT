{
    "id": "LUCENE-2082",
    "title": "Performance improvement for merging posting lists",
    "details": {
        "labels": "",
        "priority": "Minor",
        "components": [
            "core/index"
        ],
        "type": "Improvement",
        "fix_versions": [
            "4.9",
            "6.0"
        ],
        "affect_versions": "None",
        "resolution": "Unresolved",
        "status": "Open"
    },
    "description": "A while ago I had an idea about how to improve the merge performance\nfor posting lists. This is currently by far the most expensive part of\nsegment merging due to all the VInt de-/encoding. Not sure if an idea\nfor improving this was already mentioned in the past?\n\nSo the basic idea is it to perform a raw copy of as much posting data\nas possible. The reason why this is difficult is that we have to\nremove deleted documents. But often the fraction of deleted docs in a\nsegment is rather low (<10%?), so it's likely that there are quite\nlong consecutive sections without any deletions.\n\nTo find these sections we could use the skip lists. Basically at any\npoint during the merge we would find the skip entry before the next\ndeleted doc. All entries to this point can be copied without\nde-/encoding of the VInts. Then for the section that has deleted docs\nwe perform the \"normal\" way of merging to remove the deletes. Then we\ncheck again with the skip lists if we can raw copy the next section.\n\nTo make this work there are a few different necessary changes:\n\n1) Currently the multilevel skiplist reader/writer can only deal with fixed-size\nskips (16 on the lowest level). It would be an easy change to allow\nvariable-size skips, but then the MultiLevelSkipListReader can't\nreturn numSkippedDocs anymore, which SegmentTermDocs needs -> change 2)\n\n2) Store the last docID in which a term occurred in the term\ndictionary. This would also be beneficial for other use cases. By\ndoing that the SegmentTermDocs#next(), #read() and #skipTo() know when\nthe end of the postinglist is reached. Currently they have to track\nthe df, which is why after a skip it's important to take the\nnumSkippedDocs into account.\n\n3) Change the merging algorithm according to my description above. It's\nimportant to create a new skiplist entry at the beginning of every\nblock that is copied in raw mode, because its next skip entry's values\nare deltas from the beginning of the block. Also the very first posting, and\nthat one only, needs to be decoded/encoded to make sure that the\npayload length is explicitly written (i.e. must not depend on the\nprevious length). Also such a skip entry has to be created at the\nbeginning of each source segment's posting list. With change 2) we don't\nhave to worry about the positions of the skip entries. And having a few\nextra skip entries in merged segments won't hurt much.\n\n\nIf a segment has no deletions at all this will avoid any\ndecoding/encoding of VInts (best case). I think it will also work\ngreat for segments with a rather low amount of deletions. We should\nprobably then have a threshold: if the number of deletes exceeds this\nthreshold we should fall back to old style merging.\n\nI haven't implemented any of this, so there might be complications I\nhaven't thought about. Please let me know if you can think of reasons\nwhy this wouldn't work or if you think more changes are necessary.\n\nI will probably not have time to work on this soon, but I wanted to\nopen this issue to not forget about it . Anyone should feel free to\ntake this!\n\nBtw: I think the flex-indexing branch would be a great place to try this\nout as a new codec. This would also be good to figure out what APIs\nare needed to make merging fully flexible as well.",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "date": "2009-11-21T18:58:57+0000",
            "content": "This sounds like a neat idea!  For building up a new index (no deletions) it ought to be a sizable performance gain.\n\nI just committed changes on the flex branch to make it possible for codecs to override merging... ",
            "author": "Michael McCandless",
            "id": "comment-12781027"
        },
        {
            "date": "2013-04-16T20:46:37+0000",
            "content": "Is anyone actively working on this improvement? If not, I was wondering if I could contribute \u2013 I'm a graduate CS student and for my final project I'm investigating ways to optimize merging and index creation time of text indices. During my research I recently came across this ticket and I thought that I'd like to implement this idea.\n\nI took a first look at the source code \u2013 it seems that the codebase changed significantly since the time this issue was created. From what I found in the documentation (http://lucene.apache.org/core/4_0_0/MIGRATE.html), many classes mentioned here changed their names and API. Could you please update the description above or comment on what parts of it are no longer valid? ",
            "author": "Aleksandra Wozniak",
            "id": "comment-13633333"
        },
        {
            "date": "2013-04-18T22:52:57+0000",
            "content": "Hi Aleksandra,\n\nI don't think anyone is working on this now ... it'd be quite a bit of work!\n\nThe classes have changed names but the core idea is the same.  Have a look at PostingsFormat: that's the Codec component that handles reading/writing/merging of all postings files (terms dict, docs/freqs/positions/offsets).  It seems like for this issue you'd need to override Fields/Terms/PostingsConsumer.merge methods.\n\nBut some things here will likely require changes outside of Codec, eg today we always remove deletes while merging, but for this issue it looks like you may want to have a threshold below which the deletes are not removed... ",
            "author": "Michael McCandless",
            "id": "comment-13635788"
        },
        {
            "date": "2013-06-06T10:52:00+0000",
            "content": "Michael,\n\nthank you for your response. It really seems like a lot of work but hopefully I could do at least a part of it.\n\nAfter digging a little bit in the MultiLevelSkipListReader/Writer implementation, I have a doubt about the first point of the above description:\n\n\"Currently the multilevel skiplist reader/writer can only deal with fixed-size skips (16 on the lowest level). It would be an easy change to allow variable-size skips\"\n\nDoes \"variable-size skips\" mean that on each skip level we want to allow for different intervals between skip entries? For example, does a skip list like this would be correct?\n\nposting list: doc0-doc1-doc2-doc3-...-doc29 (30 entries)\nskip level 0: doc3-doc5-doc10-doc12-doc16-doc21-doc27 (intervals range from 2 to 6)\nskip level 1: doc5-doc27 (2nd and 7th position of the previous level) ",
            "author": "Aleksandra Wozniak",
            "id": "comment-13676914"
        },
        {
            "date": "2013-06-13T21:55:52+0000",
            "content": "Additionally, it seems to me that the second change from the description above is no longer needed since DocsEnum implementations just return NO_MORE_DOCS to indicate that the end of postings list is reached. ",
            "author": "Aleksandra Wozniak",
            "id": "comment-13682805"
        },
        {
            "date": "2013-06-14T11:41:11+0000",
            "content": "hi Aleksandra Wozniak,\n\nWould you be potentially interested in other postings lists idea that came up recently?\n\nhttp://markmail.org/message/6ro7bbez3v3y5mfx#query:+page:1+mid:tywtrjjcfdbzww6f+state:results\n\nIt can be of quite high impact on the index size and hopefully relatively easy to start an experiment using the lucene codec technology.\n\nJust in case you would get interested. ",
            "author": "Dmitry Kan",
            "id": "comment-13683303"
        },
        {
            "date": "2013-07-23T18:44:41+0000",
            "content": "Bulk move 4.4 issues to 4.5 and 5.0 ",
            "author": "Steve Rowe",
            "id": "comment-13717024"
        },
        {
            "date": "2014-01-29T21:26:33+0000",
            "content": "Aleksandra Wozniak are you still working on this by any chance? ",
            "author": "Otis Gospodnetic",
            "id": "comment-13885834"
        },
        {
            "date": "2014-04-16T12:54:32+0000",
            "content": "Move issue to Lucene 4.9. ",
            "author": "Uwe Schindler",
            "id": "comment-13970790"
        }
    ]
}