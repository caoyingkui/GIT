{
    "id": "SOLR-11481",
    "title": "Ref guide page explaining nuances of the recovery process",
    "details": {
        "labels": "",
        "priority": "Minor",
        "components": [
            "documentation"
        ],
        "type": "Bug",
        "fix_versions": [],
        "affect_versions": "None",
        "resolution": "Unresolved",
        "status": "Open"
    },
    "description": "The Solr recovery process involves PeerSync , which has configuration parameters to allow the number of records it should keep.\n\nIf this fails we do a index replication where possibly we can throttle replication \n\nI think it's worth explaining to users what these configuration parameters are and how does a node actually recover.",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "date": "2017-10-12T22:29:49+0000",
            "content": "\n<updateLog>\n  <str name=\"dir\">${solr.ulog.dir:}</str>\n   <int name=\"numRecordsToKeep\">10000</int>\n</updateLog>\n\n\n\nOne might assume that if he sets numRecordsToKeep that PeerSync will actually try to sync upto these many records. But looking at the code we only keep 10 transaction log files by default even when when this number is set. \n\nYonik explains on SOLR-6359 that this is because we don't want to run out of file handles in the corner case of add 1 doc + commit , add 1 doc + commit case. \n\nSo we also need to add specify maxNumLogsToKeep and keep it to a high number as well . \n\nHonestly my first reaction is that to accommodate users who are explicitly specifying a high numRecordsToKeep and then doing commits after every add we are choosing trappy behaviour for the remaining 99% users is a bad tradeoff. I'll file a separate Jira to see where that goes. \n\nSo for PeerSync we need to document both maxNumLogsToKeep and numRecordsToKeep and how they help improve recovery times.\n ",
            "author": "Varun Thacker",
            "id": "comment-16202731"
        },
        {
            "date": "2017-10-12T22:36:30+0000",
            "content": "We document the params in http://lucene.apache.org/solr/guide/updatehandlers-in-solrconfig.html#transaction-log but it doesn't explain how they interplay  ",
            "author": "Varun Thacker",
            "id": "comment-16202739"
        },
        {
            "date": "2017-10-17T04:49:31+0000",
            "content": "1. The replica asks the leader for it's fingerprint and compares it to the local copy. The fingerprint is calculated on the index and we compare the max version number from the index. If the version for matches then the indexes are the same and we mark the replica as active.\n2. If the highest version on the replica is behind the leader, then the replica asks for the last 100 ( default ) updates from the leader. \n3. If the replica is missing less than the 100 updates then it asks the leader for the specific missing updates and applies them locally\n4. In the scenario that the replica has fallen behind over a 100 updates we resort to replication of indexes\n5. In full replication, we compare each segment locally vs the leader and fetch those segments that are either missing or if the checksums don't match. ",
            "author": "Varun Thacker",
            "id": "comment-16206997"
        }
    ]
}