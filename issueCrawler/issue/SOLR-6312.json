{
    "id": "SOLR-6312",
    "title": "CloudSolrServer doesn't honor updatesToLeaders constructor argument",
    "details": {
        "affect_versions": "4.9,                                            7.5",
        "status": "Open",
        "fix_versions": [
            "4.10"
        ],
        "components": [
            "clients - java",
            "SolrJ"
        ],
        "type": "Bug",
        "priority": "Major",
        "labels": "",
        "resolution": "Unresolved"
    },
    "description": "The CloudSolrServer doesn't use the updatesToLeaders property - all SolrJ requests are being sent to the shard leaders.",
    "attachments": {
        "SOLR-6312.patch": "https://issues.apache.org/jira/secure/attachment/12662689/SOLR-6312.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Hoss Man",
            "id": "comment-14093490",
            "date": "2014-08-11T23:17:54+0000",
            "content": "Steve: can you elaborate a bit more on what exactly your code looks like, and what behavior you are seeing that you think is incorrect? (it's not clear if you are saying all requests, including queries, are only being sent to leaders when updatesToLeaders==true; or if you are saying that regardless of whether updatesToLeaders==true, updates are only going to hte leaders.\n\nfrom what i can tell, updatesToLeaders is completely ignored in 4.9, and i think should have been marked deprecated a while ago.\n\nfrom what i remember of the history, updatesToLeaders was a feature in early versions of CloudSolrServer that, instead of picking a random server from the pool of all servers, would cause the code to pick a random server from one of the current leaders - which would increase the odds of saving a \"hop\" in the case where we were sending a commit or deleteByQuery, or we got lucky and picked the \"right\" leader for a doc add/delete.\n\nBut once CloudSolrServer became smart enough to be able to ask ZooKeeper for  the DocRouter being used, we no longer needed to randomly pick a leader - we know exactly which leader to use for each update \u2013 making that setting unneccessary...\n\nhttps://svn.apache.org/viewvc?view=revision&revision=r1521713\n\nSo, if my understanding is correct, what you should be seeing is that queries are randomly distributed to any 1 solr node, while updates are always targeted at the correct leader.\n\ndoes that jive with what you are seeing?\n\n\n\nI think the bug here is mark the updatesToLeaders option deprecated, and remove it in trunk.  (either that, or: if there is still some code path where CloudSolrServer may not be able to figure out the DocRouter, then in that situation i guess it might still make sense to round robin just among the known leaders?) "
        },
        {
            "author": "Steve Rowe",
            "id": "comment-14093503",
            "date": "2014-08-11T23:32:55+0000",
            "content": "I think the bug here is mark the updatesToLeaders option deprecated, and remove it in trunk.\n\nThe updatesToLeader option has been disconnected from the way CloudSolrServer operates for 11 months now, 5 feature releases ago - what's the point of deprecating non-existent functionality?\n\n(Jessica Cheng noted this problem a ways back on SOLR-4816.) \n\nI vote for outright removal - that should have happened when SOLR-4816 was committed in r1521713. "
        },
        {
            "author": "Hoss Man",
            "id": "comment-14093508",
            "date": "2014-08-11T23:35:41+0000",
            "content": "what's the point of deprecating non-existent functionality?\n\ncorrect compilation w/o modification of existing client code on upgrade.\n "
        },
        {
            "author": "Anshum Gupta",
            "id": "comment-14093524",
            "date": "2014-08-12T00:00:17+0000",
            "content": "correct compilation w/o modification of existing client code on upgrade\n+1 for that. The public methods/constructor shouldn't be broken (even if they were superficial) in a single release. "
        },
        {
            "author": "Steve Davids",
            "id": "comment-14093533",
            "date": "2014-08-12T00:11:44+0000",
            "content": "So, if my understanding is correct, what you should be seeing is that queries are randomly distributed to any 1 solr node, while updates are always targeted at the correct leader.\n\nHoss Man You are correct, that is what I am seeing as well. Though I have a re-indexing use-case where I would actually like to distribute update requests to more than just the leader. I am currently performing XPath extraction logic in the update chain before distributed the requests to replicas, the problem I am running into is that the leader's CPU is completely pegged running the XPaths while the replicas are almost idle (~20%). I looked to this feature to allow more throughput by load balancing the extraction logic to the replicas and just forwarding the complete/hydrated document to the leader. I know this is a somewhat fringe case but still think it can be useful. "
        },
        {
            "author": "Ramkumar Aiyengar",
            "id": "comment-14093752",
            "date": "2014-08-12T05:19:00+0000",
            "content": "It's unlikely you will see a difference by sending to all replicas instead of targeting the leaders, as the replicas will internally forward your requests to the leader anyway, that's the way SolrCloud is designed \u2013 updates always go to the leader. All CSS is trying to do is save you the extra hop (and some cpu/latency savings in the process). "
        },
        {
            "author": "Steve Davids",
            "id": "comment-14093983",
            "date": "2014-08-12T11:38:18+0000",
            "content": "Yes, I understand that all updates will always go to the leader, the CPU intensive task in this entire process is running extraction logic using XPaths in the update processor chain before any requests are distributed to the leader/replicas. When the request is distributed to the leader, the leader doesn't need to start the update processor from scratch, instead it continues where the other machine left off in the processing pipeline at the DistributedUpdateProcessor. So if I am able to load balance requests to all replicas the CPU intensive tasks (early update processors) will be shared by multiple machines not just the leader and should result in increased throughput. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-14094170",
            "date": "2014-08-12T15:30:27+0000",
            "content": "Hmmm, interesting problem here. This is why, for scaling purposes, I vastly\nprefer doing any such heavy lifting on the clients so I can scale up by racking\nN clients together rather than have a Solr node be a bottleneck due to the\nparsing. Is that a possibility?\n\nSo I suspect we can close this JIRA? You're correct that updatesToLeaders\nis not respected, but it's also not going to be. Or perhaps change the title\nto \"depecrate CloudSolrServer updatesToLeaders constructor argument\".\n "
        },
        {
            "author": "Hoss Man",
            "id": "comment-14094182",
            "date": "2014-08-12T15:42:00+0000",
            "content": "So I suspect we can close this JIRA? You're correct that updatesToLeaders is not respected, but it's also not going to be.\n\nSteve's use case (and similar usecases like it, ie: using the ExtractingRequestHandler on large binary data files) actually strikes me as a really good reason to make upatesToLeaders==false meaningful again: randomize updates to all \"up\" replicas in the collection regardless of leader status.  (the default is \nupatesToLeaders=true, no reason that would change, no reason it would impact anyone except people like steve trying to distribute the load of early logic to non-leaders) "
        },
        {
            "author": "Steve Davids",
            "id": "comment-14101828",
            "date": "2014-08-19T04:26:25+0000",
            "content": "Added patch to re-enable the updatesToLeader flag and perhaps spur additional commentary  "
        },
        {
            "author": "Mark Miller",
            "id": "comment-14113827",
            "date": "2014-08-28T15:06:12+0000",
            "content": "+1. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-14942743",
            "date": "2015-10-04T18:00:32+0000",
            "content": "Interesting - I think I'm seeing lots of fails of our partition tests fail if I make this change. Just to have to verify I'm not seeing that without the change. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-14942752",
            "date": "2015-10-04T18:16:37+0000",
            "content": "Yeah, seems to be the case. I know it's more strain on the cluster to not send directly to leaders, but I wonder if some setting somewhere needs to be relaxed so that we don't keep hitting this 'no healthy nodes found' fail. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-14942841",
            "date": "2015-10-04T22:35:39+0000",
            "content": "Actually I think the tests just need a little hardening. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-14942843",
            "date": "2015-10-04T22:46:00+0000",
            "content": "Interesting - just got a replica out of sync issue with the shard split test with sendUpdatesToLeaders=false. Don't think I've seen that in some time without. I'll keep an eye on it. "
        },
        {
            "author": "Christine Poerschke",
            "id": "comment-15352997",
            "date": "2016-06-28T13:45:39+0000",
            "content": "Refreshed patch file for SOLR-9090 (which is related to this ticket but also slightly different), with a view towards committing the change towards the end of this or beginning of next week. Questions, comments, reviews etc. welcome as usual. Thank you. "
        },
        {
            "author": "Anshum Gupta",
            "id": "comment-15755215",
            "date": "2016-12-16T18:49:14+0000",
            "content": "Is this still an open issue? Considering only the builder pattern is now a non-deprecated way to construct the client, do we still end up with this when we use sendDirectUpdatesToAnyShardReplica() ? "
        },
        {
            "author": "Jeff Wartes",
            "id": "comment-16208362",
            "date": "2017-10-17T21:26:43+0000",
            "content": "As of 7.0.1, three years later, yes, I think it is still an open issue.\nCloudSolrServer.Builder has two functions that have no effect: sendUpdatesOnlyToShardLeaders and sendUpdatesToAllReplicasInShard. They are not marked depreciated, and the javadoc implies functionality. "
        },
        {
            "author": "Jason Gerlowski",
            "id": "comment-16647987",
            "date": "2018-10-12T14:44:43+0000",
            "content": "Wanted to re-bring this to people's attention if I could.  It's gotta be really confusing for our users that CloudSolrClient.Builder has 4 different methods all involving how updates are sent to shards.  None of them are well documented, and 2 of them have had no effect for the last 4 years or so.\n\nI came to this because I wanted to add Javadocs to these methods and was surprised to find that they don't do anything.  I felt like it would be a little silly to have javadocs saying: \"These methods don't have any effect.  They used to have an effect, but now we're just keeping them around as a vestigial organ\", so I thought I would maybe poke this thread again.\n\nI don't have a strong preference what we do with these methods.  I buy Steve's and Hoss' point that having this setting would be beneficial for those doing work in their update-request-chains that they want to spread around different nodes.  But it's unclear when someone will have the time/priority to make this happen and in the meantime I'd hate to see us let the \"perfect\" (this cool new functionality) get in the way of the \"good\" (less confusing interface).\n\nWould anyone care if I added a deprecation warning to these methods?  Deprecation doesn't need to be final...if someone gets around to implementing this functionality, we can always remove the deprecation.  We should do something to steer users away from using the methods in their current state.  I'd vote for temporary-deprecation since that catches the eye a little more than a Javadoc that you don't see unless think to go look it up.  But if others still object I'll just add a little javadoc warning.  \n "
        },
        {
            "author": "Mark Miller",
            "id": "comment-16649408",
            "date": "2018-10-14T14:13:59+0000",
            "content": "+1 "
        }
    ]
}