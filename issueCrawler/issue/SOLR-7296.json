{
    "id": "SOLR-7296",
    "title": "Reconcile faceting implementations",
    "details": {
        "components": [
            "faceting"
        ],
        "type": "Task",
        "labels": "",
        "fix_versions": [],
        "affect_versions": "None",
        "status": "Open",
        "resolution": "Unresolved",
        "priority": "Major"
    },
    "description": "SOLR-7214 introduced a new way of controlling faceting, the unmbrella SOLR-6348 brings a lot of improvements in facet functionality, namely around pivots. Both make a lot of sense from a user perspective, but currently have completely different implementations. With the analytics components, this makes 3 implementation of the same logic, which is bound to behave differently as time goes by. We should reconcile all implementations to ease maintenance and offer consistent behaviour no matter how parameters are passed to the API.",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "date": "2015-03-24T13:15:05+0000",
            "author": "David Smiley",
            "content": "This is important so that maintaining Solr doesn't become too painful, and to lower the barrier for new contributors.\n\nI'm inclined to say we should pick one as the back-end and then find a way to migrate the other implementation's back end to the one back-end.  It might not make sense to keep the AnalyticsComponent as a surface API.  I need to do my own homework to get an opinion of these... but my opinion of Solr's FacetComponent & SimpleFacets is that it's become an unmaintainable mess with the different facet types intertwined instead of in separate classes.  I could be refactored, sure. ",
            "id": "comment-14377821"
        },
        {
            "date": "2015-03-24T13:32:25+0000",
            "author": "Toke Eskildsen",
            "content": "The String faceting in SimpeFacet could be cleaned up as it takes 3 or 4 nearly-the-same-code paths depending on DocValues and multi/single-value. An abstraction in something like value-provider, doc->ordinal map, counting and extraction should work well. Probably with some extra decorator or aggregator elements. Hopefully including per-segment faceting. I makes a lot of sense to clean that up and treat is as a whole.\n\nEverything involving numerics is somewhat different as there are no ordinals: All values are provided directly by the sources. There is also the possibility of ongoing aggregation, such as finding the average or max. I am not sure it would work well to share the numerics processing core with String-oriented faceting. ",
            "id": "comment-14377839"
        },
        {
            "date": "2015-03-25T18:39:42+0000",
            "author": "Shawn Heisey",
            "content": "I have a question, which might be insane.  Warning: I know practically nothing about any of the implementations:\n\nBased on what I've learned from surface glancing at issues, Lucene includes what looks to me like an extensive faceting API.  Do the implementations in Solr offer any advantages that can't be folded into the Lucene API?  I'm asking because as long as we are consolidating implementations, I'm wondering if it make sense to consolidate all of the available implementations into the Lucene API. ",
            "id": "comment-14380463"
        },
        {
            "date": "2015-03-25T20:49:09+0000",
            "author": "Toke Eskildsen",
            "content": "Same warning from me: My knowledge of Lucene faceting is quite poor. Looking at guides to Lucene Faceting, it seems to be well thought out and very extensible. That supports the idea of using that as base. My main concern is the use of a central taxonomy service as it seems to collide with SolrCloud. I do not know if it is possible to avoid this service and what the cost would be. ",
            "id": "comment-14380739"
        },
        {
            "date": "2015-03-26T03:09:54+0000",
            "author": "Otis Gospodnetic",
            "content": "IIRC it requires a sidecar index, which is probably its main negative. ",
            "id": "comment-14381276"
        },
        {
            "date": "2015-03-26T04:13:18+0000",
            "author": "Shai Erera",
            "content": "I'm wondering if it make sense to consolidate all of the available implementations into the Lucene API.\n\nI'm really glad you brought it up, because I was about to do the same . Long time ago I've started to look at how to reconcile Solr faceting with Lucene's, as I feel that it's good if Lucene would have a rich faceting module, including all the goodness of Solr's, and that Solr could reuse that module, adding sugar APIs (such as JSON request/responses, caches, schema etc.). This has been my view on many components always, except maybe the distribution pieces, which may not have a place of their own in Lucene (although some might disagree).\n\nBut I'll admit that the FacetComponent looked scary and complicated, and I didn't have much time (at the time) to dig deep into it and attempt a refactoring, so I gave up. If there's reconciliation attempts now, I definitely think we should revisit this.\n\nMy main concern is the use of a central taxonomy service as it seems to collide with SolrCloud. I do not know if it is possible to avoid this service and what the cost would be.\n\nWell first, the module offers two code paths \u2013 with and without a sidecar taxonomy index. The original module came with the sidecar taxonomy index and it's been used a lot more than the other path, and therefore also richer in functionality. The second path uses DocValues only (SortedSet), which is what I believe Solr's DocValues faceting uses.\n\nOur benchmarks (I can look up the results in one of the many refactoring issues Michael McCandless and I worked on) show that the taxonomy path performs something like 20% better than DocValues, since it doesn't need to map facet ordinals across segments (i.e. in seg1 \"Author/John Doe\" received ordinal=3 and in seg2 ordinal=89). It also requires less memory footprint, although that's a bit debatable since TaxonomyReader maintains a cache...\n\nA third comment is about range faceting, which uses NumericDocValues, and not SortedSet/Taxonomy anymore, so at least there the user doesn't have to choose anymore.\n\nThere are some features that exist in the taxonomy path and not in the DocValues path for two main reasons:\n\n(1) We started the new path using DocValues with counting only, in order to explore the DV path, to get APIs straightened out and to get feedback from users.\n\n(2) The taxonomy path allows you to associate an arbitrary byte[] with a facet value, e.g. Topic/Apache Solr (0.87). If this facet was generated by a classification component, you can associate the confidence score with the facet, which you can later factor in when you \"weigh\" facet values. I no longer use the word counting because it allows you to compute multiple functions over it.\n\nThe DocValues path didn't make it possible, because we don't have a DV type that can handle that. SortedSet is almost perfect, as it computes the string ordinals, but it doesn't allow you to associate a byte[]. Perhaps we should explore that. The only DV type that allows you to do that today is Binary, but then you don't get the ordinals (efficient encoding and lookups), unless you use the taxonomy index. The taxonomy can be viewed as a hierarchical Map<String,Integer> in that regard, and that's how the taxonomy path works \u2013 it assigns an integer ID to every facet value, and in the search index we use BinaryDV to encode the <facetID, byte[]> pairs.\n\nI started to explore ways to do both, i.e. create a taxonomy inside the search index, but I never had time to complete it. The idea was to use SortedSetDV and its ordinals on one hand, but still encode facets in a BinaryDV to allow you to associate values and compute functions. It didn't look simple and I still felt (and feel) that we should offer another type of DV which does both. Something like a CompositeDV which allows you to use SortedSet and Numeric/Binary DVs together.\n\nThe taxonomy path also includes hierarchical support. Mike and I talked about adding it to the DV path as well, IIRC using similar techniques as what Solr does \u2013 on indexing Category/Computer Science/Apache/Lucene, we would index 1/Category, 2/Category/Computer Science... but we wanted to avoid the encoding of Category over and over again (since the prefix now contains the level). This is one of the things that I think can be added to the DV path (progress, not perfection ), but I guess we didn't have time and no body else thought it's important enough to contribute a patch.\n\nIIRC it requires a sidecar index, which is probably its main negative.\n\nI never really understood that I'll admit. Doesn't Solr already do that with other components such as spelling and suggester? Don't they carry sidecar files such as their dictionaries. From what I know, AnalyzingInfixSuggester builds its own sidecar Lucene index \u2013 why is that not a negative for Solr, but a persistent sidecar Map<String,Integer> is?\n\nLucene's replication module (which as a side note, I also think should be reconciled w/ Soir's replication) even handles replicating a taxonomy index together with a search index. I assume Solr does something to replicate suggester dictionaries when a node peer-syncs?\n\n-------\n\nTo conclude, I truly believe it would be beneficial to reconcile Solr faceting with Lucene's. The terms faceting can be added just like that to Lucene, it won't collide with anything and I believe it can just be under its own o.a.l.facet.terms package. DocValues faceting can be integrated with the current DV faceting. Range already exists - we should add all of Solr's goodness to it. Hierarchical DV faceting can be added just like Solr does it today (I admit I don't know how it does it today though...) and we can improve later. \n\nAnd perhaps people should stop worrying of the sidecar taxonomy index, as Solr already carries sidecars today .\n\nIf you guys want to tag team on it, I'll gladly help. I know the Lucene side of faceting (and I'm not stuck on it - I'm open to changes!), I need someone who knows the Solr side. Even if that someone knows it at a shallow level, he's already an expert compared to me . ",
            "id": "comment-14381327"
        },
        {
            "date": "2015-03-26T09:25:42+0000",
            "author": "Toke Eskildsen",
            "content": "Shai: For me the main concern is not the sidecar part, but the central part. I am thinking about distributed search here. Is Lucene faceting with taxonomy index capable of merging facet results across installations (needed for SolrCloud) and if so, do they each have their own independent taxonomy indexes or do they need to share a single one?\n\nAs for hierarchical faceting, then Solr currently does not have real support for that. Being the author of LUCENE-2369 & SOLR-2412 I would like to see it happen, both for Solr and Lucene DV. That is for another JIRA, so I'll just add that the technique I used was to have an auxiliary structure with a numeric entry for each ordinal, which was calculated from a single pass through all paths. ",
            "id": "comment-14381615"
        },
        {
            "date": "2015-03-26T10:08:01+0000",
            "author": "Shai Erera",
            "content": "Is Lucene faceting with taxonomy index capable of merging facet results across installations (needed for SolrCloud) and if so, do they each have their own independent taxonomy indexes or do they need to share a single one?\n\nYes, definitely though the code isn't part of Lucene facet module. There are two options:\n\n\n\tShare a single taxonomy index for all shards. This was done in cases where the indexes were created via MapReduce, and then left read-only. The taxonomy index was still collocated with each shard (copied), but it was never updated. This I admit is not the common case, but it's doable.\n\n\n\n\n\tHave each shard manage its own taxonomy index. When you ask for top-K values of the facet \"Author\" you get the top-K values from each shard and merge them. Obviously this is simpler than what really happens, since you need to make sure that you return the true global top-K values, but I believe Solr already handles that. I don't know the full details of the Solr implementation, but I believe it involves two phases, where in the first phase each shard returns its top-K (or top-cK) values, and then the merger decides if it needs to go back to some shards, since they may contribute to same of the facet values that didn't make it to the top-K, while they should. I read your blogs on Solr faceting, so I'm sure you know the details better than me .\n\n\n\nI would like to assume that the second phase of distributed faceted search is rather generic and shouldn't depend on one facet implementation or another. I.e. if it receives a ranked list of facet values and counts/weights (String + Integer/Float), it shouldn't care which facet impl generated these correct?\n\nSo to answer your question, it is doable, but lucene-facet currently don't offer tools to do that. However, I hope the Solr implementation can be ported/reused straightforwardly. If you know which code in Solr does that, I'd be happy to take a look. ",
            "id": "comment-14381651"
        },
        {
            "date": "2015-03-31T06:44:26+0000",
            "author": "Toke Eskildsen",
            "content": "At least for plain String faceting, Solr distributed faceting is fairly simple and works exactly as you describe. Its interface for the second phase fine-counting is basically \"give me the counts for these exact terms\". It is clever enough not to re-request counts already delivered in phase 1, but that is an implementation detail.\n\nThe core classes would be FacetComponent for the logistics, then DocValuesFacets, SimpleFacets and UninvertedField for the three different-but-nearly-the-same versions of String faceting. ",
            "id": "comment-14388122"
        },
        {
            "date": "2015-04-23T17:32:40+0000",
            "author": "David Smiley",
            "content": "I fixed the typo in the title; it was taking me forever to find this issue \u2013 even with http://jirasearch.mikemccandless.com/\n\nI took a deeper look at the new Facet Module (ported from Heliosearch) and I like it a whole lot!  I wish I had done the heatmap faceting stuff there; it would have saved me some grief.  I have more advanced heatmap analytics planned and I will do it in the Facet module not just because I like the API better but because I'll need to leverage the analytics there.  It mainly needs internal javadocs.  It's important to note that it's both a framework for doing faceting, and it has some implementations of the various types that plug into that framework.  By comparison, FacetComponent & SimpleFacets has no real framework and isn't something we should substantially improve going forward, IMO.  In principle, I don't see why Lucene's facet module couldn't be used here as well as an implementation (ala facet.method=?), plugging into Solr's new Facet module. I'm not saying it's trivial but my point is that this shouldn't be an either-or; it's complementary.  Let the Facet Module be the framework, have implementations plug-in, and put the JSON parse & standard/classic request param parsing a layer above.\n\nI haven't looked at the Analytics Contrib module but it's lack of distributed support is likely a non-starter, and it's not clear what capabilities lie there that aren't in the new Facet Module. ",
            "id": "comment-14509413"
        },
        {
            "date": "2015-04-23T17:52:03+0000",
            "author": "Yonik Seeley",
            "content": "I took a deeper look at the new Facet Module (ported from Heliosearch) and I like it a whole lot!\n\nThanks David!  IMO, it's still early... the details of how things work internally should morph according to the features we want in faceting (and we're just getting started... there's so much more we can do there).  So although what we have for the JSON Facet API will no longer be \"experimental\" for 5.2, I think the Java classes should remain experimental for longer.\n\nThe Java classes are also \"early\" from the perspective that some obvious stuff hasn't been done:\n\n\tmove string literals to constants\n\tmove certain classes out to their own files (I tend to start prototyping class hierarchies in a single file... much easier to morph early on)\n\n ",
            "id": "comment-14509444"
        }
    ]
}