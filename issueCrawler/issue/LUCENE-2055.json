{
    "id": "LUCENE-2055",
    "title": "Fix buggy stemmers and Remove duplicate analysis functionality",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [
            "modules/analysis"
        ],
        "type": "Bug",
        "fix_versions": [
            "2.9.4",
            "3.0.3",
            "3.1",
            "4.0-ALPHA"
        ],
        "affect_versions": "None",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "would like to remove stemmers in the following packages, and instead in their analyzers use a SnowballStemFilter instead.\n\n\n\tanalyzers/fr\n\tanalyzers/nl\n\tanalyzers/ru\n\n\n\nbelow are excerpts from this code where they proudly proclaim they use the snowball algorithm.\nI think we should delete all of this custom stemming code in favor of the actual snowball package.\n\n\n\n/**\n * A stemmer for French words. \n * <p>\n * The algorithm is based on the work of\n * Dr Martin Porter on his snowball project<br>\n * refer to http://snowball.sourceforge.net/french/stemmer.html<br>\n * (French stemming algorithm) for details\n * </p>\n */\n\npublic class FrenchStemmer {\n\n/**\n * A stemmer for Dutch words. \n * <p>\n * The algorithm is an implementation of\n * the <a href=\"http://snowball.tartarus.org/algorithms/dutch/stemmer.html\">dutch stemming</a>\n * algorithm in Martin Porter's snowball project.\n * </p>\n */\npublic class DutchStemmer {\n\n/**\n * Russian stemming algorithm implementation (see http://snowball.sourceforge.net for detailed description).\n */\nclass RussianStemmer",
    "attachments": {
        "LUCENE-2055.patch": "https://issues.apache.org/jira/secure/attachment/12434371/LUCENE-2055.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2009-11-11T16:13:00+0000",
            "content": "+1 - lets lose it. ",
            "author": "Mark Miller",
            "id": "comment-12776491"
        },
        {
            "date": "2009-11-11T16:32:47+0000",
            "content": "One thing I would like to fix: these packages have stoplists, but our snowball implementation is missing the stoplists from the snowball dist.\n\nThese are provided as .txt files in the full snowball distribution, so I think it would be an easy improvement to the snowball pkg to make these available somehow.\n ",
            "author": "Robert Muir",
            "id": "comment-12776503"
        },
        {
            "date": "2009-11-12T12:17:23+0000",
            "content": "setting to 3.1, because I would like to make use of simon's stopword-handling improvements to tie in the snowball stoplists.\n\nthis way we are not taking any functionality away. ",
            "author": "Robert Muir",
            "id": "comment-12776963"
        },
        {
            "date": "2010-01-18T15:52:47+0000",
            "content": "Now that we have snowball tests, I started looking at integrating snowball and deprecating this custom code. \nSo I ran the snowball tests against these hand-coded algorithms to see what the differences are... remember they all claim to implement porter:\n\n\n\tRussianStemFilter one passes 100% all snowball tests.\n\n\n\n\n\tDutchStemFilter passes 98.9% of snowball tests. all bugs were in handling of double consonants:\nexamples:\naangetroffen -> aangetrof expected: aangetroff\nafvoerbonnen -> afvoerbon expected: afvoerbonn\nklommen -> klom expected: klomm\n\n\n\n\n\tFrenchStemFilter only passes 93.92% of snowball tests. but if you put lowercasefilter after it, it passes 99.66%!\nThe problem is this stemmer incorrectly creates some uppercase stems from lowercase words. examples:\n  xviii -> xviI expected: xvii\n  vouer -> voU expected: vou\n  tranquille -> tranqUill expected: tranquill\n\n\n ",
            "author": "Robert Muir",
            "id": "comment-12801833"
        },
        {
            "date": "2010-01-18T17:06:25+0000",
            "content": "linking to LUCENE-2198, when we replace some of these buggy stemfilters with snowball ones, we will need it to implement the protected word support already exposed by the relevant analyzers. ",
            "author": "Robert Muir",
            "id": "comment-12801863"
        },
        {
            "date": "2010-01-18T19:22:28+0000",
            "content": "I think it is right to fix bad behavior, but such a change is not bw compat. It will require an index rebuild.\n\nI'm happy with the direction that non-english work is going. I'm hoping that once it is solid that the bw compat policy will be strict as core. (whatever that means  For any application of Lucene that handles many different languages, it is critical that this \"stuff\" is stable and solid. ",
            "author": "DM Smith",
            "id": "comment-12801909"
        },
        {
            "date": "2010-01-18T19:27:36+0000",
            "content": "Hello DM, me marking this as a bug does not mean it will be a backwards incompatible fix, i have not even proposed a patch yet.\n\nThis is undeniably a bug, each stemmer proudly lists that it implements the snowball algorithm, but it is not correct.\nit is my understanding that such problems (buggy stemming impls) are the reason the snowball project was created in the first place\n\nSo, we can fix the bug in 2 different ways:\n\n\tdelete the old stemmers and in the analyzers replace them with SnowballStemFilters (it does fix the bug, as they now become correct)\n\tkeep the buggy code and behavior with version\n\n ",
            "author": "Robert Muir",
            "id": "comment-12801911"
        },
        {
            "date": "2010-01-19T03:59:33+0000",
            "content": "I also wanted to comment here regarding further duplicate analysis, we can look at these in a later issue if we want\n\n\tBrazilianStemmer looks suspiciously like the Snowball Portuguese algorithm except with different diacritics handling, need to look further\n\tChineseAnalyzer (the one that does individual chinese characters) does essentially what StandardAnalyzer does with chinese text, I do not see any other features\n\n ",
            "author": "Robert Muir",
            "id": "comment-12802079"
        },
        {
            "date": "2010-01-21T13:42:42+0000",
            "content": "i'd like to work on getting these bugs fixed, but I'm not sure the best way to proceed.\n\nlooking at the different possibilities i came up with two good options, although maybe there are other ways:\n\n\n\toption 1, deprecate and keep the old broken impls and apis, but depending on Version use the correct ones instead: api and index back compat, but we keep the buggy code and support it for at least some time.\n\toption 2, deprecate the old apis, but implement it in terms of the correct one: api back compat only, but we drop the buggy code so maintenance is easier\n\n ",
            "author": "Robert Muir",
            "id": "comment-12803286"
        },
        {
            "date": "2010-02-01T09:22:00+0000",
            "content": "apologies for the large patch.\n\nthis patch does the following:\n\n\tdeprecates RussianTokenizer, RussianStemmer, RussianStemFilter, DutchStemmer, DutchStemFilter, FrenchStemmer, FrenchStemFilter\n\tuse snowball in the above analyzers instead, depending upon version.\n\tdoesn't deprecate germanstemmer, but uses snowball instead (which is maintained and relevance-tested and supports things like u+umlaut = ue, etc). the old stemmer is kept because it is a different algorithm (alternate).\n\tthe dutchstemmer had 'dictionary based stemming override' support, so to implement this, add StemmerOverrideFilter which does this in a generic way with KeywordAttribute\n\tadds KeywordAttribute support to SnowballFilter\n\tdeprecates SnowballAnalyzer in favor of language-specific analyzers.\n\tadds Romanian and Turkish stopword lists, since snowball is missing them.\n\timplements language-specific analyzers in place of all the ones snowball tried to do at once before.\n\n\n ",
            "author": "Robert Muir",
            "id": "comment-12828042"
        },
        {
            "date": "2010-02-01T09:56:29+0000",
            "content": "here is a short explanation of what i figure might be the controversial part: adding all the language-specific analyzers:\n\nI think its too difficult for a non-english user to use lucene. \nLet's take the romanian case, sure its supported by SnowballAnalyzer, but:\n\n\twhere are the stopwords? if the user is smart enough they can google this and find savoy's list... but it contains some stray nouns that should not be in there, and will they get the encoding correct?\n\tfor some languages: french, dutch, turkish: we already want to do something different already. For french we need the elision filter to tokenize correctly, for dutch, the special dictionary-based exclusions (I have been told by some any stemmer that does not handle fiets correct is useless), for turkish we need the special lowercasing.\n\tfor other languages: german, swedish, ... i think we REALLY want to implement decompounding support in the future. For german at least, there is a public domain wordlist just itching to be used for this.\n\toh yeah, and all the javadocs are in english, so writing your own analyzer is another barrier to entry.\n\n\n\nSo I think instead its best to have a \"recommended default\" organized by language, preferably one we have relevance tested / or is already published. many of the existing snowball stemmers have published relevance results available already, thus my bias towards them. Sure it won't meet everyones needs, and users should still think about using them as a template, but I think digging up your own stoplist / writing your own analyzer, figuring out your language support is really buried in snowball, combined with documentation not in your native tongue, i think this adds up to a barrier to entry that is simply too high.\n ",
            "author": "Robert Muir",
            "id": "comment-12828054"
        },
        {
            "date": "2010-02-01T11:41:39+0000",
            "content": "Several bugs:\n\n\tStemOverrideFilter should be final or have final incrementToken()\n\tThe usage of mixed CharArraySet and a conventional dictionary map is buggy. The CAS is using a different contains algo and lowercasing, you can get a hit in the CAS but the Map returns null -> NPE. I would not use a CAS for the beginning and always cast to String for now and I will open an issue for extending CAS to be a CharArrayMap\n\n ",
            "author": "Uwe Schindler",
            "id": "comment-12828071"
        },
        {
            "date": "2010-02-01T12:40:06+0000",
            "content": "StemOverrideFilter should be final or have final incrementToken()\n\nok, thanks, will fix this now.\n\nThe usage of mixed CharArraySet and a conventional dictionary map is buggy. The CAS is using a different contains algo and lowercasing, you can get a hit in the CAS but the Map returns null -> NPE. I would not use a CAS for the beginning and always cast to String for now and I will open an issue for extending CAS to be a CharArrayMap\n\nNo. Instead i will force it to be case sensitive to ignore this, it is stilly to have dutch stem filter be horribly slow because of some theoretical case like this.\n ",
            "author": "Robert Muir",
            "id": "comment-12828079"
        },
        {
            "date": "2010-02-01T12:46:41+0000",
            "content": "make StemmerOverrideFilter final, and hardcode it as case-sensitive (it makes sense to come after some sort of lowercasefilter anyway) ",
            "author": "Robert Muir",
            "id": "comment-12828093"
        },
        {
            "date": "2010-02-03T14:24:57+0000",
            "content": "updated patch:\n\n\timplement StemmerOverrideFilter with CharArrayMap\n\tfix casing problems in french and dutch: they did not call lowercasefilter, instead relying upon the stemmer to lowercase things. this causes inconsistencies with stopwords, dictionary-based stemming, exclusion sets, you name it. the old broken behavior is preserved depending on Version\n\tadd missing standardfilter to greek (depending on Version).\n\n ",
            "author": "Robert Muir",
            "id": "comment-12829085"
        },
        {
            "date": "2010-02-03T16:07:34+0000",
            "content": "Map<?,? extends String> does not make sense as String is final. Map<?,String> and the same for CharArrayMap<String>. ",
            "author": "Uwe Schindler",
            "id": "comment-12829125"
        },
        {
            "date": "2010-02-03T17:49:54+0000",
            "content": "updated patch for the generics policeman ",
            "author": "Robert Muir",
            "id": "comment-12829159"
        },
        {
            "date": "2010-02-04T18:38:43+0000",
            "content": "Robert, nice work!\nI have one comment on StemmerOverrideFilter\n\nThe ctor should not always copy the given dictionary dictionary - if is created with such a map we should use the given instance. This is similar to StopFilter vs. StopAnalyzer.\nMaybe a CharArrayMap.castOrCopy(Map<?, String>) would be handy in that case.\n\n\nOne minor thing, the  null check in DutchAnalyzer seems to be unnecessary but anyway thats fine.\n\n       if (stemdict != null && !stemdict.isEmpty())\n\n\nDutchAnalyzer also has an unused import \n\n\nimport java.util.Arrays;\n\n\n\nexcept of those +1 from my side ",
            "author": "Simon Willnauer",
            "id": "comment-12829687"
        },
        {
            "date": "2010-02-04T20:11:01+0000",
            "content": "patch addressing Simon's comments, and also fixing javadoc warnings.\n\nwhile I am here, remove other unused imports in contrib/analyzers.\n\nwill commit in a day or two if no one objects. ",
            "author": "Robert Muir",
            "id": "comment-12829751"
        },
        {
            "date": "2010-02-04T20:29:54+0000",
            "content": "I will apply the patch here later and also test everything and look through all analyzers, but as far as I see, I am happy with it. The CharArrayMap code is still ok (if the cast compiles without unchecked warning, not yet checked) - so far from generic police \n\n+1 also on having separate \"default analyzer\" classes for each language. ",
            "author": "Uwe Schindler",
            "id": "comment-12829763"
        },
        {
            "date": "2010-02-05T18:33:13+0000",
            "content": "i will commit this monster soon if no one objects. ",
            "author": "Robert Muir",
            "id": "comment-12830217"
        },
        {
            "date": "2010-02-05T22:01:14+0000",
            "content": "+1, gogogo ",
            "author": "Uwe Schindler",
            "id": "comment-12830318"
        },
        {
            "date": "2010-02-05T23:08:25+0000",
            "content": "Committed revision 907125. Thanks to the reviews and help Simon/Uwe! ",
            "author": "Robert Muir",
            "id": "comment-12830359"
        },
        {
            "date": "2010-10-29T13:12:29+0000",
            "content": "reopening for possible 2.9.4/3.0.3 backport.\n\n(i just want to add documentation recommending to use the snowball stemmers instead) ",
            "author": "Robert Muir",
            "id": "comment-12926270"
        },
        {
            "date": "2010-10-29T14:51:15+0000",
            "content": "I committed some documentation that if possible, its better to use the snowball versions for Dutch and French.\n\nCommitted revision 1028779 to 3.0.x\nCommitted revision 1028782 to 2.9.x ",
            "author": "Robert Muir",
            "id": "comment-12926302"
        }
    ]
}