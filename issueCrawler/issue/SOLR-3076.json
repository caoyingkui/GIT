{
    "id": "SOLR-3076",
    "title": "Solr(Cloud) should support block joins",
    "details": {
        "affect_versions": "None",
        "status": "Closed",
        "fix_versions": [
            "4.5",
            "6.0"
        ],
        "components": [],
        "type": "New Feature",
        "priority": "Major",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "Lucene has the ability to do block joins, we should add it to Solr.\n\nNOTE: this issue mistakenly got listed in the 4.4 section of CHANGES.txt, but is first available in Solr 4.5.",
    "attachments": {
        "27M-singlesegment.png": "https://issues.apache.org/jira/secure/attachment/12536960/27M-singlesegment.png",
        "SOLR-3076.patch": "https://issues.apache.org/jira/secure/attachment/12513651/SOLR-3076.patch",
        "Screen Shot 2012-07-17 at 1.12.11 AM.png": "https://issues.apache.org/jira/secure/attachment/12536719/Screen%20Shot%202012-07-17%20at%201.12.11%20AM.png",
        "dih-config.xml": "https://issues.apache.org/jira/secure/attachment/12576959/dih-config.xml",
        "child-bjqparser.patch": "https://issues.apache.org/jira/secure/attachment/12515102/child-bjqparser.patch",
        "tochild-bjq-filtered-search-fix.patch": "https://issues.apache.org/jira/secure/attachment/12517848/tochild-bjq-filtered-search-fix.patch",
        "bjq-vs-filters-backward-disi.patch": "https://issues.apache.org/jira/secure/attachment/12513682/bjq-vs-filters-backward-disi.patch",
        "27M-singlesegment-histogram.png": "https://issues.apache.org/jira/secure/attachment/12536959/27M-singlesegment-histogram.png",
        "dih-3076.patch": "https://issues.apache.org/jira/secure/attachment/12576960/dih-3076.patch",
        "SOLR-7036-childDocs-solr-fork-trunk-patched": "https://issues.apache.org/jira/secure/attachment/12583686/SOLR-7036-childDocs-solr-fork-trunk-patched",
        "solrconfig.xml.patch": "https://issues.apache.org/jira/secure/attachment/12536718/solrconfig.xml.patch",
        "bjq-vs-filters-illegal-state.patch": "https://issues.apache.org/jira/secure/attachment/12513494/bjq-vs-filters-illegal-state.patch",
        "solrconf-bjq-erschema-snippet.xml": "https://issues.apache.org/jira/secure/attachment/12513995/solrconf-bjq-erschema-snippet.xml",
        "parent-bjq-qparser.patch": "https://issues.apache.org/jira/secure/attachment/12513869/parent-bjq-qparser.patch",
        "SOLR-3076-childDocs.patch": "https://issues.apache.org/jira/secure/attachment/12548872/SOLR-3076-childDocs.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Mikhail Khludnev",
            "id": "comment-13201561",
            "date": "2012-02-06T20:37:32+0000",
            "content": "Hello,\n\nThe parser itself is not a very big deal. I'm stuck with filtered search for ToParentBlockJoinQuery. I'm attaching neat test for it. \n\nincepted at http://lucene.472066.n3.nabble.com/ToParentBlockJoinQuery-vs-filtered-search-td3717911.html\n\nGiving Michael's resolution I amended o.a.l.s.join.ToParentBlockJoinQuery.BlockJoinWeight.scorer(AtomicReaderContext, boolean, boolean, Bits):\n\n\tchildren query scorer obtains readerContext.reader.getLiveDocs() - all documents\n\tparent filter obtains acceptDocs to instantiate parent DocIdSet.\n\n\n\nnow it fails TestBlockJoin.testSimpleFilter() line 196 I use parent filter as a filter for search (it shouldn't influence th result). I've got an exception \n\njava.lang.IllegalStateException: parentFilter must return FixedBitSet; got org.apache.lucene.search.BitsFilteredDocIdSet@19ccba\n\tat org.apache.lucene.search.join.ToParentBlockJoinQuery$BlockJoinWeight.scorer(ToParentBlockJoinQuery.java:197)\n\nit's caused by CachingWrapperFilter.getDocIdSet(AtomicReaderContext, Bits) and BitsFilteredDocIdSet.wrap(DocIdSet, Bits).\n\n(if you don't apply changes to ToParentBlockJoinQuery, assert fails with zero doc found - parent filter is applied to children query)\n\nit seems to me:\n\n\tI did something absolutely wrong or\n\tI need to manage ToParentBlockJoinQuery work with BitsFilteredDocIdSet - I guess it might be possible.\n\n "
        },
        {
            "author": "Mikhail Khludnev",
            "id": "comment-13201574",
            "date": "2012-02-06T20:53:04+0000",
            "content": "just tried to pass readerContext.reader.getLiveDocs() to parent filter, it leads to filtering assert failure  TestBlockJoin.testSimpleFilter() line 205. So, I considering \" ToParentBlockJoinQuery work with BitsFilteredDocIdSet\"\n\nWhat do you think? Is it possible? "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13201677",
            "date": "2012-02-06T22:14:49+0000",
            "content": "I think perhaps the biggest obstacle to overcome is the indexing side.  We need to modify the transfer syntaxes to allow documents within documents, represent that in AddUpdateCommand/SolrInputDocument, and flow it through to finally call IndexWriter.addDocuments() to add them as a single block. "
        },
        {
            "author": "Mikhail Khludnev",
            "id": "comment-13202075",
            "date": "2012-02-07T04:49:14+0000",
            "content": "@Yonik,\nI agree that introducing IW.addDocuments() in DirectUpdHandler can be kind of design challenge, for experiment purpose I set big flush limits and add docs consequently in single thread with overwrite=false. But now I'm stuck with fairly basic Lucene functionality - filtered search. "
        },
        {
            "author": "Michael McCandless",
            "id": "comment-13202600",
            "date": "2012-02-07T18:33:17+0000",
            "content": "Patch, fixing ToParent/ChildBJQ to properly handle the incoming\nacceptDocs.  I added Mikhail's test, and added randomly deleted docs\nto the random test.\n\nThanks for catching & raising this Mikhail! "
        },
        {
            "author": "Mikhail Khludnev",
            "id": "comment-13202748",
            "date": "2012-02-07T20:34:23+0000",
            "content": "Michael,\n\nFirst of all, it's not, you know, fair - I just attached my own approach bjq-vs-filters-backward-disi.patch ! \nGreat idea to include delete case. \nThe only concern I have is that your patch makes BlockJoinQuery sources a little bit puzzling from my POV. I tried to reuse more Lucene code and introduce rewindable DocIdSetIterator just to provide an access to bitset.prevBitSet(). It can also be done by providing extended from of Bits interface (I don't know which of these is more perspective). \nAlso, I don't know how much the problem we are talking about is relevant to Solr - it looks like pretty Lucene issue. What should we do? Should we care? "
        },
        {
            "author": "Michael McCandless",
            "id": "comment-13203698",
            "date": "2012-02-08T16:07:08+0000",
            "content": "The only concern I have is that your patch makes BlockJoinQuery sources a little bit puzzling from my POV\n\nWell, that was the only way to \"respect\" the incoming acceptDocs, I think?  Ie, BJQ must test itself against the acceptDocs.\n\nYour patch is interesting (creating a DocIdSetBackwardIterator) but that looks like a more invasive/larger change?  So far it's only BJQ and block grouping that need this \"rewindability\", and requiring that the app provides a Filter producing a FixedBitSet for each segment (as CachingWrapperFilter will do) is not too imposing... maybe if more queries/filters require this we can rewindability to the interface... but I think it's too big a change at this point?  Maybe open a new issue to explore it?\n\nAlso, I don't know how much the problem we are talking about is relevant to Solr - it looks like pretty Lucene issue. What should we do? Should we care?\n\nYou're right this is mostly a Lucene issue so far, but I think we can just use this same issue number (I'll reference it in Lucene's changes), and then we can keep this issue open for fixing the solr side (to be able to index doc blocks, and then add BJQ query search-time support). "
        },
        {
            "author": "Mikhail Khludnev",
            "id": "comment-13204032",
            "date": "2012-02-08T21:50:22+0000",
            "content": "Michael,\n\nI agree with your points. Anyway, I suppose  that filter search fix is useful for Lucene BJQ users.\n\nOkay. Here is my first BlockJoinQParser parent-bjq-qparser.patch.\n\nMy problem is providing modules/join dependency for Solr core. I tried to amend some ant xml. But it isn't compiled. Please help me with ant, I can't. AFAIK the problem is that modules/join/buld/blabla-join.jar isn't build.\n\n\n/BlockJoinParentQParserPlugin.java:12: package org.apache.lucene.search.join does not exist\n\n\n\nthe syntax is \n\n{!parent filter=\"parent:true\"}\nchild_name:b\n\nBJQ needs CachingWrapperFilter which is not compatible/interchangeable with Solr's fq (top level vs leaf readers, you know). I had to put is into user configured cache, and also provide the parent filter only mode - when you omit child query, it returns just parent filter to be used in fq.\n\nDo you like the syntax? approach? What's worth to include in scope? \nPlease help me fix the build!! "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13204042",
            "date": "2012-02-08T21:57:24+0000",
            "content": "Hi Mikhail, take a look at solr/common-build.xml and search for 'grouping',\nyou will see how the 'grouping' module is tied in.\n\nyou can add a similar thing for 'join'.\n\nThen you also edit lucene/contrib-build.xml (again just search for 'grouping')\nand make a similar entry for 'join'.\n\nI think this is right...  "
        },
        {
            "author": "Michael McCandless",
            "id": "comment-13204105",
            "date": "2012-02-08T23:26:03+0000",
            "content": "Maybe instead of opening up end-user QP syntax to control block joins, there should be configuration that tells the query parser how to create the parent bits filter, which fields are in \"child scope\" vs \"parent scope\", etc.?  This way if a user does a field'd query, where some fields are parent and some are child, the QP would know to create BJQ? "
        },
        {
            "author": "Mikhail Khludnev",
            "id": "comment-13204747",
            "date": "2012-02-09T19:13:16+0000",
            "content": "Robert,\n\nThanks. I did mostly everything beside of the last one:\n  <target name=\"prep-lucene-jars\" \n  \t      depends=\"...\n\nReattached parent-bjq-qparser.patch builds fine.  "
        },
        {
            "author": "Mikhail Khludnev",
            "id": "comment-13204785",
            "date": "2012-02-09T19:51:39+0000",
            "content": "Michael,\n\nDo you mean something like attached solrconf-bjq-erschema-snippet.xml ? "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13204868",
            "date": "2012-02-09T21:05:31+0000",
            "content": "Maybe instead of opening up end-user QP syntax to control block joins, there should be configuration that tells the query parser how to create the parent bits filter, which fields are in \"child scope\" vs \"parent scope\", etc.? \n\nwouldn't that still need to be a query time option to be useful to the full capability of block join??\n\nfrom what i remember about block join:\n\n\tyou can have arbitrary depth of parent>child->grandchild->etc...\n\tthere's nothing prevent parents and children having the same fields\n\n\n\n...correct?\n\nso wouldn't it be kind of limiting if those types of options were configuration that couldn't be done per query/filter?  (ie: in this fq i want only docs whose parents are size:[0 TO 1000] but in this other fq i want docs who are themselves size:[10 TO 40] ... if perhaps \"parents\" are books and the children being queried are \"chapters\" and \"size\" is number of pages) "
        },
        {
            "author": "Michael McCandless",
            "id": "comment-13205016",
            "date": "2012-02-09T23:10:51+0000",
            "content": "Mikhail, I think something like that looks right?  It expresses the join structure to the QP.\n\nHoss, you're right, you can have the same field name on parent/child/grandchild/etc., so I agree, we will need something in the query syntax to disambiguate which is which for such cases.  Though I would think this would be the exception not the rule (ie, I'd expect apps to name the fields \"uniquely\" across parent and child docs).\n\nMaybe there can be field aliases?  Eg, book_page_count:[0 to 1000] and chapter_page_count[10:40], and the QP is told to map book_page_count -> parent:size and chapter_page_count -> child:size?  Or maybe we let the user explicitly scope the field, eg chapter:size, book:size, book:title, etc.  Not sure... "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13205156",
            "date": "2012-02-10T02:09:11+0000",
            "content": "Maybe there can be field aliases? Eg, book_page_count:[0 to 1000] and chapter_page_count[10:40], and the QP is told to map book_page_count -> parent:size and chapter_page_count -> child:size? Or maybe we let the user explicitly scope the field, eg chapter:size, book:size, book:title, etc. Not sure...\n\nHmmm... i kind of understand what you're saying; but the part i'm not understanding is even if you had field aliasing like that, given some query string like... \n\n  book_page_count:[0 TO 1000] and chapter_page_count[10 TO 40]\n\n\n..how would the parser know whether the user was asking for the results to be \"book documents\" matching that criteria (1-1000 pages and containing at least one chapter child containing 10-40 pages), or \"chapter documents\" matching that criteria (10-40 pages contained in a book of 1-1000 pages) or \"page documents\" (all pages in containing in a chapter of 10-40 total pages, contained in a book of 1-1000 total pages) ?\n\nI mean: it seems possible, and a QParser like that could totally support configuring those types of file mappings / hierarchy definitions in init params, but perhaps we should focus on the more user explicit, direct mapping type QParser type approach Mikhail has already started on for now, and consider that as an enhancement later?  (especially since it's not clear how the indexing side will be managed/enforced \u2013 depending on how that shapes up, it might be possible for a QParser like you're describing, or perhaps all QParsers to infer the field rules from the schema or some other configuration)\n\nI think the syntax in Mikhail's BlockJoinParentQParserPlugin looks great as a straight forward baseline implementation.  The one straw man suggestion i might toss out there for consideration would be to invert the use of the \"filter\" and \"v\" local params, so instead of...\n\n\n{!parent filter=\"parent:true\"}child_name:b\n{!parent filter=\"parent:true\"}\n\n\n\n...it might be...\n\n\n{!parent of=\"child_names:b\"}parent:true\n{!parent}parent:true\n\n\n\n...people may find that easier to read as a way to understand that the final query will return \"parent documents\" constraint such that those parent documents have children matching the \"of\" query.  The one thing i don't like this \"of\" idea is that (compared to the \"filter\" param Mikhail uses) it might be more tempting for people to use something like...\n\n\n// WRONG! (i think)\nq={!parent of=\"child_names:b\"}some_parent_field:foo\n\n\n\n...when they mean to write something like this...\n\n\nq={!parent of=\"child_names:b\"}some_query_that_identifies_the_set_of_all_parents\nfq=some_parent_field:foo\n\n\n\n...because as i understand it, it's important for the \"parentFilter\" to identify all of the parent documents, even ones you may not want returned, so that the ToParentBlockJoinQuery knows how to identify the parent of each document (correct?)\n\nThis type of user confusion is still possible with the syntax Mikhail's got, but i suspect it will be less likely \u2014 In any case, i wanted to put the idea out there.\n\nGiven McCandless supposition that the parent/child relationships are likely to be very consistent, not very deep, and not vary from query to query, one thing we could do to to help mitigate this possible confusion would be:\n\n\tmake the \"filter\" param name much longer and verbose, ie: setOfAllParentsQuery\n\tmake the param optional, and have it default to something specified as an init param, ie: defaultSetOfAllParentsQuery\n\tmake the init param mandatory\n\n\n\nThat way, in the common case people will configure things like...\n\n\n<queryParser name=\"parent\" class=\"solr.BlockJoinParentQParserPlugin\">\n  <str name=\"defaultSetOfAllParentsQuery\">type:parent</str>\n</queryParser>\n\n\n\n..and their queries will be simple...\n\n\nq={!parent}              (all parent docs)\nq={!parent}foo:bar       (all parent docss that contain kid docs matching foo:bar)\n\n\n\n...but it will still be possible for people with more complex usecases with do more complex things.\n\nMikhail: some other minor feedback on the parts i understood of your patch that i understood (note: my lack of understanding is not a fault of your patch, it's just that most of the block join stuff is very foreign to me)...\n\n\n\tplease prune down \"solrconfig-bjqparser.xml\" so it contains only the absolute minimum things you need for the test case, it makes it a lot easier for people to review the patch, and for users to understand what is necessary to utilize features demoed in the test (we have a lot of old bloaded solrconfig files i nthe test dir, but we're trying to stop doing that)\n\tthe test would be a bit easier to follow if you used different letters for the parent fields vs the child fields (abcdef, vs xyz for example)\n\tit would be good to have tests verifying that nested parent queries work as expected, ie: that something like this works...\n\nq={!parent filter=\"type:book\" v=$chapters}\nchapters=+chapter_title:Solr +_query_:{!parent filter=\"type:chapter\" v=$pages}\npages=page_body:BlockJoin\n\n \n\tit would be good to have your tests introspect the cache after doing the query to make sure the number of inserts, lookups, and hits match what you expect.\n\n\n\n...but like i said: all in all i think it's really good. "
        },
        {
            "author": "Michael McCandless",
            "id": "comment-13206276",
            "date": "2012-02-11T21:58:28+0000",
            "content": "Patch, for the 3.x backport.  I backported only the test case at\nfirst, but it failed!\n\nDigging in, it failed because BJQ requires that the parent filter\nalways include deleted docs.  This is unfortunately not easy on 3.x,\nso I added new (experimental) API SR.termDocsWithDeletedDocs(Term),\nand then create TermFilterNoDeletes (experimental), and fixed up BJQ\njavadocs to note exactly how the parents filter must be created.  Once\nI added that and fixed the test to use it, it passes again w/ no\nmodifications to BJQ sources... phew! "
        },
        {
            "author": "Michael McCandless",
            "id": "comment-13206290",
            "date": "2012-02-11T22:48:20+0000",
            "content": "New patch: removed leftover from FIR, moved the new terms filter to join module (and named it RawTermsFilter), renamed SR's new API to rawTermDocs. "
        },
        {
            "author": "Michael McCandless",
            "id": "comment-13207096",
            "date": "2012-02-13T19:19:30+0000",
            "content": "OK I've committed fixes to 3.6 and 4.0 for the BJQ bugs... let's leave this open to add BJQ support to Solr. "
        },
        {
            "author": "Mikhail Khludnev",
            "id": "comment-13207157",
            "date": "2012-02-13T20:13:56+0000",
            "content": "Michael,\n\nThank you a lot for the fix! Pls, find replies for the points above:\n\n\n\tI think it's worth to start from the essential ability - \"opening up end-user QP syntax\", and deliver fullfledged entity-relations schema later. I'm sure even this basic will be challenging enough. After we will have a feedback for essential approach, it will be clear what to include into the advanced one.\n\n\n\n\n\t\n\t\n\t\tDespite I propose to push it back, I have some thoughts about field names clash in ER-schema. If we have one field interpreted diferently between searches: first time SIZE is book entity attr, and then SIZE is chapter's attr, it can be handled via having several schemas (top level entities). We can specify which fields layout to use per every request.\n\t\n\t\n\n\n\n\n\t\n\t\n\t\tThere are cases when fields are clashed between BJQ tree levels in the single request. Vast majority of them can be resolved by distingluishing  fields between entities, i.e. there are no sigle SIZE field for book and chapter entities, but there are BOOK_SIZE and CHAPTER_SIZE, which are different due to their nature.\n\t\n\t\n\n\n\n\n\t\n\t\n\t\tEven if it's not enough and you have an attribute which belongs two both entities at the same time e.g. matte/glossy paper in our books sample, it seems like UI app concern. Imagine you have a Paper Type field in search form, what do you expect from it when search by these two joined entities? I guess the expectation is disjunction - return books which have matte cover OR matte sheets in any chapter. So, in this case the app should buid the following query: BJQ(books:true, PAPER:matte ) OR (books:true AND PAPER:matte). But where the disjunction hypothesis comes from, another app requires that books and their chapters both were glossy: BJQ(books:true, PAPER:matte ) AND (books:true AND PAPER:matte). Also there is a room for index time processing - take parent attr term, push down to chid. It's actually one of nuances which I propose to defer for a while.\n\t\n\t\n\n\n\n\n\tI'm covering improvements for test one-by-one. Stay tuned.\n\n\n\n\n\tAt the end is the sweety point - syntax.\n\n\n\n\n\t\n\t\n\t\tI believe that having body of parameter (.V) fixed, and mutate values of local params \n{!parent of=\"child_names:b\"}\nparent:true is the way to confuse user. I checked currently present Join queries - they don't do so. Local params are fixed by the app, and param body is mutated in according to user request (I know what is the &localparamtrick);\n\t\n\t\n\n\n\n\n\t\n\t\n\t\tthen instead of considering how the \"parent-filter-fallback\" will looks like I propose to think how the oposite form of jon will looks like (ToChildBlockJoinQuery - when you retrieve children whose parent are passed by the filter). In this case you still need to specify parent filter:\n\t\n\t\n\n\n\n\n{!parent filter=\"parent:true\"}child_name:b\n{!child filter=\"parent:true\"}parent_name:b\nand filter itself\n{!parent filter=\"parent:true\"}\n\nthis syntax is open for misuse:\n{!child filter=\"NOT parent:true\"}parent_name:b \n\n\n\n\nThe only thing I can suggest is make syntax more verbose:\n\n{!parent which=\"parent:true\"}child_name:b\n{!child of=\"parent:true\"}parent_name:b\n{!parent which=\"parent:true\"}\n\n\n\n\nBtw, don't you think that master/detail is more appropriate terms that parent/child?\n\n\n\n "
        },
        {
            "author": "Mikhail Khludnev",
            "id": "comment-13211098",
            "date": "2012-02-18T21:30:05+0000",
            "content": "Some news in attach child-bjqparser.patch.\n\nGood stuff - I added ToChild parser, bad thing is that ToChildBJQ seems to have a filtered search bug. See below.\n\nHoss,\nI covered all your points about tests. Also I want to add deleted blocks coverage. \n\nSyntax:\n\n\t\n{!parent which=\"PARENT:true\"}CHILD_PRICE:10\n{!child of=\"PARENT:true\"}PARENT_PRICE:10\n\n\n\tcool EntityRelationships schema is descoped\n\tI don't think that swapping local and param (\n{!parent of=\"child_names:b\"}\nparent:true) is user friendly\n\tstill asking for using master-detail in favour of parent child. WDYT?\n\n\n\nToChildBJQ vs filtered search\n\nMichael,\n\n\tI briefly looked into the TestBlockJoin.testSimple(). It asserts filtered search for children by \"skill\":\"foosball\" but I can't find such term in data.\n\tI added two plain asserts one of them is failed on erroneous 0 docnum in result. (testSimple fails after applying child-bjqparser.patch).\n\tTestBJQParser.testChildrenParser() is ignored in the patch. Looks like it fails due to another reason. Pls find my concerns in @Ignore comment.\n\n\n\n "
        },
        {
            "author": "Mikhail Khludnev",
            "id": "comment-13226820",
            "date": "2012-03-10T11:47:21+0000",
            "content": "tochild-bjq-filtered-search-fix.patch covers filtered search by ToChildBJQ and has two fixes for it. Lucene codebase is impacted only.\n\nMichael,\nPlease consider it for commit.\n\nThanks "
        },
        {
            "author": "Michael McCandless",
            "id": "comment-13228112",
            "date": "2012-03-13T01:04:03+0000",
            "content": "Thanks Mikhail!  These are real issues.\n\nI tweaked the patch a bit: I don't think we need to use .nextSetBit, because, IndexSearcher/FilteredQuery will already use .advance if the filter looks sparse. "
        },
        {
            "author": "Mikhail Khludnev",
            "id": "comment-13232807",
            "date": "2012-03-19T18:44:49+0000",
            "content": "Committers, \nIs there plan to commit filtered ToChildBJQ fix from \"13/Mar/12 01:04\"? btw I guess 3.x is also impacted. \n\nAnd about parser itself? Do you like the syntax? What's the plan?  "
        },
        {
            "author": "Michael McCandless",
            "id": "comment-13232938",
            "date": "2012-03-19T21:34:32+0000",
            "content": "Hi Mikhail, I've committed fixes for the filtering issues you found in ToChildBJQ, I think...?  Are you still seeing issues?\n\nI'm unsure of the QP syntax for BJQ... "
        },
        {
            "author": "Mikhail Khludnev",
            "id": "comment-13233730",
            "date": "2012-03-20T20:47:38+0000",
            "content": "Michael,\n\n1. I've just seen your commits. Thanks. \n\n2. Do you agree with overall approach to deliver straightforward QP with explicit joining syntax? Or you object and insist on entity-relationship-schema approach?\n\n3. What's is the level of uncertainty you have about the current QP syntax? What's your main concern and what's the way to improve it?\n\n\n "
        },
        {
            "author": "Mikhail Khludnev",
            "id": "comment-13233739",
            "date": "2012-03-20T20:54:08+0000",
            "content": "Yonik,\n\nWhat's your vision of indexing blocks in Solr?\n\n\tI guess we need to introduce new method UpdateHandler.addBlock() and AddBlockCommand as well.\n\tI suppose we have two different approaches for supporting blocks in ContentStreamLoader descendants.\n\t\n\t\twe can introduce new tag in input xml format <docs>...</docs> or <block>...<block>\n\t\twe can transfer List<SolrInputDoc>[] <in javabin format\n\t\tthe different strategy should be used for plain csv format: we need to add block separator init parameter in solrconfig.xml eg <str name=\"block.separator\">type:resume</str>\n\t\n\t\n\n\n\tas an alternative for all these above we can have just an UpdateRequestProcessor descendant which separates blocks by employing the same block.separator approach, in this case update handler support is required anyway, but it's really little efforts and less invasive.\n\n\n\nWDYT?  "
        },
        {
            "author": "Mikhail Khludnev",
            "id": "comment-13238115",
            "date": "2012-03-26T05:42:03+0000",
            "content": "Anybody, please! I need go/not-go feedback about QP-syntax and considerations about indexing part. "
        },
        {
            "author": "Michael McCandless",
            "id": "comment-13238239",
            "date": "2012-03-26T10:04:50+0000",
            "content": "\n2. Do you agree with overall approach to deliver straightforward QP with explicit joining syntax? Or you object and insist on entity-relationship-schema approach?\n\n3. What's is the level of uncertainty you have about the current QP syntax? What's your main concern and what's the way to improve it?\n\nWell, stepping back, my concern is still that I don't think there\nshould be any QP syntax to express block joins.  These are joins\n\"determined\" at indexing time, and compiled into the index, and so the\nonly remaining query-time freedom is which fields you want to search\nagainst (something QP can already understand, ie field:text syntax).\nFrom that fields list the required joins are implied.\n\nI can't imagine users learning/typing the sort of syntax we are\ndiscussing here.\n\nIt's true there are exceptional cases (Hoss's \"size\" field that's on\nboth parent and child docs), but, that's the exception not the rule; I\ndon't think we should design things (APIs, QP syntax) around exceptional\ncases.  And, I think such an exception should be\nhandled by some sort of field aliasing (\"book_page_count\" vs\n\"chapter_page_count\").\n\nFor query-time join, which is fully flexible, I agree the QP must (and\nalready does) include join syntax, ie be more like SQL, where you can\nexpress arbitrary on-the-fly joins.\n\nBut, at the same time, the 'users' of Solr's QP syntax may not be the\n\"end\" user, ie, the app's front end may very well construct these\ncomplex join expressions.... and so it's really the developers of that\nsearch app writing these join queries.  So perhaps it's fine to add\ncrazy-expert syntax that end users would rarely use but search app\ndevelopers might...?\n\nAll this being said, I defer to Hoss (and other committers more\nexperienced w/ Solr QP issues) here... if they all feel this added QP\nsyntax makes sense then let's do it! "
        },
        {
            "author": "Mikhail Khludnev",
            "id": "comment-13239202",
            "date": "2012-03-27T05:46:50+0000",
            "content": "Michael,\n\nIt's a great point about a contrast between QPs for query time and index time joins. I haven't realized it before. Completely agree.\n\nSo perhaps it's fine to add crazy-expert syntax that end users would rarely use but search app developers might...?\n\nThat's actually what I'm talking about - start from it. \n\nAlso, I don't assume that this \"crazy expert syntax\" is a termination stage for the this issue. We can have a kind of modular approach here: ER-schema module will translate plain set of filter queries into the BJQ tree expressed in \"crazy expert syntax\".  "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13250910",
            "date": "2012-04-10T18:19:57+0000",
            "content": "\nAs i said before...\n\n...perhaps we should focus on the more user explicit, direct mapping type QParser type approach Mikhail has already started on for now, and consider that (schema driven implicit block joining) as an enhancement later? (especially since it's not clear how the indexing side will be managed/enforced...)\n\nwhat Mikhail's fleshed out here seems like a good starting point for users who are willing to deal with this at the \"low\" level (similar in expertness to the \"raw\" QParser) , and would be usable today for people who take responsibility of indexing the blocks themselves.\n\nif/when/how we decide to drive the indexing side, we can think about how if/where/how to automagically hook blockjoin queries into \"higher\" level parsers like LuceneQParser, DismaxQueryParser "
        },
        {
            "author": "Mikhail Khludnev",
            "id": "comment-13415644",
            "date": "2012-07-16T21:16:46+0000",
            "content": "Hello,\n\nI'm attaching the patch includes index support SOLR-3535. significant improvement is SolrJ support.\n\nsolrconfig.xml.patch shows how to enable this magic for \"examples\" instance.\n\nI did the same benchmark as in http://www.lucidimagination.com/blog/2012/06/20/solr-and-joins/ with queries like: \n\nq=text_all:(autumn OR lie)&fq=\n{!parent which=kind:body}\nacl:[5326 TO 5326]\nq=text_all:(presumably OR isolate OR resistance)&fq=\n{!parent which=kind:body}\nacl:[1937 TO 1940]\nq=text_all:(nice OR junior OR great)&fq=\n{!parent which=kind:body}\nacl:[33 TO 36]\n\nit gives me 0.3 sec avg latency on MacBookPro. see attached solrmeter screenshot. \n "
        },
        {
            "author": "Mikhail Khludnev",
            "id": "comment-13416907",
            "date": "2012-07-18T06:38:50+0000",
            "content": "I repeat the join test with 27M docs (4.5M parent docs with 5 children per each) optimized up to single segment. You can see that it provides fairly subseconds search (with rare spikes up to 9 sec, of course). Check 27M-singlesegment.. pngs.  "
        },
        {
            "author": "Pavel Goncharik",
            "id": "comment-13447399",
            "date": "2012-09-03T19:51:35+0000",
            "content": "Hi,\n\nI'm wondering if patches in this issue implement \"block joins\" for a single Solr shard only, or implementation works correctly out-of-the-box in distributed mode (SolrCloud)? "
        },
        {
            "author": "Mikhail Khludnev",
            "id": "comment-13447419",
            "date": "2012-09-03T21:40:40+0000",
            "content": "Hi\n\nI can't check it right now, can't remember how deep I covered it, but I remember that there was a test or even level of certainty that nested docs are passed through DisttributedUpdateProcessor by using a top level doc primary key. Therefore whole block should land into particular shard.  If this necessary condition is met query side should work out of the box. \nAlso you can find about performance benefits\n\nhttp://blog.griddynamics.com/2012/08/block-join-query-performs.html "
        },
        {
            "author": "Vadim Kirilchuk",
            "id": "comment-13474899",
            "date": "2012-10-12T08:59:18+0000",
            "content": "Hi everyone, i revisited the patch and attaching another version of it (childDocs), which includes:\n\n1) SolrInputDocument#getChildrenDocs modification (suggested by Hoss)\n2) Distributed test \nFullSolrCloudDistribCmdsTest#testIndexQueryDeleteHierarchical\n3) Fixed NPE analyzer exception \n\nFeel free to check it and give a feedback!\n\nThx! "
        },
        {
            "author": "Otis Gospodnetic",
            "id": "comment-13551349",
            "date": "2013-01-11T18:24:14+0000",
            "content": "Just skimmed the comments - looks like there may still be some things to work out.  But doesn't this feel like too important not to try and include in 4.2 or 5.0?  If so, set Fix Version so it doesn't get lost? "
        },
        {
            "author": "Mikhail Khludnev",
            "id": "comment-13551483",
            "date": "2013-01-11T20:12:57+0000",
            "content": "Otis Gospodnetic for me it's 100% ready, otherwise let me know what's need to be improved. \nI can't set Fix Version beacuse it's assigned on Grant Ingersoll  "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-13551505",
            "date": "2013-01-11T20:52:07+0000",
            "content": "I'll try to look soon.  Others should be able to set the fix version, if they have the appropriate rights. "
        },
        {
            "author": "Erik Hatcher",
            "id": "comment-13551790",
            "date": "2013-01-12T03:58:12+0000",
            "content": "well just set it then, Otis!  \n\nI put only 5.0 since this is going to be a fairly big change.  Feel free to set it to 4.2 or greater if you'd like (and of course volunteer to do the work) "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13551819",
            "date": "2013-01-12T05:56:34+0000",
            "content": "Honestly I normally pretty much ignore \"fix version\" for features... it's not how things get done (or scheduled) really.\nThis feature is very important - there's no way it's getting lost. "
        },
        {
            "author": "Vadim Kirilchuk",
            "id": "comment-13621984",
            "date": "2013-04-04T09:58:15+0000",
            "content": "Hi everyone!\n\nI am attaching draft dih patch (and sample dih-config) which adds support of hierarchical docs to dih.\n\nIt is far from being complete but works for me and can be useful for others.\n\nAny Feedback Is Appreciated. Thanks.\n\n\n\n "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-13645483",
            "date": "2013-04-30T11:33:22+0000",
            "content": "Setting 4.4 as fix version since Mikhail wanted that, and I guess to encourage this happening before 5.0. Any released Lucene feature should be allowed to bubble up in Solr within a few point releases.\n\nWhat's lacking for this one now? "
        },
        {
            "author": "Tom Burton-West",
            "id": "comment-13660124",
            "date": "2013-05-16T23:07:31+0000",
            "content": "\nI'd like to test this out with some real data and would like to use the XmlUpdateRequestHandler.  Since  SOLR-3535 was folded in here, I looked here to try to find the XML syntax to use. I couldn't tell from a quick read of the code what the XML syntax would be to actually use to add a parent and children.   Would it be possible to add a test similar to solr/core/src/test/org.apache.solr.handler/XmlUpdateRequestHandlerTest?\n\nI would assume all that the xml in XmlUpdateRequestHandlerTest could be replaced with the proper xml to index a block consisting of a parent and its children\n\ni.e in the test replace:\nString xml = \n      \"<doc boost=\\\"5.5\\\">\" +\n      \"  <field name=\\\"id\\\" boost=\\\"2.2\\\">12345</field>\" +\n      \"  <field name=\\\"name\\\">kitten</field>\" +\n      \"  <field name=\\\"cat\\\" boost=\\\"3\\\">aaa</field>\" +\n      \"  <field name=\\\"cat\\\" boost=\\\"4\\\">bbb</field>\" +\n      \"  <field name=\\\"cat\\\" boost=\\\"5\\\">bbb</field>\" +\n      \"  <field name=\\\"ab\\\">a&b</field>\" +\n      \"</doc>\";\n\nwith whatever xml is needed to index a block (parent and children).\n "
        },
        {
            "author": "Vadim Kirilchuk",
            "id": "comment-13660453",
            "date": "2013-05-17T07:54:45+0000",
            "content": "Tom, you can take a look at AddBlockUpdateTest, it contains several examples. \nHere SOLR-3076.patch and SOLR-3076-childDocs.patch have a great difference: \n\nhere is SOLR-3076.patch style (Note: child documents inside fields):\n\n<add>\n  <doc>\n    <field name='id'>1</field>\n    <field name='type_s'>parent</field>\n    <field name='make_name_s'>Ford</field>\n    <field name=\"1th-subdocs\">\n      <doc> \n          <field name='id'>2</field>\n          <field name='type_s'>child</field>\n          <field name='modelyear_name_s'>1992 Ford E150 Van 2WD</field>\n      </doc>\n      <doc> \n          <field name='id'>3</field>\n          <field name='type_s'>child</field>\n          <field name='modelyear_name_s'>1993 Ford E150 Van 2WD</field>\n      </doc>\n    </field>\n    \n    <!-- \n        This was done for case when you have more then 2 types in relation:for example, Make->Model and Make->Factory \n        However, it is ok to just add all subdocs to 1th-subdocs fields.\n    -->\n    <field name=\"2th-subdocs\"> \n      <doc> \n          ...\n      </doc>\n    </field>\n  </doc>\n  \n  <doc> \n       ...\n  </doc>\n</add>\n\n\n\nhere is SOLR-3076-childDocs.patch style (Note: child documents are another doc inside doc):\n\n<add>\n  <doc>\n    <field name='id'>1</field>\n    <field name='type_s'>parent</field>\n    <field name='make_name_s'>Ford</field>\n    <doc>\n      <field name='id'>2</field>\n      <field name='type_s'>child</field>\n      <field name='modelyear_name_s'>1992 Ford E150 Van 2WD</field>\n    </doc>\n    <doc>\n      <field name='id'>3</field>\n      <field name='type_s'>child</field>\n      <field name='modelyear_name_s'>1993 Ford E150 Van 2WD</field>\n    </doc>\n    \n   <!-- \n        2th-subdocs from previous example can easily go here.\n    -->\n    <doc>\n      ...\n    </doc>\n  </doc>\n</add>\n\n\n\nAlso i suggest you to use SolrJ instead of plain xml, examples at https://github.com/griddynamics/solr-fork/blob/trunk-patched/solr/core/src/test/org/apache/solr/update/AddBlockUpdateTest.java look at testSolrJXML() "
        },
        {
            "author": "Tom Burton-West",
            "id": "comment-13661030",
            "date": "2013-05-17T20:39:16+0000",
            "content": "Thanks Vadim,\n\nI haven't used SolrJ, so I needed to translate to the XMLLoader/XML update handler.\n\nI pulled your trunk-patched version, added an XMLLoader test to AddBlockUpdateTest. It's a brain-dead copy of the testSolrJXML test.  I don't know if it is testing much, but at least for Solr users like me who are unfamiliar with SolrJ, it provides an executable example of the XML syntax currently being used.\n\np.s.\nThe attached patch is a git diff to your version. ( I don't quite know how to make a correct patch against the right version of Solr trunk)  \n "
        },
        {
            "author": "Alan Woodward",
            "id": "comment-13670225",
            "date": "2013-05-30T10:49:55+0000",
            "content": "This patch updates the 12/10/12 patch to trunk.  There are a bunch of test failures in the analyzing suggester suite, which is a bit odd.  There's also a single test failure in AddBlockUpdateTest.testExceptionThrown, which I think is actually an error in the test (it seems to expect that a document with fieldtype errors in a subdoc would be added, instead of the entire block being rejected).\n\nI have a client who's keen to get this into trunk/4x soon.  Would be good to get some momentum behind it. "
        },
        {
            "author": "Vadim Kirilchuk",
            "id": "comment-13670256",
            "date": "2013-05-30T11:24:52+0000",
            "content": "Thanks, Alan! \n\nThere are a bunch of test failures in the analyzing suggester suite, which is a bit odd.\nI will try to take a look at the weekend.\n\nThere's also a single test failure. \nRight, inconsistent behavior was fixed at some point (if you look at the test it has comment about this), so the proper way is to change numFound=1 to numFound=0. "
        },
        {
            "author": "Alan Woodward",
            "id": "comment-13670262",
            "date": "2013-05-30T11:29:35+0000",
            "content": "change numFound=1 to numFound=0\n\nThe failure is elsewhere, in the *:* query - it's expecting to find 9 docs, but actually finds 8.  But I guess this is the same change. "
        },
        {
            "author": "Vadim Kirilchuk",
            "id": "comment-13678846",
            "date": "2013-06-08T20:21:21+0000",
            "content": "There are a bunch of test failures in the analyzing suggester suite, which is a bit odd.\n\nNot reproduced for me.\n\nThe failure is elsewhere, in the : query - it's expecting to find 9 docs, but actually finds 8. But I guess this is the same change.\n\nRight, this is about changing \nassertQ(req(\":\"), \"//*[@numFound='\" + \"abcDefgHx\".length() + \"']\");\nto \nassertQ(req(\":\"), \"//*[@numFound='\" + \"abcDefgH\".length() + \"']\"); "
        },
        {
            "author": "Daniel Soriano",
            "id": "comment-13679571",
            "date": "2013-06-10T15:14:46+0000",
            "content": "Hi everyone!\nI'm interested in trying/testing this new feature, but I cannot figure out what's the right order to apply patches, either if all files are required. Could anyone suggest me how to do that?\n\nThanks! "
        },
        {
            "author": "Vadim Kirilchuk",
            "id": "comment-13679706",
            "date": "2013-06-10T18:05:48+0000",
            "content": "Hi Daniel,\n\nIt's nice to hear that more and more people want this feature.\n\nYou need only latest SOLR-3076 patch (Thanks to Alan!) https://issues.apache.org/jira/secure/attachment/12585393/SOLR-3076.patch. You should apply it to current trunk. There will be one test failure which is mentioned here (in AddBlockUpdateTest) but you can ignore it for a while. "
        },
        {
            "author": "Daniel Soriano",
            "id": "comment-13680292",
            "date": "2013-06-11T08:11:17+0000",
            "content": "But paths in patches start with a/ and b/, and patches are applied into both subdirs. I don't understand how apply this patch file to trunk. I have done two trunk copies starting with a and b, but --dry-run notices that changes are applied into both. What's the trick? "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-13680302",
            "date": "2013-06-11T08:30:08+0000",
            "content": "It's probably a git patch. Try patch -p1 as mentioned here http://wiki.apache.org/solr/HowToContribute#Working_With_Patches "
        },
        {
            "author": "Daniel Soriano",
            "id": "comment-13680500",
            "date": "2013-06-11T17:05:10+0000",
            "content": "That has been perfect!! Thanks everyone. Now, block joins are running. "
        },
        {
            "author": "Tom Burton-West",
            "id": "comment-13680731",
            "date": "2013-06-11T21:51:45+0000",
            "content": "Patch against trunk (SVN style, patch -p0) that adds testXML(), which illustrates XML block indexing syntax and exercises the XMLLoader "
        },
        {
            "author": "Otis Gospodnetic",
            "id": "comment-13684935",
            "date": "2013-06-17T03:07:22+0000",
            "content": "This is issue #2-3 in terms of popularity.  Does it work in SolrCloud-type setups? "
        },
        {
            "author": "Vadim Kirilchuk",
            "id": "comment-13684996",
            "date": "2013-06-17T05:46:40+0000",
            "content": "Otis, patch have a test class solr/core/src/test/org/apache/solr/cloud/FullSolrCloudDistribCmdsTest.java and a method #testIndexQueryDeleteHierarchical which index, query and then delete hierarchical documents. However, it asserts only sizes of parents, children and grandchildren with simple term queries (not bjq), so someone need to check it manually or update a test.\n\nBy the way, what is the #1 issue? =) "
        },
        {
            "author": "Michael McCandless",
            "id": "comment-13685462",
            "date": "2013-06-17T11:19:04+0000",
            "content": "#1 issue is SOLR-64: http://jirasearch.mikemccandless.com/search.py?index=jira&chg=dds&text=&a1=status&a2=Open&page=0&searcher=2004&sort=voteCount&format=list&id=tixjnvz4fv8r&newText= (that's just sorting all open issues by vote count).\n\nBut that issue was open for a very long time so it's not really fair  "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13685564",
            "date": "2013-06-17T13:53:35+0000",
            "content": "Starting to look at this now... hopefully we should be able to get something committed soonish. "
        },
        {
            "author": "Vadim Kirilchuk",
            "id": "comment-13686519",
            "date": "2013-06-18T09:19:09+0000",
            "content": "Yonik, it's great!\n\nJust keep in mind several improvements:\n\n\tmake _childDocuments inside SolrInputDocument lazy instead of new ArrayList() in constructor.\n\tat JavaBinCodec there is no need in SOLRINPUTDOC_CHILDS tag, it is easier to write \"SOLRINPITDOC docFieldsSize childrenNum\" instead of \"SOLRINPUTDOC docFieldsSize SOLRINPUTDOC_CHILDS childrenNum\"\n\n\n\nThere is also a blueprint of dih support for this: https://issues.apache.org/jira/secure/attachment/12576960/dih-3076.patch \nMaybe it will be better to move it to it's own jira ticket.\n\nThere are no support for:\n\n\tdelete block\n\toverwrite/update block\n\tJSON\n\n\n\nI hope it helps.\n\n "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13694282",
            "date": "2013-06-26T21:54:25+0000",
            "content": "OK, now that compound-file test related failures have been nailed, I'm back to looking at this.\n\nJust keep in mind several improvements:\n\nThanks, I'll check those suggestions out.\nAs for the stuff that there is no support for, the list seems to be getting big as I look at it... I think I'll try for a more minimalistic approach and leave the other stuff for follow-on work if possible. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13694839",
            "date": "2013-06-27T16:22:59+0000",
            "content": "Here's the most recent patch updated to trunk.  For some reason, the first test I tried (AddBlockUpdateTest) fails.  I haven't looked into why just yet... "
        },
        {
            "author": "Vadim Kirilchuk",
            "id": "comment-13694931",
            "date": "2013-06-27T18:10:07+0000",
            "content": "Right, one test fail because Alan didn't change it. You can find our discussion in comments, but let me help you:\n\nThere's also a single test failure in AddBlockUpdateTest.testExceptionThrown\nRight, inconsistent behavior was fixed at some point (if you look at the test it has comment about this), so the proper way is to change numFound=1 to numFound=0.\n\nThe failure is elsewhere, in the : query - it's expecting to find 9 docs, but actually finds 8. But I guess this is the same change.\nRight, this is about changing \nassertQ(req(\":\"), \"//*[@numFound='\" + \"abcDefgHx\".length() + \"']\");\nto \nassertQ(req(\":\"), \"//*[@numFound='\" + \"abcDefgH\".length() + \"']\"); "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13695084",
            "date": "2013-06-27T21:47:40+0000",
            "content": "Updated patch to fix test. "
        },
        {
            "author": "Jack Krupansky",
            "id": "comment-13702578",
            "date": "2013-07-08T22:56:07+0000",
            "content": "Some questions:\n\n1. Is there a reasonably high probability that this feature will make it into Solr 4.5?\n\n2. How would Solr block join compare with Elasticsearch \"nested types\"? Anything that ES has on that front that this issue would not address?\n\nSee:\nhttp://www.elasticsearch.org/guide/reference/mapping/nested-type/\n\n3. Can individual child documents be updated, replaced, deleted, appended? "
        },
        {
            "author": "Mikhail Khludnev",
            "id": "comment-13703080",
            "date": "2013-07-09T09:15:11+0000",
            "content": "2. How would Solr block join compare with Elasticsearch \"nested types\"? ...\n\nElasticSearch also provides some sort of \"nested facets\". However, I found them useless for real life eCommerce faceting. Though, internally ES has enough infrastructure to provide correct item level faceting. I feel it can be delivered there easily. It's worth to clarify what I mean in \"real life eCommerce faceting\", just check any site: if we have colored items which are nested into top-level products, and when we count item level facets eg color, we need to count number of products which has any items of the particular color and passed item level filter eg size. \n\nalso desired direction is relations schema, see discussion in the beginning, I'm not sure how ElasticSearch address it.   \n\n3. Can individual child documents be updated,...\n\nyou can only delete. I mean, you should be able to do so, but I don't remember whether it's covered by test or not. Update,Replace,Append might be possible only after \"stacked updates\" are there (frankly speaking, never).     "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13708597",
            "date": "2013-07-15T16:30:24+0000",
            "content": "It seems like the implementation of AddUpdateCommand and AddBlockCommand have almost everything in common (or should... such as handing reordered delete-by-queries, etc).  For the most part, the only difference will be what IndexWriter method is finally called.  I'm considering just modifying AddUpdateCommand instead of having a separate AddBlockCommand, but I was wondering about the reasoning behind a separate command. "
        },
        {
            "author": "Mikhail Khludnev",
            "id": "comment-13708856",
            "date": "2013-07-15T19:27:45+0000",
            "content": "Yonik Seeley it's a ginger cake! "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13712953",
            "date": "2013-07-18T22:08:33+0000",
            "content": "So it seems like for updates, we need a common term to delete everything by.  Unless someone thinks of a better name, I'll use _root_ (and the root document and all child documents will have this set to the id of the root document). "
        },
        {
            "author": "Vadim Kirilchuk",
            "id": "comment-13713462",
            "date": "2013-07-19T09:01:11+0000",
            "content": "Wdyt about \"block_id\" for name? \n\nAlso, i have a weird idea: wdyt about figuring out block based on parent bit set, i.e, we have the following parent bitSet 000100010001, and we somehow figure out that we want to update the parent in the middle, it means that we actually want to delete everything between two parents in the bitset, so we don't need anything except parent bitSet and bitSet id for parent. I don't believe it is easy, but it is just a weird idea =) "
        },
        {
            "author": "Mikhail Khludnev",
            "id": "comment-13713486",
            "date": "2013-07-19T09:27:56+0000",
            "content": "Yonik Seeley I thought address this question at SOLR-4836, but it would be great if you cover it altogether. \nPls confirm my understanding, if <uniqKey> is specified, for every block children obtain value for _root_  field, from parent's <uniqKey> field. Hence _root_ field is always used for IW.updateDocs call.\n\nbtw, uber compact codec can be implemented for that _root_ field that somehow interfere with Vadim's idea.\n\nVadim Kirilchuk introducing this separate case, blows IndexWriter code. Presumably you can try to introduce a facility to update not by term as now, but for some kind of generic query. fwiw, parent bitset is not really exists in IndexWriter see below   "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13713653",
            "date": "2013-07-19T13:38:16+0000",
            "content": "Pls confirm my understanding, if <uniqKey> is specified, for every block children obtain value for root field, from parent's <uniqKey> field. Hence root field is always used for IW.updateDocs call.\n\nRight, _root_ would always be used when dealing with a block of documents (and always be set to the parent ID by solr... this wouldn't be set by the user).  The only thing not covered by this is a transition from block to non-block or vice versa (i.e. adding a block document and then overwriting it with a non-block one).  I'm punting on that for now.  Also for deletes... unless we somehow keep track or can look it up, we'll need syntax to say that we're deleting a block.\n\nblock_id is a good descriptive name, but I've been going toward surrounding special/internal/solr-added fields with underscores.  Like _version_ and _shard_ (which may change to _route_) and _docid_.  Using that scheme, _block_id_ is a little less appealing.  Perhaps _block_ though.\n\nOn the query side, this field can be used to get from a child of any depth to the root document, and from that perspective _root_ makes more sense.  On the update side, _block_ makes a little more sense because all you care about is deleting the block as a whole with it.  Hmmm... "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13714125",
            "date": "2013-07-19T21:53:11+0000",
            "content": "Updated patch merging block functionality into AddUpdateCommand and implementing _root_.  This is just a dev snapshot - things haven't been cleaned up and there are no new tests. "
        },
        {
            "author": "Mikhail Khludnev",
            "id": "comment-13715007",
            "date": "2013-07-22T08:24:19+0000",
            "content": "delete everything between two parents in the bitset\nIndeed! Yonik Seeley we don't need _root_ if we can submit two queries for deletion: ToChild(parentid:foo) and TQ(parentid:foo)!\nSecond great idea from Vadim Kirilchuk and Aleksey Aleev is that specific FullBlockQuery which matches parent and all its' children by the given parentid. "
        },
        {
            "author": "Steve Rowe",
            "id": "comment-13717263",
            "date": "2013-07-23T18:47:40+0000",
            "content": "Bulk move 4.4 issues to 4.5 and 5.0 "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13717528",
            "date": "2013-07-23T19:45:27+0000",
            "content": "Indeed! Yonik Seeley we don't need root if we can submit two queries for deletion: ToChild(parentid:foo) and TQ(parentid:foo)!\n\nSince solr wouldn't know how to create those queries, it seems like the user would need to provide them (which doesn't seem very friendly).\nAlso, IndexWriter currently only allows atomically specifying a term with the document block... deleteByQuery wouldn't be atomic. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13721999",
            "date": "2013-07-28T17:09:08+0000",
            "content": "FYI, I haven't forgotten about this issue, but I'm traveling at the beginning of this next week.   I'll pick it up first thing when I get back. "
        },
        {
            "author": "Mikhail Khludnev",
            "id": "comment-13729926",
            "date": "2013-08-05T20:53:44+0000",
            "content": "Yonik Seeley one of inconveniences is the necessity to provide user cache for BJQParser to store parent bitset. \nDo you think it's ok to bother user by this, and provide suboptimal performance y default?\nI have few solutions in mind, will we discuss it now or later?     "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13733601",
            "date": "2013-08-08T15:35:01+0000",
            "content": "Making progeess... currently working on randomized testing (using our current join implementation to cross-check this implementation).  I've hit some snags and am working through them...\n\none of inconveniences is the necessity to provide user cache for BJQParser \n\nYeah, I had some things in mind to handle that as well. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13735994",
            "date": "2013-08-10T18:40:53+0000",
            "content": "OK, here's a patch that fixes some bugs and removes the need for the user to configure an extra cache and register the parsers. "
        },
        {
            "author": "Mikhail Khludnev",
            "id": "comment-13736024",
            "date": "2013-08-10T20:47:21+0000",
            "content": "Yonik Seeley could you please comment: \n\n\twhy PARENT:true should ignore deletions?\n\tdon't you think that \"diverging\" BJQ code makes harder the further maintenance?\n\tI propose to revise the idea of rewindable docIDset iterator (it's discussed in the beginning), manage BJQ to work with it and avoid the cast to the concrete bitset class, in this case Lucene BJQ code could work with BitsDocsSet.getTopFilter(), which is some sort of BitSetSlice already.\n\tas an alternative hack we can provide getDocset(wq, LUCENE_CACHING_WRAPPING_FILTER), where wq protects other queries from cache hit; or we can add to ExtendedQuery an ability to calculate bitset on it's own, i.e. searcher will delegate to ExtendedQuery.getDocSet(searcher) that allows it to yield Lucene's CahingWrapperFilter\n\n\n "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13736292",
            "date": "2013-08-11T14:47:37+0000",
            "content": "why PARENT:true should ignore deletions?\n\nIn an earlier iteration, it needed to... but now I think it's just desirable (as opposed to required) because it's more efficient (less backtracking over deleted docs), and more resilient to accidental error conditions (like when someone deletes a parent doc but not it's children).\n\nI propose to revise the idea of rewindable docIDset iterator \n\nSee LUCENE-5092, it looks like something like that has been rejected.\n\nAs far as maintenance, the current stuff makes some things easier to tweak.  I already did so for the child parser to make it fit better with how we put together full queries.  Anyway, the important part are the public interfaces (the XML doc, and {Unable to render embedded object: File (parent} {!child} parsers and semantics).  If we're happy with those, I think we should commit at this point - this issue has been open for far too long) not found. "
        },
        {
            "author": "Mikhail Khludnev",
            "id": "comment-13736386",
            "date": "2013-08-11T19:08:08+0000",
            "content": "like when someone deletes a parent doc but not it's children \n\nI've thought it so. However, there is an argument provided by one of my colleagues and the brightest engineer ever (Nina G) - such courtesy works until merge happens, and after merge/expunge deletes it's a pain. So, beside it's inconsistent, I even thought it wont be passed by random tests.   \n\nSee LUCENE-5092, it looks like something like that has been rejected.\nthat approach has performance implication, but I propose nothing more just API massaging without any real implementation changes/extending: let BJQ work with something, which is either CachingWrapperFilter or BitDocSet.getTopFilter().\n\nIf we're happy with those, I think we should commit at this point -  \n\nI got your point. It makes sense. We just need to raise followup issue - unify BJQs across Lucene and Solr, and ideally address it before the next release. Otherwise, it's just a way to upset a user - if someone happy with BJQ in Lucene, it should be clear that with this parser he goes to another BJQs. As an alternative intermediate measure, don't you think it's more honest to store CachingWrapperFilter in Solr's filtercache via ugly hack, for sure. Then, follow up and address it soon.  \n\nthis issue has been open for far too long)\nbut who really cares?  \n\nThanks "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13736401",
            "date": "2013-08-11T20:17:44+0000",
            "content": "why take working per-segment code and make it slower/top-level? "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13736406",
            "date": "2013-08-11T20:22:49+0000",
            "content": "per-segment caches isn't the focus of this issue (although we should add a generic per-segment cache that can be sized/managed in a diff issue). "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13736411",
            "date": "2013-08-11T20:37:02+0000",
            "content": "The previous patches were per-segment. There is no reason for it to be top-level! "
        },
        {
            "author": "Michael McCandless",
            "id": "comment-13736417",
            "date": "2013-08-11T20:56:26+0000",
            "content": "I don't understand all the design constraints here, but I really don't like that the internal fork (full copy) of the ToParent/ChildBlockJoinQuery sources.\n\nWhy is this necessary?  Is it to cutover to the top-level filter cache?\n\nWe should not fork our sources if we can help it ... "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13736504",
            "date": "2013-08-12T02:33:12+0000",
            "content": "The important parts of this issue are:\n\n\tSerialization formats (XML, javabin, etc)\n\tjoin semantics\n\tjoin syntax... i.e. {!child ...} {!parent ...}\n\tcommon public Solr Java APIs SolrInputDocument, UpdateHandler/UpdateProcessor\n\tcorrectness\n\n\n\nOther things are implementation details that can be improved over time.\nWe should be aware of things we don't want to support long term... this\nis why I removed the external/custom cache dependency (in addition to the\nusability implications).\n\nAs far as \"per-segment\" goes, some of the previous patches had issues\n(such as caching SolrCache in QParser instances), double-caching\n(the filter used by the join would be cached separately from the\nsame filter used in all other contexts), the custom caches defined in\nsolrconfig.xml, not to mention my general dislike for weak references.\nSince per-segment filter caching is an orthogonal issue (and it would be\nbest to be able to specify this on a per-filter basis), I decided it was\nbest to leave per-segment filters for a different issue and create queries\nthat would work well with the way Solr currently does it's filter caching\nand request construction.\n\nAdditionally, how to deal with the \"going backwards\" problem / expecting\nall filters to be FixedBitSet (which Solr doesn't use) is still up in the\nair: LUCENE-5092.  There's no reason to wait for that to get hashed out\nbefore giving Solr users block child/parent join functionallity.  Those details\nof the Java APIs just don't matter to Solr users.\n\nThese query classes in question are package-private classes that Solr\nusers do not see - truly an implementation detail.  Changing them in\nthe future (as long as the behavior is equivalent) would not even\nwarrant mention in release notes (unless performance had been improved).\n\nCan there still be implementation improvements? Absolutely!  But I'm\npersonally currently out of time on this issue, and I feel comfortable\nwith supporting the public APIs we've come up with for some time to come.\nSince no one seems to have issues with any of the important parts like\nthe public APIs, I plan on committing this shortly.  Additional\nimprovements/optimizations can come from follow-on patches.\n "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13736508",
            "date": "2013-08-12T02:34:55+0000",
            "content": "However, there is an argument provided by one of my colleagues and the brightest engineer ever (Nina G) - such courtesy works until merge happens, and after merge/expunge deletes it's a pain.\n\nAh, right you (and Nina G) are!  The inconsistency here (working until a merge) is worse than any performance difference.  I'll change it. "
        },
        {
            "author": "Mikhail Khludnev",
            "id": "comment-13736684",
            "date": "2013-08-12T08:21:30+0000",
            "content": "Yonik Seeley give me last chance to rescue the world Solr. \n\n\tintroduce SolrIndexSearcher.addCache(name), QParser can add usercache itself.\n\tleave it as it was before, BJQParser allows to specify user cache for storing CachingWrapperFilter, otherwise it performs bad. It seems forgivable for the 'early-adopter' feature.\n\n "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13736744",
            "date": "2013-08-12T10:48:50+0000",
            "content": "\nSince no one seems to have issues with any of the important parts like\nthe public APIs, I plan on committing this shortly.\n\nUhhh, the code is important to some of us too. There are several objections listed on this issue.\n\nThe patches contributed here took lucene's join module and integrated it into solr, actually thats the description of the issue \"Lucene has the ability to do block joins, we should add it to Solr.\".\n\nBut then suddenly the code becomes garbage: your patch FORKS CODE OF ENTIRE LUCENE JOIN MODULE to make it slow and top-level. Why even bring in lucene-join.jar here?\n\nSo yeah, i dont care if you think code is important or not, -1 to this. "
        },
        {
            "author": "Michael McCandless",
            "id": "comment-13736753",
            "date": "2013-08-12T11:10:47+0000",
            "content": "I plan on committing this shortly.\n\nPlease don't.  Three people have objections to the approach here ... let's iterate to a solution others are happy with.\n "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13736774",
            "date": "2013-08-12T11:28:36+0000",
            "content": "Ah, the joy of lucene vs solr politics.  Anyway, I'm out of time on this issue that I worked hard to get committable (and I was about to commit... it's too bad we're letting perfect be the enemy of good here, but I feel it's a hell of a lot more political than technical). "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13736776",
            "date": "2013-08-12T11:31:14+0000",
            "content": "BJQParser allows to specify user cache for storing CachingWrapperFilter\n\nI don't think that should be part of the parser API (or did you just mean just as config in solrconfig.xml?) "
        },
        {
            "author": "Mikhail Khludnev",
            "id": "comment-13736781",
            "date": "2013-08-12T11:36:37+0000",
            "content": "just mean just as config in solrconfig.xml\nyep.  "
        },
        {
            "author": "Michael McCandless",
            "id": "comment-13736790",
            "date": "2013-08-12T11:53:55+0000",
            "content": "\nI decided it was\nbest to leave per-segment filters for a different issue and create queries\nthat would work well with the way Solr currently does it's filter caching\nand request construction.\n\nI think that makes sense (decouple the two), but can we do this without forking lucene/join's *BlockJoinQuery?\n\nE.g. maybe instead of requiring a FixedBitSet, Parent/ChildBlockJoinQuery could accept an interface/abstract class, that a slice of OpenBitSet (and FixedBitSet) could implement?\n\nOr ... messy, but maybe it could work maybe: the *BlockJoinQuery could do an instanceof check + cast for this OpenBitSet slice ... "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13736799",
            "date": "2013-08-12T12:05:52+0000",
            "content": "FORKS CODE OF ENTIRE LUCENE JOIN MODULE\n\nI really wanted to stop participating in discussions like this, but then I thought that it was important to clear up this mischaracterization for casual viewers.  The patch introduced custom versions of 2 top level query classes (ToChildBlockJoinQuery and ToParentBlockJoinQuery).  Further, they were package private implementation details.  Focusing on whether the classes are officially part of the \"lucene join module\" are silly - it should be irrelevant to Solr end users... you could change those class names every day and it just wouldn't matter. "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-13736830",
            "date": "2013-08-12T12:53:31+0000",
            "content": "Hi,\nI don't think we should again start with\nAh, the joy of lucene vs solr politics\nagain! As far as I understand, the current issue is: Solr has no way to cache filters per segment, so Yonik forked the whole (or major parts) of the Lucene join module into the source code of Solr. This also includes using OpenBitSet instead of FixedBitSet (why?).\n\nI would suggest to proceed like this:\n\n\tDelay committing for now\n\tOpen new issue to allow per-segment caches in Solr\n\tOpen new issue to move away from OpenBitSet as a requirement for caching filters in Solr. For filter caching, FixedBitSet is the better alternative, as filters always have a fixed number of documents. Also reuse CachingWrapperFilter in Solr and don't have a separate filter caching. This would also allow to use the new Bitset implementations in Solr that were recently added to Lucene. Solr should simply have a non-implementation-agnostic caching for DocIdSets.\n\tOnce this is committed, adapt the current patch to use the new filter caching.\n\n\n\nFrom what I have learned in the past: Once we have the forked code in Solr there is no way to move away from it, mainly because:\n\n\tBackwards compatibility complaints of plugin authors\n\t\"It's already implemented and working - why change?\"\n\tSome people claim that \"Top-level caches are not slow\".\n\n\n\nSo my clear -1 from committing the forked code and delay it a few more weeks and instead fix the dependent issues as noted above before this one. "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-13737315",
            "date": "2013-08-12T20:38:06+0000",
            "content": "Uwe, sounds good.  Can you link the new issues here so that we can track them as part of this? "
        },
        {
            "author": "Mikhail Khludnev",
            "id": "comment-13737385",
            "date": "2013-08-12T21:39:08+0000",
            "content": "Uwe Schindler what is the reason of delaying this functionality, if we can deliver it now with the following configuration \"footprint\"?\n\n\n        <query>\n               <cache name=\"cachingWrapperFilterCache\" class=\"solr.search.LRUCache\">\n        </query>\n\t<queryParser name=\"parent\" class=\"join.BlockJoinParentQParserPlugin\">\n\n           <!-- if you omit this BJQ will perform \"suboptimal\", \n                 thought functionally complete, \n                also it annoyingly warns -->\n\n\t\t<str name=\"parent-filter-cache\">cachingWrapperFilterCache</str>\n\t</queryParser>\n\n\n\nBroken Solr on segments seems crucial to me too. \nI suppose that refactoring will take even much time than this modest piece of functionality. I feel it's really challenging from design perspective e.g. can CachingWrapperFilter flip between dense and sparse sets already? shouldn't it use off-heap memory like in LUCENE-5052 rather than pollute the heap? whether filters behavior is defined in index time or can be requested ad-hoc? etc\n\nOnce again, what about going ahead with small configuration footprint, without diverging join queries.\n\nthanks "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13737454",
            "date": "2013-08-12T22:33:41+0000",
            "content": "\nOnce again, what about going ahead with small configuration footprint, without diverging join queries.\n\nI am +1 to that setup, like the original patches on this issue (especially for block joins, its typically only ONE filter anyway: and one that must support some \"special\" stuff like prevSetBit or whatever at the moment compared to general filters). So even long term, maybe a separate cache makes sense because e.g. you want to use compressed implementations for your 'ordinary' filters.\n\n\nBroken Solr on segments seems crucial to me too.\nI suppose that refactoring will take even much time than this modest piece of functionality.\n\nI'm willing to volunteer a significant amount of my time (e.g. like, starting right now) to make it happen. As it stands now its very difficult for users to use solr's features if their index is changing rapidly: lots of garbage and slow reopens.  But right or wrong, i always felt restrained from fixing this, for some of the same reasons Uwe mentions... "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13737468",
            "date": "2013-08-12T22:47:07+0000",
            "content": "I don't think we should again start with\n> Ah, the joy of lucene vs solr politics\n\nHeh.  And then you proceed to spout a bunch of political b.s. "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-13737472",
            "date": "2013-08-12T22:52:58+0000",
            "content": "Commit 1513290 from Yonik Seeley in branch 'dev/trunk'\n[ https://svn.apache.org/r1513290 ]\n\nSOLR-3076: block join parent and child queries "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13737473",
            "date": "2013-08-12T22:54:34+0000",
            "content": "Committed w/ Mikhail's user cache approach.  To everyone who contributed to this, thank you for your patience. "
        },
        {
            "author": "Vadim Kirilchuk",
            "id": "comment-13737904",
            "date": "2013-08-13T06:38:53+0000",
            "content": "Thank you Yonik Seeley! We all waited this for a long time!\n\nBtw, as there are still many things we need to address (for example dih support): should we create subtasks for this jira or create another jira like \"Improving block joins support\" with new subtasks? wdyt? "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-13738415",
            "date": "2013-08-13T16:15:13+0000",
            "content": "Commit 1513577 from Yonik Seeley in branch 'dev/branches/branch_4x'\n[ https://svn.apache.org/r1513577 ]\n\nSOLR-3076: block join parent and child queries "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-13738729",
            "date": "2013-08-13T19:45:02+0000",
            "content": "Hi Yonik, hi Mikhail,\n\nthe committed version seems to be much better than the top-level cache one! Many, many thanks for committing that one! This was my only problem with it. But as you say, we should really work on getting Solr to no longer use top-level caches for filters and facets. Also Filters should not use OpenBitSet anymore, instead FixedBitSet or one of the new compressed bitsets (maybe off-heap). FixedBitSet is also better supported by internal APIs, as some algorithms can directly use it (e.g. in BooleanFilter), not sure if this is relevant for Solr. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13738787",
            "date": "2013-08-13T20:32:00+0000",
            "content": "Closing... \nI opened SOLR-5142 for additional work. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13738797",
            "date": "2013-08-13T20:39:22+0000",
            "content": "Filters should not use OpenBitSet anymore, instead FixedBitSet\n\nHey, it isn't my fault that Lucene chose to fork OpenBitSet  "
        },
        {
            "author": "Mikhail Khludnev",
            "id": "comment-13738801",
            "date": "2013-08-13T20:40:53+0000",
            "content": "Yonik,\nThanks and Congratulations! "
        },
        {
            "author": "David Smiley",
            "id": "comment-13739255",
            "date": "2013-08-14T05:32:15+0000",
            "content": "FYI there is an existing issue with patch that Greg Bowyer is/was working on for per-segment caching in Solr: SOLR-3763 "
        },
        {
            "author": "Anton",
            "id": "comment-13776346",
            "date": "2013-09-24T14:33:55+0000",
            "content": "Hi!\n\nI trying use this feature with solr nightly build: i add \n\n_root_\n\n field and index data with inner <doc> blocks.\n\n\n?q=*:*\n\n  gives me data:\n\n<result name=\"response\" numFound=\"2\" start=\"0\">\n    <doc>\n        <int name=\"id\">4</int>\n        <bool name=\"is_parent\">false</bool>\n        <int name=\"_root_\">3</int>\n    </doc>\n    <doc>\n        <int name=\"id\">3</int>\n        <bool name=\"is_parent\">true</bool>\n        <long name=\"_version_\">1447068567577034752</long>\n        <int name=\"_root_\">3</int>\n    </doc>\n</result>\n\n \n\nBut\n\n\n?q={!parent which=is_parent:true}*:*\n \n\ngives me error:\n\nchild query must only match non-parent docs, but parent docID=1 matched childScorer\n\n\nhowever \n\n ?q={!child of=is_parent:true}*:*\n\n \n\ngives me expected result (only one child doc):\n\n\n<result name=\"response\" numFound=\"1\" start=\"0\">\n    <doc>\n        <int name=\"id\">4</int>\n        <bool name=\"is_parent\">false</bool>\n        <int name=\"_root_\">3</int>\n    </doc>\n</result>\n\n\n\nPlease, can you explain me what i doing wrong? "
        },
        {
            "author": "Vadim Kirilchuk",
            "id": "comment-13776400",
            "date": "2013-09-24T15:42:34+0000",
            "content": "Hi Anton,\n\nIt's better to ask such questions in mail-lists, but anyway let me answer:\n1) First of all you don't need to explicitly specify root field. It's done internally by solr.\n2) \n\n?q={!parent which=is_parent:true}*:*\n\n gives you an exception because child query must never match parent docs!\n\nBut \n\n*:*\n\n breaks the constraint because it matches both child and parent docs. You can try:\n\n?q={!parent which=is_parent:true}is_parent:false\n\n\nI hope it helps. "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13784247",
            "date": "2013-10-02T18:26:55+0000",
            "content": "\nNOTE: this issue mistakenly got listed in the 4.4 section of CHANGES.txt, but is first available in Solr 4.5. "
        },
        {
            "author": "Adrien Grand",
            "id": "comment-13787138",
            "date": "2013-10-05T10:19:24+0000",
            "content": "4.5 release -> bulk close "
        }
    ]
}