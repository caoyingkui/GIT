{
    "id": "LUCENE-1313",
    "title": "Near Realtime Search (using a built in RAMDirectory)",
    "details": {
        "labels": "",
        "priority": "Minor",
        "components": [
            "core/index"
        ],
        "type": "New Feature",
        "fix_versions": [
            "4.0-ALPHA"
        ],
        "affect_versions": "2.4.1",
        "resolution": "Won't Fix",
        "status": "Closed"
    },
    "description": "Enable near realtime search in Lucene without external\ndependencies. When RAM NRT is enabled, the implementation adds a\nRAMDirectory to IndexWriter. Flushes go to the ramdir unless\nthere is no available space. Merges are completed in the ram\ndir until there is no more available ram. \n\nIW.optimize and IW.commit flush the ramdir to the primary\ndirectory, all other operations try to keep segments in ram\nuntil there is no more space.",
    "attachments": {
        "LUCENE-1313.jar": "https://issues.apache.org/jira/secure/attachment/12404907/LUCENE-1313.jar",
        "lucene-1313.patch": "https://issues.apache.org/jira/secure/attachment/12384453/lucene-1313.patch",
        "TestLuceneNRT.java": "https://issues.apache.org/jira/secure/attachment/12429459/TestLuceneNRT.java",
        "LUCENE-1313.patch": "https://issues.apache.org/jira/secure/attachment/12391299/LUCENE-1313.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2008-06-22T17:06:43+0000",
            "content": "lucene-1313.patch\n\nPatch includes libraries:\n\n\tcommons-io-1.3.2.jar\n\tcommons-lang-2.3.jar\n\tjdom.jar\n\tslf4j-api-1.5.2.jar\n\tslf4j-simple-1.5.2.jar\n\tsource from http://reader.imagero.com/uio/\n\tsource from net.sourceforge.jsorter\n\n\n ",
            "author": "Jason Rutherglen",
            "id": "comment-12607109"
        },
        {
            "date": "2008-06-24T00:21:25+0000",
            "content": "lucene-1313.patch\n\nRemoved http://reader.imagero.com/uio/ code as it routinely corrupted the log.  It's replacement is RandomAccessFile.  Added MultiThreadSearcherPolicy that is used to created a multi threaded Searcher.  Transaction multithreading has been removed because it makes it hard to debug.  It will be optional in the future.  Many bugs have been fixed.  TestSearch tests for deletes.  Index directories are now of the form \"2_index\", the index id and the suffix \"_index\".   ",
            "author": "Jason Rutherglen",
            "id": "comment-12607425"
        },
        {
            "date": "2008-06-24T21:31:37+0000",
            "content": "lucene-1313.patch\n\nDepends on LUCENE-1312 and LUCENE-1314.  More bugs fixed.  Deletes are committed to indexes only intermittently which improves the update speed dramatically.   MaybeMergeIndexes now runs via a background timer. \n\nWill remove writing a snapshot.xml file per transaction in favor of a human readable log.  Creating and deleting these small files is a bottleneck for update speed.  This way a transaction writes to 2 files only.  The merges happen in the background and so never affect the transaction update speed.  I am not sure how useful it would be, but it is possible to have a priority based IO system that favors transactions over merges.  If a transaction is coming in and a merge is happening to disk, the merge is stopped and the transaction IO runs, then the merge IO continues.  \n\nI am not sure how to handle Documents with Fields that have a TokenStream as the value as I believe these cannot be serialized.  For now I assume it will be unsupported.  \n\nAlso not sure how to handle analyzers, are these generally serializable?  It would be useful to serialize them for a more automated log recovery process. ",
            "author": "Jason Rutherglen",
            "id": "comment-12607771"
        },
        {
            "date": "2008-07-17T14:35:50+0000",
            "content": "lucene-1313.patch\n\n\n\tDepends on LUCENE-1314\n\tOceanSegmentReader implements reuse of deletedDocs bytes in conjunction with LUCENE-1314\n\tSnapshot logging happens to a rolling log file\n\tCRC32 checking added to transaction log\n\tAdded TestSystem test case that performs adds, updates and deletes.  TestSystem uses arbitrarily small settings numbers to force the various background merges to happen within a minimal number of transactions\n\tTransactions with over N documents encoded into a segment (via RAMDirectory) to the transaction log rather than serialized as a Document\n\tStarted wiki page http://wiki.apache.org/lucene-java/OceanRealtimeSearch linked from http://wiki.apache.org/lucene-java/LuceneResources.  Will place documentation there.\n\tDocument fields with Reader or TokenStream values supported\n\n\n\nBegan work on LargeBatch functionality, needs test case.  Large batches allow adding documents in bulk (also performing deletes) in a transaction that goes straight to an index bypassing the transaction log.  This provides the same  speed as using IndexWriter to perform bulk Document processing in Ocean.  \n\nStarted OceanDatabase which will offer a Java API inspired by GData.  Will offer optimistic concurrency (something required in a realtime search system) and dynamic object mapping (meaning types such as long, date, double will be mapped to a string term using some Solr code).  A file sync is performed after each transaction, will add an option to allow syncing after N transactions like mysql.  This will improve realtime update speeds.  \n\nFuture:\n\n\n\tSupport for multiple servers by implementing distributed API and replication using LUCENE-1336\n\tTest case that is akin to TestStressIndexing2 mainly to test threading\n\tAdd LargeBatch test to TestSystem\n\tFacets\n\tLooking at adding GData compatible XML over HTTP API.  Possibly can reuse the old Lucene GData code.\n\tIntegrate tag index when it's completed\n\tAdd LRU record cache to transaction log which will be useful for faster replication\n\n ",
            "author": "Jason Rutherglen",
            "id": "comment-12614365"
        },
        {
            "date": "2008-09-02T09:05:21+0000",
            "content": "Hi Jason,\n\nI took an inital look at your code last night. Didn't actually execute anything, just followed method calls around to see what it was up to.\n\nMy first comment is sort of boring, but there are virtually no javadocs for the core classes such as TransactionSystem, Batch and Index. It would be great if there was a bit at the class level exaplaining what classes they interact with and how.  It would also be very helpful if there was method level javadocs for at least the top level commit related logic.\n\nOne thing that early cought my attention is this method in TransactionSystem:\n\n  public OceanSearcher getSearcher() throws IOException {\n    Snapshot snapshot = snapshots.getLatestSnapshot();\n    if (searcherPolicy instanceof SingleThreadSearcherPolicy) {\n      return new OceanSearcher(snapshot);\n    } else {\n      return new OceanMultiThreadSearcher(snapshot, searchThreadPool);\n    }\n  }\n\n\n\nAm I supposed to call this method for each query (as suggested by the method name) or is this a factory method used to update my own Searcher instance after committing documents to the index (as suggested by the code)? \n\nIt's not such a big deal, but I personally think you should refactor the instanceOf to a Policy.searcherFactory method, or perhaps even a SearcherPolicyVisitor. Actually, this goes for a few other places in the module too: you have used instanceOf and unchecked casting a bit more extensive to solve problems than what I would have. But as it does not seem to be used in places where it would be a costrly thing to do these comments are mearly about code readability and gut feelings about future problems. \n\nI'm a bit concerned about the potential loss of data while documents only resides in InstantiatedIndex or RAMDirectory. I think I'd like an option on some sort of transaction log that could be played up in case of a crash. I think the easiset way would be to convert all documents to be pre-analyzed (field.tokenStream) before passing them on to the instantiated writer. I don't know how much resources that might consume, but it would make me feel safer. \n\n\n     karl ",
            "author": "Karl Wettin",
            "id": "comment-12627612"
        },
        {
            "date": "2008-09-02T12:05:28+0000",
            "content": "Hi Karl,\n\nThanks for taking a look at the code!  Yes the methods need javadoc, I was waiting to see if I had settled on them, and because I started building new code on top I guess the methods have settled so I need to add javadoc to them.  \n\nIf you are using TransactionSystem then the getSearcher method would be called for each query.  I have developed OceanDatabase which makes the searching transparent and implements optimistic concurrency (version number stored in the document).  I believe most systems will want to use OceanDatabase, however the raw TransactionSystem which is more like IndexWriter will be left as well.  I have been working on OceanDatabase and have neglected the javadocs of TransactionSystem.  \n\nI modeled the searcherPolicy instanceof code on the MergeScheduler type of system where there is a marker interface that the subclasses implement.   I don't mind changing it, or if you want to you can as well.  I considered it a minor detail though and admittedly did not spend much time on it.  You are welcome to change it.\n\nThe transaction log is replayed on a restart of the system.  It repopulates a RamIndex (uses RAMDirectory) on startup based on the max snapshot id of the existing indexes, and replays the transaction log from there.   \n\nI looked at converting documents to a token stream, the problem is, if the field is stored, it creates redundant storage of the data in the transaction log.  Ultimately I could not find anything to be gained from storing a token stream.  Also if it was converted, what would happen with stored fields?  The issue with replaying the document later though is not having the Analyzer.  In the distributed object code patch LUCENE-1336 I made Analyzer Serializable.  I think it's best to serialize the Analyzer, or create a small database of serialized analyzers that can be called upon during the transaction log recovery process.  Because I am not entirely sure about the ramifications of serializing the Analyzer, for example, how much data a serialized Analyzer may have.  Perhaps other have some ideas or feedback about serializing analyzers.\n\nIn conclusion, I'll add more javadocs.  Please feel free to ask more questions!\n\nJason ",
            "author": "Jason Rutherglen",
            "id": "comment-12627642"
        },
        {
            "date": "2008-09-03T18:42:33+0000",
            "content": "Is there a good place to place the javadocs on the Apache website once they are more complete?   ",
            "author": "Jason Rutherglen",
            "id": "comment-12628092"
        },
        {
            "date": "2008-10-01T18:08:11+0000",
            "content": "LUCENE-1313.patch\n\nAdded javadocs.  Still needs the LUCENE-1314 completed which will be divided into multiple patches. ",
            "author": "Jason Rutherglen",
            "id": "comment-12636110"
        },
        {
            "date": "2009-04-01T22:48:54+0000",
            "content": "The patch includes RealtimeIndex a basic class for performing atomic\ntransactional realtime indexing and search. A single thread\nperiodically flushes to disk the ram index. It relies on\nLUCENE-1516.\n\nWe need to benchmark this, specifically 1) realtime w/ramdir\ntransaction 2) realtime w/queued documents transaction 3) normal\nindexing. Realtime w/ramdir encodes the transaction to a\nRAMDirectory which is added to the RAM writer using\nIW.addIndexesNoOptimize. Option 1 may be slower than option 2,\nhowever if the system is replicating it may be the only option?\n\nLong term I believe we need to implement searching over the\nIndexWriter ram buffer (if possible). However I am not sure how\noption 1 and replication would work with it? ",
            "author": "Jason Rutherglen",
            "id": "comment-12694810"
        },
        {
            "date": "2009-04-02T08:53:26+0000",
            "content": "Jason, your last patch looks like it's taking the \"flush first to RAM Dir\" approach I just described as the next step (on the java-dev thread), right?  Which is great!\n\nSo this has no external dependencies, right?  And it simply layers on top of LUCENE-1516.\n\nI'd be very interested to compare (benchmark) this approach vs solely LUCENE-1516.\n\nCould we change this class so that instead of taking a Transaction object, holding adds & deletes, it simply mirrors IndexWriter's API?  Ie, I'd like to decouple the performance optimization of \"let's flush small segments ithrough a RAMDir first\" from the transactional semantics of \"I process a transaction atomically, and lock out other thread's transactions\".  Ie, the transactional restriction could/should layer on top of this performance optimization for near-realtime search? ",
            "author": "Michael McCandless",
            "id": "comment-12694917"
        },
        {
            "date": "2009-04-06T17:25:57+0000",
            "content": "So this has no external dependencies, right?\n\nYes.\n\nI'd be very interested to compare (benchmark) this approach\nvs solely LUCENE-1516.\n\nIs the .alg using the NearRealtimeReader from LUCENE-1516 our\nbest measure of realtime performance?\n\n\nthe transactional restriction could/should layer on\ntop of this performance optimization for near-realtime search?\n\nThe transactional system should be able to support both methods.\nPerhaps a non-locking setting would allow the same RealtimeIndex\nclass support both modes of operation? ",
            "author": "Jason Rutherglen",
            "id": "comment-12696186"
        },
        {
            "date": "2009-04-06T22:11:08+0000",
            "content": "We'll need to integrate the RAM based indexer into IndexWriter\nto carry over the deletes to the ram index while it's copied to\ndisk. This is similar to IndexWriter.commitMergedDeletes\ncarrying deletes over at the segment reader level based on a\ncomparison of the current reader and the cloned reader.\nOtherwise there's redundant deletions to the disk index using\nIW.deleteDocuments which can be unnecessarily expensive. To make\nexternal we would need to do the delete by doc id genealogy.  ",
            "author": "Jason Rutherglen",
            "id": "comment-12696277"
        },
        {
            "date": "2009-04-07T08:57:07+0000",
            "content": "\n> I'd be very interested to compare (benchmark) this approach\n> vs solely LUCENE-1516.\n\nIs the .alg using the NearRealtimeReader from LUCENE-1516 our\nbest measure of realtime performance?\n\nSo far, I think so?  You get to set an update rate (delete + add) docs, eg 50 docs/sec, and a pause time between NRT reopens.\n\nStill, it's synthetic.  If you guys (LinkedIn) have a way to fold in some realism into the test, that'd be great, if only \"our app ingests at X docs(MB)/sec and reopens the NRT reader X times per second\" to set our ballback.\n\n\n> the transactional restriction could/should layer on\n> top of this performance optimization for near-realtime search?\n\nThe transactional system should be able to support both methods.\nPerhaps a non-locking setting would allow the same RealtimeIndex\nclass support both modes of operation?\n\nSorry, what are both \"modes\" of operation?\n\nI think there are two different \"layers\" here \u2013 first layer optimizes NRT by flushing small segments to RAMDir first.  This seems generally useful and in theory has no impact to the API IndexWriter exposes (it's \"merely\" an internal optimization).  The second layer adds this new Transaction object, such that N adds/deletes/commit/re-open NRT reader can be done atomically wrt other pending Transaction objects.\n\n\nWe'll need to integrate the RAM based indexer into IndexWriter\nto carry over the deletes to the ram index while it's copied to\ndisk. This is similar to IndexWriter.commitMergedDeletes\ncarrying deletes over at the segment reader level based on a\ncomparison of the current reader and the cloned reader.\nOtherwise there's redundant deletions to the disk index using\nIW.deleteDocuments which can be unnecessarily expensive. To make\nexternal we would need to do the delete by doc id genealogy.\n\nRight, I think the RAMDir optimization would go directly into IW, if we can separate it out from Transaction.  It could naturally derive from the existing RAMBufferSizeMB, ie if NRT forces a flush, so long as its tiny, put it into the local RAMDir instead of the actual Dir, then \"deduct\" that size from the allowed budget of DW's ram usage.  When RAMDIr + DW exceeds RAMBufferSizeMB, we then merge all of RAMDir's segments into a \"real\" segment in the directory. ",
            "author": "Michael McCandless",
            "id": "comment-12696438"
        },
        {
            "date": "2009-04-08T00:22:34+0000",
            "content": "Latest realtime code, transactions are removed. \n\n\n\tNeeds to be benchmarked\n\n\n\n\n\tThere could be concurrency issues around deletes that occur\nwhile directories are being flushed to disk. \n\n\n\n\n\tIt's Java JARed to include the files and directory structure.\nThe patch relies on LUCENE-1516 which if included would make the\nchanges incomprehensible\n\n\n\n\n ",
            "author": "Jason Rutherglen",
            "id": "comment-12696840"
        },
        {
            "date": "2009-04-08T21:43:33+0000",
            "content": " Still, it's synthetic. If you guys (LinkedIn) have a way\nto fold in some realism into the test, that'd be great, if only\n\"our app ingests at X docs(MB)/sec and reopens the NRT reader X\ntimes per second\" to set our ballback. \n\nThe test we need to progress to is running the indexing side\nendlessly while also reopening every X seconds, then\nconcurrently running searches. This way we can play with a bunch\nof settings (mergescheduler threads, merge factors, max merge\ndocs, etc), use the python code to generate a dozen cases,\nexecute them and find out what seems optimal for our corpus.\nIt's a bit of work but probably the only way each Lucene user\ncan conclusively say they have the optimal settings needed for\ntheir system. Usually there is a baseline QPS that is desired,\nwhere the reopen delay may be increased to accommodate a lack of\nQPS. \n\nThe ram dir portion of the NRT indexing increases in speed when\nmore threads are allocated but those compete with search\nthreads, another issue to keep in mind. \n\nIt might be good to add some default charting to\ncontrib/benchmark?  ",
            "author": "Jason Rutherglen",
            "id": "comment-12697226"
        },
        {
            "date": "2009-04-09T09:19:03+0000",
            "content": "\nThe test we need to progress to is running the indexing side\nendlessly while also reopening every X seconds, then\nconcurrently running searches\n\nDo you have a sense of what we'd need to add to contrib/benchmark to make this test possible?  LUCENE-1516 takes the first baby step (adds a \"NearRealtimeReaderTask\").\n\n\nUsually there is a baseline QPS that is desired,\nwhere the reopen delay may be increased to accommodate a lack of\nQPS.\nRight \u2013 that's the point I made on java-dev about the \"freedom\" we have wrt NRT's performance.\n\n\nThe ram dir portion of the NRT indexing increases in speed when\nmore threads are allocated but those compete with search\nthreads, another issue to keep in mind.\nWell, single threaded indexing speed is also improved by using RAM dir.  Ie the use of RAM dir is orthogonal to the app's use of threads for indexing?\n\n\nIt might be good to add some default charting to\ncontrib/benchmark?\nI've switched to Google's visualization API (http://code.google.com/apis/visualization/) which is a delight (they have a simple-to-use Python wrapper).  It'd be awesome to somehow get simple charting folded into benchmark... maybe start w/ shear data export (as tab/comma delimited line file), and then have a separate step that slurps that data in and makes a [Google vis] chart. ",
            "author": "Michael McCandless",
            "id": "comment-12697444"
        },
        {
            "date": "2009-04-17T20:27:13+0000",
            "content": "I added an IndexWriter.getRAMIndex method that returns a\nRAMIndex object that can be updated and flushed to the\nunderlying writer. I think this is better than adding more\nmethods to IndexWriter and it separates out the logic of the RAM\nbased near realtime index and the rest of IW.\n\nPackage protected IW.addIndexesNoOptimize(DirectoryIndexReader[]\nreaders) is added which is used by RAMIndex.flush. I thought\nthis functionality could work for LUCENE-1589 as a public\nmethod, however because of the way IndexWriter performs merges\nusing segment infos, handling generic IndexReader classes (which\nmay not use segmentinfos) would then be difficult in the\naddIndexesNoOptimize case.\n\nI think RAMIndex.flush to the underlying writer is not\nsynchronized. If the IW is using ConcurrentMergeScheduler then\nthe heavy lifting is performed in the background and so should\nnot delay adding more documents to the RAMIndex.\n\nIW.getReader returns the normal IW reader and the RAMIndex\nreader if there is one.\n\nThe RAMIndex writer can be obtained and modified directly as\nopposed to duplicating the setter methods of IndexWriter such as\nsetMergeScheduler. ",
            "author": "Jason Rutherglen",
            "id": "comment-12700317"
        },
        {
            "date": "2009-04-20T21:09:13+0000",
            "content": "\n\tThe RAMIndex deletes approach changed to be like IndexWriter.\nThe deletes are queued in lists, then applied on RI.flush. \n\n\n\n\n\tThere is redundancy between IW.delete* and RI.delete*, perhaps\nwe don't need RI.delete*?\n\n\n\n\n\tWe need more multithreaded tests, probably based on\nTestIndexWriter to see if we can trigger issues in regards to\ndeletes that occur while RI is calling IW.addIndexesNoOptimize.\n\n\n\n\n\tIf RI.delete* is removed, do we need a separate RAMIndex class\nto add documents to or is there a more transparent way for NRT\nramdir to work? Perhaps we can add an IW.flushToRamDir (whereas\nIW.flush writes to the IW directory) method that flushes the\nrambuffer to the RAMIndex? Some of the the issues are around\nswapping out the RAMDir once it's segments are flushed to IW. If\nwe took this approach would we need a IW.getReaderRAM method\nthat instead of flushing to disk flushes to the ramdir? The\nother problem with the IW.flushToRamDir system is the loss of\nconcurrency where a large rambuffer may be flushing to disk\nwhile the user really wants to small incremental NRT RI based\nupdates at the same time. \n\n ",
            "author": "Jason Rutherglen",
            "id": "comment-12700934"
        },
        {
            "date": "2009-04-24T19:31:50+0000",
            "content": "For this patch I'm debating whether to add a package protected\nIndexWriter.addIndexWriter method. The problem is, the RAMIndex\nblocks on the write to disk during IW.addIndexesNoOptimize which\nif we're using ConcurrentMergeScheduler shouldn't happen?\nMeaning in this proposed solution, if segments keep on piling up\nin RAMIndex, we simply move them over to the disk IW which will\nin the background take care of merging them away and to disk.\n\nI don't think it's necessary to immediately write ram segments\nto disk (like the current patch does), instead it's possible to\nsimply copy segments over from the incoming IW, leave them in\nRAM and they can be merged to disk as necessary? Then on\nIW.flush any segmentinfo(s) that are not from the current\ndirectory can be flushed to disk? \n\nJust thinking out loud about this. ",
            "author": "Jason Rutherglen",
            "id": "comment-12702496"
        },
        {
            "date": "2009-04-24T20:03:33+0000",
            "content": "\nI don't think it's necessary to immediately write ram segments to disk\n\nI agree: it should be fine from IndexWriter's standpoint if some\nsegments live in a private RAMDir and others live in the \"real\" dir.\n\nIn fact, early versions of LUCENE-843 did exactly this: IW's RAM\nbuffer is not as efficient as a written segment, and so you can gain\nsome RAM efficiency by flushing first to RAM and then merging to disk.\n\nI think we could adopt a simple criteria: you flush the new segment to\nthe RAM Dir if net RAM used is < maxRamBufferSizeMB.  This way no\nfurther configuration is needed.  On auto-flush triggering you then\nmust take into account the RAM usage by this RAM Dir.  On commit,\nthese RAM segments must be migrated to the real dir (preferably by\nforcing a merge, somehow).\n\nA near realtime reader would also happily mix \"real\" Dir and RAMDir\nSegmentReaders.\n\nThis should work well I think, and should not require a separate\nRAMIndex class, and won't block things when the RAM segments are\nmigrated to disk by CMS. ",
            "author": "Michael McCandless",
            "id": "comment-12702515"
        },
        {
            "date": "2009-04-24T21:52:54+0000",
            "content": " I think we could adopt a simple criteria: you flush the\nnew segment to the RAM Dir if net RAM used is <\nmaxRamBufferSizeMB. This way no further configuration is needed.\nOn auto-flush triggering you then must take into account the RAM\nusage by this RAM Dir. \n\nSo we're ok with the blocking that occurs when the ram buffer is\nflushed to the ramdir? \n\nOn commit, these RAM segments must be migrated to the\nreal dir (preferably by forcing a merge, somehow). \n\nThis is pretty much like resolveExternalSegments which would be\ncalled in prepareCommit? This could make calls to commit much\nmore time consuming. It may be confusing to the user why\nIW.flush doesn't copy the ram segments to disk.\n\nA near realtime reader would also happily mix \"real\" Dir\nand RAMDir SegmentReaders.\n\nAgreed, however the IW.getReader MultiSegmentReader removes\nreaders from another directory so we'd need to add a new\nattribute to segmentinfo that marks it as ok for inclusion in\nthe MSR?\n ",
            "author": "Jason Rutherglen",
            "id": "comment-12702573"
        },
        {
            "date": "2009-04-24T22:13:54+0000",
            "content": "\nSo we're ok with the blocking that occurs when the ram buffer is\nflushed to the ramdir?\n\nWell... we don't have a choice (unless/until we implement IndexReader impl to directly search the RAM buffer).  Still, this should be a good improvement over the blocking when flushing to a real dir.\n\n\nThis is pretty much like resolveExternalSegments which would be\ncalled in prepareCommit? This could make calls to commit much\nmore time consuming. It may be confusing to the user why\nIW.flush doesn't copy the ram segments to disk.\n\nSimilar... the difference is I'd prefer to do a merge of the RAM segments vs the straight one-for-one copy that resolveExternalSegments does.\n\ncommit would only become more time consuming in the NRT case?  IE we'd only flush-to-RAMdir if it's getReader that's forcing the flush?  In which case, I think it's fine that commit gets more costly.  Also, I wouldn't expect it to be much more costly: we are doing an in-memory merge of N segments, writing one segment to the \"real\" directory.  Vs writing each tiny segment as a real one.  In fact, commit could get cheaper (when compared to not making this change) since there are fewer new files to fsync.\n\n\nAgreed, however the IW.getReader MultiSegmentReader removes\nreaders from another directory so we'd need to add a new\nattribute to segmentinfo that marks it as ok for inclusion in\nthe MSR?\n\nOr, fix that filtering to also accept IndexWriter's RAMDir. ",
            "author": "Michael McCandless",
            "id": "comment-12702579"
        },
        {
            "date": "2009-04-24T22:48:02+0000",
            "content": "I'm confused as to how we make DocumentsWriter switch from\nwriting to disk vs the ramdir? It seems like a fairly major\nchange to the system? One that's hard to switch later on after\nIW is instantiated? Perhaps the IW.addWriter method is easier in\nthis regard?\n\n the difference is I'd prefer to do a merge of the RAM\nsegments vs the straight one-for-one copy that\nresolveExternalSegments does.\n\nYeah I implemented it this way in the IW.addWriter code. I agree\nit's better for IW.commit to copy all the ramdir segments to one\ndisk segment. \n\nI started working on the IW.addWriter(IndexWriter, boolean\nremoveFrom) where removeFrom removes the segments that have been\ncopied to the destination writer from the source writer. This\nmethod gets around the issue of blocking because potentially\nseveral writers could concurrently be copied to the destination\nwriter. The only issue at this point is how the destination\nwriter obtains segmentreaders from source readers when they're\nin the other writers' pool? Maybe the SegmentInfo can have a\nreference to the writer it originated in? That way we can easily\naccess the right reader pool when we need it?\n ",
            "author": "Jason Rutherglen",
            "id": "comment-12702596"
        },
        {
            "date": "2009-04-25T10:02:37+0000",
            "content": "\nI'm confused as to how we make DocumentsWriter switch from\nwriting to disk vs the ramdir? It seems like a fairly major\nchange to the system? One that's hard to switch later on after\nIW is instantiated? Perhaps the IW.addWriter method is easier in\nthis regard?\n\nWhen we create SegmentWriteState (which is supposed to contain all\ndetails needed to tell DW how/where to write the segment), we'd set\nits directory to the RAMDir?  That ought to be all that's needed\n(though, it's possible some places use a private copy of the original\ndirectory, which we should fix).  DW should care less which Directory\nthe segment is written to...\n\n\n> the difference is I'd prefer to do a merge of the RAM\n> segments vs the straight one-for-one copy that\n> resolveExternalSegments does.\n\nYeah I implemented it this way in the IW.addWriter code. I agree\nit's better for IW.commit to copy all the ramdir segments to one\ndisk segment.\n\nOK.  Maybe we modify resolveExternalSegments to accept a \"doMerge\"?\n\n\nI started working on the IW.addWriter(IndexWriter, boolean\nremoveFrom) where removeFrom removes the segments that have been\ncopied to the destination writer from the source writer. This\nmethod gets around the issue of blocking because potentially\nseveral writers could concurrently be copied to the destination\nwriter. The only issue at this point is how the destination\nwriter obtains segmentreaders from source readers when they're\nin the other writers' pool? Maybe the SegmentInfo can have a\nreference to the writer it originated in? That way we can easily\naccess the right reader pool when we need it?\n\nI don't think we need two writers?  I think one writer, sometimes\nflushing to RAMDir, is a clean solution? ",
            "author": "Michael McCandless",
            "id": "comment-12702673"
        },
        {
            "date": "2009-04-25T11:39:05+0000",
            "content": "One separate optimization we should make with NRT is to not close the doc store (stored fields, term vector) files when flushing for an NRT reader.\n\nWe do close them now, which then makes merging quite a bit more costly.\n\nThe trickiness with this optimization is we'd need to be able to somehow share an IndexInput & IndexOutput; or, perhaps we can open an IndexInput even though an IndexOutput has the same file open (Windows may prevent this, though I think I've seen that it will in fact allow it).\n\nOnce we do that optimization, then with this RAMDir optimization we should try to have the doc store files punch straight through to the real directory, ie bypass the RAMDir.  The doc stores are space consuming, and since with autoCommit=false we can bypass merging them, it makes no sense to store them in the RAMDir.\n\nWe should probably do this optimization as a \"phase 2\", after this one. ",
            "author": "Michael McCandless",
            "id": "comment-12702683"
        },
        {
            "date": "2009-04-27T19:37:05+0000",
            "content": " When we create SegmentWriteState (which is supposed to\ncontain all details needed to tell DW how/where to write the\nsegment), we'd set its directory to the RAMDir? That ought to be\nall that's needed (though, it's possible some places use a\nprivate copy of the original directory, which we should fix). DW\nshould care less which Directory the segment is written to...\n\nAgreed that DW can write the segment to the RAMDir. I started\ncoding along these lines however what do we do about the RAMDir\nmerging? This is why I was thinking we'll need a separate IW?\nOtherwise the ram segments (if they are treated the same as disk\nsegments) would quickly be merged to disk? Or we have two\nseparate merging paths?\n\nIf we have a disk IW and ram IW, I'm not sure how the docstores\nto disk part would work though I'm sure there's some way to do\nit.\n\nmodify resolveExternalSegments to accept a \"doMerge\"?\n\nSounds good. ",
            "author": "Jason Rutherglen",
            "id": "comment-12703315"
        },
        {
            "date": "2009-04-27T19:50:58+0000",
            "content": "we should make with NRT is to not close the doc store\n(stored fields, term vector) files when flushing for an NRT\nreader. \n\nAgreed, I think this feature is a must otherwise we're doing\nunnecessary in ram merging.  \n\nwe'd need to be able to somehow share an IndexInput &\nIndexOutput; or, perhaps we can open an IndexInput even though\nan IndexOutput\n\nI ran into problems with this before, I was trying to reuse\nDirectory to write a transaction log. It seemed theoretically\ndoable however it didn't work in practice. It could have been\nthe seeking and replacing but I don't remember. FSIndexOutput\nuses a writeable RAF and FSIndexInput is read only why would\nthere be an issue?\n\n ",
            "author": "Jason Rutherglen",
            "id": "comment-12703317"
        },
        {
            "date": "2009-04-27T19:59:17+0000",
            "content": "doc store files punch straight through to the real\ndirectory\n\nTo implement this functionality in parallel (and perhaps make\nthe overall patch cleaner), writing doc stores directly to a\nseparate directory can be a different patch? There can be an\noption IW.setDocStoresDirectory(Directory) that the patch\nimplements? Then some unit tests that are separate from the near\nrealtime portion.  ",
            "author": "Jason Rutherglen",
            "id": "comment-12703327"
        },
        {
            "date": "2009-04-27T20:56:32+0000",
            "content": "\nAgreed that DW can write the segment to the RAMDir. I started\ncoding along these lines however what do we do about the RAMDir\nmerging? This is why I was thinking we'll need a separate IW?\nOtherwise the ram segments (if they are treated the same as disk\nsegments) would quickly be merged to disk? Or we have two\nseparate merging paths?\n\nHmm, right.  We could exclude RAMDir segments from consideration by\nMergePolicy?  Alternatively, we could \"expect\" the MergePolicy to\nrecognize this and be smart about choosing merges (ie don't mix\nmerges)?\n\nEG we do in fact want some merging of the RAM segments if they get too\nnumerous (since that will impact search performance).\n\n\n> we should make with NRT is to not close the doc store\n> (stored fields, term vector) files when flushing for an NRT\n> reader.\n\nAgreed, I think this feature is a must otherwise we're doing\nunnecessary in ram merging.\n\nOK, let's do this as a separate issue/optimization for NRT.  There are\ntwo separate parts to it:\n\n\n\tAbility to store doc stores in \"real\" directory (looks like you\n    opened LUCENE-1618 for this part).\n\n\n\n\n\tAbility to \"share\" IndexOutput & IndexInput\n\n\n\n\nI ran into problems with this before, I was trying to reuse\nDirectory to write a transaction log. It seemed theoretically\ndoable however it didn't work in practice. It could have been\nthe seeking and replacing but I don't remember. FSIndexOutput\nuses a writeable RAF and FSIndexInput is read only why would\nthere be an issue?\n\nHmm... seems like we need to investigate further.  We could either\n\"ask\" an IndexOutput for its IndexInput (sharing the underlying RAF),\nor try to separately open an IndexInput (which may not work on\nWindows).\n\n\nTo implement this functionality in parallel (and perhaps make\nthe overall patch cleaner), writing doc stores directly to a\nseparate directory can be a different patch? There can be an\noption IW.setDocStoresDirectory(Directory) that the patch\nimplements? Then some unit tests that are separate from the near\nrealtime portion.\n\nYes, separate issue (LUCENE-1618). ",
            "author": "Michael McCandless",
            "id": "comment-12703366"
        },
        {
            "date": "2009-04-27T21:09:25+0000",
            "content": "So let's leave this issue focused on sometimes using RAMDir for newly created segments. ",
            "author": "Michael McCandless",
            "id": "comment-12703377"
        },
        {
            "date": "2009-04-27T21:20:17+0000",
            "content": " We could exclude RAMDir segments from consideration by\nMergePolicy? Alternatively, we could \"expect\" the MergePolicy to\nrecognize this and be smart about choosing merges (ie don't mix\nmerges)? \n\nIs this over complicating things? Sometimes we want a mixture of\nRAMDir segments and FSDir segments to merge (when we've decided\nwe have too much in ram), sometimes we don't (when we just want\nthe ram segments to merge). I'm still a little confused as to\nwhy having a wrapper class that manages a disk writer and a ram\nwriter isn't cleaner?   ",
            "author": "Jason Rutherglen",
            "id": "comment-12703387"
        },
        {
            "date": "2009-04-27T22:16:09+0000",
            "content": "\nSometimes we want a mixture of\nRAMDir segments and FSDir segments to merge (when we've decided\nwe have too much in ram),\n\nI don't think we want to mix RAM & disk merging?\n\nEG when RAM is full, we want to quickly flush it to disk as a single\nsegment.  Merging with disk segments only makes that flush slower?\n\n\nI'm still a little confused as to\nwhy having a wrapper class that manages a disk writer and a ram\nwriter isn't cleaner?\n\nThis is functionally the same as not mixing RAM vs disk merging,\nright (ie just as \"clean\")? ",
            "author": "Michael McCandless",
            "id": "comment-12703419"
        },
        {
            "date": "2009-04-28T15:46:23+0000",
            "content": "Yonik raised a good question on LUCENE-1618, which is what gains do we really expect to see by using RAMDir for the tiny recently flushed segments?\n\nIt would be nice if we could approximately measure this before putting more work into this issue \u2013 if the gains are not \"decent\" this optimization may not be worthwhile.\n\nOf course, we are talking about 100s of milliseconds for the turnaround time to add docs & open an NRT reader, so if the time for writing/opening many tiny files in RAMDir vs FSDir  differs by say 10s of msecs then we should pursue this.  We should also consider that the IO system may very well be quite busy (doing merge(s), backups, etc.) and that'd make it slower to have to create tiny files.\n\nA simpler optimization might be to allow using CFS for tiny files (even when CFS is turned off), but built the CFS in RAM (ie, write tiny files first to RAMFiles, then make the CFS file on disk).  That might get most of the gains since the FSDir sees only one file created per tiny segment, not N. ",
            "author": "Michael McCandless",
            "id": "comment-12703686"
        },
        {
            "date": "2009-04-28T16:02:32+0000",
            "content": "Yonik raised a good question on LUCENE-1618, which is what gains do we really expect to see by using RAMDir for the tiny recently flushed segments?\n\nI raised it more because of the direction the discussion was veering (write through caching to a RAMDirectory, and RAMDirectory being faster to search).  I do believe that RAMDirectory can probably improve NRT, but  it would be due to avoiding waiting for file open/write/close/open/read (as Mike also said)... and not any difference during IndexSearcher.search(), which should be irrelevant due to the relative size differences of the RAMDirectory and the FSDirectory.  Small file creation speeds will also be heavily dependent on the exact file system used. ",
            "author": "Yonik Seeley",
            "id": "comment-12703695"
        },
        {
            "date": "2009-04-28T22:05:31+0000",
            "content": "EG when RAM is full, we want to quickly flush it to disk\nas a single segment. Merging with disk segments only makes that\nflush slower?\n\nI assume it's ok for the IW.mergescheduler to be used which may\nnot immediately perform the merge to disk (in the case of\nConcurrentMergeScheduler)? When implementing using\naddIndexesNoOptimize (which blocks) I realized we probably don't\nwant blocking to occur because that means shutting down the\nupdates. \n\nAlso a random thought, it seems like ConcurrentMergeScheduler\nworks great for RAMDir merging, how does it compare with\nSerialMS on an FSDirectory? It seems like it shouldn'y be too much\nfaster given the IO sequential access bottleneck? ",
            "author": "Jason Rutherglen",
            "id": "comment-12703853"
        },
        {
            "date": "2009-04-29T10:03:04+0000",
            "content": "\nI assume it's ok for the IW.mergescheduler to be used which may\nnot immediately perform the merge to disk (in the case of\nConcurrentMergeScheduler)?\n\nOnly if we \"accept\" requiring MergePolicy to be aware that some\nsegments are in RAMDir and some are in the \"real\" Dir and to \"act\naccordingly\", ie 1) don't mix the dirs when merging, 2) when RAM is\n\"full\" merge every single RAM segment into a single \"real Dir\" segment\n(requires IW to provide exposure on how much RAM DW's buffer is\ncurrently consuming), 3) properly \"maintain\" the RAM segments (ie,\nmerge RAM -> RAM somehow) so that searchers don't search too many RAM\nsegments.\n\nI think this approach is probably best: you're right that allowing CMS\nto manage these RAM segments is nice since it'll happen in the BG and\nwill not block updates.\n\nIt does mean, though, that the RAM usage semantics of IW is no longer\nso \"crisp\" as flushing today (\"once RAM is full, stop world & flush it\nto disk, then resume\") but I think that's acceptable and perhaps\npreferable since world is no longer stopped to flush RAM -> disk.\n\nThough one trickiness is... if a large RAM -> RAM merge takes place,\nwe temporarily double the RAM consumption.  I think MergePolicy simply\nshouldn't do that.  Ie at not point should it be merging a very large\n%tg of the RAM segments.  It should instead merge RAM -> disk.\n\nThis'd also mean advanced users that implement their own MergePolicy\nmust realize when IW is used with NRT reader that additional smarts is\nrecommended wrt \n\n\nWhen implementing using\naddIndexesNoOptimize (which blocks) I realized we probably don't\nwant blocking to occur because that means shutting down the\nupdates.\nRight, this is one of the strong reasons to do the \"internal\" approach\nvs \"external\" one.\n\n\nAlso a random thought, it seems like ConcurrentMergeScheduler\nworks great for RAMDir merging, how does it compare with\nSerialMS on an FSDirectory? It seems like it shouldn'y be too much\nfaster given the IO sequential access bottleneck?\n\nBy far the biggest win of CMS over SMS is in the first merge, because\nit does not block the further addition of docs.  Thus an app can\ncontinue indexing into RAM buffer (consuming CPU & RAM resources)\nwhile a BG thread consumes RAM + IO resources.  This is very much a\nwin.\n\nBeyond the first merge...in theory, modern IO systems have concurrency\n(eg the NCQ in a single SATA drive) so you should \"gain\" by having\nseveral threads performing IO at once.  The OS & hard drives attempt\nto re-order the request in a more optimal way (like an elevator,\nsweeping floors).  I haven't explictly tested this with Lucene...\n\nI believe SSDs handle concurrent requests very well since under the\nhood most of them are multi-channel basically RAID0 devices (eg Intel\nX25M has 10 channels). ",
            "author": "Michael McCandless",
            "id": "comment-12704051"
        },
        {
            "date": "2009-04-29T21:02:33+0000",
            "content": "A merge policy may be more optimal for ram segments vs disk\nsegments. Perhaps the best way to make this clean is to keep the\nram merge policy and real dir merge policies different? That way\nwe don't merge policy implementations don't need to worry about\nram and non-ram dir cases.\n\nPerhaps an IW.updatePendingRamMerges method should be added that\nhandles this separately? Does the ram dir ever need to worry\nabout things like maxNumSegmentsOptimize and optimize?\n\nRight, this is one of the strong reasons to do the\n\"internal\" approach vs \"external\" one.\n\nI think having the ram merge policy should cover the reasons I\nhad for having a separate ram writer. Although the IW.addWriter\nmethod I implemented would not have blocked, but I don't think\nit's necessary now if we have a separate ram merge policy. ",
            "author": "Jason Rutherglen",
            "id": "comment-12704340"
        },
        {
            "date": "2009-04-30T13:17:43+0000",
            "content": "\nPerhaps the best way to make this clean is to keep the\nram merge policy and real dir merge policies different? That way\nwe don't merge policy implementations don't need to worry about\nram and non-ram dir cases.\n\nOK tentatively this feels like a good approach.  Would you re-use\nMergePolicy, or make a new RAMMergePolicy?\n\nWould we use the same MergeScheduler to then execute the selected\nmerges?\n\nHow would we handle the \"it's time to flush some RAM to disk\" case?\nWould RAMMergePolicy make that decision?\n\nPerhaps an IW.updatePendingRamMerges method should be added that handles this separately?\n\nYes?\n\nDoes the ram dir ever need to worry about things like maxNumSegmentsOptimize and optimize?\n\nNo?\n\n\nI think having the ram merge policy should cover the reasons I\nhad for having a separate ram writer. Although the IW.addWriter\nmethod I implemented would not have blocked, but I don't think\nit's necessary now if we have a separate ram merge policy.\n\nOK good. ",
            "author": "Michael McCandless",
            "id": "comment-12704628"
        },
        {
            "date": "2009-04-30T20:25:55+0000",
            "content": " Would you re-use MergePolicy, or make a new\nRAMMergePolicy? \n\nMergePolicy is used as is with a special IW method that handles\nmerging ram segments for the real directory (which has an issue\naround merging contiguous segments, can that be relaxed in this\ncase as I don't understand why this is?)\n\nThe patch is not committable, however I am posting it to show a\npath that seems to work. It includes test cases for merging in\nram and merging to the real directory.\n\n\n\tIW.getFlushDirectory is used by internal calls to obtain the\ndirectory to flush segments to. This is used in DocumentsWriter\nrelated calls.\n\n\n\n\n\tDocumentsWriter.directory is removed so that methods requiring\nthe directory call IW.getFlushDirectory instead.\n\n\n\n\n\tIW.setRAMDirectory sets the ram directory to be used.\n\n\n\n\n\tIW.setRAMMergePolicy sets the merge policy to be used for\nmerging segments on the ram dir.\n\n\n\n\n\tIn IW.updatePendingMerges totalRamUsed is the size of the ram\nsegments + the ram buffer used. If totalRamUsed exceeds the max\nram buffer size then IW. updatePendingRamMergesToRealDir is\ncalled.\n\n\n\n\n\tIW. updatePendingRamMergesToRealDir registers a merge of the\nram segments to the real directory (currently causes a\nnon-contiguous segments exception)\n\n\n\n\n\tMergePolicy.OneMerge has a directory attribute used when\nbuilding the merge.info in _mergeInit.\n\n\n\n\n\tTest case includes testMergeInRam, testMergeToDisk,\ntestMergeRamExceeded\n\n\n\nThere is one error that occurs regularly in testMergeRamExceeded\n\n MergePolicy selected non-contiguous segments to merge\n(_bo:cx83 _bm:cx4 _bn:cx2 _bl:cx1->_bj _bp:cx1->_bp _bq:cx1->_bp\n_c2:cx1->_c2 _c3:cx1->_c2 _c4:cx1->_c2 vs _5x:c120 _6a:c8\n_6t:c11 _bo:cx83** _bm:cx4** _bn:cx2** _bl:cx1->_bj**\n_bp:cx1->_bp** _bq:cx1->_bp** _c1:c10 _c2:cx1->_c2**\n_c3:cx1->_c2** _c4:cx1->_c2**), which IndexWriter (currently)\ncannot handle \n  ",
            "author": "Jason Rutherglen",
            "id": "comment-12704779"
        },
        {
            "date": "2009-04-30T21:59:03+0000",
            "content": "\n\tOk, fixed the ensureContiguousMerge exception by asking the\nmergePolicy (not ramMergePolicy) to evaluate the ram segment\ninfos as an optimize to directory. Now all the current tests\npass. \n\n\n\n\n\tThe patch is cleaned up a little, needs more, and further test\ncases.\n\n\n\n\n\tIndexWriter doesn't accept setRAMDirectory anymore, it needs to\nbe passed into the IndexWriter constructor. This because we\ncan't run the system and the ram dir is changed in the middle of\nan operation. \n\n ",
            "author": "Jason Rutherglen",
            "id": "comment-12704809"
        },
        {
            "date": "2009-04-30T23:19:16+0000",
            "content": "Fixed and cleaned up more.\n\nAll tests pass\n\nAdded entry in CHANGES.txt\n\nI'm going to integrate LUCENE-1618 and test that out as a part of the next patch. ",
            "author": "Jason Rutherglen",
            "id": "comment-12704842"
        },
        {
            "date": "2009-05-01T13:57:31+0000",
            "content": "Patch looks good!  Some comments:\n\n\n\tI don't think the caller should provide the RAMDir... and we\n    should have a getter to get it. I think this should be\n    under-the-hood.  This is simply a nice way for IW to use RAM as\n    buffer in the presence of frequent NRT readers being opened.\n\n\n\n\n\tIf NRT is never used, the behavior of IW should be unchanged\n    (which is not the case w/ this patch I think).  RAMDir should be\n    created the first time a flush is done due to NRT creation.\n\n\n\n\n\tStoredFieldsWriter & TermVectorsTermsWriter now writes to\n    IndexWriter.getFlushDirectory(), which is confusing because that\n    method returns the RAMDir if set?  Shouldn't this be the opposite?\n    (Ie it should flush to IndexWriter.getDirectory()?  Or we should\n    change getFlushDiretory to NOT return the ramdir?)\n\n\n\n\n\tWhy did you need to add synchronized to some of the SegmentInfo\n    files methods?  (What breaks if you undo that?).  The contract\n    here is IW protects access to SegmentInfo/s.\n\n\n\n\n\tThe MergePolicy needs some smarts when it's dealing w/ RAM.  EG it\n    should not do a merge of more than XXX% of total RAM usage (should\n    flush to the real directory instead).\n\n\n\n\n\tNothing is calling the new ramOverLimit?\n\n\n\n\n\tStill some noise (MockRAMDir, DocFieldProcessorPerThread, some\n    changes in LogMergePolicy)\n\n ",
            "author": "Michael McCandless",
            "id": "comment-12704995"
        },
        {
            "date": "2009-05-01T18:38:32+0000",
            "content": "\n\tIndexFileDeleter takes into account the ram directory (which\nwhen using NRT with the FSD caused files to not be found). \n\n\n\n\n\tFSD is included and writes fdx, fdt, tvx, tvf, tvd extension\nfiles to the primary directory (which is the same as\nIW.directory). LUCENE-1618 needs to be updated with these\nchanges (or we simply include it in this patch as the\nLUCENE-1618 patch is only a couple of files).\n\n\n\n\n\tRemoved DocumentsWriter.ramOverLimit\n\n\n\n\n\tI think we need to give the option of a ram mergescheduler\nbecause the user may want not want the ram merging and disk\nmerging to compete for threads. I'm thinking if of the use case\nwhere NRT is a priority then one may allocate more threads to\nthe ram CMS and less to the disk CMS. This also gives us the\noption of trying out more parameters when performing benchmarks\nof NRT.\n\n\n\n\n\tWe may want to default the ram mergepolicy to not use compound\nfiles as it's not useful when using a ram dir?\n\n\n\n\n\tBecause FSD uses IW.directory, FSD will list files that\noriginated from FSD and from IW.directory, we may want to keep\ntrack of which files are supposed to be in FSD (from the\nunderlying primary dir) and which are not?\n\n\n\nIf NRT is never used, the behavior of IW should be\nunchanged (which is not the case w/ this patch I think). RAMDir\nshould be created the first time a flush is done due to NRT\ncreation. \n\nIn the patch if ramdir is not passed in, the behavior of IW\nremains the same as it is today. You're saying we should have IW\ncreate the ramdir by default after getReader is called and\nremove the IW ramdir constructor? What if the user has an\nalternative ramdir implementation they want to use?\n\nStoredFieldsWriter & TermVectorsTermsWriter now writes to\nIndexWriter.getFlushDirectory(), which is confusing because that\nmethod returns the RAMDir if set? Shouldn't this be the\nopposite? (Ie it should flush to IndexWriter.getDirectory()? Or\nwe should change getFlushDiretory to NOT return the\nramdir?)\n\nThe attached patch uses FileSwitchDirectory, where these files\nare written to the primary directory (IW.directory). So\ngetFlushDirectory is ok?\n\nWhy did you need to add synchronized to some of the\nSegmentInfo files methods? (What breaks if you undo that?). The\ncontract here is IW protects access to SegmentInfo/s\n\nSegmentInfo.files was being cleared while sizeInBytes was called\nwhich resulted in an NPE. The alternative is sync IW in\nIW.size(SegmentInfos) which seems a bit extreme just to obtain\nthe size of a segment info?\n\nThe MergePolicy needs some smarts when it's dealing w/\nRAM. EG it should not do a merge of more than XXX% of total RAM\nusage (should flush to the real directory instead)\n\nIsn't this handled well enough in updatePendingMerges or is\nthere more that needs to be done? ",
            "author": "Jason Rutherglen",
            "id": "comment-12705086"
        },
        {
            "date": "2009-05-02T10:51:11+0000",
            "content": "\n\nIndexFileDeleter takes into account the ram directory (which\nwhen using NRT with the FSD caused files to not be found).\n\nI don't like how \"deep\" the dichotomy of \"RAMDir vs FSDir\" is being\npushed.  Why can't we push FSD down to all these places (IFD,\nSegmentInfo/s, etc.)?\n\n\nFSD is included and writes fdx, fdt, tvx, tvf, tvd extension\nfiles to the primary directory (which is the same as\nIW.directory). LUCENE-1618 needs to be updated with these\nchanges (or we simply include it in this patch as the\nLUCENE-1618 patch is only a couple of files).\n\nWhy did this require changes to FSD?\n\n\nI think we need to give the option of a ram mergescheduler\nbecause the user may want not want the ram merging and disk\nmerging to compete for threads. I'm thinking if of the use case\nwhere NRT is a priority then one may allocate more threads to\nthe ram CMS and less to the disk CMS. This also gives us the\noption of trying out more parameters when performing benchmarks\nof NRT.\n\nI think we're unlikely to gain from more than 1 BG thread for RAM\nmerging?  But I agree it'd be horrible if CMS blocked RAM merging\nbecause its allotted threads were tied up merging disk segments.\nCould we simply make the single CMS instance smart enoguh to realize\nthat a single RAM merge is allowed to proceed regardless of the thread\nlimit?\n\n\nWe may want to default the ram mergepolicy to not use compound\nfiles as it's not useful when using a ram dir?\n\nI think actually hardwire it, not just default.  Building CFS in RAM\nmakes no sense.  Worse, if we allow one to choose to do it we then\nhave to fix FSD to understand CFX must go to the dir too, and, we'd\nhave to fix IW to not merge in the doc store files when building a\nprivate CFS.  Net/net I think we should not allow CFS for the RAM\nsegments.\n\nOn merging to disk it can then respect the user's CFS setting.\n\n\nBecause FSD uses IW.directory, FSD will list files that\noriginated from FSD and from IW.directory, we may want to keep\ntrack of which files are supposed to be in FSD (from the\nunderlying primary dir) and which are not?\n\nI don't understand what's wrong here?\n\n\n> If NRT is never used, the behavior of IW should be\n> unchanged (which is not the case w/ this patch I think). RAMDir\n> should be created the first time a flush is done due to NRT\n> creation.\n\nIn the patch if ramdir is not passed in, the behavior of IW\nremains the same as it is today. You're saying we should have IW\ncreate the ramdir by default after getReader is called and\nremove the IW ramdir constructor?\n\nRight.  This should be \"under the hood\".\n\n\nWhat if the user has an alternative ramdir implementation they want to\nuse?\n\nI think I'd rather not open up that option just yet.  This really is a\nprivate optimization to how IW uses RAM.  We may want to further\nchange/improve how RAM is used.\n\nWay back when, IW used a RAMDir internally for buffering; then, with\nLUCENE-843 we switched to whole different format (DW's ram\nbuffering).  Now we are adding back RAMDir for NRT; maybe we'll switch\nits format at some point... or change NRT to directly search DW's\nRAM... etc.  How IW uses RAM is very much an internal detail so I'd\nrather not expose it publically.\n\n[BTW: once we have this machinery online, it's conceivable that we'd\nwant to flush to RAMDir even in the non-NRT case.  EG, say DW's RAM\nbuffer is full and it's time to flush.  If it flushes to RAM,\ntypically the RAMDir is far more compact than DW's RAM buffer and it\nthen still has some more space to work with, before having to flush to\ndisk.  If we explore this it should be in a new issue (later)...]\n\n\n> StoredFieldsWriter & TermVectorsTermsWriter now writes to\n> IndexWriter.getFlushDirectory(), which is confusing because that\n> method returns the RAMDir if set? Shouldn't this be the\n> opposite? (Ie it should flush to IndexWriter.getDirectory()? Or\n> we should change getFlushDiretory to NOT return the\n> ramdir?)\n\nThe attached patch uses FileSwitchDirectory, where these files\nare written to the primary directory (IW.directory). So\ngetFlushDirectory is ok?\n\nOK, though I'd like to simply always use FSD, even if primary &\nsecondary are the same dir.  All these if's checking for both dirs,\npassing both dirs deep into Lucene's APIs, etc., are spooky.\n\n\n> Why did you need to add synchronized to some of the\n> SegmentInfo files methods? (What breaks if you undo that?). The\n> contract here is IW protects access to SegmentInfo/s\n\nSegmentInfo.files was being cleared while sizeInBytes was called\nwhich resulted in an NPE. The alternative is sync IW in\nIW.size(SegmentInfos) which seems a bit extreme just to obtain\nthe size of a segment info?\n\nBut... why did we have one thread asking for size while another was\ntweaking the SegmentInfo?  What leads to that?  We need to better\nunderstand the root cause here.\n\nThe size consumed by the RAM segments should be carefully computed\n(called only in sychchronized(iw) context) and then shared. This value\nchanges relatively rarely (on flushing a new segment to ram; on\napplying deletes that include RAM segments; on doing a ram->ram\nmerge), but is read frequently (per doc added, to decide whether it's\ntime to flush).  I think the value should be pushed to DW whenever it\nchanges, via synchronized method in DW; and then the existing\nsynchronized logic in DW that decides if it's time to \"flush after\"\nshould consult that value.  No further synchronizing should be\nnecessary.\n\nAlso, this ram size should be used not only for deciding when it's\ntime to merge to a disk segment, but also when it's time for DW to\nflush a new segment (which I think your current patch is missing?).\n\n\n> The MergePolicy needs some smarts when it's dealing w/ RAM. EG it\n> should not do a merge of more than XXX% of total RAM usage (should\n> flush to the real directory instead).\n\nIsn't this handled well enough in updatePendingMerges or is\nthere more that needs to be done?\n\nThere is more that needs to be done, because MergePolicy must\nconditionalize its logic based on RAM vs FS.  Ie, if our RAM buffer is\n32 MB, and there are say 31 MB of RAM segments that suddenly need\nmerging (becuase we just flushed the 10th RAM segment), we should not\ndo a RAM -> RAM merge at that point (because 31./32. = very high pctg\nof our net RAM buffer).  Instead we should force RAM -> disk at that\npoint, even though technically RAM is not yet full.\n\nOoh: maybe a better approach is to disallow the merge if the expected\npeak RAM usage will exceed our buffer.  I like this better.  So if\nbudget is 32 MB, and net RAM used (segments + DW) is say 22, we have a\n10 MB \"budget\", so we are allowed to select merges that total to < 10\nMB. ",
            "author": "Michael McCandless",
            "id": "comment-12705255"
        },
        {
            "date": "2009-05-04T18:31:12+0000",
            "content": "I don't like how \"deep\" the dichotomy of \"RAMDir vs\nFSDir\" \n\nAgreed, it's a bit awkward but I don't see another way to do\nthis. The good thing is if IW has written some .fdt files to the\nmain dir (via FSD), IW crashes, then IW is created again, IFD\nautomatically deletes the extraneous .fdt (and other extension)\nfiles.\n\nWhy can't we push FSD down to all these places (IFD,\nSegmentInfo/s, etc.)?\n\nCould we simply make the single CMS instance smart enough\nto realize that a single RAM merge is allowed to proceed\nregardless of the thread limit?\n\nHmm... I think for benchmarking it would be good to allow\noptions as we simply don't know. In the latest patch a ram\nmergescheduler can be set to the IndexWriter.\n\nhave to fix FSD to understand CFX must go to the dir\ntoo\n\nI think this is fixed in the patch, where compound files are not\ncreated in RAM. \n\nYou're saying we should have IW create the ramdir by default\nafter getReader is called and remove the IW ramdir constructor?\nRight. This should be \"under the hood\".\n\nOk, this will require some reworking of the patch. \n\nOK, though I'd like to simply always use FSD, even if\nprimary & secondary are the same dir. \n\nHow will always using FSD work? Doesn't it assume writing to two\ndifferent directories?\n\nthis ram size should be used not only for deciding when\nit's time to merge to a disk segment, but also when it's time\nfor DW to flush a new segment\n\nIn the new patch this is fixed.\n\nSo if budget is 32 MB, and net RAM used (segments + DW)\nis say 22, we have a 10 MB \"budget\", so we are allowed to select\nmerges that total to < 10 MB.\n\nOne issue is the ram buffer flush doubles the ram used (because\nthe segment is flushed as is to the RAM dir). You're saying\nroughly estimate the ram size used on the result of a merge and\nhave the merge policy take this into account? This makes sense,\notherwise we will consistently (if temporarily) exceed the ram\nbuffer size. The algorithm is fairly simple? Find segments whose\ntotal sizes are lower than whatever we have left of the max ram\nbuffer size? I have new code, but will rework it a bit to\ninclude this discussion.  ",
            "author": "Jason Rutherglen",
            "id": "comment-12705675"
        },
        {
            "date": "2009-05-04T22:14:49+0000",
            "content": "\n> OK, though I'd like to simply always use FSD, even if\n> primary & secondary are the same dir.\n\nHow will always using FSD work? Doesn't it assume writing to two\ndifferent directories?\n\nI think on creating IW the user should state (via new expert ctor)\nthat they intend to use it for NRT (say, a new boolean\n\"enableNearRealTime\").\n\nThen we could pass IFD either an FSD (when in NRT mode) or the normal\ndirectory when not in NRT mode.  IFD would not longer have to\nduplicate FSD's logic (summing the two dir's listAlls, the\ngetDirectoryForFile).\n\nSegmentInfos.hasExternalSegments, and MultiSegmentReader ctor, should\nbe \"smart\" when they're passed an FSD (probably we should add\nDirectory.contains(Directory) method, which by default returns true if\nthis.equals(dir), but FSD would override to return true if the\nincoming dir .equals primary & secondary).\n\nLikewise all the switching in DW to handle two dirs should be rolled\nback (eg you adde DW.fileLength(name, dir1, dir2) that's dup code with\nFSD).\n\n\nOne issue is the ram buffer flush doubles the ram used (because\nthe segment is flushed as is to the RAM dir).\n\nI think we must keep transient RAM usage below the specified limit, so\nthat limits our flushing freedom.  Ie, in the NRT case, once DW's RAM\nbuffer exceeds half of the allowed remaining RAM budget (ie, the limit\nminus total RAM segments) then we trigger a flush to RAM and then to\nthe \"real\" dir.\n\nOr... we could flush the new segment directly to the real dir as one\nsegment, and merge all prior RAM segments as a separate new segment in\nthe main dir, if the free RAM is large enough.\n\n\n> this ram size should be used not only for deciding when\n> it's time to merge to a disk segment, but also when it's time\n> for DW to flush a new segment\n\nIn the new patch this is fixed.\n\nI don't see where this is taken into account?  Did you mean to attach\na new patch? ",
            "author": "Michael McCandless",
            "id": "comment-12705788"
        },
        {
            "date": "2009-05-05T00:32:02+0000",
            "content": "\n\tIn DocumentsWriter.balanceRAM if NRT is on the total ram\nconsumed is \"(numBytesUsed * 2) + writer.getRamDirSize()\".\nnumBytesUsed is the current consumption of the ram buffer.\nBasically what we flush to ram, we'll consume that much of the\nbuffer. This is now taken into account in the bufferIsFull\ncalculation.\n\n\n\n\n\tDouble dir usage should be factored out.\n\n\n\n\n\tTestIndexWriterRamDir.testFSDirectory fails. It tries to\nsimulate a crashing IW. When the IW is created again it should\ndelete the old files, for some reason it's not with FSDirectory\n(open file handles on Windows perhaps)\n\n\n\n we could flush the new segment directly to the real dir\nas one segment, and merge all prior RAM segments as a separate\nnew segment in the main dir, if the free RAM is large enough.\n\nYeah it's unclear what the best policy is here. Do we want to\nhave some sort of custom merge policy method/class to take care\nof this so the user can customize it? ",
            "author": "Jason Rutherglen",
            "id": "comment-12705846"
        },
        {
            "date": "2009-05-05T00:52:03+0000",
            "content": "Did we decide to simply add a boolean param in the ctor to turn\non NRT instead of relying on getReader. Using getReader could\ncause problems with switching directories midstream.  ",
            "author": "Jason Rutherglen",
            "id": "comment-12705851"
        },
        {
            "date": "2009-05-05T08:26:48+0000",
            "content": "\nDid we decide to simply add a boolean param in the ctor to turn\non NRT instead of relying on getReader. Using getReader could\ncause problems with switching directories midstream.\nYes, let's switch to that. ",
            "author": "Michael McCandless",
            "id": "comment-12705952"
        },
        {
            "date": "2009-05-05T09:00:21+0000",
            "content": "\n\n\tWe shouldn't add FSD.setPrimaryExtensions?\n\n\n\n\n\tThe dual directories is continuing to push deeper (when I'm\n    wanting to do the reverse).  EG, MergeScheduler.getDestinationDirs\n    should not be needed?\n\n\n\n\n\tWe should no longer need IndexWriter.getFlushDirectory?  IE, IW\n    once again has a single \"Directory\" as seen by IFD,\n    DocFieldProcessorPerThread, etc.  In the NRT case, this is an FSD;\n    in the non-NRT case it's the Dir that was passed in (unless, in a\n    future issue, we explore using FSD, too, for better performance).\n\n\n\n\n\tWe can't up and change CMS.handleMergeException (breaks\n    back-compat); can you deprecate old & add a new one that calls old\n    one?  Let's have the new one take a Throwable and\n    MergePolicy.OneMerge?\n\n\n\n\n\tInstead of overriding \"equals\" (FSD.equals) can you change to\n    \"Directory.contains\"?\n\n\n\n\n\tIW's RAMDir usage still isn't factored in properly.  EG\n    DW.doBalancRAM is not taking it into account.\n\n\n\n\n\tFurthermore, we can't call writer.getRamDirSize() from\n    DW.balanceRAM \u2013 that's far too costly.  Instead, whenever RAMDir\n    changes (deletes are applied, or a new RAM segment is created), we\n    must push down to DW that usage with a new synchronized method.\n    (I described this above).  We should remove\n    IW.getRamDirSize()... ie, this size should always be \"pushed on\n    change\", not \"polled on read\".  We change it rarely and read it\n    incredibly often.\n\n\n\n\n\tWe don't need IW.getRamLogMergePolicy()?  Instead, let's ignore\n    \"MergePolicy.useCompoundFile()\" when we are writing the new\n    segment to RAMDir?  Likewise we should not cast RAMMergePolicy to\n    LogMergePolicy in setRAMMergePolicy, nor turn off its CFS there.\n\n\n\n\n\tI still don't think we need a separate RAMMergeScheduler; I think\n    CMS should simply always run such merges (ie not block on max\n    thread count).  IW.getNextMerge can then revert to its former\n    self.\n\n\n\n\n\tMergePolicy.OneMerge.segString no longer needs to take a\n    Directory (because it now stores a Directory).\n\n\n\n\n\tThe mergeRAMSegmentsToDisk shouldn't be fully synchronized, eg\n    when doWait is true it should release the lock while merges are\n    taking place.\n\n ",
            "author": "Michael McCandless",
            "id": "comment-12705963"
        },
        {
            "date": "2009-05-05T19:53:06+0000",
            "content": "RAMDir changes (deletes are applied, or a new RAM segment is\ncreated), we must push down to DW that usage with a new synchronized\nmethod.\n\nSounds like we create a subclass of RAMDirectory with this\nfunctionality?\n\nWe don't need IW.getRamLogMergePolicy()?\n\nBecause we don't want the user customizing this?\n\nWe should no longer need IndexWriter.getFlushDirectory? IE, IW\nonce again has a single \"Directory\" as seen by IFD,\nDocFieldProcessorPerThread, etc. In the NRT case, this is an FSD; in\nthe non-NRT case it's the Dir that was passed in (unless, in a future\nissue, we explore using FSD, too, for better performance).\n\nPass in FSD in the constructor of DocumentsWriter (and others) as\nbefore? \n\nI still don't think we need a separate RAMMergeScheduler; I\nthink CMS should simply always run such merges (ie not block on max\nthread count). IW.getNextMerge can then revert to its former\nself.\n\nWhere does the thread come from for this if we're using max threads?\nIf we allocate one, we're over limit and keeping it around. We'd need\na more advanced threadpool that elastically grows the thread pool and\nkills threads that are unused over time. With Java 1.5 we can use\nThreadPoolExecutor. Is a dedicated thread pool something we want to\ngo to? Even then we can potentially still max out a given thread pool\nwith requests to merge one directory or the other. We'd probably\nstill need two separate thread pools. \n\nMergePolicy.OneMerge.segString no longer needs to take a\nDirectory (because it now stores a Directory).\n\nYeah, I noticed this, I'll change it. MergeSpecification.segString is\npublic and takes a directory that is not required. What to do?  ",
            "author": "Jason Rutherglen",
            "id": "comment-12706175"
        },
        {
            "date": "2009-05-05T21:37:29+0000",
            "content": "The dual directories is continuing to push deeper (when I'm\nwanting to do the reverse). EG, MergeScheduler.getDestinationDirs\nshould not be needed?\n\nIf we remove getFlushDirectory, are you saying getDirectory should\nreturn the FSD if RAM NRT is turned on? This seems counter intuitive\nin that we still need a clear separation of the two directories? The\nuser would expect the directory they passed into the ctor to be\nreturned? \n\ngetDestinationDirs is used by the ram merge scheduler, which if we\nuse a single CMS would go away. \n\nI'm looking at how to get RAMLogMergePolicy to take into account the\nsize of the ram segments it's merging such that they do not total\nbeyond the remaining available ram. Looks like we could keep a\nrunning byte total while it's building the merges and stop once we've\nreached the limit, though I'm not sure how exact this is (will the\nmerges be balanced using this system?). It seems like a variation on\nthe LogByteSizeMergePolicy however it's unclear whether\nLogDocMergePolicy or LogByteSizeMergePolicy ram merges will perform\nbetter (does it matter since it's all in ram and we're capping the\ntotal?) ",
            "author": "Jason Rutherglen",
            "id": "comment-12706207"
        },
        {
            "date": "2009-05-06T05:21:29+0000",
            "content": "I'm not sure we have the right model yet for deciding when to\nflush the ram buffer and/or ram segments. Perhaps we can simply\ndivide the ram buffer size in half, allocating one part to the\nram buffer, the other to the ram segments. When one exceeds it's\n(rambuffersize/2) allotment, it's flushed to disk. This way if\nthe ram buffer size is 32MB, we will always safely flush 16MB to\ndisk. The more ram allotted, greater the size of what's flushed\nto disk. We may eventually want to offer an expert method to set\nthe ram buffer size and ram dir max size individually. \n\nPut another way I think we need a balanced upper limit for the\nram buffer and the NRT ram dir, which seems (to me) to be hard\nto achieve by allowing too much growth at the expensive of the\nother.\n\nI'd like to stay away from flushing the ram buffer to disk when\nit's below say 20% of the ram buffer size as it seems\ninefficient to do this (because we'll have to do an expensive\ndisk merge on it later). On the other hand if the user is not\ncalling get reader very often and we're auto flushing at 1/2 the\nram buffer size, we're short changing ourselves and only\nflushing a segment half the size of what it could be. I suppose\nwe could stick with the 1/2 model, only turning it on once ram\nsegments are being merged in ram?\n\nIf when merging ram segments (using the specialized\nRAMMergePolicy) we only merge in ram the ones that fit, what do\nwe do with the ram segments remaining that need to be flushed to\ndisk? What if they are only make up 20% of the total size of the\nram segments? If we merge the 20% to disk it seems inefficient? ",
            "author": "Jason Rutherglen",
            "id": "comment-12706305"
        },
        {
            "date": "2009-05-06T11:16:22+0000",
            "content": "\n\n> RAMDir changes (deletes are applied, or a new RAM segment is\n> created), we must push down to DW that usage with a new synchronized\n> method.\n\nSounds like we create a subclass of RAMDirectory with this\nfunctionality?\n\nI don't think that's needed.  I think whenever IW makes a change to\nthe RAMDir, which is easily tracked, it pushes to DW the new RAMDir\nsize.\n\n\n> We don't need IW.getRamLogMergePolicy()?\n\nBecause we don't want the user customizing this?\nThat, and because it's only used to determine CFS or not, which we've\nturned off for RAMDir.\n\n\n> We should no longer need IndexWriter.getFlushDirectory? IE, IW\n> once again has a single \"Directory\" as seen by IFD,\n> DocFieldProcessorPerThread, etc. In the NRT case, this is an FSD; in\n> the non-NRT case it's the Dir that was passed in (unless, in a future\n> issue, we explore using FSD, too, for better performance).\n\nPass in FSD in the constructor of DocumentsWriter (and others) as\nbefore?\n\nRight.  All these places could care less if they are dealing w/ FSD or\na \"real\" dir.  They should simply use the Directory API as they\npreviously did.\n\n\n> I still don't think we need a separate RAMMergeScheduler; I\n> think CMS should simply always run such merges (ie not block on max\n> thread count). IW.getNextMerge can then revert to its former\n> self.\n\nWhere does the thread come from for this if we're using max threads?\nIf we allocate one, we're over limit and keeping it around. We'd need\na more advanced threadpool that elastically grows the thread pool and\nkills threads that are unused over time. With Java 1.5 we can use\nThreadPoolExecutor. Is a dedicated thread pool something we want to\ngo to? Even then we can potentially still max out a given thread pool\nwith requests to merge one directory or the other. We'd probably\nstill need two separate thread pools.\n\nThe thread is simply launched w/o checking maxThreadCount, if the\nmerge is in RAM.\n\nRight, with JDK 1.5 we can make CMS better about pooling threads.\nRight now it does no long-term pooling (unless another merge happens\nto be needed when a thread finishes its last merge).\n\n\n> MergePolicy.OneMerge.segString no longer needs to take a\n> Directory (because it now stores a Directory).\n\nYeah, I noticed this, I'll change it. MergeSpecification.segString is\npublic and takes a directory that is not required. What to do?\nDo the usual back-compat dance \u2013 deprecate it and add the new one.\n\n\n> The dual directories is continuing to push deeper (when I'm\n> wanting to do the reverse). EG, MergeScheduler.getDestinationDirs\n> should not be needed?\n\nIf we remove getFlushDirectory, are you saying getDirectory should\nreturn the FSD if RAM NRT is turned on? This seems counter intuitive\nin that we still need a clear separation of the two directories? The\nuser would expect the directory they passed into the ctor to be\nreturned?\n\nI agree, we should leave getDirectory() as is (returns whatever Dir\nwas passed in).\n\nWe can keep getFlushDirectory, but it should not have duality inside it\n\u2013 it should simply return the FSD (in the NRT case) or the normal\ndir.  I don't really like the name getFlushDirectory... but can't\nthink of a better one yet.\n\nThen, nothing outside of IW should ever know there are two directories\nat play.  They all simply deal with the one and only Directory that IW\nhands out.\n\nOn the \"when to flush to RAM\" question... I agree it's tricky.  This\nlogic belongs in the RAMMergePolicy.  That policy needs to be\nempowered to decide if a new flush goes to RAM or disk, to decide when\nto merge all RAM segments to a new disk segment, to be able to check\nif IW is in NRT mode, etc.  Probably the RAM merge policy also needs\ncontrol over how much of the RAM buffer it's going to give to DW,\ntoo. At first the policy should not change the non-NRT case (ie one\nalways flushes straight to disk).  We can play w/ that in a separate\nissue.  Need to think more about the logic... ",
            "author": "Michael McCandless",
            "id": "comment-12706377"
        },
        {
            "date": "2009-05-06T19:13:34+0000",
            "content": "I don't think that's needed. I think whenever IW makes a\nchange to the RAMDir, which is easily tracked, it pushes to DW\nthe new RAMDir size.\n\nBecause we know the IW.ramdir is a RAMDirectory implementation,\nwe can use sizeInBytes? It's synchronized, maybe we want a\ndifferent method that's not? It seems like keeping track of all\nfiles writes outside ramdir is going to be difficult? For\nexample when we do deletes via SegmentReader how would we keep\ntrack of that?\n\nThat, and because it's only used to determine CFS or not,\nwhich we've turned off for RAMDir.\n\nSo we let the user set the RAMMergePolicy but not get it?\n\nThe thread is simply launched w/o checking\nmaxThreadCount, if the merge is in RAM.\n\nHmm... We can't just create threads and let them be garbage\ncollected as JVMs tend to throw OOMs with this. If we go down\nthis route of a single CMS, maybe we can borrow some code from\nan Apache project that's implemented a threadpool.\n ",
            "author": "Jason Rutherglen",
            "id": "comment-12706557"
        },
        {
            "date": "2009-05-06T21:53:11+0000",
            "content": "\n> I don't think that's needed. I think whenever IW makes a\n> change to the RAMDir, which is easily tracked, it pushes to DW\n> the new RAMDir size.\n\nBecause we know the IW.ramdir is a RAMDirectory implementation,\nwe can use sizeInBytes? It's synchronized, maybe we want a\ndifferent method that's not? It seems like keeping track of all\nfiles writes outside ramdir is going to be difficult? For\nexample when we do deletes via SegmentReader how would we keep\ntrack of that?\n\nWe should definitely just use the sizeInBytes() method.\n\nI'm saying that IW knows when it writes new files to the RAMDir\n(flushing deletes, flushing new segment) and it's only at those times\nthat it should call sizeInBytes() and push that value down to DW.\n\n\n> That, and because it's only used to determine CFS or not,\n> which we've turned off for RAMDir.\n\nSo we let the user set the RAMMergePolicy but not get it?\n\nOh, we should add a getter (getRAMMergePolicy, not getLogMergePolicy)\nfor it, but it should return MergePolicy not LogMergePolicy.\n\n\n> The thread is simply launched w/o checking\n> maxThreadCount, if the merge is in RAM.\n\nHmm... We can't just create threads and let them be garbage\ncollected as JVMs tend to throw OOMs with this. If we go down\nthis route of a single CMS, maybe we can borrow some code from\nan Apache project that's implemented a threadpool.\n\nThis is how CMS has always been.  It launches threads relatively\nrarely \u2013 this shouldn't lead to OOMs.  One can always subclass CMS if\nthis is somehow a problem.  Or we could modify CMS to pool its threads\n(as a new issue)? ",
            "author": "Michael McCandless",
            "id": "comment-12706611"
        },
        {
            "date": "2009-05-06T23:38:09+0000",
            "content": "In the patch the merge policies are split up which requires some\nof the RAM NRT logic to be in updatePendingMerges. \n\nOne solution is to have a merge policy that manages merging to\nram and to disk, kind of an overarching merge policy for the\nprimary MP and the RAM MP. This would push the logic of ram\nmerging and primary dir merging to the meta merge policy which\nwould clean up IW from managing ram segs vs. prim segs.\n\nDoes IW.optimize and IW.expungeDeletes operate on the ramdir as\nwell (the expungeDeletes javadoc implies calling\nIR.numDeletedDocs will return zero when there are no deletes).  ",
            "author": "Jason Rutherglen",
            "id": "comment-12706662"
        },
        {
            "date": "2009-05-08T05:36:57+0000",
            "content": "Something in the DocumentsWriter API we may need to change is to\nallow passing a directory through the IndexingChain. In the RAM\nNRT case, which directory we write to can change depending on if\na ram buffer has exceeded it's maximum available size. If it is\nunder half the available ram it will to go the ram dir, if not\nthe new segment will be written to disk. For this reason we\ncan't simply pass a directory into the constructor of\nDocumentsWriter, nor can we rely on calling\nIW.getFlushDirectory. We should be able to rely on the directory\nin SegmentWriteState? ",
            "author": "Jason Rutherglen",
            "id": "comment-12707243"
        },
        {
            "date": "2009-05-08T09:06:09+0000",
            "content": "\nDoes IW.optimize and IW.expungeDeletes operate on the ramdir as\nwell (the expungeDeletes javadoc implies calling\nIR.numDeletedDocs will return zero when there are no deletes).\nI think IW.optimize should mean all RAM segments are merged into the single on-disk segment?\n\nAnd IW.expungeDeletes should also apply to RAM segments, ie if RAM segments have pending deletes, they are merged away (possibly entirely in RAM, ie the RAM merge policy could simply merge to a new RAM segment)?\n\n\nIn the patch the merge policies are split up which requires some\nof the RAM NRT logic to be in updatePendingMerges.\nOne solution is to have a merge policy that manages merging to\nram and to disk,\n\nIt looks like it's the \"is it time to flush to disk\" logic, right?  Why can't we make that the purview of the RAM MergePolicy?  We may need to extend MergePolicy API to tell it how much RAM is free in the budget.\n\nWe should be able to rely on the directory in SegmentWriteState?\n\nI think we should fix the indexing chain to always use SegmentWriteState's Directory and not pass Directory to the ctors?  Does something go wrong if we take that approach? ",
            "author": "Michael McCandless",
            "id": "comment-12707283"
        },
        {
            "date": "2009-05-11T16:21:26+0000",
            "content": "IW.optimize should mean all RAM segments are merged into\nthe single on-disk segment\n\nYes.\n\nIW.expungeDeletes should also apply to RAM segments, ie\nif RAM segments have pending deletes, they are merged away\n(possibly entirely in RAM, ie the RAM merge policy could simply\nmerge to a new RAM segment)?\n\nYes.\n\nwe should fix the indexing chain to always use\nSegmentWriteState's Directory and not pass Directory to the\nctors\n\nYep.\n\nThe next patch will have these features. ",
            "author": "Jason Rutherglen",
            "id": "comment-12708100"
        },
        {
            "date": "2009-05-12T03:20:48+0000",
            "content": "\n\tA single merge scheduler is used. We will need to open a new\nissue for a version of ConcurrentMergeScheduler that allocates\nthreads perhaps based on the merge.directory? We'd also probably\nwant to add thread pooling.\n\n\n\n\n\tThere's a package protected IW ctor that accepts the ram dir.\nThis is used in the test case for insuring we aren't creating\n.cfs files in the ram dir.\n\n\n\n\n\tIW.optimize merges all segments (ram included) to the primary\ndir\n\n\n\n\n\tIW.expungeDeletes merges segments with deletes, in ram ones\nstay in ram (unless they won't fit), and primary dir ones are\nhandled as usual\n\n\n\n\n\tAdded testOptimize, testExpungeDeletes, and some other test\ncases\n\n\n\n\n\tNeeds a test case to make sure we're merging to the primary\ndir when the ram dir is full or a flush won't fit in the ram dir\n\n\n\n\n\tThere's a mergeRamSegmentsToDir and resolveRamSegments. Two\ndifferent methods because mergeRamSegmentsToDir operates by\nsimply scheduling merges, resolveRamSegments operates in the\nforeground like resolveExternalSegments. I'm not sure if we can\ncombine the two. resolveRamSegments seems to have a thread\nnotification problem and so hangs at times. I'll look into this\nfurther unless it's obvious what the problem is.\n\n\n\n\n\tWhen RAM NRT is on (via the IndexWriter constructor), setting\nthe ram buffer size allocates half of the given number to the\nDocumentsWriter buffer and half to the ram dir. It may be best\nto dynamically change these numbers based on usage etc.\n\n\n\n\n\tAdded NRTMergePolicy which is used only when RAM NRT is on. It\nutilizes the regular merge policy and the ram merge policy.\n\n\n\n\n\tThe ram dir size is pushed to DocumentsWriter\n\n\n\n\n\tRAMMergePolicy extends LogDocMergePolicy and defaults the\nuseCompoundFile and useCompoundDocStore to false\n\n\n\n\n\tSorry for the whitespace stuff, I'll clean it up later, I\nwanted to post the latest to get feedback\n\n ",
            "author": "Jason Rutherglen",
            "id": "comment-12708309"
        },
        {
            "date": "2009-05-12T19:24:03+0000",
            "content": "I think the easiest way to handle the ram buf size vs. the ram\ndir size is the allow each to grow on request. I have some code\nI need to test that implements it. This way we're growing based\non demand and availability. The only thing we may want to add is\na way to grow and perhaps automatically flush based on the\ngrowth requested and perhaps prioritizing requests? ",
            "author": "Jason Rutherglen",
            "id": "comment-12708578"
        },
        {
            "date": "2009-05-19T21:59:02+0000",
            "content": "\n\tAll tests pass, added more tests\n\n\n\n\n\tAdded DocumentsWriter.growRamBufferBy/growRamDirMaxBy methods\nthat allow dynamically requesting more ram. We start off at\n50/50, ramdir/rambuffer. Then whenever one needs more, grow* is\ncalled.  \n\n\n\n\n\tWe need a RAMPolicy class that allows customizing how ram is\nallocated. Currently the ramdir and the rambuffer compete for\nspace, the user will presumably want to customize this.\n\n\n\n\n\tI'm not sure the flushing always occurs when it should, and\nnot sure yet how to test to insure it's flushing when it should\n(other than watching a log). What happened to the adding logging\nto Lucene patch? \n\n ",
            "author": "Jason Rutherglen",
            "id": "comment-12710899"
        },
        {
            "date": "2009-05-22T13:47:34+0000",
            "content": "I think generally we are close.  I have lots of little comments from\nlooking through the patch:\n\n\n\tCan you update the CHANGES entry to something like \"IndexWriter\n    now uses RAM more efficiently when in near real-time mode\"?  (Ie\n    we don't pass RAMDir to IW).\n\n\n\n\n\tDW.push/getRAMDirSize, RAMTotalMax, RAMBufferAvailable, etc. need\n    to be synchronized?\n\n\n\n\n\tSince IW.flushDocStores always goes to the main directory, why\n    does it now take a Directory arg?\n\n\n\n\n\tI don't think doAfterFlush should be responsible for calling\n    pushRamDirSize(); that's more of a hook for external subclasses.\n\n\n\n\n\tYes, IW.ramSizeInBytes() should include the ramDir's bytes\n\n\n\n\n\tThere are still places where Directory.contains should be used,\n    instead of pulling both dirs and checkign each.  EG, the assert in\n    DW.applyDeletes, and this assert in IW:\n\nif (ramNrt && merge.directory == switchDirectory) {\n  assert !merge.useCompoundFile;\n}\n\n\n    I'd like to eliminate IW.getInternalDirectory, if possible: to\n    anyone interacting with IW, there is only one Directory, and the\n    switching is entirely \"under the hood\".\n\n\n\n\n\tI realized there is in fact a benefit to using CFS in RAM: much\n    better RAM efficiency for tiny segments (because RAMDir's buffer\n    size is 1 KB).  Though such segments would presumably be merged\n    away with time, so it may not be a big deal...\n\n\n\n\n\tIs IW.mergeRAMSegmentToDir only for testing?\n\n\n\n\n\tCan you name things theRAMSetting instead of theRamSetting?  (Ie,\n    RAM is all caps).\n\n\n\n\n\tFor IW.resolveRAMSegments, maybe we should make a single merge\n    that merges everything down?  Why even bother interacting with a\n    merge policy, here?\n\n\n\n\n\tCan you rename flush()'s new arg \"flushToRAM\" to\n    \"allowFlushToRAM\"?  Ie, even when this is true, that method may\n    decide RAM is full and in fact flush to the real dir.\n\n\n\n\n\tCan you rename IW.ramNRT to IW.flushToRAM?  (Since it's in fact\n    orthogonal to NRT).\n\n\n\n\n\tIt's sneaky to set docWriter.flushToDir before calling\n    docWriter.flush; can't we make that an arg to docWriter.flush?\n    (And docWriter would never store it).\n\n\n\n\n\tWhy did you need to add DW.fileLength?\n\n\n\n\n\tIW.SWITCH_FILE_EXTS should be private static final (not public)?\n\n\n\n\n\tWe lost private on a number of attrs in IW \u2013 can you restore?\n    (You should insert nocommit comments when you do that, to reduce\n    risk that such changes slip in).\n\n\n\n\n\tLikewise for SegmentReader.coreRef.\n\n\n\n\n\tWhy did you need to make RAMDir.sizeInBytes volatile?  Isn't it\n    always updated/accessed from sync(RAMDir) context?\n\n\n\n\n\tWhy do we need a new class RAMMergePolicy?  (There's no API\n    difference over MergePolicy).  Can't we simply by default\n    instantiate LogByteSizeMergePolicy, and set CFS/CFX to false?\n\n\n\n\n\tIW.fileSwitchDirectory should be private?\n\n\n\n\n\tHave you done any perf tests with flushToRAM = true?  EG should we\n    enable it by default?  I think if we have a good policy for\n    managing RAM it could very well be higher performance.  But, we\n    should explore this under a different issue, so leave the default\n    at \"no ram dir\".\n\n\n\nOn the \"how to share RAM\" between RAMDir & DW's RAM buffer... instead\nof pre-dividing and growing over time, I think we can simplify it by\nlogically sharing a single \"pool\".\n\nThe RAMDir only alters its ram usage when 1) we flush a new segment to\nit, 2) a merge completes (either writing to the real dir or to the ram\ndir), or 3) deletes are applied to segments in RAM.  When such a\nchange happens we notify DW.  DW takes then adds that base into its\nram consumption to decide when it's time to flush.\n\nFor starters, and we can optimize this later, I don't think DW should\nchoose on its own to flush itself to the RAMDir?  That should only\nhappen when getReader is called, and there's still plenty of RAM\nfree.\n\nSo what happens is... each time getReader() is called, we make a new\nsmallish RAM segment.  Over time, these RAM segments need merging so\nwe merge them.  (If such a merge is fairly large, probably instead of\nwriting to ram it should write the new segment to the real dir, since\nintermediate RAM usage will be too high).\n\nAt some point, DW detects that the RAMDir size plus its own buffer is\nat the limit.  If DW's buffer is relatively small, it should probably\nsimply flush to the RAMDir then dump entire RAMDir to the real dir as\na single merge.  If DW's buffer is big, as would happen if you opened\nan NRT reader but never actually called getReader(), it should flush\nstraight to the real dir.\n\nOne challenge we face is ensuring that while we are flushing all ram\nsegments to disk, we don't block the getReader() turnaround.  IE we\ncan't make getReader() do that flush synchronously.  So that needs to\nbe a BG merge, but we must somehow temporarily disregard the size of\nthose segments while the merge is running.  Or, perhaps we \"merge RAM\nsegments to disk\" a bit early, eg once RAM consumed is > 90% of the\ntotal RAM buffer, or something. ",
            "author": "Michael McCandless",
            "id": "comment-12712082"
        },
        {
            "date": "2009-05-26T16:42:29+0000",
            "content": "I started on the pooled ram model after the last patch because\nit is cleaner. Bytes are allocated up to the given limit set by\nIW.setRAMBufferSizeMB. As mentioned below, we may want to add a\nsetting for the max ram temporarily used.\n\nI'm reusing the DocumentsWriter.numBytesAlloc/numBytesUsed and\ncreated a RAMPolicy that manages ramDirBytesAlloc and\nramDirBytes. Each time a merge is scheduled, the\nsizeof(segments) is allocated by RAMPolicy and the segmentsAlloc\nis stored in OneMerge. Once the merge completes or fails, the\nramDirBytesAlloc is adjusted by the difference between the\nactual bytes used and OM.ramDirAlloc. This way we always have\nthe most accurate ramDir allocation in RamP, and we properly\nadjust the amount of ram consumed. This works well with our\nconcurrent merging model where we can't predict when a merge\nwill complete.\n\nOne challenge we face is ensuring that while we are\nflushing all ram segments to disk, we don't block the\ngetReader() turnaround. IE we can't make getReader() do that\nflush synchronously....perhaps we \"merge RAM segments to disk\" a\nbit early, eg once RAM consumed is > 90% of the total RAM\nbuffer\n\nYou're talking about the synchronization in IW.doFlushInternal\nwhich would block getReader while writing a segment to disk? Our\ndefault RAMPolicy should be one where we always flush the ram\nbuffer to the ramdir. Basically there must always be room in the\nram dir for the ram buffer. ramdir + (rambuf * 2) < maxSize. Or\ndo we assume that it's ok for ramUsed to temporarily exceed\nramMax by a given percent (110% which would be an option in\nRAMPolicy)? while ramBuf is being flushed to ramDir? \n\nWe may want to make some assumptions about usage of getReader\n(i.e. getReader is called fairly often such that the rambuffer\nis usually less than half of the ram used) when flushToRam=true\nso that we can get a version of this functionality out the door,\nthen iterate as we gather feedback from users?\n\nI'll include the comments in the next patch.  ",
            "author": "Jason Rutherglen",
            "id": "comment-12713097"
        },
        {
            "date": "2009-05-29T15:49:50+0000",
            "content": "I had forgotten about concurrency with the docstores (keeping an\nopen IndexInput and IndexOutput) when using an FSDirectory. I\nwrote a test (which fails) so getting this functionality to work\ncould require some reworking of FSDirectory internals?\n(Something on the order of auto updating IndexInput's buffers\nand file length as IndexOutput is flushed?)\n\nWe need simultaneous IndexInput and IndexOutput ops to work as\ndocstore is streamed to FSDir for multiple segments. After a\nsegment is flushed to the ramdir it can be read from, including\nthe docstore which is still actively being written to (for the\nnew segments)?  ",
            "author": "Jason Rutherglen",
            "id": "comment-12714491"
        },
        {
            "date": "2009-05-29T16:05:05+0000",
            "content": "I had forgotten about concurrency with the docstores\n\nThat's a big (and good) change; I think we should save that one for another issue, and leave this one focusing on flushing segments through a RAMDir? ",
            "author": "Michael McCandless",
            "id": "comment-12714494"
        },
        {
            "date": "2009-05-29T17:31:14+0000",
            "content": "I guess I'm confused about the doc stores. We keep one open on\ndisk for multiple segments being created in the via FSD, which\nmeans the IndexOutput isn't closed, however for each new\nSegmentReader that's opened, we're creating a new IndexInput\nonly after the segment is flushed (to FSD, docstore to disk). \n\nSo the concurrent docstores may work without too much changing\nof FSDir internals, as the portion of the docstore file that the\nSR needs to know about has been flushed to disk when SR is\nopened. The SR should then be able to open the docstore file\ncleanly regardless of the open IndexOutput adding more to the\nfile for the next rambuf segment? ",
            "author": "Jason Rutherglen",
            "id": "comment-12714522"
        },
        {
            "date": "2009-05-29T18:01:22+0000",
            "content": "\nThe SR should then be able to open the docstore file\ncleanly regardless of the open IndexOutput adding more to the\nfile for the next rambuf segment?\n\nThat's the crucial question: can we open a new IndexInput, while an IndexOutput is still writing to the file?  I vaguely remember being surprised that this worked fine on Windows, but I'm not sure.\n\nIf that's fine across all OS's, then, yes we could avoid closing the docStores when flushing a new segment.\n\nIf it's not fine, then we'd need a way to make an IndexOutputInput, which is a bigger change.\n\nWe also should [separately] consider having multiple SegmentReaders that share the same docStores, share a single set of IndexInputs (cloned).  Ie if the RAM MergePolicy allows many segments in RAM at once, we are still opening real file descriptors to read the doc stores, so without such sharing we could start running out of descriptors. ",
            "author": "Michael McCandless",
            "id": "comment-12714535"
        },
        {
            "date": "2009-05-31T20:24:45+0000",
            "content": "I want to run the Lucene unit tests in NRT mode without creating and/or\nmodifying all the test cases. In lieu of adding a\nSystem.property that turns NRT on, have we settled on a\ndifferent mechanism for global settings? Perhaps the back compat\ntype of system can be used here? Or for now a static variable on\nIW?\n\ncan we open a new IndexInput, while an IndexOutput is\nstill writing to the file?\n\nI ran a test case successfully that writes to a file while\nopening threads that read from flushed sections on windows.\n\nClosing docstores for every flush would seem to cause a lot of\noverhead. With NRT + FSD aren't termvector files merged on disk for\nevery segment?  \n\nWe also should [separately] consider having multiple\nSegmentReaders that share the same docStores\n\nDoesn't FSDir open only one FD per file? \n ",
            "author": "Jason Rutherglen",
            "id": "comment-12714924"
        },
        {
            "date": "2009-06-01T00:52:45+0000",
            "content": "\nI want to run the Lucene unit tests in NRT mode without creating and/or \nmodifying all the test cases.  \nYou can just temporarily set the default then run all tests? \n\nWe never reached consensus on a back compat sort of setting... \n\n\nI ran a test case successfully that writes to a file while \nopening threads that read from flushed sections on windows.  \n\nExcellent; let's take this up under a new issue? If this holds true across platform (and Windows is the most challenging one) then it'll make sharing much easier. \n\n\nClosing docstores for every flush would seem to cause a lot of \noverhead. With NRT + FSD aren't termvector files merged on disk for \nevery segment?  \n\nYes it adds overhead, though, it's not on the critical path for opening a new reader since it happens in the BG. So... things like LUCENE-1526 (making deletions, norms incrementally copy-on-write) I think are higher priority. \n\nDoesn't FSDir open only one FD per file? \n\nNo, it opens a real file every time openInput is called. I guess we could think about having it share/clone internally? ",
            "author": "Michael McCandless",
            "id": "comment-12714948"
        },
        {
            "date": "2009-06-01T04:26:03+0000",
            "content": "You can just temporarily set the default then run all\ntests? \n\nOr have separate parallel classes inherited classes that set the\nstatic IW variable, run the tests, and perhaps have additional\nNRT specific test methods.\n\nI guess we could think about having it share/clone\ninternally?\n\nYeah we should, I got this confused with how we're cloning in\nmost o.a.l.i classes, but if we're calling openInput it seems\nlike we should have it internally clone, I guess we'll have an\nissue with classes that don't IndexInput.close, however it's\nbetter to solve these than open many unnecessary file\ndescriptors. \n\nlet's take this up under a new issue?\n\nThe issue would only be the unit test for now, or should it be a\npart of an existing issue? Ok, it will clean up LUCENE-1313's\nunit test class. ",
            "author": "Jason Rutherglen",
            "id": "comment-12714966"
        },
        {
            "date": "2009-06-01T19:53:36+0000",
            "content": "With flushToRAM=true, when IW.commit is called, do we still want\nto not have concurrent merges execute synchronously? Or only\nwait for the merges to complete that are from ramDir to\nprimaryDir? ",
            "author": "Jason Rutherglen",
            "id": "comment-12715221"
        },
        {
            "date": "2009-06-01T23:52:29+0000",
            "content": "\nThe issue would only be the unit test for now, or should it be a\npart of an existing issue? \nI meant the issue of FSDir sharing a single IndexInput if the same file is opened more than once (you opened LUCENE-1671 for this).\n\nI guess we'll have an issue with classes that don't IndexInput.close\n\nThis (failing to close an IndexInput that was obtained from Directory.openInput) should be rare in Lucene \u2013 we try not to do that.  Failing to close clones does happen...\n\n\nWith flushToRAM=true, when IW.commit is called, do we still want\nto not have concurrent merges execute synchronously? Or only\nwait for the merges to complete that are from ramDir to\nprimaryDir?\n\nI think only ramDir -> primaryDir?  commit() today doens't block on BG merges. ",
            "author": "Michael McCandless",
            "id": "comment-12715305"
        },
        {
            "date": "2009-06-02T18:59:28+0000",
            "content": "For IW.resolveRAMSegments, maybe we should make a single\nmerge that merges everything down? Why even bother interacting\nwith a merge policy, here?\n\nLogMergePolicy.findMergesForOptimize I assumed would merge\nsegments to a single segment, in testing resolveRAMSegments that\ndoesn't always seem to be the case? \n\nWhen I created a mergeAllSegments to one, the\nensureContiguousMerge would throw an exception. I thought about\navoiding ensureContiguousMerge but it required reworking a bunch\nof code. Why does ensureContiguousMerge exist? Is it for\nassertions or is there a reason segments need to be next to each\nother when merging?  ",
            "author": "Jason Rutherglen",
            "id": "comment-12715628"
        },
        {
            "date": "2009-06-02T19:29:59+0000",
            "content": "\nLogMergePolicy.findMergesForOptimize I assumed would merge\nsegments to a single segment, in testing resolveRAMSegments that\ndoesn't always seem to be the case?\nIt should, but it will respect mergeFactor in the process (ie do multiple merges if necessary). I'm thinking we should just merge all the RAM segments in one go, and not consult merge policy, in resolveRAMSegments.\n\n\nWhen I created a mergeAllSegments to one, the\nensureContiguousMerge would throw an exception. \nWhy does this throw an exception?  Ie you passed in the in-order RAM segments?\n\n\nWhy does ensureContiguousMerge exist? Is it for\nassertions or is there a reason segments need to be next to each\nother when merging?\n\nI think the only thing that'd break is IndexWriter now assumes continuity when it removes the old segments and puts the new one in.  LUCENE-1076 explores allowing MergePolicy to select non-contiguous merges.\n\nBut: with autoCommit=false, in order to avoid merging the doc stores, the segments (even RAM segments) must be contiguous.  This is a sizable performance gain when building a large index in one IndexWriter session. ",
            "author": "Michael McCandless",
            "id": "comment-12715635"
        },
        {
            "date": "2009-06-02T20:44:52+0000",
            "content": "Just so we don't forget, we need to test flushToRAM with a custom IndexDeletionPolicy which could be a bit tricky. ",
            "author": "Jason Rutherglen",
            "id": "comment-12715675"
        },
        {
            "date": "2009-06-05T04:44:00+0000",
            "content": "\n\tRAM buffer size is stored in the writer rather than set into\nDocumentsWriter. This is due to the actual ram buffer limit in\nNRT changing depending on the size of the ramdir. \n\n\n\n\n\tNRTMergePolicy and IW.resolveRAMSegments merges all ram dir\nsegments to primaryDir (i.e. disk) when the ramDir is over\ntotalMax, or any new merges would put ramDir over totalMax.\n\n\n\n\n\tIn DocumentsWriter we have a set limit on the buffer size\nwhich is (tempMax - ramDirSize)/2. This keeps the total ram used\nunder the totalMax (or IW.maxBufferSize), while also keeping our\ntemporary ram usage under the tempMax amount. When DW.ramBuffer\nlimit is reached, it's auto flushed to the ramDir.\n\n\n\n\n\tAll tests pass except TestIndexWriterRAMDir.testFSDirectory.\nWill look into this further. When flushToRAM is on by default,\nthere seems to be deadlock in\norg.apache.lucene.TestMergeSchedulerExternal, however when I\ntried to see if there is any via jconsole by setting\nANT_OPTS=\"-Dcom.sun.management.jmxremote\" I didn't see any. I'm\nnot sure if this is due to not connecting to the right process?\nOr something else.\n\n\n\n\n\tAdded testReadDocuments which insures we can read documents\nwe've flushed to disk. This essentially tests our ability to\nsimultaneously read and write documents to and from the\ndocstore. It seemd to work on Windows.\n\n\n\n\n\tI think there's more that can be done to more accurately\nmanage the RAM however I think the way it works is a good\nstarting point.\n\n\n ",
            "author": "Jason Rutherglen",
            "id": "comment-12716496"
        },
        {
            "date": "2009-06-15T13:56:55+0000",
            "content": "Whats the verdict on this one Mike? Got the impression this was a likely 3.1 ... ",
            "author": "Mark Miller",
            "id": "comment-12719561"
        },
        {
            "date": "2009-06-15T15:35:44+0000",
            "content": "OK let's push it to 3.1.  It's very much in progress, but 1) the iterations are slow (it's a big patch), 2) it's a biggish change so I'd prefer to it shortly after a release, not shortly before, so it has plenty of time to \"bake\" on trunk. ",
            "author": "Michael McCandless",
            "id": "comment-12719600"
        },
        {
            "date": "2009-06-15T17:45:18+0000",
            "content": "Just wanted to give an update on this, I'm running the unit\ntests with flushToRAM=true, the ones that fail are (mostly)\ntests that look for files when they're now in RAM (temporarily)\nand the like. I'm not sure what to do with these tests, 1)\nignore them (kind of hard to not run specific methods, I think)\n2) or conditionalize them to run only if flushToRAM=false.  ",
            "author": "Jason Rutherglen",
            "id": "comment-12719665"
        },
        {
            "date": "2009-06-15T20:56:52+0000",
            "content": "TestThreadedOptimize is throwing a ensureContiguousMerge\nexception. I think this is highlighting the change to merging\nall ram segments to a single primaryDir segment can sometimes\nlead to choosing segments that are non-contiguous? I'm not sure\nof the best way to handle this. ",
            "author": "Jason Rutherglen",
            "id": "comment-12719767"
        },
        {
            "date": "2009-06-16T14:25:32+0000",
            "content": "\nI think this is highlighting the change to merging\nall ram segments to a single primaryDir segment can sometimes\nlead to choosing segments that are non-contiguous?\nI don't see why that results in a non-contiguous merge?   Ie, at all times the RAM segments should be on the tail of SegmentInfos?  So if you merge all of them, in order, that merge should be contiguous? ",
            "author": "Michael McCandless",
            "id": "comment-12720147"
        },
        {
            "date": "2009-06-16T14:26:16+0000",
            "content": "conditionalize them to run only if flushToRAM=false.\n\nThat seems good? ",
            "author": "Michael McCandless",
            "id": "comment-12720148"
        },
        {
            "date": "2009-06-18T00:55:35+0000",
            "content": "The patch is cleaned up. A static variable IndexWriter.GLOBALNRT\nis added, which allows all the tests to be run with\nflushToRAM=true. I reran the tests which hopefully still work as\nintended. Tests that looked for specific file names were changed\nto work with NRT. Some of the tests are skipped entirely and\nneed to be written specifically for flushToRAM. \n\n\n\tTestIndexWriterMergePolicy,TestBackwardsCompatibility failures\nare expected\n\n\n\n\n\tTestIndexWriterRAMDir.testFSDirectory fails (will be fixed)\n\n\n\n\n\tTestThreadedOptimize ensureContiguousMerge fails. This one is\na bit mysterious, perhaps the correct assertion will show where\nit's going wrong. \n\n\n\nI need to go through and mark the tests that can be converted to\nbe NRT specific.  ",
            "author": "Jason Rutherglen",
            "id": "comment-12721021"
        },
        {
            "date": "2009-06-18T22:52:20+0000",
            "content": "\n\tTestThreadedOptimize passes, LogMergePolicy now filters the\nsegmentInfos based on the dir, rather than NRTMergePolicy\npassing in only ramInfos or primaryInfos. LogMergePolicy is\ncareful to select contiguous segments, by passing in a subset of\nsegmentInfos, the merge policy selection broke down.\n\n\n\n\n\tTestIndexWriter.testAddIndexOnDiskFull,\ntestAddIndexesWithCloseNoWait fails, which I don't think\nhappened before. testAddIndexOnDiskFull fails when\nautoCommit=true which I'm not sure is a valid test by the time\nthis patch goes in but it probably needs to be looked into. \n\n\n\nThe other previous notes are still valid. ",
            "author": "Jason Rutherglen",
            "id": "comment-12721534"
        },
        {
            "date": "2009-06-19T18:46:04+0000",
            "content": "Using a single segmentInfos in IW seems to be problematic as\nwe'll always potentially have different dir non-contiguous\ninfos. I'm seeing the error off and on in different test cases.\nI will put together a patch separating the two dir infos in IW. ",
            "author": "Jason Rutherglen",
            "id": "comment-12721927"
        },
        {
            "date": "2009-06-19T18:56:11+0000",
            "content": "On second thought, the previous idea would require quite a bit\nof work. Perhaps OneMerge can have the segmentInfos (ramDir or\nprimaryDir) they were selected from and the ensureContiguous can\nverify that? Then we'd adjust commitMerge to remove the newly\nmerged segments individually.\n\nI'll give this a try. ",
            "author": "Jason Rutherglen",
            "id": "comment-12721933"
        },
        {
            "date": "2009-06-22T22:16:19+0000",
            "content": "It's progressing.  Randomly some tests fail such as the one noted below.  \n\n\n\tTestIndexWriter.testAddIndexesWithCloseNoWait fails with\n\"rollback() was called or addIndexes* hit an unhandled\nexception\", TestCrash.testWriterAfterCrash fails with \" [junit]\njava.io.FileNotFoundException: _a.fnm [junit] at\norg.apache.lucene.store.MockRAMDirectory.openInput(MockRAMDirecto\nry.java:252) [junit] at\norg.apache.lucene.index.FieldInfos.<init>(FieldInfos.java:67)\"\n\n\n\n\n\tassert in the ctor of MergeDocIDRemapper removed (not yet sure\nhow to replace it)\n\n\n\n\n\tOneMerge.fromInfos is added which is the set of segmentinfos\nthe merge was selected from. This is for ensureContiguousMerge\nwhere it's failing because we have essentially two different\nsets of segmentInfos (ram and primaryDir) in the\nIW.segmentInfos. They are not related, but for convenience are\nkept together for most of IW, then are separated out in the\nmerge policy. If the goal of ensureContiguousMerge is to keep\ndocStoreSegments together, this will work as ramDir and\nprimaryDir docStores should not need to be adjacent (I think,\nand need to verify).\n\n ",
            "author": "Jason Rutherglen",
            "id": "comment-12722866"
        },
        {
            "date": "2009-06-30T21:28:31+0000",
            "content": "Expected tests fail, the previous tests that were failing pass\non 2 runs. I didn't make any changes though so am suspicious! ",
            "author": "Jason Rutherglen",
            "id": "comment-12725815"
        },
        {
            "date": "2009-08-28T17:24:14+0000",
            "content": "Benchmark of LUCENE-1313 ",
            "author": "Jason Rutherglen",
            "id": "comment-12748909"
        },
        {
            "date": "2009-09-23T02:03:57+0000",
            "content": "Patch is updated to trunk and compiles. Unit tests fail because\nthey're hardcoded for specific numbers of files etc, otherwise I\ndon't think there's anything glaring.\n\nThe included benchmark indexes 1 document, queries with a sort,\nand repeats N times. This is way too taxing using the existing\nIW.getReader when pointing to a hard drive, basically the\nmachine becomes unusable. I haven't figured out what to publish\nor how long I want to wait. I'll just run it overnight. \n\nThis patch's benchmark fairs much better, I'll publish it's\nresults as well. Thinking 1, 10, 25, 50, 100, 1000 doc\nincrements should suffice, so there's some variation.  \n ",
            "author": "Jason Rutherglen",
            "id": "comment-12758538"
        },
        {
            "date": "2009-09-23T02:11:50+0000",
            "content": "Ah, missing file now included. ",
            "author": "Jason Rutherglen",
            "id": "comment-12758539"
        },
        {
            "date": "2009-10-16T02:10:44+0000",
            "content": "I think this patch has a memory leak, I'm trying to get a copy of an open source Yourkit license for profiling the heap usage.  The code is unfortunately quite large so whatever it is, is probably easy to fix and hard to find. ",
            "author": "Jason Rutherglen",
            "id": "comment-12766376"
        },
        {
            "date": "2009-11-02T19:04:35+0000",
            "content": "Realizing the previous patches approach has grown too\ncomplicated, this is a far simpler implementation that fulfills\nthe same goal, batching segments in RAM until they exceed a\ngiven maximum size, then merging those RAM segments to a primary\ndirectory (i.e. disk). All the while allowing all segments to be\nsearchable with a minimum latency turnaround.\n\n\n\tSegment names are generated for the ram writer from the\nprimary writer, this insures name continuity. Actually I'm not\nsure this is necessary anymore.\n\n\n\n\n\tThe problem is when the ram segments are merged into the\nprimary writer, they appear to be non-contiguous. Some of the\ncontiguous segment checking has been relaxed for this case, and\nneeds to be conditional on the segment merging being from the\nram dir. Perhaps we can have our cake and eat it too here by\nkeeping the contiguous check around for all cases?\n\n\n\n\n\tWhen the ram writer's usage exceeds a specified size, the ram\nbuffer is flushed, and the ram segments are synchronously merged\nto the primary writer using a mechanism similar to\naddIndexesNoOptimize.\n\n ",
            "author": "Jason Rutherglen",
            "id": "comment-12772602"
        },
        {
            "date": "2009-11-03T00:37:02+0000",
            "content": "\n\tEnsure contiguous is mostly back\n\n\n\n\n\tCleaned up the code and made the flush method non-synchronized\n\n\n\n\n\tThere's a subtle synchronization bug causing files to not be found in the testRandomThreads method\n\n\n\n\n\tThere's excessive merge logging to debug the sync issue\n\n ",
            "author": "Jason Rutherglen",
            "id": "comment-12772791"
        },
        {
            "date": "2009-11-04T19:51:20+0000",
            "content": "I wanted to simplify a little more to more easily understand the\nedge cases that fail. In the multithreaded test, files were\nsometimes left open which is hard for me to debug. \n\nThe TestNRT.testSimple method passes however, IndexFileDeleter\nis complaining about not being able to delete when expected\nwhich is shown in the IW.infoStream.\n\nThe NRT.flush method creates a merge of all the ram segments,\nthen calls IW.mergeIn to manually merge the ram segments into\nthe writer. OneMerge contains the writer where the segment\nreaders should be obtained from. In this case, the primary\nwriter obtains the readers from the ram writer's readerpool.\nThis is important because deletes may be coming in as we're\nmerging. However I'm not sure this will work without a shared\nlock between the writers for commitMergedDeletes which requires\nsyncing.\n\nMike, can you take a look to see if this path will work? ",
            "author": "Jason Rutherglen",
            "id": "comment-12773624"
        },
        {
            "date": "2009-11-05T02:05:14+0000",
            "content": "The tests pass, and the previous kinks seem to be worked out.\nActually there is still one issue, where in waitForMerges, the\nassert mergingSegments size equals zero occasionally fails. I\nthink this is a small sync problem because of the manual merge\nbetween the two writers. \n\nI'll run the multi threaded test at a longer interval to see\nwhat other errors may crop up. Once it runs successfully for\nlets say 30 minutes, we can beef up the stress testing of this\npatch by doing concurrent updates, deletes, etc. ",
            "author": "Jason Rutherglen",
            "id": "comment-12773745"
        },
        {
            "date": "2009-11-05T02:15:23+0000",
            "content": "Alright, the issue was simple, OneMerge.registerDone was being set to false by the primary writer, so the ram writer wasn't removing the infos from mergingSegments in mergeFinish.\n ",
            "author": "Jason Rutherglen",
            "id": "comment-12773747"
        },
        {
            "date": "2009-11-05T06:34:21+0000",
            "content": "TestNRTReaderWithThreads2 fails periodically, it's just another\nsynchronization issue. I added syncing on the merge writer in\nmethods like commitMergedDeletes and commitMerge. Perhaps more\nof that type of syncing needs to be added. It can take time for\nthese issues to be figured out.\n\nThere's also remnants of a first attempt at transparently\nutilizing the NRT class within IW. ",
            "author": "Jason Rutherglen",
            "id": "comment-12773803"
        },
        {
            "date": "2009-11-05T19:33:19+0000",
            "content": "New assertions in NRT.flush are catching the issue that's occurring.   ",
            "author": "Jason Rutherglen",
            "id": "comment-12774044"
        },
        {
            "date": "2009-11-05T19:44:29+0000",
            "content": "I'll try to have a look at this soon Jason!  Sounds like good progress... ",
            "author": "Michael McCandless",
            "id": "comment-12774049"
        },
        {
            "date": "2009-11-05T21:43:41+0000",
            "content": "OK, all the tests pass consistently now.  \n\nI guess the next feature is to have NRT.flush execute in a single background thread rather than block update doc calls. ",
            "author": "Jason Rutherglen",
            "id": "comment-12774090"
        },
        {
            "date": "2009-11-05T21:56:23+0000",
            "content": "I turned on assert !sr.hasChanges in readerPool.release, and it fails sometimes.  I'm not quite sure why yet. ",
            "author": "Jason Rutherglen",
            "id": "comment-12774098"
        },
        {
            "date": "2009-11-06T01:23:24+0000",
            "content": "Well, I added the background thread for NRT.flush, however, I've also been debugging this assert !sr.hasChanges issue, which out of 7000 iterations, occurs once, and is fairly minor.  Hmm... Apply deletes shouldn't really conflict so I'm hoping this isn't an original bug unrelated to LUCENE-1313. ",
            "author": "Jason Rutherglen",
            "id": "comment-12774171"
        },
        {
            "date": "2009-11-09T20:47:36+0000",
            "content": "This patch includes flushing in a background thread.  Some formatting has been cleaned up, javadocs added.\n\nI ran TestNRTReaderWithThreads2 a couple times for kicks and didn't see the assert sr.hasChanges error.  I'll probably focus on adding more stress testing. ",
            "author": "Jason Rutherglen",
            "id": "comment-12775127"
        },
        {
            "date": "2009-11-24T23:53:58+0000",
            "content": "I went back to trying to utilize a RAM dir inside of IW. This\nactually works well now, and the code is less intrusive than the\nprevious patches. The incoming directory is placed in a\nPrefixSwitchDirectory which accepts indicating whether a segment\nis destined for the ram directory or the primary directory. \n\nA single internal segment infos collection is used, the first\nhalf are primary dir segments, the second, ram dir segments. \n\nThe above mentioned changes of course break many unit tests. I'm\ngoing through and evaluating what do on a case by case basis,\nand am open to suggestions.  ",
            "author": "Jason Rutherglen",
            "id": "comment-12782249"
        },
        {
            "date": "2010-01-04T14:31:14+0000",
            "content": "I've just tried applying this patch to my checked-out version of trunk (revision 895585) but it appears that the PrefixSwitchDirectory class is missing - is there another patch that is needed to get this working? ",
            "author": "Jingkei Ly",
            "id": "comment-12796191"
        },
        {
            "date": "2010-01-05T04:31:21+0000",
            "content": "Jingkei, Sorry, please try this patch... ",
            "author": "Jason Rutherglen",
            "id": "comment-12796526"
        },
        {
            "date": "2010-01-05T14:42:36+0000",
            "content": "Thanks Jason, the patch applies cleanly now. \n\nI've tested it out but it appears that in my extreme use case (I need to handle a case where 1 document is added to the index and then is made immediately available for searching many times a second) the patch version seems to be about 1/3rd slower than the current NRT implementation in Lucene 3.0, with most of the time lost in searching. I'd expected the RAMDirectory implementation to be faster - is what I'm seeing against your expectations too?  ",
            "author": "Jingkei Ly",
            "id": "comment-12796677"
        },
        {
            "date": "2010-01-05T15:37:53+0000",
            "content": "> the patch version seems to be about 1/3rd slower than the current NRT implementation in Lucene 3.0\n\nHow are you measuring the 1/3?  Can you post your test?  It may be helpful to create a similar test using Lucene's benchmark code.  \n\n> with most of the time lost in searching\n\nIs it QPS or query times that are going down? ",
            "author": "Jason Rutherglen",
            "id": "comment-12796705"
        },
        {
            "date": "2010-01-05T16:46:58+0000",
            "content": "Jason,\n\nI've attached the benchmarking test I've based my observations on. My use case is to add 1 document to the index and to perform a search immediately afterwards and be guaranteed that the document I previously added is available in the search (which it is why it is done synchronously in 1 thread).\n\nApologies for the sysouts on which I'm basing my observations on - the main point is that adding a few thousand docs in this fashion appears to be faster in Lucene 3.0 when compared to the equivalent with trunk+patch. The 1/3rd slower observation I made is based on the fact that on my machine (quad-core, 4GB RAM, Windows XP), Lucene 3.0 is able to process 35 docs per second in the fashion I've described, whereas trunk + patch runs at 22 docs per second.\n\nHaving rerun the test, It appears the average time it takes for a query to complete is slower but it's actually the average time it takes to get a new realtime reader that is much slower.\n\nI haven't ruled out having done something really stupid in my test, in which case I apologise in advance! ",
            "author": "Jingkei Ly",
            "id": "comment-12796758"
        },
        {
            "date": "2010-01-05T16:57:08+0000",
            "content": "Lucene 3.0 is able to process 35 docs per second in the\nfashion I've described, whereas trunk + patch runs at 22 docs\nper second.\n\nI glanced at the benchmark posted. It'll take some digging into,\nI ran tests before like this (add 1 doc, do a search) and\nLUCENE-1313 was faster than trunk/3.0. On Windows XP it was\ndefinitely faster before (I saw XP perform lots of disk access\nwhen creating small files) so perhaps there's something else\ngoing on. ",
            "author": "Jason Rutherglen",
            "id": "comment-12796763"
        },
        {
            "date": "2011-01-24T21:16:43+0000",
            "content": "Won't be working on these and they're old ",
            "author": "Jason Rutherglen",
            "id": "comment-12986019"
        }
    ]
}