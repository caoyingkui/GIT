{
    "id": "SOLR-737",
    "title": "Incorrect 500 error reported with maxClausCount limit",
    "details": {
        "affect_versions": "1.3",
        "status": "Closed",
        "fix_versions": [
            "1.3"
        ],
        "components": [],
        "type": "Improvement",
        "priority": "Minor",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "Here is my installation:\nSolr Specification Version: 1.2.2008.08.13.13.05.16\nLucene Implementation Version: 2.4-dev 685576 - 2008-08-13 10:55:25\n\nI did the following query today:\nauthor:(r*a* AND fisher)\n\nAnd get the following 500 error:\n\nmaxClauseCount is set to 1024\n\norg.apache.lucene.search.BooleanQuery$TooManyClauses: maxClauseCount is set to 1024\n        at org.apache.lucene.search.BooleanQuery.add(BooleanQuery.java:165)\n        at org.apache.lucene.search.BooleanQuery.add(BooleanQuery.java:156)\n        at org.apache.lucene.search.MultiTermQuery.rewrite(MultiTermQuery.java:63)\n        at org.apache.lucene.search.WildcardQuery.rewrite(WildcardQuery.java:54)\n        at org.apache.lucene.search.BooleanQuery.rewrite(BooleanQuery.java:385)\n        at org.apache.lucene.search.IndexSearcher.rewrite(IndexSearcher.java:163)\n        at org.apache.lucene.search.Query.weight(Query.java:94)\n        at org.apache.lucene.search.Searcher.createWeight(Searcher.java:175)\n        at org.apache.lucene.search.Searcher.search(Searcher.java:126)\n        at org.apache.lucene.search.Searcher.search(Searcher.java:105)\n        at org.apache.solr.search.SolrIndexSearcher.getDocListNC(SolrIndexSearcher.java:966)\n        at org.apache.solr.search.SolrIndexSearcher.getDocListC(SolrIndexSearcher.java:838)\n        at org.apache.solr.search.SolrIndexSearcher.search(SolrIndexSearcher.java:269)\n        at org.apache.solr.handler.component.QueryComponent.process(QueryComponent.java:160)\n        at org.apache.solr.handler.component.SearchHandler.handleRequestBody(SearchHandler.java:167)\n        at org.apache.solr.handler.RequestHandlerBase.handleRequest(RequestHandlerBase.java:135)\n        at org.apache.solr.core.SolrCore.execute(SolrCore.java:1156)\n        at org.apache.solr.servlet.SolrDispatchFilter.execute(SolrDispatchFilter.java:341)\n        at org.apache.solr.servlet.SolrDispatchFilter.doFilter(SolrDispatchFilter.java:272)\n        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1088)\n        at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:360)\n        at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)\n        at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:181)\n        at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:729)\n        at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:405)\n        at org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:206)\n        at org.mortbay.jetty.handler.HandlerCollection.handle(HandlerCollection.java:114)\n        at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)\n        at org.mortbay.jetty.Server.handle(Server.java:324)\n        at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:505)\n        at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:829)\n        at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:513)\n        at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:211)\n        at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:380)\n        at org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:395)\n        at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:488)",
    "attachments": {
        "SOLR-737.patch": "https://issues.apache.org/jira/secure/attachment/12389107/SOLR-737.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Andrew Nagy",
            "id": "comment-12626611",
            "date": "2008-08-28T15:17:21+0000",
            "content": "Why has this been relegated to an improvement and held to 1.4?\n\nThis is a major showstopper bug for me - unless I am understanding something incorrectly? "
        },
        {
            "author": "Mark Miller",
            "id": "comment-12626615",
            "date": "2008-08-28T15:22:11+0000",
            "content": "Because its an artificial limitation from lucene - truncation queries expand to one clause per possible term in the index - generate enough of these clauses and you have a really slow search. Lucene bails at the default of 1024. Not sure if this setting is available in solr, but as Otis marked as improvement, I would guess not and the idea is to add it. Its not a bug though - your wildcard term is just matching over 1024 terms in the index. "
        },
        {
            "author": "Andrew Nagy",
            "id": "comment-12626619",
            "date": "2008-08-28T15:27:11+0000",
            "content": "Thanks Mark for clarification.  This makes sense now.  Solr does already have a configurable maxClauseCount and the default is 1024.\n\nCan anyone supply more information on whether or not this is something that can be enhanced in Lucene - for me this is a very important query and since I have well over a million documents - I will never be able to issue this query. "
        },
        {
            "author": "Erik Hatcher",
            "id": "comment-12626620",
            "date": "2008-08-28T15:32:06+0000",
            "content": "Andrew - for one, you can increase the boolean clause limit (at the risk of a less performant query).  In solrconfig, adjust this: <maxBooleanClauses>1024</maxBooleanClauses>\n\nAlso, there are many tricks that can be played to make wildcard querying more efficient if you are willing to sacrifice index size and manage index analyzer and query analyzer carefully.  Have a look this topic in the java-user@lucene archives.  I did a lot of work once upon a time for a client that involved term rotation during indexing and then morphing wildcard queries to have maximal prefix for best efficiency.\n\nAs a thought experiment - consider what you'd do if you had to satisfy a patrons request for \"find me all books matching r*a* in the title\" using a card catalog system!    "
        },
        {
            "author": "Andrew Nagy",
            "id": "comment-12626621",
            "date": "2008-08-28T15:32:25+0000",
            "content": "Sorry to keep blathering on - but I am trying to understand this issue better.\n\nIf I issue the query (r* AND fisher) the results come back to me immediately ... no slow down what so ever.  And an r* is going to have many many more possibilities than r*a* - it still seems like there is a bug here.\n\nCan anyone clarify how lucene handles this? "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12626628",
            "date": "2008-08-28T15:40:09+0000",
            "content": "r* is a prefix query that Solr turns into a ConstantScorePrefixQuery\nr*a* is a wildcard query.... it should eventually get the same treatment, but we don't currently have a ConstantScoreWildcardQuery. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12626640",
            "date": "2008-08-28T16:37:30+0000",
            "content": "Here's a quick patch to fix things. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12626648",
            "date": "2008-08-28T17:01:42+0000",
            "content": "Thinking on this a little further, I do think this is a bug, and I do think it warrants going into 1.3\n\nThe original range and prefix queries were broken, and I fixed them via ConstantScoreQuery.  I never did it for wildcard query because the company I worked for at the time didn't use them.  But any query that explodes when you change the index is arguably broken.\n\nObjections to this going into 1.3? "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12626653",
            "date": "2008-08-28T17:14:03+0000",
            "content": "+1 for marking for 1.3\n\nDoes it also make execution of these queries any faster? Sorry, I'm not very familiar with ConstantScoreQuery and related Lucene classes. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12626655",
            "date": "2008-08-28T17:19:25+0000",
            "content": "Does it also make execution of these queries any faster?\n\nOn balance, I think so.  If only a few terms would be matched, it will be a little slower.  If a lot of terms are matched, then it will normally be faster. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12626738",
            "date": "2008-08-28T21:04:19+0000",
            "content": "committed.\nI'm currently figuring out how to do a merge to commit it to the 1.3 branch also. "
        }
    ]
}