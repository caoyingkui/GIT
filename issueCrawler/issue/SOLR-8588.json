{
    "id": "SOLR-8588",
    "title": "Add TopicStream to the streaming API to support publish/subscribe messaging",
    "details": {
        "components": [],
        "type": "New Feature",
        "labels": "",
        "fix_versions": [
            "6.0"
        ],
        "affect_versions": "None",
        "status": "Resolved",
        "resolution": "Implemented",
        "priority": "Major"
    },
    "description": "The TopicStream is a publish/subscribe messaging service built on top of SolrCloud.  The TopicStream returns all new documents for a specific query. Version numbers will be used as checkpoints for Topics to ensure single delivery of each document. When combined with the DaemonStream (SOLR-8550), Topics can provide continuous streaming. Sample syntax:\n\n\ntopic(checkpointCollection, dataCollection, id=\"topicA\",  q=\"awesome stuff\" checkpointEvery=\"1000\")\n\n\n\nThe checkpoint collection will be used to persist the topic checkpoints.\n\nExample combined with the DaemonStream:\n\n\ndaemon(topic(...)...)\n\n\n\nWhen combined with SOLR-7739 this allows for messaging based on machine learned classifications.\n\nThe TopicStream supports 3 models of publish/subscribe messaging:\n\n1) Request & response: In this model a topic(...) expression can be saved and executed at any time. In this scenario the TopicStream will always retrieve it's checkpoints and start from where it left off.\n\n2) Continuous pull streaming: In this model you would wrap the TopicStream in a DaemonStream and call read() in a loop inside a java program.  This would provide a continuous stream of new content as it arrives in the index.\n\n3) Continuous push streaming: In this model you would send an expression like this to the /stream handler: daemon(update(topic(...)...)...). This daemon process would run inside Solr and continuously stream new documents from the topic and push them to another SolrCloud collection. Other pushing expressions can be created to push documents in different ways or take other types of actions.",
    "attachments": {
        "SOLR-8588.patch": "https://issues.apache.org/jira/secure/attachment/12787875/SOLR-8588.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2016-01-31T19:01:04+0000",
            "author": "Joel Bernstein",
            "content": "I think this ticket is the one I'm most excited about at the moment because it leverages so many of Solr's strengths. Topics can be arbitrary queries so they don't have to be registered in advance. It leverages Solr's transaction log and version number. SolrCloud replication provides scale and redundancy. Combined with DaemonStreams, topics can \"live\" inside Solr and continually push data, or can be embedded in client apps to provide continuous streaming. ",
            "id": "comment-15125455"
        },
        {
            "date": "2016-02-14T21:35:43+0000",
            "author": "Joel Bernstein",
            "content": "First pass at the TopicStream implementation. Tests to follow. ",
            "id": "comment-15146737"
        },
        {
            "date": "2016-02-15T19:05:40+0000",
            "author": "Joel Bernstein",
            "content": "Patch with first set of working tests. ",
            "id": "comment-15147708"
        },
        {
            "date": "2016-02-15T19:23:19+0000",
            "author": "Kevin Risden",
            "content": "This code could be cleaner I think:\n\n\nCollections.shuffle(shuffler, new Random());\nReplica rep = shuffler.get(0);\n\n\n\nreplace with something like:\n\n\nRandom random = new Random();\nReplica rep = shuffler.get(random.nextInt(shuffler.size()));\n\n\n\nThe initialization of random could be done once I think. ",
            "id": "comment-15147718"
        },
        {
            "date": "2016-02-15T20:40:27+0000",
            "author": "Joel Bernstein",
            "content": "Yep, this is nicer. I'll include this in the next patch. ",
            "id": "comment-15147776"
        },
        {
            "date": "2016-02-15T21:49:19+0000",
            "author": "Joel Bernstein",
            "content": "Added simple test for daemon(topic(...)....) continuous streaming. ",
            "id": "comment-15147827"
        },
        {
            "date": "2016-02-17T23:51:27+0000",
            "author": "Joel Bernstein",
            "content": "Added tests for checkpointing during read() iteration. ",
            "id": "comment-15151447"
        },
        {
            "date": "2016-02-17T23:52:08+0000",
            "author": "Joel Bernstein",
            "content": "Next step is manual testing. ",
            "id": "comment-15151448"
        },
        {
            "date": "2016-02-19T18:44:13+0000",
            "author": "Joel Bernstein",
            "content": "Manual testing looks good. It turned up a connection leak, which is now fixed (I'll put up a new patch shortly). Just need to clean up a few things and prepare this for committal for 6.0. ",
            "id": "comment-15154639"
        },
        {
            "date": "2016-02-20T01:03:19+0000",
            "author": "ASF subversion and git services",
            "content": "Commit b2475bf9fdc59c02454f730a6cc4916cff03f862 in lucene-solr's branch refs/heads/master from jbernste\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=b2475bf ]\n\nSOLR-8588: Add TopicStream to the streaming API to support publish/subscribe messaging ",
            "id": "comment-15155248"
        },
        {
            "date": "2016-02-20T01:03:20+0000",
            "author": "ASF subversion and git services",
            "content": "Commit f9127a919ac212c4a5c36e66fb0d0c15a7867c0e in lucene-solr's branch refs/heads/master from jbernste\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=f9127a9 ]\n\nSOLR-8588: Update CHANGES.txt ",
            "id": "comment-15155249"
        }
    ]
}