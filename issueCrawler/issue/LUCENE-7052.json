{
    "id": "LUCENE-7052",
    "title": "BytesRefHash.sort should always sort in unicode code point order",
    "details": {
        "resolution": "Fixed",
        "affect_versions": "None",
        "components": [],
        "labels": "",
        "fix_versions": [
            "6.0"
        ],
        "priority": "Major",
        "status": "Resolved",
        "type": "Improvement"
    },
    "description": "Today BytesRefHash.sort takes a custom Comparator but we always pass it BytesRef.getUTF8SortedAsUnicodeComparator().",
    "attachments": {
        "LUCENE-7052-cleanup1.patch": "https://issues.apache.org/jira/secure/attachment/12790349/LUCENE-7052-cleanup1.patch",
        "LUCENE-7052.patch": "https://issues.apache.org/jira/secure/attachment/12790307/LUCENE-7052.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "id": "comment-15170541",
            "author": "Michael McCandless",
            "date": "2016-02-27T10:34:05+0000",
            "content": "Simple patch. "
        },
        {
            "id": "comment-15170558",
            "author": "Robert Muir",
            "date": "2016-02-27T11:31:00+0000",
            "content": "+1 "
        },
        {
            "id": "comment-15170566",
            "author": "Dawid Weiss",
            "date": "2016-02-27T12:11:56+0000",
            "content": "Are you for simplifying the code? Because I doubt it'll be any speed improvement. "
        },
        {
            "id": "comment-15170604",
            "author": "Adrien Grand",
            "date": "2016-02-27T14:39:30+0000",
            "content": "+1 for the simplification "
        },
        {
            "id": "comment-15170605",
            "author": "Michael McCandless",
            "date": "2016-02-27T14:49:24+0000",
            "content": "Yeah, just shrinking the API. "
        },
        {
            "id": "comment-15170801",
            "author": "Steve Rowe",
            "date": "2016-02-28T02:17:22+0000",
            "content": "Mike, why did you add an implementation of codePoints() instead of using the CharSequence version (returning IntStream) + toArray()?  The test passes for me with this patch:\n\n\ndiff --git a/lucene/core/src/test/org/apache/lucene/util/TestBytesRefHash.java b/lucene/core/src/test/org/apache/lucene/util/TestBytesRefHash.java\nindex 50d921b..c3a58ff 100644\n--- a/lucene/core/src/test/org/apache/lucene/util/TestBytesRefHash.java\n+++ b/lucene/core/src/test/org/apache/lucene/util/TestBytesRefHash.java\n@@ -168,15 +168,6 @@ public class TestBytesRefHash extends LuceneTestCase {\n     }\n   }\n \n-  private static int[] codePoints(String input) {\n-    int length = Character.codePointCount(input, 0, input.length());\n-    int word[] = new int[length];\n-    for (int i = 0, j = 0, cp = 0; i < input.length(); i += Character.charCount(cp)) {\n-      word[j++] = cp = input.codePointAt(i);\n-    }\n-    return word;\n-  }\n-\n   /**\n    * Test method for\n    * {@link org.apache.lucene.util.BytesRefHash#sort()}.\n@@ -191,8 +182,8 @@ public class TestBytesRefHash extends LuceneTestCase {\n       SortedSet<String> strings = new TreeSet<>(new Comparator<String>() {\n           @Override\n           public int compare(String a, String b) {\n-            int[] aCodePoints = codePoints(a);\n-            int[] bCodePoints = codePoints(b);\n+            int[] aCodePoints = a.codePoints().toArray();\n+            int[] bCodePoints = b.codePoints().toArray();\n             for(int i=0;i<Math.min(aCodePoints.length, bCodePoints.length);i++) {\n               if (aCodePoints[i] < bCodePoints[i]) {\n                 return -1;\n\n "
        },
        {
            "id": "comment-15170951",
            "author": "Dawid Weiss",
            "date": "2016-02-28T07:46:34+0000",
            "content": "Neither is actually pretty as the treeset invokes a comparator multiple times for the same string, causing multiple identical string-int[] conversions along the way. This is test-method only though, so it doesn't matter much. "
        },
        {
            "id": "comment-15170991",
            "author": "Uwe Schindler",
            "date": "2016-02-28T10:33:02+0000",
            "content": "Hi Mike,\nI know originally we added the different comparators to be able to allow the index term dict to be sorted in different order. This never prooved to be useful, as many Lucene queries rely on the default order. The only codec that used another byte order internally was the Lucene 3 one (but it used the unicode spaghetti algorithm to reorder its term enums at runtime). As this is now all gone, I'd suggest to also remove the utf8AsUtf16 comparator. Mabye remove the comparators at all and just implement BytesRef.compareTo() and use that one for sorting?\n\nI checked the code: utf8SortedAsUTF16SortOrder is only used in TSTLookup nowhere else anymore (except some test that check alternative sorts - those can be removed).\n\nAs a first step I changed the BytesRef code to no longer use inner classes and instead use a lambda to define the comparators. But I'd suggest to remove at least the UTF-16 one completely and move it as private impl detail to TSTLookup (as only used there).\n\nFYI: The lambda has no speed impact because it is called only once and internally compiles to a class file that implements Comparator. It just looks nicer than the horrible comparator classes "
        },
        {
            "id": "comment-15170992",
            "author": "Uwe Schindler",
            "date": "2016-02-28T10:37:17+0000",
            "content": "Oh this was already committed. Maybe open another issue to remove the obsolete comparator and convert to lambda. "
        },
        {
            "id": "comment-15170994",
            "author": "Michael McCandless",
            "date": "2016-02-28T10:40:07+0000",
            "content": "Mike, why did you add an implementation of codePoints() instead of using the CharSequence version (returning IntStream) + toArray()? \n\nOh, because I didn't even know about CharSequence.codePoints!\n\n+1 to your patch, thanks.\n\nNeither is actually pretty as the treeset invokes a comparator multiple times for the same string, causing multiple identical string-int[] conversions along the way. This is test-method only though, so it doesn't matter much.\n\nIt's definitely inefficient (converting to a sortable key on every comparison), but it keeps the code simple, which I think is usually the right tradeoff for a test case?\n\nAs this is now all gone, I'd suggest to also remove the utf8AsUtf16 comparator. Mabye remove the comparators at all and just implement BytesRef.compareTo() and use that one for sorting?\n\n+1, that sounds awesome! "
        },
        {
            "id": "comment-15170995",
            "author": "Uwe Schindler",
            "date": "2016-02-28T10:40:43+0000",
            "content": "+1 to Steve Rowe change. We are on Java 8, so use Java 8 methods. "
        },
        {
            "id": "comment-15170997",
            "author": "Uwe Schindler",
            "date": "2016-02-28T10:42:03+0000",
            "content": "Mike, should I open a new issue for the comparator cleanups. I have the patch almost ready? "
        },
        {
            "id": "comment-15170999",
            "author": "Michael McCandless",
            "date": "2016-02-28T10:44:34+0000",
            "content": "TestUnicodeUtil.testUTF8toUTF32 (and I'm sure other places) can also cutover to CharSequence.codePoints. "
        },
        {
            "id": "comment-15171000",
            "author": "Michael McCandless",
            "date": "2016-02-28T10:44:41+0000",
            "content": "Mike, should I open a new issue for the comparator cleanups. I have the patch almost ready?\n\nYes please!! "
        },
        {
            "id": "comment-15171002",
            "author": "Uwe Schindler",
            "date": "2016-02-28T10:55:52+0000",
            "content": "Hi Mike, here is a patch, moving the UTF-16 comparator away and clean up code.\n\nI also changed the TreeSet comparator to a lambda using CharSequence#codePoints() because I hit the same in another test  "
        },
        {
            "id": "comment-15171003",
            "author": "Uwe Schindler",
            "date": "2016-02-28T10:56:47+0000",
            "content": "I wil open now other issue with the attached patch. As the Steve Rowe suggestion is implemented there, we can leave THIS issue closed. "
        },
        {
            "id": "comment-15171004",
            "author": "Uwe Schindler",
            "date": "2016-02-28T10:59:57+0000",
            "content": "New issue: LUCENE-7053 "
        },
        {
            "id": "comment-15172230",
            "author": "Hoss Man",
            "date": "2016-02-29T17:53:49+0000",
            "content": "I'm confused ... this issue is marked resolved, and Uwe said \"Oh this was already committed.\" but no commits are linked to it, not does it have any subtasks.\n\ncan someone clarify when/how this was resolved?\n "
        },
        {
            "id": "comment-15172280",
            "author": "Steve Rowe",
            "date": "2016-02-29T18:13:59+0000",
            "content": "AFAICT Mike forgot to include the JIRA in his log message for this commit (from the email sent to commits@l.a.o):\n\n\nRepository: lucene-solr\nUpdated Branches:\n refs/heads/master 70440bbbd -> 126ac9a5f\n\nBytesRefHash.sort always sorts in unicode order\n\nProject: http://git-wip-us.apache.org/repos/asf/lucene-solr/repo\nCommit: http://git-wip-us.apache.org/repos/asf/lucene-solr/commit/126ac9a5\nTree: http://git-wip-us.apache.org/repos/asf/lucene-solr/tree/126ac9a5\nDiff: http://git-wip-us.apache.org/repos/asf/lucene-solr/diff/126ac9a5\n\nBranch: refs/heads/master\nCommit: 126ac9a5fe00fbbc6870ef25ae3fc6af6cd7c557\nParents: 70440bb\nAuthor: Mike McCandless <mikemccand@apache.org>\nAuthored: Sat Feb 27 10:26:20 2016 -0500\nCommitter: Mike McCandless <mikemccand@apache.org>\nCommitted: Sat Feb 27 10:26:20 2016 -0500\n\n "
        },
        {
            "id": "comment-15172384",
            "author": "Michael McCandless",
            "date": "2016-02-29T18:56:56+0000",
            "content": "Sorry, yeah I forgot the issue number!  Thanks for linking it Steve Rowe! "
        }
    ]
}