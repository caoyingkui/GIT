{
    "id": "LUCENE-880",
    "title": "DocumentWriter closes TokenStreams too early",
    "details": {
        "labels": "",
        "priority": "Minor",
        "components": [],
        "type": "Bug",
        "fix_versions": [],
        "affect_versions": "None",
        "resolution": "Fixed",
        "status": "Resolved"
    },
    "description": "The DocumentWriter closes a TokenStream as soon as it has consumed its tokens. The javadoc of TokenStream.close() says that it releases resources associated with the stream. However, the DocumentWriter keeps references of the resources (i. e. payload byte arrays, term strings) until it writes the postings to the new segment, which means that DocumentWriter should call TokenStream.close() after it has written the postings.\n\nThis problem occurs in multithreaded applications where e. g. pooling is used for the resources. My patch adds a new test to TestPayloads which shows this problem. Multiple threads add documents with payloads to an index and use a pool of byte arrays for the payloads. TokenStream.close() puts the byte arrays back into the pool. The test fails with the old version but runs successfully with the patched version. \n\nAll other units tests pass as well.",
    "attachments": {
        "lucene-880.patch": "https://issues.apache.org/jira/secure/attachment/12357377/lucene-880.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2007-05-15T11:28:09+0000",
            "content": "Patch with new unit test. ",
            "author": "Michael Busch",
            "id": "comment-12495960"
        },
        {
            "date": "2007-05-17T12:39:10+0000",
            "content": "Committed. ",
            "author": "Michael Busch",
            "id": "comment-12496549"
        }
    ]
}