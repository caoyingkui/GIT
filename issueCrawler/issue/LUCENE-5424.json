{
    "id": "LUCENE-5424",
    "title": "FilteredQuery useRandomAccess() should use cost()",
    "details": {
        "type": "Improvement",
        "priority": "Major",
        "labels": "",
        "resolution": "Fixed",
        "components": [
            "core/query/scoring"
        ],
        "affect_versions": "None",
        "status": "Closed",
        "fix_versions": []
    },
    "description": "Now that Lucene's DISI has a cost() method, it's possible for FilteredQuery's RANDOM_ACCESS_FILTER_STRATEGY to use a smarter algorithm in its useRandomAccess() method.  In particular, it might examine filterIter.cost() to see if it is greater than the cost returned by weight.scorer().cost() of the query.",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "id": "comment-13886924",
            "author": "Michael McCandless",
            "content": "+1, there is a TODO about this in the code.\n\nBut I'm not sure how to translate cost to the right filter strategy.... maybe we need a hasAdvance() as Rob suggested on LUCENE-5418?\n\nAlso, useRandomAccess should not be used for costly filters: it should be used for cheap filters (e.g. a FixedBitSet), because this is passed down as the acceptDocs to possibly many, many postings iterators.  EG, if you run a BQ with 10 terms and pass a Filter to IS when doing the search ... if useRandomAccess is true, that filter is checked in all 10 of those DocsEnums, quite possibly many times per document. ",
            "date": "2014-01-30T19:01:01+0000"
        },
        {
            "id": "comment-13886963",
            "author": "David Smiley",
            "content": "I know I commented on LUCENE-5418 and then immediately created this issue but these are not particularly related.  I totally recognize that RANDOM_ACCESS_FILTER_STRATEGY is for the typical case of fast filters.  And indeed I observed the TODO comment and thought, hey, DISI does have a cost() now \u2013 lets do this!  Now there's this JIRA issue \n\nNot sure how to arrive at the right tuning ratio between the cost() of both DISI's.  Maybe use the benchmark module and try various filters that match 1%, 2%, etc. up to 99% of the documents, against some simple query that always matches the same 50 % of the total docs?  And then test this method given configurable threshold ratios of query_cost/filter_cost of 10%, 20%, ... etc. and see where the inflection point is.  That's complicated, yeah.   ",
            "date": "2014-01-30T19:33:13+0000"
        }
    ]
}