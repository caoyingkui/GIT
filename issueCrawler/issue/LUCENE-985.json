{
    "id": "LUCENE-985",
    "title": "AIOOB thrown when length of termText is longer than 16384 characters (ArrayIndexOutOfBoundsException)",
    "details": {
        "labels": "",
        "priority": "Minor",
        "components": [
            "core/index"
        ],
        "type": "Bug",
        "fix_versions": [
            "2.3"
        ],
        "affect_versions": "2.3",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "DocumentsWriter has a max term length of 16384; if you cross that you\nget an unfriendly ArrayIndexOutOfBoundsException.  We should fix to raise a clearer exception.",
    "attachments": {
        "LUCENE-985.patch": "https://issues.apache.org/jira/secure/attachment/12364076/LUCENE-985.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2007-08-17T22:09:33+0000",
            "content": "As a clarification point for people who stumble upon this issue years from now after encountering whatever exception we put in place of the current one...\n\nwhy is there a max termText length? ",
            "author": "Hoss Man",
            "id": "comment-12520693"
        },
        {
            "date": "2007-08-17T22:11:10+0000",
            "content": "(making summary longer to improve searchability of the exception for other people who may get bit by it)\n ",
            "author": "Hoss Man",
            "id": "comment-12520695"
        },
        {
            "date": "2007-08-18T00:16:20+0000",
            "content": "> As a clarification point for people who stumble upon this issue\n> years from now after encountering whatever exception we put in place\n> of the current one...why is there a max termText length?\n\nThis is because DocumentsWriter packs the term text for each unique\nterm seen into a pool of char[] blocks of 16384 chars each (to avoid\nGC overhead of each separate String).  So, every time a new term is\nseen, it puts it at the end of the current block; when there's not\nenough space it allocates another block from the pool.  So a given\nterm must fit entirely into a single block. ",
            "author": "Michael McCandless",
            "id": "comment-12520727"
        },
        {
            "date": "2007-08-18T00:34:10+0000",
            "content": "I doubt anyone will have a problem with the limit. And if they hit the exception it is probably due to bad end-user input of some kind. I always run a token filter that leaves out any token larger than 250 charachters or so, depending on the application. (It was quite accidential that I hit this AIOOBE.)\n\nThat would also be a recommendation I think makes sense in the documentation people will look up when hitting the exception. ",
            "author": "Karl Wettin",
            "id": "comment-12520741"
        },
        {
            "date": "2007-08-18T00:54:46+0000",
            "content": "> I doubt anyone will have a problem with the limit. And if they hit\n> the exception it is probably due to bad end-user input of some\n> kind. I always run a token filter that leaves out any token larger\n> than 250 charachters or so, depending on the application. (It was\n> quite accidential that I hit this AIOOBE.)\n\nAgreed!\n\n> That would also be a recommendation I think makes sense in the\n> documentation people will look up when hitting the exception.\n\nI've added a blurb in javadoc for IndexWriter.addDocument explaining\nthis limit.\n\nThanks for catching this Karl! ",
            "author": "Michael McCandless",
            "id": "comment-12520744"
        }
    ]
}