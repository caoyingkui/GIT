{
    "id": "LUCENE-8240",
    "title": "Make TokenStreamComponents.setReader public",
    "details": {
        "labels": "",
        "priority": "Major",
        "resolution": "Unresolved",
        "affect_versions": "None",
        "status": "Open",
        "type": "Wish",
        "components": [
            "modules/analysis"
        ],
        "fix_versions": []
    },
    "description": "The simplest change for this would be to make TokenStreamComponents.setReader() public. Another alternative would be to provide a SubFieldAnalyzer along the lines of what is attached, although for reasons given below I think this implementation is a little hacky and would ideally be supported in a different way before making that part of a public Lucene API.\n\nExposing this method would allow a third-party extension to access it in order to wrap TokenStreamComponents. My use case is a SubFieldAnalyzer (attached, for reference) that applies different analysis to different instances of a field. This supports a big \"catch-all\" field that has different (index-time) text processing. The way we implement that is by creating a TokenStreamComponents that wraps separate per-subfield components and switches among them when setReader() is called.\n\nWhy setReader()? This is the only part of the API where we can inject this notion of subfields. setReader() is called with a Reader for each field instance, and we supply a special Reader that identifies its subfield.\n\nThis is a bit hacky \u2013 ideally subfields would be first-class citizens in the Analyzer API, so eg there would be methods like Analyzer.createComponents(String fieldName, String subFieldName), etc. However this seems like a pretty big change for an experimental feature, so it seems like an OK tradeoff to live with the Reader-per-subfield hack for now.\n\nCurrently SubFieldAnalyzer has to live in org.apache.lucene.analysis package in order to call\u00a0TokenStreamComponents.setReader (on a separate instance) and propitiate java's code-hiding rules, which is awkward.",
    "attachments": {
        "SubFieldAnalyzer.java": "https://issues.apache.org/jira/secure/attachment/12917692/SubFieldAnalyzer.java"
    },
    "issue_links": {},
    "comments": [
        {
            "id": "comment-16426843",
            "date": "2018-04-05T12:36:58+0000",
            "content": "If you have different analysis chains for sub fields, how do you know how to analyze queries? ",
            "author": "Adrien Grand"
        },
        {
            "id": "comment-16426854",
            "date": "2018-04-05T12:45:02+0000",
            "content": "Right, you can use this to distinguish index-time differences only. In our case it's used to apply different synonyms to different subfields, and then we don't apply synonyms at query time. There are other possible uses I think; eg you could apply language-specific tokenization at index time to different subfields, but you might not know the intended language at query time, so you have to use a more general tokenizer. I don't know how useful that would be in practice - haven't tried it; you'd have different expectations of the user, at query time, than your documents.\u00a0 Maybe a better example would be WordDelimiter \u2013 you might want to apply token splitting and recombination on number parts to a subfield that is a part number, but not to other subfields, and then at query time, you could do only the splitting \u2013 it is already asymmetric, usually. ",
            "author": "Mike Sokolov"
        },
        {
            "id": "comment-16426899",
            "date": "2018-04-05T13:08:42+0000",
            "content": "Ok, I understand your use-case now. I'm not sure I'm up to making it easy to do this kind of things, for instance knowing the text content and the analyzer is not enough to know how a field got analyzed, you'd also need to know what sub field name was provided. I'm wondering that you may be able to do what you want with the current API by creating a Tokenizer wrapper that sets the current sub field name in a custom attribute, and then have a custom synonym filter that applies different synonyms depending on the current field, which it can read thanks to the custom attribute? ",
            "author": "Adrien Grand"
        },
        {
            "id": "comment-16426969",
            "date": "2018-04-05T14:04:25+0000",
            "content": "Yes, a custom SynonymFilter would do it, but the logic in SynonymGraphFilter today is pretty complex, and to \"wrap\" it we would need to copy and take over maintaining a fork of that class since it can't be subclassed. I like to try to avoid forking code when I can \u2013 what if someone makes a nice enhancement to that in the future?\n\nAnother thing I tried, using a SubFieldAttribute to indicate the sub-field, was a SwitchTokenFilter that would pull from different upstream SynonymGraphFilters, all sharing the same source TokenStream. I eventually got this working, but it was tricky since eg you need to reset() all the components only once, and you need to inject a subfield-switch token as a distinct meta-event in the token stream with no characters or position change, in order to give the SwitchTokenFilter a chance to draw the next token from the correct stream.\nknowing the text content and the analyzer is not enough to know how a field got analyzed\nI'm not sure I understand this concern. When do we need to know this? Well it is true that in our case we do care, not so much about which analysis was used, but which sub-field some tokens belong to, because we use that information for scoring. So we store a positional mapping to enable that, but it isn't necessary to support the analysis. ",
            "author": "Mike Sokolov"
        },
        {
            "id": "comment-16427001",
            "date": "2018-04-05T14:20:37+0000",
            "content": "I think I am missing the high level use case here. Why do we need to add such complexity to the analysis api? Its already too complex. ",
            "author": "Robert Muir"
        },
        {
            "id": "comment-16427014",
            "date": "2018-04-05T14:25:41+0000",
            "content": "Maybe the proposed change got lost in all the discussion. All I am proposing here is to change the visibility of TokenStreamComponents.setReader(Reader) from `protected` to `public`. ",
            "author": "Mike Sokolov"
        },
        {
            "id": "comment-16427033",
            "date": "2018-04-05T14:37:56+0000",
            "content": "But I don't think we should do that without good reason: and i don't see that yet. ",
            "author": "Robert Muir"
        },
        {
            "id": "comment-16428854",
            "date": "2018-04-06T19:52:35+0000",
            "content": "Well, I don't have much more to say, but perhaps this background from our use case will sway you  We did try breaking up our large catchall field into separate fields, since it is more natural for Lucene than having these sub-fields. However we have so many of them (100s) that the performance of our queries was poor due to the zillions of term queries we had to generate, and in the end smooshing all these little fields together into one big one, with this switchable analyzer ended up being the best tradeoff. ",
            "author": "Mike Sokolov"
        }
    ]
}