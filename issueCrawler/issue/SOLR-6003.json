{
    "id": "SOLR-6003",
    "title": "JSON Update increment field with non-stored fields causes subtle problems",
    "details": {
        "affect_versions": "4.7.1",
        "status": "Closed",
        "fix_versions": [],
        "components": [
            "update"
        ],
        "type": "Bug",
        "priority": "Major",
        "labels": "",
        "resolution": "Not A Problem"
    },
    "description": "In our application we have large multi-field documents.  We occasionally need to increment one of the numeric fields or add a value to a multi-value text field.  This appears to work correctly using JSON update.  But later we discovered that documents were disappearing from search results and eventually found the documentation that indicates that to use field modification you must store all fields of the document.\n\nPerhaps you will argue that you need to impose this restriction \u2013 which I would hope could be overcome because of the cost of us having to store all fields.  But in any case, it would be better for others if you could return an error if someone tries to update a field on documents with non-stored fields.",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "author": "Erick Erickson",
            "id": "comment-13976359",
            "date": "2014-04-22T04:21:50+0000",
            "content": "I see what you're asking, but I'm not at all clear that it's a good idea. It's perfectly reasonable to have fields that are not stored and still use atomic updates, consider copyField directives for instance. There's no need to store the destination fields for atomic updates to work fine.\n\nYou'd need to have conditions like, \"Return an error if any field is not stored and it's not the destination of a stored field that's a copyField\", which starts to get very error-prone.\n\nThere's work being done  on updates that do not require fields to be stored, but I don't know how that's going.... "
        },
        {
            "author": "Kingston Duffie",
            "id": "comment-13976395",
            "date": "2014-04-22T05:09:17+0000",
            "content": "Yes, you've describes this more precisely than I did.  Thanks.  I searched\nfor items in Jira about updates but didn't find anything about work going\non to eliminate the need to store fields, but didn't find anything.  Until\nthen, I suspect that I won't be the last guy burned by this limitation \u2013\nthinking that their updates worked, only to discover that some non-stored\nfields get blown away \u2013 even though those weren't the ones that were\nupdated.\n\nAs you say, it would be good to detect and report an error.  And, I\nbelieve, this situation can be checked once at the time when the schema is\nfirst used to create the collection/core, so that this flag can be checked\non any update request.\n\n\n "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13976789",
            "date": "2014-04-22T13:52:38+0000",
            "content": "see: https://issues.apache.org/jira/browse/LUCENE-4258\n\nbq: ..this situation can be checked once at the time when the schema is first used to create the collection/core...\n\nIt's still a \"false error\".\n\nHow would you distinguish a situation where atomic updates were not being used from one that did? There's nothing in the schema itself that says \"we're going to use atomic updates\", it's purely how the index is going to be used. So there'd be nothing to check. \n "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-13976824",
            "date": "2014-04-22T14:29:07+0000",
            "content": "How would you distinguish a situation where atomic updates were not being used from one that did?\n\nIf we were to scan the schema for atomic update suitability when the schema object is created or updated, we could set a flag in the schema object.\n\nThen we could log a warning message each time an atomic update is done against a schema that doesn't meet the criteria.  Someone might have a situation where the unstored fields are included with every update.  If it is too expensive to detect that situation, we can provide a config option to turn off the warning. "
        },
        {
            "author": "Kingston Duffie",
            "id": "comment-13976878",
            "date": "2014-04-22T14:59:14+0000",
            "content": "Sorry.  I wasn't clear enough.  I meant that SOLR could set a flag when the\ncore is loaded by looking at the schema and know that it is one where field\nupdates shouldn't be permitted.  Based on that flag, when it receives a\nfield update request, it could reject it without having to review the\nschema each time.\n\nAnyway, the argument is moot for me, personally, as now that we're aware of\nthis limitation we will obviously avoid it.  I was just concerned about\nthose that follow me.\n\n\n "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-13980415",
            "date": "2014-04-24T22:43:14+0000",
            "content": "\"I thought of it later\" followup: Instead of a flag, put a Collection<String> field (which we might want to explicitly declare as a Set) in the schema object that contains all the field names that must be present in an atomic update request to avoid data loss.  Log a warning if any of those fields are missing from an atomic update. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13980465",
            "date": "2014-04-24T23:19:00+0000",
            "content": "Hmmm, why not just an additional flag on the field you're declaring? Bad name, but \"requiredToBeStored\". Which I'm suggesting entirely facetiously because we already have 'stored=\"true\" '.\n\nThe problem with anything along these lines IMO is that requiring the user to somehow mark  the list of fields required for atomic updates in the schema or \"specially tagging\" the field require the user to already understand how  atomic updates work. The original problem statement, as I read it, was to be able to have this happen automagically. It all seems like it would require maintenance in addition to the initial effort to no good purpose. "
        },
        {
            "author": "Kingston Duffie",
            "id": "comment-13980496",
            "date": "2014-04-24T23:35:41+0000",
            "content": "I agree.  Our ultimate goal, of course, is just to remove the restriction that all non-copied fields must be stored if you want to use field updates on any field.  Until we get there, the spirit of SOLR-6003 is simply to report an error to those systems that may try to use field updates on a schema that can't support it.  \n\nMy own experience was that since I was unaware of this rather obscure restriction, we thought field updates were working just fine.  Only later did we discover that certain queries (but not all!) were failing to find documents based on certain fields.  I thought if there were a simple change that detected the situation and produced an error, the next guy wouldn't have to suffer as I did.  Admittedly, \"read the documentation\" is a reasonable answer.  I wish I had. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13980506",
            "date": "2014-04-24T23:45:31+0000",
            "content": "Kingston:\n\nYeah, there's an awful lot of \"tribal knowledge\" in Solr/Lucene. Partly that's a result of the speed that some of the mad people code at (yes, I'm a bit jealous)...\n\nI'm sympathetic to the idea, I just don't see a good way to make it work given that atomic updates are entirely a request-time construct. We don't require one to declare \"I intend to use atomic updates\". And unless we do require such a thing, I don't see any way to enforce letting the user know that not enough fields are stored to work as expected. I suppose a flag in the schema like <safeAtomicUpdate>true|false</safeAtomicUpdate> could trigger such effort but it'd have to default to \"false\" in order to not break existing applications. And again, for a user to know that they needed to set it to \"true\" implies they're aware of this limitation so having such a flag may well not have saved you since you would have to turn it on....\n\nFWIW "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-13980513",
            "date": "2014-04-24T23:54:11+0000",
            "content": "I have not looked at the code that generates the schema object from schema.xml, so I'm not familiar with the actual object names or the methods.  Here's an extreme simplification of my idea with simple variable names and objects/methods that probably do not correspond to what's really in the schema object.  When the schema object is created:\n\n\nSet<String> atomicUpdateRequiredFields = new HashSet<>();\nforeach (Field f : fields) {\n  if (! f.isCopyfieldDestination()) {\n    if (! f.isStored()) {\n      atomicUpdateRequiredFields.add(f.name());\n    }\n  }\n}\n\n\n\nWhen an Atomic Update request arrives, the update processor will retrieve atomicUpdateRequiredFields (or whatever we call it).  If the update does not include all of those fields (or actions on any of those fields attempt to use add/inc/remove instead of set/removeAll), we log a warning.  The warning will include the uniqueKey value and all field names that were bad/missing.\n\nWhen the user goes to their log to find out why they are missing data, they'll have log entries that clearly explain the problem.  A configuration option could be created that will fail such updates instead of logging a warning. "
        },
        {
            "author": "Kingston Duffie",
            "id": "comment-13980522",
            "date": "2014-04-25T00:01:25+0000",
            "content": "Shawn,\n\nUnless I'm mistaken, the field that you ask to update is unrelated to the\nfield list you are building.  Suppose I have a stored field, A, and an\nunstored field, B.  (No copy fields at all.)  Both fields are index=true.\n If you perform an update on field A, you may lose the index information\nabout field B (because it doesn't have that content to reindex).\n\nSo I believe your logic could be much simpler:\n\n\nboolean fieldUpdatesPermissible = true;\nforeach (Field f : fields) {\n  if (! f.isCopyfieldDestination()) {\n    if (! f.isStored()) {\n      fieldUpdatesPermissible = false;\n      break;\n    }\n  }\n}\n\n\n\n\n "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13980531",
            "date": "2014-04-25T00:15:50+0000",
            "content": "if i'm correctly following the gist of what you guys are aiming for, the \"warn/fail if it looks like they shouldn't be using atomic updates\" type logic you are imagining doesn't account for dynamicFields, or the use cases i've seen in the wild where users deliberately have non-stored fields (to save space) that they might replace with new values on atomic update, or they just leave the field out of the update as a way to remove the value. (a deliberate choice of one or the other is made by their update client on every update)\n\nI think at the end of the day, nothing we can imagine doing to try and help people with this type of problem is going to overcome the problem shawn & erick already alluded to: any sort of configuration/warning/setting to help Solr know what type of situation is \"not ok\" is something the user would have to explicitly set, which would require the user to know about the limitation in the first place, which would eliminate the need for any special configuration/warning/setting.\n\n(The one exception to this might be situations where the user conifiguring solr is aware of the situation, but wants to leave some fields non-stored and needs a way to fail \"incomplete\" updates that don't specify those fields - that could be done fairly easily with an UpdateProcessor)\n "
        },
        {
            "author": "Kingston Duffie",
            "id": "comment-13980539",
            "date": "2014-04-25T00:25:24+0000",
            "content": "Based on remarks from Hoss Man and Erick, I'm starting to question whether\nI even understand the current limitation correctly.  My understanding\n(based on my own experience) is that atomic updates do not work *even if\nthe field being updated is stored*.  It appears that other non-stored\nfields are lost as part of the update.\n\nIs my understanding incorrect on this point?\n\nIf not, then I can't understand a realistic use case \"in the wild\" where\nsomeone has a non-stored field that is indexed but doesn't care if it is\nlost when they update some other field.  My claim is that if you have a\nschema that has at least one indexed but unstored field, SOLR could safely\nreturn an error for an update request.  No?\n\n(I apologize in advance if I'm simply beating a dead horse here.)\n\n\n "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13980661",
            "date": "2014-04-25T03:48:24+0000",
            "content": "bq:  ...is that atomic updates do not work even if the field being updated is stored...\n\nOK, maybe we're getting close to the issue here. This should absolutely work. A stored field will be preserved when you do an atomic update, you just have to be careful that you use \"set\" or \"add\" appropriately if you intention is that you replace all the existing values in a field with the new value or add another value to the field.... "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-13981032",
            "date": "2014-04-25T13:53:17+0000",
            "content": "Hoss is right: I had not considered dynamic fields.\n\nIt should be possible to detect the general case of \"this schema might be unsuitable\" even with dynamic fields, as Kingston Duffie described in his code example.  My code example was trying to detect the specific case of \"this particular atomic update WILL lose data with the current schema.\"  Because I haven't examined the code yet, I do not know how difficult dynamic field support will be.\n\nBecause they are probably easy, a combination of the general case with dynamic fields and the specific case with explicit fields would be a good starting point.  Test cases will be required.  After that's done, hopefully dynamic fields can be fully supported in the specific case, eliminating the need for the general case. "
        },
        {
            "author": "Kingston Duffie",
            "id": "comment-13981067",
            "date": "2014-04-25T14:43:09+0000",
            "content": "Erick,  I was referring to the section on Stored Values in Caveats and Limitations on this page:  https://wiki.apache.org/solr/Atomic_Updates  where it says that ALL non-copy fields must be stored.  But perhaps I'm reading more into that than is actually required.  If it will work to store ONLY those fields that may be updated, that would be a huge savings for us.  I'm unfamiliar with the implementation.  Can you confirm based on your understanding that only fields that may be updated need to be stored?  If so, it would be great to update the documentation accordingly. "
        },
        {
            "author": "Jack Krupansky",
            "id": "comment-13981086",
            "date": "2014-04-25T15:07:02+0000",
            "content": "It sounds like a separate Jira should be filed for some of these broader discussions.\n\nThis specific Jira should focus on the specific issue of \"increment\" for a non-stored field, and \"append\" to a non-stored multivalued field. Clearly this case should produce an exception since it can't possibly do anything reasonable since it needs to access the previous value before applying the increment or append. "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-13981117",
            "date": "2014-04-25T15:18:58+0000",
            "content": "Kingston Duffie, you are reading it correctly.\n\nWhen an atomic update request is made, the first thing the code does is use the uniqueKey value to query the index, then use the stored fields found in the index to populate the new SolrInputDocument object.  At this point, any field that is not stored will not be present in the new SolrInputDocument.  Once the new document is populated, the atomic update operations are applied.\n\nIf you are using \"set\" as your action, it would not be a problem for that field to be unstored.  I believe a \"removeAll\" action is planned for a future release, and that would also not be a problem with an unstored field.\n\nWhen the action is \"add\" or \"inc\", there is an assumption of an existing value in the field.  A new \"remove\" action is already in the code for Solr 4.9, which also has an assumption of an existing value.\n\nIt would be a MAJOR change (probably at both the Solr and the Lucene levels) to support updating a document containing unstored fields without providing the values for those fields.  It would be even harder (possibly impossible) to support doing add/inc/remove options on a field that's not stored. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13981164",
            "date": "2014-04-25T15:42:15+0000",
            "content": "Kingston:\n\nSorry, I added to the confusion; Shawn's comment is spot on.\n\nJust to make my position on this clear, I do NOT think this kind of \"check if schema doesn't support updates because not enough fields are stored and throw an exception\" is worth the effort. While I'm an advocate of \"fail early and fail often\", this just doesn't seem like \n1> it's going to be as easy as one might think. We've already seen the effort expand with dynamic fields, what else is lurking?\n2> is going to be trivial to maintain\n3> is worth the risk of screwing it up and making perfectly valid, carefully thought out installations start failing because we suddenly decide to enforce rules that have never been in the contract.\n4> is at all worth the complexification of the code.\n\nAnd assuming the \"stacked updates\" ever actually happens at the Lucene level, this will all go away anyway....\n\nIn particular, I'm -1,000 on anything more onerous than a warning coming out in the log files, that ideally could be turned off via configuration in the schema. I'm not convinced that just a warning would have helped Kingston & Co. in this case anyway, there's a lot of info that comes out in the log file at startup, might just have been lost in the noise.\n\nFWIW "
        },
        {
            "author": "Kingston Duffie",
            "id": "comment-13981177",
            "date": "2014-04-25T15:53:15+0000",
            "content": "Shawn, your comment seems inconsistent to me.  You say, \"you are reading it\ncorrectly\", which tells me that you agree that ALL indexed fields must be\nstored even if you are only updating one specific field that is stored.\n However you go on to say that, \"... it would not be a problem for that\nfield to be unstored\" (as long as the action is \"set\").\n\nAgain, I'm feeling like I may just be missing something.  It makes perfect\nsense to me that field updates to stored fields should not cause a problem\neven if other indexed fields are not stored.  However, that's not what the\ndocumentation says.  It says, (and I quote):\n\n\"The core functionality of atomically updating a document requires that all\nfields in your SchemaXml <https://wiki.apache.org/solr/SchemaXml> must be\nconfigured as stored=\"true\" except for fields which are <copyField/>\ndestinations\n\u2013 which must be configured as stored=\"false\". This is because the atomic\nupdates are applied to the document represented by the existing stored\nfield values.\"\n\nI assumed that this meant that after the update is applied, the full\ndocument is reindexed and if indexable fields are not all present at that\ntime, then that information will be lost in the index.\n\nThis whole bug is premised on this assumption of mine \u2013 i.e., that it is\ntrivial to unambiguously detect this situation and report an error.  But if\nthis assumption is incorrect, I will be delighted \u2013 because in my case I\nhave one small field that needs to be updated, while I would strongly\nprefer not to have to store other large fields that I index.  (Think about\nchanging tags associated with large documents where the body of the\ndocument will never change, but tags associated with the document will be\nupdated later.  I'd rather not store the document body.)\n\n\n "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13981212",
            "date": "2014-04-25T16:27:20+0000",
            "content": "OK, we're getting lost in the vagaries of English.\n\nHere's a rule of thumb that I use. You must store all fields when using atomic updates that are not the destination of a copyField directive. If you don't, any data associated with a non-stored field that is not the destination of a copyField directive will be lost.\n\nHow's that? "
        },
        {
            "author": "Kingston Duffie",
            "id": "comment-13981230",
            "date": "2014-04-25T16:45:25+0000",
            "content": "Sounds unambiguous, but I want to be sure because of comments from others\non this thread.  Consider this hypothetical schema:\n\nfield A:  indexed=true, stored=true\nfield B:  indexed=true, stored=false\n\nThere are no copyFields at all.\n\nWith this schema, if I do an atomic update to field A on a given document,\nsay, {a : {set : \"newvalue\"}}, I will lose information in the index about\nfield B for that document.  Correct?\n\n\n "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-13981265",
            "date": "2014-04-25T17:15:18+0000",
            "content": "With this schema, if I do an atomic update to field A on a given document, say, {a : {set : \"newvalue\"}}, I will lose information in the index about field B for that document. Correct?\n\nCorrect.\n\n "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13981280",
            "date": "2014-04-25T17:28:47+0000",
            "content": "With this schema, if I do an atomic update to field A on a given document, say, {a : {set : \"newvalue\"}}, I will lose information in the index about field B for that document. Correct?\n\nCorrect: but that may have been your intent when designing that schema.  You may have set it up that way precisely because you know that anytime you update a document you will either be explicitly supplying a replacement value for field \"b\", or deliberately excluding a value for field \"b\" so that the current field goes away.\n\nThis is what i was refering to in my earlier comment...\n\n...or the use cases i've seen in the wild where users deliberately have non-stored fields (to save space) that they might replace with new values on atomic update, or they just leave the field out of the update as a way to remove the value. (a deliberate choice of one or the other is made by their update client on every update)\n\njust because an atomic update causes information to be removed from a non-stored field, doesn't mean that removal isn't a deliberate part o the use case\n\n\u2014\n\nThis specific Jira should focus on the specific issue of \"increment\" for a non-stored field, and \"append\" to a non-stored multivalued field. Clearly this case should produce an exception since it can't possibly do anything reasonable since it needs to access the previous value before applying the increment or append.\n\nAgreed - we can't, in general, make assumptions about failing any atomic update just because some fields in the schema aren't stored \u2013 but i don't see any reason why we can't fail in some specific cases of things like  \"inc\" or \"remove\" directly on non-stored fields. (I'm surprised we aren't already) "
        },
        {
            "author": "Kingston Duffie",
            "id": "comment-13981295",
            "date": "2014-04-25T17:37:23+0000",
            "content": "Hoss Man, you make an excellent point that I was simply failing to think\nabout \u2013 the case that someone may be fine if their existing indexed\ncontent is lost for a non-stored field \u2013 typically because they will be\nproviding new information, if necessary, for that field and others.  Thanks\nfor helping me understand.  With that in mind, I'm fine in closing this\nissue \u2013 while also even more strongly looking forward to improvements in\nthis area in future.\n\n\n "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13981324",
            "date": "2014-04-25T17:57:32+0000",
            "content": "Closing as per Kingston's OK. "
        }
    ]
}