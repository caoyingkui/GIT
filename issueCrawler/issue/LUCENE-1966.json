{
    "id": "LUCENE-1966",
    "title": "Arabic Analyzer: Stopwords list needs enhancement",
    "details": {
        "labels": "",
        "priority": "Trivial",
        "components": [
            "modules/analysis"
        ],
        "type": "Improvement",
        "fix_versions": [
            "3.0"
        ],
        "affect_versions": "2.9",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "The provided Arabic stopwords list needs some enhancements (e.g. it contains a lot of words that not stopwords, and some cleanup) . patch will be provided with this issue.",
    "attachments": {
        "LUCENE-1966.patch": "https://issues.apache.org/jira/secure/attachment/12421683/LUCENE-1966.patch",
        "arabic-stopwords-comments.txt": "https://issues.apache.org/jira/secure/attachment/12421682/arabic-stopwords-comments.txt"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2009-10-08T23:07:39+0000",
            "content": "Please see the arabic-stopwords-comments.txt to see my comments on the list, and why/what did I change.\n\nThe patch provides an updated Arabic stopwords file, and modifies ArabicAnalyzer to filter stopwords after the normalization, as the provided list is a normalized Arabic stop words.\n\nBest, ",
            "author": "Basem Narmok",
            "id": "comment-12763744"
        },
        {
            "date": "2009-10-09T01:04:09+0000",
            "content": "Basem, thanks for the patch, and the comments.\n\nOne thing I noticed: if I apply the patch, \u0639\u0644\u0649 (the stopword) will not be filtered as a stopword. This is because it will be normalized to \u0639\u0644\u064a (the name).\n\nSo, if we are going to normalize before stopfilter, I think we need to make sure the stopwords do not contain yeh without dots, or else these will not work. This is one example of why I was scared to apply normalization before stopwords, because by doing so, we cause \u0639\u0644\u0649 and \u0639\u0644\u064a to conflate.\n\nLet me know what you think about this. ",
            "author": "Robert Muir",
            "id": "comment-12763774"
        },
        {
            "date": "2009-10-11T09:36:35+0000",
            "content": "Robert, you are correct, to solve the problem we have two options: \n1- to remove words like \u0639\u0644\u064a and \u0648\u0641\u064a\n2- to use unnormalized stiowirds list, before the normalization filter.\n\nI think the best is the second option, so this patch only modifies the list (unnormalized), please try it. ",
            "author": "Basem Narmok",
            "id": "comment-12764442"
        },
        {
            "date": "2009-10-11T13:34:21+0000",
            "content": "Basem, thanks. I like the new list.\n\nI have one very minor question: in the list we have \u0623\u064a\u0636\u0627 / \u0627\u064a\u0636\u0627 twice.\n\nI wanted to check with you, is this by accident or did you have some other spellings in mind?\n\nIf it is by accident, let me know, I can just remove the duplicates before committing. ",
            "author": "Robert Muir",
            "id": "comment-12764449"
        },
        {
            "date": "2009-10-11T14:53:08+0000",
            "content": "Hi Robert,\n\nRegarding \u0627\u064a\u0636\u0627 / \u0623\u064a\u0636\u0627 ...\n\nNo, not by accident, I included both formats (normalized,unnormalized). Arabic users tend to use both on the internet (different spellings), another example is words like \u0623\u064a / \u0627\u064a ",
            "author": "Basem Narmok",
            "id": "comment-12764456"
        },
        {
            "date": "2009-10-11T15:01:37+0000",
            "content": "Basem, I meant: there are two entries for \u0623\u064a\u0636\u0627 , and two entries for \u0627\u064a\u0636\u0627 (total of four)\n\nedit: here are the relevant line numbers from the new stopwords.txt:\n\nLines 72 and 73:\n\n\u0627\u064a\u0636\u0627\n\u0623\u064a\u0636\u0627\n\n\n\nLines 123 and 124:\n\n\u0627\u064a\u0636\u0627\n\u0623\u064a\u0636\u0627\n\n ",
            "author": "Robert Muir",
            "id": "comment-12764462"
        },
        {
            "date": "2009-10-11T15:32:18+0000",
            "content": "Basem I can simply remove 123 & 124 if this is the case, but I did not want to do this without checking first.\n\nThe reason is, I wonder if perhaps you intended for these two to be \u0623\u064a\u0636\u0627\u064b and \u0627\u064a\u0636\u0627\u064b (with fathatan) ",
            "author": "Robert Muir",
            "id": "comment-12764465"
        },
        {
            "date": "2009-10-11T17:21:35+0000",
            "content": "Oh, my mistake, sorry, yes please remove the last two on 123 & 124.\n\nno, they are just duplicate of the ones on line 72 & 73\n ",
            "author": "Basem Narmok",
            "id": "comment-12764493"
        },
        {
            "date": "2009-10-11T17:25:52+0000",
            "content": "Basem, ok! Thanks a lot for your help here. I will commit soon. ",
            "author": "Robert Muir",
            "id": "comment-12764495"
        },
        {
            "date": "2009-10-11T18:25:33+0000",
            "content": "before I commit this, I want to solicit any comments/concerns about backwards compat, assuming the following notice:\n\n\nChanges in runtime behavior\n\n * LUCENE-1966: Modified and cleaned the default Arabic stopwords list used\n   by ArabicAnalyzer. You'll need to fully re-index any previously created \n   indexes.  (Basem Narmok via Robert Muir)\n\n\n\ni know contrib has no bw compat guarantee, but just want to double-check. \nPerhaps in the future someone might help fix the Persian stopwords file also so this may happen again  ",
            "author": "Robert Muir",
            "id": "comment-12764501"
        },
        {
            "date": "2009-10-11T22:22:19+0000",
            "content": "Seems good.\n\nBTW with FAST ESP we never used stopwords, as hits from stopwords get low relevancy (keywords with high number of hits = low value, low importance, so less relevant), so such hits will never get into the top results. Also, using stopwords will affect phrase search, most of the search engines avoid removing them. But, at the end it depends on the client's application, and what she really wants, as enterprise search could have very specific and different needs than Internet search.\n\nAnyways, still I am testing the Arabic Analyzer, and I will provide you with more comments soon. but for the stopwords they are good for now  ",
            "author": "Basem Narmok",
            "id": "comment-12764515"
        },
        {
            "date": "2009-10-11T22:52:38+0000",
            "content": "Basem, yes I think the improvements are good.\n\nMy question is really: is it OK to commit this for 3.0 or should we wait for 3.1? ",
            "author": "Robert Muir",
            "id": "comment-12764519"
        },
        {
            "date": "2009-10-14T12:24:48+0000",
            "content": "Committed revision 825110.\n\nThanks Basem! ",
            "author": "Robert Muir",
            "id": "comment-12765537"
        }
    ]
}