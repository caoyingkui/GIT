{
    "id": "LUCENE-7674",
    "title": "java.lang.IllegalStateException: Child query must not match same docs with parent filter. Combine them as must clauses (+) to find a problem doc. docId=2147483647, class org.apache.lucene.search.ConjunctionScorer",
    "details": {
        "labels": "",
        "priority": "Major",
        "resolution": "Unresolved",
        "affect_versions": "6.3",
        "status": "Open",
        "type": "Bug",
        "components": [],
        "fix_versions": []
    },
    "description": "Started seeing this error message on a production Solr 6.3.0 system today making use of parent/child documents:\n\n\njava.lang.IllegalStateException: Child query must not match same docs with parent filter. Combine them as must clauses (+) to find a problem doc. docId=2147483647, class org.apache.lucene.search.ConjunctionScorer\n    at org.apache.lucene.search.join.ToParentBlockJoinQuery$BlockJoinScorer.checkOrthogonal(ToParentBlockJoinQuery.java:403)\n    at org.apache.lucene.search.join.ToParentBlockJoinQuery$BlockJoinScorer.access$400(ToParentBlockJoinQuery.java:206)\n    at org.apache.lucene.search.join.ToParentBlockJoinQuery$BlockJoinScorer$1.nextDoc(ToParentBlockJoinQuery.java:327)\n    at org.apache.lucene.search.Weight$DefaultBulkScorer.scoreAll(Weight.java:219)\n    at org.apache.lucene.search.Weight$DefaultBulkScorer.score(Weight.java:172)\n    at org.apache.lucene.search.BulkScorer.score(BulkScorer.java:39)\n    at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:669)\n    at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:473)\n    at org.apache.solr.search.DocSetUtil.createDocSetGeneric(DocSetUtil.java:106)\n    at org.apache.solr.search.DocSetUtil.createDocSet(DocSetUtil.java:95)\n    at org.apache.solr.search.SolrIndexSearcher.getDocSetNC(SolrIndexSearcher.java:1379)\n    at org.apache.solr.search.SolrIndexSearcher.getPositiveDocSet(SolrIndexSearcher.java:1057)\n    at org.apache.solr.search.SolrIndexSearcher.getProcessedFilter(SolrIndexSearcher.java:1227)\n    at org.apache.solr.search.SolrIndexSearcher.getDocListAndSetNC(SolrIndexSearcher.java:1842)\n    at org.apache.solr.search.SolrIndexSearcher.getDocListC(SolrIndexSearcher.java:1616)\n    at org.apache.solr.search.SolrIndexSearcher.search(SolrIndexSearcher.java:617)\n    at org.apache.solr.handler.component.QueryComponent.process(QueryComponent.java:531)\n    at org.apache.solr.handler.component.SearchHandler.handleRequestBody(SearchHandler.java:295)\n    at org.apache.solr.handler.RequestHandlerBase.handleRequest(RequestHandlerBase.java:153)\n    at org.apache.solr.core.SolrCore.execute(SolrCore.java:2213)\n    at org.apache.solr.servlet.HttpSolrCall.execute(HttpSolrCall.java:654)\n    at org.apache.solr.servlet.HttpSolrCall.call(HttpSolrCall.java:460)\n    at org.apache.solr.servlet.SolrDispatchFilter.doFilter(SolrDispatchFilter.java:303)\n    at org.apache.solr.servlet.SolrDispatchFilter.doFilter(SolrDispatchFilter.java:254)\n    at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1668)\n    at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:581)\n    at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)\n    at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)\n    at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)\n    at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1160)\n    at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:511)\n    at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)\n    at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1092)\n    at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n    at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)\n    at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)\n    at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)\n    at org.eclipse.jetty.server.Server.handle(Server.java:518)\n    at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:308)\n    at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:244)\n    at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:273)\n    at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:95)\n    at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)\n    at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceAndRun(ExecuteProduceConsume.java:246)\n    at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:156)\n    at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:654)\n    at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:572)\n    at java.lang.Thread.run(Thread.java:745)\n\n\n\nThe \"docId=2147483647\" part seems suspicious since that corresponds to Integer.MAX_VALUE and my index only has 102,013,289 docs in it.  According to the Solr searcher stats page I have:\n\nnumDocs: 71,870,998\nmaxDocs: 102,013,289\ndeletedDocs: 30,142,291\n\nI took the query that was failing and attempted to intersect my parent query with the child query to find any problem docs but that came back with 0 results.\n\nAfter performing an optimize (via the Solr UI) on the index the problem has gone away and the query that previously triggered this error works as it should.",
    "attachments": {
        "LUCENE-7674-attempt-to-reproduce.patch": "https://issues.apache.org/jira/secure/attachment/12853143/LUCENE-7674-attempt-to-reproduce.patch",
        "LUCENE-7674.patch": "https://issues.apache.org/jira/secure/attachment/12850892/LUCENE-7674.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "id": "comment-15850611",
            "date": "2017-02-02T22:22:54+0000",
            "content": "This particular error means that there is a problem in the way your index is structured since you had at least one segment that did not have a parent doc as a last document. This is wrong because block joins work on blocks of documents that contain 0-n children followed by one parent so the last document is necessarily a parent document. ",
            "author": "Adrien Grand"
        },
        {
            "id": "comment-15850640",
            "date": "2017-02-02T22:42:26+0000",
            "content": "Thanks Adrien Grand!  I'm trying to figure out if this an issue on my side (very possible) or if it's a Solr or Lucene issue.\n\nAll my indexing goes through Solr (via SolrJ) and as far as I can tell I'm not attempting to index any child documents without a corresponding parent document.  I'm not even sure if Solr or SolrJ would allow me to do that.\n\nDoes it make sense that optimizing the index would cause the problem to go away?\n\nI think I was able to snag a copy of the index that was causing problems before the optimized version was able to replicate.  Any suggestions/pointers for trying to track down whatever docs are problematic?  Will running CheckIndex on it tell me anything useful? ",
            "author": "Tim Underwood"
        },
        {
            "id": "comment-15851165",
            "date": "2017-02-03T07:11:49+0000",
            "content": "Tim Underwood, it usually happens when uniqueKey is duplicated, it causes deleting former parent doc. \nIt can be verified with org.apache.lucene.search.join.CheckJoinIndex, although it doesn't have main() method. \n\nAdrien Grand, what if will invoke CheckJoinIndex logic lazily somewhere in org.apache.lucene.search.join.QueryBitSetProducer.getBitSet(LeafReaderContext)? It won't cost much as well it should be lazy, but provides more predictable behaviour for users.   ",
            "author": "Mikhail Khludnev"
        },
        {
            "id": "comment-15851858",
            "date": "2017-02-03T18:13:07+0000",
            "content": "Thanks Mikhail Khludnev!  Running CheckJoinIndex on my bad index (assuming I got my parentsFilter right) says:\n\n\njava.lang.IllegalStateException: Parent doc 3324040 of segment _vfo(6.3.0):C28035360/10475131:delGen=86 is deleted but has a live child document 3323449\n\n\n\nRunning CheckJoinIndex on the optimized version of the index doesn't complain.\n\nSo... that leaves me wondering where the bug is.  I am frequently (via Solr) re-indexing parent/child documents that duplicate existing documents based on my unique key field but my understanding is that Solr should automatically delete the old parent and child documents for me.  Maybe thats a bad assumption.\n\nIt looks like maybe I'm running into one or more of these issues: SOLR-5211, SOLR-5772, SOLR-6096, SOLR-6596, SOLR-6700\n\nSounds like I should probably just make sure I explicitly delete any old parent/child documents that I'm replacing to be on the safe side. ",
            "author": "Tim Underwood"
        },
        {
            "id": "comment-15851923",
            "date": "2017-02-03T18:49:32+0000",
            "content": "I also noticed that I have some deleteByQuery calls that target parents documents but not their children (my assumption being that Solr or Lucene would also delete the corresponding child documents).  Perhaps that is what is causing the orphan child documents.  I'll be sure to explicitly delete those also. ",
            "author": "Tim Underwood"
        },
        {
            "id": "comment-15852123",
            "date": "2017-02-03T21:06:54+0000",
            "content": "LUCENE-7674.patch introduces CheckingQueryBitSetProducer which checks parent segment's bitset before caching and switches {!parent} {!child} to use it. It laid well, beside of, and it's interesting! BJQParserTest.testGrandChildren(). When we have three levels: parent, child, grand-child and searching for children (2nd level), it requires to include all ascendant levels (parent) in bitset. This, will break existing queries for those who run more than two level blocks. But such explicitly strict behavior solves problems for those who tires to retrieve intermediate levels by [child] then, I remember a couple of such threads in the list. \nWhat do you think?        \n ",
            "author": "Mikhail Khludnev"
        },
        {
            "id": "comment-15852127",
            "date": "2017-02-03T21:09:29+0000",
            "content": "Tim Underwood, you've got everything right! Thanks for gathering those pet peeves in the list. Here is one more, SOLR-7606 - it's my favorite ones. I need to tackle them sooner or later.  ",
            "author": "Mikhail Khludnev"
        },
        {
            "id": "comment-15855527",
            "date": "2017-02-07T08:01:27+0000",
            "content": "Adrien Grand , Uwe Schindler, what's your opinion about CheckingQueryBitsetProducer and restricting multilevel blocks? ",
            "author": "Mikhail Khludnev"
        },
        {
            "id": "comment-15855698",
            "date": "2017-02-07T10:21:24+0000",
            "content": "It feels wrong to me that we enforce these rules at search time, while they should be enforced at index time. I think the true fix to all these block join issues would be to make Solr know queries that describe the parent and child spaces rather than expect users to provide them at search time. Then once it knows that, it could reject update/delete operations that would break the block structure, fail queries that use a parent query that is not one of the expected ones, maybe add a FILTER clause to the child query to restrict it to the child space in case some fields are used at multiple levels, etc. ",
            "author": "Adrien Grand"
        },
        {
            "id": "comment-15855708",
            "date": "2017-02-07T10:29:39+0000",
            "content": "I agree with Adrien. The current block join support in Solr is a desaster, because it was released to early. Just nuke the broken APIs and create a new one, so Solr internally knows from schema/mapping how to block join and also prevent misformed updates. This is also worth a backwards compatibility break! Doing expensive runtime checks on every query just to keep a broken API/implementation is not a good idea. Break hard and come with a better API, the users will still be more happy, trust me. I know so many users who f*ck up the block joins, as Solr does not enforce it correctly. Do the following:\n\n\tremove Solr ID fields from child documents (why do we have them? This also makes updates to child documents impossible)\n\talways hide child documents on \"normal\" queries and return them only with the parent document (like Elasticsearch does)\n\tautomatically add block join queries if fields of the child documents are part of the query\n\tadd some extra queries to specifically search on childs and return childs only (hiding parents, of course)\n\tif somebody updates a parent document, delete also all childs and create a new block\n\thide the block join filter. Solr should have an internal marker field to support block join, which is never exposed\n\n ",
            "author": "Uwe Schindler"
        },
        {
            "id": "comment-15855777",
            "date": "2017-02-07T11:09:36+0000",
            "content": "Oh.. I've got your point, guys. Thanks. I'd probably raise gsoc ticket and try to scratch backlog.  ",
            "author": "Mikhail Khludnev"
        },
        {
            "id": "comment-15856492",
            "date": "2017-02-07T18:23:32+0000",
            "content": "+1 to Adrien Uwe's remarks.  It was released too early. ",
            "author": "David Smiley"
        },
        {
            "id": "comment-15870765",
            "date": "2017-02-16T22:02:01+0000",
            "content": "Ok. I started to scratch the spec at SOLR-10144. Everybody are welcome. Meanwhile, I tried to reproduce this exact failure to come up with more informative message. But it seems like it's impossible - recently redesigned BlockJoinQuery ignores children behind the last parent in segment.   ",
            "author": "Mikhail Khludnev"
        }
    ]
}