{
    "id": "SOLR-1336",
    "title": "Add support for lucene's SmartChineseAnalyzer",
    "details": {
        "affect_versions": "None",
        "status": "Closed",
        "fix_versions": [
            "3.1",
            "4.0-ALPHA"
        ],
        "components": [
            "Schema and Analysis"
        ],
        "type": "New Feature",
        "priority": "Major",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "SmartChineseAnalyzer was contributed to lucene, it indexes simplified chinese text as words.\n\nif the factories for the tokenizer and word token filter are added to solr it can be used, although there should be a sample config or wiki entry showing how to apply the built-in stopwords list.\nthis is because it doesn't contain actual stopwords, but must be used to prevent indexing punctuation... \n\nnote: we did some refactoring/cleanup on this analyzer recently, so it would be much easier to do this after the next lucene update.\nit has also been moved out of -analyzers.jar due to size, and now builds in its own smartcn jar file, so that would need to be added if this feature is desired.",
    "attachments": {
        "SOLR-1336.patch": "https://issues.apache.org/jira/secure/attachment/12415966/SOLR-1336.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Robert Muir",
            "id": "comment-12740975",
            "date": "2009-08-08T21:28:03+0000",
            "content": "patch, needs lucene-smartcn-2.9-dev.jar added to lib to work (this analyzer is not in the -analyzers.jar anymore) "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12740981",
            "date": "2009-08-08T21:58:12+0000",
            "content": "Thanks Robert!\nAre the stopwords (words=\"org/apache/lucene/analysis/cn/stopwords.txt\") being loaded directly from the jar?  If so, a comment to that effect might prevent some confusion.\n\nDo you happen to know what the memory footprint of this analyzer is if it's used?  I assume the dictionaries will get loaded on the first use.\n\nMight be cool to add a chinese field to example/exampledocs/solr.xml... or maybe there should be an international.xml doc where we could add a few different languages? "
        },
        {
            "author": "Robert Muir",
            "id": "comment-12740988",
            "date": "2009-08-08T22:25:03+0000",
            "content": "\nAre the stopwords (words=\"org/apache/lucene/analysis/cn/stopwords.txt\") being loaded directly from the jar? If so, a comment to that effect might prevent some confusion. \n\nYes, good idea.\n\n\nDo you happen to know what the memory footprint of this analyzer is if it's used? I assume the dictionaries will get loaded on the first use.\n\nNo, I am not sure of the footprint, but it is probably quite large (a few MB). They will be loaded on first use, correct. Also, the smartcn jar file itself is large due to the dictionaries in question. So, you may have noticed solr.war is much smaller after the last lucene update, since it was factored out of analyzers.jar. \n\n\nMight be cool to add a chinese field to example/exampledocs/solr.xml... or maybe there should be an international.xml doc where we could add a few different languages?\n\nI figured this wasn't the best place to have an example... i like the idea of international.xml, with some examples for other languages too.\n\nIf there is some concern about the size of this (monster) analyzer, one option is to put these factories/examples elsewhere, to keep the size of solr smaller.  "
        },
        {
            "author": "Robert Muir",
            "id": "comment-12741003",
            "date": "2009-08-09T01:22:04+0000",
            "content": "add warning about large dictionaries, note that stopwords are being loaded from jar file, and add an international.xml with examples for several languages. "
        },
        {
            "author": "Kumar Raja",
            "id": "comment-12749859",
            "date": "2009-09-01T11:14:28+0000",
            "content": "I applied the patch with the latest Solr code and lucene-rc2 jars and tried indexing the some chinese text. However, i got a AbstractMethodError during tokenization. \nWhat am i doing wrong here?\n\n\nTHE STACK TRACE\n\n \nSEVERE: java.lang.AbstractMethodError\n        at org.apache.solr.analysis.TokenizerChain.tokenStream(TokenizerChain.java:64)\n        at org.apache.solr.schema.IndexSchema$SolrIndexAnalyzer.tokenStream(IndexSchema.java:360)\n        at org.apache.lucene.analysis.Analyzer.reusableTokenStream(Analyzer.java:44)\n        at org.apache.lucene.index.DocInverterPerField.processFields(DocInverterPerField.java:123)\n        at org.apache.lucene.index.DocFieldConsumersPerField.processFields(DocFieldConsumersPerField.java:36)\n        at org.apache.lucene.index.DocFieldProcessorPerThread.processDocument(DocFieldProcessorPerThread.java:234)\n        at org.apache.lucene.index.DocumentsWriter.updateDocument(DocumentsWriter.java:762)\n        at org.apache.lucene.index.DocumentsWriter.updateDocument(DocumentsWriter.java:745)\n        at org.apache.lucene.index.IndexWriter.updateDocument(IndexWriter.java:2199)\n        at org.apache.lucene.index.IndexWriter.updateDocument(IndexWriter.java:2171)\n        at org.apache.solr.update.DirectUpdateHandler2.addDoc(DirectUpdateHandler2.java:218)\n        at org.apache.solr.update.processor.RunUpdateProcessor.processAdd(RunUpdateProcessorFactory.java:60)\n        at org.apache.solr.handler.XMLLoader.processUpdate(XMLLoader.java:140)\n        at org.apache.solr.handler.XMLLoader.load(XMLLoader.java:69)\n        at org.apache.solr.handler.ContentStreamHandlerBase.handleRequestBody(ContentStreamHandlerBase.java:54)\n        at org.apache.solr.handler.RequestHandlerBase.handleRequest(RequestHandlerBase.java:131)\n        at org.apache.solr.core.SolrCore.execute(SolrCore.java:1333)\n        at org.apache.solr.servlet.SolrDispatchFilter.execute(SolrDispatchFilter.java:303)\n        at org.apache.solr.servlet.SolrDispatchFilter.doFilter(SolrDispatchFilter.java:232)\n        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:235)\n\n  "
        },
        {
            "author": "Robert Muir",
            "id": "comment-12749877",
            "date": "2009-09-01T12:28:16+0000",
            "content": "Hi, thanks for testing!\n\nfirst, I am having trouble trying to figure out what is going on here, since it looks like the stack trace is unrelated to smart chinese analyzer.\nits a little bit more difficult since i am looking at the latest solr code and my tokenizerchain:64 is not tokenStream() !\n\nDue to the exception you are getting, I suspect something is out of date... maybe its as simple as 'ant clean'  and recompile? "
        },
        {
            "author": "Kumar Raja",
            "id": "comment-12750340",
            "date": "2009-09-02T08:58:13+0000",
            "content": "Hi Robert,\nSorry...my bad. There was a mix up of the Solr versions on my machine which caused this error.\n\nThis tool is great. It works wonderful and there is a test case pass rate is amazing!!!! Is there a similar tool for other asian languages, say Japanese and Korean? Can this be customized to accomodate those languages?\n\nIs there any wiki link or document to help us understand how this tool works? Sort of behind the scenes.... What exactly does the dictionary contain? Is it any ordinary chinese dictionary or some sort of a customized/lemmatized dictionary? Also, how can one add new words to the dictionary?\n\nThanks,\nKumar "
        },
        {
            "author": "Kumar Raja",
            "id": "comment-12750342",
            "date": "2009-09-02T08:59:03+0000",
            "content": "Since this feature works so well, i think it can easily shipped along with Solr 1.4. \nWhen is this going to be committed to the Solr build? "
        },
        {
            "author": "Robert Muir",
            "id": "comment-12750439",
            "date": "2009-09-02T13:47:44+0000",
            "content": "Can this be customized to accomodate those languages?\nMaybe, but we have to do work first. the dictionary is limited to GB2312 encoding, so we can't add support for new languages until this is fixed.\n\nIs there any wiki link or document to help us understand how this tool works? Sort of behind the scenes....\nThere are some sparse javadocs or code comments. also see the original jira ticket: LUCENE-1629\n\nWhat exactly does the dictionary contain? Is it any ordinary chinese dictionary or some sort of a customized/lemmatized dictionary? \nThere are two dictionaries: word dictionary, and bigram dictionary. \nThese dictionaries contain words and bigrams respectively, along with frequency, in a \"trie\"-like structure organized by chinese character.\n\nAlso, how can one add new words to the dictionary?\nThis is currently really difficult. please see LUCENE-1817 for some background information. \nFor the moment you will have to recompile your own custom jar file, and be familiar with the file formats the analyzer uses.\nNote, we put strong warnings as we would like to change the file formats in an upcoming release, to something based on Unicode.\nThis way, we can support more languages, and perhaps also make it easier to customize the dictionary data "
        },
        {
            "author": "Robert Muir",
            "id": "comment-12750446",
            "date": "2009-09-02T14:03:51+0000",
            "content": "Kumar, by the way, I wanted to mention if by any chance you feel inclined to help us improve this analyzer, please don't hesitate!\n\nThere is so much work to do: dictionary format, code refactoring, better unicode support, among other things.\nEven if you don't want to write any code but have good Chinese & English skills, there are still some javadocs in Chinese that haven't been translated. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-12751146",
            "date": "2009-09-03T20:44:52+0000",
            "content": "we moved some parts of this analyzer around in LUCENE-1882\n\nthis syncs the patch up with lucene trunk (not rc2 as it does not reflect LUCENE-1882). "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12753247",
            "date": "2009-09-09T20:29:18+0000",
            "content": "I was going to check this out, but Lucene 2.9_RC3 doesn't work with Solr - need to wait for RC4.\n\nAny objections to committing this for 1.4 and adding it to the example server, provided we can verify that there isn't a memory cost if it's not used?  The downside is a 3MB jar in solr/lib and in the solr.war "
        },
        {
            "author": "Hoss Man",
            "id": "comment-12754481",
            "date": "2009-09-12T05:05:13+0000",
            "content": "The downside is a 3MB jar in solr/lib and in the solr.war\n\ncontrib?\n\nChinese isn't something everybody needs, and 3MB would almost double the size of the solr.war.  "
        },
        {
            "author": "Robert Muir",
            "id": "comment-12754539",
            "date": "2009-09-12T14:54:39+0000",
            "content": "contrib?\n\nsounds reasonable to me. in a few days i can upload a new patch. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12754541",
            "date": "2009-09-12T15:15:28+0000",
            "content": "I agree it would be an awkward thing to have inside solr.war\nShould we copy to example/solr/lib like the Tika libs are (we already have 32MB of jars there)? "
        },
        {
            "author": "Stanislaw Osinski",
            "id": "comment-12756177",
            "date": "2009-09-16T18:59:14+0000",
            "content": "Keeping the Chinese analyzer JAR optional sounds good. As Carrot2 also uses it, I'd need to make sure the clustering contrib doesn't fail when the JAR is not there and clustering in Chinese is requested (I think I'd simply log a WARN saying that the Chinese analyzer JAR is required for best clustering results). "
        },
        {
            "author": "Robert Muir",
            "id": "comment-12756592",
            "date": "2009-09-17T15:42:43+0000",
            "content": "Thanks, so do we want a contrib (which would mostly just be the jar file + the 2 factories) or should it go in example/solr/lib?\n\nIf we do the latter, where should i put factories? These could be useful if someone wants the chinese analysis to work a little different, \nfor example SmartChineseAnalyzer does porter stemming on english but someone might not want that. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12759611",
            "date": "2009-09-25T16:29:21+0000",
            "content": "I guess it should go into contrib for now...\nwhere should i put factories?\n\nIt would be nice if we could avoid another jar, just for 2 small classes.\nPerhaps we could make them lazy load?  token streams are reused now, so a small reflection overhead is no longer an issue. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-12759616",
            "date": "2009-09-25T16:36:29+0000",
            "content": "\nPerhaps we could make them lazy load? token streams are reused now, so a small reflection overhead is no longer an issue.\n\nIf we do this, then we could avoid a contrib that is really just a jar file? and instead could the jar file just go in the example/solr/lib? "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12759625",
            "date": "2009-09-25T17:02:04+0000",
            "content": "In theory perhaps, but one problem is that example/solr/lib isn't even in svn... nothing lives there, but is copied there (currently).\nThere's been a lot of discussions on solr-dev lately about where the tika libs should live, etc... \nhttp://search.lucidimagination.com/search/document/a9520632864db021/distinct_example_for_solr_cell\nAnd SOLR-1449 is also in the mix as a way to reference jars outside of the example lib. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-12759630",
            "date": "2009-09-25T17:16:40+0000",
            "content": "Yonik maybe it would be better to wait until these things settle out first? (I glanced at issues and saw -1, +1, and such)\n\nI guess there is always the option for release 1.4, do nothing, and instruct users that want to use this analyzer to put lucene-smartcn-2.9.jar in their lib and use analyzer= (they will be stuck with porter stemming and such for now though) "
        },
        {
            "author": "Robert Muir",
            "id": "comment-12892110",
            "date": "2010-07-25T15:36:32+0000",
            "content": "I don't think jar file size should prevent us from adding support for all the analyzers we have.\n\nThis comes with the territory for CJK. Individuals interested in \"optimizing\" size can help\nwith LUCENE-2510, but I don't think that should block integrating all our analyzers, nor should\nthey have to all wait till 4.0 "
        },
        {
            "author": "Robert Muir",
            "id": "comment-12927453",
            "date": "2010-11-02T15:03:51+0000",
            "content": "I committed just the factories and a simple test to the analysis-extras contrib.\n\nCommitted revision 1030073, 1030076 (3x) "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-13013263",
            "date": "2011-03-30T15:46:01+0000",
            "content": "Bulk close for 3.1.0 release "
        }
    ]
}