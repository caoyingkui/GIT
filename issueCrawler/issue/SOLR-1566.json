{
    "id": "SOLR-1566",
    "title": "Allow components to add fields to outgoing documents",
    "details": {
        "affect_versions": "None",
        "status": "Closed",
        "fix_versions": [
            "4.0-ALPHA"
        ],
        "components": [
            "search"
        ],
        "type": "New Feature",
        "priority": "Major",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "Currently it is not possible for components to add fields to outgoing documents which are not in the the stored fields of the document.  This makes it cumbersome to add computed fields/metadata .",
    "attachments": {
        "SOLR-1566-rm.patch": "https://issues.apache.org/jira/secure/attachment/12452648/SOLR-1566-rm.patch",
        "SOLR-1566.patch": "https://issues.apache.org/jira/secure/attachment/12425214/SOLR-1566.patch",
        "SOLR-1566_parsing.patch": "https://issues.apache.org/jira/secure/attachment/12474579/SOLR-1566_parsing.patch",
        "SOLR-1566-gsi.patch": "https://issues.apache.org/jira/secure/attachment/12452563/SOLR-1566-gsi.patch",
        "SOLR-1566-DocTransformer.patch": "https://issues.apache.org/jira/secure/attachment/12473156/SOLR-1566-DocTransformer.patch",
        "SOLR-1566-PageTool.patch": "https://issues.apache.org/jira/secure/attachment/12476185/SOLR-1566-PageTool.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Noble Paul",
            "id": "comment-12778839",
            "date": "2009-11-17T12:24:17+0000",
            "content": "idea as a patch.\n\nAny component must be able to add fields to the document. There are two ways to do it. Add the value directly or add a component (DocFieldSource) which will add the value just in time before the document is written out. The component can choose to add the values based on the other values or it can add some metadata to the document\n\n\nThere is a new class SolrDocumentSlice extends DocSlice . The requirement is that all responsewriters must use  SolrDocumentSlice#getSolrDocumentIterator() to write out documents.\n\nI have not made the necessary changes to the response writers yet. I wish to get the feedback from others on the approach before going ahead further "
        },
        {
            "author": "Noble Paul",
            "id": "comment-12781358",
            "date": "2009-11-23T10:44:16+0000",
            "content": "untested patch.  But\n I am happy with the changes I have made. If others think it is fine , I can add testcases and commit "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12789913",
            "date": "2009-12-13T16:40:19+0000",
            "content": "I think we should try to coordinate w/ SOLR-1298 a bit and take a step back "
        },
        {
            "author": "Noble Paul",
            "id": "comment-12789914",
            "date": "2009-12-13T16:44:35+0000",
            "content": "Yeah. SOLR-1298 and this are trying to achieve something in common. It is not possible for these 2 issues to have 2 different directions.  \n\nIt is not enough to have just function results to be added as values. We should be able to add just about anything "
        },
        {
            "author": "Hoss Man",
            "id": "comment-12872646",
            "date": "2010-05-27T22:09:52+0000",
            "content": "Bulk updating 240 Solr issues to set the Fix Version to \"next\" per the process outlined in this email...\n\nhttp://mail-archives.apache.org/mod_mbox/lucene-dev/201005.mbox/%3Calpine.DEB.1.10.1005251052040.24672@radix.cryptio.net%3E\n\nSelection criteria was \"Unresolved\" with a Fix Version of 1.5, 1.6, 3.1, or 4.0.  email notifications were suppressed.\n\nA unique token for finding these 240 issues in the future: hossversioncleanup20100527 "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12897544",
            "date": "2010-08-12T02:01:14+0000",
            "content": "I know this sounds simple and maybe I'm missing something, but why can't we have a simple data structure that is attached to the SolrResponse and then in the ResponseWriters, (pretty much where it adds the Score onto the item) it looks up the document in the data structure (it's likely a Map where the key is the doc id and the value is a list of values to add to the doc) and then adds the fields, optionally marking them as \"pseudo\" or annotative fields?  I can't imagine the memory usage would get out of hand unless you are retrieving a large number of docs (but then you have memory issues anyway) and it is short-lived so it likely never proceeds out of Eden memory anyway.  Everybody already has access to the SolrResponse to some extent.  For those who want, we could likely make it a configuration item such that even the holding Map isn't created, but that likely isn't too big of a deal.\n\nThoughts? "
        },
        {
            "author": "Chris Male",
            "id": "comment-12897645",
            "date": "2010-08-12T09:19:31+0000",
            "content": "Thats basically where I was headed with SOLR-1298.  Although I still believe that having them added as fields to the Documents properly, whether it be at the SolrIndexSearcher level or somewhere higher, means we can more easily use the values in other areas without having to write custom code in each place. "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12897701",
            "date": "2010-08-12T11:28:11+0000",
            "content": "Thats basically where I was headed with SOLR-1298\n\nHmm, missed that, let me check it out again.\n\nmeans we can more easily use the values in other areas \n\nTrue, but Solr doesn't really materialize the Document until the end anyway, so all you are doing is creating the store anyway.\n\nI've got a basic implementation already that simply adds a small storage piece onto SolrQueryResponse.  It is a <code>Map<Integer, List<DocAnnotations>><code> where a DocAnnotation is a String name and a Object value.  At RespWriting time, it simply adds the objects as fields onto the appropriate documents.  The key to the Map is the Lucene doc id.  Not sure if that is ideal, but I figure anyone adding to a document would have that handle, but that remains to be seen. "
        },
        {
            "author": "Chris Male",
            "id": "comment-12897704",
            "date": "2010-08-12T11:38:52+0000",
            "content": "I've got a basic implementation already that simply adds a small storage piece onto SolrQueryResponse. It is a <code>Map<Integer, List<DocAnnotations>><code> where a DocAnnotation is a String name and a Object value. At RespWriting time, it simply adds the objects as fields onto the appropriate documents. The key to the Map is the Lucene doc id. Not sure if that is ideal, but I figure anyone adding to a document would have that handle, but that remains to be seen.\n\nSounds reasonable to me.  Except I still fear that by creating the DocAnnotation idea we are now adding another construct to Documents.  Sure, as you say, Solr doesn't materialize Documents till it needs to write them out, but still a Document consists only of Fields.  Now they consist of Fields and DocAnnotations.  Its not a big issue I suppose, just wondering whether its needed.  Perhaps a simple renaming to MetadataField or AnnotatedField or something would suffice. "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12897705",
            "date": "2010-08-12T11:49:50+0000",
            "content": "Now they consist of Fields and DocAnnotations.\n\nNah, they don't really.  It's just sdoc.addField(annot.name, annot.value)\n\nThe only thing that is missing in that is it might be nice to be able to mark that field as being a \"pseudo\" field. "
        },
        {
            "author": "Chris Male",
            "id": "comment-12897709",
            "date": "2010-08-12T12:01:46+0000",
            "content": "Nah, they don't really. It's just sdoc.addField(annot.name, annot.value)\n\nAh okay, super!\n\nThe only thing that is missing in that is it might be nice to be able to mark that field as being a \"pseudo\" field.\n\nThat would be nice.  Perhaps we can expand SolrDocument to include a list of pseudo fields? If that needs to be converted into a lucene Document then it can be merged with the rest. "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12897711",
            "date": "2010-08-12T12:04:06+0000",
            "content": "I'd add, however, that it is no different from adding the score.  Also, I don't know that marking the field is required, as, IMO, the Document that is written out is intended to be \"truth\" as far as Solr is concerned, not as far as the Lucene index is concerned. "
        },
        {
            "author": "Chris Male",
            "id": "comment-12897713",
            "date": "2010-08-12T12:08:35+0000",
            "content": "Would you change how score is handled so its like other pseudo fields? "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12897714",
            "date": "2010-08-12T12:10:17+0000",
            "content": "Then again, there are things like sorting, etc. that we may or may not want to support, so you wouldn't want the app dev. to expect to sort by a pseudo field (or maybe you do) "
        },
        {
            "author": "Chris Male",
            "id": "comment-12897716",
            "date": "2010-08-12T12:14:21+0000",
            "content": "If we think in terms of spatial distances, then it might be useful to be able to sort by the pseudo field? I know we currently resolve that issue by sorting by function query, but if you already calculate the distance in some other spatial process, might as well be able to sort on it? "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12897717",
            "date": "2010-08-12T12:15:32+0000",
            "content": "Would you change how score is handled so its like other pseudo fields? \n\nI doubt it.  It is a bit different, I think, than other pseudo-fields. "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12897721",
            "date": "2010-08-12T12:25:08+0000",
            "content": "If we think in terms of spatial distances, then it might be useful to be able to sort by the pseudo field? I know we currently resolve that issue by sorting by function query, but if you already calculate the distance in some other spatial process, might as well be able to sort on it? \n\nYeah, that is true, but sorting is such a low level operation and this issue is about any component doing it, no matter where in the list it occurs.  I just don't see how to make the two sync up w/o having to resort and that would be a perf. killer in many ways (CPU and memory).   IMO, I think this piece of functionality should be about \"marking up\" the result set that is going to be returned.  \n\nOf course, even with the approach I propose, it has the potential to be a memory killer if done wrong.  For instance, I doubt you'd want to stuff in the Map every single distance you calculate, you really only want to add those items that you know are going to be in the final result list.  Perhaps the alternate way is to provide a call back mechanism at Document binding time (i.e. the ResponseWriter) where it gives some Interface the document and then the implementation can add what it wants per the application. "
        },
        {
            "author": "Chris Male",
            "id": "comment-12897729",
            "date": "2010-08-12T12:51:07+0000",
            "content": "Yeah, that is true, but sorting is such a low level operation and this issue is about any component doing it, no matter where in the list it occurs. I just don't see how to make the two sync up w/o having to resort and that would be a perf. killer in many ways (CPU and memory). IMO, I think this piece of functionality should be about \"marking up\" the result set that is going to be returned.\n\nI concur.  I think its best not to do too much stuff in this issue.  If we get pseudo fields being written out, then later on we can address advanced usages.\n\nOf course, even with the approach I propose, it has the potential to be a memory killer if done wrong. For instance, I doubt you'd want to stuff in the Map every single distance you calculate, you really only want to add those items that you know are going to be in the final result list.\n\nYup, this is the crux of the issue.\n\nPerhaps the alternate way is to provide a call back mechanism at Document binding time (i.e. the ResponseWriter) where it gives some Interface the document and then the implementation can add what it wants per the application.\n\nI just wrote something about how I didn't see how that addressed the problem, but then it clicked what you are getting at.  Through this Callback you can then re-calculate the distances for your page of results and  recalculating 10 distances is a nominal cost.\n\nI think thats a really great idea, but I wonder if that shouldn't be an additional process to what you've already made? For spatial it makes perfect sense, but I wonder whether its appropriate for other use cases? I'm trying to imagine some use case where the value can only be captured as part of some convoluted query or analysis process.  Consequently you want to store it when you can and not at binding time.  But maybe a) those use cases dont exist and b) We should leave it up to the user to create a storage system that hooks into the callback.\n "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12897749",
            "date": "2010-08-12T13:46:40+0000",
            "content": "but I wonder if that shouldn't be an additional process to what you've already made?\n\nTotally agree.\n\nb) We should leave it up to the user to create a storage system that hooks into the callback.\n\nYep, that would work too.  Heck, it would even allow one to materialize stuff from a DB or Cassandra, etc.  We'd probably want to be able to do bulk operations if that is the case.  But again, that's getting ahead of ourselves, I think. "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12897750",
            "date": "2010-08-12T13:50:12+0000",
            "content": "The biggest problem here, is the ResponseWriters are a tangled web and it is not always clear they have access to the SolrQueryResponse at the right place, but maybe I'm not understanding them fully yet. "
        },
        {
            "author": "Chris Male",
            "id": "comment-12897824",
            "date": "2010-08-12T16:32:36+0000",
            "content": "Sounds like a good time to untangle the web. "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12897879",
            "date": "2010-08-12T18:21:29+0000",
            "content": "Hmm, so digging in a bit more here and looking at Noble's patch, I think what I have, Noble has and what Chris has are very similar.  The big diff is Chris and Noble hook into the SolrIndexSearcher, whereas what I was intending to do was to hook into the response writers.  As mentioned in the prev. comment, this is a bit tedious, such that it likely does make sense to hook into the SolrIndexSearcher.\n\nThen again, the SolrQueryRequest already has a context object on it (which is what Chris' patch uses, I think), so maybe we should just use that along w/ the Resp. Writers.  Argh. "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12900420",
            "date": "2010-08-19T19:55:34+0000",
            "content": "Here's a half-baked patch that I'm putting up b/c Ryan indicated to me he might have some time to work on it.  It doesn't have the call back capabilities I think we need (that can then hook into Functions) but it does have:\n\n1. Per request storage (although I think we should just re-use the SolrQueryRequest.context Map)\n2. ResponseWriter integration (i.e. no SolrIndexSearcher integration)\n "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-12900790",
            "date": "2010-08-20T17:38:24+0000",
            "content": "attaching some stuff that really does not work, but at least sketches a direction till it hit the 'how do we actually write the fields' road block...\n\nposting here just for reference.\n\nThis takes the approach of adding an 'augmenter' calss:\n\npublic abstract class DocAugmenter \n{\n\t/**\n\t * Call this before you start writing out fields\n\t * @param rsp \n\t * @param req \n\t * \n\t * @return true if it has any fields to augment\n\t */\n\tpublic abstract boolean setup(SolrQueryRequest req);\n\t\n\t/**\n\t * Make sure 'setup' has been called first!\n\t */\n\tpublic abstract void augment( int docId, Document doc );\n}\n\n\n\n\nthe 'setup' call give the augmeter a chance to bulk load all the values if that is what it wants to do.  perhaps we would want a shutdown also "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12902456",
            "date": "2010-08-25T14:15:25+0000",
            "content": "I think we all have generally worked around the same issues here, between this and SOLR-1298.  I guess we just need to pick some names and work it out.  \n\nOne thing about this last patch (and mine, I think) is that perhaps we should just put the augmenter on the Request.  That way, you don't have to add the response in a bunch of places.  Besides, in my mind anyway, you are requesting augmentation via the Augmenter provided. \n\nAlso, I'm not sure why StdAugmenter is instantiated in SolrCore.  Wouldn't we want to allow for that to be driven by some user implementations?\n\nPerhaps, since there are a few of us w/ eyes on this, we should first try to tackle the ResponseWriter mess. "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-12908593",
            "date": "2010-09-13T03:01:31+0000",
            "content": "updating to /trunk and moving back to the SolrDocument approach even though it does not work (it is more clear) "
        },
        {
            "author": "Bill Bell",
            "id": "comment-12915529",
            "date": "2010-09-27T22:48:23+0000",
            "content": "OK. Do we have something that works? Near works? Are we going with this or SOLR-1298 ? We need a decision ?\n\nIf not defined in schema.xml we could just add a parameter: fi=distance:hsin(6500, score, 39, -109)\n\nFI = Field Injection (1 or more).\n\nIt could be handled in the responseWriter. Later adding it to schema.xml can be tackled? \n\nThanks. "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-12975653",
            "date": "2010-12-28T22:06:30+0000",
            "content": "updated patch to work with trunk\n\nnote, this does not do anything yet, but points towards a direction "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-13000055",
            "date": "2011-02-27T22:27:10+0000",
            "content": "updating to trunk... still not really working (or doing anyting) "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-13004219",
            "date": "2011-03-08T21:18:57+0000",
            "content": "Updated path that actually works! "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-13004227",
            "date": "2011-03-08T21:31:48+0000",
            "content": "I just added a path that almost works.  Rather then bang my head on it some more, i think some feedback would be great.\n\nOriginally, I hoped to clean up the ResponeWriter mess, and make a single place that would 'augment' docs \u2013 but there are so many micro optimizations for each format that approach seems difficult.  \n\nInstead I went for an approach the moves Set<String> returnFields to a class that knows more then just a list of strings.  This holds an augmenter that can add to SolrDocument or write to the response.\n\nNow you can make a request like:\n\nhttp://localhost:8983/solr/select?q=*:*&fl=id,score,_docid_,_shard\n\nand get back a response\n\n  \"response\":{\"numFound\":17,\"start\":0,\"maxScore\":1.0,\"docs\":[\n      {\n        \"id\":\"GB18030TEST\",\n        \"score\":1.0,\n        \"_docid_\":0,\n        \"_shard_\":\"getshardid???\"},\n      {\n        \"id\":\"SP2514N\",\n        \"score\":1.0,\n        \"_docid_\":1,\n        \"_shard_\":\"getshardid???\"},\n      {\n        \"id\":\"6H500F0\",\n        \"features\":[\n          \"SATA 3.0Gb/s, NCQ\",\n          \"8.5ms seek\",\n          \"16MB cache\"],\n        \"score\":1.0,\n        \"_docid_\":2,\n        \"_shard_\":\"getshardid???\"},\n...\n\n\n\n\nright now, docid just returns the lucene docid, and shard returns a constant string saying \"getshardid???\"\n\nThe distributed tests (BasicDistributedZkTest, and TestDistributedSearch) don't pass, but everything else does.  I will wait for general feedback before trying to track that down.\n\nAlso looking at SOLR-1298,  I would love some feedback on how we could read function queries and ideally used ones that are already defined elsewhere.\n\n\n\n\n\n\nfeedback welcome!\n\n\n "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13004240",
            "date": "2011-03-08T21:47:09+0000",
            "content": "Hey Ryan, I've also been working on this recently, trying to keep all of the various use-cases in mind (it's difficult!).  It's all just been about brainstorming on the back-end (the chain of things that can modify documents), but I also have code that parses multiple \"fl\" params, including field globbing and function queries.  It doesn't implement those yet, just allows for their specification.  "
        },
        {
            "author": "Bill Bell",
            "id": "comment-13004354",
            "date": "2011-03-09T03:32:58+0000",
            "content": "Here is one use case: \n\n\tReturn geodist() as a field in the results.\n\n "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-13004634",
            "date": "2011-03-09T16:25:52+0000",
            "content": "This takes a different approach \u2013 it forces all the writers to use SolrDocument rather then DocList "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-13004636",
            "date": "2011-03-09T16:30:41+0000",
            "content": "Here is a different approach that allows the whole Document to be transformed rather then just letting you add fields to the response.  The basic interface is now:\n\npublic abstract class DocTransformer\n{\n  public abstract void transform(SolrDocument doc, int docid, Float score);\n}\n\n\n\n\nSome notes about the patch \u2013 many tests fail because this does not support the old xml style where multivalued fields show up as a single item. "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-13004800",
            "date": "2011-03-09T21:13:38+0000",
            "content": "Updated patch.  This changes the the API to:\n\npublic abstract class DocTransformer\n{\n  public void setContext( TransformContext context ) {}\n  public abstract void transform(SolrDocument doc, int docid);\n}\n\n\n\nThis will let the TransformContext hold objects that may be useful for filling up the SolrDocument later.  \n\nFor example, the DocIterator is included in TransformContext and that is used to fill in the score (rather then passing Float score to every transformer).  Another example would be if we have the Query object and want to add 'explain' info directly to the document.\n\nBill \u2013 re geodist(), yes that is my real motivation for this!  see SOLR-1298\n\nSomething is still weird with the Distributed search stuff, but figure I should get feedback on general approach before worrying about that. "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-13004870",
            "date": "2011-03-09T23:20:57+0000",
            "content": "updating this patch with a non-trivial transformation.  This adds explain info directly to the results SOLR-2417 "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-13010780",
            "date": "2011-03-24T17:24:29+0000",
            "content": "updated patch for trunk.\n\nstill need to fix test failure in distributed test case.\n\nI think the basic approach is sound \u2013 i'd like to commit soon so we have something to iterate against.  I think yoniks thoughts are about parsing the the request query.  I hope what i have is OK, and could be replaced/improved when he has code to do that.\n "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-13010914",
            "date": "2011-03-24T20:51:21+0000",
            "content": "updated patch \u2013 distributed tests still fail "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13011053",
            "date": "2011-03-25T00:48:44+0000",
            "content": "Here's my prototype parsing patch that adds support for multiple \"fl\" params, field globbing and function queries. "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-13011218",
            "date": "2011-03-25T14:31:29+0000",
            "content": "all tests pass.\n\nI think this is ready to go \u2014 and we can iterate from here "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-13011221",
            "date": "2011-03-25T14:36:03+0000",
            "content": "Yonik SOLR-1566_parsing.patch looks good \u2013 should be able to replace the 'ReturnFields' class in my patch when it is ready to go "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13011264",
            "date": "2011-03-25T16:29:57+0000",
            "content": "I've tried to go over my brainstorming notes and pull out some stuff that might make sense (as opposed to the stuff that no one will understand w/o a lot more context, like why approach X or approach Y won't work).\n\n\n\tKnow when not to load any stored fields at all (fields could all come from pseudofields, including external fields)\n\t\n\t\texample: fl=\n{!func key=id}id    // use the fieldcache to load an id (important option for distributed search)\n  ** example: fl={!func key=id}\n,mul(popularity,editorial_score)&rows=1000000000  // stream the entire thing\n\t\n\t\n\tGeneral transformer class: something that adds, changes, or removes fields based on an external/database lookup\n\t\n\t\tmay need to work in batches of external ids (a getNextDocument() iterator pattern could allow\n      buffering and then an external request with a bunch of ids)\n\t\tprobably wants to work in batches of SolrDocument, not docids\n\t\tmay need to inspect the FieldsSpec to see what fields were requested\n\t\t\n\t\t\task: did the request ask for field \"x\" that I am responsible for?\n\t\t\task: did the request specifically ask for field \"x\"\n\t\t\n\t\t\n\t\n\t\n\tfunction query that needs to work in-order for good efficiency (query/scorer is one example)\n\t\n\t\tneed to work in potentially big blocks (100 docids at a time), sort the ids then retrieve values in order\n\t\tdon't want to instantiate all SolrDocuments at once... just keep a float[100] or Object[100]\n\t\tif multiple function queries, don't make each sort it's own list of  docids, share somehow?\n\t\t\n\t\t\tthe sharing mechanism could just be a private implementation to this type of transformer\n\t\t\n\t\t\n\t\n\t\n\ttransformers that need the Index... don't make each one look up the right AtomicReaderContext, share it somehow\n\texternal fields should work with highlighting (eventually)\n\t\n\t\tneeds to be possible for highlighting to work on SolrDocuments and only run the transformers once... replacing the original DocList with something else\n\t\n\t\n\tdifferent DocLists need different transformer lists\n\t\n\t\texample: multiple DocLists as the result of grouping\n\t\texample: allow overriding \"fl\" per grouping command\n\t\n\t\n\tneed more than one level of pseudo-fields...\n\t\n\t\texample: user may specify fl=add(a,b)... that's \"global\" unless overridden\n      but the grouping code may want to add the group pseudo-field when using\n      the flattened/simple format\n\t\n\t\n\n "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-13011359",
            "date": "2011-03-25T19:02:27+0000",
            "content": "Yonik, i took your patch and appled to trunk in:  SOLR-2444\n\nI think it makes sense to start a new issue for how the params are parsed since it looks like a lot is going on there "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-13011543",
            "date": "2011-03-26T03:40:47+0000",
            "content": "This is a large issue with many smaller threads, lets close this one and open smaller issues to sort of the details \u2013 In particular:\n\n\tSOLR-2444 will track what we do with the fl parameer\n\tSOLR-1298 will track getting function queries working\n\n "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13016213",
            "date": "2011-04-06T01:52:46+0000",
            "content": "Somewhere we lost some formatting goodness.\n\nbefore the patch we had\n\n  \"response\":{\"numFound\":22,\"start\":0,\"docs\":[\n      {\n        \"id\":\"GB18030TEST\",\n        \"name\":\"Test with some GB18030 encoded characters\"},\n      {\n        \"id\":\"SP2514N\",\n        \"name\":\"Samsung SpinPoint P120 SP2514N - hard drive - 250 GB - ATA-133\"},\n      {\n        \"id\":\"6H500F0\",\n        \"name\":\"Maxtor DiamondMax 11 - hard drive - 500 GB - SATA-300\"},\n      {\n\n\n\nAnd now we have\n\n\n  \"response\":{\"numFound\":19,\"start\":0,\"docs\":[{\n        \"id\":\"GB18030TEST\",\n        \"name\":\"Test with some GB18030 encoded characters\"},{\n        \"id\":\"SP2514N\",\n        \"name\":\"Samsung SpinPoint P120 SP2514N - hard drive - 250 GB - ATA-133\"},{\n        \"id\":\"6H500F0\",\n        \"name\":\"Maxtor DiamondMax 11 - hard drive - 500 GB - SATA-300\"},{\n\n\n\nWhich makes it visually tough to find the start of a new document (well... not so hard w/ just 2 fields, but pretty hard with many larger fields) "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13018654",
            "date": "2011-04-12T01:03:05+0000",
            "content": "Hmmm, I think I just hit another issue:\n\nhttp://localhost:8983/solr/browse\n\n\njava.lang.ClassCastException: org.apache.solr.response.ResultContext cannot be cast to org.apache.solr.common.SolrDocumentList\n\tat org.apache.solr.response.PageTool.<init>(PageTool.java:46)\n\tat org.apache.solr.response.VelocityResponseWriter.write(VelocityResponseWriter.java:62)\n\n "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-13019103",
            "date": "2011-04-12T23:11:24+0000",
            "content": "Also encountered the Velocity bug. Fixed it by patching PageTool (attached). "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13023419",
            "date": "2011-04-22T21:34:09+0000",
            "content": "Somewhere we lost some formatting goodness.\n\nI just committed a small fix for this. "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-13046132",
            "date": "2011-06-08T18:55:02+0000",
            "content": "This has been in trunk for a while \u2013 any new problems should get their own JIRA issue "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-13152891",
            "date": "2011-11-18T14:24:30+0000",
            "content": "Ryan,\n\nI see http://wiki.apache.org/solr/DocTransformers has some pretty thin details on this stuff.  How does one actually invoke it at Query Time?  I see how to configure it.\n\nIs it something like fl=id,score,[myTransformer ... ]  ?  That's what it seems like based on the ReturnFields parsing code. "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-13152892",
            "date": "2011-11-18T14:26:13+0000",
            "content": "Debugging a bit shows that this is indeed how it is done.  I will add it to the docs. "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-13152928",
            "date": "2011-11-18T15:41:11+0000",
            "content": "I fixed it up a little bit (at least using the right syntax) and added a link to:\nhttp://wiki.apache.org/solr/CommonQueryParameters#Transformers "
        },
        {
            "author": "Antony Stubbs",
            "id": "comment-13178856",
            "date": "2012-01-03T17:48:09+0000",
            "content": "Are there any tests writing for any of the doctransformer architecture? I can't find any. I'm looking for something to base tests for a new regex transformer and highlighting augmenting transformer.. "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13178874",
            "date": "2012-01-03T18:02:28+0000",
            "content": "Antony: I don't see any specific \"unit\" tests of the internals, but if you look at all the svn commits associated with this issue there is at least one example of doing functional tests to ensure that the transformers are called at the output is included in the response documents...\n\nhttps://svn.apache.org/viewvc/lucene/dev/trunk/solr/src/test/org/apache/solr/client/solrj/SolrExampleTests.java?r1=1085450&r2=1085449&view=diff&pathrev=1085450\n "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-13178878",
            "date": "2012-01-03T18:06:23+0000",
            "content": "The QueryElevationComponentTest has some examples as well.  I thought there were tests in other places. "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-13178908",
            "date": "2012-01-03T18:51:43+0000",
            "content": "See Also:\n\n\thttp://wiki.apache.org/solr/DocTransformers\n\thttp://wiki.apache.org/solr/CommonQueryParameters#fl\n\n\n "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-13178922",
            "date": "2012-01-03T18:58:11+0000",
            "content": "There are some tests in: SolrExampleTests.java#testAugmentFields()\n\nand TestPseudoReturnFields.java "
        },
        {
            "author": "Antony Stubbs",
            "id": "comment-13178926",
            "date": "2012-01-03T19:00:42+0000",
            "content": "Thanks, that's a start. I'm specifically looking to access the highlighting results, but I can't see how I can. The highlighting results are added to the ResponseBuilder.Response directly in HighlightingComponent: rb.rsp.add(\"highlighting\", sumData);. I want to be able to extract that highlighting component and do some processing on it in my DocTransformer.. "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-13178938",
            "date": "2012-01-03T19:10:32+0000",
            "content": "To do highlighting in a Transformer, you may not want/need to use the Highlighting component at all.  You could do it directly in the Transformer \u2013 this way you have direct access to the output and can avoid building the Map<String,Highlighting Results> that gets added to the response.\n "
        },
        {
            "author": "Antony Stubbs",
            "id": "comment-13179092",
            "date": "2012-01-03T22:41:10+0000",
            "content": "Thanks Ryan.. I was trying to get access to the highlighting results, rather than run it from the transformer - doesn't seem right. But it could be a start.. I think I saw an access point for that... "
        },
        {
            "author": "Ryo Hideno",
            "id": "comment-13223197",
            "date": "2012-03-06T12:44:49+0000",
            "content": "Please do not forget QuerySenderListener. "
        }
    ]
}