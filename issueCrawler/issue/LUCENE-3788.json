{
    "id": "LUCENE-3788",
    "title": "Separate getting Directory from IndexReader from its concrete subclasses",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [
            "core/index"
        ],
        "type": "Improvement",
        "fix_versions": [],
        "affect_versions": "None",
        "resolution": "Won't Fix",
        "status": "Closed"
    },
    "description": "Currently only subclasses of DirectoryReader expose the underlying Directory via public final directory(). IMHO this aspect should be separated from DirectoryReader so that other IndexReader implementations could expose any underlying Directory if they wanted to. Specifically, I have a use case where I'd like to expose a synthetic Directory view of resources used for ParallelCompositeReader.",
    "attachments": {
        "LUCENE-3788.patch": "https://issues.apache.org/jira/secure/attachment/12514622/LUCENE-3788.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2012-02-15T10:34:05+0000",
            "content": "Initial patch. Following this we may need to change the way how Solr uses IndexReaderFactory and use DirectoryBased.directory() to obtain references to underlying Directory instead of relying on IR being a subclass of DirectoryReader. ",
            "author": "Andrzej Bialecki",
            "id": "comment-13208347"
        },
        {
            "date": "2012-02-15T10:41:11+0000",
            "content": "Hi Andrzej,\n\nmaybe you misunderstood the whole thing. IndexReader itself no longer has a Directory. If you want a synthetic Directory behind an index, subclass DirectoryReader, which is abstract - thats easy.\n\nI expected your issue (I know from Robert the reasons for that), so here is the solution: Subclass DirectoryReader and override the very few methods regarding Directory and commit/reopen; in the ctor you pass the getSequentialSubReaders() of your ParallelCompositeReader to DirectoryReader's protected ctor - everything else just works by magic.\n\nWe dont want Directory back in IndexReader as this is separate from the concept of IndexReaders. The problem is mainly Solr, which heavily relies on Directory, but Solr should be abstracted so the Directory-handling stuff is not closely tied into the core.\n\nInstead of opening this issue, you should create an issue at Solr to make it not rely on an Directory (which is the wrong way for ParallelReaders on several Directories, as it has not only one directory).\n\nI would like to close this as won't fix. ",
            "author": "Uwe Schindler",
            "id": "comment-13208351"
        },
        {
            "date": "2012-02-15T10:51:13+0000",
            "content": "Additionally, DirectoryReader is exactly the abstraction you are requesting. Solr also needs commits, versions,.. - all from DirectoryReader. So your magic ParallelDirectoryReader sould simply subclass DirectoryReader (which, again, is abstract): Example code is here:\n\n\npublic class MagicDirectoryReader extends DirectoyReader {\n  public MagicDirectoryReader(Directory dir, ParallelCompositeReader parallel) {\n   // need to \"cast/copy\" the array type as PCR returns IR[] for getSeq, but we know that its atomic:\n   super(dir, Arrays.copyOf(parallel.getSequentialSubReaders(), AtomicReader[].class));\n  }\n\n  // override the rest of abstract methods to fake the commit/reopen-stuff for solr\n}\n\n ",
            "author": "Uwe Schindler",
            "id": "comment-13208355"
        },
        {
            "date": "2012-02-15T10:56:16+0000",
            "content": "See also LUCENE-3734 for the complete thing, this issue was created explicitely for Solr and your company. ",
            "author": "Uwe Schindler",
            "id": "comment-13208359"
        },
        {
            "date": "2012-02-15T11:16:45+0000",
            "content": "Hi Uwe,\n\nIt would be good if you would communicate with Robert about that Lucid-internal problem\nthis issue was created explicitely for Solr and your company.\n\nThis is not helpful ... this was IMHO a legitimate doubt about the use of trunk APIs, and if there's a possible confusion about how to use the new IR-s then probably I'm not the only one confused, and it's irrelevant whether I'm working today for Lucid or for any other company.\n\nbut it's easy to solve, I can also help.\n\nAnd this is helpful.  Thanks, let's close this issue. ",
            "author": "Andrzej Bialecki",
            "id": "comment-13208374"
        },
        {
            "date": "2012-02-15T11:28:38+0000",
            "content": "I did not want to complain, it was just already the idea behind LUCENE-3734! Thanks for reminding that we may need some documentation!\n\nSorry for problems, but maybe the code pasted above helps. The whole reason behind the issue LUCENE-3734 was to support this special case regading Solr and the use of ParallelReaders, so I already did the work - because I expected that this issue will be opened. I only wanted to help and prevent cluttering up the Lucene API again and I am happy to support your further.\n\nParallelCompositeReader was also implemented to support a non-slow parallel reader, I did a lot of work together with Mike to support PCR. ",
            "author": "Uwe Schindler",
            "id": "comment-13208381"
        },
        {
            "date": "2012-02-15T12:11:22+0000",
            "content": "Cool. I really appreciate your help, Uwe. Let's close this as Won't Fix - at least now we have a JIRA that explains why this is a bad idea  ",
            "author": "Andrzej Bialecki",
            "id": "comment-13208407"
        },
        {
            "date": "2012-02-15T12:20:46+0000",
            "content": "Thanks,\nby the way, I would be glad to see a good and working ParallelReader implementation together with your new Tee/Sink/...Codec that indexes to separate Directories. Mabye we get updateable indexed fields soon \n\nI have one hint (I remember you talks about parallel indexes at various conferences): IR no longer supports deletions (another cleanup); but as far as I remember the parallelReaders used IR.deleteDocument() to \"hide\" some documents and keep the indexes in sync (by adding deleted \"fake\" documents). The trick would be now, to use the new \"feature\" of ParallelXReader, which is to only look into the deletes of the first reader. So the \"fake deleted\" documents in the parallel readers can simply be ignored and stay undeleted, because the main index already has the deleted bits and PR returns those.\n\nPlease keep me informed, if the DR API is ok to implement the \"fake\" parts like IndexCommits or reopen() logic for Solr? I suspect that openIfChanged is horrible to do correct for parallel readers that change separately  ",
            "author": "Uwe Schindler",
            "id": "comment-13208414"
        }
    ]
}