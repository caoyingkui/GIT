{
    "id": "SOLR-4205",
    "title": "Clover runs on ASF Jenkins idle dead without a test or any thread running in main() loop waiting for file descriptor",
    "details": {
        "affect_versions": "None",
        "status": "Closed",
        "fix_versions": [
            "4.1",
            "6.0"
        ],
        "components": [
            "Tests"
        ],
        "type": "Bug",
        "priority": "Major",
        "labels": "",
        "resolution": "Duplicate"
    },
    "description": "I had to kill ASF Jenkins Clover builds two times after several 10 hours of inactivity in a random Solr test. I requested a stack trace before killing the only running JVM (clover runs with one JVM only, because clover does not like multiple processes writing the same clover metrics file).\n\nIn both cases (4.x and trunk) the stack trace was looking identical after sending kill -3...\n\nhttps://builds.apache.org/job/Lucene-Solr-Clover-trunk/76/consoleFull (yesterday):\n\n[junit4:junit4] HEARTBEAT J0 PID(81884@lucene.zones.apache.org): 2012-12-16T13:01:00, stalled for 28447s at: TestFunctionQuery.testBooleanFunctions\n[junit4:junit4] HEARTBEAT J0 PID(81884@lucene.zones.apache.org): 2012-12-16T13:02:00, stalled for 28507s at: TestFunctionQuery.testBooleanFunctions\n[junit4:junit4] HEARTBEAT J0 PID(81884@lucene.zones.apache.org): 2012-12-16T13:03:00, stalled for 28567s at: TestFunctionQuery.testBooleanFunctions\n[junit4:junit4] JVM J0: stdout was not empty, see: /usr/home/hudson/hudson-slave/workspace/Lucene-Solr-Clover-trunk/solr/build/solr-core/test/temp/junit4-J0-20121216_044733_583.sysout\n[junit4:junit4] >>> JVM J0: stdout (verbatim) ----\n[junit4:junit4] 2012-12-16 13:03:49\n[junit4:junit4] Full thread dump OpenJDK 64-Bit Server VM (20.0-b12 mixed mode):\n[junit4:junit4] \n[junit4:junit4] \"searcherExecutor-2577-thread-1\" prio=5 tid=0x000000085eb67000 nid=0x61c105b waiting on condition [0x00007ffff0b0d000]\n[junit4:junit4]    java.lang.Thread.State: WAITING (parking)\n[junit4:junit4] \tat sun.misc.Unsafe.park(Native Method)\n[junit4:junit4] \t- parking to wait for  <0x00000008178c9c40> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)\n[junit4:junit4] \tat java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)\n[junit4:junit4] \tat java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)\n[junit4:junit4] \tat java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:386)\n[junit4:junit4] \tat java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1043)\n[junit4:junit4] \tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1103)\n[junit4:junit4] \tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)\n[junit4:junit4] \tat java.lang.Thread.run(Thread.java:679)\n[junit4:junit4] \n[junit4:junit4] \"RMI TCP Accept-0\" daemon prio=5 tid=0x0000000840ce2800 nid=0x61c0aa2 runnable [0x00007ffff9496000]\n[junit4:junit4]    java.lang.Thread.State: RUNNABLE\n[junit4:junit4] \tat java.net.PlainSocketImpl.socketAccept(Native Method)\n[junit4:junit4] \tat java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:375)\n[junit4:junit4] \tat java.net.ServerSocket.implAccept(ServerSocket.java:470)\n[junit4:junit4] \tat java.net.ServerSocket.accept(ServerSocket.java:438)\n[junit4:junit4] \tat sun.rmi.transport.tcp.TCPTransport$AcceptLoop.executeAcceptLoop(TCPTransport.java:387)\n[junit4:junit4] \tat sun.rmi.transport.tcp.TCPTransport$AcceptLoop.run(TCPTransport.java:359)\n[junit4:junit4] \tat java.lang.Thread.run(Thread.java:679)\n[junit4:junit4] \n[junit4:junit4] \"RMI Scheduler(0)\" daemon prio=5 tid=0x0000000840ce1000 nid=0x61c0969 waiting on condition [0x00007ffff0f11000]\n[junit4:junit4]    java.lang.Thread.State: WAITING (parking)\n[junit4:junit4] \tat sun.misc.Unsafe.park(Native Method)\n[junit4:junit4] \t- parking to wait for  <0x0000000814f12f88> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)\n[junit4:junit4] \tat java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)\n[junit4:junit4] \tat java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)\n[junit4:junit4] \tat java.util.concurrent.DelayQueue.take(DelayQueue.java:189)\n[junit4:junit4] \tat java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:688)\n[junit4:junit4] \tat java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:681)\n[junit4:junit4] \tat java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1043)\n[junit4:junit4] \tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1103)\n[junit4:junit4] \tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)\n[junit4:junit4] \tat java.lang.Thread.run(Thread.java:679)\n[junit4:junit4] \n[junit4:junit4] \"GC Daemon\" daemon prio=5 tid=0x0000000840ce0000 nid=0x61c0949 in Object.wait() [0x00007ffff6d6f000]\n[junit4:junit4]    java.lang.Thread.State: TIMED_WAITING (on object monitor)\n[junit4:junit4] \tat java.lang.Object.wait(Native Method)\n[junit4:junit4] \tat sun.misc.GC$Daemon.run(GC.java:117)\n[junit4:junit4] \t- locked <0x0000000814f1c428> (a sun.misc.GC$LatencyLock)\n[junit4:junit4] \n[junit4:junit4] \"RMI Reaper\" prio=5 tid=0x0000000840cdf800 nid=0x61c0947 in Object.wait() [0x00007ffff7577000]\n[junit4:junit4]    java.lang.Thread.State: WAITING (on object monitor)\n[junit4:junit4] \tat java.lang.Object.wait(Native Method)\n[junit4:junit4] \tat java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:133)\n[junit4:junit4] \t- locked <0x0000000814f1ad08> (a java.lang.ref.ReferenceQueue$Lock)\n[junit4:junit4] \tat java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:149)\n[junit4:junit4] \tat sun.rmi.transport.ObjectTable$Reaper.run(ObjectTable.java:350)\n[junit4:junit4] \tat java.lang.Thread.run(Thread.java:679)\n[junit4:junit4] \n[junit4:junit4] \"RMI TCP Accept-0\" daemon prio=5 tid=0x0000000840cde800 nid=0x61c0936 runnable [0x00007ffff6e70000]\n[junit4:junit4]    java.lang.Thread.State: RUNNABLE\n[junit4:junit4] \tat java.net.PlainSocketImpl.socketAccept(Native Method)\n[junit4:junit4] \tat java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:375)\n[junit4:junit4] \tat java.net.ServerSocket.implAccept(ServerSocket.java:470)\n[junit4:junit4] \tat java.net.ServerSocket.accept(ServerSocket.java:438)\n[junit4:junit4] \tat sun.rmi.transport.tcp.TCPTransport$AcceptLoop.executeAcceptLoop(TCPTransport.java:387)\n[junit4:junit4] \tat sun.rmi.transport.tcp.TCPTransport$AcceptLoop.run(TCPTransport.java:359)\n[junit4:junit4] \tat java.lang.Thread.run(Thread.java:679)\n[junit4:junit4] \n[junit4:junit4] \"RMI TCP Accept-0\" daemon prio=5 tid=0x0000000840cde000 nid=0x61c0934 runnable [0x00007ffff494b000]\n[junit4:junit4]    java.lang.Thread.State: RUNNABLE\n[junit4:junit4] \tat java.net.PlainSocketImpl.socketAccept(Native Method)\n[junit4:junit4] \tat java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:375)\n[junit4:junit4] \tat java.net.ServerSocket.implAccept(ServerSocket.java:470)\n[junit4:junit4] \tat java.net.ServerSocket.accept(ServerSocket.java:438)\n[junit4:junit4] \tat sun.rmi.transport.tcp.TCPTransport$AcceptLoop.executeAcceptLoop(TCPTransport.java:387)\n[junit4:junit4] \tat sun.rmi.transport.tcp.TCPTransport$AcceptLoop.run(TCPTransport.java:359)\n[junit4:junit4] \tat java.lang.Thread.run(Thread.java:679)\n[junit4:junit4] \n[junit4:junit4] \"TimeLimitedCollector timer thread\" daemon prio=5 tid=0x0000000848e69800 nid=0x61c096d waiting on condition [0x00007ffff3a3c000]\n[junit4:junit4]    java.lang.Thread.State: TIMED_WAITING (sleeping)\n[junit4:junit4] \tat java.lang.Thread.sleep(Native Method)\n[junit4:junit4] \tat org.apache.lucene.search.TimeLimitingCollector$TimerThread.run(TimeLimitingCollector.java:267)\n[junit4:junit4] \n[junit4:junit4] \"metrics-meter-tick-thread-2\" daemon prio=5 tid=0x000000084c8c6800 nid=0x61c087d runnable [0x00007ffffdfe1000]\n[junit4:junit4]    java.lang.Thread.State: TIMED_WAITING (parking)\n[junit4:junit4] \tat sun.misc.Unsafe.park(Native Method)\n[junit4:junit4] \t- parking to wait for  <0x0000000811568070> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)\n[junit4:junit4] \tat java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:226)\n[junit4:junit4] \tat java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2081)\n[junit4:junit4] \tat java.util.concurrent.DelayQueue.take(DelayQueue.java:193)\n[junit4:junit4] \tat java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:688)\n[junit4:junit4] \tat java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:681)\n[junit4:junit4] \tat java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1043)\n[junit4:junit4] \tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1103)\n[junit4:junit4] \tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)\n[junit4:junit4] \tat java.lang.Thread.run(Thread.java:679)\n[junit4:junit4] \n[junit4:junit4] \"metrics-meter-tick-thread-1\" daemon prio=5 tid=0x000000084c8c5000 nid=0x61c087b runnable [0x00007ffffe1e3000]\n[junit4:junit4]    java.lang.Thread.State: TIMED_WAITING (parking)\n[junit4:junit4] \tat sun.misc.Unsafe.park(Native Method)\n[junit4:junit4] \t- parking to wait for  <0x0000000811568070> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)\n[junit4:junit4] \tat java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:226)\n[junit4:junit4] \tat java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2081)\n[junit4:junit4] \tat java.util.concurrent.DelayQueue.take(DelayQueue.java:193)\n[junit4:junit4] \tat java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:688)\n[junit4:junit4] \tat java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:681)\n[junit4:junit4] \tat java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1043)\n[junit4:junit4] \tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1103)\n[junit4:junit4] \tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)\n[junit4:junit4] \tat java.lang.Thread.run(Thread.java:679)\n[junit4:junit4] \n[junit4:junit4] \"Low Memory Detector\" daemon prio=5 tid=0x00000008011c4800 nid=0x61c0876 runnable [0x0000000000000000]\n[junit4:junit4]    java.lang.Thread.State: RUNNABLE\n[junit4:junit4] \n[junit4:junit4] \"C2 CompilerThread1\" daemon prio=5 tid=0x00000008011c3800 nid=0x61c0875 waiting on condition [0x0000000000000000]\n[junit4:junit4]    java.lang.Thread.State: RUNNABLE\n[junit4:junit4] \n[junit4:junit4] \"C2 CompilerThread0\" daemon prio=5 tid=0x00000008011c3000 nid=0x61c0874 waiting on condition [0x0000000000000000]\n[junit4:junit4]    java.lang.Thread.State: RUNNABLE\n[junit4:junit4] \n[junit4:junit4] \"Signal Dispatcher\" daemon prio=5 tid=0x00000008011c2000 nid=0x61c0873 waiting on condition [0x0000000000000000]\n[junit4:junit4]    java.lang.Thread.State: RUNNABLE\n[junit4:junit4] \n[junit4:junit4] \"Finalizer\" daemon prio=5 tid=0x00000008011c1800 nid=0x61c0872 in Object.wait() [0x00007ffffebed000]\n[junit4:junit4]    java.lang.Thread.State: WAITING (on object monitor)\n[junit4:junit4] \tat java.lang.Object.wait(Native Method)\n[junit4:junit4] \tat java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:133)\n[junit4:junit4] \t- locked <0x0000000810cec8f8> (a java.lang.ref.ReferenceQueue$Lock)\n[junit4:junit4] \tat java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:149)\n[junit4:junit4] \tat java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:177)\n[junit4:junit4] \n[junit4:junit4] \"Reference Handler\" daemon prio=5 tid=0x00000008011c0800 nid=0x61c0871 in Object.wait() [0x00007ffffecee000]\n[junit4:junit4]    java.lang.Thread.State: WAITING (on object monitor)\n[junit4:junit4] \tat java.lang.Object.wait(Native Method)\n[junit4:junit4] \tat java.lang.Object.wait(Object.java:502)\n[junit4:junit4] \tat java.lang.ref.Reference$ReferenceHandler.run(Reference.java:133)\n[junit4:junit4] \t- locked <0x0000000810ce8b80> (a java.lang.ref.Reference$Lock)\n[junit4:junit4] \n[junit4:junit4] \"main\" prio=5 tid=0x00000008011c0000 nid=0x61c0672 runnable [0x00007fffffbfd000]\n[junit4:junit4]    java.lang.Thread.State: RUNNABLE\n[junit4:junit4] \tat java.io.FileInputStream.readBytes(Native Method)\n[junit4:junit4] \tat java.io.FileInputStream.read(FileInputStream.java:236)\n[junit4:junit4] \tat java.io.BufferedInputStream.read1(BufferedInputStream.java:273)\n[junit4:junit4] \tat java.io.BufferedInputStream.read(BufferedInputStream.java:334)\n[junit4:junit4] \t- locked <0x0000000810ce22e0> (a java.io.BufferedInputStream)\n[junit4:junit4] \tat sun.nio.cs.StreamDecoder.readBytes(StreamDecoder.java:282)\n[junit4:junit4] \tat sun.nio.cs.StreamDecoder.implRead(StreamDecoder.java:324)\n[junit4:junit4] \tat sun.nio.cs.StreamDecoder.read(StreamDecoder.java:176)\n[junit4:junit4] \t- locked <0x0000000810ce22c8> (a java.io.InputStreamReader)\n[junit4:junit4] \tat java.io.InputStreamReader.read(InputStreamReader.java:184)\n[junit4:junit4] \tat java.io.BufferedReader.fill(BufferedReader.java:153)\n[junit4:junit4] \tat java.io.BufferedReader.readLine(BufferedReader.java:316)\n[junit4:junit4] \t- locked <0x0000000810ce22c8> (a java.io.InputStreamReader)\n[junit4:junit4] \tat java.io.BufferedReader.readLine(BufferedReader.java:379)\n[junit4:junit4] \tat com.carrotsearch.ant.tasks.junit4.slave.StdInLineIterator.computeNext(StdInLineIterator.java:31)\n[junit4:junit4] \tat com.carrotsearch.ant.tasks.junit4.slave.StdInLineIterator.computeNext(StdInLineIterator.java:13)\n[junit4:junit4] \tat com.carrotsearch.ant.tasks.junit4.dependencies.com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:141)\n[junit4:junit4] \tat com.carrotsearch.ant.tasks.junit4.dependencies.com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:136)\n[junit4:junit4] \tat com.carrotsearch.ant.tasks.junit4.dependencies.com.google.common.collect.Iterators$5.hasNext(Iterators.java:539)\n[junit4:junit4] \tat com.carrotsearch.ant.tasks.junit4.slave.SlaveMain.execute(SlaveMain.java:150)\n[junit4:junit4] \tat com.carrotsearch.ant.tasks.junit4.slave.SlaveMain.main(SlaveMain.java:255)\n[junit4:junit4] \tat com.carrotsearch.ant.tasks.junit4.slave.SlaveMainSafe.main(SlaveMainSafe.java:12)\n[junit4:junit4] \n[junit4:junit4] \"VM Thread\" prio=5 tid=0x000000080121e800 nid=0x61c0870 runnable \n[junit4:junit4] \n[junit4:junit4] \"GC task thread#0 (ParallelGC)\" prio=5 tid=0x0000000801215800 nid=0x61c0863 runnable \n[junit4:junit4] \n[junit4:junit4] \"GC task thread#1 (ParallelGC)\" prio=5 tid=0x0000000801216800 nid=0x61c0864 runnable \n[junit4:junit4] \n[junit4:junit4] \"GC task thread#2 (ParallelGC)\" prio=5 tid=0x0000000801217000 nid=0x61c0865 runnable \n[junit4:junit4] \n[junit4:junit4] \"GC task thread#3 (ParallelGC)\" prio=5 tid=0x0000000801217800 nid=0x61c0866 runnable \n[junit4:junit4] \n[junit4:junit4] \"GC task thread#4 (ParallelGC)\" prio=5 tid=0x0000000801218000 nid=0x61c0867 runnable \n[junit4:junit4] \n[junit4:junit4] \"GC task thread#5 (ParallelGC)\" prio=5 tid=0x0000000801219000 nid=0x61c0868 runnable \n[junit4:junit4] \n[junit4:junit4] \"GC task thread#6 (ParallelGC)\" prio=5 tid=0x0000000801219800 nid=0x61c0869 runnable \n[junit4:junit4] \n[junit4:junit4] \"GC task thread#7 (ParallelGC)\" prio=5 tid=0x000000080121a000 nid=0x61c086a runnable \n[junit4:junit4] \n[junit4:junit4] \"GC task thread#8 (ParallelGC)\" prio=5 tid=0x000000080121a800 nid=0x61c086b runnable \n[junit4:junit4] \n[junit4:junit4] \"GC task thread#9 (ParallelGC)\" prio=5 tid=0x000000080121b800 nid=0x61c086c runnable \n[junit4:junit4] \n[junit4:junit4] \"GC task thread#10 (ParallelGC)\" prio=5 tid=0x000000080121c000 nid=0x61c086d runnable \n[junit4:junit4] \n[junit4:junit4] \"GC task thread#11 (ParallelGC)\" prio=5 tid=0x000000080121c800 nid=0x61c086e runnable \n[junit4:junit4] \n[junit4:junit4] \"GC task thread#12 (ParallelGC)\" prio=5 tid=0x000000080121d000 nid=0x61c086f runnable \n[junit4:junit4] \n[junit4:junit4] \"VM Periodic Task Thread\" prio=5 tid=0x000000080121f000 nid=0x61c0877 waiting on condition \n[junit4:junit4] \n[junit4:junit4] JNI global references: 1183\n[junit4:junit4] \n[junit4:junit4] Heap\n[junit4:junit4]  PSYoungGen      total 212224K, used 110789K [0x0000000830220000, 0x000000083d1c0000, 0x0000000840220000)\n[junit4:junit4]   eden space 211840K, 52% used [0x0000000830220000,0x0000000836e516f0,0x000000083d100000)\n[junit4:junit4]   from space 384K, 0% used [0x000000083d160000,0x000000083d160000,0x000000083d1c0000)\n[junit4:junit4]   to   space 384K, 0% used [0x000000083d100000,0x000000083d100000,0x000000083d160000)\n[junit4:junit4]  PSOldGen        total 524288K, used 127127K [0x0000000810220000, 0x0000000830220000, 0x0000000830220000)\n[junit4:junit4]   object space 524288K, 24% used [0x0000000810220000,0x0000000817e45ef0,0x0000000830220000)\n[junit4:junit4]  PSPermGen       total 83968K, used 83967K [0x000000080b020000, 0x0000000810220000, 0x0000000810220000)\n[junit4:junit4]   object space 83968K, 99% used [0x000000080b020000,0x000000081021fd98,0x0000000810220000)\n[junit4:junit4] <<< JVM J0: EOF ----\n\n\n\nhttps://builds.apache.org/job/Lucene-Solr-Clover-4.x/77/consoleFull (today):\n\n[junit4:junit4] HEARTBEAT J0 PID(2916@lucene.zones.apache.org): 2012-12-16T22:11:23, stalled for 13809s at: QueryEqualityTest (suite)\n[junit4:junit4] HEARTBEAT J0 PID(2916@lucene.zones.apache.org): 2012-12-16T22:12:23, stalled for 13869s at: QueryEqualityTest (suite)\n[junit4:junit4] HEARTBEAT J0 PID(2916@lucene.zones.apache.org): 2012-12-16T22:13:23, stalled for 13929s at: QueryEqualityTest (suite)\n[junit4:junit4] HEARTBEAT J0 PID(2916@lucene.zones.apache.org): 2012-12-16T22:14:23, stalled for 13989s at: QueryEqualityTest (suite)\n[junit4:junit4] JVM J0: stdout was not empty, see: /usr/home/hudson/hudson-slave/workspace/Lucene-Solr-Clover-4.x/solr/build/solr-core/test/temp/junit4-J0-20121216_175857_638.sysout\n[junit4:junit4] >>> JVM J0: stdout (verbatim) ----\n[junit4:junit4] 2012-12-16 22:14:25\n[junit4:junit4] Full thread dump OpenJDK 64-Bit Server VM (20.0-b12 mixed mode):\n[junit4:junit4] \n[junit4:junit4] \"TimeLimitedCollector timer thread\" daemon prio=5 tid=0x00000008460dc800 nid=0x61c9fa3 waiting on condition [0x00007ffffd8da000]\n[junit4:junit4]    java.lang.Thread.State: TIMED_WAITING (sleeping)\n[junit4:junit4] \tat java.lang.Thread.sleep(Native Method)\n[junit4:junit4] \tat org.apache.lucene.search.TimeLimitingCollector$TimerThread.run(TimeLimitingCollector.java:267)\n[junit4:junit4] \n[junit4:junit4] \"metrics-meter-tick-thread-2\" daemon prio=5 tid=0x000000084b749800 nid=0x61c9f96 runnable [0x00007ffffe0e2000]\n[junit4:junit4]    java.lang.Thread.State: TIMED_WAITING (parking)\n[junit4:junit4] \tat sun.misc.Unsafe.park(Native Method)\n[junit4:junit4] \t- parking to wait for  <0x0000000810dd3f20> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)\n[junit4:junit4] \tat java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:226)\n[junit4:junit4] \tat java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2081)\n[junit4:junit4] \tat java.util.concurrent.DelayQueue.take(DelayQueue.java:193)\n[junit4:junit4] \tat java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:688)\n[junit4:junit4] \tat java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:681)\n[junit4:junit4] \tat java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1043)\n[junit4:junit4] \tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1103)\n[junit4:junit4] \tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)\n[junit4:junit4] \tat java.lang.Thread.run(Thread.java:679)\n[junit4:junit4] \n[junit4:junit4] \"metrics-meter-tick-thread-1\" daemon prio=5 tid=0x000000084b749000 nid=0x61c9f95 runnable [0x00007ffffe1e3000]\n[junit4:junit4]    java.lang.Thread.State: TIMED_WAITING (parking)\n[junit4:junit4] \tat sun.misc.Unsafe.park(Native Method)\n[junit4:junit4] \t- parking to wait for  <0x0000000810dd3f20> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)\n[junit4:junit4] \tat java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:226)\n[junit4:junit4] \tat java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2081)\n[junit4:junit4] \tat java.util.concurrent.DelayQueue.take(DelayQueue.java:193)\n[junit4:junit4] \tat java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:688)\n[junit4:junit4] \tat java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:681)\n[junit4:junit4] \tat java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1043)\n[junit4:junit4] \tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1103)\n[junit4:junit4] \tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)\n[junit4:junit4] \tat java.lang.Thread.run(Thread.java:679)\n[junit4:junit4] \n[junit4:junit4] \"Low Memory Detector\" daemon prio=5 tid=0x00000008011c4800 nid=0x61c9f90 runnable [0x0000000000000000]\n[junit4:junit4]    java.lang.Thread.State: RUNNABLE\n[junit4:junit4] \n[junit4:junit4] \"C2 CompilerThread1\" daemon prio=5 tid=0x00000008011c3800 nid=0x61c9f8f waiting on condition [0x0000000000000000]\n[junit4:junit4]    java.lang.Thread.State: RUNNABLE\n[junit4:junit4] \n[junit4:junit4] \"C2 CompilerThread0\" daemon prio=5 tid=0x00000008011c3000 nid=0x61c9f8e waiting on condition [0x0000000000000000]\n[junit4:junit4]    java.lang.Thread.State: RUNNABLE\n[junit4:junit4] \n[junit4:junit4] \"Signal Dispatcher\" daemon prio=5 tid=0x00000008011c2000 nid=0x61c9f8d waiting on condition [0x0000000000000000]\n[junit4:junit4]    java.lang.Thread.State: RUNNABLE\n[junit4:junit4] \n[junit4:junit4] \"Finalizer\" daemon prio=5 tid=0x00000008011c1800 nid=0x61c9f8c in Object.wait() [0x00007ffffebed000]\n[junit4:junit4]    java.lang.Thread.State: WAITING (on object monitor)\n[junit4:junit4] \tat java.lang.Object.wait(Native Method)\n[junit4:junit4] \tat java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:133)\n[junit4:junit4] \t- locked <0x00000008109642d8> (a java.lang.ref.ReferenceQueue$Lock)\n[junit4:junit4] \tat java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:149)\n[junit4:junit4] \tat java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:177)\n[junit4:junit4] \n[junit4:junit4] \"Reference Handler\" daemon prio=5 tid=0x00000008011c0800 nid=0x61c9f8b in Object.wait() [0x00007ffffecee000]\n[junit4:junit4]    java.lang.Thread.State: WAITING (on object monitor)\n[junit4:junit4] \tat java.lang.Object.wait(Native Method)\n[junit4:junit4] \tat java.lang.Object.wait(Object.java:502)\n[junit4:junit4] \tat java.lang.ref.Reference$ReferenceHandler.run(Reference.java:133)\n[junit4:junit4] \t- locked <0x0000000810967160> (a java.lang.ref.Reference$Lock)\n[junit4:junit4] \n[junit4:junit4] \"main\" prio=5 tid=0x00000008011c0000 nid=0x61c9d83 runnable [0x00007fffffbfd000]\n[junit4:junit4]    java.lang.Thread.State: RUNNABLE\n[junit4:junit4] \tat java.io.FileInputStream.readBytes(Native Method)\n[junit4:junit4] \tat java.io.FileInputStream.read(FileInputStream.java:236)\n[junit4:junit4] \tat java.io.BufferedInputStream.read1(BufferedInputStream.java:273)\n[junit4:junit4] \tat java.io.BufferedInputStream.read(BufferedInputStream.java:334)\n[junit4:junit4] \t- locked <0x000000081098f1f8> (a java.io.BufferedInputStream)\n[junit4:junit4] \tat sun.nio.cs.StreamDecoder.readBytes(StreamDecoder.java:282)\n[junit4:junit4] \tat sun.nio.cs.StreamDecoder.implRead(StreamDecoder.java:324)\n[junit4:junit4] \tat sun.nio.cs.StreamDecoder.read(StreamDecoder.java:176)\n[junit4:junit4] \t- locked <0x000000081098f1e0> (a java.io.InputStreamReader)\n[junit4:junit4] \tat java.io.InputStreamReader.read(InputStreamReader.java:184)\n[junit4:junit4] \tat java.io.BufferedReader.fill(BufferedReader.java:153)\n[junit4:junit4] \tat java.io.BufferedReader.readLine(BufferedReader.java:316)\n[junit4:junit4] \t- locked <0x000000081098f1e0> (a java.io.InputStreamReader)\n[junit4:junit4] \tat java.io.BufferedReader.readLine(BufferedReader.java:379)\n[junit4:junit4] \tat com.carrotsearch.ant.tasks.junit4.slave.StdInLineIterator.computeNext(StdInLineIterator.java:31)\n[junit4:junit4] \tat com.carrotsearch.ant.tasks.junit4.slave.StdInLineIterator.computeNext(StdInLineIterator.java:13)\n[junit4:junit4] \tat com.carrotsearch.ant.tasks.junit4.dependencies.com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:141)\n[junit4:junit4] \tat com.carrotsearch.ant.tasks.junit4.dependencies.com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:136)\n[junit4:junit4] \tat com.carrotsearch.ant.tasks.junit4.dependencies.com.google.common.collect.Iterators$5.hasNext(Iterators.java:539)\n[junit4:junit4] \tat com.carrotsearch.ant.tasks.junit4.slave.SlaveMain.execute(SlaveMain.java:150)\n[junit4:junit4] \tat com.carrotsearch.ant.tasks.junit4.slave.SlaveMain.main(SlaveMain.java:255)\n[junit4:junit4] \tat com.carrotsearch.ant.tasks.junit4.slave.SlaveMainSafe.main(SlaveMainSafe.java:12)\n[junit4:junit4] \n[junit4:junit4] \"VM Thread\" prio=5 tid=0x000000080121e800 nid=0x61c9f8a runnable \n[junit4:junit4] \n[junit4:junit4] \"GC task thread#0 (ParallelGC)\" prio=5 tid=0x0000000801215800 nid=0x61c9f7d runnable \n[junit4:junit4] \n[junit4:junit4] \"GC task thread#1 (ParallelGC)\" prio=5 tid=0x0000000801216800 nid=0x61c9f7e runnable \n[junit4:junit4] \n[junit4:junit4] \"GC task thread#2 (ParallelGC)\" prio=5 tid=0x0000000801217000 nid=0x61c9f7f runnable \n[junit4:junit4] \n[junit4:junit4] \"GC task thread#3 (ParallelGC)\" prio=5 tid=0x0000000801217800 nid=0x61c9f80 runnable \n[junit4:junit4] \n[junit4:junit4] \"GC task thread#4 (ParallelGC)\" prio=5 tid=0x0000000801218000 nid=0x61c9f81 runnable \n[junit4:junit4] \n[junit4:junit4] \"GC task thread#5 (ParallelGC)\" prio=5 tid=0x0000000801219000 nid=0x61c9f82 runnable \n[junit4:junit4] \n[junit4:junit4] \"GC task thread#6 (ParallelGC)\" prio=5 tid=0x0000000801219800 nid=0x61c9f83 runnable \n[junit4:junit4] \n[junit4:junit4] \"GC task thread#7 (ParallelGC)\" prio=5 tid=0x000000080121a000 nid=0x61c9f84 runnable \n[junit4:junit4] \n[junit4:junit4] \"GC task thread#8 (ParallelGC)\" prio=5 tid=0x000000080121a800 nid=0x61c9f85 runnable \n[junit4:junit4] \n[junit4:junit4] \"GC task thread#9 (ParallelGC)\" prio=5 tid=0x000000080121b800 nid=0x61c9f86 runnable \n[junit4:junit4] \n[junit4:junit4] \"GC task thread#10 (ParallelGC)\" prio=5 tid=0x000000080121c000 nid=0x61c9f87 runnable \n[junit4:junit4] \n[junit4:junit4] \"GC task thread#11 (ParallelGC)\" prio=5 tid=0x000000080121c800 nid=0x61c9f88 runnable \n[junit4:junit4] \n[junit4:junit4] \"GC task thread#12 (ParallelGC)\" prio=5 tid=0x000000080121d000 nid=0x61c9f89 runnable \n[junit4:junit4] \n[junit4:junit4] \"VM Periodic Task Thread\" prio=5 tid=0x000000080121f000 nid=0x61c9f91 waiting on condition \n[junit4:junit4] \n[junit4:junit4] JNI global references: 1271\n[junit4:junit4] \n[junit4:junit4] Heap\n[junit4:junit4]  PSYoungGen      total 229120K, used 170968K [0x0000000830220000, 0x000000083eb60000, 0x0000000840220000)\n[junit4:junit4]   eden space 228992K, 74% used [0x0000000830220000,0x000000083a8fe360,0x000000083e1c0000)\n[junit4:junit4]   from space 128K, 75% used [0x000000083eb40000,0x000000083eb58000,0x000000083eb60000)\n[junit4:junit4]   to   space 384K, 0% used [0x000000083eaa0000,0x000000083eaa0000,0x000000083eb00000)\n[junit4:junit4]  PSOldGen        total 524288K, used 179710K [0x0000000810220000, 0x0000000830220000, 0x0000000830220000)\n[junit4:junit4]   object space 524288K, 34% used [0x0000000810220000,0x000000081b19fa98,0x0000000830220000)\n[junit4:junit4]  PSPermGen       total 83968K, used 83967K [0x000000080b020000, 0x0000000810220000, 0x0000000810220000)\n[junit4:junit4]   object space 83968K, 99% used [0x000000080b020000,0x000000081021fc68,0x0000000810220000)\n[junit4:junit4] <<< JVM J0: EOF ----\n\n\n\nTo me it looks like there is something wrong with the test runner. In other cases this totally-hanging threads were caused by permgen-errors, but nothing like this in the logs. It looks like the slave is waiting forever to get some messages from the master or vice versa.\n\nYou can imitate clover tests on ASF Jenkins by running:\n\nANT_OPTS=\"-Xmx1536M\" ant -Dtests.jettyConnector=Socket jenkins-clover\n\n\n\n(the ANT_OPTS are just for the generate-clover-task using lots of memory - totally unrelated. This is just needed after the tests ran successfully). jenkins-clover calls run-clover task which automatically gives more memory to the child JVMs, so maybe this is related and needs more memory. You can find that in the main common-build.xml file, where you will find a property definition if=\"run.clover\" giving more heap and code cache to childs:\n\n\n  <condition property=\"tests.heapsize\" value=\"768M\">\n    <isset property=\"run.clover\"/>\n  </condition>\n  <property name=\"tests.heapsize\" value=\"512M\"/>\n  \n  <condition property=\"tests.clover.args\" value=\"-XX:ReservedCodeCacheSize=128m\">\n    <isset property=\"run.clover\"/>\n  </condition>\n  <property name=\"tests.clover.args\" value=\"\"/>\n\n\n\n(maybe tweak that if Solr needs more memory - Lucene clover passes fine).\n\nI disabled clover tests for now.",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "author": "Dawid Weiss",
            "id": "comment-13533735",
            "date": "2012-12-17T08:58:39+0000",
            "content": "This definitely looks like a bug in the runner although I have no idea how to reproduce this or what may be causing it. The symptoms are: truncated events file:\n\n[\n  \"SUITE_FAILURE\"\n\n\n\nand the main test thread gone. This is very weird. "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-13533737",
            "date": "2012-12-17T09:01:34+0000",
            "content": "Do you flush the event file? "
        },
        {
            "author": "Dawid Weiss",
            "id": "comment-13533738",
            "date": "2012-12-17T09:13:11+0000",
            "content": "Sure. "
        },
        {
            "author": "Dawid Weiss",
            "id": "comment-13533820",
            "date": "2012-12-17T10:29:46+0000",
            "content": "I pushed yet another minor release (it's damn hard to test against third party libraries with ivy...) \u2013 2.0.7. It just contains an explicit flush but I don't think this will make a difference. \n\nUwe, could you upgrade the ivy files and enable the build again? we'll see if this helps or changes the behavior anyhow. I'm busy for the rest of the day but I'll take a look at the results in the evening. "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-13533822",
            "date": "2012-12-17T10:38:04+0000",
            "content": "Updated in trunk revision: 1422836, 4.x revision: 1422837 "
        },
        {
            "author": "Commit Tag Bot",
            "id": "comment-13533823",
            "date": "2012-12-17T10:38:12+0000",
            "content": "[trunk commit] Uwe Schindler\nhttp://svn.apache.org/viewvc?view=revision&revision=1422836\n\nSOLR-4205: Update randomized-testing framework to 2.0.7 "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-13533826",
            "date": "2012-12-17T10:40:24+0000",
            "content": "I triggered a new trunk clover build. "
        },
        {
            "author": "Commit Tag Bot",
            "id": "comment-13533827",
            "date": "2012-12-17T10:42:25+0000",
            "content": "[branch_4x commit] Uwe Schindler\nhttp://svn.apache.org/viewvc?view=revision&revision=1422837\n\nMerged revision(s) 1422836 from lucene/dev/trunk:\nSOLR-4205: Update randomized-testing framework to 2.0.7 "
        },
        {
            "author": "Dawid Weiss",
            "id": "comment-13534282",
            "date": "2012-12-17T20:39:52+0000",
            "content": "There is definitely a bug \u2013 something I don't fully comprehend at the moment. It seems it may be related to running in very low-memory conditions (permgen exhausted, memory exhausted). I'll keep digging but I have some urgent stuff to do \u2013 can we increase permgen limits, at least temporarily, on nightlies and clover builds? "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-13534284",
            "date": "2012-12-17T20:43:34+0000",
            "content": "I will look into this! "
        },
        {
            "author": "Commit Tag Bot",
            "id": "comment-13534550",
            "date": "2012-12-18T02:26:56+0000",
            "content": "[trunk commit] Steven Rowe\nhttp://svn.apache.org/viewvc?view=revision&revision=1423252\n\nSOLR-4205: Maven configuration: upgrade randomizedtesting-runner to v2.0.7 "
        },
        {
            "author": "Commit Tag Bot",
            "id": "comment-13534551",
            "date": "2012-12-18T02:30:44+0000",
            "content": "[branch_4x commit] Steven Rowe\nhttp://svn.apache.org/viewvc?view=revision&revision=1423253\n\nSOLR-4205: Maven configuration: upgrade randomizedtesting-runner to v2.0.7 (merge trunk r1423252) "
        },
        {
            "author": "Dawid Weiss",
            "id": "comment-13534728",
            "date": "2012-12-18T07:28:10+0000",
            "content": "Thanks Steve, although 2.0.7 doesn't seem to solve the hang-on-OOM issue  "
        },
        {
            "author": "Commit Tag Bot",
            "id": "comment-13534799",
            "date": "2012-12-18T10:07:09+0000",
            "content": "[trunk commit] Uwe Schindler\nhttp://svn.apache.org/viewvc?view=revision&revision=1423389\n\nSOLR-4205: Add permgen space for Clover runs and raise memory for nightly jenkins builds, too. "
        },
        {
            "author": "Commit Tag Bot",
            "id": "comment-13534801",
            "date": "2012-12-18T10:10:48+0000",
            "content": "[branch_4x commit] Uwe Schindler\nhttp://svn.apache.org/viewvc?view=revision&revision=1423390\n\nMerged revision(s) 1423389 from lucene/dev/trunk:\nSOLR-4205: Add permgen space for Clover runs and raise memory for nightly jenkins builds, too. "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-13534804",
            "date": "2012-12-18T10:13:27+0000",
            "content": "I committed a permgen memory increase to both nightly and clover tasks (for jenkins).\n\nThe issue in Clover may not be resolveable without raising permgen, but the nightly builds hanging is more crazy. It looks like the testDistributedSearch start way too many jetty instances that don't clean up enough their classloaders. Please note: -Dtests.nightly and -Dtests.multiplier=3 was set, i changed the multiplier to 2, too (in the jenkins config).\n\nMaybe change the nightly/multiplier effect for BaseDistributedTestCase? Mark? If we can handle this, I would like the remove the hack for the nightly runs again! "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-13534866",
            "date": "2012-12-18T12:58:16+0000",
            "content": "The latest jenkins-nightly build succeeded. jenkins-clover is currently running... "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-13534974",
            "date": "2012-12-18T15:38:13+0000",
            "content": "With the raised permgen also clover build succeeded. Most interinesting: The coverage get back to 80%. I assume the change to SocketConnector in Jetty is causing this, making the tests on FreeBSD succeed and so raising the coverage instead of timing out. I assume testDistributedSearch tests almost every single line of code \n\nMark: We should at least work on making testDistributesSearch in the nightly builds with a multiplicator of 3 does not OOM. I would like to revert the changes in \"jenkins nightly\" task because they are nox cross-JVM portable. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13534990",
            "date": "2012-12-18T15:55:37+0000",
            "content": "I think it succeeded for a few reasons:\n\n1. We switched back to using the socket connector on freebsd - some runs started to pass, but many, especially nightly and maven ones, still failed.\n\n2. I broke up the basic zk test that was using so much perm space into 2 tests and took out the atLeasts that may have been making it make a more cores than could be handled.\n\n3. I stopped trying to do work arounds for black hole and added timeouts for pretty much every call we do (still no timeouts in prod, but tests override to add timeouts). This is part of the make tests work with blackhole issue I opened.\n\nBetween the 3, we are getting closer. It's un-lodged some new fails though, so there is still some work to do, but we are getting there. "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-13534994",
            "date": "2012-12-18T15:58:12+0000",
            "content": "When did you commit that? Because the new runs for clover and nightly were passing after my commit raising permgen, so should I revert that to try out? "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13535011",
            "date": "2012-12-18T16:15:59+0000",
            "content": "#2 I committed like yesterday. #3 might have been the day before.\n\nProbably worth trying at the lower perm gen to see if we should reduce the test anymore. "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-13535076",
            "date": "2012-12-18T17:24:41+0000",
            "content": "The last failing run was last night, so I think we should maybe run the test suite locally with -Dtests.nightly and -Dtests.multiplicator=3 first before reverting parts of my commit. Thanks in any case! "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13535082",
            "date": "2012-12-18T17:33:05+0000",
            "content": "That's weird - I don't think there is anything in the test that looks at the multiplier (since I changed it)...so not sure how that would still matter.\n\nwe should maybe run the test suite locally with -Dtests.nightly and -Dtests.multiplicator=3 first \n\nThat actually passed for me a few days ago on my dev machine when I tried, so I don't think I can learn much on my machine. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13535086",
            "date": "2012-12-18T17:35:38+0000",
            "content": "Are you sure the failure yesterday was a permgen one? "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-13535087",
            "date": "2012-12-18T17:38:35+0000",
            "content": "Yes! The Nightly one was a permgen failure: https://builds.apache.org/job/Lucene-Solr-NightlyTests-4.x/124/console\nMaybe the size of permgen is different on different platforms.\n\nI have no idea if your patches were already committed, this one ran yesterday at 16:00 UTC, but took until this morning hanging after permgen  - I killed it this morning.\n\nDid you run all tests or only a selection. Permgen issues mostly happen when a test run does not allow GC to unload all classes, so it only happens when running all tests. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13535109",
            "date": "2012-12-18T18:01:32+0000",
            "content": "Okay - 16:00 UTC looks like 11am EST? I suck at timezones. If that is the case, I did not commit till 12:49 pm EST. "
        },
        {
            "author": "Commit Tag Bot",
            "id": "comment-13535192",
            "date": "2012-12-18T19:30:52+0000",
            "content": "[trunk commit] Uwe Schindler\nhttp://svn.apache.org/viewvc?view=revision&revision=1423587\n\nSOLR-4205: Give jenkins-nightly another try with default mem settings. "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-13535194",
            "date": "2012-12-18T19:32:04+0000",
            "content": "I reverted the nightly memory settings from build.xml and give it another try. The multiplier on jenkins is still set to 2 instead of 3. If this passes, I will reconfigure Jenkins, too.\n\nClover tests should run with more permgen, because it was always very critical (clover annotated classes are much larger). But clover is already very JVM specific, because it also needs more bytecode/assembler cache settings and stuff like that. "
        },
        {
            "author": "Commit Tag Bot",
            "id": "comment-13535199",
            "date": "2012-12-18T19:36:32+0000",
            "content": "[branch_4x commit] Uwe Schindler\nhttp://svn.apache.org/viewvc?view=revision&revision=1423590\n\nMerged revision(s) 1423587 from lucene/dev/trunk:\nSOLR-4205: Give jenkins-nightly another try with default mem settings. "
        },
        {
            "author": "Dawid Weiss",
            "id": "comment-13541351",
            "date": "2012-12-31T11:52:25+0000",
            "content": "I said it'd be difficult to make anything sensible under low-memory conditions, didn't I? Even hotspot goes wild. Try it:\n\n\nimport java.util.LinkedList;\n\npublic class CodeOom {\n  static LinkedList<byte[]> ohMy = new LinkedList<byte[]>(); \n\n  public void oomInCode() {\n    int stringLength = 1024 * 1024 * 5;\n    while (true) {\n      try {\n          ohMy.add(new byte [stringLength]);\n      } catch (OutOfMemoryError e) {\n        if (stringLength < 100) {\n          throw e;\n        } else {\n          stringLength /= 2;\n        }\n      }\n    }\n  }\n  \n  public static void main(String[] args) {\n    try {\n      new CodeOom().oomInCode();\n    } catch (Throwable t) {\n      Runtime.getRuntime().halt(/* anything != 0, 1, etc. */ 5);\n    }\n  }\n}\n\n\n\nThis should terminate with exit code 5. So it does, normally. But not when there's no memory. See for yourself:\n\n\ndweiss@ophelia:~/tmp$ java -cp . CodeOom; echo $?\n1\n\n "
        },
        {
            "author": "Dawid Weiss",
            "id": "comment-13542051",
            "date": "2013-01-02T08:18:06+0000",
            "content": "I can't guarantee it'll be fine but it should be better... we'll see. "
        }
    ]
}