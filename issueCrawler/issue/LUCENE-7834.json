{
    "id": "LUCENE-7834",
    "title": "BlockTree's terms index should be loaded into memory lazily",
    "details": {
        "labels": "",
        "priority": "Major",
        "resolution": "Won't Fix",
        "affect_versions": "None",
        "status": "Closed",
        "type": "Improvement",
        "components": [
            "core/codecs"
        ],
        "fix_versions": []
    },
    "description": "I propose that BlockTree delay loading the FST prefix terms index into memory until terms(String) is first called.  This seems like how it should work since if someone wants to eager load then they can use IndexReaderWarmer.  By making the FST lazy load, we can be more NRT friendly (if some fields are rarely used), and also save memory (if some fields are rarely used).",
    "attachments": {
        "LUCENE_7834_BlockTreeLazyFST.patch": "https://issues.apache.org/jira/secure/attachment/12868572/LUCENE_7834_BlockTreeLazyFST.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "id": "comment-16014538",
            "date": "2017-05-17T18:16:48+0000",
            "content": "Attached patch.  indexIn is kept open instead of closed eagerly since an FST may need to be loaded at any time, and it's problematic to re-open it.\n\nNote I added this TODO about \"indexIn\" in FieldReader's constructor:\n    //TODO DWS: I don't see how it can be null.  Lots of null checks on \"index\" in BlockTree could be removed. ",
            "author": "David Smiley"
        },
        {
            "id": "comment-16014608",
            "date": "2017-05-17T18:47:56+0000",
            "content": "I am not sure we should do this lazily, it can create a false sense of security.\n\nSomeone really does not have enough memory for their data, seems fine, then they hit merge (or calls addindexes) and all the fields are loaded and they get OOM. ",
            "author": "Robert Muir"
        },
        {
            "id": "comment-16014622",
            "date": "2017-05-17T18:53:55+0000",
            "content": "I am not sure we should do this lazily, it can create a false sense of security.\n\nThen maybe IndexReaderWarmer should be registered by default?  Oh yeah, I only see this used by IndexWriterConfig.setMergedSegmentWarner... maybe IndexReader should have one of these for on-open? ",
            "author": "David Smiley"
        },
        {
            "id": "comment-16015692",
            "date": "2017-05-18T12:46:43+0000",
            "content": "Agreed with Robert about the false sense of security. I remember I hated when norms would only start using memory when they were used. I have seen some threads about the memory usage of terms recently and I'm wondering whether this is misusage of Lucene somehow such as too many fields/segments or whether the terms index is hitting adversarial patterns of the terms dictionary that make it use lots of memory. In the latter case maybe this is something we can address? ",
            "author": "Adrien Grand"
        },
        {
            "id": "comment-16015940",
            "date": "2017-05-18T15:27:15+0000",
            "content": "Here's a use-case:  Lots of searchable fields, but most of them are copied to a catch-all search field.  Most searches don't reference the source fields (i.e. most searches aren't specific about exactly what field needs to match), but it needs to be supported for the small number of queries that do.  By not loading them eagerly, it saves memory and is more NRT friendly.\n\nAny thoughts on adding IndexReaderWarmer support to IndexSearcher?  I think many/most apps warm their index already, and perhaps most that don't arguably should. \n\nA half baked idea I was just exploring was a PostingsFormat wrapper that lazy-loads.  But a problem there is knowing which fields exist without using the underlying real PostingsFormat (which would trigger memory & stuff we are trying to avoid).  And of course you can't then tell the underlying postings format which field exactly you want alone (and not the others) so this seems to be totally unworkable.  It'd be nice if it did though; then you could make any PostingsFormat lazy load... you could even have a wrapping PostingsFormat that could unload if it so chose.  Wishful thinking, alas.  Maybe there is a possibility there still by concocting a special combo of CFS and PerFieldPostingsFormat. ",
            "author": "David Smiley"
        },
        {
            "id": "comment-16015956",
            "date": "2017-05-18T15:41:08+0000",
            "content": "By not loading them eagerly, it saves memory and is more NRT friendly.\n\nBut then you pay the price at query time since the FST needs to be loaded as part of query execution. This doesn't sound like a better default to me, it is just moving the problem? ",
            "author": "Adrien Grand"
        },
        {
            "id": "comment-16015981",
            "date": "2017-05-18T15:58:15+0000",
            "content": "But then you pay the price at query time since the FST needs to be loaded as part of query execution. This doesn't sound like a better default to me, it is just moving the problem?\n\nIt's ultimately a trade-off that the user can be in control of through the amount of warming they do.  I don't view this as \"moving the problem\"; perhaps we aren't thinking of \"the problem\" as the same thing. The \"problem\" I'm trying to solve is to save memory/latency that sometimes won't even be needed at all. ",
            "author": "David Smiley"
        },
        {
            "id": "comment-16031955",
            "date": "2017-05-31T21:00:02+0000",
            "content": "I can move this to a boolean option on BlockTreeTermsReader. When the option is disabled (thus eager), I can also have the constructor eagerly close the IndexInput for the index as it won't be needed (one less file handle).  Alternatively, I could add a method to eager load them (and close that IndexInput) that can be called immediately after construction by Lucene50PostingsFormat. Any opinion? ",
            "author": "David Smiley"
        },
        {
            "id": "comment-16032759",
            "date": "2017-06-01T10:30:54+0000",
            "content": "I don't think we should make lazy-loading of the terms index possible.  Lucene used to do this and we moved away from it, long ago, for all the traps mentioned so far.\n\nAnother trap: the memory needed by your search app would become less predictable, because you would feel successful that you were able to open the reader and run searches, and then later on when the lazy load trips, more heap is used, possibly leading to OOME.\n\nLoading the FST is also very low cost, a single seek and then sequential read of N bytes. ",
            "author": "Michael McCandless"
        },
        {
            "id": "comment-16033127",
            "date": "2017-06-01T15:07:33+0000",
            "content": "Making something not possible seems like an extreme position to take, especially considering that search isn't a one-size (one decision) fits-all technology, and Lucene is a library not a search server.  That's one aspect of search I find so interesting and fun; each user often has some unique aspects that make some defaults less appropriate for them.  Perhaps a search app might want to work in very low memory (relative to the data) environments (or very big data relative to realistic RAM amounts on a machine), and they wish to spend their resources engineering it to work and not buying more RAM.  Or perhaps they want even lower NRT search tolerances in which the term dictionaries are eagerly loaded in a non-blocking thread.  I understand it's possible to shoot one's self in the foot, so to speak, but I think that's more a question of defaults vs letting users who know and test their environment be able to do what they want to do without forking large parts of Lucene. ",
            "author": "David Smiley"
        },
        {
            "id": "comment-16034299",
            "date": "2017-06-02T07:51:50+0000",
            "content": "I agree with Mike that we should not make lazy loading possible. I don't think this change improves NRT delays, and if memory is a concern I'd rather increase the block sizes, which effectively improves the worst-case scenario, than enable lazy-loading, which only helps if not all fields are used. Also delaying to search-time a problem that should have occurred at open-time sounds wrong to me. ",
            "author": "Adrien Grand"
        }
    ]
}