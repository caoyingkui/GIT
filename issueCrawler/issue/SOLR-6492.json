{
    "id": "SOLR-6492",
    "title": "Solr field type that supports multiple, dynamic analyzers",
    "details": {
        "affect_versions": "None",
        "status": "Open",
        "fix_versions": [
            "5.0"
        ],
        "components": [
            "Schema and Analysis"
        ],
        "type": "New Feature",
        "priority": "Major",
        "labels": "",
        "resolution": "Unresolved"
    },
    "description": "A common request - particularly for multilingual search - is to be able to support one or more dynamically-selected analyzers for a field. For example, someone may have a \"content\" field and pass in a document in Greek (using an Analyzer with Tokenizer/Filters for German), a separate document in English (using an English Analyzer), and possibly even a field with mixed-language content in Greek and English. This latter case could pass the content separately through both an analyzer defined for Greek and another Analyzer defined for English, stacking or concatenating the token streams based upon the use-case.\n\nThere are some distinct advantages in terms of index size and query performance which can be obtained by stacking terms from multiple analyzers in the same field instead of duplicating content in separate fields and searching across multiple fields. \n\nOther non-multilingual use cases may include things like switching to a different analyzer for the same field to remove a feature (i.e. turning on/off query-time synonyms against the same field on a per-query basis).",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "author": "Trey Grainger",
            "id": "comment-14126258",
            "date": "2014-09-08T23:02:04+0000",
            "content": "I previously implemented this field type when writing chapter 14 of Solr in Action, but I would like to make some improvements and then submit the code back to Solr to (hopefully) be committed. The current code from Solr in Action can be found here:\nhttps://github.com/treygrainger/solr-in-action/tree/first-edition/src/main/java/sia/ch14\n\nTo use the current version, you would do the following:\n1) Add the following to schema.xml:\n  <fieldType name=\"multiText\"\n        class=\"sia.ch14.MultiTextField\" sortMissingLast=\"true\"\n        defaultFieldType=\"text_general\"\n        fieldMappings=\"en:text_english,\n                       es:text_spanish,\n                       fr:text_french,\n                       fr:text_german\"/> *\n\n  <field name=\"someMultiTextField\" type=\"multiText\" indexed=\"true\" multiValued=\"true\" />\n\n  *note that \"text_spanish\", \"text_english\", \"text_french\", and \"text_german\" refer to field types which are defined elsewhere in the schema.xml:\n\n2) Index a document with a field containing multilingual text using syntax like one of the following:\n  <field name=\"someMultiTextField\">some text</field> **\n  <field name=\"someMultiTextField\">en|some text</field>\n  <field name=\"someMultiTextField\">es|some more text</field>\n  <field name=\"someMultiTextField\">de,fr|some other text</field>\n\n  **uses the default analyzer\n\n3) submit a query specifying which language you want to query in:\n  /select?q=someMultiTextField:en,de|keyword_goes_here\n\n--------------------------------------\n\nImprovements to be made before the patch is finalized:\n1) Make it possible to specify the field type mappings in the field name instead of the field value:\n  <field name=\"someMultiTextField|de,fr\">some other text</field>\n  /select?q=a bunch of keywords here&df=someMultiTextField|en,de\n\nThis makes querying easier, because the languages can be detected prior to parsing of the query, which prevents prefixes from having to be substituted on each query term (which is cost-prohibitive for most because it effectively means pre-parsing the query before it goes to Solr).\n\n2) Enable support for switching between \"stacking\" token streams from each analyzer (good default because it mostly respects position increments across languages and minimizes duplicate tokens in the index) and concatenating token streams.\n\n3) Possibly add the ability to switch analyzers in the middle of input text:\n<field name=\"someMultiTextField\">de,fr|some other el|text</field>\n\n4) Extensive unit testing "
        },
        {
            "author": "Sharon Krisher",
            "id": "comment-14189951",
            "date": "2014-10-30T11:32:12+0000",
            "content": "Hi Trey, \nIn section (1) of \"improvements to be made before the patch is finalized\": when you pass the parameter df=someMultiTextField|en,de , which code will then parse it and use it to decide which analysis chain to use ?\n\nI have a similar issue in my project, where I need to pass the user's language to my custom analyzer so it will be able to invoke language-specific analysis code.\nI thought of the following solution:\n\n\tPass the query language as a local parameter of the query param (or as part of the df param as in your suggestion)\n\tCreate a custom parser (that extends the extended dismax parser). In this parser, read the query language from the local params of the request (parsers receive the local params and the request params in their constructor) and store the language in a ThreadLocal variable.\n\tIn my analyzer code, access the ThreadLocal variable and get the language from there.\nDo you see an issue with this solution?\n\n "
        },
        {
            "author": "Trey Grainger",
            "id": "comment-14190715",
            "date": "2014-10-30T19:58:41+0000",
            "content": "Hi Sharon,\n\nYour question was which code that will parse \"df=someMultiTextField|en,de\"\nand decide which analysis chain to use. In short, since FieldTypes have\naccess to the schema but Analyzers and Tokenizers don't, I'm creating a new\nFieldType which passes the schema into a new Analyzer, which can then pass\nthe schema into the new Tokenizer. When the Tokenizer is used, the\nfieldname (string) and value (reader) are passed in, so it is possible to\npull the metadata (\"|en,de\") off of either of these and dynamically choose\na new analysis chain analyzer from the schema at that time.\n\nI've done this work already for pulling data out of the field content (so I\nknow that works), but pulling the metadata from the fieldname is still\npending (I'm hoping to work on it this weekend). If you want to see what\nI've done thusfar, you can look on github at MultiTextField,\nMultiTextFieldAnalyzer, and MultiTextFieldTokenizer:\nhttps://github.com/treygrainger/solr-in-action/blob/master/src/main/java/sia/ch14/MultiTextField.java\nhttps://github.com/treygrainger/solr-in-action/blob/master/src/main/java/sia/ch14/MultiTextFieldAnalyzer.java\nhttps://github.com/treygrainger/solr-in-action/blob/master/src/main/java/sia/ch14/MultiTextFieldTokenizer.java\n\nI have some questions / feedback on your proposed solution... I'm hopping\non a plane now but will post them later tonight.\n\nThanks,\n\nTrey Grainger\nCo-author, Solr in Action\nDirector of Engineering, Search & Analytics @CareerBuilder\n\n\nOn Thu, Oct 30, 2014 at 7:32 AM, Sharon Krisher (JIRA) <jira@apache.org>\n "
        },
        {
            "author": "Trey Grainger",
            "id": "comment-14191418",
            "date": "2014-10-31T05:55:40+0000",
            "content": "Hi Sharon,\n\nIn terms of your suggestion, I do think that using local params to pass in\nthe language could be a more user-friendly solution than requiring them to\nput the params on the field name: i.e. q=\n{!langs=en|de}\nhello world&df=text\nvs. q=hello world&df=text|en,de, though the syntax may get a bit weird if\nyou want to specify different languages for different fields. For example,\nif using the edsimax query parser, you would need to do something like\nq=\n{!langs=text1:en,de|text2:en,zh}\nhello world&qf=text1 text2 vs. just\nq=hello world&qf=text1|en,de text2|en|zh.\n\nFor the most simple use-case (every field uses the same language), or for\nthe use-case where you don't know what fields the user is querying on\nup-front, I think the local params syntax would be preferred for end-users.\nThere is a big down-side to doing this, however: it requires you to\nimplement a qparser to parse this data and put it somewhere that the\nAnalyzer can see. This means that your multi-lingual field would only be\nsearchable with your custom query parser (whereas if the determination of\nthe language is passed in as part of the field name or content as I\ndescribed, it should work seamlessly with all of the query parsers, since\nthe data gets passed through all the way to the Analyzer).\n\nYour solution with the ThreadLocal storage of the data is interesting...\nI'm not positive whether it will work or not (i.e. does the analyzer always\nrun on the same thread as the incoming request for both queries and\nindexing, and will that also continue to be the case into the future)? I\nknow that threads are at least re-used across requests and that the\nTokenStreamComponents for analyzers are re-used in a threadlocal pool, but\nthat just means you'd have to be very careful about not caching or reusing\nlanguages across requests, not that it couldn't work. Also, just out of\ncuriosity, how do you plan to pass the languages in at index time?\n\nThe Analyzer/Tokenizers only accept the fieldname (string) and the field\ncontent (reader) as parameters, so passing in additional parameters through\na threadlocal seems like a bit of a hack that violates the design there\n(though arguably that design is too restrictive and should change). I'd be\ncurious if anyone else thinks this would work...\n\nThanks,\n\nTrey Grainger\nCo-author, Solr in Action\nDirector of Engineering, Search & Analytics @CareerBuilder\n\n\n "
        },
        {
            "author": "Kranti Parisa",
            "id": "comment-14346256",
            "date": "2015-03-04T02:22:07+0000",
            "content": "Wouldn't it be useful if there is a way to read the value of a field from the Solr document and conditionally apply the analyzer/tokenizers?\n\nSo that langid update request processor can identify the language and we can use that field value to chose analysis part dynamically.. "
        },
        {
            "author": "Kranti Parisa",
            "id": "comment-14346261",
            "date": "2015-03-04T02:26:29+0000",
            "content": "In other words, like the update processor chains we should have analysis chains defined in schema.xml and these chains could be resued between multiple fields and on each field there should be a way to conditionally chose the analysis chain based on the value of another field. \n\nNot sure if I'm reemphasizing your design.. "
        },
        {
            "author": "Trey Grainger",
            "id": "comment-14346292",
            "date": "2015-03-04T02:58:35+0000",
            "content": "Hi Kranti,\n\nThe design almost exactly as you described when you said \"have analysis chains defined in schema.xml and these chains could be resued between multiple fields and on each field there should be a way to conditionally chose the analysis chain\". Specifically, each analysis chain is just defined as a FieldType, like you would define any analysis chain you were going assign to a field.\n\nWhat I hadn't considered yet, however, was having the update processor choose choose the analyzers based upon a value in another field.  I had previously only been considering the case where a user would either:\n1) Use an automatic language identifier update processor, or\n2) Pass the language in directly in the content of the field. (i.e. <field name=\"my_field\">en,es|document content here</field>). \n\nHaving the ability to specify the key for the analyzers in a different field would probably be more user friendly, and this would be trivial to implement, so I can look to add it. Something like this:\n<field name=\"my_field\">document content here</field>\n<field name=\"language\">en</field>\n<field name=\"language\">es</field>\n\nIs that what you were hoping for? "
        },
        {
            "author": "Kranti Parisa",
            "id": "comment-14347335",
            "date": "2015-03-04T18:38:02+0000",
            "content": "Yes, so \"my_field\" will chose the analyzers based on the value of the field \"language\"? If so, how are you planning to configure that mapping?\nExample:\n\n\n<field name=\"content\" dynamicType=\"dynamic_field_type_one\" indexed=\"true\" stored=\"true\"/>  \n\n\n\n\n<dynamicFieldType name=\"dynamic_field_type_one\">\n    <condition sourceFieldName=\"language\" sourceFieldValue=\"en\" fieldType=\"text_en\"/>\n    <condition sourceFieldName=\"language\" sourceFieldValue=\"es\" fieldType=\"text_es\"/>\n    <condition sourceFieldName=\"language\" sourceFieldValue=\"ja\" fieldType=\"text_ja\"/>\n</dynamicFieldType>\n\n\n\nso that we can pick up the fieldType for the field \"content\" based on the values of another field \"language\". later stage sourceFieldValue could support regex as well and we can introduce more params to the \"condition\" element. like chose fieldType based on multiple field values etc..\n\nWe have dynamicField definitions already, why not dynamicFieldType? \n\nThis way we can reuse the \"field\" definitions except that instead of the \"type\" param we have \"dynamicType\" and get the \"fieldType\" based on the condition. once that is done, rest of the flow should be same as today to apply the correct analyzers of that field type. "
        },
        {
            "author": "Danny Teichthal",
            "id": "comment-14984312",
            "date": "2015-11-01T09:29:35+0000",
            "content": "Hi Trey Grainger,\nWe started exploring your github code for indexing multi lingual text to a single field for internal project.\nIt looks like the best solution for our requirements.\nWhat is holding us back is the question if and when it will be part of Solr.\nIs there any planned progress for this JIRA issue?\n\n\nThanks,\n\n "
        },
        {
            "author": "Trey Grainger",
            "id": "comment-15343254",
            "date": "2016-06-22T03:00:06+0000",
            "content": "Hi Kranti Parisa and Danny Teichthal. Apologies for the long lapse without a response on this issue. I won't get into the reasons here (combination of personal and professional commitments), but I just wanted to say that I expect to pick this issue back up in the near future and continue work on this patch.\n\nIn the meantime, I have added an ASL 2.0 license to the current code (from Solr in Action) so that folks can feel free to use what's there now: https://github.com/treygrainger/solr-in-action/tree/master/src/main/java/sia/ch14\n\nI'll turn what's there now into a patch, update it to Solr trunk, and keep iterating on it until the folks commenting on this issue are satisfied with the design and capabilities. Stay tuned... "
        },
        {
            "author": "Kranti Parisa",
            "id": "comment-15345062",
            "date": "2016-06-22T19:54:30+0000",
            "content": "Trey Grainger awesome, looking fwd to it. "
        },
        {
            "author": "Danny Teichthal",
            "id": "comment-15345928",
            "date": "2016-06-23T07:03:18+0000",
            "content": "Trey Grainger - great, looking forward too.\nAre there any other planned changes except from the new license? "
        },
        {
            "author": "Jan Rasehorn",
            "id": "comment-16028252",
            "date": "2017-05-29T11:42:53+0000",
            "content": "Hi Guys, this sounds like a solution for indexing a whole document when the document language is known upfront. \nBut what if the language is not known upfront or if a document contains different text paragraphs with possibly different languages - like it can often be found in support tickets?\n\nSince I did not like the approach using separate fields, I did it the following way:\n1. I wrote a tokenizer that detects the paragraphs based on a given regexp (a result of cleaning up the support ticket text)\n2. The tokenizer detects the paragraph language at runtime (using the solr built in language detector)\n3. The tokenizer runs Open NLP POS tagging depending on the language it identified and saves the POS tags in the type attribute for each token. \n    The language is stored as payload for each token.\n4. I developed a \"Delegating filter\", which only delegates the \"incrementToken\" call to the filter (stemmer) if the payload value matched the filter value. This way I can configure in schema.xml, which stemmer to use for which language.\n\nWith this approach I do not depend on knowning the document language upfront.\nWhat do you think? "
        },
        {
            "author": "David Smiley",
            "id": "comment-16028623",
            "date": "2017-05-29T20:59:21+0000",
            "content": "Nice strategy Jan R.! "
        },
        {
            "author": "Jan Rasehorn",
            "id": "comment-16043031",
            "date": "2017-06-08T16:57:02+0000",
            "content": "The issue with the approach above is, that for small texts a different language might be determined. This means the same words are stemmed differently by the query analyzer compared to the index analyzer. \nSo I chose another strategy for the query analyzer.\nI simply create copies of the query tokens and add a language payload for the languages I want to support. After that I apply the same approach as used in the index analyzer to call the appropriate stemmers for the different languages using my \"DelegatingFilter\". So in the end the query tokens will be copied and stemmed by different stemmers independently which language the query tokens actually belong to. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-16292780",
            "date": "2017-12-15T16:42:50+0000",
            "content": "Another application of this that just crossed my mind is the old \"exact match when stemming\" process. KeywordRepeatFilterFactory>>stemmer>>RemoveDuplicatesTokenFilterFactory at index time and then two analysis chains at query time, one with the stemmer and one without.\n\nStill not perfect, if I index \"running\" and then search for \"run\" I'd get a match on the stemmed version. It would handle the case of indexing \"run\" and searching (exact match) on \"running\" and some of the other more surprising effects of stemming. "
        }
    ]
}