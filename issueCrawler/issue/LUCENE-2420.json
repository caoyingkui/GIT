{
    "id": "LUCENE-2420",
    "title": "\"fdx size mismatch\" overflow causes RuntimeException",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [
            "core/index"
        ],
        "type": "Bug",
        "fix_versions": [],
        "affect_versions": "3.0.1",
        "resolution": "Not A Problem",
        "status": "Closed"
    },
    "description": "I just saw the following error:\n\njava.lang.RuntimeException: after flush: fdx size mismatch: -512764976 docs vs 30257618564 length in bytes of _0.fdx file exists?=true\n        at org.apache.lucene.index.StoredFieldsWriter.closeDocStore(StoredFieldsWriter.java:97)\n        at org.apache.lucene.index.DocFieldProcessor.closeDocStore(DocFieldProcessor.java:51)\n        at org.apache.lucene.index.DocumentsWriter.closeDocStore(DocumentsWriter.java:371)\n        at org.apache.lucene.index.IndexWriter.flushDocStores(IndexWriter.java:1724)\n        at org.apache.lucene.index.IndexWriter.doFlushInternal(IndexWriter.java:3565)\n        at org.apache.lucene.index.IndexWriter.doFlush(IndexWriter.java:3491)\n        at org.apache.lucene.index.IndexWriter.flush(IndexWriter.java:3482)\n        at org.apache.lucene.index.IndexWriter.closeInternal(IndexWriter.java:1658)\n        at org.apache.lucene.index.IndexWriter.close(IndexWriter.java:1621)\n        at org.apache.lucene.index.IndexWriter.close(IndexWriter.java:1585)\n\nNote the negative SegmentWriteState.numDocsInStore. I assume this is because Lucene has a limit of 2 ^ 31 - 1 = 2147483647 (sizeof(int)) documents per index, though I couldn't find this documented clearly anywhere. It would have been nice to get this error earlier, back when I exceeded the limit, rather than now, after a bunch of indexing that was apparently doomed to fail.\n\nHence, two suggestions:\n\n\tState clearly somewhere that the maximum number of documents in a Lucene index is sizeof(int).\n\tThrow an exception when an IndexWriter first exceeds this number rather than only on close.",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "date": "2010-04-29T18:18:31+0000",
            "content": "I remember that the Integer.MAX_VAL is documented somewhere. I can try to look it up later. But a lot of places in the API use int as the doc Id (IndexReader, ScoreDoc, even IndexWriter.max/numDocs()), and so I think there's a strong hint about that limitation.\n\nAs for throwing the exception sooner, I don't think it will be correct. IndexWriter implements transaction semantics. Until you call commit() or close(), whatever operations you've made are not officially in the index yet. If your JVM dies before that, they will get lost. Therefore throwing the exception earlier would be wrong. Also think that you intend to index 1000 docs and delete 100,000. Would you want to get the exception while adding the docs, knowing that you are about to delete much more soon?\n ",
            "author": "Shai Erera",
            "id": "comment-12862312"
        },
        {
            "date": "2010-04-29T22:55:05+0000",
            "content": "I finally found the documentation saying that the maximum number of documents is ~274 billion:\n  http://lucene.apache.org/java/3_0_1/fileformats.html\n\nGoogle queries that failed to find this:\n  lucene index maximum documents\n  lucene document limit\n  lucene max docs\n\nMaybe a bullet could be added to the FAQ (which does turn up for most of these queries)?\n  http://wiki.apache.org/lucene-java/LuceneFAQ\n\nAs far as the exception goes, regardless of the transaction semantics, I really don't think the code works correctly after numeric overflow. Once SegmentWriteState.numDocsInStore is negative, I would expect code like StoredFieldsWriter.flush to fail:\n\n  synchronized public void flush(SegmentWriteState state) throws IOException {\n    if (state.numDocsInStore > 0) {\n      ...\n\nPerhaps I'm wrong, but it seems like this is going to do the wrong thing when SegmentWriteState.numDocsInStore is negative. If I'm not wrong, then it seems sensible to me to raise an exception on numeric overflow. ",
            "author": "Steven Bethard",
            "id": "comment-12862463"
        },
        {
            "date": "2010-04-30T04:10:26+0000",
            "content": "That documentation discusses the limitation around the number of unique terms Lucene can handle, which sums up to ~274 billion: \"which means the maximum number of unique terms in any single index segment is ~2.1 billion times the term index interval (default 128) = ~274 billion\".\n\nOne line below this you can find this documentation: \"Similarly, Lucene uses a Java int to refer to document numbers, and the index file format uses an Int32 on-disk to store document numbers\" which suggests the Integer.MAX_VAL limitation ... but I agree it could have been spelled out more clearly.\n\nIf numDocsInStore is negative, SegmentFieldsWriter.flush() doesn't do anything ... you mean that that code should throw the exception? ",
            "author": "Shai Erera",
            "id": "comment-12862528"
        },
        {
            "date": "2010-04-30T07:25:45+0000",
            "content": "Thanks, yeah, something more explicit and easier to find with Google would be good.\n\nYeah, I mean that code should throw the exception. Actually, anywhere that checks the value of numDocsInStore could/should throw the exception, e.g.\n\nsynchronized public void flush(SegmentWriteState state) throws IOException {\n    if (state.numDocsInStore > 0) {\n\n synchronized public void closeDocStore(SegmentWriteState state) throws IOException {\n    final int inc = state.numDocsInStore - lastDocID;\n    if (inc > 0) {\n\nDon't know if SegmentWriteState.numDocsInStore is used anywhere else (I haven't loaded it into an IDE to look at files other than StoredFieldsWriter), but in at least these two cases it would be easy to give an exception explaining that the maximum number of documents had been exceeded.\n\nAlternatively, you could try to fix the code to work correctly after integer overflow (to support the transaction use case you described above) though it's less obvious to me how to do that correctly everywhere. Probably involves changing some \"> 0\"s into \"!= 0\"s and being careful in a few other ways. ",
            "author": "Steven Bethard",
            "id": "comment-12862571"
        },
        {
            "date": "2015-08-18T07:52:47+0000",
            "content": "Closing old inactive issue.\nIf this is still something you think needs fixing, please re-open this issue and provide more information. ",
            "author": "Jan H\u00f8ydahl",
            "id": "comment-14700873"
        }
    ]
}