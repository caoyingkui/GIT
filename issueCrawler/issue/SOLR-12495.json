{
    "id": "SOLR-12495",
    "title": "Enhance the Autoscaling policy syntax to evenly distribute replicas among nodes",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [
            "AutoScaling"
        ],
        "type": "New Feature",
        "fix_versions": [
            "7.5",
            "master (8.0)"
        ],
        "affect_versions": "None",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "Support a new function value for\u00a0replica= \"#EQUAL\"\n\n#EQUAL\u00a0means the equal no:of replicas on each \"node\"\nthe value of replica will be calculated as\u00a0\u00a0<= Math.ceil(number_of_replicas/number_of_valid_nodes)\u00a0\n\nexample 1:\n\n{\"replica\" : \"#EQUAL\" , \"shard\" : \"#EACH\" , \"node\" : \"#ANY\"}\n\n\ncase 1 : nodes=3, replicationFactor=4\n the value of replica will be calculated as Math.ceil(4/3) = 1.33\n\ncurrent state : nodes=3, replicationFactor=2\n\nthis is equivalent to the hard coded rule\n\n{\"replica\" : \"<3\" , \"shard\" : \"#EACH\" , \"node\" : \"#ANY\"}\n\n\ncase 2\u00a0:\u00a0\ncurrent state : nodes=3, replicationFactor=2\n\nthis is equivalent to the hard coded rule\n\n{\"replica\" : \"<3\" , \"shard\" : \"#EACH\" , \"node\" : \"#ANY\"}\n\n\nexample:2\n\n{\"replica\" : \"#EQUAL\"  , \"node\" : \"#ANY\"}\n\ncase 1: numShards = 2, replicationFactor=3, nodes = 5\n\nthis is equivalent to the hard coded rule\n\n{\"replica\" : \"1.2\" , \"node\" : \"#ANY\"}",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "date": "2018-06-20T18:44:22+0000",
            "content": "Wanted to add a couple of comments:\n\nWould be great if this occurs per-collection. For example, a collection with 42 replicas and 40 nodes should expect to have one replica from that collection on each node, with 2 nodes having\u00a02 replicas. {\"replica\": \"#MINIMUM\", \"collection\": \"#EACH\", \"node\": \"#ANY\"}\n\nCluster-wide\u00a0would also go along with this, making sure each node has a similar amount of replicas. {\"replica\": \"#MINIMUM\", \"node\": \"#ANY\"}\n\nA warning that \"<3\" which is ceil(42/40) = 2 works, but only after each node has one\u00a0replica. This rule also allows for 2 replicas on 21 nodes, which is not as good as 1 replica on all nodes, and 2 replicas on 1 node. I think this\u00a0should be fixed by the ordering of the nodes by preference, but only if the list is updated after each movement.\n\nNoble Paul FYI ",
            "author": "Jerry Bao",
            "id": "comment-16518476"
        },
        {
            "date": "2018-06-21T14:35:00+0000",
            "content": "well\n\n\n{\"replica\": \"#MINIMUM\", \"node\": \"#ANY\"}\n\n\n\nmeans it is applied on a per collection basis\n\nA warning that \"<3\" which is ceil(42/40) = 2 works, but only after each node has one replica. This rule also allows for 2 replicas on 21 nodes\n\nIn reality, it works slightly different.  The value \"<3\" is not a constant . it keeps varying when every replica is created. for instance , when replica # 40 is being created , the value is (40/40 = 1) that is like saying replica:\"<2\" .  whereas , when replica #41 is created, it suddenly becomes \"replica\" : \"<3\". So actually allocations happen evenly \n\n\u00a0 ",
            "author": "Noble Paul",
            "id": "comment-16519435"
        },
        {
            "date": "2018-06-21T18:39:28+0000",
            "content": "well\n\n{\"replica\": \"#MINIMUM\", \"node\": \"#ANY\"}\n\n\nmeans it is applied on a per collection basis\nThat seems confusing to me; the way I read it is: keep a minimum number of replicas on every node. Just to clarify, when you say per-collection basis, you're meaning each collection is balanced? If that is so will there be a way to keep the entire cluster balanced irrespective of collection? Is that covered by the core preference? My concern here is that without a way to keep the entire cluster balanced irrespective of collection, you'll end up with nodes with one replica of every collection and other nodes with 0 replicas. For example, if you had three collections with 30 replicas each, and 45 nodes, you could end up with 30 nodes, each with one of each collections replica, and 15 nodes with 0 replicas, which is unbalanced.\nIn reality, it works slightly different. The value \"<3\" is not a constant . it keeps varying when every replica is created. for instance , when replica # 40 is being created , the value is (40/40 = 1) that is like saying\u00a0replica:\"<2\"\u00a0. whereas , when replica #41 is created, it suddenly becomes\u00a0\"replica\" : \"<3\". So actually allocations happen evenly\nI understand that it's not constant, but what I'm saying is the rule itself can not be violated but the cluster not balanced. If I have 42\u00a0replicas and 40 nodes, I would want 1 replica on every node before getting 2 on other nodes. ceil(42/40) -> <3 rule, which has the potential of having 2 replicas on 21 nodes, which satisfies the rule but is not balanced. ",
            "author": "Jerry Bao",
            "id": "comment-16519668"
        },
        {
            "date": "2018-06-22T05:43:50+0000",
            "content": "That seems confusing to me; the way I read it is: keep a minimum number of replicas on every node. ...\nActually, the terms replica , shard are always associated with a collection. If the attribute shard is present , the replica counts are computed on a per-shard basis , if it is absent, it is computed on a per-collection basis\n\nThe equivalent term for a replica globally is a core which is not associated with a collection or shard\nI understand that it's not constant, but what I'm saying is the rule itself can not be violated but the cluster not balanced.\nright . what it means is that it will not show any violation even though new replicas are assigned appropriately. I'm going to redefine the meaning of #MINIMUM\n\nInstead of computing the value to <= Math.ceil(number_of_replicas/number_of_valid_nodes) it will be computed to the actual value of number_of_replicas/number_of_valid_nodes .\n So, in your case if there are 40 nodes and 42 replicas , it is equivalent to\n\n{\"replica\": 1.02, \"node\": \"#ANY\"}\n\n\nThat means The no:of of replicas will have to be between 1 and 2 (inclusive) . Which means , both 1 and 2 are valid but 0 ,\u00a03 or >3 are invalid and , the list of violations will show that ",
            "author": "Noble Paul",
            "id": "comment-16520032"
        },
        {
            "date": "2018-06-22T18:21:36+0000",
            "content": "\nActually, the terms replica , shard are always associated with a collection. If the attribute shard is present , the replica counts are computed on a per-shard basis , if it is absent, it is computed on a per-collection basis\n\nThe equivalent term for a replica globally is a core which is not associated with a collection or shard\nI see; could \n{\"core\": \"#MINIMUM\", \"node\": \"#ANY\"}\n be included with this issue? Along with per-collection balancing, we'll also need cluster-wide balancing.\n\n\nThat means The no:of of replicas will have to be between 1 and 2 (inclusive) . Which means , both 1 and 2 are valid but 0 , 3 or >3 are invalid and , the list of violations will show that\nAwesome! No qualms here then \n\nThanks for all your help on this issue! Cluster balancing is a critical issue for us @ Reddit. ",
            "author": "Jerry Bao",
            "id": "comment-16520654"
        },
        {
            "date": "2018-06-23T02:02:40+0000",
            "content": "I see; could {\"core\": \"#MINIMUM\", \"node\": \"#ANY\"} be included with this issue? Along with per-collection balancing, we'll also need cluster-wide balancing.\n\nwell we already have a global preference which says \n\n{\"minimize\" : \"cores\"}\n\n\n\nIs there anything that's not already addressed by that? I understand that it won't show any violations if you are already in an imbalanced state. \n\nThe problem with implementing a feature like this that  you can clearly have conflicts if you create 2 rules as follows. This can always lead to violations which are impossible to satisfy\n\n{\"cores\" : \"#MINIMUM\", \"node\" : \"#ANY\"}\n{\"replica\" : \"#MINIMUM\", \"shard\" : \"#EACH\", \"node\" : \"#ANY\"}\n\n ",
            "author": "Noble Paul",
            "id": "comment-16520943"
        },
        {
            "date": "2018-06-24T01:22:22+0000",
            "content": "\nIs there anything that's not already addressed by that? I understand that it won't show any violations if you are already in an imbalanced state.\n\nThats the main issue: no violations if you're already in an imbalanced state. If the autoscaling suggestions also suggested to move replicas to a more balanced state (based on the preferences) without any violations, then that would solve this issue. \n\nWe have machines that have 0 load on them because the collections are distributed amongst the machines but all of the replicas aren't distributed. We also see machines with too much load because they have one of every collection's replica on it.\n\n\nThis can always lead to violations which are impossible to satisfy\n\nI think this can lead to violations that are impossible to satisfy because often to fix the violation, it takes multiple steps. Something like, doing a 3-way triangle movement. I understand that the more movement possible, the exponential increase in combinations you have to check, but I think we can be smarter here about deciding which machines are definitely possible to move to and which doesn't make sense to move to.\n\nI would say that if we could incorporate the preferences into suggestions (so that the trigger can move things to be more balanced based on our preferences), that should help us a lot here. ",
            "author": "Jerry Bao",
            "id": "comment-16521323"
        },
        {
            "date": "2018-07-04T14:40:05+0000",
            "content": "Commit f86c477521637a5cd48808c9f6b3d86b6db92b42 in lucene-solr's branch refs/heads/master from Noble Paul\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=f86c477 ]\n\nSOLR-12495: An #EQUALS function for replica in autoscaling policy to equally distribute replicas ",
            "author": "ASF subversion and git services",
            "id": "comment-16532834"
        },
        {
            "date": "2018-07-04T14:42:41+0000",
            "content": "Commit cdb8a00a088cedb5f7031f242d3478cdab76e7f5 in lucene-solr's branch refs/heads/branch_7x from Noble Paul\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=cdb8a00 ]\n\nSOLR-12495: An #EQUALS function for replica in autoscaling policy to equally distribute replicas ",
            "author": "ASF subversion and git services",
            "id": "comment-16532835"
        },
        {
            "date": "2018-07-16T07:56:48+0000",
            "content": "Commit 4240402c5e3b5c8d3c3882c0f813d896f9ec9fd0 in lucene-solr's branch refs/heads/branch_7x from Noble Paul\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=4240402 ]\n\nSOLR-12495,SOLR-11986 ref guide ",
            "author": "ASF subversion and git services",
            "id": "comment-16544919"
        },
        {
            "date": "2018-07-16T07:58:15+0000",
            "content": "Commit 1e50030940c2b089542e180d1abc6af66ac0c947 in lucene-solr's branch refs/heads/master from Noble Paul\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=1e50030 ]\n\nSOLR-12495,SOLR-11986 ref guide ",
            "author": "ASF subversion and git services",
            "id": "comment-16544922"
        }
    ]
}