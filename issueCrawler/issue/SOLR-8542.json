{
    "id": "SOLR-8542",
    "title": "Integrate Learning to Rank into Solr",
    "details": {
        "components": [],
        "type": "New Feature",
        "labels": "",
        "fix_versions": [
            "6.4",
            "7.0"
        ],
        "affect_versions": "None",
        "status": "Resolved",
        "resolution": "Fixed",
        "priority": "Major"
    },
    "description": "This is a ticket to integrate learning to rank machine learning models into Solr. Solr Learning to Rank (LTR) provides a way for you to extract features directly inside Solr for use in training a machine learned model. You can then deploy that model to Solr and use it to rerank your top X search results. This concept was previously presented by the authors at Lucene/Solr Revolution 2015.\n\n\n\nSolr Reference Guide documentation:\n\n\thttps://cwiki.apache.org/confluence/display/solr/Learning+To+Rank\n\n\n\nSource code and README files:\n\n\tsolr/contrib/ltr\n\tsolr/contrib/ltr/example",
    "attachments": {
        "SOLR-8542.patch": "https://issues.apache.org/jira/secure/attachment/12836396/SOLR-8542.patch",
        "SOLR-8542-branch_5x.patch": "https://issues.apache.org/jira/secure/attachment/12782146/SOLR-8542-branch_5x.patch",
        "SOLR-8542-trunk.patch": "https://issues.apache.org/jira/secure/attachment/12782118/SOLR-8542-trunk.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2016-01-13T20:00:36+0000",
            "author": "Michael Nilsson",
            "content": "Attached the patch against trunk which contains our LTR code as a contrib module, plus a readme.md going over how to use it. ",
            "id": "comment-15096887"
        },
        {
            "date": "2016-01-13T22:39:46+0000",
            "author": "Michael Nilsson",
            "content": "Attached a patch for the ltr contrib module against branch_5x as well ",
            "id": "comment-15097177"
        },
        {
            "date": "2016-01-14T19:20:52+0000",
            "author": "Christine Poerschke",
            "content": "Hello Joshua, Michael and Diego. Thanks for your patch for this new feature.\n\nJust to say that i've started taking a look at yesterday's SOLR-8542-trunk.patch and have three simple observations so far, in no particular order:\n\n\tMany of the lines in solr/contrib/ltr/README.txt are very long. Having said that, I do not know what the recommended maximum line length for README files is and am perhaps just using the wrong browser or editor to read.\n\tBinary diff for solr/contrib/ltr/test-lib/jcl-over-slf4j-1.7.7.jar seems to form part of the patch, unintentionally so probably.\n\tRunning ant validate after applying to patch locally points out 'tabs instead of spaces' and 'invalid logging pattern' for some of the files.\n\n\n\n(The https://en.wikipedia.org/wiki/Learning_to_rank page mentioned in the README.txt for reading up on learning to rank will be my commute reading.) ",
            "id": "comment-15098670"
        },
        {
            "date": "2016-01-14T19:36:19+0000",
            "author": "Shawn Heisey",
            "content": "I personally use 80 columns for files like README.txt, but from other people's additions to CHANGES.txt, I know that others are using more.  I am frequently viewing text files like this in ssh or on terminals, so I find lines longer than 80 characters to be annoying.  For source code, I edit in an IDE more often than with vi, so longer lines are not really a problem there. ",
            "id": "comment-15098702"
        },
        {
            "date": "2016-01-16T00:07:46+0000",
            "author": "ASF GitHub Bot",
            "content": "GitHub user diegoceccarelli opened a pull request:\n\n    https://github.com/apache/lucene-solr/pull/217\n\n    SOLR-8542: Integrate Learning to Rank into Solr\n\n    See https://issues.apache.org/jira/i#browse/SOLR-8542\n\nYou can merge this pull request into a Git repository by running:\n\n    $ git pull https://github.com/bloomberg/lucene-solr trunk-learning-to-rank-plugin\n\nAlternatively you can review and apply these changes as the patch at:\n\n    https://github.com/apache/lucene-solr/pull/217.patch\n\nTo close this pull request, make a commit to your master/trunk branch\nwith (at least) the following in the commit message:\n\n    This closes #217\n\n\ncommit 336db4ccf6434e690a745a4af88b5d9c21edc25e\nAuthor: Diego Ceccarelli <dceccarelli4@bloomberg.net>\nDate:   2016-01-13T22:29:17Z\n\n    SOLR-8542: Integrate Learning to Rank into Solr\n\n    Solr Learning to Rank (LTR) provides a way for you to extract features\n    directly inside Solr for use in training a machine learned model. You\n    can then deploy that model to Solr and use it to rerank your top X\n    search results. This concept was previously presented by the authors at\n    Lucene/Solr Revolution 2015\n\n ",
            "id": "comment-15102741"
        },
        {
            "date": "2016-01-16T00:21:49+0000",
            "author": "Diego Ceccarelli",
            "content": "Thanks Christine and Shawn for your comments, \nThe above patch for the current trunk fix the problems that you highlighted: \n\n\tnow the README fits in 80 columns\n\tant validate works.\n\tsolr/contrib/ltr/test-lib/jcl-over-slf4j-1.7.7.jar is not part of the patch\n\n\n\nThe patch also contains some example files and an explanation (reported in the JIRA description) on \nhow to test the plugin on the techproducts example of Solr. \n ",
            "id": "comment-15102768"
        },
        {
            "date": "2016-01-16T12:24:47+0000",
            "author": "Ishan Chattopadhyaya",
            "content": "Exciting stuff! \nEven though I haven't yet tried out the patch here, I was wondering how easy would it be to plugin some of the RankLib stuff in future? There's SOLR-8183 for this. I was wondering if the framework developed here is generic enough to have some of those algorithms (and others) to be plugged in. Personally, I'm interested in the GBDT algorithm (since I've used that in a previous project) and MART seems close to that.\n ",
            "id": "comment-15103146"
        },
        {
            "date": "2016-01-16T17:13:23+0000",
            "author": "Diego Ceccarelli",
            "content": "Hi Ishan, thanks for pointing out SOLR-8183, I didn't know about that, it seems quite related. \nWe can plug RankLib creating a new class representing the new LTR model, extending ModelMetadata, for example:\n\n\npublic class RankLibModel extends ModelMetadata {\n\t\n\tRanker rankLibRanker;\n\tRankerFactory rankerFactory = new RankerFactory();\n\tDenseDataPoint documentFeatures = new DenseDataPoint(); // this contructor is missing, we will need a way to create a datapoint\n\t\n\tpublic RankLibModel(String name, String type, List<Feature> features,\n\t      String featureStoreName, Collection<Feature> allFeatures,\n\t      NamedParams params) {\n\t\t  super(name, type, features, featureStoreName, allFeatures, params);\n\t\t  // the  file containing the model is  a parameter\n\t\t  String ranklibModelFile = getParams().getParam(\"model-file\")\n\t\t  // load the model\n\t\t  rankLibRanking = rankerFactory.loadModel(ranklibModelFile);\n\t}\n\t\n\t@Override\n\tpublic float score(float[] modelFeatureValuesNormalized) {\n\t\t// set the feature vector in the datapoint object\n\t        documentFeatures.setFeatureVector(modelFeatureValuesNormalized)\n\t\t// predict the score using the ranklib model\n\t\treturn rankLibRanker.eval(documentFeatures);\n\t}\n\t\t  \n}\n\n\n\nThis code will load a particular RankLib model, using the file specified into the model store configuration. \nIf you send to Solr a model configuration file like this:\n\n\n{\n    \"type\":\"org.apache.solr.ltr.ranking.RankLibModel\",\n    \"name\":\"ranklib-GBDT\",\n    \"features\":[\n    {\"name\":\"isInStock\"},\n    {\"name\":\"price\"},\n    {\"name\":\"originalScore\"},\n    {\"name\":\"productNameMatchQuery\"}\n    ],\n    \"params\":{\n\t\t\"model-file\":\"/data/ranking/ranking-GBDT.txt\"        \n    }\n}\n\n\n\nThe plugin will create a RankLib model by using the model in /data/ranking/ranking-GBDT.txt and you'll be able \nto use it at ranking time using its name ranklib-GBDT, adding the ltr param to the query: \n\n\nhttp://localhost:8983/solr/techproducts/query?indent=on&q=test&wt=json&rq={!ltr model=ranklib-GBDT reRankDocs=25} \n\n\n\nAt query time, the features isInStock , price , originalScore , and productNameMatchQuery will be computed and provided in the score(float[] modelFeatureValuesNormalized) method in order to get the new predicted score \nfor each document. If RankLib's licence is compatible I think we could plug this into the plugin. Any comments?  ",
            "id": "comment-15103260"
        },
        {
            "date": "2016-01-17T05:45:26+0000",
            "author": "Ajinkya Kale",
            "content": "+1 to RankLib inside this plugin. Will save re-implementations of LTR algorithms. ",
            "id": "comment-15103601"
        },
        {
            "date": "2016-01-17T08:19:24+0000",
            "author": "Upayavira",
            "content": "Why mstore and fstore on the schema api? Can't we have schema/feature-store and schema/model-store? They are way more self-explanatory and make the LTR stuff that little bit more accessible. ",
            "id": "comment-15103631"
        },
        {
            "date": "2016-01-18T20:32:36+0000",
            "author": "Christine Poerschke",
            "content": "Hi Diego - thanks for patch update:\n\n\tI started looking at the code in https://github.com/apache/lucene-solr/pull/217.patch today but am still a bit undecided on how to best share comments, e.g. reviews.apache.org vs. github pull request comments vs. in this JIRA log vs. some other way? Code comments in this JIRA log would probably distract from what the new feature is about. reviews.apache.org seems to have a nicer diff than github but does it require extra step(s) after updating the github pull request (I have not used reviews.apache.org so far).\n\tticket cross-reference: LUCENE-6971 removed StorableField and StoredDocument yesterday/today (217.patch from the day-before-yesterday used them in a few places)\n\n\n ",
            "id": "comment-15105790"
        },
        {
            "date": "2016-01-29T17:34:37+0000",
            "author": "Tommaso Teofili",
            "content": "I do not seem to be able to browse the PR at https://github.com/apache/lucene-solr/pull/217.patch is the attached patch supposed to be the one to review instead ? ",
            "id": "comment-15123843"
        },
        {
            "date": "2016-01-29T17:38:29+0000",
            "author": "Diego Ceccarelli",
            "content": "Hi Tommaso, It was removed during the transition from svn to git. We'll reopen the PR today.  ",
            "id": "comment-15123848"
        },
        {
            "date": "2016-01-29T18:40:11+0000",
            "author": "ASF GitHub Bot",
            "content": "GitHub user diegoceccarelli opened a pull request:\n\n    https://github.com/apache/lucene-solr/pull/4\n\n    SOLR-8542: Integrate Learning to Rank into Solr\n\n    Solr Learning to Rank (LTR) provides a way for you to extract features\n    directly inside Solr for use in training a machine learned model. You\n    can then deploy that model to Solr and use it to rerank your top X\n    search results. This concept was previously presented by the authors at\n    Lucene/Solr Revolution 2015\n\nYou can merge this pull request into a Git repository by running:\n\n    $ git pull https://github.com/bloomberg/lucene-solr master-ltr-plugin-rfc\n\nAlternatively you can review and apply these changes as the patch at:\n\n    https://github.com/apache/lucene-solr/pull/4.patch\n\nTo close this pull request, make a commit to your master/trunk branch\nwith (at least) the following in the commit message:\n\n    This closes #4\n\n\ncommit 1bee2ad0ce64b2f091e34f7fb42e00387616c987\nAuthor: Diego Ceccarelli <dceccarelli4@bloomberg.net>\nDate:   2016-01-13T22:29:17Z\n\n    SOLR-8542: Integrate Learning to Rank into Solr\n\n    Solr Learning to Rank (LTR) provides a way for you to extract features\n    directly inside Solr for use in training a machine learned model. You\n    can then deploy that model to Solr and use it to rerank your top X\n    search results. This concept was previously presented by the authors at\n    Lucene/Solr Revolution 2015\n\n ",
            "id": "comment-15123954"
        },
        {
            "date": "2016-01-29T18:46:48+0000",
            "author": "Michael Nilsson",
            "content": "We have reopened the pull request now into master, which used to be trunk before the svn->git conversion.  Next week we will start addressing the comments posted thus far in the ticket as well. ",
            "id": "comment-15123964"
        },
        {
            "date": "2016-02-22T16:27:35+0000",
            "author": "Christine Poerschke",
            "content": "Hello. Just a quick note to say that i'm resuming actively looking at this ticket, today focused mainly on the solr/contrib/ltr/src/java/org/apache/solr/ltr/rest classes.\n\ncode comments/questions:\n\n\tIn ManagedFeatureStore and ManagedModelStore the doDeleteChild method makes no storeManagedData method call - oversight?\n\tManagedFeatureStore.doGet throws an exception when the childId concerned is not present, might it just return a response without features?\n\tManagedResource.doPut->ManagedFeatureStore.applyUpdatesToManagedData->update->addFeature calling chain it seems could throw an exception when a name being updated/added already exists. REST wikipedia page mentions about PUT and DELETE being idempotent - should repeats of the same name simply replace the existing entry for that name?\n\n\n\nobservations (question to follow):\n\n\tManagedFeatureStore.addFeature calls NameValidator.check and could throw an InvalidFeatureNameException exception\n\tManagedFeatureStore.createFeature would throw an exception if Class.forName(type) finds no class or f.init(name, params, id) throws an exception\n\tManagedModelStore.applyUpdatesToManagedData->update->makeModelMetaData throws an exception when the data has no features field or when there are other 'invalid input' type problems\n\tLTRComponent uses ManagedFeatureStore and ManagedModelStore\n\tLTRQParserPlugin uses ManagedModelStore, and ManagedModelStore in turn uses ManagedFeatureStore\n\n\n\nquestion (for everyone and perhaps more REST that LTR related actually really?):\n\n\tTo what extent should the REST/ManagedResource class be only representing state and/or to what extent should it also contain 'invalid input' type logic and associated error handling?\n\tIf the represented state could be logically valid as well as invalid, might the state representation and use of the represented state be separated out, perhaps something along these lines in LTRComponent.inform(SolrCore core)?\n\n\n\n\ncore.getRestManager().addManagedResource(LTRParams.FSTORE_END_POINT, ManagedFeatureStoreInfo.class);\nManagedFeatureStoreInfo fri = (ManagedFeatureStoreInfo) core.getRestManager().getManagedResource(LTRParams.FSTORE_END_POINT);\n\ncore.getRestManager().addManagedResource(LTRParams.MSTORE_END_POINT, ManagedModelStoreInfo.class);\nManagedModelStoreInfo mri = (ManagedModelStoreInfo) core.getRestManager().getManagedResource(LTRParams.MSTORE_END_POINT);\n\nLTRModelStore ltr_ms;\ntry {\n  ltr_ms = new LTRModelStore(fri, mri);\n} catch ... {\n  // exception handling here\n}\n// TODO: do something here so that ltr_ms is available to LTRQParserPlugin\n// question: would feature store and model store changes still propagate through to ltr_ms?\n\n ",
            "id": "comment-15157231"
        },
        {
            "date": "2016-02-24T14:36:27+0000",
            "author": "Christine Poerschke",
            "content": "Continued looking at this ticket's patch/pull request - cool stuff! Comments and questions to follow. Thank you. ",
            "id": "comment-15163092"
        },
        {
            "date": "2016-02-24T14:39:01+0000",
            "author": "Christine Poerschke",
            "content": "The branch behind the https://github.com/apache/lucene-solr/pull/4 above is master-ltr-plugin-rfc and i've just created master-ltr-plugin-rfc-cpoerschke-comments branch off that.\n\nIn (unrelated) SOLR-8621 we had an in-progress branch also and its usage and intentions emerged and were clarified over time, and so based on that perhaps it's helpful to suggest usage up-front here:\n\n\tmaster-ltr-plugin-rfc branches off (Jan 29th) master\n\tmaster-ltr-plugin-rfc-cpoerschke-comments branches off (Feb 24th) master-ltr-plugin-rfc\n\t'git merge' and 'git rebase' and 'git --force push' will be avoided\n\tfurther commits to master-ltr-plugin-rfc* are anticipated\n\t'git cherry-pick' of changes from master to master-ltr-plugin-rfc* will be done where helpful (e.g. SOLR-8600 was cherry-picked from master to master-ltr-plugin-rfc-cpoerschke-comments)\n\tcherry-picking between master-ltr-plugin-rfc* branches welcome and will be done where helpful\n\tat some point in the future activity on master-ltr-plugin-rfc* branches will cease and if required a new (say) master-ltr-plugin-rfc-march branch off (Mar 1?th) master will be created\n\tat the very end everything will be squashed and rebased onto latest master and then committed as a single commit\n\n\n\nDoes that sound workable or too complicated? Alternatives, comments, etc. welcome as usual. (And to clarify, suggested usage here is specific for this SOLR-8542 ticket only, any general recommended usage type discussions would be for elsewhere.) ",
            "id": "comment-15163098"
        },
        {
            "date": "2016-02-24T14:42:44+0000",
            "author": "Christine Poerschke",
            "content": "Question related to Feature Engineering - is that the right term? - and feature extraction.\n\nLTRQParserPlugin.java#L117 mentions\n\nFor training a new model offline you need feature vectors, but dont yet have a model.\n\nand README.txt#L280 mentions about for now using a dummy model e.g.\n\nfv=true&fl=*,score,[features]&rq={!ltr model=dummyModel reRankDocs=25}\n\nto extract features.\n\nIf it is known already, could you outline what the replacement for the above fv/fl/dummyModel combination is likely to look like?\n\nSemi-related to that:\n\n\twould the efi.* parameters move out of the rq then since candidate features to be returned in the response might reference external feature info?\n\tmight it be useful to have optional version and/or comment string elements in the feature and model JSON format? Illustration:\n\n{\n  \"type\": \"org.apache.solr.ltr.feature.impl.SolrFeature\",\n  \"name\":  \"documentRecency\",\n  \"comment\": \"Initial version, we may have to tweak the recip function arguments later.\",\n  \"params\": {\n      \"q\": \"{!func}recip( ms(NOW,publish_date), 3.16e-11, 1, 1)\"\n  }\n}\n...\n{\n    \"type\":\"org.apache.solr.ltr.ranking.RankSVMModel\",\n    \"name\":\"myModelName\",\n    \"version\": \"1.0\",\n    \"comment\": \"features and parameters determined using XYZ with ABC data, ticket reference: 12345\",\n    \"features\":[\n        ...\n    ],\n    \"params\":{\n        ...\n    }\n}\n\n\n\n ",
            "id": "comment-15163105"
        },
        {
            "date": "2016-02-24T14:44:41+0000",
            "author": "Christine Poerschke",
            "content": "Question related to the optional \"store\" element in the features and model JSON.\n\nCould you clarify/outline when/how the \"store\" element would be used? Illustration:\n\n###### features.json\n[\n{\n  \"name\":\"isBook\",\n  # absence of \"store\" element means default store\n  \"type\":\"org.apache.solr.ltr.feature.impl.OriginalScoreFeature\",\n  \"params\":{}\n},\n{\n  \"name\": \"isBook\", # same feature name but different store (and different type and/or params)\n  \"store\": \"someStore\",\n  \"type\": \"org.apache.solr.ltr.feature.impl.SolrFeature\",\n  \"params\":{ \"fq\": [\"{!terms f=category}book\"] }\n}\n]\n...\n###### model.json\n{\n    \"type\":\"org.apache.solr.ltr.ranking.RankSVMModel\",\n    \"name\":\"myModelName\",\n    \"name\":\"myStore\", # can this model reference features from another store (in this example assume the myStore store has no isBook feature)?\n    \"features\":[\n        { \"name\": \"userTextTitleMatch\"},\n        { \"name\": \"originalScore\"},\n        { \"name\": \"isBook\"}\n    ],\n    \"params\":{\n        \"weights\": {\n            \"userTextTitleMatch\": 1.0,\n            \"originalScore\": 0.5,\n            \"isBook\": 0.1\n        }\n\n    }\n}\n\n\n\n\nAre feature and model stores local to each solr config or can they be shared across configs? Illustration:\n\n###### extract from zookeeper data:\n/collections \n /collections/collection1\n DATA:\n     {\"configName\":\"configA\"}\n /collections/collection2\n DATA:\n     {\"configName\":\"configB\"}\n\n/configs\n /configs/configA\n  /configs/configA/solrconfig.xml\n  /configs/configA/schema.xml\n /configs/configB\n  /configs/configB/solrconfig.xml\n  /configs/configB/schema.xml\n\n???/features.json\n???/model.json\n\n ",
            "id": "comment-15163109"
        },
        {
            "date": "2016-03-03T22:58:18+0000",
            "author": "Michael Nilsson",
            "content": "Hey Christine, I've posted a response to most of your comments thus far below.\n\ndoDeleteChild method makes no storeManagedData method call\nWe have a ticket for this that we'll fix along with other improvements for our next commit.\n\nManagedFeatureStore.doGet throws an exception when the childId concerned is not present\nWe could return a response with no features if desired, we were currently using the error response to differentiate between a feature store not existing and one existing without any features added to it yet.\n\nManagedResource.doPut addFeature could throw an exception when a name being updated/added already exists.  Should repeats of the same name simply replace the existing entry for that name?\nTypically when you have models deployed using some features, you don't want to \"update\" an existing feature. You should instead add a new feature with your updates and deploy a newly trained model using it, because you don't want the meaning/value of the original feature used by historical models to change.  This is to ensure reproducible results when testing an old model that used the old version of the feature.  We use this error to prevent this from happening.\n\nLTRComponent state + use of state separation. Would feature store and model store changes still propagate through to ltr_ms\nIf you deploy new features to your feature store, you would want to start extracting those features, which means we should propagate them down.  We could make feature stores write-once, and any new features would require a new feature store with all the old ones copied over to avoid this, but that might be cumbersome to the user and leave lots of old feature stores around until the user cleans them up.\nQuestion: The only reason we currently have the LTRComponent is so that it can register the Model and Feature stores as managed resources because it can be SolrCore aware.  Is there a way we can do this without the use of a component?\n\nBranch/commit process\nEverything you said sounds do-able.  The only question I have is regarding \"'git merge' and 'git rebase' and 'git --force push' will be avoided\".  Agreed about git force, but if at the end we're going to make a new master-ltr-plugin-rfc-march branch, and everything is going to be squashed and rebased, why not allow merges into the master-ltr-plugin-rfc to keep up to date with master changes instead of cherry-picking everything one by one into it?\n\nFeature engineering dummy model replacement\nCurrently you have to use a dummy model to reference what features you want extracted like you said.\n\nfv=true&fl=*,score,[features]&rq={!ltr model=dummyModel reRankDocs=25}\n\nThe only reason you need the model is because it has a FeatureStore, which has all the features you are looking to extract.  Instead, we are planning on allowing you to specify which FeatureStore you want to use for feature extraction directly in the features Document Transformer.  We will also remove the superfluous fv=true parameter, since the document transformer already identifies the fact that you want to extract features.  The new expected sample request for feature extraction would probably look something like this instead\n\nfl=*,score,[features featureStore=MyFeatures]\n\n\nwould the efi. parameters move out of the rq\nWe will probably also move efi out as well, since you need them for both feature extraction and reranking with a model\n\nmight it be useful to have optional version and/or comment string elements in the feature\nI think the comment section would be a good idea.  The version touches on the what I mentioned earlier about updates vs adds.  We'll have to think about the best way to handle this since you don't want to lose/replace versions 1 and 2 when you deploy version 3 of a feature.\n\nCould you clarify/outline when/how the \"store\" element would be used?\nA FeatureStore is a list of features that you want to extract (and use for training, logging, or in a model for reranking).  In the majority of the cases, you will probably just have 1 feature store, and all iterations of your models will use the same feature store, with any new features added to the store.  A model cannot use features from other stores.  It may be the case that a single collection services many different applications.  If each of those applications wants to rerank its results differently and only cares about a subset of features, then they could each make their own FeatureStores with their say 100 features for extraction instead of pulling out the thousands of other features that all the other teams made for that same collection.\n\nAre feature and model stores local to each solr config or can they be shared across configs?\nThe feature and model stores are currently tied locally to each collection/config, like managed stopwords/synonyms.  If you wanted to have comparable scores for searches across multiple collections for a unified search list, you have to deploy that model to each of the collections.\n ",
            "id": "comment-15178779"
        },
        {
            "date": "2016-03-07T16:05:23+0000",
            "author": "Christine Poerschke",
            "content": "Hi Michael, thanks for the response above. Based on it, some follow-on questions/observations below.\n\nTypically ... you don't want to \"update\" an existing feature. You should instead add a new feature with your updates and deploy a newly trained model using it ... all iterations of your models will use the same feature store, with any new features added to the store. A model cannot use features from other stores. ...\n\nIf features present in a feature store aren't normally updated because existing models use them and if models cannot use features from other stores - I wonder if combining features.json and model.json content might be a viable option? models.json illustration shown below, please see also solrconfig.xml related illustration and observations that follow it.\n\n\n###### models.json\n[\n{\n    \"type\":\"org.apache.solr.ltr.ranking.RankSVMModel\",\n    \"name\":\"myFirstModelName\",\n    \"features\":[\n        { \"name\": \"originalScore\",\n          \"type\":\"org.apache.solr.ltr.feature.impl.OriginalScoreFeature\",\n          \"params\":{}\n        },\n        { \"name\": \"isBook\",\n          \"type\": \"org.apache.solr.ltr.feature.impl.SolrFeature\",\n          \"params\":{ \"fq\": [\"{!terms f=category}book\"] }\n        }\n    ],\n    \"params\":{\n        \"weights\": {\n            \"originalScore\": 0.5,\n            \"isBook\": 0.1\n        }\n\n    }\n},\n{\n    \"type\":\"org.apache.solr.ltr.ranking.RankSVMModel\",\n    \"name\":\"mySecondModelName\",\n    ...\n}\n]\n\n ",
            "id": "comment-15183189"
        },
        {
            "date": "2016-03-07T16:12:30+0000",
            "author": "Christine Poerschke",
            "content": "... Question: The only reason we currently have the LTRComponent is so that it can register the Model and Feature stores as managed resources because it can be SolrCore aware. Is there a way we can do this without the use of a component?\n\nNot answering directly the managed resources part of the question but having noticed that the features.json/model.json needs to be accompanied by various solrconfig.xml changes in practice - I wonder if configuring models as plugin part of solrconfig.xml might be something to explore?\n\ncurrent (features|model).json and solrconfig.xml configuration:\n\n###### features.json\n...\n###### firstModel.json\n...\n###### secondModel.json\n...\n###### solrconfig.xml\n...\n<queryParser name=\"ltr\" class=\"org.apache.solr.ltr.ranking.LTRQParserPlugin\" />\n...\n<transformer name=\"features\" class=\"org.apache.solr.ltr.ranking.LTRFeatureLoggerTransformerFactory\"/>\n...\n<searchComponent name=\"ltrComponent\" class=\"org.apache.solr.ltr.ranking.LTRComponent\"/>\n...\n<requestHandler name=\"/query\" class=\"solr.SearchHandler\">\n  ...\n  <arr name=\"last-components\">\n    <str>ltrComponent</str>\n  </arr>\n</requestHandler>\n...\n\n\n\npotential alternative solrconfig.xml configuration:\n\n###### solrconfig.xml\n...\n<!-- no queryParser name=\"ltr\" element since LTRQParserPlugin is in QParserPlugin.standardPlugins -->\n<!-- no transformer name=\"features\" since LTRFeatureLoggerTransformerFactory is in TransformerFactory.defaultFactories -->\n\n<reRankModelFactory name=\"myFirstModelName\" class=\"solr.SVMRerankModelFactory\">\n  <!-- model features -->\n  <str name=\"features\">originalScore,isBook</str>\n  <str name=\"originalScore.class\">org.apache.solr.ltr.feature.impl.OriginalScoreFeature</str>\n  <str name=\"isBook.class\">org.apache.solr.ltr.feature.impl.SolrFeature</str>\n  <str name=\"isBook.fq\">{!terms f=category}book</str>\n  <!-- model parameters -->\n  <float name=\"weights.originalScore\">0.5</float>\n  <float name=\"weights.isBook\">0.1</float>\n</reRankModelFactory>\n\n<reRankModelFactory class=\"solr.SVMRerankModelFactory\">\n  <str name=\"\">mySecondModelName</str>\n  ...\n</reRankModelFactory>\n...\n\n\n\nThe most obvious implication of having a new solrconfig.xml element instead of (features|model).json managed resources would be that solr/core rather than solr/contrib/ltr contains the code.\n\n\tFrom an end-user perspective this means 'Learning to Rank' support out-of-the-box i.e. no need to build and deploy extra jar files plus no need to configure LTRQParserPlugin and LTRFeatureLoggerTransformerFactory queryParser and transformer elements. Though note that <reRankModelFactory class=\"mycompany.MyCustomReRankModelFactory\"> customisation is supported if something other than the out-of-the-box models is required.\n\tOne of the out-of-the-box factories could be a features-only factory similar to the 'dummyModel' mentioned above, e.g.\n\n<reRankModelFactory name=\"featuresOnly\" class=\"solr.NoRerankingFactory\">\n  <str name=\"features\">originalScore,isBook</str>\n  <str name=\"originalScore.class\">org.apache.solr.ltr.feature.impl.OriginalScoreFeature</str>\n  <str name=\"isBook.class\">org.apache.solr.ltr.feature.impl.SolrFeature</str>\n  <str name=\"isBook.fq\">{!terms f=category}book</str>\n</reRankModelFactory>\n\n\n\n\n\nA concern might be that the reRankModelFactory element(s) would bloat solrconfig.xml and that the element(s) being embedded in solrconfig.xml would be more difficult to edit than one or two json files.\n\n\tThe bloat concern can be addressed via xi:include e.g.\n\n###### solrconfig.xml\n...\n<xi:include href=\"solrconfig-reRankModelFactory-myFirstModelName.xml\" xmlns:xi=\"http://www.w3.org/2001/XInclude\"/>\n...\n###### solrconfig-reRankModelFactory-myFirstModelName.xml\n<reRankModelFactory name=\"myFirstModelName\" class=\"solr.SVMRerankModelFactory\">\n  <!-- model features -->\n  <str name=\"features\">originalScore,isBook</str>\n  <str name=\"originalScore.class\">org.apache.solr.ltr.feature.impl.OriginalScoreFeature</str>\n  <str name=\"isBook.class\">org.apache.solr.ltr.feature.impl.SolrFeature</str>\n  <str name=\"isBook.fq\">{!terms f=category}book</str>\n  <!-- model parameters -->\n  <float name=\"weights.originalScore\">0.5</float>\n  <float name=\"weights.isBook\">0.1</float>\n</reRankModelFactory>\n\n\n\txml vs. json representation is a fair point, if the feature engineering process usually outputs json files then perhaps a simple utility script could help convert that json into solrconfig.xml a reRankModelFactory xml element.\n\n\n\nA factory approach could naturally support arbitrary models including chaining or nesting of models. (A factory approach is of course also possible with json format.)\n\n<reRankModelFactory name=\"myTwoPassModelName\" class=\"solr.MultiPassRerankModelFactory\">\n  <str name=\"passPrefixes\">simple,complex</str>\n\n  <!-- simple model factory -->\n  <str name=\"simple.class\">solr.SVMRerankModelFactory</str>\n  <!-- simple model features -->\n  <str name=\"simple.features\">originalScore,isBook</str>\n  <str name=\"simple.originalScore.class\">org.apache.solr.ltr.feature.impl.OriginalScoreFeature</str>\n  <str name=\"simple.isBook.class\">org.apache.solr.ltr.feature.impl.SolrFeature</str>\n  <str name=\"simple.isBook.fq\">{!terms f=category}book</str>\n  <!-- simple model parameters -->\n  <float name=\"simple.weights.originalScore\">0.5</float>\n  <float name=\"simple.weights.isBook\">0.1</float>\n\n  <!-- complex model factory -->\n  <str name=\"complex.class\">mycompany.MyComplexRerankModelFactory</str>\n  <!-- complex model features -->\n  <str name=\"complex.features\">x,y</str>\n  <str name=\"complex.x.class\">...</str>\n  <str name=\"complex.x.aaa\">...</str>\n  <int name=\"complex.x.bbb\">...</int>\n  <str name=\"complex.y.class\">...</str>\n  <int name=\"complex.y.zzz\">...</int>\n  <!-- complex model parameters -->\n  <float name=\"complex.something.configurable\">0.42</float>\n  ...\n</reRankModelFactory>\n\n ",
            "id": "comment-15183195"
        },
        {
            "date": "2016-03-07T16:15:35+0000",
            "author": "Christine Poerschke",
            "content": "Hoss Man and Steve Rowe - would you have any thoughts on 'managed resource(s)' vs. 'solrconfig.xml plugin(s)' alternatives w.r.t. feature and model representation/configuration? Thanks. ",
            "id": "comment-15183199"
        },
        {
            "date": "2016-03-07T16:28:34+0000",
            "author": "Christine Poerschke",
            "content": "... The only question I have is regarding \"'git merge' and 'git rebase' and 'git --force push' will be avoided\". Agreed about git force, but if at the end we're going to make a new master-ltr-plugin-rfc-march branch, and everything is going to be squashed and rebased, why not allow merges into the master-ltr-plugin-rfc to keep up to date with master changes instead of cherry-picking everything one by one into it?\n\nMy impression was that 'git rebase' (against master) could be run for master-ltr-plugin-rfc but then it would have to be followed by a 'git --force push' (and that is the thing to avoid). 'git merge' to pull in changes from master onto the master-ltr-plugin-rfc is perhaps possible without a force push, haven't tried that.\n\nIn terms of transition from master-ltr-plugin-rfc to master-ltr-plugin-rfc-march branch, for that anything can be used in my opinion, rebase/merge/squash/etc. since it's starting a fresh branch.\n\nNot sure if that answered your question? ",
            "id": "comment-15183216"
        },
        {
            "date": "2016-03-08T01:51:41+0000",
            "author": "Steve Rowe",
            "content": "Just read through the comments on the issue, but haven't looked at any code yet.\n\nI think you're asking about using managed resources or solrconfig.xml plugins as configuration locations.  I think that relatively short config stuff fits naturally in solrconfig.xml, and managed resource infrastructure is set up to enable modifications to structured data in resources via API (is that enabled here?  probably not, just whole-resource CRUD, I'm guessing).  So I'd guess solrconfig.xml is a better fit here.\n\nNote that new usages of solrconfig.xml config should consider how they can be addressed via the Config API.\n\nOne other consideration you didn't mention: shouldn't the Solr blob store be considered for storage/versioning/sharing of models?  (Skimming here makes me think that they are stored in Zk as files with per-collection config.) ",
            "id": "comment-15184203"
        },
        {
            "date": "2016-03-08T11:30:28+0000",
            "author": "Alessandro Benedetti",
            "content": "Really interesting stuff  \nI think could be useful to have more details about the training phase.\nI briefly reviewed both the pull request and documentation, and it seems that to try the demo, we already provide a trained model.\nThe only lines related the training seems to be :\n\"  A good library for training LambdaMART ( http://sourceforge.net/p/lemur/wiki/RankLib/ ).\n +You will need to convert the RankLib model format to the format specified above. \" ( similar documentation for the linear SVM approach) .\n\nIt would be cool to have more documentation about the training as well, explaining how to train the model starting from  :\n\n\tan example point-wise training set\n\ta set of defined feature\n\n\n\nA step by step tutorial would be awesome !\nAnyway I will proceed in studying the plugin and try to do that on my own following the third party training tutorials.\nWell done again,\n\nCheers ",
            "id": "comment-15184805"
        },
        {
            "date": "2016-03-08T12:31:03+0000",
            "author": "Alessandro Benedetti",
            "content": "A couple of questions,  for some specific use case :\n\n1) Grouping\nHow does the plugin behave for grouping ? Let's assume we have 1000 docs in 5 groups, even if we return only 1 doc per group, i assume the plugin will :\n1) first re-score the top K >>x ( so re-scoring 1000 docs )\n2) group the results\n3) return the 5 groups ( each one for example with top document)\nOr will be possible to re-rank only the top document per group ? ( so only the 5 top documents )\n\nAccording to the re-rank official solr documentation :\n\"Combining Ranking Queries With Other Solr Features\nThe \"rq\" parameter and the re-ranking feature in general works well with other Solr features. For example, it can be used in conjunction with the collapse parser to re-rank the group heads after they've been collapsed. It also preserves the order of documents elevated by the elevation component. And it even has it's own custom explain so you can see how the re-ranking scores were derived when looking at debug information.\"\nCan we assume this would happen with the LTR plugin as well ?\n\n2) Join - Parent Search\nLet's assume we return parents based on a query on the children .\nJust wondering how to combine the block join query parser to the LTR re-rank, to re-rank only the parents ( without re-scoring the children) .\nAlso in this case, according to the re-rank documentation, it seems to be compatible, is the plugin going to work with that as well ?\n\nI will take a look on my own on these topics, but any thought would be much appreciated  ",
            "id": "comment-15184843"
        },
        {
            "date": "2016-03-08T12:35:11+0000",
            "author": "Diego Ceccarelli",
            "content": "We decided to decouple models and features because:\n\n\n\tthe general use case is that you use a particular model (+ relying on a set of features) to rank your documents, but you also want to compute (and log) new features for training a new model to use in the future. All the features in a feature store will be computed but the model will receive only the requested features (allowing also to update the feature store adding new features without affecting the model)\n\ttwo models could use the same feature, but normalize the feature values in a different way (see the Normalizer class)\n\n ",
            "id": "comment-15184848"
        },
        {
            "date": "2016-03-08T12:49:33+0000",
            "author": "Diego Ceccarelli",
            "content": "Alessandro, thanks for the questions: \n\n\n\tAt the moment RankQuery (on which LTR relies) is not supported in grouping (but we are working on that - see SOLR-8776), I think the correct solution would be to perform the steps 1,2,3. Maybe we can move the discussion on SOLR-8776 since it affects, in general, RankQueries and grouping. The easy solution is to use collapsing instead of grouping, collapsing is supported by RankQuery and we tested that LTR works as well.\n\tJoin - Parent Search.  I would if RankQuery supports block join, it should work, but we didn't check.\n\n ",
            "id": "comment-15184865"
        },
        {
            "date": "2016-03-08T13:00:01+0000",
            "author": "Diego Ceccarelli",
            "content": "I had the same idea. My only concern is: would then be possible to update the solrconfig.xml without bouncing Solr? with the managed resources we would be able to add a feature/model at runtime and start to use it. Would be possible to get the same behavior with the solr config? (...and first, do we want it?  )  ",
            "id": "comment-15184876"
        },
        {
            "date": "2016-03-08T13:04:10+0000",
            "author": "Christine Poerschke",
            "content": "Thanks Steve for bringing Solr blob store into consideration. Related links:\n\n\tSOLR-8773 'Make blob store usage intuitive and robust'\n\tBlob Store API in the Apache Solr Reference Guide's Configuration APIs section.\n\n ",
            "id": "comment-15184880"
        },
        {
            "date": "2016-03-08T15:32:05+0000",
            "author": "Alessandro Benedetti",
            "content": "Diego,\nthanks for the reply!\njust verified :\n1) as documentation specifies, the re-rank component works on the collapsed results, so we can assume LTR re-rank will work as well.\n2) just tried the Block Join Parent Query Parser with the re-rank query parser, and it is working ( the parents returned are re-ranked according to the re-rank parameters ) . I can assume the LTR query parser to work in that scenario as well.\nThanks for your help !\n\nCheers ",
            "id": "comment-15185083"
        },
        {
            "date": "2016-03-08T15:44:52+0000",
            "author": "Alessandro Benedetti",
            "content": "Maybe I still have not a clear picture, but isn't the model generated externally, with a training set and a training library ( that uses the feature vectors as well) and then fed to Solr ? ( in the Json format described ? with the different weights and components automatically calculated)\n\nIn that case, I don't see it as a part of the  solrconfig.xml  .\nFurthermore, as Diego pointed out, are we sure we want to need a core reload each time we add a feature/model ?\nI see a better fit in there to have a managed resource ( like the synonyms for example), and the possibility of adding features and model at runtime, without any core reload or restart necessary,\n ",
            "id": "comment-15185108"
        },
        {
            "date": "2016-03-09T10:34:24+0000",
            "author": "ASF GitHub Bot",
            "content": "Github user alessandrobenedetti commented on a diff in the pull request:\n\n    https://github.com/apache/lucene-solr/pull/4#discussion_r55499494\n\n    \u2014 Diff: solr/contrib/ltr/README.txt \u2014\n    @@ -0,0 +1,330 @@\n    +Apache Solr Learning to Rank\n    +========\n    +\n    +This is the main [learning to rank integrated into solr](http://www.slideshare.net/lucidworks/learning-to-rank-in-solr-presented-by-michael-nilsson-diego-ceccarelli-bloomberg-lp)\n    +repository.\n    +[Read up on learning to rank](https://en.wikipedia.org/wiki/Learning_to_rank)\n    +\n    +Apache Solr Learning to Rank (LTR) provides a way for you to extract features\n    +directly inside Solr for use in training a machine learned model.  You can then\n    +deploy that model to Solr and use it to rerank your top X search results.\n    +\n    +\n    +# Changes to solrconfig.xml\n    +```xml\n    +<config>\n    +  ...\n    +\n    +  <!-- Query parser used to rerank top docs with a provided model -->\n    +  <queryParser name=\"ltr\" class=\"org.apache.solr.ltr.ranking.LTRQParserPlugin\" />\n    +\n    +  <!--  Transformer that will encode the document features in the response.\n    +  For each document the transformer will add the features as an extra field\n    +  in the response. The name of the field we will be the the name of the\n    +  transformer enclosed between brackets (in this case [features]).\n    +  In order to get the feature vector you will have to\n    +  specify that you want the field (e.g., fl=\"*,[features])  -->\n    +  <transformer name=\"features\" class=\"org.apache.solr.ltr.ranking.LTRFeatureLoggerTransformerFactory\" />\n    +\n    +\n    +  <!-- Component that hooks up managed resources for features and models -->\n    +  <searchComponent name=\"ltrComponent\" class=\"org.apache.solr.ltr.ranking.LTRComponent\"/>\n    +  <requestHandler name=\"/query\" class=\"solr.SearchHandler\">\n    +    <lst name=\"defaults\">\n    +      <str name=\"echoParams\">explicit</str>\n    +      <str name=\"wt\">json</str>\n    +      <str name=\"indent\">true</str>\n    +      <str name=\"df\">id</str>\n    +    </lst>\n    +    <arr name=\"last-components\">\n    +      <!-- Use the component in your requestHandler -->\n    +      <str>ltrComponent</str>\n    +    </arr>\n    +  </requestHandler>\n    +\n    +  <query>\n    +    ...\n    +\n    +    <!-- Cache for storing and fetching feature vectors -->\n    +    <cache name=\"QUERY_DOC_FV\"\n    +      class=\"solr.search.LRUCache\"\n    +      size=\"4096\"\n    +      initialSize=\"2048\"\n    +      autowarmCount=\"4096\"\n    +      regenerator=\"solr.search.NoOpRegenerator\" />\n    +  </query>\n    +\n    +</config>\n    +\n    +```\n    +\n    +\n    +# Build the plugin\n    +In the solr/contrib/ltr directory run\n    +`ant dist`\n    +\n    +# Install the plugin\n    +In your solr installation, navigate to your collection's lib directory.\n    +In the solr install example, it would be solr/collection1/lib.\n    +If lib doesn't exist you will have to make it, and then copy the plugin's jar there.\n    +\n    +`cp lucene-solr/solr/dist/solr-ltr-X.Y.Z-SNAPSHOT.jar mySolrInstallPath/solr/myCollection/lib`\n    +\n    +Restart your collection using the admin page and you are good to go.\n    +You can find more detailed instructions [here](https://wiki.apache.org/solr/SolrPlugins).\n    +\n    +\n    +# Defining Features\n    +In the learning to rank plugin, you can define features in a feature space\n    +using standard Solr queries. As an example:\n    +\n    +###### features.json\n    +```json\n    +[\n    +{ \"name\": \"isBook\",\n    +  \"type\": \"org.apache.solr.ltr.feature.impl.SolrFeature\",\n    +  \"params\":{ \"fq\": [\"\n{!terms f=category}\nbook\"] }\n    +},\n    +{\n    +  \"name\":  \"documentRecency\",\n    +  \"type\": \"org.apache.solr.ltr.feature.impl.SolrFeature\",\n    +  \"params\": {\n    +      \"q\": \"\n{!func}\nrecip( ms(NOW,publish_date), 3.16e-11, 1, 1)\"\n    +  }\n    +},\n    +{\n    +  \"name\":\"originalScore\",\n    +  \"type\":\"org.apache.solr.ltr.feature.impl.OriginalScoreFeature\",\n    +  \"params\":{}\n    +},\n    +{\n    +  \"name\" : \"userTextTitleMatch\",\n    +  \"type\" : \"org.apache.solr.ltr.feature.impl.SolrFeature\",\n    +  \"params\" : { \"q\" : \"\n{!field f=title}\n${user_text}\" }\n    +}\n    +]\n    +```\n    +\n    +Defines four features. Anything that is a valid Solr query can be used to define\n    +a feature.\n    +\n    +### Filter Query Features\n    +The first feature isBook fires if the term 'book' matches the category field\n    +for the given examined document. Since in this feature q was not specified,\n    +either the score 1 (in case of a match) or the score 0 (in case of no match)\n    +will be returned.\n    +\n    +### Query Features\n    +In the second feature (documentRecency) q was specified using a function query.\n    +In this case the score for the feature on a given document is whatever the query\n    +returns (1 for docs dated now, 1/2 for docs dated 1 year ago, 1/3 for docs dated\n    +2 years ago, etc..) . If both an fq and q is used, documents that don't match\n    +the fq will receive a score of 0 for the documentRecency feature, all other\n    +documents will receive the score specified by the query for this feature.\n    +\n    +### Original Score Feature\n    +The third feature (originalScore) has no parameters, and uses the\n    +OriginalScoreFeature class instead of the SolrFeature class.  Its purpose is\n    +to simply return the score for the original search request against the current\n    +matching document.\n    +\n    +### External Features\n    +Users can specify external information that can to be passed in as\n    +part of the query to the ltr ranking framework. In this case, the\n    +fourth feature (userTextPhraseMatch) will be looking for an external field\n    +called 'user_text' passed in through the request, and will fire if there is\n    +a term match for the document field 'title' from the value of the external\n    +field 'user_text'. See the \"Run a Rerank Query\" section for how\n    +to pass in external information.\n    +\n    +### Custom Features\n    +Custom features can be created by extending from\n    +org.apache.solr.ltr.ranking.Feature, however this is generally not recommended.\n    +The majority of features should be possible to create using the methods described\n    +above.\n    +\n    +# Defining Models\n    +Currently the Learning to Rank plugin supports 2 main types of\n    +ranking models: [Ranking SVM](http://www.cs.cornell.edu/people/tj/publications/joachims_02c.pdf)\n    +and [LambdaMART](http://research.microsoft.com/pubs/132652/MSR-TR-2010-82.pdf)\n    +\n    +### Ranking SVM\n    +Currently only a linear ranking svm is supported. Use LambdaMART for\n    +a non-linear model. If you'd like to introduce a bias set a constant feature\n    +to the bias value you'd like and make a weight of 1.0 for that feature.\n    +\n    +###### model.json\n    +```json\n    +{\n    +    \"type\":\"org.apache.solr.ltr.ranking.RankSVMModel\",\n    +    \"name\":\"myModelName\",\n    +    \"features\":[\n    +        \n{ \"name\": \"userTextTitleMatch\"}\n,\n    +        \n{ \"name\": \"originalScore\"}\n,\n    +        \n{ \"name\": \"isBook\"}\n    +    ],\n    +    \"params\":{\n    +        \"weights\": \n{\n    +            \"userTextTitleMatch\": 1.0,\n    +            \"originalScore\": 0.5,\n    +            \"isBook\": 0.1\n    +        }\n    +\n    +    }\n    +}\n    +```\n    +\n    +This is an example of a toy Ranking SVM model. Type specifies the class to be\n    +using to interpret the model (RankSVMModel in the case of Ranking SVM).\n    +Name is the model identifier you will use when making request to the ltr\n    +framework. Features specifies the feature space that you want extracted\n    +when using this model. All features that appear in the model params will\n    +be used for scoring and must appear in the features list.  You can add\n    +extra features to the features list that will be computed but not used in the\n    +model for scoring, which can be useful for logging.\n    +Params are the Ranking SVM parameters.\n    +\n    +Good library for training SVM's (https://www.csie.ntu.edu.tw/~cjlin/liblinear/ ,\n    +https://www.csie.ntu.edu.tw/~cjlin/libsvm/) . You will need to convert the\n    +libSVM model format to the format specified above.\n    +\n    +### LambdaMART\n    +\n    +###### model2.json\n    +```json\n    +{\n    +    \"type\":\"org.apache.solr.ltr.ranking.LambdaMARTModel\",\n    +    \"name\":\"lambdamartmodel\",\n    +    \"features\":[\n    +        \n{ \"name\": \"userTextTitleMatch\"}\n,\n    +        \n{ \"name\": \"originalScore\"}\n    +    ],\n    +    \"params\":{\n    +        \"trees\": [\n    +            {\n    +                \"weight\" : 1,\n    +                \"tree\": {\n    +                    \"feature\": \"userTextTitleMatch\",\n    +                    \"threshold\": 0.5,\n    +                    \"left\" : \n{\n    +                        \"value\" : -100\n    +                    }\n,\n    +                    \"right\": {\n    +                        \"feature\" : \"originalScore\",\n    +                        \"threshold\": 10.0,\n    +                        \"left\" : \n{\n    +                            \"value\" : 50\n    +                        }\n,\n    +                        \"right\" : \n{\n    +                            \"value\" : 75\n    +                        }\n    +                    }\n    +                }\n    +            },\n    +            {\n    +                \"weight\" : 2,\n    +                \"tree\": \n{\n    +                    \"value\" : -10\n    +                }\n    +            }\n    +        ]\n    +    }\n    +}\n    +```\n    +This is an example of a toy LambdaMART. Type specifies the class to be using to\n    +interpret the model (LambdaMARTModel in the case of LambdaMART). Name is the\n    +model identifier you will use when making request to the ltr framework.\n    +Features specifies the feature space that you want extracted when using this\n    +model. All features that appear in the model params will be used for scoring and\n    +must appear in the features list.  You can add extra features to the features\n    +list that will be computed but not used in the model for scoring, which can\n    +be useful for logging. Params are the LambdaMART specific parameters. In this\n    +case we have 2 trees, one with 3 leaf nodes and one with 1 leaf node.\n    +\n    +A good library for training LambdaMART ( http://sourceforge.net/p/lemur/wiki/RankLib/ ).\n    +You will need to convert the RankLib model format to the format specified above.\n    +\n    +# Deploy Models and Features\n    +To send features run\n    +\n    +`curl -XPUT 'http://localhost:8983/solr/collection1/schema/fstore' --data-binary @/path/features.json -H 'Content-type:application/json'`\n    +\n    +To send models run\n    +\n    +`curl -XPUT 'http://localhost:8983/solr/collection1/schema/mstore' --data-binary @/path/model.json -H 'Content-type:application/json'`\n    +\n    +\n    +# View Models and Features\n    +`curl -XGET 'http://localhost:8983/solr/collection1/schema/fstore'`\n    +`curl -XGET 'http://localhost:8983/solr/collection1/schema/mstore'`\n    +\n    +\n    +# Run a Rerank Query\n    +Add to your original solr query\n    +`rq=\n{!ltr model=myModelName reRankDocs=25}\n`\n    +\n    +The model name is the name of the model you sent to solr earlier.\n    +The number of documents you want reranked, which can be larger than the\n    +number you display, is reRankDocs.\n    +\n    +### Pass in external information for external features\n    +Add to your original solr query\n    +`rq=\n{!ltr reRankDocs=3 model=externalmodel efi.field1='text1' efi.field2='text2'}\n`\n    +\n    +Where \"field1\" specifies the name of the customized field to be used by one\n    +or more of your features, and text1 is the information to be pass in. As an\n    +example that matches the earlier shown userTextTitleMatch feature one could do:\n    +\n    +`rq=\n{!ltr reRankDocs=3 model=externalmodel efi.user_text='Casablanca' efi.user_intent='movie'}\n`\n    +\n    +# Extract features\n    +To extract features you need to use the feature vector transformer + set the\n    +fv parameter to true (this required parameter will be removed in the future).\n    +For now you need to also use a dummy model with all the features you want to\n    +extract inside the features parameter list of the model (this limitation will\n    +also be changed in the future so you can extract features without a dummy model).\n    +\n    +`fv=true&fl=*,score,[features]&rq=\n{!ltr model=dummyModel reRankDocs=25}\n`\n    +\n    +## Test the plugin with solr/example/techproducts in 6 steps\n    +\n    +Solr provides some simple example of indices. In order to test the plugin with\n    +the techproducts example please follow these steps\n    +\n    +1. compile solr and the examples\n    +\n    +    cd solr\n    +    ant dist\n    +    ant example\n    \u2014 End diff \u2013\n\n    I think ant example is deprecated in the current master branch,\n    we should point that with recent releases,\n    ant server \n    is necessary! ",
            "id": "comment-15186931"
        },
        {
            "date": "2016-03-09T14:33:04+0000",
            "author": "Alessandro Benedetti",
            "content": "Just started playing with training a lambdaMart model with RankLib.\nWhich tool did you use to parse the RankLib model to the Json format compatible with LTR Plugin ( by default RankLib returns an XML describing the trained model) ?\nAny suggestion would be useful! ",
            "id": "comment-15187160"
        },
        {
            "date": "2016-03-09T17:41:23+0000",
            "author": "ASF GitHub Bot",
            "content": "Github user alessandrobenedetti commented on a diff in the pull request:\n\n    https://github.com/apache/lucene-solr/pull/4#discussion_r55557481\n\n    \u2014 Diff: solr/contrib/ltr/src/java/org/apache/solr/ltr/ranking/ModelQuery.java \u2014\n    @@ -0,0 +1,540 @@\n    +package org.apache.solr.ltr.ranking;\n    +\n    +/*\n    + * Licensed to the Apache Software Foundation (ASF) under one or more\n    + * contributor license agreements.  See the NOTICE file distributed with\n    + * this work for additional information regarding copyright ownership.\n    + * The ASF licenses this file to You under the Apache License, Version 2.0\n    + * (the \"License\"); you may not use this file except in compliance with\n    + * the License.  You may obtain a copy of the License at\n    + *\n    + *     http://www.apache.org/licenses/LICENSE-2.0\n    + *\n    + * Unless required by applicable law or agreed to in writing, software\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n    + * See the License for the specific language governing permissions and\n    + * limitations under the License.\n    + */\n    +\n    +import java.io.IOException;\n    +import java.util.ArrayList;\n    +import java.util.Collection;\n    +import java.util.HashMap;\n    +import java.util.List;\n    +import java.util.Map;\n    +import java.util.Set;\n    +\n    +import org.apache.lucene.index.LeafReaderContext;\n    +import org.apache.lucene.index.Term;\n    +import org.apache.lucene.search.DisiPriorityQueue;\n    +import org.apache.lucene.search.DisiWrapper;\n    +import org.apache.lucene.search.DisjunctionDISIApproximation;\n    +import org.apache.lucene.search.DocIdSetIterator;\n    +import org.apache.lucene.search.Explanation;\n    +import org.apache.lucene.search.IndexSearcher;\n    +import org.apache.lucene.search.Query;\n    +import org.apache.lucene.search.Scorer;\n    +import org.apache.lucene.search.Weight;\n    +import org.apache.lucene.search.Scorer.ChildScorer;\n    +import org.apache.solr.ltr.feature.ModelMetadata;\n    +import org.apache.solr.ltr.feature.norm.Normalizer;\n    +import org.apache.solr.ltr.feature.norm.impl.IdentityNormalizer;\n    +import org.apache.solr.ltr.log.FeatureLogger;\n    +import org.apache.solr.request.SolrQueryRequest;\n    +\n    +/**\n    + * The ranking query that is run, reranking results using the ModelMetadata\n    + * algorithm\n    + */\n    +public class ModelQuery extends Query {\n    +\n    +  // contains a description of the model\n    +  protected ModelMetadata meta;\n    +  // feature logger to output the features.\n    +  private FeatureLogger fl = null;\n    +  // Map of external parameters, such as query intent, that can be used by\n    +  // features\n    +  protected Map<String,String> efi;\n    +  // Original solr query used to fetch matching documents\n    +  protected Query originalQuery;\n    +  // Original solr request\n    +  protected SolrQueryRequest request;\n    +\n    +  public ModelQuery(ModelMetadata meta) \n{\n    +    this.meta = meta;\n    +  }\n    +\n    +  public ModelMetadata getMetadata() \n{\n    +    return meta;\n    +  }\n    +\n    +  public void setFeatureLogger(FeatureLogger fl) \n{\n    +    this.fl = fl;\n    +  }\n    +\n    +  public FeatureLogger getFeatureLogger() \n{\n    +    return this.fl;\n    +  }\n    +\n    +  public Collection<Feature> getAllFeatures() \n{\n    +    return meta.getAllFeatures();\n    +  }\n    +\n    +  public void setOriginalQuery(Query mainQuery) \n{\n    +    this.originalQuery = mainQuery;\n    +  }\n    +\n    +  public void setExternalFeatureInfo(Map<String,String> externalFeatureInfo) \n{\n    +    this.efi = externalFeatureInfo;\n    +  }\n    +\n    +  public void setRequest(SolrQueryRequest request) \n{\n    +    this.request = request;\n    +  }\n    +\n    +  @Override\n    +  public int hashCode() {\n    +    final int prime = 31;\n    +    int result = super.hashCode();\n    +    result = prime * result + ((meta == null) ? 0 : meta.hashCode());\n    +    result = prime * result\n    +        + ((originalQuery == null) ? 0 : originalQuery.hashCode());\n    +    result = prime * result + ((efi == null) ? 0 : originalQuery.hashCode());\n    \u2014 End diff \u2013\n\n    I think this is a typo.\n    It should be :\n    result = prime * result + ((efi == null) ? 0 : efi.hashCode());\n\n    This is a small thing but actually currently make the system not usable when you experiment different refi variable values. Basically the cache is always hit, even if your refi variables change dynamically.\n    Anyway is really a minimal fix  ",
            "id": "comment-15187489"
        },
        {
            "date": "2016-03-10T17:34:48+0000",
            "author": "Alessandro Benedetti",
            "content": "I think it is necessary to contribute the module configuration for Idea as well  :\n\ndev-tools/idea/solr/contrib/ltr is necessary for a nice integration with IntelliJ Idea.\n\nNot sure if for Eclipse is necessary anything ! ",
            "id": "comment-15189604"
        },
        {
            "date": "2016-03-11T21:51:39+0000",
            "author": "Joshua Pantony",
            "content": "Hey Alessandro, thanks for all the interest! We actually wrote our own script to parse RankLib to the LTR Plugin format. Do you think it would be prudent to add that to this push? It seemed somewhat outside the scope of this ticket because we wanted the plugin to be as agnostic to the model training as possible, but I could see the logic in having some library specific utilities. \n\nI'll add some more documentation for the training phase.  ",
            "id": "comment-15191539"
        },
        {
            "date": "2016-03-13T10:18:04+0000",
            "author": "Alex",
            "content": "Hi guys, great plug-in. Using solr search queries as features is really cool.\n\nAs far as I understand, at the moment the training is happening outside Solr. Would be really awesome if the training is happening inside Solr. I don't have any idea how this can be done, but I hope you guys have something in mind. ",
            "id": "comment-15192277"
        },
        {
            "date": "2016-03-14T09:54:33+0000",
            "author": "Alessandro Benedetti",
            "content": "Hi Joshua,\nI was assuming you had some sort of script/app tranformer to parse the xml and build your Json \nI think could be definitely useful to have it as well.\n\nI understand and I agree you didn't want to force the user to any specific training library ( and related model in output) .\nBut in the end, the plugin supports ( at the moment) 2 possible learned model ( linear SVM and LambdaMart), so I think can be really helpful to provide users with a step by step guide to run an example end to end.\n\nI think the next step could be to add the training component in Solr as well.\nI will describe in another post in this issue, a possible basic approach  ",
            "id": "comment-15193007"
        },
        {
            "date": "2016-03-14T10:02:20+0000",
            "author": "Alessandro Benedetti",
            "content": "As I briefly discussed with Diego, about how to include the training in Solr as well :\nA simple integration could be :\n\n1) select a supported training library for linear SVM and one for the LambdaMart ( basically the libraries that you already suggest in the README could be a starting point)\n\n2) create an Update Request handler that accepts the training set ( and the format of the training set will be clearly described in the documentation like : LETOR )\nThis update handler will basically take the training set file and related parameters supported by the related library to proceed with the training. \nTrying to use the default configuration parameter where possible, in the way to make it as easy as possible the user interaction.\nThe update handler  will then extract the document features ( a revisit of the cache could be interesting in here, to improve the rycicling of feature extraction)\n\n3) update request handler will train the model calling internally the selected library , using all the parameters provided. The model generated will be converted in the supported Json format and stored in the model store.\n\nThis sample approach could be complicated as much as we want ( we can add flexibility in the library to be used and make it easy to extend) .\nA further next step could be to add a layer of signal processing directly in Solr , to build the training set as well .\n( a sort of REST Api that takes in input the  document, queryId, rating score) and automatically create an entry of the training set stored in some smart way.\nThan we can trigger the model generation or set up  schedule to refresh the model automatically.\nWe could even take into account only certain periods, store training data in different places, clean the training set automatically from time to time ect ext \nNow I am going off topic, but there are a lot of things to do with the training , to ease the integration \nHappy to discuss them and get new ideas to improve the plugin which I think is going to be really , really valuable for the Solr community ",
            "id": "comment-15193017"
        },
        {
            "date": "2016-03-16T16:44:17+0000",
            "author": "Alessandro Benedetti",
            "content": "I will continue adding observations in here, feel free to re-organize the observations later :\n\nEFI \nLet's assume we have a problem where we decided to decompose categorical features.\nThis means that potentially we can decompose a categorical features into N binary features.\n\nThe original categorical feature can be single valued which means that when callilng the rank query component we don't want to send N efis .\ne.g.\n&rq=\n{!ltr model=lambdaModel4 reRankDocs=25 efi.isFromLondon=1 efi.isFromLiverpool=0 efi.isFromManchester=0 ...}\n\nbut only one :\ne.g.\n&rq=\n{!ltr model=lambdaModel4 reRankDocs=25 efi.isFromLondon=1 }\nThe others will be default to 0 .\n\nAt the moment the plugin will complain with java.lang.NumberFormatException: For input string: \\\"${efi.isFromManchester}\\\"\" .\nWe should add the default to 0 when the efi is not passed.\nMaybe I simply missed the syntax to do that, I tried some standard way like ${efi.isFromManchester:0} in the feature json definition but it doesn't work .\n\njust let me know if we have a better channel than Jira to notify these observations . ",
            "id": "comment-15197653"
        },
        {
            "date": "2016-03-23T15:29:07+0000",
            "author": "Michael Nilsson",
            "content": "Thanks for all of the feedback Alessandro, we're actively working on some of your comments so far! Nice catch on the hash function, and we're looking into adding default values for the external feature information (efi).  As a part of this pull request we do not plan on adding training built into Solr, but that would be a very good next enhancement.  However, to help people in the Solr community get started with training and testing with machine learned ranking models, we are putting together some scripts and updating our readme to incorporate actual steps to train a model with libsvm instead of using the sample model.json file we provided.  This should make it a lot easier for people to pick this up and start using a real ranking model based off their own data.  We're keeping track of both JIRA comments and Github pull request comments on our end so they don't get lost. This is working ok so far, but if others have better suggestions we're open to them too.  ",
            "id": "comment-15208599"
        },
        {
            "date": "2016-04-13T09:38:57+0000",
            "author": "Ahmet Anil Pala",
            "content": "hi guys,\n\ngreat initiative! I love it. However, I will have some comments regarding some issues I am experiencing with LTR.\n\n\n\tcan we have a feature that is actually an external file field? I've tried it with FieldValueFeature and got NPE\n\n\n\nat org.apache.solr.ltr.feature.impl.FieldValueFeature$FieldValueFeatureWeight$FieldValueFeatureScorer.score(FieldValueFeature.java:93)\n\nIf this has not been implemented yet, it would be nice to have it.\n\n\n\tI need to reload the core whenever I want to curl new features after wiping the old version. If I don't do it, I get the following:\n\n\n\n\"Bad Request (400) - Expected Map to create a new ManagedResource but received a java.util.ArrayList\\n\\tat org.apache.solr.rest.RestManager$RestManagerManagedResource.doPut(RestManager.java:523)\n\n\n\tI know this is a long shot but worth asking. Apparently, LTR has been developed to have relatively 'simple' (pointwise or pairwise constraint training without kernels like SVM with linear kernel) machine learned models. Are there plans to implement a version which can rank the search results based on a classifier which works on document pairs and tells which one should be ranked higher than the other as opposed to a model that calculates a score given a single document and then reorders the results by that score?\n\n ",
            "id": "comment-15238961"
        },
        {
            "date": "2016-04-13T12:55:53+0000",
            "author": "Ahmet Anil Pala",
            "content": "Update: I got external file fields through 'q' parameter in org.apache.solr.ltr.feature.impl.SolrFeature. Works fine although I still think FieldValueFeature should provide access to them in addition to the non-eff fields. ",
            "id": "comment-15239187"
        },
        {
            "date": "2016-04-21T15:53:08+0000",
            "author": "Alessandro Benedetti",
            "content": "Hi gents,\nI am going to start using the plugin in a closer way.\nI think it is likely that I will find small bugs ( like the cache for EFI features ect) or improvements.\nWhat is the last version of the code available ?\nHow can I contribute back improvements/bug-fix ?\n\nIs this the last version : https://github.com/bloomberg/lucene-solr/commits/master-ltr-plugin-rfc-cpoerschke-comments ?\n\nCould make sense to create a separate repo, containing only the plugin, self contained without the entire Solr.\nIn that way I could branch from there, and then time by time ask pull-requests to include bug-fix if approved.\n\nWhat do you think? Diego Ceccarelli  Michael Nilsson ?\n\nCheers ",
            "id": "comment-15252089"
        },
        {
            "date": "2016-04-21T16:02:56+0000",
            "author": "Diego Ceccarelli",
            "content": "Thanks Alessandro, \nPlease refer to the plugin master branch https://github.com/bloomberg/lucene-solr/tree/master-ltr-plugin-rfc, we are going to merge there Christine's changes. \n\n> How can I contribute back improvements/bug-fix ?\nGithub PR are welcome. \n\n>Could make sense to create a separate repo, containing only the plugin, self contained without the entire Solr.\n\nI'm not against having a separate repo only with the plugin. what do you think Christine Poerschke?  ",
            "id": "comment-15252108"
        },
        {
            "date": "2016-04-21T16:03:27+0000",
            "author": "Diego Ceccarelli",
            "content": "Great!  ",
            "id": "comment-15252110"
        },
        {
            "date": "2016-04-25T19:47:19+0000",
            "author": "Joshua Pantony",
            "content": "Hi, thanks for the interest! Was there a specific algorithm you had in mind that is currently not supported? Often it is possible to formulate comparisons in the training phase in such a way that you can still compare just one score in the live phase. Lets use rankSVM (a pairwise approach) as an example. Given documents D1 and D2, the feature vector represented by the function V(D), if we know that D1 > D2, we can formulate this in the training stage as the objective function (V(D1) - V(D2)) * W  > 0 . Here we have created an objective function by directly comparing pairs of documents D1 and D2, hence it is pairwise. In the live phase given documents D1, D2, D3 and D4 we \"could\" do a direct pairwise approach aka:\n\n(V(D1) - V(D2)) * W > 0 ?,\n(V(D1) - V(D3)) * W > 0 ?,\n(V(D1) - V(D4)) * W > 0 ?,\n(V(D2) - V(D3)) * W > 0 ?,\n(V(D2) - V(D4)) * W > 0 ?,\n(V(D3) - V(D4)) * W > 0 ?\n\nHowever this is computationally inefficient. In this case if we do a direct comparison using our original objective function that we trained on, we'd need to do 6 dot products. Using some basic math, in the live phase we can change (D1 - D2) * W > 0 to V(D1) * W > V(D2) * W . Now all I need to do in a live setting is calculate V(D1) * W, V(D2) * W, V(D3) * W, V(D4) * W . Once we do that we can just sort the numbers and volla we've done pairwise comparisons in the same time complexity as a pointwise approach. Of course don't trust me, read this paper: http://www.cs.cornell.edu/people/tj/publications/joachims_02c.pdf (note I vastly simplified rank SVM here for ease of dialogue). \n\nSo all that being said, I'll circle back to my original question, was there a specific algorithm you had in mind that we don't easily support? If so happy to add it in some future patch (no promise on when though  ). [should be noted there is some debate / grey area around if lambdaMART is listwise or pairwise but it is generally considered among the strongest performing methods] ",
            "id": "comment-15256886"
        },
        {
            "date": "2016-04-27T13:18:54+0000",
            "author": "Ahmet Anil Pala",
            "content": "Hi, thanks for the answer.\n\nWell, nothing in particular. I have experimented with NNs and SVM with RBF kernels and they are promising especially in the cases where the target attribute is result of a complex interaction of inputs which is likely to be the case if you are after modelling some user behavior. What is different in the SVM with polynomial kernels is that although training can be done in a pairwise fashion (constraint training), in the 'live phase' the distance of an example form the separating hyperplane can be used to score the documents. This is possible because we can 'distribute' the W over the polynomial kernel as you did above:\n\nW(K(V(D_1), V(D_2)) > 0\nW(V(D_1) - V(D_2)) > 0 where K(A,B) = A - B\nW*V(D_1) - W*V(D_2) > 0\n\nHowever, some kernels do not allow this. For example, RBF kernel. RBF(D_1, D_2) = e^(-0.5*||D_1-D_2||\u02c62). This is also an example of 'kernel trick' where the non-linear feature mapping kernel does is implicit. In this case, we cannot use SVM as a scorer as our learned W is supposed to be multiplied by the kernel value of the document pair in the 'live phase' for the predictions. Therefore, In his paper Joachims didn't use SVM with kernels. He explains it as follows:\n\n\"If Kernels are not used, this property makes the application of the learned retrieval function very efficient. Fast algorithms exists for computing rankings based on linear functions by means of inverted indices\"\n\nAs you said lambdaMart is a promising model. I like it especially because it is a hierarchical model. so the LTR can treat different search cases differently (e.g different hours of day, different ranking formula). However, I'd love to be able to at least use my pairwise NN model (used fann library) in Solr using LTR. But then, 'reordering' of the products will be based on a classifier and some near-optimal algorithm for using a classifier for reordering must be used. There do exist solutions for them although I don't know the performance implications of this. The following paper covers some of them : http://arxiv.org/pdf/1105.5464.pdf ",
            "id": "comment-15260124"
        },
        {
            "date": "2016-04-27T15:28:13+0000",
            "author": "Joshua Pantony",
            "content": "Okay makes sense. You are correct that we are limited in some cases. Other examples of algorithms that wouldn't currently adapt well are things like ListNet and BoltzRank (similar to your problem). Technically support for this could be added in the re scorer level. We made a conscious effort to focus our initial code on something that allowed for some of the more popular algorithms and also had fast performance. I'd love to add support for more. That being said if some friendly developer wanted to add that support we'd love a pull request  .  Our public branch can be found at: https://github.com/bloomberg/lucene-solr/tree/master-ltr-plugin-rfc . ",
            "id": "comment-15260320"
        },
        {
            "date": "2016-05-27T14:35:39+0000",
            "author": "ASF GitHub Bot",
            "content": "GitHub user mnilsson23 opened a pull request:\n\n    https://github.com/apache/lucene-solr/pull/40\n\n    SOLR-8542: Integrate Learning to Rank into Solr\n\n    Solr Learning to Rank (LTR) provides a way for you to extract features\n    directly inside Solr for use in training a machine learned model. You\n    can then deploy that model to Solr and use it to rerank your top X\n    search results. This concept was previously presented by the authors at\n    Lucene/Solr Revolution 2015.\n\n    See the [README](https://github.com/bloomberg/lucene-solr/tree/master-ltr-plugin-release/solr/contrib/ltr) for more information on how to get started.\n\n\n\nYou can merge this pull request into a Git repository by running:\n\n    $ git pull https://github.com/bloomberg/lucene-solr master-ltr-plugin-release\n\nAlternatively you can review and apply these changes as the patch at:\n\n    https://github.com/apache/lucene-solr/pull/40.patch\n\nTo close this pull request, make a commit to your master/trunk branch\nwith (at least) the following in the commit message:\n\n    This closes #40\n\n\ncommit 073de9b2719abe91e106119b23b977e521e8b32f\nAuthor: Diego Ceccarelli <dceccarelli4@bloomberg.net>\nDate:   2016-01-13T22:29:17Z\n\n    SOLR-8542: Integrate Learning to Rank into Solr\n\n    Solr Learning to Rank (LTR) provides a way for you to extract features\n    directly inside Solr for use in training a machine learned model. You\n    can then deploy that model to Solr and use it to rerank your top X\n    search results. This concept was previously presented by the authors at\n    Lucene/Solr Revolution 2015\n\ncommit b2bbe8c13122280ee5a76149bfb55fd1b7324279\nAuthor: Michael Nilsson <mnilsson23@bloomberg.net>\nDate:   2016-05-25T22:13:05Z\n\n    Learning to Rank plugin updates\n\n\n\tUpdated our documentation about the training phase and how to train a real model for those that are not familiar with this process.  We provided a step by step example building a rankSVM model externally, and supplied a sample script which does this using liblinear.\n\tFormatted the code based on the lucene eclipse style\n\tUpdated the hashCode and equals functions of the ModelQuery as Alessandro Benedetti pointed out\n\tRenamed ModelMetadata, the class you would subclass to add a new model for scoring docs, to LTRScoringAlgorithm\n\tCleaned up the LTRScoringAlgorithm to no longer have a type parameter\n\tAdded IntelliJ support.  Thank you Alessandro Benedetti for adding it\n\tRenamed mstore and fstore endpoints to feature-store and model-store as per Upayavira's suggestion\n\tAdded support for default efi parameters using the same Solr  standard in solrconfig.  When defining a feature in the config, put ${isFromManchester:0} to get 0 as a default, and you won't have to specify it in the request's efi params. Thanks for the enhancement suggestion Alessandro Benedetti\n\tRemoved the fv=true param requirement for extracting features.\n\tYou do not have to provide a \"dummy model\" first for extracting features, so you can request the transformer without the need of an rq ranking query.  Inside the transformer you can provide a store=myFeatureStore param, and it will extract all features from that feature store directly.  You can also provide local efi params if needed when extracting without an rq.\n\n\n\n ",
            "id": "comment-15304130"
        },
        {
            "date": "2016-05-27T14:38:28+0000",
            "author": "ASF GitHub Bot",
            "content": "Github user diegoceccarelli commented on the pull request:\n\n    https://github.com/apache/lucene-solr/pull/4#issuecomment-222163577\n\n    thanks Alessandro, we integrated part of your PR in the new patch.  ",
            "id": "comment-15304133"
        },
        {
            "date": "2016-05-27T14:38:28+0000",
            "author": "ASF GitHub Bot",
            "content": "Github user diegoceccarelli closed the pull request at:\n\n    https://github.com/apache/lucene-solr/pull/4 ",
            "id": "comment-15304134"
        },
        {
            "date": "2016-05-27T14:40:01+0000",
            "author": "Michael Nilsson",
            "content": "Hi everyone!  We just made a push with many changes that were requested by you guys, plus a few other things.\nWe have also updated to the latest Solr master branch as of few days ago.  Just as a heads up, we replaced the old pull request with a new one due to some history changes when merging with the latest master.  Below you'll find a list some of the items we changed.\n\n\n\tUpdated our documentation about the training phase and how to train a real model for those that are not familiar with this process.  We provided a step by step example building a rankSVM model externally, and supplied a sample script which does this using liblinear.\n\tFormatted the code based on the lucene eclipse style\n\tUpdated the hashCode and equals functions of the ModelQuery as Alessandro Benedetti pointed out\n\tRenamed ModelMetadata, the class you would subclass to add a new model for scoring docs, to LTRScoringAlgorithm\n\tCleaned up the LTRScoringAlgorithm to no longer have a type parameter\n\tAdded IntelliJ support.  Thank you Alessandro Benedetti for adding it\n\tRenamed mstore and fstore endpoints to feature-store and model-store as per Upayavira's suggestion\n\tAdded support for default efi parameters using the same Solr  standard in solrconfig.  When defining a feature in the config, put ${isFromManchester:0} to get 0 as a default, and you won't have to specify it in the request's efi params. Thanks for the enhancement suggestion Alessandro Benedetti\n\tRemoved the fv=true param requirement for extracting features.\n\tYou do not have to provide a \"dummy model\" first for extracting features, so you can request the transformer without the need of an rq ranking query.  Inside the transformer you can provide a store=myFeatureStore param, and it will extract all features from that feature store directly.  You can also provide local efi params if needed when extracting without an rq.\n\n\n\nPlease read through the README for more information on the plugin, and how to train your own external model.\nAlso, we have opened up the ability to create issues in our Github repository where the plugin currently lives.\nPlease feel free to make or suggest issues, and we will keep track of them there instead of in this long list of comments.\nThanks for the support everyone, and expect more frequent updates in the future. ",
            "id": "comment-15304137"
        },
        {
            "date": "2016-10-07T15:27:20+0000",
            "author": "Michael Nilsson",
            "content": "Hello everyone!  We have just made a push to the Solr LTR contrib module pull request in preparation for upstreaming into Solr's master branch.  We've made a lot of changes since May.  We're up to date with the latest master, and ant validate passes. We fixed ant documentation-lint issues encountered in the contrib module, but linting stopped in changes.html so there might be some lingering lint issues.\nWe welcome any comments on the contrib module, and please feel free to take a look at the README to get started.  We will also be at this year's Lucene Solr Revolution if you want to stop by and ask us anything in person as well! ",
            "id": "comment-15555378"
        },
        {
            "date": "2016-10-10T10:45:49+0000",
            "author": "Alessandro Benedetti",
            "content": "Well done guys ! Impressive!\n\nJust a couple of observations and ideas that can help :\n\nFeature Caching Improvements : https://github.com/bloomberg/lucene-solr/issues/172\nLambdaMART explain summarization :  https://github.com/bloomberg/lucene-solr/issues/173\n\nI can not wait to see the plugin in the official release !  ",
            "id": "comment-15561952"
        },
        {
            "date": "2016-10-10T14:53:44+0000",
            "author": "Christine Poerschke",
            "content": "Just a quick note for the log here to say that i have snapshot the pull request to https://github.com/apache/lucene-solr/tree/jira/solr-8542 branch and created LEGAL-276 re: potential patent concerns question. ",
            "id": "comment-15562506"
        },
        {
            "date": "2016-10-19T02:26:05+0000",
            "author": "Christine Poerschke",
            "content": "And another quick note for the log here to say that i have snapshot the updated pull request to https://github.com/apache/lucene-solr/tree/jira/solr-8542-v2 branch and updated the LEGAL-276 ticket re: the thus changed understanding as far as any potential patent concerns go. ",
            "id": "comment-15587430"
        },
        {
            "date": "2016-10-21T09:04:18+0000",
            "author": "adeppa",
            "content": "Hi Team,\n\nCould you help any one how to integrate LTR in to solr 5.1.0 ,if need to apply the any patch please help me ,\n\nThanks\nAdeppa ",
            "id": "comment-15594543"
        },
        {
            "date": "2016-10-24T21:02:14+0000",
            "author": "Michael Nilsson",
            "content": "Hey adeppa, \n\nSo our plan is to get this merged into master, roughly solr 7x, very soon.  We will then be working on backporting the commit/patch to 6x so it can be rolled out in a solr release.  We would strongly recommend you upgrade to 6x to get access to a sturdier and more performant solr version with access to new features like the plugin.\n\nIf upgrading to 6x is not possible, you could cherry-pick the commit into your own branch_5x solr repo and resolve any conflicts.  However, there have been many changes compared to what's in master which affect the code the plugin was built on, so the backporting would take some effort.  \n\n-Mike ",
            "id": "comment-15603212"
        },
        {
            "date": "2016-10-25T09:35:19+0000",
            "author": "adeppa",
            "content": "\nHi Mike,\n\nThanks for the information, Now i can't able to upgrade to solr 6x ,i was tried above patch but not working still showing many errors, my solr current version 5.1.0 ,please help me how to apply that patch my current solr source \n\n\n\nThanks\nAdeppa ",
            "id": "comment-15604783"
        },
        {
            "date": "2016-11-01T17:44:34+0000",
            "author": "Christine Poerschke",
            "content": "Attaching patch generated as diff between 'master' and https://github.com/apache/lucene-solr/tree/jira/solr-8542-v2 - master commit to follow shortly. ",
            "id": "comment-15626118"
        },
        {
            "date": "2016-11-01T19:38:45+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 5a66b3bc089e4b3e73b1c41c4cdcd89b183b85e7 in lucene-solr's branch refs/heads/master from Christine Poerschke\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=5a66b3b ]\n\nSOLR-8542: Adds Solr Learning to Rank (LTR) plugin for reranking results with machine learning models. (Michael Nilsson, Diego Ceccarelli, Joshua Pantony, Jon Dorando, Naveen Santhapuri, Alessandro Benedetti, David Grohmann, Christine Poerschke) ",
            "id": "comment-15626456"
        },
        {
            "date": "2016-11-02T13:58:02+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 9eb806a23339a4c6ade88ac86da889b8b889a936 in lucene-solr's branch refs/heads/master from Steve Rowe\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=9eb806a ]\n\nSOLR-8542: Add maven config and improve IntelliJ config. ",
            "id": "comment-15629052"
        },
        {
            "date": "2016-11-02T23:59:04+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 5a66b3bc089e4b3e73b1c41c4cdcd89b183b85e7 in lucene-solr's branch refs/heads/apiv2 from Christine Poerschke\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=5a66b3b ]\n\nSOLR-8542: Adds Solr Learning to Rank (LTR) plugin for reranking results with machine learning models. (Michael Nilsson, Diego Ceccarelli, Joshua Pantony, Jon Dorando, Naveen Santhapuri, Alessandro Benedetti, David Grohmann, Christine Poerschke) ",
            "id": "comment-15630965"
        },
        {
            "date": "2016-11-02T23:59:15+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 9eb806a23339a4c6ade88ac86da889b8b889a936 in lucene-solr's branch refs/heads/apiv2 from Steve Rowe\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=9eb806a ]\n\nSOLR-8542: Add maven config and improve IntelliJ config. ",
            "id": "comment-15630969"
        },
        {
            "date": "2016-11-11T19:18:34+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 2c752b04cb63c0b6638f14959839b15fa1fa3e5a in lucene-solr's branch refs/heads/master from Michael Nilsson\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=2c752b0 ]\n\nSOLR-8542: disallow reRankDocs<1 i.e. must rerank at least 1 document\n(Michael Nilsson via Christine Poerschke) ",
            "id": "comment-15657874"
        },
        {
            "date": "2016-11-11T19:18:36+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 86a515789f6e4626d71480c7fdf38c33b71ded93 in lucene-solr's branch refs/heads/master from Christine Poerschke\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=86a5157 ]\n\nSOLR-8542, SOLR-9746: prefix solr/contrib/ltr's search and response.transform packages with ltr ",
            "id": "comment-15657875"
        },
        {
            "date": "2016-12-06T08:40:00+0000",
            "author": "adeppa",
            "content": "Michael Nilsson\nHi Team,\n\nI am working on LTR master branch with solr 6.3, when i try to integrate code in eclipse showing to me compile time errors in couple of class i.e FieldLengthFeatureWeight,LTRScoringQuery ,After adding the unimplemented  methods to couple of class i.e FieldValueFeatureWeight,SolrFeatureWeight,ValueFeatureWeight ,\n\nIn the LTRScoringQuery class showing error on  \n@Override\n  public ModelWeight createWeight(IndexSearcher searcher, boolean needsScores, float boost)\n      throws IOException \n\nNote :if i remove @Override  error is went off ,is it any impact \n\n\nand FieldLengthFeatureWeight class showing error on\npublic FieldLengthFeatureScorer(FeatureWeight weight,\n          NumericDocValues norms) throws IOException {\n        super(weight, norms);\n\nNote : Here super (weight,norms ) method showing error \nand \n @Override\n      public float score() throws IOException {\n\n        final long l = norms.longValue();\nNote : norms.longValue(); statement is showing error \nplease help me for the above error resolution  \n\nThanks\nAdeppa ",
            "id": "comment-15724819"
        },
        {
            "date": "2016-12-07T21:23:17+0000",
            "author": "ASF subversion and git services",
            "content": "Commit bfc3690d5203cee20550450bac3771e5c2b85cbf in lucene-solr's branch refs/heads/master from Christine Poerschke\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=bfc3690 ]\n\nSOLR-8542: couple of tweaks (Michael Nilsson, Diego Ceccarelli, Christine Poerschke)\n\n\n\tremoved code triplication in ManagedModelStore\n\tLTRScoringQuery.java tweaks\n\tFeatureLogger.makeFeatureVector(...) can now safely be called repeatedly (though that doesn't happen at present)\n\tmake Feature.FeatureWeight.extractTerms a no-op; (OriginalScore|SolrFeature)Weight now implement extractTerms\n\n\n\n\n\tLTRThreadModule javadocs and README.md tweaks\n\n\n\n\n\tadd TestFieldValueFeature.testBooleanValue test; replace \"T\"/\"F\" magic string use in FieldValueFeature\n\tadd TestOriginalScoreScorer test; add OriginalScoreScorer.freq() method\n\tin TestMultipleAdditiveTreesModel revive dead explain test\n\n ",
            "id": "comment-15729952"
        },
        {
            "date": "2016-12-08T18:44:04+0000",
            "author": "ASF subversion and git services",
            "content": "Commit a511b30a50672365d46c3d052e19a9fedd228e2e in lucene-solr's branch refs/heads/branch_6x from Christine Poerschke\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=a511b30 ]\n\nSOLR-8542: Adds Solr Learning to Rank (LTR) plugin for reranking results with machine learning models. (Michael Nilsson, Diego Ceccarelli, Joshua Pantony, Jon Dorando, Naveen Santhapuri, Alessandro Benedetti, David Grohmann, Christine Poerschke) ",
            "id": "comment-15733031"
        },
        {
            "date": "2016-12-08T18:44:06+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 084809b77cc6b62be5f6f888d78574487cb3ec5b in lucene-solr's branch refs/heads/branch_6x from Steve Rowe\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=084809b ]\n\nSOLR-8542: Add maven config and improve IntelliJ config. ",
            "id": "comment-15733032"
        },
        {
            "date": "2016-12-08T18:44:08+0000",
            "author": "ASF subversion and git services",
            "content": "Commit f87d672be749fde603f592021bba875fd01e0f01 in lucene-solr's branch refs/heads/branch_6x from Michael Nilsson\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=f87d672 ]\n\nSOLR-8542: disallow reRankDocs<1 i.e. must rerank at least 1 document\n(Michael Nilsson via Christine Poerschke) ",
            "id": "comment-15733033"
        },
        {
            "date": "2016-12-08T18:44:10+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 252c6e9385ba516887543eb1968c8654b35b2b81 in lucene-solr's branch refs/heads/branch_6x from Christine Poerschke\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=252c6e9 ]\n\nSOLR-8542, SOLR-9746: prefix solr/contrib/ltr's search and response.transform packages with ltr ",
            "id": "comment-15733034"
        },
        {
            "date": "2016-12-08T18:44:14+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 3e2657214e103290142d0facfc860cb01f6e033e in lucene-solr's branch refs/heads/branch_6x from Christine Poerschke\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=3e26572 ]\n\nSOLR-8542: couple of tweaks (Michael Nilsson, Diego Ceccarelli, Christine Poerschke)\n\n\n\tremoved code triplication in ManagedModelStore\n\tLTRScoringQuery.java tweaks\n\tFeatureLogger.makeFeatureVector(...) can now safely be called repeatedly (though that doesn't happen at present)\n\tmake Feature.FeatureWeight.extractTerms a no-op; (OriginalScore|SolrFeature)Weight now implement extractTerms\n\n\n\n\n\tLTRThreadModule javadocs and README.md tweaks\n\n\n\n\n\tadd TestFieldValueFeature.testBooleanValue test; replace \"T\"/\"F\" magic string use in FieldValueFeature\n\tadd TestOriginalScoreScorer test; add OriginalScoreScorer.freq() method\n\tin TestMultipleAdditiveTreesModel revive dead explain test\n\n ",
            "id": "comment-15733036"
        },
        {
            "date": "2016-12-08T18:44:15+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 9e8dd854cda6d56cc8d498cc23d138eeb74732fd in lucene-solr's branch refs/heads/branch_6x from Christine Poerschke\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=9e8dd85 ]\n\nSOLR-8542: master-to-branch_6x backport changes (Michael Nilsson, Naveen Santhapuri, Christine Poerschke)\n\n\n\tremoved 'boost' arg from LTRScoringQuery.createWeight signature\n\tclasses extending Weight now implement normalize and getValueForNormalization\n\tFieldLengthFeatureScorer tweaks\n\n ",
            "id": "comment-15733037"
        },
        {
            "date": "2016-12-09T13:01:24+0000",
            "author": "Christine Poerschke",
            "content": "Hi Adeppa,\n\nJust a quick note to say that the branch_6x commits below (and specifically the \"master-to-branch_6x backport changes\" commit) might potentially help with the compile time errors you describe.\n\nIn terms of official Solr 6.3 backporting of the LTR plugin, we do not plan to backport to branch_6_3 but branch_6x will turn into \"Solr 6.4\" when the next release happens.\n\nRegards,\n\nChristine ",
            "id": "comment-15735251"
        },
        {
            "date": "2016-12-09T13:04:17+0000",
            "author": "Christine Poerschke",
            "content": "done:\n\n\tmaster commit(s)\n\tbranch_6x commit(s)\n\n\n\nnext steps:\n\n\tSolr Reference Guide documentation (https://cwiki.apache.org/confluence/display/solr/Internal+-+TODO+List as starting point)\n\t(to avoid duplication) reduce solr/contrib/ltr/README.md content to point to the appropriate Solr Reference Guide section(s)\n\n ",
            "id": "comment-15735258"
        },
        {
            "date": "2016-12-09T13:53:16+0000",
            "author": "adeppa",
            "content": "Hi Christine\n\n\nI done some change accordingly 6.3 solr ,i will create different PR and share with you ,if you have time please review and validate my changes \n\n\nThanks\nAdeppa  ",
            "id": "comment-15735376"
        },
        {
            "date": "2016-12-19T11:50:53+0000",
            "author": "adeppa",
            "content": "Hi Christe,\nCould you help me how to create model.json and feature.json ,i didn't get any idea about that please give me int ",
            "id": "comment-15760966"
        },
        {
            "date": "2016-12-19T16:49:28+0000",
            "author": "ASF subversion and git services",
            "content": "Commit c8542b2bd0470af9f8d64bb8133f31828b342604 in lucene-solr's branch refs/heads/master from Christine Poerschke\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=c8542b2 ]\n\nSOLR-8542: techproducts example now includes (disabled) learning-to-rank support (enable via -Dsolr.ltr.enabled=true)\n\nadditional changes as follows:\n\n\n\tLTRFeatureLoggerTransformerFactory:\n\t\n\t\tfeature values cache name configurable (instead of hard-coded value that needs to match solrconfig.xml configuration)\n\t\tjavadocs (example and parameters)\n\t\n\t\n\n\n\n\n\tCSV FeatureLogger:\n\t\n\t\tremoved delimiter and separator assumptions in tests\n\t\tchanged delimiter and separator (from \"key:val;key:val\" to \"key=val,key=val\")\n\t\tconfigurable (key value) delimiter and (features) separator\n\t\n\t\n\n\n\n\n\tJSON FeatureLogger:\n\t\n\t\tdefer support for this (removing MapFeatureLogger class)\n\t\n\t\n\n\n\n\n\tadds 'training libraries' to (Linear|MultipleAdditiveTrees)Model javadocs\n\n\n\n(Diego Ceccarelli, Michael Nilsson, Christine Poerschke) ",
            "id": "comment-15761675"
        },
        {
            "date": "2016-12-19T17:18:46+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 4852851d85fc874e3d6fb48faac98d0552873b80 in lucene-solr's branch refs/heads/branch_6x from Christine Poerschke\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=4852851 ]\n\nSOLR-8542: techproducts example now includes (disabled) learning-to-rank support (enable via -Dsolr.ltr.enabled=true)\n\nadditional changes as follows:\n\n\n\tLTRFeatureLoggerTransformerFactory:\n\t\n\t\tfeature values cache name configurable (instead of hard-coded value that needs to match solrconfig.xml configuration)\n\t\tjavadocs (example and parameters)\n\t\n\t\n\n\n\n\n\tCSV FeatureLogger:\n\t\n\t\tremoved delimiter and separator assumptions in tests\n\t\tchanged delimiter and separator (from \"key:val;key:val\" to \"key=val,key=val\")\n\t\tconfigurable (key value) delimiter and (features) separator\n\t\n\t\n\n\n\n\n\tJSON FeatureLogger:\n\t\n\t\tdefer support for this (removing MapFeatureLogger class)\n\t\n\t\n\n\n\n\n\tadds 'training libraries' to (Linear|MultipleAdditiveTrees)Model javadocs\n\n\n\n(Diego Ceccarelli, Michael Nilsson, Christine Poerschke) ",
            "id": "comment-15761736"
        },
        {
            "date": "2016-12-23T12:58:09+0000",
            "author": "ASF subversion and git services",
            "content": "Commit ac3f1bb339df530d6d4484f26c9ab2da17bd28df in lucene-solr's branch refs/heads/master from Christine Poerschke\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=ac3f1bb ]\n\nSOLR-8542: reduce direct solrconfig-ltr.xml references in solr/contrib/ltr tests ",
            "id": "comment-15772851"
        },
        {
            "date": "2016-12-23T13:16:34+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 01846cbb4ccfdc9237cbd0af631b8d000448b0f8 in lucene-solr's branch refs/heads/branch_6x from Christine Poerschke\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=01846cb ]\n\nSOLR-8542: reduce direct solrconfig-ltr.xml references in solr/contrib/ltr tests ",
            "id": "comment-15772880"
        },
        {
            "date": "2016-12-23T14:05:41+0000",
            "author": "ASF subversion and git services",
            "content": "Commit f62874e47a0c790b9e396f58ef6f14ea04e2280b in lucene-solr's branch refs/heads/master from Christine Poerschke\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=f62874e ]\n\nSOLR-8542: change default feature vector format (to 'dense' from 'sparse')\n\nalso: increase test coverage w.r.t. 'sparse' vs. 'dense' vs. 'default' feature vector format ",
            "id": "comment-15772965"
        },
        {
            "date": "2016-12-23T14:48:46+0000",
            "author": "ASF subversion and git services",
            "content": "Commit b7c75a3a1c7524994cb2413afa82562e30eaadcb in lucene-solr's branch refs/heads/branch_6x from Christine Poerschke\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=b7c75a3 ]\n\nSOLR-8542: change default feature vector format (to 'dense' from 'sparse')\n\nalso: increase test coverage w.r.t. 'sparse' vs. 'dense' vs. 'default' feature vector format ",
            "id": "comment-15773039"
        },
        {
            "date": "2017-01-04T18:11:52+0000",
            "author": "ASF subversion and git services",
            "content": "Commit eb2a8ba2eec0841f03bbcf7807e602f7164a606e in lucene-solr's branch refs/heads/master from Christine Poerschke\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=eb2a8ba ]\n\nSOLR-8542: README and solr/contrib/ltr/example changes\n\ndetails:\n\n\treduced README in favour of equivalent Solr Ref Guide content and (new) example/README\n\tsolr/contrib/ltr/example improvements and fixes\n\n\n\nalso:\n\n\tstop supporting '*' in Managed(Feature|Model)Store.doDeleteChild\n\n ",
            "id": "comment-15798927"
        },
        {
            "date": "2017-01-04T18:46:30+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 94dad5b68e5a46ea820514a43e3a759ef3c57716 in lucene-solr's branch refs/heads/branch_6x from Christine Poerschke\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=94dad5b ]\n\nSOLR-8542: README and solr/contrib/ltr/example changes\n\ndetails:\n\n\treduced README in favour of equivalent Solr Ref Guide content and (new) example/README\n\tsolr/contrib/ltr/example improvements and fixes\n\n\n\nalso:\n\n\tstop supporting '*' in Managed(Feature|Model)Store.doDeleteChild\n\n ",
            "id": "comment-15799024"
        },
        {
            "date": "2017-01-04T18:49:27+0000",
            "author": "Christine Poerschke",
            "content": "The Solr Reference Guide content for SOLR-8542 (Integrate Learning to Rank into Solr) is currently on the tentatively named https://cwiki.apache.org/confluence/display/solr/Result+Reranking page. Suggestions for alternative page names would be very welcome.\n\nThe \"Result Reranking\" page would be placed after the \"Result Grouping\" and \"Result Clustering\" pages, suggestions for alternative placements would be welcome also.\n\nThe following files currently mention the \"Result Reranking\" page:\n\n\thttps://github.com/apache/lucene-solr/blob/master/solr/contrib/ltr/README.md\n\thttps://github.com/apache/lucene-solr/blob/master/solr/contrib/ltr/example/README.md\n\thttps://github.com/apache/lucene-solr/blob/master/solr/server/solr/configsets/sample_techproducts_configs/conf/solrconfig.xml\n\n ",
            "id": "comment-15799033"
        },
        {
            "date": "2017-01-06T21:11:14+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 88450c70bb4daa3ca6c4750581bddeaad9bea6f9 in lucene-solr's branch refs/heads/branch_6x from Christine Poerschke\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=88450c7 ]\n\nSOLR-8542: expand 'Assemble training data' content in solr/contrib/ltr/README\n\n(Diego Ceccarelli via Christine Poerschke in response to SOLR-9929 enquiry from Jeffery Yuan.) ",
            "id": "comment-15805756"
        },
        {
            "date": "2017-01-06T21:24:00+0000",
            "author": "Christine Poerschke",
            "content": "The bot did not (yet) update for it here but there is equivalent 'master' branch commit as per the bot's update on SOLR-9929 itself. ",
            "id": "comment-15805800"
        },
        {
            "date": "2017-01-06T21:38:41+0000",
            "author": "Christine Poerschke",
            "content": "Thanks everyone! ",
            "id": "comment-15805836"
        },
        {
            "date": "2017-01-10T22:25:10+0000",
            "author": "Cassandra Targett",
            "content": "Christine Poerschke: About the docs in the Ref Guide - thanks, by the way! - I've started to take a look and will have more feedback but for now I'm wondering if there is a reason why you didn't name the page in the Ref Guide something like \"Learning to Rank\", or \"Machine Learned Ranking\"? The current name feels like it is hiding the true topic of the page, but I haven't studied the topic enough to know if there is a reason for doing that in this case. ",
            "id": "comment-15816376"
        },
        {
            "date": "2017-01-11T00:02:31+0000",
            "author": "Markus Jelsma",
            "content": "I agree with Cassandra because it also allows for confusion with reranking post filter. Machine Learned Ranking covers the topic nicely i believe. ",
            "id": "comment-15816600"
        },
        {
            "date": "2017-01-11T12:47:20+0000",
            "author": "Christine Poerschke",
            "content": "Hi Cassandra and Markus - thanks for your input. \"Result Reranking\" remains very much a tentative name, happy to change it.\n\nHow about \"Learning To Rank\" as a sub-page of the \"Query Re-Ranking\" i.e.\n\n\n* Searching\n  * ...\n  * Query Re-Ranking\n    * Learning To Rank\n  * Transforming Result Documents\n  * ...\n  * Result Grouping\n  * Result Clustering\n  * ...\n\n\n\ninstead of the current\n\n\n* Searching\n  * ...\n  * Query Re-Ranking\n  * Transforming Result Documents\n  * ...\n  * Result Grouping\n  * Result Clustering\n  * ...\n  * Result Reranking\n\n\n\nwhere the tentatively named \"Result Reranking\" is tentatively a sibling of \"Result Grouping\" and \"Result Clustering\"?\n.\nRegarding the alternative of \"Machine Learned Ranking\", how about reserving that for future use (similar to the \"Parameter Substitution\" reservation) e.g. for it to become a \"routing page\" directing users to the \"Learning To Rank\" page, the \"Logistic Regression Text Classification\" content mentioned in \"Streaming Expressions\" and whatever else will come along in future in terms of machine learned ranking? ",
            "id": "comment-15818223"
        },
        {
            "date": "2017-01-11T17:51:54+0000",
            "author": "Cassandra Targett",
            "content": "How about \"Learning To Rank\" as a sub-page of the \"Query Re-Ranking\"...\n\n+1 Christine Poerschke, I like that idea.\n\nRegarding the alternative of \"Machine Learned Ranking\", how about reserving that for future use\n\nAh, I get what you're saying. There will be features in the future (hopefully) that would make an umbrella page named \"Machine Learned Ranking\" worth having so we shouldn't use it now. How about renaming it to \"Learning to Rank\", then? ",
            "id": "comment-15818959"
        },
        {
            "date": "2017-01-13T10:36:24+0000",
            "author": "Christine Poerschke",
            "content": "How about \"Learning To Rank\" as a sub-page of the \"Query Re-Ranking\" ... +1 ... I like that idea.\n\nLearning To Rank is now the documentation page. I renamed and relocated the page and updated 'code' and 'ref guide' references to it. http://git-wip-us.apache.org/repos/asf/lucene-solr/commit/987e2650 and http://git-wip-us.apache.org/repos/asf/lucene-solr/commit/9b03e384 are the 'code' commits.\n\nRegarding the alternative of \"Machine Learned Ranking\", how about reserving that for future use ...\n\nTentative page name and draft content now at https://cwiki.apache.org/confluence/display/solr/Machine+Learning+and+Solr because I think there's actually already enough functionality (Learning To Rank from SOLR-8542 here and Joel Bernstein's Logistic Regression Text Classification) to bring the \"future use\" into the present - what do you think? ",
            "id": "comment-15821579"
        },
        {
            "date": "2017-04-06T18:31:21+0000",
            "author": "Varun Thacker",
            "content": "Hi Christine,\n\nI was trying to play around with LTR but I don't see anything under /contrib/ltr in a solr binary? I see /contrib/ltr/example/config.json on git . Am I missing something here? ",
            "id": "comment-15959496"
        },
        {
            "date": "2017-04-06T18:37:27+0000",
            "author": "Christine Poerschke",
            "content": "Hi Varun,\n\nhttps://cwiki.apache.org/confluence/display/solr/Learning+To+Rank has a Quick Start Example using the techproducts example which is included in the solr binary distribution. The solr/contrib/ltr/example content is intentionally not included in the binary distribution but it is (as you say) available in the git repo. ",
            "id": "comment-15959506"
        },
        {
            "date": "2017-04-06T18:56:05+0000",
            "author": "Varun Thacker",
            "content": "Oh I see what happened.\n\nOn https://cwiki.apache.org/confluence/display/solr/Learning+To+Rank I was reading the \"Training example\" section which took me to https://github.com/apache/lucene-solr/tree/releases/lucene-solr/6.4.0/solr/contrib/ltr/example and then I was like why isn't contrib/ltr/example/config.json there \n\nSo I have a few questions:\n1. Should we state explicitly that this example is not shipped in the binary?  Any reason why we don't out of curiosity ?\n2. The \"Installation\" section of https://cwiki.apache.org/confluence/display/solr/Learning+To+Rank states that we need \" all JARs under contrib/ltr/lib.\" . I don't see anything under the binary. Is it safe to remove it?\n\nBTW I love the documentation. Very thorough ",
            "id": "comment-15959535"
        },
        {
            "date": "2017-04-07T16:22:47+0000",
            "author": "Christine Poerschke",
            "content": "... Should we state explicitly that this example is not shipped in the binary? ...\n\nDone.\n\n... Any reason why we don't out of curiosity ? ...\n\nAs is the example folder content is not intended or suitable for production use. The train_and_upload_demo_model.py script name intends to convey that but inclusion of the folder in the release could be misunderstood to mean that the example content is maintained and ready-to-use to the same extent as the solr/bin scripts.\n\n... we need \" all JARs under contrib/ltr/lib.\" . I don't see anything under the binary. Is it safe to remove it? ...\n\nGood catch! I was inspired by the \"Installation\" section of https://cwiki.apache.org/confluence/display/solr/Result+Clustering and missed that contrib/ltr/lib is empty. I just updated the documentation and created SOLR-10451 for the techproducts solrconfig.xml update and to prune the empty (except for README.txt) contrib/ltr folder out of the Solr binary release.\n\n... BTW I love the documentation. ...\n\nThanks! \n\n\n\nPS: Thanks for the interest and feedback here. Let's wrap up here and continue or start any further conversations outside of this (completed) JIRA ticket in the usual places e.g. as per http://lucene.apache.org/solr/community.html#mailing-lists-irc\n\n\tthe Solr User Mailing list for usage and configuration related questions and problems\n\tthe Developer List for code and development related discussions\n\tthe Comments section of https://cwiki.apache.org/confluence/display/solr/Learning+To+Rank for documentation related corrections or suggestions.\n\n ",
            "id": "comment-15961055"
        }
    ]
}