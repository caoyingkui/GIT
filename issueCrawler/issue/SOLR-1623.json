{
    "id": "SOLR-1623",
    "title": "Solr hangs (often throwing java.lang.OutOfMemoryError: PermGen space) when indexing many different field names",
    "details": {
        "affect_versions": "1.3,                                            1.4",
        "status": "Closed",
        "fix_versions": [],
        "components": [
            "update"
        ],
        "type": "Bug",
        "priority": "Critical",
        "labels": "",
        "resolution": "Won't Fix"
    },
    "description": "With the following fields in schema.xml:\n\n <fields>\n   <field name=\"id\" type=\"sint\" indexed=\"true\" stored=\"true\" required=\"true\" /> \n    <dynamicField name=\"weight_*\"  type=\"sint\"    indexed=\"true\"  stored=\"true\"/>\n</fields>\n\n\nRun the following code:\n\n\nimport java.util.ArrayList;\nimport java.util.List;\nimport org.apache.solr.client.solrj.SolrServer;\nimport org.apache.solr.client.solrj.impl.CommonsHttpSolrServer;\nimport org.apache.solr.common.SolrInputDocument;\n\n    public static void main(String[] args) throws Exception {\n        SolrServer server;\n        try \n{\n            server = new CommonsHttpSolrServer(args[0]);\n        }\n catch (Exception e) \n{\n            System.err.println(\"can't creater server using: \" + args[0] + \"  \" + e.getMessage());\n            throw e;\n        }\n        for (int i = 0; i < 1000; i++) {\n            List<SolrInputDocument> batchedDocs = new ArrayList<SolrInputDocument>();\n            for (int j = 0; j < 1000; j++) \n{\n                SolrInputDocument doc = new SolrInputDocument();\n                doc.addField(\"id\", i * 1000 + j);\n                // hangs after 30 to 50 batches\n                doc.addField(\"weight_aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\" + Integer.toString(i) + \"_\" + Integer.toString(j), i * 1000 + j);\n                // hangs after about 200 batches\n                //doc.addField(\"weight_\" + Integer.toString(i) + \"_\" + Integer.toString(j), i * 1000 + j);\n                batchedDocs.add(doc);\n            }\n            try \n{\n                server.add(batchedDocs, true);\n                System.err.println(\"Done with batch=\" + i);\n                // server.commit(); //doesn't change anything\n            }\n catch (Exception e) \n{\n                System.err.println(\"batchId=\" + i + \" bad batch: \" + e.getMessage());\n                throw e;\n            }\n        }\n    }\n\nAnd soon the client (sometime throws) and solr will freeze. sometime you can see: java.lang.OutOfMemoryError: PermGen space in the server logs",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "author": "Yonik Seeley",
            "id": "comment-12786161",
            "date": "2009-12-04T20:57:44+0000",
            "content": "This is most likely due to interning of field names.  If you really need that many field names, the only option right now is to increase the size of the perm gen. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-12786167",
            "date": "2009-12-04T21:08:02+0000",
            "content": "Whats odd is that he has it marked as affects 1.4 as well - but that doesn't intern to perm gen anymore? Did you really test with 1.4? Or am I missing something?\n\nYou can also turn on gc for the perm gen space - not a complete solution, but it can help under the right circumstances (likely in combination with a larger perm gen space)). "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12786175",
            "date": "2009-12-04T21:29:42+0000",
            "content": "Whats odd is that he has it marked as affects 1.4 as well - but that doesn't intern to perm gen anymore?\n\nThe default StringHelper.intern() from Lucene is just a cache - String.intern() is still called. "
        },
        {
            "author": "Laurent Chavet",
            "id": "comment-12786185",
            "date": "2009-12-04T21:46:22+0000",
            "content": "Yes this definitely repros in 1.4.\n\nUnfortunately I think I need a lot of fields; here is what I am trying to do:\n\nI want to store news articles and extract many topics for each story with a score for each topic for each story.\n\nSo for example a story migh have a topic of Crime with a score of 20.\n\nSo what I am doing now is store:\n\nField:Topic    Value:Crime      indexed=\"true\" stored=\"true\"            (need to searched and retrieved)\nField:Weight_Topic_Crime  Value:20  indexed=\"true\" stored=\"true\"   (needs to be sorted and retrieved)\n\nBecause there can be a lot of different value for the field topic; with this schema  we end up with a lot of fields starting with weight.\n\nAny suggestion on how to achieve the same result in a different way?\n\nThanks,\n\nLaurent "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13835712",
            "date": "2013-11-30T13:24:02+0000",
            "content": "2013 Old JIRA cleanup "
        },
        {
            "author": "Alexandre Rafalovitch",
            "id": "comment-15538884",
            "date": "2016-10-01T17:38:58+0000",
            "content": "We are several JVM versions and virtual space management algorithms later now. If anything similar comes up against JRE 1.8, a new issue can be opened. "
        }
    ]
}