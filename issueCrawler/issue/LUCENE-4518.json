{
    "id": "LUCENE-4518",
    "title": "Suggesters: highlighting (explicit markup of user-typed portions vs. generated portions in a suggestion)",
    "details": {
        "components": [],
        "fix_versions": [],
        "affect_versions": "None",
        "priority": "Major",
        "labels": "",
        "type": "New Feature",
        "resolution": "Unresolved",
        "status": "Open"
    },
    "description": "As a user, I would like the lookup result of the suggestion engine to contain information which allows me to distinguish the user-entered portion from the autocompleted portion of a suggestion. That information can then be used for e.g. highlighting. \n\nNotes:\n\nIt's trivial if the suggestion engine only applies simple prefix search, as then the user-typed prefix is always a true prefix of the completion. However, it's non-trivial as soon as you use an AnalyzingSuggester, where the completion may (in extreme cases) be quite different from the user-provided input. As soon as case/diacritics folding, script adaptation (kanji/hiragana) come into play, the completion is no longer guaranteed to be an extension of the query. Since the caller of the suggestion engine (UI) generally does not know the implementation details, the required information needs to be passed in the LookupResult.\n\nDiscussion on java-user:\n\n> I haven't found a simple solution for the highlighting yet,\n> particularly when using AnalyzingSuggester (where it's non-trivial).\n\nMike McCandless:\n\nAhh I see ... it is challenging in that case.  Hmm.  Maybe open an issue for this as well, so we can discuss/iterate?",
    "attachments": {
        "LUCENE-4518.patch": "https://issues.apache.org/jira/secure/attachment/12551862/LUCENE-4518.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2012-10-31T12:17:44+0000",
            "content": "I don't really see highlighting fitting into suggesters. Suggesters are already too complicated: this is a UI problem that can be handled outside of lucene. ",
            "author": "Robert Muir",
            "id": "comment-13487699"
        },
        {
            "date": "2012-10-31T12:30:58+0000",
            "content": "I don't see how this can easily be addressed in the UI. \n\nGo to http://www.google.de and enter \"praefi\" as the query. The top two completions are\n\npr\u00e4fi*x*\npr\u00e4fi*nal*\n\nNote that in both cases the prefix \"pr\u00e4fi\" is recognized although the query is \"praefi\".\n\nTo handle this in the UI, the UI layer would have to duplicate the Analyzer's logic about case and diacritics folding.  \n\nI agree that in general, this may not be possible at all, but in simpler cases (case folding, diacritics insensitivity) I should think it's feasible (but hard on the UI level). ",
            "author": "Oliver Christ",
            "id": "comment-13487711"
        },
        {
            "date": "2012-10-31T12:52:04+0000",
            "content": "I tend to agree with Oliver. I have done similar things because the frontend lacks information here. I agree its non-trivial but we should provide it if we can. For absolute correctness you likely need to reanalyze and intersect with the automaton :/ ",
            "author": "Simon Willnauer",
            "id": "comment-13487730"
        },
        {
            "date": "2012-10-31T13:34:56+0000",
            "content": "In a classic FST, once you consumed the input and start looking for completions, you'd know how many input symbols you consumed, and how many output symbols you've collected so far, and how many symbols the TopNSearcher appends (i.e. how long, in characters, the completed portion of the string is). That information should be sufficient to explicitly distinguish the two parts. As long as completions don't \"surround\" the user-entered portions (google: \"sox ticket purc\"), or the prefix for some reason ends in the \"middle\" of a UTF8 byte sequence, this may be sufficient to cover basic use cases and put the length of the covered prefix (or completed suffix) into each LookupResult. I'm assuming that the input and output symbols are \"reasonably aligned\" in the transition labels, which may not be the case in the current implementation (I haven't gotten to that level of detail yet  ). ",
            "author": "Oliver Christ",
            "id": "comment-13487770"
        },
        {
            "date": "2012-10-31T17:11:06+0000",
            "content": "It'd be quite easy to back trace on each topN path to get the point at\nwhich it \"started\" (= the end of where we matched based on the user's\ninput).\n\nThe challenge is ... that's the analyzed form, not the surface form;\nin general we need the reverse mapping from analyzed form offsets back\nto surface form offsets ... and the OffsetAttribute gives us that, but\nunfortunately only gives us start/end of each token.\n\nAnother challenge is we convert the analyzed form into a graph\n(TokenStreamToAutomaton), so we'd somehow need to get the surface\nform offsets through there too. ",
            "author": "Michael McCandless",
            "id": "comment-13487968"
        },
        {
            "date": "2012-10-31T17:20:58+0000",
            "content": "Actually start/end offset of a each token is probably sufficient here?  Because the analyzed form of the partial token the user typed will show the end offset we want, I think? ",
            "author": "Michael McCandless",
            "id": "comment-13487985"
        },
        {
            "date": "2012-11-01T18:22:57+0000",
            "content": "Hmm... it could be that if we simply record the partial output (surface form) we've accumulated so far, when we add a start path into the TopNSearcher, that this could make a good hilite candidate.\n\nThe FST will always output \"eagerly\", meaning on seeing a given partial input, it will output as much as is unambiguously possible.  So I suspect the equivalent in Lucene of the \"praefi\" example would just work.\n\nThe only problem I can think of where this won't work is if the completion is [somewhat] deterministic.  EG if you only had added \"electron\" and \"electronics\" to your suggester, and user has typed only 'e' so far, the output on traversing only 'e' would be electron, which is way too much to hilite.  But in a \"real\" app, where there are tons and tons of suggestions, I suspect this would become a vanishingly minor issue. ",
            "author": "Michael McCandless",
            "id": "comment-13488906"
        },
        {
            "date": "2012-11-02T14:20:22+0000",
            "content": "Initial patch, that just records the starting output from when the path was added to the queue, and uses that to set the new prefixLength in LookupResult.\n\nCurrently I only fixed WFST, Analyzing and Fuzzy suggesters to set this.  WFST will always be correct (it's trivial), while Analyzing/Fuzzy can sometimes be too long (if there is a common prefix to all possible completions from that starting point). ",
            "author": "Michael McCandless",
            "id": "comment-13489440"
        },
        {
            "date": "2013-01-16T19:55:59+0000",
            "content": "I\u2019ve played around with Mike\u2019s patches, but for the AnalyzingSuggester the results have been mixed. Since the transition symbols in the automaton are not closely aligned between the surface and the analyzed form, LookupResult.prefixLength (which attempts to represent the length of the surface string which corresponds to the lookup string) is off quite a bit, leading to very confusing highlighting in non-trivial cases. \n\nI think this is ultimately due to the way how the FST is constructed, but that seems to be non-trivial to change.\n\nIn addition, just returning the (surface) prefix length which corresponds to the lookup string is not sufficient for more complex suggesters, such as \u201cinfix suggesters\u201d where the user-provided string is not a prefix of the full surface term (google.com: type in \u201csox rumor\u201d). What the suggesters ultimately would have to return is a list of text chunks where each chunk has a flag whether it\u2019s based on the lookup string or has been auto-completed.\n\nSo at this point we are back at trying to identify the matched string portions by other means, which isn\u2019t perfect either, but acceptable in most cases.  ",
            "author": "Oliver Christ",
            "id": "comment-13555396"
        },
        {
            "date": "2013-01-16T22:18:58+0000",
            "content": "OK thanks for testing Oliver ... sounds like the approach here is a no-go in practice. ",
            "author": "Michael McCandless",
            "id": "comment-13555529"
        }
    ]
}