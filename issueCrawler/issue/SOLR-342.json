{
    "id": "SOLR-342",
    "title": "Add support for Lucene's new Indexing and merge features (excluding Document/Field/Token reuse)",
    "details": {
        "affect_versions": "None",
        "status": "Resolved",
        "fix_versions": [],
        "components": [
            "update"
        ],
        "type": "Improvement",
        "priority": "Minor",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "LUCENE-843 adds support for new indexing capabilities using the setRAMBufferSizeMB() method that should significantly speed up indexing for many applications.  To fix this, we will need trunk version of Lucene (or wait for the next official release of Lucene)\n\nSide effect of this is that Lucene's new, faster StandardTokenizer will also be incorporated.  \n\nAlso need to think about how we want to incorporate the new merge scheduling functionality (new default in Lucene is to do merges in a background thread)",
    "attachments": {
        "SOLR-342.tar.gz": "https://issues.apache.org/jira/secure/attachment/12368415/SOLR-342.tar.gz",
        "copyLucene.sh": "https://issues.apache.org/jira/secure/attachment/12370858/copyLucene.sh",
        "SOLR-342.patch": "https://issues.apache.org/jira/secure/attachment/12368495/SOLR-342.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Grant Ingersoll",
            "id": "comment-12531353",
            "date": "2007-09-30T16:58:41+0000",
            "content": "I think we should wait a bit more on this, as there still are a fair number of issues related to these changes in Lucene that need to be ironed out. "
        },
        {
            "author": "Mike Klaas",
            "id": "comment-12531588",
            "date": "2007-10-01T18:19:50+0000",
            "content": "We could probably just wait for lucene 2.3 to be released before releasing 1.3.  I wouldn't be averse to pre-integrating the changes, though. "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12531591",
            "date": "2007-10-01T18:28:09+0000",
            "content": "yep, I agree with pre-integrating, just from watching the Lucene discussions going on lately, I think it is worth letting a few more things be worked out before using a nightly build. "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12536817",
            "date": "2007-10-22T20:14:47+0000",
            "content": "Updated to cover the broader scope of changes that effect upgrading to Lucene trunk.\n\nPlan to implement:\nAdd <ramBufferSizeMB> tag to specify the number of megabytes to give Lucene.  Setting this value will override all other related settings (maxBufferedDocs, etc.) related to IndexWriter configuration\n\nAdd <mergeScheduler> tag that can have two values:  concurrent or serial.   Or would it be better to take in a classname?  Doing the latter would mean we would have to have a no-arg constructor, right?\n\nAdd <mergePolicy> tag that defines the merge policy that can have two values: byteSize or docCount.  Or would it be better to take a classname? \n\nNOTE: I am not proposing to handle the new reusable Document/Field/Token mechanism in Lucene, which should also be considered.\n\n "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12537169",
            "date": "2007-10-23T23:25:07+0000",
            "content": "Perhaps for now mergePolicy should be aligned with the buffering limit (ram or docs)?\nIf/when we do add <mergePolicy> it seems like it should be a class name. "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12537617",
            "date": "2007-10-25T14:39:58+0000",
            "content": "OK, this would imply it is set to LogByteSizeMergePolicy when setting <ramBufferSizeMB> and LogDocMergePolicy when setting <maxBufferedDocs> "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12537731",
            "date": "2007-10-25T21:19:37+0000",
            "content": "First crack at implementing this.  All tests pass on OS X except SolrJ's SolrExceptionTest, but for some reason that is failing on a clean version, too, so I am convinced it is not due to anything I did.\n\nMy personal benchmarking of just the Lucene side of things (see indexing.alg in Lucene contrib/benchmark) show pretty significant performance gains.  This is also anecdotally confirmed by my basic testing in Solr.\n\nI set the default to be 16MB, per Mike McCandless defaults in Lucene, but this is probably too low given the server nature of Solr where a lot more memory is likely to be available.\n\nThere are 4 new configuration possibilities:\n<ramBufferSizeMB> -  When set, <maxBufferedDocs> is set to DISABLE_AUTO_FLUSH.  Default is the maxBufferedDocs way, but this could be changed to be the other way around (and probably should be)\n<mergePolicy> - Set the MergePolicy, default is the new Lucene LogByteSizeMergePolicy.  Old Lucene policy is LogDocMergePolicy.  LogByteSizeMergePolicy by default.\n<mergeScheduler> - Set the way merges are performed.  New way is ConcurrentMergeScheduler which runs the merges in separate background threads.  Old way was SerialMergeScheduler. Concurrent by default.\n<luceneAutoCommit>  - Specify whether Lucene IndexWriter should autoCommit flushes.  false is the best for performance.  Still need to develop recommendations for when to change this.  Named it this way to avoid confusion with Solr's version.  false by default.\n\nPatch is inside the tar file, as well as a bundling of the Lucene jars (not technically the latest, but only a couple days old) "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12537738",
            "date": "2007-10-25T21:30:31+0000",
            "content": "> Default is the maxBufferedDocs way, but this could be changed to be the other way around (and probably should be)\n\n+1\nramBufferSizeMB is now the default in Lucene AFAIK.\nI think perhaps 32MB might be a good default.\n\nluceneAutoCommit [...] Still need to develop recommendations for when to change this.\nFor Solr, you never would want to use it.  trying to catch a glimpse of new segments as they are flushed leads to an inconsistent view of the index since docs haven't been deleted yet.\n\nWe do need to document recommended solrconfig.xml changes in CHANGES.txt (at the top in the migration section we normally have) for people to get these performance gains with existing configs. "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12537924",
            "date": "2007-10-26T11:13:22+0000",
            "content": "\n+1\nramBufferSizeMB is now the default in Lucene AFAIK.\nI think perhaps 32MB might be a good default.\n\nThe other thing is, Lucene actually supports setting both, and flushes based on whichever one is hit first.  Is this worth supporting?\n\n\nFor Solr, you never would want to use it. trying to catch a glimpse of new segments as they are flushed leads to an inconsistent view of the index since docs haven't been deleted yet.\nShould we even expose this, then?  It seems like we should just make it false.\n\nI will write up more in the changes. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12537992",
            "date": "2007-10-26T15:43:59+0000",
            "content": "> The other thing is, Lucene actually supports setting both, and flushes based on whichever one is hit first. Is this worth supporting?\n\nSince it takes no extra work in Solr, I guess we should just allow it.\n\n> Should we even expose this [lucene autocommit], then? It seems like we should just make it false.\n\nI think so... some people use Solr in some quite advanced ways.\n "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12538023",
            "date": "2007-10-26T17:10:13+0000",
            "content": "Changes:\n\n1. Updated changes.txt with recommendations on settings.\n\n2. Changed SolrIndexWriter from last patch to allow for setting both maxBufferedDocs and ramBufferSizeMB.\n\n3. Updated the various sample solrconfig.xml to have a default of 32 MB for ramBufferSizeMB.  Commented out maxBufferedDocs, but did not deprecate it.\n\n4. Added a note to the various solrconfig.xml explaining what Lucene does if BOTH ramBufferSizeMB and maxBufferedDocs is set.\n\nThe Lucene libraries are bundled with the previous patch, but are still needed. "
        },
        {
            "author": "Will Johnson",
            "id": "comment-12547854",
            "date": "2007-12-03T14:26:04+0000",
            "content": "just a comment to say that we added this patch and saw rather signifigant improvements, on the order of 10-25% for different index tests. "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12547918",
            "date": "2007-12-03T17:48:26+0000",
            "content": "Dumb little script to copy over the required Lucene jars from a built Lucene directory.  Takes in two parameters, the location of Lucene Home and the version to copy over.  Requires Lucene to be built.\n\nBelongs in the lib directory.\n\nFor example,\n./copyLucene.sh <path to Lucene> 2.3-dev "
        },
        {
            "author": "Will Johnson",
            "id": "comment-12547925",
            "date": "2007-12-03T18:16:30+0000",
            "content": "is there any update on getting this patch committed?  we needed to be able to set some of the buffer sizes so the script wouldn't help.  have other people experienced tourbles with 2.3 and/or this patch that i should be wary of? "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12547927",
            "date": "2007-12-03T18:24:51+0000",
            "content": "In my mind, there are still some issues w/ 2.3 dev that are being worked on.   Personally, I think we should wait until 2.3 is released, but it would be good for people to get some running-time with this patch, if they can, before then, as that will help work out any issues remaining in 2.3. "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12555132",
            "date": "2007-12-31T19:47:31+0000",
            "content": "Looks like Lucene 2.3 is shaping up to be released fairly soon (~2 weeks) and that many of the indexing/thread-safety concerns have been worked out.  Might as well wait for the official release at this point, although I have been using 2.3-dev for a fairly long time at this point. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12555777",
            "date": "2008-01-04T03:20:07+0000",
            "content": "I don't think it's necessary to wait for the official lucene 2.3 release, esp since there is still a lot of solr work to be done (tokenizer upgrades to use char[], reusable tokenizers, reusable analyzers?, etc).  We could upgrade to the latest snapshot when someone is willing to tackle those issues. "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12565025",
            "date": "2008-02-02T03:32:59+0000",
            "content": "Updated to work against trunk.\n\nAs always, let me know if there is anything I can do to help get this committed. "
        },
        {
            "author": "Koji Sekiguchi",
            "id": "comment-12565128",
            "date": "2008-02-03T00:06:12+0000",
            "content": "Now mergeFactor can be effective as long as mergePolicy is an instance of LogMergePolicy.\nHow about\n\n<mergePolicy mergeFactor=\"10\"/>\n\nor\n\n<mergePolicy>\n  <mergeFactor>10</mergeFactor>\n</mergePolicy>\n\ninstead of\n\n<indexDefaults>\n  <mergeFactor>10</mergeFactor>\n</indexDefaults> "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12566643",
            "date": "2008-02-07T15:46:52+0000",
            "content": "I did some benchmarking of the autocommit functionality in Lucene (as opposed to in Solr, which is different).  Currently, in Lucene autocommit is true by default, meaning that every time there is a flush, it is also committed.  Solr adds its own layer on top of this with its commit semantics.  There is a noticeable difference in memory used and speed in Lucene performance between autocommit = false and autocommit = true.  \n\nSome rough numbers using the autocommit.alg in Lucene's benchmark contrib (from trunk):  \n Operation       round ac ram   runCnt   recsPerRun        rec/s  elapsedSec    avgUsedMem    avgTotalMem\n     [java] MAddDocs_200000     0rue2.00        1       200000        400.1      499.90    61,322,608     68,780,032\n     [java] MAddDocs_200000 -   1lse2.00 -  -   1 -  -  200000 -  -   499.9 -  - 400.08 -  49,373,632 -   75,018,240\n     [java] MAddDocs_200000     2rue2.00        1       200000        383.7      521.27    70,716,096     75,018,240\n     [java] MAddDocs_200000 -   3lse2.00 -  -   1 -  -  200000 -  -   552.7 -  - 361.89 -  68,069,464 -   75,018,240\n\nThe first row has autocommit = true, second is false, and then alternating.  The key value is the rec/s, which is:\n1. ac = true 400.1\n2. ac = false 499.9\n3. ac = true 383.7\n4. ac = false 552.7\n\nNotice also the diff in avgUsedMem.  Adding this functionality may, perhaps, be more important to Solr's performance than the flush by RAM capability. "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12566648",
            "date": "2008-02-07T15:53:37+0000",
            "content": "Update of patch to account for the fact that mergeFactor is only for Log based merges.  I left it as the <mergeFactor> tag, but put in an instanceof clause in the init method of the SolrIndexWriter to check to see if the mergeFactor is settable. "
        },
        {
            "author": "Will Johnson",
            "id": "comment-12567099",
            "date": "2008-02-08T17:10:50+0000",
            "content": "I think we're running into a very serious issue with trunk + this patch.  either the document summaries are not matched or the overall matching is 'wrong'.  i did find this in the lucene jira: LUCENE-994 \n\n\"Note that these changes will break users of ParallelReader because the\nparallel indices will no longer have matching docIDs. Such users need\nto switch IndexWriter back to flushing by doc count, and switch the\nMergePolicy back to LogDocMergePolicy. It's likely also necessary to\nswitch the MergeScheduler back to SerialMergeScheduler to ensure\ndeterministic docID assignment.\"\n\nwe're seeing rather consistent bad results but only after 20-30k documents and multiple commits and wondering if anyone else is seeing anything.  i've verified that the results are bad even though luke which would seem to remove the search side of hte solr equation.   the basic test case is to search for title:foo and get back documents that only have title:bar.  we're going to start on a unit test but give the document counts and the corpus we're testing against it may be a while so i thought i'd ask to see if anyone had any hints.\n\nremoving this patch seems to remove the issue so i doesn't appear to be a lucene problem\n "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12567111",
            "date": "2008-02-08T17:20:51+0000",
            "content": "Yikes!  Thanks for the report Will.  It certainly sounds like a Lucene issue to me (esp because removal of this patch fixes things... that means it only happens under certain lucene settings).  Could you perhaps try the very latest Lucene trunk (there were some seemingly unrelated fixes recently). "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12567140",
            "date": "2008-02-08T18:06:36+0000",
            "content": "Will, are you using term vectors anywhere, or any customizations to Solr (at the lucene level)?\nWhen you say \"document summaries are not matched\", you you mean that the incorrect documents are matched, or that the correct documents are matched but just highlighting is wrong? "
        },
        {
            "author": "Will Johnson",
            "id": "comment-12567147",
            "date": "2008-02-08T18:25:31+0000",
            "content": "patched solr + lucene trunk is stil broken.  if anyone has any pointers for ways to coax this problem to happen before we get 20-30k large docs in the system let me know and we can start working on a unit test, otherwise it's going to take a while to reproduce anything. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12567152",
            "date": "2008-02-08T18:34:32+0000",
            "content": "Thanks Will.  My guess at this point is a merging bug in Lucene, so you might be able to reproduce by forcing more merges.  Make mergeFacor=2 and lower how many docs it takes to do a merge (set maxBufferedDocs to 2, or set ramBufferSizeMB to 1). "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12567187",
            "date": "2008-02-08T20:23:58+0000",
            "content": "Can you share your settings? (solrconfig.xml), or at least the relevant sections.   "
        },
        {
            "author": "Will Johnson",
            "id": "comment-12567198",
            "date": "2008-02-08T20:46:50+0000",
            "content": "we have: \n\n<mergeFactor>10</mergeFactor> \n<ramBufferSizeMB>64</ramBufferSizeMB> \n<maxMergeDocs>2147483647</maxMergeDocs> \n\nand i'm working on a unit test but just adding a few terms per doc doesnt seem to trigger it, at least not 'quickly.' "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12567207",
            "date": "2008-02-08T21:20:19+0000",
            "content": "You mentioned ParallelReader, are you using that, or any other patches?\n\nproblem to happen before we get 20-30k large docs\n\nwhat is \"large\" in your terms?   "
        },
        {
            "author": "Will Johnson",
            "id": "comment-12567218",
            "date": "2008-02-08T21:49:41+0000",
            "content": "we're not using parallel reader but we are using direct core access instead of going over http.  as for doc size, we're indexing wikipedia but creating anumber of extra fields.  they are only large in comparison to any of the 'large volume' tests i've seen in most of the solr and lucene tests.  \n\n\n\twill\n\n "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12567221",
            "date": "2008-02-08T22:01:24+0000",
            "content": "Direct core meaning embedded, right?  It's interesting, b/c I have done a fair amount of Lucene 2.3 testing w/ Wikipedia (nothing like a free, fairly large dataset)\n\nCan you reproduce the problem using Lucene directly? (have a look at contrib/benchmark for a way to get Lucene/Wikipedia up and running quickly)\n\nAlso, are there any associated exceptions anywhere in the chain?  Or is it just that your index is bad?  Are you starting from a clean index or updating an existing one? "
        },
        {
            "author": "Will Johnson",
            "id": "comment-12567235",
            "date": "2008-02-08T22:48:53+0000",
            "content": "we're using SolrCore in terms of:\n\ncore = new SolrCore(\"foo\", dataDir, solrConfig, solrSchema);\nUpdateHandler handler = core.getUpdateHandler();\nupdateHandler.addDoc(command);\n\nwhich is a bit more low level than normal however when we flipped back to solr trunk + lucene 2.3 everything was fine so it leads me to belive that we are ok in that respect.\n\ni was going to try and reproduce with lucene directly also but that too is a bit outside the scope of what i have time for at the moment.  \n\nand we're not getting any exceptions, just bad search results. "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12567504",
            "date": "2008-02-11T02:15:43+0000",
            "content": "Also, are you doing multi-threaded indexing or are you indexing while searching? "
        },
        {
            "author": "Will Johnson",
            "id": "comment-12567508",
            "date": "2008-02-11T03:08:56+0000",
            "content": "we are doing multi-threaded indexing and searching while indexing however the 'bad' results come back after the indexing run is finished and the index itself is static. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12567809",
            "date": "2008-02-11T20:37:56+0000",
            "content": "OK, I've managed to reproduce this in a straight lucene testcase.\nI'm doing further verification and will open up a Lucene bug shortly. "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12568938",
            "date": "2008-02-14T14:12:30+0000",
            "content": "Sounds like we will have a Lucene 2.3.1 release in the next week or so with the fixes in place.  Will, in the meantime, when LUCENE-1177 and LUCENE-1173 get committed,maybe you could try either building the LUCENE 2.3 branch or trying out with the Lucene nightly build to see if it solves your issue and let us know. "
        },
        {
            "author": "Will Johnson",
            "id": "comment-12569408",
            "date": "2008-02-15T20:52:45+0000",
            "content": "i switched to the lucene 2.3 branch, updated (and confirmed that yonik's 1 line change was in place), reran the tests and still saw the same problem.  if i missed something please let me know. "
        },
        {
            "author": "Michael McCandless",
            "id": "comment-12569525",
            "date": "2008-02-16T11:17:06+0000",
            "content": "Will, did you create a new index in your test?\n\nAlso make sure you are using this URL to checkout the 2.3 branch sources:\n\n  https://svn.apache.org/repos/asf/lucene/java/branches/lucene_2_3\n\nYou should see 7 issues listed in the CHANGES.txt under \"Bug fixes\"? "
        },
        {
            "author": "Michael McCandless",
            "id": "comment-12569845",
            "date": "2008-02-18T10:49:44+0000",
            "content": "Will, one more thing to try is to on assertions for org.apache.lucene.*; this may catch an issue sooner. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12569948",
            "date": "2008-02-18T17:01:52+0000",
            "content": "Will, you should be able to verify the lucene version with this link:\nhttp://localhost:8983/solr/admin/registry.jsp\nIt should be different from this:\n\tLucene Specification Version: 2.3.0\n\tLucene Implementation Version: 2.3.0 613715 - buschmi - 2008-01-21 01:30:48 "
        },
        {
            "author": "Will Johnson",
            "id": "comment-12570319",
            "date": "2008-02-19T17:23:14+0000",
            "content": "the new solr with the new lucene did the trick.  i was made the mistake of using the 2.3 tag instead of the branch before which was why i still saw the problem. "
        },
        {
            "author": "Michael McCandless",
            "id": "comment-12570327",
            "date": "2008-02-19T17:37:45+0000",
            "content": "Super, I'm glad to hear that! "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12574502",
            "date": "2008-03-03T13:48:01+0000",
            "content": "I'm going to upgrade to 2.3.1 and then double check this and commit, unless I hear any objections in the next day or two. "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12574506",
            "date": "2008-03-03T13:58:20+0000",
            "content": "oops, we are already on 2.3.1, so then I will just commit in a day or two. "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12575488",
            "date": "2008-03-05T20:23:07+0000",
            "content": "Committed revision 634016. "
        }
    ]
}