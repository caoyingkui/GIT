{
    "id": "SOLR-2026",
    "title": "Need infrastructure support in Solr for requests that perform multiple sequential queries",
    "details": {
        "affect_versions": "None",
        "status": "Closed",
        "fix_versions": [],
        "components": [
            "SearchComponents - other"
        ],
        "type": "New Feature",
        "priority": "Minor",
        "labels": "",
        "resolution": "Information Provided"
    },
    "description": "Several known cases exist where multiple index searches need to be performed in order to arrive at the final result.  Typically, these have the constraint that the results from one search query are required in order to form a subsequent search query.  While it is possible to write a custom QueryComponent or search handler to perform this task, an extension to the SearchHandler base class would readily permit such query sequences to be configured using solrconfig.xml.\n\nI will be therefore writing and attaching a patch tomorrow morning which supports this extended functionality in a backwards-compatible manner.  The tricky part, which is figuring out how to funnel the output of the previous search result into the next query, can be readily achieved by use of the SolrRequestObject.getContext() functionality.  The stipulation will therefore be that the SolrRequestObject's lifetime will be that of the entire request, which makes complete sense.  (The SolrResponseObject's lifetime will, on the other hand, be limited to a single query, and the last response so formed will be what gets actually returned by SearchHandler.)",
    "attachments": {
        "SOLR-2026.patch": "https://issues.apache.org/jira/secure/attachment/12451241/SOLR-2026.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Karl Wright",
            "id": "comment-12895110",
            "date": "2010-08-04T00:40:12+0000",
            "content": "As pointed out, SOLR-1878 has a similar but more narrow requirement. "
        },
        {
            "author": "Karl Wright",
            "id": "comment-12895336",
            "date": "2010-08-04T17:56:55+0000",
            "content": "Patch which optionally runs multiple Lucene queries, and which makes the result of the previous Lucene query available for the next one. "
        },
        {
            "author": "Karl Wright",
            "id": "comment-12895340",
            "date": "2010-08-04T18:04:10+0000",
            "content": "Here's an example of the solrconfig.xml using the attached patch:\n\n  <requestHandler name=\"/querytest\" class=\"solr.SearchHandler\" lazy=\"true\">\n\n    <arr name=\"queries\">\n      <lst name=\"query1\">\n          <!-- the first query's configuration -->\n          <arr name=\"components\">\n            <str>query</str>\n          </arr>\n      </lst>\n      <lst name=\"query2\">\n          <!-- the second query's configuration -->\n          <arr name=\"components\">\n            <str>query</str>\n          </arr>\n      </lst>\n    </arr>\n\n    <!-- Note well: the final query of the sequence is specified at this root level.  In this case, the default components are all chosen.\n          Thus, this example represents three Lucene queries performed in sequence.  -->\n\n  </requestHandler>\n\n\nNote also that the ResponseBuilder object from the previous Lucene query is made available in the next Lucene query's request context.  Use SolrRequestObject.getContext().get(\"previousresponse\") to grab it. "
        },
        {
            "author": "Lance Norskog",
            "id": "comment-12895468",
            "date": "2010-08-04T23:40:01+0000",
            "content": "What if I want to send different data the second time? Or if I want to choose between two subsequent queries based on the first response?\n\nI propose that this patch should instead allow the user to create javascript to control the second and subsequent queries. \n "
        },
        {
            "author": "Karl Wright",
            "id": "comment-12895500",
            "date": "2010-08-05T01:09:36+0000",
            "content": "\"What if I want to send different data the second time? Or if I want to choose between two subsequent queries based on the first response?\"\n\nI see no reason whatsoever that this proposal would be unable to do precisely those kinds of things.  Indeed, that's the whole point.\nI'm not sure what you are bringing in javascript for.  Are you talking server-side javascript, or client-side?  If server-side, this sounds like adding extra wheels whose incremental utility is unclear.  If client-side, then it's completely orthogonal to this proposal.\n\nReading a bit between the lines, it sounds like you are thinking in terms of multiple Lucene queries that result from multiple, different request queries.  But that's not the model I'm talking about at all - I'm looking at a single request query, but multiple Lucene queries, each resulting from execution of a distinct set of search components on that single request query. "
        },
        {
            "author": "Karl Wright",
            "id": "comment-12895503",
            "date": "2010-08-05T01:17:26+0000",
            "content": "Further clarification as to the purpose behind this proposal:\nThe incoming request has a \"query\", but it may not be possible to convert that \"query\" into a single Lucene index query.  (It's really important to keep track of the distinction between the user query and the underlying Lucene queries, or you'll go insane.)  In my situation, the place where I see this happening is when there are two (or more) non-trivial query parsers, yielding multiple stages to evaluate a final response - e.g., Query Parser 1 generates a lucene query that yields results, which are used in part to construct the query generated by Query Parser 2 in some way.\n "
        },
        {
            "author": "Simon Willnauer",
            "id": "comment-12895712",
            "date": "2010-08-05T15:31:36+0000",
            "content": "Karl,\nthis improvement sounds perfectly reasonable to me. The usecase could indeed help many people who have to run search requests including multiple queries without doing another roundtrip and sending results from previous queries back and forth.  I modified your patch a little bit and marked bw stuff as deprecated. I also added replacements for those methods as well as simplifying some of the code.\n\nI didn't run all the test yet  but the tests I added for this issue pass. I attach my current status and run complete tests tomorrow!\n\nSimon "
        },
        {
            "author": "Lance Norskog",
            "id": "comment-12895912",
            "date": "2010-08-06T01:28:38+0000",
            "content": "The incoming request has a \"query\", but it may not be possible to convert that \"query\" into a single Lucene index query. (It's really important to keep track of the distinction between the user query and the underlying Lucene queries, or you'll go insane.) In my situation, the place where I see this happening is wh,en there are two (or more) non-trivial query parsers, yielding multiple stages to evaluate a final response - e.g., Query Parser 1 generates a lucene query that yields results, which are used in part to construct the query generated by Query Parser 2 in some way. \n\nYes, this is a valid use case. There are other use cases that I've seen over the months that have other reasons to do a series of queries instead of one.  I claim that if Solr really supports this, it should support it with a clean, modular architecture which handles many different uses cases that we don't know about yet. This implies programmability to achieve each use case. This would mean either, as you suggest, adding a way to allow QueryHandlers to do multiple calls, or adding a scripting language to the server side.\n\nBut, this shakes out as two levels: a scripting language would have to be a QueryHandler that does two Solr queries, so it would need the improvement you supply in this issue.\n\nSo, I would request that the new QueryHandler infrastructure be able to support the Java scripting APIs.\n\nLance "
        },
        {
            "author": "Lance Norskog",
            "id": "comment-12895914",
            "date": "2010-08-06T01:32:22+0000",
            "content": "Also, how does this interact with Distributed Search? The first query may need the results of a distributed search to create the second query.  "
        },
        {
            "author": "Karl Wright",
            "id": "comment-12896007",
            "date": "2010-08-06T09:27:39+0000",
            "content": "Re: Distributed Search:\nLuckily, shards from a distributed search are assembled by the SearchHandler, and my modifications for this feature force this assembly to happen on every Lucene query in the sequence in turn.  So, at that level, it all works properly.  On the other hand, since sharding is specified as part of the request arguments, it is probably not currently possible to specify different sharding for each of the queries in the sequence.  I imagine this can be addressed by future patches that allow default sharding to be optionally specified in the solrconfig.xml file on a per-query basis.\n "
        },
        {
            "author": "Simon Willnauer",
            "id": "comment-12896009",
            "date": "2010-08-06T09:41:54+0000",
            "content": "So, I would request that the new QueryHandler infrastructure be able to support the Java scripting APIs.\n\nLance, can you elaborate why you have such strong feelings about making this part scriptable?\n\nadding a way to allow QueryHandlers to do multiple calls\nCan't you do this already? Maybe I miss something but what keeps you from running two queries in a single QueryComponent? From what I understand is that this patch enables you doing this by editing the solrconf.xml rather than subclass QueryComponent and if you wanna change the  previous executed query component you have to change your code. Correct me if I am wrong.\n\nsimon "
        },
        {
            "author": "Karl Wright",
            "id": "comment-12896011",
            "date": "2010-08-06T10:01:46+0000",
            "content": "Maybe I miss something but what keeps you from running two queries in a single QueryComponent?\n\nYou can, so long as you kick off both queries with a SearchComponent's process() method.  Problem is, this basically bypasses most of Solr, including distribute queries, the SearchComponent pipeline, etc.\n\nThe purpose of this change was to add a well-defined infrastructure to allow people to do multiple queries in a Solr friendly way. "
        },
        {
            "author": "Lance Norskog",
            "id": "comment-12896211",
            "date": "2010-08-07T02:18:28+0000",
            "content": "Lance, can you elaborate why you have such strong feelings about making this part scriptable?\n\nI have seen requests for this ability several times on the mail lists, and each time the request is \"I have this one interesting use case so let's add a new feature that makes my use case work\". (Not an unusual occurence   Now that we have jumped to Java 1.6, it makes sense to do scriptable modules in some places, instead of saying \"make a subclass\".\n\nLance "
        },
        {
            "author": "Hoss Man",
            "id": "comment-12897994",
            "date": "2010-08-12T23:04:06+0000",
            "content": "Skimming the thread that spawned this issue, the issue comments, and the patch I'm a little confused as to what some of the main use cases for functionality like this would be unless it was tied to a scripting system to dictate how the params for each \"query\" (really a sub-request) should be driven by the params for the first \"quer\".  (Perhaps there is some static use case i'm just not seeing where the distinct requests are independent of each other?)\n\nIn any case: adding this to SerachHandler actaully seems to be really overly-complicated.\n\nWouldn't this be more straight forward as it's own distinct RequestHandler (that didn't even know about SearchComponents?)  There doesn't seem to be any reason why the logic even needs to be aware of when it's used in a distributed fashion, the new \"SequentialRequestHandler\" would always run on the coordinator, and the individual sub-requests would be to SearchHandler instances (probably with differnet components or default param configurations) where the shards param would kick in if present and result in distributed queries.\n\nSearchHandler could remain untouched, and keep it's current focus (managing SearchComponents) while the new SequentialRequestHandler would focus on executing independdent sub queries in sequence.\n\n\ndoes that make sense? "
        },
        {
            "author": "Simon Willnauer",
            "id": "comment-12898195",
            "date": "2010-08-13T11:41:32+0000",
            "content": "Wouldn't this be more straight forward as it's own distinct RequestHandler (that didn't even know about SearchComponents?\nIt would be at least the cleaner solution and I like it. I am actually quiet happy that some of the more \"solr\" experienced people (thanks hoss  jumped in and looked at that. I still don't  understand what this has to do with scripting engines but I guess it you folks have you usecase as I do...\n\nThere doesn't seem to be any reason why the logic even needs to be aware of when it's used in a distributed fashion\nMaybe I miss something but where am I aware of if I'm distributed? I don't see this - enlighten me please! From the outside this looks like a single request which can for sure be done via a \"SequentialRequestHandler\" which delegates down to a list of SearHandler instances. If the request is distributed I actually might not want the coordinator to fire a distributed request for each SearchHandler it has configured but maybe fire the distributed request on a higher level eg. the SequentialRequestHandler instance on the distributed nodes it is talking to. It would safe a whole set of network roundtrips, right? I guess both has valid use-cases so this should probably be configurable...  \n\nSearchHandler could remain untouched, and keep it's current focus (managing SearchComponents) while the new SequentialRequestHandler would focus on executing independdent sub queries in sequence.\n\n+1 yeah that makes lots of sense to me, plus bw compat comes for free - I will update the patch\n\nsimon "
        },
        {
            "author": "Hoss Man",
            "id": "comment-12899154",
            "date": "2010-08-16T22:44:27+0000",
            "content": "I still don't understand what this has to do with scripting engines but I guess it you folks have you usecase as I do...\n\nI don't actually have any usecases ... but all of the use cases i can imagine involve needing some mechanism to specify in the configuration how the outcome of the various requests in the sequence should influence the input to the subsequent requests \u2013 some form of scripting specified in the cofig files seems like the most straight forward mechanism, but other more constrained syntaxes could certainly work as well \u2013 the key is I can't  think of any use cases where you don't need any mechanism at all \u2013 at least not unless you plan on writting a lot of one off special case SearchComponents.\n\nMaybe I miss something but where am I aware of if I'm distributed?\n\nthat's my point \u2013 i only skimmed your code, but in glancing at it it wasn't obvious to me if the changes you made were going to result in the \"sequential\" type functionality being applied on the \"coordinator\" node of a distributed request, or on the individual shards, or both.  it's something that needs to be considered if this logic lives in SearchHandler. (either making it config able, or picking the \"right\" choice for every one)\n\nBut if it's a distinct RequestHandler, then there is a nice seperation of logic, and the contrl over where it is used in a distributed setup is all controlled by solrconfig.xml and existing request params. ie...\n\nIf:\n\n\t\"/searchA\" is mapped to an instance of SearchHandler with some components/defaults\n\t\"/searchB\" is mapped to an instance of SearchHandler with some other components/defaults\n\t\"/sequence\" is mapped to an instance of SequentialRequestHandler, that fires sequential requsts to \"/searchA\" then \"/searchB\"\nThen:\n\thttp://coordinator/solr/sequence?shards=shard1,shard2 - executes \"/sequence\" on the coordinator machine, where it (locally) executes \"searchA\" and \"searchB\" which each (independently) fire distributed requests to shard1/searchA+shard2/searchA and shard1/searchB+shard2/searchB\n\thttp://coordinator/solr/searchA?shards=shard1,shard2&shards.qt=/sequence - executes \"/searchA\" on the coordinator machine which fires distributed requests to shard1/sequence and shard2/sequence which each (independendly) sequentially run shard1/searchA+shard1/searchB and shard2/searchA+shard2/searchB\n\n\n\n...the first use cases seems more straight forward and logical to me personally, but the second seems equally plausible.\n\n(of course: it's totally possible that i just radically don't understand the goal at all ... as evident by my confusion about how this would possibly be useful w/o some mechanism for configuring how each request is influenced by the outcome of the previous request ... in which case feel free to ignore me)\n "
        },
        {
            "author": "Lance Norskog",
            "id": "comment-12899253",
            "date": "2010-08-17T02:46:49+0000",
            "content": "Here's a use case: field collapsing. Some people currently do field collapsing with 2 queries: first you get a few hundred documents with just the id and collapsar field. Then you trim the id set from the collapsar contents. and grab the first N unique ids. This is fine when you don't really care how many docs are in each collapsar group, you only care that there is more than one item per group.\n\nThis works great as a 2-query sequence where the code analyses the first return to create the second query.\n "
        },
        {
            "author": "Lance Norskog",
            "id": "comment-12899254",
            "date": "2010-08-17T02:47:59+0000",
            "content": "About where in the stack this should occur: I can wanting to do 2 successive queries at each shard, or doing one query against all shards, then a second query against shards.  These would be implemented in different parts of the code stack, right? "
        },
        {
            "author": "Simon Willnauer",
            "id": "comment-12899382",
            "date": "2010-08-17T12:01:40+0000",
            "content": "But if it's a distinct RequestHandler, then there is a nice seperation of logic, and the contrl over where it is used in a distributed setup is all controlled by solrconfig.xml and existing request params. ie...\n\n100% agreement, moving the logic to do that up to a dedicated RequestHandler is a the way to go. \n\n...the first use cases seems more straight forward and logical to me personally, but the second seems equally plausible.\n\nI understand those use-cases but I still have a hard time to understand why this would require something like a scripting engine. IMO adding scripting support just for the sake of being able to fire more than one query seems to be over-engineered. The use-cases you outlined can be handled by a way easier and at the same time more consistent way IMO. (@hoss - don't get me wrong I am not saying you explicitly asked for a scripting engine \n\nBoth use-cases we where talking about could be covered by simple configuration. In a \"SequentialRequestHandler\" each sub-request  could refere to another requestHandler configured somewhere else with distinct default values. Requests which should be fired as 2 successive queries on each shard would be enclosed by a <combine> tag while all others are considered to be executed one after another on all shards.  \n\n<requestHandler name=\"/sequential\" class=\"solr.SequentialRequestHandler\" >\n  <requests>\n    <requestHandler>searchA</requestHandler>\n    <requestHandler>searchB</requestHandler>\n    <combine>\n        <requestHandler>searchC</requestHandler>\n        <requestHandler>searchD</requestHandler>\n    </combine>\n  </requests>\n</requestHandler>\n\n\n\nA request to /sequential could then be (reqeusts param is optional and would override the configuration):\nhttp://coordinator/solr/sequence?shards=shard1,shard2&requests=searchA,searchB,\n{searchC,searchD}\n\nsubsequent requests to shards would be:\nhttp://shard1/solr/searchA?params....\nhttp://shard2/solr/searchA?params....\n\nhttp://shard1/solr/searchB?params....\nhttp://shard2/solr/searchB?params....\n\nhttp://shard1/solr/sequence?requests=searchC,searchD&params....\nhttp://shard2/solr/sequence?requests=searchC,searchD&params....\n\nthe coordinator can then handle all the logic required to build params for subsequent request. By default it would just fire one after another and render the results returned from the last request. Users should be able to subclass the SequentialRequestHandler to add more sophisticated logic.\n\nLance, would that fit your needs too?\n\n\n\n\n "
        },
        {
            "author": "Lance Norskog",
            "id": "comment-12900966",
            "date": "2010-08-21T03:34:54+0000",
            "content": "NP. All I would suggest is to make all of the architecture changes to something more modular and flexible, rather than adding support for a special-purpose tool. "
        },
        {
            "author": "Hoss Man",
            "id": "comment-12903111",
            "date": "2010-08-26T22:24:00+0000",
            "content": "I understand those use-cases but I still have a hard time to understand why this would require something like a scripting engine.\n\nMaybe we have an XY Problem here?\n\nI read the description of this issue, and see that the goal is for a single request fro ma client, to result in Solr internally executing multiple sequential requests, where the result of request N can be used to influence requests N+M.\n\nMy thought process based on that reading, is that in order to be useful, some mechanism is needed when configuring these sequential requests, so that the perosn writting the config can say \"extract some value X from the result of request N using the following rule, use value X as input for request M using the following rule\" \u2013 and that sounds like scripting to me.\n\nIf the infrastructure for executing these sequential requests doesn't support a mechanism like this natively, then it seems like it would only be useful for triggering sequential requests to special case RequestHandlers that know they will be used in this manner, and have special code for getting the variables they expect from the output of the RequestHandlers that come before then in the sequence \u2013 but in that case, the infrastructure doesn't really do anything for you, these custom Requesthandlers could do the sequential execution themselves (that part is really trivial)\n\nI can imagine lots of use cases where this functionality would be useful with existing (general purpose) request handlers provided it allowed scripting in it's config to control how the output of one affected the input of another (ie: two hits to the same SearchHandler, the second one replcaeing hte \"q\" param with the top term returned by the SpellCheckComponent from the first request) but i haven't been able to think of a use case where it would be useful w/o this type of configuration.\n\nCan you provides some details on the type of use case you are thinking of that wouldn't require some type of scripting?\n\nSo far the only example posted is Karl's, where as he described it the request handler in the second request would absolutely have to be some custom plugin that knows to look at SolrRequestObject.getContext().get(\"previousresponse\") "
        },
        {
            "author": "Lance Norskog",
            "id": "comment-12903791",
            "date": "2010-08-28T06:47:08+0000",
            "content": "In fact, I have a use case that needs no custom code: \"There are more results from this site\" like Google Search. No counts, just a binary value.\n\nThe easy way to do this is to pull the collapsar field from successive docs until you end up with 10 unique documents, and 10 boolean values. No custom code required.  This should be a custom RequestHandler/SearchHandler/whatever is the right thing.\n\nThis would have to be above the distributed broker.  "
        },
        {
            "author": "Simon Willnauer",
            "id": "comment-12976693",
            "date": "2011-01-03T10:57:26+0000",
            "content": "moving out "
        },
        {
            "author": "Peter Sturge",
            "id": "comment-13002701",
            "date": "2011-03-04T16:38:48+0000",
            "content": "Hi Karl,\n\nThis patch is a really good idea - many thanks for coming up with this!\nI've tried applying this on trunk, but I get a few compile errors from the patch, and I'm not quite sure how to use it in a query.\n\nThe compile errors have to do with:\nSearchHandler.java (~line 267):\n    ResponseBuilder rb = new ResponseBuilder();\nResponseBuilder doesn't have a no-arg ctor\n\nResponseBuilder.java (~line 141): (copyFrom())\n    debug = rb.debug;\nThere is no 'debug' parameter.\n\nI've fixed these up locally, but as I've only just looked at this, I thought I'd run it by you before patching it up.\nThere's also an NPE thrown if debugQuery=true (@DebugComponent.java:56)\n\nI haven't been able to build a query that seems to work..\nDo you have any example query urls you use for testing?\n   http://127.0.0.1:9000/solr/select?qt=multiquery&blah&blah etc...\n\nMany thanks!\nPeter\n "
        },
        {
            "author": "Karl Wright",
            "id": "comment-13002719",
            "date": "2011-03-04T17:11:25+0000",
            "content": "Lots of stuff has changed in trunk since the patch was posted.  I think you'd have to debug it all over again, and attach a new patch, to bring it up to date.\n\nSince this basically should work the same for a single query as does the current trunk, the first round of testing is just making sure everything still works as before.  If you then change solrconfig.xml to specify multiple query processing chains, then obviously you need code that can work with that.  I tested it with proprietary Nokia code, so I can't exactly include that.  "
        },
        {
            "author": "Steve Rowe",
            "id": "comment-13717269",
            "date": "2013-07-23T18:47:41+0000",
            "content": "Bulk move 4.4 issues to 4.5 and 5.0 "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-13971272",
            "date": "2014-04-16T12:57:37+0000",
            "content": "Move issue to Solr 4.9. "
        },
        {
            "author": "Alexandre Rafalovitch",
            "id": "comment-15566643",
            "date": "2016-10-11T21:19:08+0000",
            "content": "In Solr 6.x, we have subquery document transformer, as well multiple request processing using streams.\n\nI believe this invalidates enough of this issue, that it does not make sense to keep it open. If there are still some missing edge-cases, a new issue would make more sense. "
        }
    ]
}