{
    "id": "SOLR-6273",
    "title": "Cross Data Center Replication",
    "details": {
        "affect_versions": "None",
        "status": "Resolved",
        "fix_versions": [
            "6.0"
        ],
        "components": [],
        "type": "New Feature",
        "priority": "Major",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "This is the master issue for Cross Data Center Replication (CDCR)\ndescribed at a high level here: http://yonik.com/solr-cross-data-center-replication/",
    "attachments": {
        "SOLR-6273-plus-8263-5x.patch": "https://issues.apache.org/jira/secure/attachment/12775961/SOLR-6273-plus-8263-5x.patch",
        "SOLR-6273-trunk-testfix7.patch": "https://issues.apache.org/jira/secure/attachment/12771105/SOLR-6273-trunk-testfix7.patch",
        "SOLR-6273-trunk-testfix3.patch": "https://issues.apache.org/jira/secure/attachment/12745835/SOLR-6273-trunk-testfix3.patch",
        "SOLR-6273-5x-rollup.patch": "https://issues.apache.org/jira/secure/attachment/12774655/SOLR-6273-5x-rollup.patch",
        "SOLR-6273-trunk-testfix2.patch": "https://issues.apache.org/jira/secure/attachment/12737268/SOLR-6273-trunk-testfix2.patch",
        "SOLR-6273-trunk-testfix6.patch": "https://issues.apache.org/jira/secure/attachment/12770112/SOLR-6273-trunk-testfix6.patch",
        "SOLR-6273.patch": "https://issues.apache.org/jira/secure/attachment/12685336/SOLR-6273.patch",
        "forShalin.patch": "https://issues.apache.org/jira/secure/attachment/12768116/forShalin.patch",
        "SOLR-6273-trunk.patch": "https://issues.apache.org/jira/secure/attachment/12731826/SOLR-6273-trunk.patch",
        "SOLR-6273-trunk-testfix1.patch": "https://issues.apache.org/jira/secure/attachment/12735360/SOLR-6273-trunk-testfix1.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Arcadius Ahouansou",
            "id": "comment-14076189",
            "date": "2014-07-28T12:44:37+0000",
            "content": "Thanks Yonik Seeley for the detailed blog entry.\nThis issue looks very similar to SOLR-6205 "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-14076230",
            "date": "2014-07-28T13:47:49+0000",
            "content": "This issue looks very similar to SOLR-6205\n\nNot really... other than they both have \"Data Center\" in the title.\nSOLR-6205 looks like it is about location awareness (rack, zone, DC, etc)  and is a good thing to have independent of this issue. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-14117542",
            "date": "2014-09-01T16:42:56+0000",
            "content": "Note: some of us will be collaborating on a github branch here:\nhttps://github.com/Heliosearch/lucene-solr/tree/solr6273\n\nLet me know (privately to keep down noise) if you want to help out and want write access to that repo. "
        },
        {
            "author": "Renaud Delbru",
            "id": "comment-14235662",
            "date": "2014-12-05T15:57:56+0000",
            "content": "The initial patch for cdcr for trunk. It contains a working version of the cross data center replication for active-passive scenarios. The CdcrRequestHandler provides an API to control and monitor the replication. A documentation on how to configure cdcr and of the API can be found here.\nThis patch includes the following patches: SOLR-6621, SOLR-6819, SOLR-6823, and a few minor modifications on the UpdateLog and TransactionLog classes. Other than that, the rest of the CDCR code simply extends the Solr Core code. "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-14236719",
            "date": "2014-12-06T10:23:31+0000",
            "content": "This is a very important feature. Thanks for all your work! I intend to start reviewing this in detail next week. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-14239416",
            "date": "2014-12-09T14:03:35+0000",
            "content": "Renaud Delbru, this looks awesome! I've had a chance to review the patch and do a fair amount of manual testing. So far, during manual testing CDCR is working as designed. The unit tests look strong.  \n\nShalin Shekhar Mangar, looking forward to hearing your thoughts on the patch when you've had a chance to review. \n\nI'd be happy to move this forward towards committal unless another committer would like this assignment.\n\nI think it makes sense to commit this to trunk and then spend some time refining this before backporting to 5x. \n\nI see two things we'll need to tackle before committing to trunk:\n\n1) The CdcReplicationDistributedZkTest takes about 7 minutes to run on my computer. We'll need to come up with a strategy for shortening this for normal test runs. If anyone knows any tricks to make this test run faster please chime in. If we can't make it run faster we can move parts of the test to @nightly.\n\n2) We need to make sure that the default CDCR startup state for trunk doesn't cause any issues. I'll do some manual testing and see if I see any issues here.\n\n\n\n "
        },
        {
            "author": "Greg Solovyev",
            "id": "comment-14366070",
            "date": "2015-03-17T20:57:38+0000",
            "content": "I am working on applying this patch to test cross datacenter replication. Unless I am misunderstanding the code, this patch assumes that replication for each collection is configured in solrconfig.xml. I.e without this section in a collection's solrconfig.xml file the collection won't get replicated:\n<lst name=\"replica\">\n      <str name=\"zkHost\">${zkHost}</str>\n      <str name=\"source\">source_collection</str>\n      <str name=\"target\">target_collection</str>\n    </lst>\n\nThis means that CDCR won't work for collections created via collections API using a shared configset, because when collections are created via collections API with a configset, all collections will have identical solrconfig.xml and so there is no way to overwrite source and target parameters for each collection. "
        },
        {
            "author": "Greg Solovyev",
            "id": "comment-14376677",
            "date": "2015-03-23T21:25:34+0000",
            "content": "This patch expands the previously added patch to add the following features:\n\n\tif source_collection is not defined - use the collection name associated with the Core\n\tif target_collection is not defined - use the same name as source_collection\n\tif target collection does not exist on the target cloud - provision it with the same parameters as the source collection\n\n "
        },
        {
            "author": "Greg Solovyev",
            "id": "comment-14376686",
            "date": "2015-03-23T21:30:10+0000",
            "content": "P.S. last patch is made off of 4.10.2 tag "
        },
        {
            "author": "Renaud Delbru",
            "id": "comment-14496047",
            "date": "2015-04-15T11:04:15+0000",
            "content": "A new version of the patch. The patch has been created from the latest branch_5x. The full Solr test suite has been executed successfully (there were a few timeouts in some of the tests, but this seems irrelevant to this patch). The principal change in this new version includes a fix for the replication of tlog files. The ReplicationHandler and IndexFetcher have been modifed to replicate tlog files during a recovery (only if CDCR is activated). Some unit tests covering various scenarios can be found\nin core/src/test/org/apache/solr/cloud/CdcrReplicationHandlerTest.java.\nIn addition of the suite of automated unit tests, this version has been tested in various real deployments. One client has extensively tested the robustness and performance of CDCR in pre-prod, and is satisfied with the results. \n\nWe think that the code is in a relatively good state to be pushed to Solr. How can we move forward from here ? "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-14496394",
            "date": "2015-04-15T15:39:20+0000",
            "content": "Renaud:\n\nWhich of the sub-tasks are still open? Should we create a different JIRA for \"CDCR enhancements\" or some such and deal with the sub-tasks there? Mostly I'm thinking about how to close this JIRA at checkin if/when.\n\nAll:\n\nThis is a major patch that adds much-needed functionality to Solr, something that we haven't had a really good answer for in the past. But it's...er...big. After we get consensus, I expect we'd want to check this into trunk and let it bake for a while (how long?) before merging into 5x.\n\nI think we really need some eyes on this.... "
        },
        {
            "author": "Greg Solovyev",
            "id": "comment-14496652",
            "date": "2015-04-15T18:28:47+0000",
            "content": "Frankly, we would not be able to use this feature without auto-provisioning of collections (the feature that I added in my version of the patch). I cannot tell from the subtasks if this feature part of any of them.  "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-14497009",
            "date": "2015-04-15T21:10:59+0000",
            "content": "Great stuff, can we get this into trunk as experimental/beta for wider exposure to the real world, before stabilizing the APIs?\n\nI notice that slice is being used instead of shard in the patch. I thought we decided to use shard in all user facing APIs and docs? "
        },
        {
            "author": "Renaud Delbru",
            "id": "comment-14507324",
            "date": "2015-04-22T16:10:46+0000",
            "content": "Hi,\n\nErick Erickson: From the original subtasks, the ones that are not covered with this patch are: SOLR-6465 and SOLR-6466.\n\nGreg Solovyev: The current patch does not cover the auto-provisioning of collections / live configuration of peer clusters. I think this issue should be tackled as part of SOLR-6466.\n\nJan H\u00f8ydahl: Could you point to where slice is being used instead of shard ? This should not be a problem to change that. "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-14508592",
            "date": "2015-04-23T07:29:03+0000",
            "content": "Jan H\u00f8ydahl: Could you point to where slice is being used instead of shard ? This should not be a problem to change that.\n\ncurl -s \"https://issues.apache.org/jira/secure/attachment/12725545/SOLR-6273.patch\" |grep -n slice\n\n "
        },
        {
            "author": "Renaud Delbru",
            "id": "comment-14513880",
            "date": "2015-04-27T10:33:47+0000",
            "content": "Here is a new patch with the following changes:\n\n\n\tRenamed 'slice' into 'shard'\n\n\n\n\n\tRemoved an optimisation in the replication of tlog files which could lead to duplicate tlog entries on a slave node. We were trying to avoid transferring tlog files that were already present on the slave nodes in order to reduce network transfer. However, tlog files between the master and slave can differ, overlap, etc. making the comparison difficult to achieve. We removed this optimisation and now during a recovery the tlog replication will transfer all the tlog files from the master to the slave, and replace on the slave node all the existing tlog files.\n\n "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-14514791",
            "date": "2015-04-27T19:33:09+0000",
            "content": "What do people think about letting this bake in trunk for a while? If there are no objections I'll probably commit this to trunk in the next few days. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-14535430",
            "date": "2015-05-08T20:25:57+0000",
            "content": "OK, there have been no objections to this, so I'm going to commit it to trunk, let it bake for a little while then merge into 5.2. Probably get this done tonight or tomorrow. "
        },
        {
            "author": "Arcadius Ahouansou",
            "id": "comment-14535654",
            "date": "2015-05-08T21:49:12+0000",
            "content": "Note that this is just a question, not an objection.\n\nThe design blog talks only about 2 DCs being required.\n\nLets suppose that the DC1 and DC2 are both operational and updates being send to both of them.\nIf suddenly, the pipe between the two get broken for a couple of hours while updates still going into individual DC.\nWhen the link is re-established, updates/replications from TransactionLog will fly from both DCs i.e DC1->DC2 and DC2->DC1\n\n\n\n\n\tHow do we guaranty the order of execution of updates from TL? ... i.e when the link was broken, there have been deletion of doc#1 in DC1 followed by add/update of same doc#1 in DC2\n\n\n\n\n\tIn case DC1 lags far behind the other, full index replication (a la master-slave) may happen, meaning all updates done on DC1 will be overwritten by data from DC2 leading to data loss?\n\n\n\n\n\tWould a 3rd DC help make the system more redundant?\n\n "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-14537396",
            "date": "2015-05-10T22:18:11+0000",
            "content": "Here's a patch that applies against trunk, so far it passes precommit but I  haven't yet run the full test suite, won't have a chance until tonight.\n\nDifferences from original patch:\n\n\n\tThe \"usual\" reconciliation issues, a few minor incompatibilities with code that's changed in trunk.\n\n\n\n\n\tCloudSolrServer <- CloudSolrClient (etc).\n\n\n\n\n\tFixed forbidden APIs that failed precommit\n\n\n\n\n\tSome files were prefixed by Cdc, others by Cdcr so I made them all Cdcr for consistency's sake.\n\n\n\n\n\tformatted everything that'd changed. NOTE: I tried the nifty \"only vcs changed\" option in IntelliJ and it seemed to work fine. If anyone sees gratuitous formatting changes, let me know. By far the majority of the code is new though.\n\n\n\nAssuming the tests run OK, I intend to commit this later this evening or perhaps tomorrow evening unless there are objections. I'll commit this to trunk, let it bake for a while then merge back into 5x. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-14537512",
            "date": "2015-05-11T03:16:28+0000",
            "content": "Renaud Delbru Things are looking pretty good. The only thing that isn't working when I run \"ant test\" on trunk is it complains that AbstractCdcrDistributedZkTest should be a concrete class since it contains the @Test annotation. Should \npublic void testDistribSearch()\n\njust have the @Test removed? (It's late or I'd look some more).\n\nIf it's just that simple, let me know and I'll fix it up in the trunk patch and it'll be merged into 5x along with the rest of my changes.\n\nThanks!\nErick "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-14538573",
            "date": "2015-05-11T20:14:48+0000",
            "content": "Removing the @Test in this case seems to be fine.\n\nGot through nightly OK.\n\nSpeaking of which, these are pretty long tests. Should they be annotated with @Nightly? What do people think? Or perhaps left the way they are for baking then made Nightly later? "
        },
        {
            "author": "Jakub Kotowski",
            "id": "comment-14538611",
            "date": "2015-05-11T20:36:14+0000",
            "content": "Renaud is travelling this week so he might not be able to respond. I think that removing @Tests is ok. Even though, Renaud had to dig deep in the test framework to make things work so better that he confirms later when he's back. Can't comment about @Nightly as I don't know your process. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-14542953",
            "date": "2015-05-14T00:04:48+0000",
            "content": "Arcadius Ahouansou Sorry it took a while to get back to you, but currently CDCR is active-passive, not active-active so the scenario you asked about shouldn't arise. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-14552748",
            "date": "2015-05-20T17:46:46+0000",
            "content": "Updated trunk patch (the original patch was against 4x). In addition to the last trunk patch I uploaded on 10-May, this one tries to resolve the test issues. You'll see some //nocommit and //EOE comments so it won't pass precommit. These are just markers to allow others to review the test changes, I'll remove them before committing as well as add a new CHANGES.txt entry.\n\nFortunately, the original patch against 4x was mostly new code so there were very few places that needed to be reconciled. "
        },
        {
            "author": "Renaud Delbru",
            "id": "comment-14554099",
            "date": "2015-05-21T10:49:59+0000",
            "content": "Erick Erickson I have checked the new patch on the latest trunk. The unit tests seem to properly run with the latest changes. Thanks for porting this to trunk. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-14554391",
            "date": "2015-05-21T14:58:29+0000",
            "content": "Renaud Delbru Thanks for looking it over. OK, I'll clean up the nocommits etc and check it in probably tomorrow. "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14556624",
            "date": "2015-05-22T18:58:30+0000",
            "content": "Commit 1681186 from Erick Erickson in branch 'dev/trunk'\n[ https://svn.apache.org/r1681186 ]\n\nSOLR-6273: Cross Data Center Replication "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-14556630",
            "date": "2015-05-22T19:01:34+0000",
            "content": "I'm going to let this bake on trunk for a week or so, then merge into 5.3.\n\nthanks Renaud, Yonik et.al.! "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-14557413",
            "date": "2015-05-23T16:10:39+0000",
            "content": "Rats, coffee hasn't kicked in yet. Mis-typed the JIRA, here's what the comment should have been on the latest commit:\n\n\"SOLR-6273: Cross Data Center Replication disabling noisy tests until we figure it out\"\n\nRevision is: [ https://svn.apache.org/r1681361 ] "
        },
        {
            "author": "Renaud Delbru",
            "id": "comment-14559431",
            "date": "2015-05-26T17:20:29+0000",
            "content": "Erick Erickson, I was able to reproduce the issues from the failed jinkins build. After replicating the tlog files, the update log of the slave is not properly \"re-initialised\", and it still contains references to the previous tlog files. I have attached a fix for this. "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14559780",
            "date": "2015-05-26T20:15:25+0000",
            "content": "Commit 1681839 from Erick Erickson in branch 'dev/trunk'\n[ https://svn.apache.org/r1681839 ]\n\nSOLR-6273: Cross Data Center Replication: Fix at least one test, un-Ignore tests "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-14559792",
            "date": "2015-05-26T20:21:30+0000",
            "content": "Apologies in advance if re-enabling all the tests generates noise. I couldn't get a failure on my box in 150 tries or so, so I'll have to pull logs from Jenkins if/when additional issues spring up.\n "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14560186",
            "date": "2015-05-27T00:10:20+0000",
            "content": "Commit 1681893 from Erick Erickson in branch 'dev/trunk'\n[ https://svn.apache.org/r1681893 ]\n\nSOLR-6273: re-ignoring failed tests "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14560392",
            "date": "2015-05-27T04:36:51+0000",
            "content": "Commit 1681904 from Erick Erickson in branch 'dev/trunk'\n[ https://svn.apache.org/r1681904 ]\n\nSOLR-6273: disable more failing tests now that we have logs "
        },
        {
            "author": "Renaud Delbru",
            "id": "comment-14570834",
            "date": "2015-06-03T13:43:31+0000",
            "content": "Erick Erickson, I have attached a new patch regarding the unit test failures from the jenkins job. It is likely that the errors we saw are due to the jenkins server being under heavy load and therefore less responsive, which might trigger race condition issues in the assertions of the unit tests.\nI have added various safeguard methods to the unit test framework, so that the it will wait for the completion of particular tasks (cdcr state replication, update log cleaning, etc.) and fail after a given timeout (15s). "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-14570978",
            "date": "2015-06-03T15:10:57+0000",
            "content": "Renaud:\n\nCool! Yeah, the test cases for this kind of thing are tricky for sure. I'll give it a spin a bit later today and we'll see what Jenkins thinks. "
        },
        {
            "author": "Martin Grotzke",
            "id": "comment-14612476",
            "date": "2015-07-02T20:32:24+0000",
            "content": "Hi all, we're currently evaluating how to expand our current single DC solrcloud to multi (2) DCs. This effort here looks very promising, great work!\nAssuming we'd test how it works for us, could we follow the documentation mentioned above (https://docs.google.com/document/d/1DZHUFM3z9OX171DeGjcLTRI9uULM-NB1KsCSpVL3Zy0/edit?usp=sharing)? Does it match the current implementation? Do you have any other suggestions for us if we'd test this? Thanks!  "
        },
        {
            "author": "Renaud Delbru",
            "id": "comment-14613124",
            "date": "2015-07-03T11:08:16+0000",
            "content": "Hi Martin,\n\nThe google doc is up to date with the current implementation. One suggestion is for tuning the performance of the replication. The performance of the replication depends on the \"Replicator Parameters\". In your scenario, the two main parameters will be \"schedule\" and \"batchSize\". If you would like to see a very small latency between replication batches, you can decrease the \"schedule\" parameter from 1000ms to 1ms. To improve the network IO, you can also try to increase the \"batchSize\" parameter to a larger number (if your documents are a few kbs or less, you can try to increase it to 500, 1000 or more). \n\nTo measure the impact that the parameters have on the replication performance, you can use the monitoring api, e.g., ?action=QUEUES, to retrieve some stats about the replication queue. The queue size will tell you how much your replica lags behind the source cluster. If the replication is not fast enough, you'll see the queue size increasing. The idea is to try to tune the schedule and batchSize parameters until you find the optimal values for your collection and setup, and see this queue being relatively stable and small. "
        },
        {
            "author": "Martin Grotzke",
            "id": "comment-14613472",
            "date": "2015-07-03T21:59:42+0000",
            "content": "Great, thanks for the advice, Renaud!  "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-14631545",
            "date": "2015-07-17T16:33:26+0000",
            "content": "All tests pass consistently for me now, I'll be committing this shortly for more baking. "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14631552",
            "date": "2015-07-17T16:38:14+0000",
            "content": "Commit 1691606 from Erick Erickson in branch 'dev/trunk'\n[ https://svn.apache.org/r1691606 ]\n\nSOLR-6273: Cross Data Center Replication. All tests are now passing on my machine, let's see if Jenkins flushes anything out "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-14631555",
            "date": "2015-07-17T16:39:36+0000",
            "content": "Note: These tests take a long time to run. I'm thinking about changing the annotation to \"Nightly\" after it bakes for a bit, I'll assign a JIRA to myself to track. "
        },
        {
            "author": "Steve Rowe",
            "id": "comment-14631768",
            "date": "2015-07-17T19:17:59+0000",
            "content": "Erick Erickson, I got a CdcrReplicationDistributedZkTest failure on my Jenkins: http://jenkins.sarowe.net/job/Lucene-Solr-tests-trunk/806/\n\n\nStack Trace:\njava.lang.AssertionError\n\tat __randomizedtesting.SeedInfo.seed([679B796D4028309D:6FFB0C414F261896]:0)\n\tat org.junit.Assert.fail(Assert.java:92)\n\tat org.junit.Assert.assertTrue(Assert.java:43)\n\tat org.junit.Assert.assertTrue(Assert.java:54)\n\tat org.apache.solr.cloud.CdcrReplicationDistributedZkTest.doTestTargetCollectionNotAvailable(CdcrReplicationDistributedZkTest.java:138)\n\tat org.apache.solr.cloud.CdcrReplicationDistributedZkTest.doTests(CdcrReplicationDistributedZkTest.java:46)\n[...]\n\n "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-14632085",
            "date": "2015-07-17T23:08:02+0000",
            "content": "Steve Rowe Got it, thanks! I knew it was too good to be true. "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14650612",
            "date": "2015-08-02T05:26:26+0000",
            "content": "Commit 1693786 from shalin@apache.org in branch 'dev/trunk'\n[ https://svn.apache.org/r1693786 ]\n\nSOLR-6273: Reset test hooks in a finally block to avoid leakage to other tests "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-14661623",
            "date": "2015-08-07T10:48:26+0000",
            "content": "Before we release 5.3, we should move this issue out of the 5.3 section and move it to 6.0.0 until it is backported. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-14661968",
            "date": "2015-08-07T15:13:16+0000",
            "content": "It's not in the CHANGES.txt file for 5.x at all (just checked, but I can always miss things), just in trunk so maybe this isn't a problem? I'll move it to the proper place before I merge it back to 5x.\n\nOr am I missing the point? "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-14661978",
            "date": "2015-08-07T15:20:10+0000",
            "content": "Oh, I am sorry. This issue is mentioned under 5.3.0 on trunk which got me confused. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-14661980",
            "date": "2015-08-07T15:22:46+0000",
            "content": "NP, I'm happy to have as many eyes catching stuff I miss as possible! "
        },
        {
            "author": "Ramkumar Aiyengar",
            "id": "comment-14663130",
            "date": "2015-08-08T19:14:28+0000",
            "content": "Erick Erickson, any plans to move this to branch_5x soon? I am aware that this needs to be bedded in a bit, so no big deal either way, but if you follow my merge for SOLR-7859, you might have to merge in a change to CdcrReplicatorState to avoid failing on forbidden-apis/precommit. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-14663213",
            "date": "2015-08-09T00:41:54+0000",
            "content": "Ramkumar Aiyengar Real Soon Now. Which is what I've been thinking for a month or more. I have another version that might make the test behave itself better that I'm going to try to get to today or tomorrow.  But I'll just have to deal with the merging issues if and when. Except I'll be merging in the current trunk before then so probably pick those changes up as I go.\n\nThanks for the heads-up, but don't delay your stuff at all this may (continue to) take a while. "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-14963616",
            "date": "2015-10-19T17:03:45+0000",
            "content": "I've been playing with this feature for a couple of days and I have a few thoughts to improve this before we merge it into branch_5x.\n\n\n\tI think the configuration should be moved out of solrconfig.xml \u2013 the source collection name is redundant (it is always the one to which the core belongs) and it is the wrong place to configure peer cluster details. Perhaps the peer cluster details should be in cluster properties and the target collection should live as a collection level property. All this should be editable using our config APIs\n\tI feel it is too complex to have the user configure things like batch sizes and scheduler delays etc. Maybe a better way is to stream the transaction log in a single thread constantly and throttle to a configurable transfer rate. This will also reduce memory requirements by avoiding huge batches and possibly improve transfer speed as well. See point below.\n\tThe current CDCR code behaves poorly on bulk loads. I loaded a 600MB file containing 2.7M JSON documents into the source collection in 177 seconds but it took more than 6 hours to replicate them into the target collection using schedule=1ms and batch size = 64. We need to do better than that by default.\n\tRelated to the point above, the current CDCR code is not suitable for bootstrapping a new target cluster. We should look into a snapshot replication to speed up the bootstrap process (and maybe even the bulk loads)\n\tWe need better stats/reporting including transfer rate, latency etc\n\tEach core puts a watch on the current shard's leader node to figure out if it is the current leader and therefore whether it should start the cdcr threads. I think this is not necessary. A similar problem was faced by SOLR-6266 the couchbase indexer plugin (not committed yet). I think we should have a event handler API for cores to listen for important cluster state events such as leader changes or state changes and do away with individual plugins adding a listener on ZK nodes. A better solution may be to have collection level plugins that can be automatically elected, failed over etc but that is a lot of work so I'll defer that for now.\n\n\n\nThoughts? "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-14964020",
            "date": "2015-10-19T20:42:58+0000",
            "content": "thanks for looking! Currently I'm soooo far behind trying to figure out what is with the test framework (I suspect that framework is failing, we've hit some kind of edge case or something) that the notion of next steps is kind of off my radar but we'll certainly look at improvements once the test issues are worked out.\n "
        },
        {
            "author": "Anshum Gupta",
            "id": "comment-14964328",
            "date": "2015-10-20T00:47:37+0000",
            "content": "Erick Erickson: Should we just move the entry for this from the 5.3 section and into the 6.0 section (even on trunk)? It's kind of confusing as it wasn't released with 5.3. "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14965204",
            "date": "2015-10-20T14:46:40+0000",
            "content": "Commit 1709619 from shalin@apache.org in branch 'dev/trunk'\n[ https://svn.apache.org/r1709619 ]\n\nSOLR-6273: Fixed a null check, some typos and a few compiler warnings "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14966804",
            "date": "2015-10-21T13:27:09+0000",
            "content": "Commit 1709829 from shalin@apache.org in branch 'dev/trunk'\n[ https://svn.apache.org/r1709829 ]\n\nSOLR-6273: Moved entry in change log from Solr 5.3.0 to 6.0 "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-14967391",
            "date": "2015-10-21T16:25:09+0000",
            "content": "Can some one explain at what point is the tlog replication used?\n\nRenaud Delbru or Yonik Seeley "
        },
        {
            "author": "Renaud Delbru",
            "id": "comment-14968970",
            "date": "2015-10-22T11:15:08+0000",
            "content": "Shalin Shekhar Mangar thanks for looking into this.\n\nRegarding performance (2 and 3), it is true that the right batch size and scheduler delay is very important for optimal performance. With the proper batch sizes and scheduler delays, we have seen very low update latency between the source and target clusters. In your setup, one document was approximately 0.2kb in size, therefore the batch size was ~14kb which should correspond to ~14mb/s of transfer rate. With such a transfer rate, the replication should have been done in a few seconds / minutes, not hours. Could you give more information about your setup / benchmark ? Were replication turned off while you were indexing on the source, or you turned it on after ?\n\nIn term of moving from a batch model to to a pure streaming one, this might probably simplify the configuration on the user size, but in term of performance, I am not sure - maybe some other people can give their opinion here. Batch size might not use that much memory (if properly configured), and transfer speed also (if the batch size is properly configured too). One way to simplify also the configuration for the user is, like you proposed, having a configurable transfer rate but with some logic to automatically adjust the batch size and scheduler delay based on the configurable transfer rate ?\n\nAbout 5, I think transfer rate is a good addition. Latency could be computed as the QUEUES monitoring action is returning the last document timestamp. "
        },
        {
            "author": "Renaud Delbru",
            "id": "comment-14968987",
            "date": "2015-10-22T11:27:37+0000",
            "content": "The tlog replication is only relevant to the source cluster, as it ensures that tlogs are replicated between a master and slaves in case of a recovery (with a snappull). If not, then there are some scenarios where a slave can end up with an incomplete update log, and if it becomes the master, then we will miss some updates and the target cluster becomes inconsistent wrt the source cluster. "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-14968998",
            "date": "2015-10-22T11:44:34+0000",
            "content": "Sorry, you are right. I wasn't using the 1ms delay \u2013 I had uploaded the new config but forgot to reload the source collection so it was using 1000ms as the schedule which explains the slowness.\n\nIn term of moving from a batch model to to a pure streaming one, this might probably simplify the configuration on the user size, but in term of performance, I am not sure...\n\nYeah, I now see that it probably won't affect performance much. But I would still prefer streaming because that the batch size and schedule is really achieving the same thing i.e. streaming. Furthermore, as you said, schedule and batchSize are two more things for the user to configure whereas setting a transfer rate is much easier for the user.\n "
        },
        {
            "author": "Renaud Delbru",
            "id": "comment-14969006",
            "date": "2015-10-22T11:56:42+0000",
            "content": "Yes, I think we should probably change the default value of the scheduler to 1ms unless we change the model to a streaming one. 1000ms is way too high as default value. "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-14969010",
            "date": "2015-10-22T12:02:50+0000",
            "content": "The tlog replication is only relevant to the source cluster, as it ensures that tlogs are replicated between a master and slaves in case of a recovery (with a snappull)\n\nAh, I see, thanks for explaining. Am I correct in assuming that since the current tlog is not in the logs deque therefore this does not interfere with the replaying of buffered updates? "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-14969015",
            "date": "2015-10-22T12:07:24+0000",
            "content": "Any idea why this might happen? Looks like the state is null. This started happening after I reloaded the source collection and re-indexed the JSON documents.\n\n\n339784408 ERROR (cdcr-replicator-41-thread-155-processing-n:127.0.1.1:8001_solr x:cdcr_source_shard1_replica1 s:shard1 c:cdcr_source r:core_node1) [c:cdcr_source s:shard1 r:core_node1 x:cdcr_source_shard1_replica1] o.a.s.c.u.ExecutorUtil Uncaught exception java.lang.NullPointerException thrown by thread: cdcr-replicator-41-thread-155-processing-n:127.0.1.1:8001_solr x:cdcr_source_shard1_replica1 s:shard1 c:cdcr_source r:core_node1\njava.lang.Exception: Submitter stack trace\n\tat org.apache.solr.common.util.ExecutorUtil$MDCAwareThreadPoolExecutor.execute(ExecutorUtil.java:204)\n\tat org.apache.solr.handler.CdcrReplicatorScheduler$1.run(CdcrReplicatorScheduler.java:80)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\nException in thread \"cdcr-replicator-41-thread-155\" java.lang.NullPointerException\n\tat java.util.concurrent.ConcurrentLinkedQueue.checkNotNull(ConcurrentLinkedQueue.java:914)\n\tat java.util.concurrent.ConcurrentLinkedQueue.offer(ConcurrentLinkedQueue.java:327)\n\tat org.apache.solr.handler.CdcrReplicatorScheduler$1$1.run(CdcrReplicatorScheduler.java:89)\n\tat org.apache.solr.common.util.ExecutorUtil$MDCAwareThreadPoolExecutor$1.run(ExecutorUtil.java:231)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n\n "
        },
        {
            "author": "Renaud Delbru",
            "id": "comment-14969182",
            "date": "2015-10-22T13:52:57+0000",
            "content": "That's a good point, and I think the current implementation might interfere with the replay of the buffered updates. The current tlog replication works as follow:\n1) Fetch the the tlog files from the master\n2) reset the update log before switching the tlog directory\n3) switch the tlog directory and re-initialise the update log with the new directory.\nCurrently there is no logic to keep \"buffered updates\" while resetting and reinitializing the update log. It looks like the tlog replication still needs some work. "
        },
        {
            "author": "Renaud Delbru",
            "id": "comment-14969188",
            "date": "2015-10-22T13:55:52+0000",
            "content": "First time I saw this issue.\nHow did you perform the reload ? Have you deleted it the source collection before the reload, or just reload and overwrite the existing documents ? "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-14969218",
            "date": "2015-10-22T14:19:41+0000",
            "content": "I used the collection reload API and then added new documents. Since my json documents do not have an 'id' field and I am using data driven schema, there is no overwriting and the same docs are added again with a new unique key. "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-14969223",
            "date": "2015-10-22T14:22:52+0000",
            "content": "In that case, this can easily lead to lost updates. We should add a test which does constant indexing and triggers a recovery in a replica and asserts that all replicas are consistent at steady state.  "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-14969445",
            "date": "2015-10-22T16:55:25+0000",
            "content": "Shalin Shekhar Mangar Renaud and I have been trying to figure out what in the test framework seems to be giving us trouble getting the existing tests to pass. We've (well, mostly Renaud) have reworked some of the tests but still having problems. I have several changes on my local machine that help isolate the problems, but don't fix it. But some recent changes have caused a 100% failure case so I'm not going to commit anything. If you (or anyone else) want to play with the changes I can attach a patch that applies to trunk.\n\nWe're getting an NPE that wasn't there before and I won't have time until this weekend at best to look any more deeply.\n\nLet me know if you'd like to see the current patch, I've been waiting until I could get some better idea of what it is in the current tests that's wonky before checking anything in. "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-14969683",
            "date": "2015-10-22T19:06:32+0000",
            "content": "Hi Erick Erickson, please post the patch and I can take a look. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-14969724",
            "date": "2015-10-22T19:25:08+0000",
            "content": "Shalin Shekhar Mangar Attached a patch for you that should apply cleanly to trunk. It rolls up all the intermediate changes we've made AND has some special logging in IndexFetcher to show which of the chained calls generates the null pointer exception, and it's:\nsolrcore.getUpdateHandler().getUpdateLog() that's generating the exception\n\nJust look for the initials EOE line 290 or so. Obviously that shouldn't be committed \n\nApplying this patch to trunk should be used as a  base for ongoing work, I've been meaning to commit it for a while but haven't gotten to the bottom of the test failures we were having before the null pointer issue cropped up. I'll be happy to coordinate that whenever. "
        },
        {
            "author": "Renaud Delbru",
            "id": "comment-14985508",
            "date": "2015-11-02T16:44:19+0000",
            "content": "Erick Erickson Find attached your patch with some fixes.\nThe cause of the NPE was that some replication handler tests were not running in cloud mode, and therefore the update log was null. I have added a simple fix for that issue. I have also fixed some merge issues with the latest trunk. The full Solr test suite was executed successfully.\n\nShalin Shekhar Mangar Regarding the potential issue with the transaction log replication, I will have a look this week. Should I open a sub-issue to track this separately ?  "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-14994357",
            "date": "2015-11-06T20:16:58+0000",
            "content": "OK, this patch fixes up a number of test issues. There still remains some zombie thread leaks. I tried extending the ThreadLeakLingering annotation just for a quick test but that didn't seem to cure the zombie problem. \n\nApart from the zombie issue, I haven't seen test failures for about 300 tests of CdcrReplicationDistributedZkTest, and both precommit and test succeed. I'll be beasting the other CDCR tests over the weekend, but as they take quite some time to run it'll be a slow process.\n\nI'm going to commit this as it's the current state of the art and we should base any additional changes on this code line... "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14994358",
            "date": "2015-11-06T20:18:20+0000",
            "content": "Commit 1713022 from Erick Erickson in branch 'dev/trunk'\n[ https://svn.apache.org/r1713022 ]\n\nSOLR-6273: testfix7, improves test pass ratio significantly "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14995525",
            "date": "2015-11-08T05:18:54+0000",
            "content": "Commit 1713207 from Erick Erickson in branch 'dev/trunk'\n[ https://svn.apache.org/r1713207 ]\n\nSOLR-6273: Took out inadvertent copyright comment "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-15002518",
            "date": "2015-11-12T17:43:01+0000",
            "content": "Commit 1714099 from Erick Erickson in branch 'dev/trunk'\n[ https://svn.apache.org/r1714099 ]\n\nSOLR-6273: Removed unused imports, no code changes "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-15030112",
            "date": "2015-11-27T17:55:40+0000",
            "content": "This patch rolls up all of the changes from trunk for application on the 5x code line for this JIRA. I'm adding it for a couple reasons:\n\n1> If we decide to fold this into 5.5, we should just be able to apply this and go rather than reconstruct all the commits.\n\n2> Applying this along with the patch for SOLR-8263 will be simple for anyone who wants this functionality on the Solr 5x code line. I recommend that this be applied against the 5.4.x line as that's closest to the code base used to generate this patch.\n\nWARNINGS!\n1> THIS IS SUPPLIED \"AS IS\". I've applied it to 5x very close to the time Solr 5.4 was cut. I've run over 100 runs of all the CDCR test suites, precommit and test on it. All this works just like trunk where we haven't seen Jenkins errors for quite a while. All that said, this is not officially supported on 5x and may never be, depending on when 6.0 is released.\n\n2> SOLR-8263 addresses a potential data loss issue and should be applied after this patch. There'll be a 5x version of SOLR-8263 soon. Like this JIRA, the code for SOLR-8263 will be applied to trunk but not 5x unless we decide to back-port this functionality to 5x. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-15030119",
            "date": "2015-11-27T18:01:07+0000",
            "content": "Closing this (finally!). SOLR-8263 needs to be fixed yet in order for us to tie a bow around CDCR, that's a separate issue.\n\nThis is NOT being back-ported to 5.x at this point. I've provided a 5x rollup patch in case we want to do that, but we'll decide that later. I'll create a blocker on 5.5 just as a marker for consciously resolving this question if there's going to be a 5.5. release. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-15043634",
            "date": "2015-12-06T01:41:00+0000",
            "content": "Need to attach combined 6273 and 8263 patch here too "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-15043635",
            "date": "2015-12-06T01:42:27+0000",
            "content": "This patch is for 5x if we ever want to put CDCR in a 5x release since both SOLR-6273 and SOLR-8263 should be committed. I'll put this patch on both JIRAs. The patch should just be applied to 5x, no merging from trunk is necessary there.\n\nNOTE: The 5x patch was a little tricky to generate as dis-allowing local loggers happened between times, but all that is incorporated here.\n\nMany kudos to Renaud for all this work "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-15043637",
            "date": "2015-12-06T01:42:53+0000",
            "content": "Attached 5x rollup patch for 6273 and 8263\n\nBTW, I've beasted the 4 CDCR test suites over 100 times each with this rollup patch against 5x so I'm pretty confident it's faithfully reflects the trunk code. "
        },
        {
            "author": "Dennis Gove",
            "id": "comment-15246258",
            "date": "2016-04-18T18:30:11+0000",
            "content": "Updated patch for 5x (specifically v5.5) which includes the changes in SOLR-8263. A small number of changes related to variable visibility have been made to the original patch.\n\nAlso, this patch was created with git whereas the original one appears to have been created with svn. I believe this is the cause of the file size difference (the new one is smaller). "
        },
        {
            "author": "Michael Griffith",
            "id": "comment-15274637",
            "date": "2016-05-06T19:50:01+0000",
            "content": "Is this CDCR compatible with 4.10.3 \u2013 is it already baked into the code base prior to 4.10.3?  Alfresco 5.1 is now out and it uses 4.10.3 as its solr base, but the alfresco project heavily modifies the code.  I'm try to figure out if this is something that can be used in our alfresco data centers without having to patch or change any code.\n\nthanks in advance,\n "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-15274674",
            "date": "2016-05-06T20:29:33+0000",
            "content": "First, it's better to raise this kind of question on the user's list, a closed JIRA will only get eyeballs on it by chance.\n\nGah, there was a kerfuffle with the labels for JIRAs and this one is labeled \"master\", which isn't very helpful. To answer though, this only current on 6.0+. There is a 5x patch that I put up \"just in case\" that's never been applied to the 5x code line. 4x is not going to happen. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-15274710",
            "date": "2016-05-06T20:48:09+0000",
            "content": "Alfresco's Solr implementation doesn't use SolrCloud, so CDCR is not going to work with Alfresco Solr.\n\nAlfresco's Solr implementation is eventually consistent though and should work across data centers, no CDCR needed.  "
        }
    ]
}