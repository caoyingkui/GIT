{
    "id": "SOLR-6246",
    "title": "Core fails to reload when AnalyzingInfixSuggester is used as a Suggester",
    "details": {
        "affect_versions": "4.8,                                            4.8.1,                                            4.9,                                            5.0,                                            5.1,                                            5.2,                                            5.3,                                            5.4",
        "status": "Closed",
        "fix_versions": [
            "6.4.1",
            "6.5",
            "7.0"
        ],
        "components": [
            "SearchComponents - other"
        ],
        "type": "Sub-task",
        "priority": "Major",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "LUCENE-5477 - added near-real-time suggest building to AnalyzingInfixSuggester. One of the changes that went in was a writer is persisted now to support real time updates via the add() and update() methods.\n\nWhen we call Solr's reload command, a new instance of AnalyzingInfixSuggester is created. When trying to create a new writer on the same Directory a lock cannot be obtained and Solr fails to reload the core.\n\nAlso when AnalyzingInfixLookupFactory throws a RuntimeException we should pass along the original message.\n\nI am not sure what should be the approach to fix it. Should we have a reloadHook where we close the writer?",
    "attachments": {
        "SOLR-6246.patch": "https://issues.apache.org/jira/secure/attachment/12662471/SOLR-6246.patch",
        "SOLR-6246-test.patch": "https://issues.apache.org/jira/secure/attachment/12662688/SOLR-6246-test.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Varun Thacker",
            "id": "comment-14100514",
            "date": "2014-08-18T10:22:13+0000",
            "content": "When we call Solr's reload command, a new instance of AnalyzingInfixSuggester is created. When trying to create a new writer on the same Directory a lock cannot be obtained and Solr fails to reload the core.\n\nSolrSuggester adds close hooks but that doesn't work in this case. The reason is that the close hooks gets called only after the new core gets created. CoreContainer.reload() first creates the new core ( which fails ) and only after it has registered the new core does it clean up the old core ( registerCore() )\n\nWe need to clean up the resources before the new core is created or use the same resources again if it hasn't changed. "
        },
        {
            "author": "Varun Thacker",
            "id": "comment-14100537",
            "date": "2014-08-18T11:02:57+0000",
            "content": "I experimented by adding a closeHook which gets called before the new SolrCore gets created. At least the core now reloads correctly.\n\nThis approach has one major disadvantage - There will be a short period where the suggester won't work since we close it before the new core has been registered.\n\nAny ideas as to how should we tackle this in a correct way?\n\n "
        },
        {
            "author": "Varun Thacker",
            "id": "comment-14101824",
            "date": "2014-08-19T04:22:07+0000",
            "content": "Simple test which fails because the core fails to load. "
        },
        {
            "author": "Varun Thacker",
            "id": "comment-14102435",
            "date": "2014-08-19T16:38:44+0000",
            "content": "Previous patch was incorrect. Forgot to add the solrconfig changes without which AnalyzingInfixSuggester would never get used in the test.\n\nThis is also reported by an user on the user list - http://lucene.472066.n3.nabble.com/BlendedInfixSuggester-index-write-lock-failures-on-core-reload-td4152984.html "
        },
        {
            "author": "Hoss Man",
            "id": "comment-14102604",
            "date": "2014-08-19T18:32:11+0000",
            "content": "SolrSuggester adds close hooks but that doesn't work in this case. The reason is that the close hooks gets called only after the new core gets created....\nI experimented by adding a closeHook which gets called before the new SolrCore gets created. At least the core now reloads correctly.\n\nHmm, yeah ... the lifecycle implications and general API changes involved in fixing this bug are definitely tricky ... i'm not eager to rush into adding a new method to CloseHook.  If we do add something, i think it might be better to consider a general \"ReloadHook\" that could inform components when a SolrCore is about to be reloaded, and then followup with the new SolrCore instance once it's created, maybe something like...\n\n\npublic abstract ReloadHook {\n  public abstract void preReload(SolrCore oldCore);\n  public abstract void postReload(SolrCore oldCore, SolrCore newCore);\n}\n\n\n\nThis approach has one major disadvantage - There will be a short period where the suggester won't work since we close it before the new core has been registered.\n\nOne way we might be able to mitigate that is by: a) changing the lock factory we use on the suggester Directory; 2) subclassing  AnalyzingInfixSuggester to be aware of the reloading taking place.  \n\nThe idea being that when AnalyzingInfixLookupFactory initially constructs the FSDirectory, it could explicitly configure something like the SingleInstanceLockFactory - that should allow 2 instances of AnalyzingInfixSuggester (in the same JVM) open it at the same time \u2013 but then, to prevent corruption risk if both Suggester instances try to write to that Directory, we need to subclass them and customize them to know when the \"reload\" is taking place, so the old one blocks itself from doing anymore writes.\n\nso suggestions would still be available while waiting for the new core to start, but not updates to the dictionary.\n\n\n\nThis is definitely hairy. "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-14295090",
            "date": "2015-01-28T12:18:39+0000",
            "content": "Hmm, this is annoying, what is the next step? "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-14309130",
            "date": "2015-02-06T13:53:03+0000",
            "content": "Could we perhaps do this in steps?\n\n\tFirst implement ReloadHook and accept that suggester is unavailable during reload\n\tThen handle fancy locking stuff in another issue?\n\n "
        },
        {
            "author": "Varun Thacker",
            "id": "comment-14385893",
            "date": "2015-03-29T19:01:20+0000",
            "content": "I was testing out the AnalyzingInfixSuggester on trunk and noticed that with <str name=\"buildOnStartup\">false</str> ( which is the default ) this problem does not happen. Only when we turned to true does a reload fail.\n\nSo starting Solr 5.1 setting <str name=\"buildOnStartup\">false</str> should be the workaround till we fix this problem\n\nEDIT: I was wrong. The problem still exists. Sorry for the noise. "
        },
        {
            "author": "Stephan Lagraulet",
            "id": "comment-14585858",
            "date": "2015-06-15T12:38:09+0000",
            "content": "Hoss Man How would you add this ReloadHook? I was thinking of adding methods to SolrCoreAware but there's a significant impact as many classes uses this interface... "
        },
        {
            "author": "Hoss Man",
            "id": "comment-14587034",
            "date": "2015-06-15T22:27:40+0000",
            "content": "the crux of my suggestion was that we should NOT add any new methods to any existing interface/abstraction, instead we could add an entirely new ReloadHook API, and let classes pass instances of that API to Solr just like they can currently pass instances of CloseHook.\n\nit was a largely off the cuff suggestion, that i haven't really given any thought to since ... i have no idea if there is a better approach.\n\nJan: if you think it's a good idea, then by all means go for it piecemeal ... i honestly have no idea how serious the downsides would be during the interim between adding a ReloadHook that the Suggester could use in one version of solr and resolving the locking issues in a later version (corrupt suggestions index after reload? errors when trying to add docs during reload? complete failure to reload?) ... those ramifications seem like they should make the difference in deciding wether the changes can be made incrementally. "
        },
        {
            "author": "David Smiley",
            "id": "comment-14611480",
            "date": "2015-07-02T05:03:50+0000",
            "content": "I admit I haven't looked at the patch or underlying code, but perhaps no new API is needed to solve this.  Perhaps suggesters that write to Lucene directories could (somehow) be configured to only use a lock file when it needs to build the index?  If a suggester-build is in progress on the old core, this might fail a reload attempt... but this is a far smaller issue than the disaster we have today. "
        },
        {
            "author": "Alessandro Benedetti",
            "id": "comment-14903525",
            "date": "2015-09-22T22:01:48+0000",
            "content": "Any update on this ?\nis Anyone working on this at the minute ?\nI agree is quite important as basically is not possible to consistently use the suggester when Solr in Cloud mode ! "
        },
        {
            "author": "Jacques Du Rand",
            "id": "comment-15087350",
            "date": "2016-01-07T13:30:03+0000",
            "content": "Confirmed. Bug still exists in Solr 5.3.1 "
        },
        {
            "author": "Dario Govergun",
            "id": "comment-15185472",
            "date": "2016-03-08T18:45:28+0000",
            "content": "I can also confirm that the bug still exists in Solr 5.3.1\nAnd I also tested it in 5.5.0 with the same luck. It locks. "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-15186697",
            "date": "2016-03-09T07:53:39+0000",
            "content": "I was thinking more that in preReload() the old Suggester simply shuts down, freeing up any locks and making suggest unavailable. Then the reload will not fail due to locks, but there is a (potentially long) time span where suggest is unavailable. I feel this is better than failing reloads, which in most environments do not take place very frequently after all. "
        },
        {
            "author": "David Smiley",
            "id": "comment-15187215",
            "date": "2016-03-09T15:08:23+0000",
            "content": "+1 to this compromise for the time being "
        },
        {
            "author": "Dario Govergun",
            "id": "comment-15200096",
            "date": "2016-03-17T18:20:55+0000",
            "content": "I don't know if the other issue I'm having while implementing this has something to do with this one. If not, please correct me.\n\nThe other thing that is happening to me is that I get a Store Lookup Build Failed error, after sending a build command, using the suggester configured to use the AnalyzingInfixSuggester implementation.\nThe logs are not very explicit:\n\n\n2016-03-17 18:07:02.616 INFO  (qtp1698904557-13) [   x:users] o.a.s.h.c.SuggestComponent SuggestComponent prepare with : omitHeader=true&echoParams=explicit&suggest.dictionary=suggest&suggest.build=true&suggest=true&json.nl=flat&wt=json&suggest.count=10\n2016-03-17 18:07:02.618 INFO  (qtp1698904557-13) [   x:users] o.a.s.s.s.SolrSuggester SolrSuggester.build(suggest)\n2016-03-17 18:07:02.778 ERROR (qtp1698904557-13) [   x:users] o.a.s.s.s.SolrSuggester Store Lookup build failed\n2016-03-17 18:07:02.778 INFO  (qtp1698904557-13) [   x:users] o.a.s.h.c.SuggestComponent SuggestComponent process with : omitHeader=true&echoParams=explicit&suggest.dictionary=suggest&suggest.build=true&suggest=true&json.nl=flat&wt=json&suggest.count=10\n2016-03-17 18:07:02.778 INFO  (qtp1698904557-13) [   x:users] o.a.s.c.S.Request [users] webapp=/solr path=/suggest params={omitHeader=true&suggest=true&suggest.build=true&json.nl=flat&wt=json} status=0 QTime=162\n\n\n\nDoes this have to do with the same thing? Or is it another issue with this lookup implementation? "
        },
        {
            "author": "G\u00e9rald Quaire",
            "id": "comment-15232476",
            "date": "2016-04-08T16:53:00+0000",
            "content": "Hello,\n\nI met this issue in my project. I need to reload the Solr Core after modifying the configuration of the suggester via Solrj. In my suggester, I 'm using an AnalyzingInfixSuggester as lookup algorithm. At each reload command, the \"LockObtainFailedException\" exception rises. \nTo avoid this problem, I have overloaded the SuggestComponent and the SolrSuggester classes in order to introduce a static map that stores the suggesters already created for the current core and the current composant. My SolrSuggester  is now implemented the Closeable interface to call the close method of the lookup object. \nSo when the core is reloading, the SuggestComponent first gets the suggesters created previously by this core and closes all suggesters. And then, it can create the new Suggester instances. Here is an excerpt of the code in the SuggestComponent:\n\n    protected static Map<String, Map<String, SolrSuggester>> CoreSuggesters = new ConcurrentHashMap<>();\n...\n   @Override\n    public void inform(SolrCore core) {\n        if (initParams != null) {\n            LOG.info(\"Initializing SuggestComponent\");\n\n           CoreSuggesters.computeIfPresent(core.getName() + this.getName(), (K, map) -> {\n                if (map != null) {\n                    for (SolrSuggester suggest : map.values()) {\n                        try \n{\n                            suggest.close();\n                        }\n catch (IOException e) \n{\n                            LOG.warn(\"Could not close the suggester.\", e);\n                        }\n                    }\n                    map.clear();\n                }\n                return null;\n            });\n\n          // Initialize the new suggesters here\n...\n           CoreSuggesters.putIfAbsent(core.getName() + this.getName(), suggesters);\n            core.addCloseHook(new CloseHook() {\n                @Override\n                public void preClose(SolrCore core) {\n                    CoreSuggesters.computeIfPresent(core.getName() + internalName, (K, map) -> {\n                        if (map != null) {\n                            for (SolrSuggester suggest : map.values()) {\n                                try \n{\n                                    suggest.close();\n                                }\n catch (IOException e) \n{\n                                    LOG.warn(\"Could not close the suggester.\", e);\n                                }\n                            }\n                            map.clear();\n                        }\n                        return null;\n                    });\n                } // end of the inform method\n\nIt was painful to make the overloadingbecause the classes SuggestComponent and SolrSuggester are not written to be extended. \nThis code has fixed my issue for now. I don't know if it is a clean solution (I don't think so), but it seems working. I hope this trick will be helpful.  "
        },
        {
            "author": "Shamik Bandopadhyay",
            "id": "comment-15394059",
            "date": "2016-07-26T16:41:51+0000",
            "content": "Any update on this ? "
        },
        {
            "author": "Varun Thacker",
            "id": "comment-15394072",
            "date": "2016-07-26T16:51:29+0000",
            "content": "Hi Shamik,\n\nI don't think anyone is currently working on it. But patches are always welcome  "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-15413719",
            "date": "2016-08-09T15:26:21+0000",
            "content": "I've been hitting this as well.  One suggestion that might minimize the impact:  close the writer after build.  In analyzing the method usages, we don't seem to call the inline/online \"add/update\" methods anywhere in the code, so there really isn't any reason to keep the writer open.  I know in theory Lucene supports updating the suggesters, but we aren't using it.  \n\nWhile closing the writer at the end of the build won't completely eliminate the problem (e.g. opening a new searcher while a build is underway), I think it could lower the likelihood. "
        },
        {
            "author": "Varun Thacker",
            "id": "comment-15430744",
            "date": "2016-08-22T13:23:41+0000",
            "content": "close the writer after build. In analyzing the method usages\n\nI think that might be a good solution.\n\nSolr does not support real time updates to the suggester so its fine from it's perspective.\n\nFrom a Lucene API standpoint it's probably not ideal but maybe not all that bad?\n\nThis is what I am thinking -\n\nCreate a Lucene issue in which AnalyzingInfixSuggester#build closes the writer by default at the end.\n\nThe add and update methods call ensureOpen  and those who do frequent real time updates directly via lucene won't see any slowdowns.\n\n Michael McCandless - Would this approach have any major drawback from Lucene's perspective?  Else I can go ahead an tackle this in a Lucene issue "
        },
        {
            "author": "Michael McCandless",
            "id": "comment-15430911",
            "date": "2016-08-22T14:51:50+0000",
            "content": "Fixing AnalyzingInfixSuggester to close the writer at the end of build seems reasonable? "
        },
        {
            "author": "ASF GitHub Bot",
            "id": "comment-15573129",
            "date": "2016-10-13T20:43:57+0000",
            "content": "GitHub user Peter-LaComb opened a pull request:\n\n    https://github.com/apache/lucene-solr/pull/96\n\n    SOLR-6246 - Fix core reload if suggester has been built.\n\n    In my testing, it is not required to keep the writer open for the suggester to keep working.\n    Add and Update call ensureOpen, which will open a new writer if it has been set = null.\n    This change closes it at the end of a build and sets the reference = null such that\n    Add and Update will continue to work correctly. Additionally, commit is updated to not\n    throw if the writer is null. This is correct because nothing has been added or updated\n    since the last build.\n    The only thing I'm left with uncertainty about is reloading a core with NRT updates\n    pending. This would appear to still cause the issue to appear again. The difference being that\n    a rebuild would alleviate the issue. This requires additional thought.\n\nYou can merge this pull request into a Git repository by running:\n\n    $ git pull https://github.com/Peter-LaComb/lucene-solr bugfix/SOLR-6246\n\nAlternatively you can review and apply these changes as the patch at:\n\n    https://github.com/apache/lucene-solr/pull/96.patch\n\nTo close this pull request, make a commit to your master/trunk branch\nwith (at least) the following in the commit message:\n\n    This closes #96\n\n\ncommit c31db2f53b431ccb3263c824c7d5fde20aab5293\nAuthor: Peter T. LaComb Jr <peter.lacomb@beeline.com>\nDate:   2016-10-13T20:28:25Z\n\n    SOLR-6246 - Fix core reload if suggester has been built.\n    In my testing, it is not required to keep the writer open for the suggester to keep working.\n    Add and Update call ensureOpen, which will open a new writer if it has been set = null.\n    This change closes it at the end of a build and sets the reference = null such that\n    Add and Update will continue to work correctly. Additionally, commit is updated to not\n    throw if the writer is null. This is correct because nothing has been added or updated\n    since the last build.\n    The only thing I'm left with uncertainty about is reloading a core with NRT updates\n    pending. This would appear to still cause the issue to appear again. The difference being that\n    a rebuild would alleviate the issue. This requires additional thought.\n\n "
        },
        {
            "author": "ASF GitHub Bot",
            "id": "comment-15575582",
            "date": "2016-10-14T14:58:46+0000",
            "content": "Github user Peter-LaComb commented on the issue:\n\n    https://github.com/apache/lucene-solr/pull/96\n\n    I broke three or more tests - need to fix that. "
        },
        {
            "author": "ASF GitHub Bot",
            "id": "comment-15575583",
            "date": "2016-10-14T14:58:47+0000",
            "content": "Github user Peter-LaComb closed the pull request at:\n\n    https://github.com/apache/lucene-solr/pull/96 "
        },
        {
            "author": "Steve Rowe",
            "id": "comment-15671489",
            "date": "2016-11-16T20:14:10+0000",
            "content": "One suggestion that might minimize the impact: close the writer after build.\n\nI've opened LUCENE-7564 to do this. "
        },
        {
            "author": "Steve Rowe",
            "id": "comment-15671575",
            "date": "2016-11-16T20:46:14+0000",
            "content": "Modernized version of Varun Thacker's test patch.\n\nThis test now succeeds when I run it on master patched with LUCENE-7564.\n\nThere is no testing of reloading while build is underway though. "
        },
        {
            "author": "Christoph Froeschel",
            "id": "comment-15761000",
            "date": "2016-12-19T12:04:53+0000",
            "content": "Hello. \nI wanted to hear if there is an update to this issue or a workaround?\nWe are seeing this issue in SOLR version 6.2.1. "
        },
        {
            "author": "Andreas Ravn",
            "id": "comment-15761094",
            "date": "2016-12-19T12:57:21+0000",
            "content": "I did a test installation of last week's nightly build of the forthcoming 6.4, and could not reproduce the issue anymore. I was able to flawlessly reload indexes that were using AnalyzingInfixSuggester. As far as a couple of functionality tests were going, everything seems to work fine.\n\nNevertheless, I would also be interested in obtaining more \"official\" information on the fix's status. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-15761604",
            "date": "2016-12-19T16:28:25+0000",
            "content": "Perhaps related? "
        },
        {
            "author": "David Smiley",
            "id": "comment-15764878",
            "date": "2016-12-20T18:27:28+0000",
            "content": "Perhaps related?\n\nErick Erickson what is related to what? "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-15764898",
            "date": "2016-12-20T18:35:06+0000",
            "content": "Bah. The comments when linking other JIRAs don't have any obvious association, do they?\n\nPerhaps related to SOLR-7747. "
        },
        {
            "author": "Christoph Froeschel",
            "id": "comment-15797822",
            "date": "2017-01-04T09:53:46+0000",
            "content": "Just wanted to hear if there is someone having a workaround for this?\n\nBest Regards\nChristoph "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-15798653",
            "date": "2017-01-04T16:26:34+0000",
            "content": "It'd be great if you could give a recent Solr a spin and see if the problem persists. \n\nThere are a bunch of JIRAs floating around with some hints that this is fixed but nobody has volunteered to verify that this JIRA is fixed by them.\nSee: \nLUCENE-7564\nSOLR-6100 "
        },
        {
            "author": "Andreas Ravn",
            "id": "comment-15798664",
            "date": "2017-01-04T16:30:41+0000",
            "content": "Hi Erick,\n\nI did. Please see my reply to Christoph Froeschels comment from Dec 19, 2016.\n\nCheers, Andreas "
        },
        {
            "author": "James Doepp",
            "id": "comment-15798673",
            "date": "2017-01-04T16:34:54+0000",
            "content": "My \"workaround\" was to create a separate core with only the suggesters. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-15798805",
            "date": "2017-01-04T17:28:44+0000",
            "content": "Thanks Andreas! "
        },
        {
            "author": "Christoph Froeschel",
            "id": "comment-15799242",
            "date": "2017-01-04T20:30:41+0000",
            "content": "Hello.\n\nI've looked at Andreas' comment. The problem is that i need to push some software to production and for that I would not like to have a nightly build but a stable release. On my test machine I have 6.2.1 installed. That's why I was looking for a workaround.\n\nBest Regards\nChristoph "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-15799360",
            "date": "2017-01-04T21:12:09+0000",
            "content": "If you can stand to wait a bit, Solr 6.4 may be cut in the next couple of weeks. Otherwise the only workaround I've seen is to have a separate core be your suggester that you don't reload. "
        },
        {
            "author": "jefferyyuan",
            "id": "comment-15822340",
            "date": "2017-01-13T21:04:16+0000",
            "content": "I am running on Solr 6.4 - solr-6.4.0-195.\nBut the problem still exists. Even restarting solr doesn't work - after restart solr and reload collection or current node still fails with LockObtainFailedException.\n\nI even tried to manually delete the write.lock, then call reload-collection/cores , it still failed again with same error.\n\nINFO  - 2017-01-12 16:55:42.392; [c:myCollection s:shard2 r:core_node3 x:searchItems_shard2_replica1] org.apache.solr.servlet.HttpSolrCall; [admin] webapp=null path=/admin/cores params=\n{core=searchItems_shard2_replica1&qt=/admin/cores&action=RELOAD&wt=javabin&version=2}\n status=500 QTime=592\nERROR - 2017-01-12 16:55:42.393; [c:myCollection s:shard2 r:core_node3 x:searchItems_shard2_replica1] org.apache.solr.common.SolrException; null:org.apache.solr.common.SolrException: Error handling 'reload' action\n\tat org.apache.solr.handler.admin.CoreAdminOperation.lambda$static$2(CoreAdminOperation.java:114)\n\tat org.apache.solr.handler.admin.CoreAdminOperation$$Lambda$23/265321659.execute(Unknown Source)\n\tat org.apache.solr.handler.admin.CoreAdminOperation.execute(CoreAdminOperation.java:377)\n\tat org.apache.solr.handler.admin.CoreAdminHandler$CallInfo.call(CoreAdminHandler.java:365)\n\tat org.apache.solr.handler.admin.CoreAdminHandler.handleRequestBody(CoreAdminHandler.java:156)\n\tat org.apache.solr.handler.RequestHandlerBase.handleRequest(RequestHandlerBase.java:152)\n\tat org.apache.solr.servlet.HttpSolrCall.handleAdminRequest(HttpSolrCall.java:664)\n\tat org.apache.solr.servlet.HttpSolrCall.call(HttpSolrCall.java:445)\n\tat org.apache.solr.servlet.SolrDispatchFilter.doFilter(SolrDispatchFilter.java:303)\n\tat org.apache.solr.servlet.SolrDispatchFilter.doFilter(SolrDispatchFilter.java:254)\n\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1691)\n\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:582)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)\n\tat org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)\n\tat org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)\n\tat org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)\n\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)\n\tat org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)\n\tat org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n\tat org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)\n\tat org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)\n\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)\n\tat org.eclipse.jetty.server.Server.handle(Server.java:534)\n\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:320)\n\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)\n\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:273)\n\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:95)\n\tat org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)\n\tat org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)\n\tat org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)\n\tat org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: org.apache.solr.common.SolrException: Unable to reload core [searchItems_shard2_replica1]\n\tat org.apache.solr.core.CoreContainer.reload(CoreContainer.java:950)\n\tat org.apache.solr.handler.admin.CoreAdminOperation.lambda$static$2(CoreAdminOperation.java:112)\n\t... 34 more\nCaused by: org.apache.solr.common.SolrException: org.apache.lucene.store.LockObtainFailedException: Lock held by this virtual machine: /Applications/solr-6.4.0/example/cloud/node2/solr/searchItems_shard2_replica1/data/infix_suggestions/write.lock\n\tat org.apache.solr.core.SolrCore.<init>(SolrCore.java:899)\n\tat org.apache.solr.core.SolrCore.reload(SolrCore.java:589)\n\tat org.apache.solr.core.CoreContainer.reload(CoreContainer.java:944)\n\t... 35 more\nCaused by: java.lang.RuntimeException: org.apache.lucene.store.LockObtainFailedException: Lock held by this virtual machine: /Applications/solr-6.4.0/example/cloud/node2/solr/searchItems_shard2_replica1/data/infix_suggestions/write.lock\n\tat org.apache.solr.spelling.suggest.fst.BlendedInfixLookupFactory.create(BlendedInfixLookupFactory.java:139)\n\tat org.apache.solr.spelling.suggest.SolrSuggester.init(SolrSuggester.java:120)\n\tat org.apache.solr.handler.component.SuggestComponent.inform(SuggestComponent.java:119)\n\tat org.apache.solr.core.SolrResourceLoader.inform(SolrResourceLoader.java:695)\n\tat org.apache.solr.core.SolrCore.<init>(SolrCore.java:879)\n\t... 37 more\nCaused by: org.apache.lucene.store.LockObtainFailedException: Lock held by this virtual machine: /Applications/solr-6.4.0/example/cloud/node2/solr/searchItems_shard2_replica1/data/infix_suggestions/write.lock\n\tat org.apache.lucene.store.NativeFSLockFactory.obtainFSLock(NativeFSLockFactory.java:127)\n\tat org.apache.lucene.store.FSLockFactory.obtainLock(FSLockFactory.java:41)\n\tat org.apache.lucene.store.BaseDirectory.obtainLock(BaseDirectory.java:45)\n\tat org.apache.lucene.index.IndexWriter.<init>(IndexWriter.java:804)\n\tat org.apache.lucene.search.suggest.analyzing.AnalyzingInfixSuggester.<init>(AnalyzingInfixSuggester.java:250)\n\tat org.apache.lucene.search.suggest.analyzing.AnalyzingInfixSuggester.<init>(AnalyzingInfixSuggester.java:207)\n\tat org.apache.lucene.search.suggest.analyzing.BlendedInfixSuggester.<init>(BlendedInfixSuggester.java:141)\n\tat org.apache.solr.spelling.suggest.fst.BlendedInfixLookupFactory$1.<init>(BlendedInfixLookupFactory.java:119)\n\tat org.apache.solr.spelling.suggest.fst.BlendedInfixLookupFactory.create(BlendedInfixLookupFactory.java:116)\n\t... 41 more "
        },
        {
            "author": "Steve Rowe",
            "id": "comment-15822354",
            "date": "2017-01-13T21:12:29+0000",
            "content": "jefferyyuan, Solr 6.4 has not yet been released - where did \"solr-6.4.0-195\" come from? "
        },
        {
            "author": "jefferyyuan",
            "id": "comment-15822377",
            "date": "2017-01-13T21:32:07+0000",
            "content": "From https://builds.apache.org/job/Solr-Artifacts-6.x/lastSuccessfulBuild/artifact/solr/package/\n\n\tit was build 195 when I downloaded at that time\n\n\n\nI will try the newest build and check whether this works "
        },
        {
            "author": "jefferyyuan",
            "id": "comment-15822691",
            "date": "2017-01-14T05:13:16+0000",
            "content": "I tested with the latest build - solr-6.4.0-222,reloading collection/cores with AnalyzingInfixSuggester still failed with LockObtainFailedException.\nIt failed with same error even after after solr.\n\nIt can be easily reproduced, add a suggest component, then **build the suggester**: suggest?suggest.build=true. Then reload collection or cores.\n\n\n\tSeems the key to reproduce the issue is we need build the suggester.\n\n\n\n\t<searchComponent name=\"suggest\" class=\"solr.SuggestComponent\">\n\t\t<lst name=\"suggester\">\n\t\t\t<str name=\"name\">infixSuggester</str>\n\t\t\t<str name=\"lookupImpl\">BlendedInfixLookupFactory</str>\n\t\t\t<str name=\"dictionaryImpl\">DocumentDictionaryFactory</str>\n\t\t\t<str name=\"blenderType\">position_linear</str>\n\t\t\t<str name=\"field\">suggester</str>\n\t\t\t<str name=\"contextField\">suggesterContextField</str>\n\t\t\t<str name=\"minPrefixChars\">4</str>\n\t\t\t<str name=\"suggestAnalyzerFieldType\">textSuggest</str>\n\t\t\t<str name=\"indexPath\">infix_suggestions</str>\n\t\t\t<str name=\"highlight\">true</str>\n\t\t\t<str name=\"buildOnStartup\">false</str>\n\t\t\t<str name=\"buildOnCommit\">false</str>\n\t\t</lst>\n\t</searchComponent>\n\n\t<requestHandler name=\"/suggest\" class=\"solr.SearchHandler\"\n\t\t>\n\t\t<lst name=\"defaults\">\n\t\t\t<str name=\"suggest\">true</str>\n\t\t\t<str name=\"suggest.dictionary\">infixSuggester</str>\n\t\t\t<str name=\"suggest.onlyMorePopular\">true</str>\n\t\t\t<str name=\"suggest.count\">10</str>\n\t\t\t<str name=\"suggest.collate\">true</str>\n\t\t</lst>\n\t\t<arr name=\"components\">\n\t\t\t<str>suggest</str>\n\t\t</arr>\n\t</requestHandler> "
        },
        {
            "author": "Steve Rowe",
            "id": "comment-15836589",
            "date": "2017-01-24T20:31:21+0000",
            "content": "Patch that adds a random dictionary with configurable size and new tests that use it: \n\n\n\tA build/reload test for each of AnalyzingInfixSuggester and BlendedInfixSuggester.\n\tA test that starts building a suggester in the background then initiates a core reload.\n\n\n\nAll the tests fail now. The first two only fail 50% of the time, with the cause given in others' reports on this issue; I'm not sure why they don't fail all the time.  (My earlier report of the previous test patch passing may have been luck/insufficient trials?).  The reload-while-building test sometimes finishes building, and then fails like the other tests, but sometimes reload causes the suggester's index writer to be closed, which causes an exception to be thrown, interrupting the build process.\n\nFor some reason, the suggesters' sidecar indexes have write.lock files in them even after writer.close() is called. "
        },
        {
            "author": "Steve Rowe",
            "id": "comment-15846444",
            "date": "2017-01-31T06:20:28+0000",
            "content": "I filed LUCENE-7670 to address an issue I see with tests: a second core reload after a suggester build will trigger the failures mentioned above, because suggesters opened over already-built indexes were creating an IndexWriter just to create a SearcherManager, thus locking the index directory. "
        },
        {
            "author": "Steve Rowe",
            "id": "comment-15851017",
            "date": "2017-02-03T03:52:50+0000",
            "content": "jefferyyuan, can you see if the LUCENE-7670 change included in the 6.4.1 release candidate (and also the 6.5.0 snapshot available from https://builds.apache.org/job/Solr-Artifacts-6.x/lastSuccessfulBuild/artifact/solr/package/) fixes the problem for you?  The 6.4.1 release candidate #1 is pointed to from here: <https://lists.apache.org/thread.html/89506bf377f49835cfb3d2174d747a5995bfbb5dd9c0475e6ce70aae@%3Cdev.lucene.apache.org%3E> "
        },
        {
            "author": "jefferyyuan",
            "id": "comment-15851104",
            "date": "2017-02-03T05:49:32+0000",
            "content": "First I reproduce the issue in current 6.4.\nThen verified the 6.4.1 release candidate fixed the issue.\n\nThanks for solving this issue and looking for 6.4.1 release. Steve Rowe "
        },
        {
            "author": "Steve Rowe",
            "id": "comment-15851143",
            "date": "2017-02-03T06:38:53+0000",
            "content": "I think suggester builds interrupted by core reload or shutdown should fail gracefully (rather than hold up reload/shutdown).\n\nThis patch:\n\n\n\tCleans up the previously described tests.\n\tChanges SolrSuggester.build() to throw SolrCoreState.CoreIsClosedException with a descriptive message when AlreadyClosedException is thrown during suggester build due to a closed IndexWriter (the result of calling close() on the suggester as part of a core reload or shutdown).\n\tTests for reload & shutdown during suggester build look for the appropriate wrapped exception.\n\tNew expectThrows() variant added to LuceneTestCase that checks for both expected outer and wrapped exceptions.\n\n\n\nI think it's ready. "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-15852328",
            "date": "2017-02-03T23:34:29+0000",
            "content": "Commit 7b081e468a97b353a5e096ed69163ee9c3044925 in lucene-solr's branch refs/heads/branch_6x from Steve Rowe\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=7b081e4 ]\n\nSOLR-6246: SolrSuggester.build() now throws SolrCoreState.CoreIsClosedException when a core reload/shutdown happens; add a random test lookup dictionary with configurable size; add \n{Analyzing,Blended}\nInfixSuggester reload/build tests; add a wrapped-exception expectThrows() variant to LuceneTestCase "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-15852329",
            "date": "2017-02-03T23:34:31+0000",
            "content": "Commit 90b16c6d855c534fda1229f1afe7bc622cd0b7da in lucene-solr's branch refs/heads/branch_6x from Steve Rowe\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=90b16c6 ]\n\nSOLR-6246: add CHANGES entry "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-15852330",
            "date": "2017-02-03T23:34:35+0000",
            "content": "Commit 6c1a4b673a0b74d85d54593b76babe34bf543dbb in lucene-solr's branch refs/heads/master from Steve Rowe\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=6c1a4b6 ]\n\nSOLR-6246: SolrSuggester.build() now throws SolrCoreState.CoreIsClosedException when a core reload/shutdown happens; add a random test lookup dictionary with configurable size; add \n{Analyzing,Blended}\nInfixSuggester reload/build tests; add a wrapped-exception expectThrows() variant to LuceneTestCase "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-15852331",
            "date": "2017-02-03T23:34:39+0000",
            "content": "Commit f9e36d9d76582e97103b29d2c4a4cf9d8e6fc1c6 in lucene-solr's branch refs/heads/master from Steve Rowe\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=f9e36d9 ]\n\nSOLR-6246: add CHANGES entry "
        },
        {
            "author": "Steve Rowe",
            "id": "comment-15852355",
            "date": "2017-02-03T23:53:49+0000",
            "content": "Thanks jefferyyuan for testing! "
        },
        {
            "author": "jefferyyuan",
            "id": "comment-15855637",
            "date": "2017-02-07T09:33:02+0000",
            "content": "Thanks Steve Rowe\nI am wondering is there any plan to also fix this issue in 6.4.x version? \nThis fix is so valuable, without this we can't really use AnalyzingInfixSuggester - as we always reload the collections to update schema or config etc.\n\nAnd it takes time to release 6.5 - usually several(2 or 3) months. "
        },
        {
            "author": "Andreas Ravn",
            "id": "comment-15855738",
            "date": "2017-02-07T10:47:22+0000",
            "content": "I'd also appreciate if this fix could be provided in 6.4.x. This bug is our critical impediment for a two-major-versions update. "
        },
        {
            "author": "Steve Rowe",
            "id": "comment-15856094",
            "date": "2017-02-07T14:33:57+0000",
            "content": "jefferyyuan, you yourself tested 6.4.1 and found that the fixes included in that release fixed your problem.  Quoting the CHANGES.txt entry for this issue:\n\nAdded tests to check that the changes in LUCENE-7564 and LUCENE-7670 enable AnalyzingInfixSuggester and BlendedInfixSuggester to play nicely with core reload.\n\nLUCENE-7564 and LUCENE-7670 contain the fixes for the problem identified in this issue, and they were included in Lucene/Solr 6.4.1.\n\nThis issue contains tests that confirm the fix in the Solr context, and it wasn't ready until after the 6.4.1 release candidate voting was already underway, so couldn't be included.  \n\nHere's what I included in the Solr 6.4.1 release announcement:\n\nAnalyzingInfixSuggester/BlendedInfixSuggester now work with core reload "
        },
        {
            "author": "jefferyyuan",
            "id": "comment-15856300",
            "date": "2017-02-07T16:39:30+0000",
            "content": "This is great news. Thanks so much Steve Rowe for clarifying my questions.\n\n\tI should do more search before asking here. My fault.\nI do read release notes for Solr 6.4.1 but not lucene 6.4.1 - which I should.\nAlso I should have read the issue links this Jira depends on.\n\n "
        },
        {
            "author": "David Smiley",
            "id": "comment-15856421",
            "date": "2017-02-07T17:53:51+0000",
            "content": "I was confused too!  I recommend marking this as fixed for 6.4.1 and 6.5.0.  If not both, then just 6.4.1.  Of course this isn't a substitute for reading release notes but nonetheless I think adjusting the fix version is more true to the title of this issue being addressed at the 6.4.1 version. "
        },
        {
            "author": "Steve Rowe",
            "id": "comment-15856580",
            "date": "2017-02-07T19:08:35+0000",
            "content": "I was confused too! I recommend marking this as fixed for 6.4.1 and 6.5.0 [...]  I think adjusting the fix version is more true to the title of this issue being addressed at the 6.4.1 version.\n\nI think you're right - I added 6.4.1 as fix version.  I'm leery of introducing an intentional difference between JIRA and CHANGES, but really the issue is that there should have been a Solr CHANGES note for the Lucene changes, but I didn't do that.  "
        },
        {
            "author": "Alessandro Benedetti",
            "id": "comment-16087402",
            "date": "2017-07-14T14:43:27+0000",
            "content": "i didn't have the time to investigate this issue in deep, but can this potentially affect also the DirectSolrSpellChecker?\ni will continue my investigations but I see a Solr cloud instance to fail to reload/restart, complaining about a lock in the index directory \n( \nERROR [org.apache.solr.core.CoreContainer] (coreLoadExecutor-5-thread-6) Error creating core [core1]: Index locked for write for core core1: org.apache.solr.common.SolrException: Index locked for write for core core1\n\non collection reload it just silentily times out... "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-16087536",
            "date": "2017-07-14T16:13:23+0000",
            "content": "Probably not. DirectSolrSpellChecker just looks in the index using (on a quick scan) IndexReader which doesn't hold a lock IIUC "
        }
    ]
}