{
    "id": "LUCENE-7132",
    "title": "BooleanQuery scores can be diff for same docs+sim when using coord (disagree with Explanation which doesn't change)",
    "details": {
        "resolution": "Fixed",
        "affect_versions": "5.5",
        "components": [
            "core/search"
        ],
        "labels": "",
        "fix_versions": [
            "5.5.2",
            "6.1",
            "7.0"
        ],
        "priority": "Blocker",
        "status": "Closed",
        "type": "Bug"
    },
    "description": "Some of the folks reported that sometimes explain's score can be different than the score requested by fields parameter. Interestingly, Explain's scores would create a different ranking than the original result list. This is something users experience, but it cannot be re-produced deterministically.",
    "attachments": {
        "debug.xml": "https://issues.apache.org/jira/secure/attachment/12794786/debug.xml",
        "SOLR-8884.patch": "https://issues.apache.org/jira/secure/attachment/12794814/SOLR-8884.patch",
        "LUCENE-7132.patch": "https://issues.apache.org/jira/secure/attachment/12795064/LUCENE-7132.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "id": "comment-15206665",
            "author": "Ahmet Arslan",
            "date": "2016-03-22T16:09:33+0000",
            "content": "There is the Rajesh's response file that demonstrates the problem. "
        },
        {
            "id": "comment-15206710",
            "author": "Alessandro Benedetti",
            "date": "2016-03-22T16:25:32+0000",
            "content": "In my case it happened when testing a re-ranking capability.\nThe explain debug ranking was the correct one, with correct and expected scores.\nThe results in the response were wrongly scored and ranked.\nI've never gone back to that and while I was testing, starting and restarting, the problem disappeared quite suddenly and I was not able to reproduce it.\nI know the information I added is almost null, hopefully we can get more evidence from other people !\n\nCheers "
        },
        {
            "id": "comment-15206987",
            "author": "Ahmet Arslan",
            "date": "2016-03-22T18:33:24+0000",
            "content": "Randomized test case for Lucene in hopes that it will trigger sometime. Will try to write Solr counterpart. "
        },
        {
            "id": "comment-15208919",
            "author": "Ahmet Arslan",
            "date": "2016-03-23T18:24:38+0000",
            "content": "This is truly a Lucene level bug. Attached path includes a failing test case. It can be reproduced with: ant test  -Dtestcase=TestExplain -Dtests.method=testRajeshData -Dtests.seed=D5E55A7E84F4C82C -Dtests.slow=true -Dtests.locale=es-HN -Dtests.timezone=Asia/Samarkand -Dtests.asserts=true -Dtests.file.encoding=UTF-8 "
        },
        {
            "id": "comment-15208940",
            "author": "Ahmet Arslan",
            "date": "2016-03-23T18:43:43+0000",
            "content": "Can someone who have the appropriate permissions please move SOLR-8884 to LUCENE-XXXX? "
        },
        {
            "id": "comment-15208979",
            "author": "Steve Rowe",
            "date": "2016-03-23T19:18:37+0000",
            "content": "Done.  Please adjust the issue title accordingly. "
        },
        {
            "id": "comment-15209154",
            "author": "Ahmet Arslan",
            "date": "2016-03-23T20:56:25+0000",
            "content": "Lucene only patch. Interestingly, testExplainScoreEquality method also failed once for me. Which can be reproduced with : ant test  -Dtestcase=TestExplain -Dtests.method=testExplainScoreEquality -Dtests.seed=B90C674F754D524 -Dtests.locale=de -Dtests.timezone=Etc/GMT-12 -Dtests.asserts=true -Dtests.file.encoding=UTF-8 \nHowever, testRajeshData method fails more frequently. "
        },
        {
            "id": "comment-15209155",
            "author": "Ahmet Arslan",
            "date": "2016-03-23T20:57:45+0000",
            "content": "Thanks Steve for taking care of this! "
        },
        {
            "id": "comment-15210008",
            "author": "Ahmet Arslan",
            "date": "2016-03-24T09:47:50+0000",
            "content": "It is really hard to decipher what is going on inside the good old TFIDFSimilarity.\n\nTFIDFSimilarity.IDFStats.normalize\n    @Override\n    public void normalize(float queryNorm, float boost) {\n      this.boost = boost;\n      this.queryNorm = queryNorm;\n      queryWeight = queryNorm * boost * idf.getValue();\n      value = queryWeight * idf.getValue();         // idf for document\n    }\n\n\n\n\n\tWhy query weight has a IDF multiplicand?\n\tWhy TFIDFSimilarity.IDFStats#value is set to IDF square?\n\tWhy TFIDFSimilarity.IDFStats#value is need even though we have TFIDFSimilarity.IDFStats.idf.getValue();\n\tTFIDFSimilarity.TFIDFSimScorer#score returns tf(freq) * IDFStats.value which looks tfxIDFxIDF to me.\n\n "
        },
        {
            "id": "comment-15220127",
            "author": "Andreas Kostyrka",
            "date": "2016-03-31T16:22:02+0000",
            "content": "Just wanted to mention, it seems to affect SOLR 5.4.1 and 5.3.1 at least too. "
        },
        {
            "id": "comment-15222996",
            "author": "Hoss Man",
            "date": "2016-04-02T18:34:06+0000",
            "content": "\nW/o really having firm idea what's going on here i spent some time reviewing the tests that Ahmet posted, and then started poking at things with a stick \u2013 mainly to see if I could figure out the missing piece of the puzzle that caused things to fail in \"testRajeshData()\" but not in any of our existing randomized tests.  \n\nI feel down the rabit hole a bit looking into this, and I still have no concrete idea what the underlying problem is, but i have a few uneducated guesses...\n\n\n\tthe problem seems to only affect BooleanQueries where a \"coord\" factor is involved\n\t\n\t\tadding setDisableCoord(true) on the queries in testRajeshData seems to make all seeds pass\n\t\tso obviously reproducing this bug requires a Similarity that has a non-trivila coord function (like ClassicSimilaity in Ahmet's TestExplain)\n\t\n\t\n\tthe score values are inconsistent between randomized runs of testRajeshData, while the explain values stay the same\n\t\n\t\teven though the test data & similarity are fixed, testRajeshData pass fine with some seeds, while others fail\n\t\twhen testRajeshData does fail, it's because the scores have changed compared to the values produced in previous passing runs\n\t\tbest guess: something about the MergePolicy and the way docs are co-located in diff segments is triggering a pathological code path in some BooleanWeight/Scorer optimization code?\n\t\t\n\t\t\tperhaps because a segment may not even contain one of the optional terms, so it's Scorer is null?\n\t\t\n\t\t\n\t\tif it's not the MergePolicy, then perhaps something about the codec used and the term stats?\n\t\n\t\n\n\n\nThings i've added/revised in this new version of the patch...\n\n\n\tadded some more asserts to TestExplain.testRajeshData to help demonstrate that it's the score that has changed between successful vs failing runs\n\tfixed a bug in TestExplain.testExplainScoreEquality that was causing false failures\n\t\n\t\trandomSimpleString(random()) can produce the empty string, which was causing the test to not match the numDocs it was expecting since a whitespace based analyzer is being used\n\t\tNOTE: these false failures where the only case i've ever seen TestExplain.testExplainScoreEquality fail\n\t\n\t\n\tadded a TestBaseExplanationTestCase to the test-framework\n\t\n\t\tI had some initial concerns that maybe some old changes/refactorings to BaseExplanationTestCase had completely eliminated the checks that were suppose to be done in that test, so i added this class to ensure it would fail as expected when an Explanation didn't match scores\n\t\n\t\n\tadded more coord randomization in TestSimpleExplanations\n\t\n\t\teven w/these changes, i've never seen these tests fail\n\t\n\t\n\tadded a new TestSimpleExplanationsWithHeavyIDF\n\t\n\t\tthis was one of the first things i tried, based on Ahmet's concerns about IDFStats.normalize\n\t\tsince TestExplain.testRajeshData was failing so consistently, but we've never seen failures like this from any of of the existing BaseExplanationTestCase, i speculated that maybe IDF stats or index size were a big factor, and tried to bang out a subclass of TestSimpleExplanations that added a lot of (ignored) docs with the same terms to make the doc freq stats more interesting for the terms being searched on\n\t\ti've never seen this test fail\n\t\tsome refactoring in BaseExplanationTestCase was needed to write this test\n\t\n\t\n\n\n\n\n\nAs things stand now with the current patch, here are some test seeds for TestExplain that pass for me...\n\n\nant test  -Dtestcase=TestExplain -Dtests.method=testRajeshData -Dtests.seed=11679FC4F397A674 -Dtests.slow=true -Dtests.locale=th -Dtests.timezone=Etc/GMT+1 -Dtests.asserts=true -Dtests.file.encoding=UTF-8 -Dtests.verbose=true\n...\n   [junit4]   2> NOTE: test params are: codec=Asserting(Lucene60): {id=PostingsFormat(name=SimpleText), body=PostingsFormat(name=Memory doPackFST= false)}, docValues:{}, maxPointsInLeafNode=604, maxMBSortInHeap=6.961830329642295, sim=ClassicSimilarity, locale=th, timezone=Etc/GMT+1\n\n\n\nant test -Dtestcase=TestExplain -Dtests.verbose=true -Dtests.seed=610EF558241D1898 -Dtests.slow=true -Dtests.locale=th -Dtests.timezone=Etc/GMT+1 -Dtests.asserts=true -Dtests.file.encoding=UTF-8 -Dtests.verbose=true\n...\n   [junit4]   2> NOTE: test params are: codec=Asserting(Lucene60): {id=PostingsFormat(name=Memory doPackFST= true), body=Lucene50(blocksize=128)}, docValues:{}, maxPointsInLeafNode=738, maxMBSortInHeap=5.910307356558968, sim=RandomSimilarity(queryNorm=true,coord=no): {}, locale=th, timezone=Etc/GMT+1\n\n\n\nAnd here are some examples of failures...\n\n\nfails...\n\n\nant test  -Dtestcase=TestExplain -Dtests.method=testRajeshData -Dtests.seed=A2E2DCFC7459241E -Dtests.slow=true -Dtests.locale=ar-EG -Dtests.timezone=Africa/Asmara -Dtests.asserts=true -Dtests.file.encoding=US-ASCII -Dtests.verbose=true\n\n   [junit4]   2> NOTE: reproduce with: ant test  -Dtestcase=TestExplain -Dtests.method=testRajeshData -Dtests.seed=A2E2DCFC7459241E -Dtests.slow=true -Dtests.locale=ar-EG -Dtests.timezone=Africa/Asmara -Dtests.asserts=true -Dtests.file.encoding=US-ASCII\n   [junit4] FAILURE 1.09s | TestExplain.testRajeshData <<<\n   [junit4]    > Throwable #1: java.lang.AssertionError: o-365 score expected:<0.7475659251213074> but was:<0.2491886466741562>\n   [junit4]    > \tat __randomizedtesting.SeedInfo.seed([A2E2DCFC7459241E:C3C4FAF539C031CF]:0)\n   [junit4]    > \tat org.apache.lucene.search.TestExplain.testRajeshData(TestExplain.java:210)\n   [junit4]    > \tat java.lang.Thread.run(Thread.java:745)\n   [junit4]   2> NOTE: test params are: codec=CheapBastard, sim=RandomSimilarity(queryNorm=false,coord=no): {}, locale=ar-EG, timezone=Africa/Asmara\n   [junit4]   2> NOTE: Linux 3.19.0-51-generic amd64/Oracle Corporation 1.8.0_74 (64-bit)/cpus=4,threads=1,free=236148720,total=248512512\n\n\n\n\nant test  -Dtestcase=TestExplain -Dtests.method=testRajeshData -Dtests.seed=92DC100B28B70C2C -Dtests.slow=true -Dtests.locale=he -Dtests.timezone=America/Guyana -Dtests.asserts=true -Dtests.file.encoding=UTF-8  -Dtests.verbose=true\n\n   [junit4]   2> NOTE: reproduce with: ant test  -Dtestcase=TestExplain -Dtests.method=testRajeshData -Dtests.seed=92DC100B28B70C2C -Dtests.slow=true -Dtests.locale=he -Dtests.timezone=America/Guyana -Dtests.asserts=true -Dtests.file.encoding=UTF-8\n   [junit4] FAILURE 1.03s | TestExplain.testRajeshData <<<\n   [junit4]    > Throwable #1: java.lang.AssertionError: m-o-365 score expected:<1.2357021570205688> but was:<0.41190072894096375>\n   [junit4]    > \tat __randomizedtesting.SeedInfo.seed([92DC100B28B70C2C:F3FA3602652E19FD]:0)\n   [junit4]    > \tat org.apache.lucene.search.TestExplain.testRajeshData(TestExplain.java:207)\n   [junit4]    > \tat java.lang.Thread.run(Thread.java:745)\n   [junit4]   2> NOTE: test params are: codec=Lucene60, sim=ClassicSimilarity, locale=he, timezone=America/Guyana\n   [junit4]   2> NOTE: Linux 3.19.0-51-generic amd64/Oracle Corporation 1.8.0_74 (64-bit)/cpus=4,threads=1,free=173898752,total=249561088\n   [junit4]   2> NOTE: All tests run in this JVM: [TestExplain]\n\n\n\nMy refactoring of BaseExplanationTestCase also seems to have somehow introduced/tickled a stranage bug in the test framework that trips our SecurityManager settings \u2013 note that the seed below causes an odd AccessControlException at the suite level after all TestSimpleExplanations test methods have finished successfully...\n\n\nant test  -Dtestcase=TestSimpleExplanations -Dtests.seed=74B719CE50C8168A -Dtests.slow=true -Dtests.locale=sr-Latn -Dtests.timezone=America/St_Vincent -Dtests.asserts=true -Dtests.file.encoding=UTF-8\n\n   ...\n   [junit4] OK      0.01s | TestSimpleExplanations.testBQ14\n   [junit4] OK      0.01s | TestSimpleExplanations.testBQ1\n   [junit4] OK      0.03s | TestSimpleExplanations.testBQ20\n   [junit4] OK      0.03s | TestSimpleExplanations.testBQ4\n   [junit4] OK      0.01s | TestSimpleExplanations.testP2\n   [junit4]   2> NOTE: test params are: codec=Asserting(Lucene60), sim=RandomSimilarity(queryNorm=false,coord=no): {field=DFR I(n)B2, alt=DFR I(ne)B1}, locale=sr-Latn, timezone=America/St_Vincent\n   [junit4]   2> NOTE: Linux 3.19.0-51-generic amd64/Oracle Corporation 1.8.0_74 (64-bit)/cpus=4,threads=1,free=303553832,total=329777152\n   [junit4]   2> NOTE: All tests run in this JVM: [TestSimpleExplanations]\n   [junit4]   2> NOTE: reproduce with: ant test  -Dtestcase=TestSimpleExplanations -Dtests.seed=74B719CE50C8168A -Dtests.slow=true -Dtests.locale=sr-Latn -Dtests.timezone=America/St_Vincent -Dtests.asserts=true -Dtests.file.encoding=UTF-8\n   [junit4] ERROR   0.00s | TestSimpleExplanations (suite) <<<\n   [junit4]    > Throwable #1: java.security.AccessControlException: access denied (\"java.lang.RuntimePermission\" \"accessClassInPackage.sun.nio.fs\")\n   [junit4]    > \tat __randomizedtesting.SeedInfo.seed([74B719CE50C8168A]:0)\n   [junit4]    > \tat java.security.AccessControlContext.checkPermission(AccessControlContext.java:472)\n   [junit4]    > \tat java.security.AccessController.checkPermission(AccessController.java:884)\n   [junit4]    > \tat java.lang.SecurityManager.checkPermission(SecurityManager.java:549)\n   [junit4]    > \tat java.lang.SecurityManager.checkPackageAccess(SecurityManager.java:1564)\n   [junit4]    > \tat java.lang.Class.checkPackageAccess(Class.java:2372)\n   [junit4]    > \tat java.lang.Class.checkMemberAccess(Class.java:2351)\n   [junit4]    > \tat java.lang.Class.getDeclaredFields(Class.java:1915)\n   [junit4]    > \tat java.security.AccessController.doPrivileged(Native Method)\n   [junit4]    > \tat java.lang.Thread.run(Thread.java:745)\n   [junit4] Completed [1/1 (1!)] in 2.50s, 68 tests, 1 error <<< FAILURES!\n\n "
        },
        {
            "id": "comment-15222999",
            "author": "Hoss Man",
            "date": "2016-04-02T18:37:59+0000",
            "content": "Michael McCandless, Adrien Grand - any theory as to what could cause diff scores to be produced between diff test runs even though the Query, Documents & Similarity are fixed in Ahmet's TestExplain.testRajeshData?\n\nDawid Weiss, Uwe Schindler - any idea what i did to causes this weird AccessControlException in TestSimpleExplanations? "
        },
        {
            "id": "comment-15223004",
            "author": "Uwe Schindler",
            "date": "2016-04-02T18:45:33+0000",
            "content": "Dawid Weiss, Uwe Schindler - any idea what i did to causes this weird AccessControlException in TestSimpleExplanations?\n\nThe problem is caused by the static leak detector (same issue like the fix I posted to Solr). The leak detetctor measures static fields and their heap usage. Unfortunately this fails for non-public classes (e.g. implementations of Path). So be sure to null all static fields on afterClass().\n\nIn Java 9 this fails more often, so be sure to always null out static non-final fields that point to \"more complex\" and internal Java objects. "
        },
        {
            "id": "comment-15223008",
            "author": "Uwe Schindler",
            "date": "2016-04-02T18:55:24+0000",
            "content": "Here is what's wrong in the test: You have to null the writer field in BaseExplanationTestCase like the searcher in afterClass(). "
        },
        {
            "id": "comment-15223206",
            "author": "Uwe Schindler",
            "date": "2016-04-03T10:41:34+0000",
            "content": "I added https://github.com/randomizedtesting/randomizedtesting/issues/227 to make this easier to debug. The stack trace is not very helpful to figure out that the \"bad\" guy was the non-nulled writer field. "
        },
        {
            "id": "comment-15225118",
            "author": "Uwe Schindler",
            "date": "2016-04-04T21:45:34+0000",
            "content": "With LUCENE-7174 committed (update of randomizedtesting framework), your test produces the following failure:\n\n\n   [junit4]   2> NOTE: test params are: codec=Asserting(Lucene60), sim=RandomSimilarity(queryNorm=false,coord=no): {field=DFR I(n)B2, alt=DFR I(ne)B1}, locale=sr-Latn, timezone=America/St_Vincent\n   [junit4]   2> NOTE: Windows 7 6.1 amd64/Oracle Corporation 1.8.0_72 (64-bit)/cpus=8,threads=1,free=166881504,total=261095424\n   [junit4]   2> NOTE: All tests run in this JVM: [TestSimpleExplanations]\n   [junit4]   2> NOTE: reproduce with: ant test  -Dtestcase=TestSimpleExplanations -Dtests.seed=74B719CE50C8168A -Dtests.slow=true -Dtests.locale=sr-Latn -Dtests.timezone=America/St_Vincent -Dtests.asserts=true -Dtests.file.encoding=UTF-8\n   [junit4] ERROR   0.00s | TestSimpleExplanations (suite) <<<\n   [junit4]    > Throwable #1: junit.framework.AssertionFailedError: Clean up static fields (in @AfterClass?) and null them, your test still has references to classes of which the sizes cannot be measured due to security restrictions or Java 9 module encapsulation:\n   [junit4]    >   - protected static org.apache.lucene.index.RandomIndexWriter org.apache.lucene.search.BaseExplanationTestCase.writer\n   [junit4]    > \tat __randomizedtesting.SeedInfo.seed([74B719CE50C8168A]:0)\n   [junit4]    > \tat java.lang.Thread.run(Thread.java:745)\n   [junit4]    > Caused by: java.security.AccessControlException: access denied (\"java.lang.RuntimePermission\" \"accessClassInPackage.sun.nio.fs\")\n   [junit4]    > \tat java.security.AccessControlContext.checkPermission(AccessControlContext.java:472)\n   [junit4]    > \tat java.security.AccessController.checkPermission(AccessController.java:884)\n   [junit4]    > \tat java.lang.SecurityManager.checkPermission(SecurityManager.java:549)\n   [junit4]    > \tat java.lang.SecurityManager.checkPackageAccess(SecurityManager.java:1564)\n   [junit4]    > \tat java.lang.Class.checkPackageAccess(Class.java:2372)\n   [junit4]    > \tat java.lang.Class.checkMemberAccess(Class.java:2351)\n   [junit4]    > \tat java.lang.Class.getDeclaredFields(Class.java:1915)\n   [junit4]    > \tat java.security.AccessController.doPrivileged(Native Method)\n   [junit4]    > \t... 10 more\n   [junit4] Completed [1/1 (1!)] in 2.90s, 69 tests, 1 failure <<< FAILURES!\n\n "
        },
        {
            "id": "comment-15313411",
            "author": "Hoss Man",
            "date": "2016-06-03T00:43:54+0000",
            "content": "\nI was reminded of this issue today and pinged Michael McCandless about it on IRC.\n\nIn reviewing the issue myself, to try and describe it to him succinctly, I realized the key bullet points of this bug is:\n\n\n\tIt is possible to build an index, with no deleted documents such that a particular BooleanQuery returns drastically different scores for some documents depending on if/how the segments in the index have been merged.\n\tThe Explanations for every document matching this BooleanQuery do not change based on if/how the segments in the index have been merged \u2013 such that the Explanations can be drastically different then the scores\n\n\n\nCouched that way, and with a request from mike to try and confirm if the bug was dependent on using LuceneTestCase.newIndexWriterConfig (i gather he suspected it might be a test only bug) I revamped the previous test class to attempt to more straight forwardly demonstrate the crux of the matter.\n\nThere are now two test methods: testScoresWithDefaultIWC & testScoresWithRandomIWC \u2013 both delegating to the same helpe method for the meat of the test, just using different IndexWriterConfigs.\n\n\"checkScores\" is the meat of both test methods.  It builds up an index using the same \"RajeshData.txt\" and then executes a fixed query against the index, recording the scores of every mathcing document.  It then does a forceMerge(1,true) on the IndexWriter, and re-executes the query comparing the scores of every matching document against the scores from the previous query execution.\n\nIf the tests make it this far (and they rarely do) then does the query again, this time checking the \"Explanation\" for every matching document against the score.\n\n\n\nWith this seed, both tests demonstrate an identical inconsistency between the scores of a document containing body=\"Microsoft Office 365\" between the pre-merge and single-segment indexes....\n\n\n   [junit4] <JUnit4> says ahoj! Master seed: B6DEF72C383813DE\n   [junit4] Executing 1 suite with 1 JVM.\n   [junit4] \n   [junit4] Started J0 PID(29777@localhost).\n   [junit4] Suite: org.apache.lucene.search.TestBooleanScoreConsistency\n   [junit4]   2> NOTE: reproduce with: ant test  -Dtestcase=TestBooleanScoreConsistency -Dtests.method=testScoresWithRandomIWC -Dtests.seed=B6DEF72C383813DE -Dtests.slow=true -Dtests.locale=ar-IQ -Dtests.timezone=Asia/Jayapura -Dtests.asserts=true -Dtests.file.encoding=UTF-8\n   [junit4] FAILURE 2.80s | TestBooleanScoreConsistency.testScoresWithRandomIWC <<<\n   [junit4]    > Throwable #1: java.lang.AssertionError: 7614: score doesn't match (previously returned) expected score for Microsoft Office 365 expected:<1.2357021570205688> but was:<0.41190072894096375>\n   [junit4]    > \tat __randomizedtesting.SeedInfo.seed([B6DEF72C383813DE:2C10E99E7CDA36F8]:0)\n   [junit4]    > \tat org.apache.lucene.search.TestBooleanScoreConsistency.checkScoresAgainstExpected(TestBooleanScoreConsistency.java:178)\n   [junit4]    > \tat org.apache.lucene.search.TestBooleanScoreConsistency.checkScores(TestBooleanScoreConsistency.java:137)\n   [junit4]    > \tat org.apache.lucene.search.TestBooleanScoreConsistency.testScoresWithRandomIWC(TestBooleanScoreConsistency.java:85)\n   [junit4]    > \tat java.lang.Thread.run(Thread.java:745)\n   [junit4]   2> NOTE: reproduce with: ant test  -Dtestcase=TestBooleanScoreConsistency -Dtests.method=testScoresWithDefaultIWC -Dtests.seed=B6DEF72C383813DE -Dtests.slow=true -Dtests.locale=ar-IQ -Dtests.timezone=Asia/Jayapura -Dtests.asserts=true -Dtests.file.encoding=UTF-8\n   [junit4] FAILURE 1.63s | TestBooleanScoreConsistency.testScoresWithDefaultIWC <<<\n   [junit4]    > Throwable #1: java.lang.AssertionError: 7614: score doesn't match (previously returned) expected score for Microsoft Office 365 expected:<1.2357021570205688> but was:<0.41190072894096375>\n   [junit4]    > \tat __randomizedtesting.SeedInfo.seed([B6DEF72C383813DE:1CF87A1A7D4B3415]:0)\n   [junit4]    > \tat org.apache.lucene.search.TestBooleanScoreConsistency.checkScoresAgainstExpected(TestBooleanScoreConsistency.java:178)\n   [junit4]    > \tat org.apache.lucene.search.TestBooleanScoreConsistency.checkScores(TestBooleanScoreConsistency.java:137)\n   [junit4]    > \tat org.apache.lucene.search.TestBooleanScoreConsistency.testScoresWithDefaultIWC(TestBooleanScoreConsistency.java:79)\n   [junit4]    > \tat java.lang.Thread.run(Thread.java:745)\n   [junit4]   2> NOTE: test params are: codec=Asserting(Lucene62): {id=PostingsFormat(name=Direct), body=Lucene50(blocksize=128)}, docValues:{}, maxPointsInLeafNode=825, maxMBSortInHeap=5.5977062021908015, sim=RandomSimilarity(queryNorm=false,coord=crazy): {}, locale=ar-IQ, timezone=Asia/Jayapura\n   [junit4]   2> NOTE: Linux 3.19.0-51-generic amd64/Oracle Corporation 1.8.0_74 (64-bit)/cpus=4,threads=1,free=266511232,total=336068608\n   [junit4]   2> NOTE: All tests run in this JVM: [TestBooleanScoreConsistency]\n   [junit4] Completed [1/1 (1!)] in 4.72s, 2 tests, 2 failures <<< FAILURES!\n   [junit4] \n   [junit4] \n   [junit4] Tests with failures [seed: B6DEF72C383813DE]:\n   [junit4]   - org.apache.lucene.search.TestBooleanScoreConsistency.testScoresWithRandomIWC\n   [junit4]   - org.apache.lucene.search.TestBooleanScoreConsistency.testScoresWithDefaultIWC\n   [junit4] \n   [junit4] \n   [junit4] JVM J0:     0.40 ..     5.70 =     5.30s\n   [junit4] Execution time total: 5.77 sec.\n   [junit4] Tests summary: 1 suite, 2 tests, 2 failures\n\n\n\nWith this seed, the pre-merge and single-segment indexes in both tests return identical scores for all matching docs, but the Explanations (which seem to be correct AFAICT) don't match the scores...\n\n\n   [junit4] <JUnit4> says salut! Master seed: AEB2F91E0E8938CC\n   [junit4] Executing 1 suite with 1 JVM.\n   [junit4] \n   [junit4] Started J0 PID(29716@localhost).\n   [junit4] Suite: org.apache.lucene.search.TestBooleanScoreConsistency\n   [junit4]   2> NOTE: reproduce with: ant test  -Dtestcase=TestBooleanScoreConsistency -Dtests.method=testScoresWithDefaultIWC -Dtests.seed=AEB2F91E0E8938CC -Dtests.slow=true -Dtests.locale=zh -Dtests.timezone=Australia/Sydney -Dtests.asserts=true -Dtests.file.encoding=ISO-8859-1\n   [junit4] FAILURE 4.08s | TestBooleanScoreConsistency.testScoresWithDefaultIWC <<<\n   [junit4]    > Throwable #1: java.lang.AssertionError: 15581: score() and explain() return different values for: Office 365\n   [junit4]    > 0.7475659 = product of:\n   [junit4]    >   2.2426977 = sum of:\n   [junit4]    >     2.2426977 = weight(body:365 in 15581) [ClassicSimilarity], result of:\n   [junit4]    >       2.2426977 = score(doc=15581,freq=1.0), product of:\n   [junit4]    >         0.5300819 = queryWeight, product of:\n   [junit4]    >           6.769362 = idf(docFreq=53, docCount=17297)\n   [junit4]    >           0.07830604 = queryNorm\n   [junit4]    >         4.230851 = fieldWeight in 15581, product of:\n   [junit4]    >           1.0 = tf(freq=1.0), with freq of:\n   [junit4]    >             1.0 = termFreq=1.0\n   [junit4]    >           6.769362 = idf(docFreq=53, docCount=17297)\n   [junit4]    >           0.625 = fieldNorm(doc=15581)\n   [junit4]    >   0.33333334 = coord(1/3)\n   [junit4]    >  expected:<0.2491886466741562> but was:<0.7475659251213074>\n   [junit4]    > \tat __randomizedtesting.SeedInfo.seed([AEB2F91E0E8938CC:49474284BFA1F07]:0)\n   [junit4]    > \tat org.apache.lucene.search.TestBooleanScoreConsistency.checkScoresAgainstExplanations(TestBooleanScoreConsistency.java:214)\n   [junit4]    > \tat org.apache.lucene.search.TestBooleanScoreConsistency.checkScores(TestBooleanScoreConsistency.java:138)\n   [junit4]    > \tat org.apache.lucene.search.TestBooleanScoreConsistency.testScoresWithDefaultIWC(TestBooleanScoreConsistency.java:79)\n   [junit4]    > \tat java.lang.Thread.run(Thread.java:745)\n   [junit4]   2> NOTE: reproduce with: ant test  -Dtestcase=TestBooleanScoreConsistency -Dtests.method=testScoresWithRandomIWC -Dtests.seed=AEB2F91E0E8938CC -Dtests.slow=true -Dtests.locale=zh -Dtests.timezone=Australia/Sydney -Dtests.asserts=true -Dtests.file.encoding=ISO-8859-1\n   [junit4] FAILURE 1.90s | TestBooleanScoreConsistency.testScoresWithRandomIWC <<<\n   [junit4]    > Throwable #1: java.lang.AssertionError: 7614: score() and explain() return different values for: Microsoft Office 365\n   [junit4]    > 1.2357022 = product of:\n   [junit4]    >   1.8535532 = sum of:\n   [junit4]    >     0.05939492 = weight(body:microsoft in 7614) [ClassicSimilarity], result of:\n   [junit4]    >       0.05939492 = score(doc=7614,freq=1.0), product of:\n   [junit4]    >         0.09644668 = queryWeight, product of:\n   [junit4]    >           1.2316633 = idf(docFreq=13720, docCount=17297)\n   [junit4]    >           0.07830604 = queryNorm\n   [junit4]    >         0.6158317 = fieldWeight in 7614, product of:\n   [junit4]    >           1.0 = tf(freq=1.0), with freq of:\n   [junit4]    >             1.0 = termFreq=1.0\n   [junit4]    >           1.2316633 = idf(docFreq=13720, docCount=17297)\n   [junit4]    >           0.5 = fieldNorm(doc=7614)\n   [junit4]    >     1.7941582 = weight(body:365 in 7614) [ClassicSimilarity], result of:\n   [junit4]    >       1.7941582 = score(doc=7614,freq=1.0), product of:\n   [junit4]    >         0.5300819 = queryWeight, product of:\n   [junit4]    >           6.769362 = idf(docFreq=53, docCount=17297)\n   [junit4]    >           0.07830604 = queryNorm\n   [junit4]    >         3.384681 = fieldWeight in 7614, product of:\n   [junit4]    >           1.0 = tf(freq=1.0), with freq of:\n   [junit4]    >             1.0 = termFreq=1.0\n   [junit4]    >           6.769362 = idf(docFreq=53, docCount=17297)\n   [junit4]    >           0.5 = fieldNorm(doc=7614)\n   [junit4]    >   0.6666667 = coord(2/3)\n   [junit4]    >  expected:<0.41190072894096375> but was:<1.2357021570205688>\n   [junit4]    > \tat __randomizedtesting.SeedInfo.seed([AEB2F91E0E8938CC:347CE7AC4A6B1DEA]:0)\n   [junit4]    > \tat org.apache.lucene.search.TestBooleanScoreConsistency.checkScoresAgainstExplanations(TestBooleanScoreConsistency.java:214)\n   [junit4]    > \tat org.apache.lucene.search.TestBooleanScoreConsistency.checkScores(TestBooleanScoreConsistency.java:138)\n   [junit4]    > \tat org.apache.lucene.search.TestBooleanScoreConsistency.testScoresWithRandomIWC(TestBooleanScoreConsistency.java:85)\n   [junit4]    > \tat java.lang.Thread.run(Thread.java:745)\n   [junit4]   2> NOTE: test params are: codec=Asserting(Lucene62): {id=PostingsFormat(name=MockRandom), body=PostingsFormat(name=LuceneFixedGap)}, docValues:{}, maxPointsInLeafNode=127, maxMBSortInHeap=5.70855157410318, sim=RandomSimilarity(queryNorm=true,coord=crazy): {}, locale=zh, timezone=Australia/Sydney\n   [junit4]   2> NOTE: Linux 3.19.0-51-generic amd64/Oracle Corporation 1.8.0_74 (64-bit)/cpus=4,threads=1,free=181104832,total=342360064\n   [junit4]   2> NOTE: All tests run in this JVM: [TestBooleanScoreConsistency]\n   [junit4] Completed [1/1 (1!)] in 6.29s, 2 tests, 2 failures <<< FAILURES!\n   [junit4] \n   [junit4] \n   [junit4] Tests with failures [seed: AEB2F91E0E8938CC]:\n   [junit4]   - org.apache.lucene.search.TestBooleanScoreConsistency.testScoresWithDefaultIWC\n   [junit4]   - org.apache.lucene.search.TestBooleanScoreConsistency.testScoresWithRandomIWC\n   [junit4] \n   [junit4] \n   [junit4] JVM J0:     0.41 ..     7.13 =     6.73s\n   [junit4] Execution time total: 7.18 sec.\n   [junit4] Tests summary: 1 suite, 2 tests, 2 failures\n\n\n\nWith this perplexing seed (found using tests.iters) the Randomized IndexWriterConfig manages to pass all checks in the test \u2013 getting scores consistent with the Explanation both before and after the forceMerge \u2013 but the default IndexWriterConfig still demonstrates the problem...\n\n\n   [junit4] <JUnit4> says hallo! Master seed: 29D39C39B6047864:5BA9313A359A1831\n   [junit4] Executing 1 suite with 1 JVM.\n   [junit4] \n   [junit4] Started J0 PID(29867@localhost).\n   [junit4] Suite: org.apache.lucene.search.TestBooleanScoreConsistency\n   [junit4] OK      6.16s | TestBooleanScoreConsistency.testScoresWithRandomIWC\n   [junit4]   2> NOTE: reproduce with: ant test  -Dtestcase=TestBooleanScoreConsistency -Dtests.method=testScoresWithDefaultIWC -Dtests.seed=29D39C39B6047864 -Dtests.slow=true -Dtests.locale=uk-UA -Dtests.timezone=Indian/Comoro -Dtests.asserts=true -Dtests.file.encoding=ISO-8859-1\n   [junit4] FAILURE 1.26s | TestBooleanScoreConsistency.testScoresWithDefaultIWC <<<\n   [junit4]    > Throwable #1: java.lang.AssertionError: 7614: score doesn't match (previously returned) expected score for Microsoft Office 365 expected:<1.2357021570205688> but was:<0.41190072894096375>\n   [junit4]    > \tat __randomizedtesting.SeedInfo.seed([29D39C39B6047864:5BA9313A359A1831]:0)\n   [junit4]    > \tat org.apache.lucene.search.TestBooleanScoreConsistency.checkScoresAgainstExpected(TestBooleanScoreConsistency.java:178)\n   [junit4]    > \tat org.apache.lucene.search.TestBooleanScoreConsistency.checkScores(TestBooleanScoreConsistency.java:137)\n   [junit4]    > \tat org.apache.lucene.search.TestBooleanScoreConsistency.testScoresWithDefaultIWC(TestBooleanScoreConsistency.java:79)\n   [junit4]    > \tat java.lang.Thread.run(Thread.java:745)\n   [junit4]   2> NOTE: test params are: codec=Asserting(Lucene62), sim=RandomSimilarity(queryNorm=false,coord=yes): {}, locale=uk-UA, timezone=Indian/Comoro\n   [junit4]   2> NOTE: Linux 3.19.0-51-generic amd64/Oracle Corporation 1.8.0_74 (64-bit)/cpus=4,threads=1,free=285815104,total=350748672\n   [junit4]   2> NOTE: All tests run in this JVM: [TestBooleanScoreConsistency]\n   [junit4] Completed [1/1 (1!)] in 7.73s, 2 tests, 1 failure <<< FAILURES!\n   [junit4] \n   [junit4] \n   [junit4] Tests with failures [seed: 29D39C39B6047864:5BA9313A359A1831]:\n   [junit4]   - org.apache.lucene.search.TestBooleanScoreConsistency.testScoresWithDefaultIWC\n   [junit4] \n   [junit4] \n   [junit4] JVM J0:     0.37 ..     8.58 =     8.21s\n   [junit4] Execution time total: 8.62 sec.\n   [junit4] Tests summary: 1 suite, 2 tests, 1 failure\n\n "
        },
        {
            "id": "comment-15313885",
            "author": "Michael McCandless",
            "date": "2016-06-03T09:11:58+0000",
            "content": "Thanks Hoss Man I'll dig. "
        },
        {
            "id": "comment-15313895",
            "author": "Michael McCandless",
            "date": "2016-06-03T09:24:52+0000",
            "content": "Hmm seems like something is wrong w/ BQ's bulk scorer, because if I take it out and just use the default:\n\n\n@@ -361,6 +363,9 @@ final class BooleanWeight extends Weight {\n \n   @Override\n   public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {\n+    // nocommit\n+    return super.bulkScorer(context);\n+    /*\n     final BulkScorer bulkScorer = booleanScorer(context);\n     if (bulkScorer != null) {\n       // bulk scoring is applicable, use it\n@@ -369,6 +374,7 @@ final class BooleanWeight extends Weight {\n       // use a Scorer-based impl (BS2)\n       return super.bulkScorer(context);\n     }\n+    */\n   }\n \n   @Override\n\n\n\nThen at least the first seed above passes... "
        },
        {
            "id": "comment-15313899",
            "author": "Michael McCandless",
            "date": "2016-06-03T09:30:44+0000",
            "content": "OK if I put back BQ's bulkScorer, but then use new IndexSearcher instead of newSearcher the first seed above gets further along: the scores agree before/after forceMerge, but the explanation is still incorrect... "
        },
        {
            "id": "comment-15313941",
            "author": "Michael McCandless",
            "date": "2016-06-03T10:19:39+0000",
            "content": "A bit more progress ... it looks like somehow BooleanScorer gets confused and is collecting a window with more than one sub-scorer matching, yet failed to tell the top collector to reset back to the fake scorer (it's still on a boosted scorer, I think from a prior window that had only one matching sub, incorrectly applying a 0.3333 boost). "
        },
        {
            "id": "comment-15314070",
            "author": "Michael McCandless",
            "date": "2016-06-03T13:06:29+0000",
            "content": "OK I found the bug ... it's sneaky \n\nIn BooleanScorer.scoreWindowSingleScorer, we try to \"reset the scorer that should be used for the general case\" by calling collector.setScorer(fakeScorer).\n\nThe problem is collector at that point is the singleClauseCollector not the original collector ... I think this attached patch fixes it. "
        },
        {
            "id": "comment-15314149",
            "author": "Michael McCandless",
            "date": "2016-06-03T14:06:24+0000",
            "content": "Robert Muir pointed out that LUCENE-7138 is likely the same bug ... I'll confirm. "
        },
        {
            "id": "comment-15314472",
            "author": "Hoss Man",
            "date": "2016-06-03T17:47:42+0000",
            "content": "thanks for digging mike!\n\nthe lsat patch you attached only included \"modified\" files, not the \"added\" files from previous patches, so it was missing the new tests.  At first i though maybe that was intentional on your part, that once you had diagnosed the root cause you had modified an existing test to include some checks for this specific situation so we wouldn't need my the crufty TestBooleanScoreConsistency with it's hardcoded data that we probably can't commit as is anyway \u2013 but i couldn't find any test modifications you had made to reliably reproduce this problem.\n\nI'm attaching a unified patch that inlcudes all the previous test code along with mike's fixes ... but obviously we still need to improve this test to not include this user data (see nocommit) ... i'll work on that. "
        },
        {
            "id": "comment-15314505",
            "author": "Hoss Man",
            "date": "2016-06-03T18:07:22+0000",
            "content": "\n\n10:21 <@hoss:#lucene-dev> mikemccand: ping?\n...\n10:44 <@mikemccand:#lucene-dev> hoss: here\n10:45 <@hoss:#lucene-dev> oh yeah ... just writting up a jira response ... i think you generated your patch just using \"git diff\" so it missed \n                          the \"new\" test files?\n10:45 <@hoss:#lucene-dev> i've got a unified patch i'm about to post, so we have both the fix andthe tests that reliably demonstrate the \n                          problem\n10:45 <@mikemccand:#lucene-dev> oh yeah sorry i did!\n10:45 <@mikemccand:#lucene-dev> ++ thanks\n10:46 <@hoss:#lucene-dev> no worries ... what i really wanted to ping you about was writting a better test\n10:46 <@hoss:#lucene-dev> right now that test shouldn't be committed as is -- data fro ma user i'm certain we don't have rights to\n10:46 <@mikemccand:#lucene-dev> ahh yeah that should be fun :)\n10:46 <@mikemccand:#lucene-dev> yeah i saw the comment about that ...\n10:46 <@hoss:#lucene-dev> i'm wondering if you could give me some pointers on the hueristics that lead to this optimizatio, so i can try to \n                          write a tighter test case that hits it?\n10:46 <@hoss:#lucene-dev> (to prevent a regression)\n10:46 <@mikemccand:#lucene-dev> ok lemme try\n10:47 <@mikemccand:#lucene-dev> right, we need a test\n10:47 <@mikemccand:#lucene-dev> you need a 2 clause BQ\n10:47 <@mikemccand:#lucene-dev> where a document with docID 0 -- 2047 matches only one term\n10:47 <@mikemccand:#lucene-dev> and then another docID > 2047 matches two terms\n10:47 <@mikemccand:#lucene-dev> in that case the 2nd document should get the wrong (disagrees w/ explain) score i think\n10:48 <@hoss:#lucene-dev> docID 0 .. as in literally docID 0 in teh index? ... it was that magical?\n10:48 <@mikemccand:#lucene-dev> yes!\n10:48 <@mikemccand:#lucene-dev> BS1 scores in windows of 2048 documents\n10:48 <@hoss:#lucene-dev> holy fuck that's an edge case\n10:48 <@mikemccand:#lucene-dev> the bug is that if 1 window uses an \"optimization\" because only 1 clauses matches ...\n10:48 <@mikemccand:#lucene-dev> then that optimization messes up the state\n10:48 <@mikemccand:#lucene-dev> and subsequent windows get the wrong scores\n10:48 <@mikemccand:#lucene-dev> yeah serious edge case :)\n10:48 <@mikemccand:#lucene-dev> i'm glad you pushed on this :)\n10:48 <@mikemccand:#lucene-dev> thanks\n10:49 <@hoss:#lucene-dev> oh ... so like, doc ID 2049 matching, but no other doc matches until after 2048 * 2 would also hit this bug?\n10:49 <@hoss:#lucene-dev> actually ... it sounds like any doc matching as long as it's the only doc in it's window, and then another doc in a \n                          alater window?\n10:49 <@mikemccand:#lucene-dev> right!\n10:50 <@mikemccand:#lucene-dev> (where that later window's doc had more than 1 clause matching)\n10:50 <@hoss:#lucene-dev> ok .. so really, we just need more tests with lots of docs, so that we force matches across the windows ... because \n                          2048 is hardcoded, not somethign we can randomize to small values via LTC\n10:50 <@mikemccand:#lucene-dev> yeah ..\n10:51 <@hoss:#lucene-dev> hmmm... why did forceMerge change things then?\n10:51 <@hoss:#lucene-dev> with no deletions wy did the windows change?\n10:51 <@mikemccand:#lucene-dev> hmmm i'm not sure?\n10:51 <@mikemccand:#lucene-dev> the forceMerge is crazy: the index already had one segment\n10:51 <@mikemccand:#lucene-dev> at least for your first seed\n10:52 <@mikemccand:#lucene-dev> yet forceMerge DID run, because CFS wanted to change\n10:52 <@mikemccand:#lucene-dev> but this should not have altered the docID order\n10:52 <@mikemccand:#lucene-dev> so yeah i can't explain why forceMerge \"matters\" here\n10:53 <@hoss:#lucene-dev> and yet - if it wasn't for the forceMerge, the only indication of the bug would be that the Explanations don't match \n                          -- unless we hardcoded scores in a test, which is hard for randomized data\n10:53 <@hoss:#lucene-dev> nee impossible\n10:54 <@mikemccand:#lucene-dev> yes\n10:57 <@hoss:#lucene-dev> weird.... maybe there's another factor to the optimization we need to consider? ... i'll let you ponder while i try \n                          to figure out a test bsaed on what we know :)\n10:57 <@mikemccand:#lucene-dev> LOL ok\n...\n11:04 <@hoss:#lucene-dev> mikemccand: BTW, you mind if i transcribe this conv to jira so i don't lose it?\n11:04 <@mikemccand:#lucene-dev> ++ great\n\n "
        },
        {
            "id": "comment-15315242",
            "author": "Hoss Man",
            "date": "2016-06-04T01:42:43+0000",
            "content": "\nOk, based on mike's clues, here are changes made in this new patch that (w/o mikes fix) help repro the bug more often...\n\n\n\n\tTestBoolean2\n\t\n\t\trandomize usage of coord in all the queries tested\n\t\trandomly injects (empty) filler docs into the index to force matches to exist in diff buckets\n\t\t\n\t\t\tthis required some changes to queriesTest to know how to compute the correct expDocNrs to pass to CheckHits\n\t\t\n\t\t\n\t\tupdated the \"bigSearcher\" assertions to also compare the results from multiple Scorers\n\t\t\n\t\t\ti never saw this actaully make a diff in terms of test fail/success, likely because of how bigSearcher is really only tacking stuff on to the end of the index, but since test was already comparing multiple scorers for the main index to try and find situations where BulkScorer would return diff results from the default Scorer it seemed like a good idea to check here as well.\n\t\t\n\t\t\n\t\tadded a \"singleSegmentSearcher\" that has a copy of the main index that has been forceMerged to a single segment\n\t\tupdated queriesTest to also use CheckHits.checkHitsQuery to compare results from the main index with the singleSegmentSearcher\n\t\t\n\t\t\tthis was inspired by the fact that in previous testing forceMerge(1) was changing the scores of documents even though there were no deletions, and Mike couldn't explain that.\n\t\t\tThis currently causes failures in some cases, even w/mikes fix applied - see below\n\t\t\n\t\t\n\t\n\t\n\treplaced TestSimpleExplanationsWithHeavyIDF with TestSimpleExplanationsWithFillerDocs\n\t\n\t\tnow the filler docs are injected in betwen existing docs\n\t\tdpeending on a random boolean, all filler docs are either:\n\t\t\n\t\t\tempty \u2013 so the queries from the super class tests aren't modified, just the expected docids\n\t\t\tfill of terms used in the queries (to muck with IDF like in the previous patch) \u2013 so the queries from the super class are also wrapped to exclude these filler docs\n\t\t\n\t\t\n\t\n\t\n\tBaseExplanationTestCase\n\t\n\t\tremoved some no-longer needed refactoring that was in early patch\n\t\tadded some randomization to wrap any query tested in a BooleanQuery with a \"SHOULD\" clause that matches nothing (to force more interesting coord cases)\n\t\n\t\n\tremoved TestBooleanScoreConsistency and RajeshData.txt since they are no longer needed to reproduce he underlying bug easily\n\n\n\n(NOTE: i experimented with injecting empty filler docs in TestMinShouldMatch2 as well, but it slowd the test WAAAAY down \u2013 ie: close to 5 minutes on my machine.   I'm guessing because of how it uses \"SlowMinShouldMatchScorer\" ... so i abandoned those changes.  Might be worth considering adding those back if someone sees a way to prevent it from being so dang slow)\n\n\nExcept for the above note in red (about TestBoolean2 failing in some cases when comparing the hits+scores between the original index and a copy of that index merged down to a single segment) mike's fix resolved every failure I was able to generate with these test changes.\n\nI suspect that either:\n\n\tI'm making some mistaken assumption in the validity of comparing scores between indexes like that (i don't think  i am based on mikes comments from IRC yesterday)\n\tThere is a bug in my changes related to creating a \"singleSegmentSearcher\" that can be compared to \"searcher\" (extremely possible)\n\tThere is still another, as yet undiagnosed, bug somwhere in BooleanQuery/BooleanScorer that causes discrepencies between otherwise equivilent indexes based on segment boundaries (seems plausible given mikes comments on IRC this morning that he couldn't think of any reason why the bug he identified would be affected by forceMerge)\n\n\n\nHere's an example of a failing seed with the current patch \u2013 note that based on the stack trace, both searchers produced a list of results that match the expected docids in the expected order, but the scores (for at least the first docid matched) are not equivilent...\n\n\n   [junit4] <JUnit4> says \u041f\u0440\u0438\u0432\u0435\u0442! Master seed: 1205E6391E501C49\n   [junit4] Executing 1 suite with 1 JVM.\n   [junit4] \n   [junit4] Started J0 PID(28313@localhost).\n   [junit4] Suite: org.apache.lucene.search.TestBoolean2\n   [junit4]   2> NOTE: reproduce with: ant test  -Dtestcase=TestBoolean2 -Dtests.method=testQueries10 -Dtests.seed=1205E6391E501C49 -Dtests.slow=true -Dtests.locale=zh-HK -Dtests.timezone=Australia/ACT -Dtests.asserts=true -Dtests.file.encoding=ISO-8859-1\n   [junit4] FAILURE 0.04s | TestBoolean2.testQueries10 <<<\n   [junit4]    > Throwable #1: junit.framework.AssertionFailedError: Hit 0, doc nrs 2 and 2\n   [junit4]    > unequal       : 0.5625806\n   [junit4]    >            and: 0.42193544\n   [junit4]    > for query:+field:w3 +field:xx +field:w2 field:zz\n   [junit4]    > \tat __randomizedtesting.SeedInfo.seed([1205E6391E501C49:E53B440260B039AE]:0)\n   [junit4]    > \tat junit.framework.Assert.fail(Assert.java:50)\n   [junit4]    > \tat org.apache.lucene.search.CheckHits.checkEqual(CheckHits.java:223)\n   [junit4]    > \tat org.apache.lucene.search.CheckHits.checkHitsQuery(CheckHits.java:205)\n   [junit4]    > \tat org.apache.lucene.search.TestBoolean2.queriesTest(TestBoolean2.java:196)\n   [junit4]    > \tat org.apache.lucene.search.TestBoolean2.testQueries10(TestBoolean2.java:329)\n   [junit4]    > \tat java.lang.Thread.run(Thread.java:745)\n   [junit4]   2> NOTE: test params are: codec=CheapBastard, sim=RandomSimilarity(queryNorm=true,coord=no): {field=DFR I(ne)LZ(0.3), field2=DFR I(n)2}, locale=zh-HK, timezone=Australia/ACT\n   [junit4]   2> NOTE: Linux 3.19.0-51-generic amd64/Oracle Corporation 1.8.0_74 (64-bit)/cpus=4,threads=1,free=281959656,total=315097088\n   [junit4]   2> NOTE: All tests run in this JVM: [TestBoolean2]\n   [junit4] Completed [1/1 (1!)] in 1.36s, 1 test, 1 failure <<< FAILURES!\n\n\n\nBut not every seed fails, example...\n\n\n   [junit4] <JUnit4> says \u05e9\u05dc\u05d5\u05dd! Master seed: 153FC5D5F31DB0CE\n   [junit4] Executing 1 suite with 1 JVM.\n   [junit4] \n   [junit4] Started J0 PID(28077@localhost).\n   [junit4] Suite: org.apache.lucene.search.TestBoolean2\n   [junit4] OK      0.10s | TestBoolean2.testQueries09\n   [junit4] OK      0.04s | TestBoolean2.testQueries05\n   [junit4] OK      0.03s | TestBoolean2.testQueries08\n   [junit4] OK      0.04s | TestBoolean2.testQueries06\n   [junit4] OK      0.02s | TestBoolean2.testQueries02\n   [junit4] OK      0.02s | TestBoolean2.testQueries10\n   [junit4] OK      0.04s | TestBoolean2.testQueries03\n   [junit4] OK      0.01s | TestBoolean2.testQueries01\n   [junit4] OK      0.01s | TestBoolean2.testQueries04\n   [junit4] OK      0.01s | TestBoolean2.testQueries07\n   [junit4] OK      3.68s | TestBoolean2.testRandomQueries\n   [junit4] Completed [1/1] in 29.83s, 11 tests\n\n\n\n "
        },
        {
            "id": "comment-15315851",
            "author": "Michael McCandless",
            "date": "2016-06-05T11:54:14+0000",
            "content": "Thanks Hoss Man, I can reproduce that failure with your patch ... I'll dig.  It is baffling  "
        },
        {
            "id": "comment-15315854",
            "author": "Michael McCandless",
            "date": "2016-06-05T12:00:51+0000",
            "content": "Hmm, testQueries10 changes the similarity of searcher temporarily, but fails to also change singleSegmentSearcher's similarity ... when I fix that, then this seed passes.\n\nBut then on beasting I see other new failures ... digging. "
        },
        {
            "id": "comment-15315856",
            "author": "Michael McCandless",
            "date": "2016-06-05T12:11:32+0000",
            "content": "OK I found another test bug: you have to use a LogMergePolicy when building the single segment searcher else the docIDs can be jumbled since otherwise merge policies are allowed (and, do!) to merge segments out of order.\n\nMaybe this also explains the original \"force merge changed results\" issue?  Except, on the one seed I was debugging before, the original index was a single segment, so no matter the merge policy, the docID order would not change ...\n\nHere's Hoss's last patch with those two test bugs fixed ... seems to survive beasting of TestBoolean2 for a while, and Lucene's core tests passed once. "
        },
        {
            "id": "comment-15315857",
            "author": "Michael McCandless",
            "date": "2016-06-05T12:13:44+0000",
            "content": "I think this bug is serious enough that we should be sure to get it into 6.1.0 ... I marked blocker. "
        },
        {
            "id": "comment-15315859",
            "author": "Michael McCandless",
            "date": "2016-06-05T12:15:54+0000",
            "content": "I also confirmed that if I revert the fix in BooleanScorer.java that TestBoolean2 does fail on some seeds ... thanks Chris Hostetter (Unused)! "
        },
        {
            "id": "comment-15316427",
            "author": "Adrien Grand",
            "date": "2016-06-06T12:36:44+0000",
            "content": "Thanks Michael McCandless and Hoss for digging this sneaky bug! +1 to the patch\n\nI think this bug is serious enough that we should be sure to get it into 6.1.0 ... I marked blocker.\n\n+1 "
        },
        {
            "id": "comment-15316481",
            "author": "Michael McCandless",
            "date": "2016-06-06T13:18:27+0000",
            "content": "Thanks Adrien Grand and Hoss Man, I'll commit the last patch. "
        },
        {
            "id": "comment-15316561",
            "author": "ASF subversion and git services",
            "date": "2016-06-06T14:35:51+0000",
            "content": "Commit c8570ed821654cdce5f92ae17d06a21f242524e2 in lucene-solr's branch refs/heads/master from Mike McCandless\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=c8570ed ]\n\nLUCENE-7132: BooleanQuery sometimes assigned the wrong score when ranges of documents had only one clause matching while other ranges had more than one clause matchng "
        },
        {
            "id": "comment-15316568",
            "author": "ASF subversion and git services",
            "date": "2016-06-06T14:40:57+0000",
            "content": "Commit 5dfaf0392fcd3b7e4b529dce0cd1035b766880a7 in lucene-solr's branch refs/heads/branch_6x from Mike McCandless\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=5dfaf03 ]\n\nLUCENE-7132: BooleanQuery sometimes assigned the wrong score when ranges of documents had only one clause matching while other ranges had more than one clause matchng "
        },
        {
            "id": "comment-15316569",
            "author": "Michael McCandless",
            "date": "2016-06-06T14:41:17+0000",
            "content": "Thanks everyone. "
        },
        {
            "id": "comment-15334281",
            "author": "ASF subversion and git services",
            "date": "2016-06-16T17:48:19+0000",
            "content": "Commit 77844e2591235bfc1944e901922f876c1d43c264 in lucene-solr's branch refs/heads/branch_5_5 from Steve Rowe\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=77844e2 ]\n\nLUCENE-7132: BooleanQuery sometimes assigned the wrong score when ranges of documents had only one clause matching while other ranges had more than one clause matchng\n\n(Cherry-picked from commit 5dfaf0392fcd3b7e4b529dce0cd1035b766880a7) "
        },
        {
            "id": "comment-15334282",
            "author": "ASF subversion and git services",
            "date": "2016-06-16T17:48:21+0000",
            "content": "Commit 4f6bddefe3310e0361c9b57fd522781d82c89bb8 in lucene-solr's branch refs/heads/branch_5_5 from Steve Rowe\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=4f6bdde ]\n\nLUCENE-7132: Add 5.5.2 CHANGES entry "
        },
        {
            "id": "comment-15334283",
            "author": "ASF subversion and git services",
            "date": "2016-06-16T17:48:22+0000",
            "content": "Commit 707bcc9b3bdae7b2bb2b9a7d9e30e1aa348587cb in lucene-solr's branch refs/heads/branch_5x from Steve Rowe\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=707bcc9b ]\n\nLUCENE-7132: BooleanQuery sometimes assigned the wrong score when ranges of documents had only one clause matching while other ranges had more than one clause matchng\n\n(Cherry-picked from commit 5dfaf0392fcd3b7e4b529dce0cd1035b766880a7) "
        },
        {
            "id": "comment-15334284",
            "author": "ASF subversion and git services",
            "date": "2016-06-16T17:49:03+0000",
            "content": "Commit 9f513d5569db42fe10b6580e69a754b7aa05f596 in lucene-solr's branch refs/heads/branch_6_0 from Mike McCandless\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=9f513d5 ]\n\nLUCENE-7132: BooleanQuery sometimes assigned the wrong score when ranges of documents had only one clause matching while other ranges had more than one clause matchng "
        },
        {
            "id": "comment-15866802",
            "author": "Adrien Grand",
            "date": "2017-02-14T22:08:52+0000",
            "content": "Reopening to fix the fixVersion. "
        }
    ]
}