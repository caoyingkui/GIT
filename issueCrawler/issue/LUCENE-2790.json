{
    "id": "LUCENE-2790",
    "title": "IndexWriter should call MP.useCompoundFile and not LogMP.getUseCompoundFile",
    "details": {
        "labels": "",
        "priority": "Minor",
        "components": [
            "core/index"
        ],
        "type": "Improvement",
        "fix_versions": [
            "3.1",
            "4.0-ALPHA"
        ],
        "affect_versions": "None",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "Spin off from here: http://www.gossamer-threads.com/lists/lucene/java-dev/112311.\n\nI will attach a patch shortly that addresses the issue on trunk.",
    "attachments": {
        "LUCENE-2790-3x.patch": "https://issues.apache.org/jira/secure/attachment/12465373/LUCENE-2790-3x.patch",
        "LUCENE-2790.patch": "https://issues.apache.org/jira/secure/attachment/12465131/LUCENE-2790.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2010-12-02T12:32:47+0000",
            "content": "Patch applied on trunk. I took the opportunity to fix some minor Javadoc warnings as well. ",
            "author": "Shai Erera",
            "id": "comment-12966087"
        },
        {
            "date": "2010-12-02T13:04:34+0000",
            "content": "Fails addIndexesWithThreads with ConcurrentModificationException, if MergePolicy actually tries to iterate infos passed to useCompoundFile(SIS, SI). ",
            "author": "Earwin Burrfoot",
            "id": "comment-12966103"
        },
        {
            "date": "2010-12-02T13:11:17+0000",
            "content": "Check this patch out.\nIt changes useCompoundFile(SIS, SI) to respect noCFSRatio and drops useCompoundFile from OneMerge, so all decisions about using compound files now happen in a single place.\nIt also highlights the problem with your patch - when calling useCompoundFile from addIndexes, you should hold a lock, so segmentInfos won't be modified while mergePolicy inspects them. ",
            "author": "Earwin Burrfoot",
            "id": "comment-12966108"
        },
        {
            "date": "2010-12-02T13:14:12+0000",
            "content": "test-core passed for me before I uploaded the patch. Can you please post here the 'ant test' command that reproduces it?\n\nI checked who implements useCompoundFile and all I find is LogMP and NoMP, both don't iterate on the SegmentInfos. What MP did you test with?\n\nAnyway, need to take a closer look at that. So if you can paste here the 'ant test' that reproduces it, it'd be great. ",
            "author": "Shai Erera",
            "id": "comment-12966110"
        },
        {
            "date": "2010-12-02T13:19:11+0000",
            "content": "I checked who implements useCompoundFile and all I find is LogMP and NoMP, both don't iterate on the SegmentInfos. What MP did you test with?\nApply my patch, it changes LogMP to use SegmentInfos.\n\nSo if you can paste here the 'ant test' that reproduces it, it'd be great.\nant test -Dtestcase=TestAddIndexes -Dtestmethod=testAddIndexesWithThreads -Dtests.seed=5369960668186287821:331425426639083833 -Dtests.codec=randomPerField\nThe test is threaded, so it doesn't fail always. ",
            "author": "Earwin Burrfoot",
            "id": "comment-12966112"
        },
        {
            "date": "2010-12-02T13:59:05+0000",
            "content": "Patch fixes the threading issue Earwin reported, by checking whether to create the CFS in a sync block. Also, after discussing this on IRC, the code is further simplified by creating the compound file before the new segment is committed.\n\nHowever, some tests still fail on ConcurrentModException. I cannot debug it now, so am posting the patch in case someone wants to take a stab. I can continue later. To reproduce the failure:\n\nant test -Dtestcase=TestIndexWriter -Dtestmethod=testDeleteUnusedFiles -Dtests.seed=-1861905402886420424:-8896948763797565454 -Dtests.codec=randomPerField\n ",
            "author": "Shai Erera",
            "id": "comment-12966125"
        },
        {
            "date": "2010-12-02T15:46:40+0000",
            "content": "Okay, this patch fixes remaining threading issue in IW.mergeMiddle,\nand three tests that were expecting CFS segments and weren't getting ones\ndue to flush now respecting noCFSRatio and noCFSRatio default of 0.1 ",
            "author": "Earwin Burrfoot",
            "id": "comment-12966150"
        },
        {
            "date": "2010-12-02T16:46:05+0000",
            "content": "Patch looks great!\n\nMy only concern is... it looks like addIndexes(IR[]), with compound file used in the end, may fail to delete the non-compound files once the SegmentInfo is committed?  Maybe we should add a test to show the failure...\n\nI think we need to do something like this:\n\n          // delete new non cfs files directly: they were never\n          // registered with IFD\n          deleter.deleteNewFiles(merger.getMergedFiles(merge.info));\n\n ",
            "author": "Michael McCandless",
            "id": "comment-12966167"
        },
        {
            "date": "2010-12-02T17:02:21+0000",
            "content": "Hmm... something is amiss.  I hit this failure:\n\nant test -Dtestcase=TestIndexSplitter -Dtestmethod=test -Dtests.seed=5299033587626573117:-25334708766924714 -Dtests.codec=randomPerField\n\n\n\nBut it passes on trunk... ",
            "author": "Michael McCandless",
            "id": "comment-12966178"
        },
        {
            "date": "2010-12-02T17:17:23+0000",
            "content": "Fixed your test failure ",
            "author": "Earwin Burrfoot",
            "id": "comment-12966187"
        },
        {
            "date": "2010-12-02T19:51:16+0000",
            "content": "Patch looks good. All tests pass for me. Let's give it a couple more tries, to allow for random tests to catch us. It'd be good if you can try running them too. ",
            "author": "Shai Erera",
            "id": "comment-12966248"
        },
        {
            "date": "2010-12-02T21:16:41+0000",
            "content": "Shai, what about:\nMy only concern is... it looks like addIndexes(IR[]), with compound file used in the end, may fail to delete the non-compound files once the SegmentInfo is committed?\nI fixed everything else, but can't answer this question. ",
            "author": "Earwin Burrfoot",
            "id": "comment-12966285"
        },
        {
            "date": "2010-12-03T14:24:19+0000",
            "content": "Attached adds a test to TestAddIndexes w/ the fix as Mike proposed. The test fails w/o the fix and passes w/ it.\n\nAlso, I noticed that if I don't set noCFSRatio to 1.0, then the added segments are not converted to a CFS. That is because useCompoundFiles on LMP decides not to do that, because the size of the segment, which is 377 bytes, is more than 10% of the total index size, which is ... 0. I wonder if we should handle that case, or leave it as is - at some point, when more documents are added, that segment will be converted to a CFS.\n\nI think that means that the first few segments that will be flushed will remain in non CFS format. I'm fine w/ it, just making sure I understand this right. ",
            "author": "Shai Erera",
            "id": "comment-12966543"
        },
        {
            "date": "2010-12-03T14:28:33+0000",
            "content": "Same patch, only uses MockAnalyzer and not WhitespaceAnalyzer (which failed compilation from command line). ",
            "author": "Shai Erera",
            "id": "comment-12966546"
        },
        {
            "date": "2010-12-03T14:56:11+0000",
            "content": "Ok, let's commit?\n\nThere's no need to force first few commits to CFS. CFS' sole purporse is to keep number of simultaneously open files low. Not likely you gonna see frightening numbers with only a pair of segments in index.\nLater these segments are merged (and probably CFSed), so no worries. ",
            "author": "Earwin Burrfoot",
            "id": "comment-12966550"
        },
        {
            "date": "2010-12-03T15:36:31+0000",
            "content": "Ok, let's commit?\n\n+1 ",
            "author": "Michael McCandless",
            "id": "comment-12966557"
        },
        {
            "date": "2010-12-04T04:57:43+0000",
            "content": "Do you see any back-compat issues w/ back-porting it to 3x? I'm thinking about the change in behavior of useCompoundFile in LMP which now factors is noCFSRatio. However, I see that noCFSRatio is in 3x's LMP and defaults to 0.1, which already changes behavior, so I think we can apply this change to 3x as well. What do you think? ",
            "author": "Shai Erera",
            "id": "comment-12966787"
        },
        {
            "date": "2010-12-04T06:01:42+0000",
            "content": "Committed revision 1042101 to trunk.\n\nI will back port to 3x if you agree this isn't a backwards break.\n\nBTW, I did not add a CHANGES entry, because it's an internal optimization we've made to IndexWriter. Hmm .. maybe we should document the changes to LMP.useCompoundFile (that it now factors in the noCFSRatio)? ",
            "author": "Shai Erera",
            "id": "comment-12966788"
        },
        {
            "date": "2010-12-04T09:55:32+0000",
            "content": "I think we should document the change to LMP.useCompoundFile?\n\nBut: I don't consider this a backwards break.\n\nHow Lucene manages the index files is under-the-hood so we are free to change it. ",
            "author": "Michael McCandless",
            "id": "comment-12966815"
        },
        {
            "date": "2010-12-06T09:16:31+0000",
            "content": "How Lucene manages the index files is under-the-hood so we are free to change it.\n\nThat's correct. However, sadly, the backwards tests do not agree with you . Because the runtime behavior has changed, the tests fail. If you try to call LMP.setNoCFSRation, you get a NoSuchMethodError because the tests are compiled against 3.0's source, where indeed it does not exist.\n\nI'm trying to resolve it by fetching the method using reflection, but this shows another problem w/ how we maintain the backwards tests. ",
            "author": "Shai Erera",
            "id": "comment-12967127"
        },
        {
            "date": "2010-12-06T13:15:32+0000",
            "content": "Backport to 3x. Note the reflection hack I had to use to make the backwards tests run. I don't commit yet - waiting for some response about the backwards tests. If you're ok with it, I'll commit. ",
            "author": "Shai Erera",
            "id": "comment-12967181"
        },
        {
            "date": "2010-12-06T13:25:40+0000",
            "content": "I would simply disable the tests. Reflection should only be used when mock classes are used that affect thousands of tests. There are already lots of tests disabled. ",
            "author": "Uwe Schindler",
            "id": "comment-12967183"
        },
        {
            "date": "2010-12-06T14:57:28+0000",
            "content": "I don't mind disabling the tests, but I think we should discuss the bigger issue (on that thread on the mailing list). If we decide to make it a 'policy' to disable backwards tests that break due to legal changes to the API and behavior, let's at least reach a consensus. ",
            "author": "Shai Erera",
            "id": "comment-12967208"
        },
        {
            "date": "2010-12-07T09:35:03+0000",
            "content": "Committed revision 1042948 (3x)\n\nI decided to keep the reflection hack for now, until we come up w/ a better decision. One of the tests which had to be fixed is TestBackwardsCompatibility which needs to be in backwards and I don't think we can delete it, even if it's tested by 'core' as well.\n\nThanks Earwin and others for your comments and help ! ",
            "author": "Shai Erera",
            "id": "comment-12968644"
        },
        {
            "date": "2011-03-30T15:49:57+0000",
            "content": "Bulk close for 3.1 ",
            "author": "Grant Ingersoll",
            "id": "comment-13013312"
        }
    ]
}