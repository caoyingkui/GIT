{
    "id": "SOLR-11779",
    "title": "Basic long-term collection of aggregated metrics",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [
            "metrics"
        ],
        "type": "New Feature",
        "fix_versions": [
            "7.4",
            "master (8.0)"
        ],
        "affect_versions": "7.3,                                            master (8.0)",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "Tracking the key metrics over time is very helpful in understanding the cluster and user behavior.\n\nCurrently even basic metrics tracking requires setting up an external system and either polling /admin/metrics or using SolrMetricReporter-s. The advantage of this setup is that these external tools usually provide a lot of sophisticated functionality. The downside is that they don't ship out of the box with Solr and require additional admin effort to set up.\n\nSolr could collect some of the key metrics and keep their historical values in a round-robin database (eg. using RRD4j) to keep the size of the historic data constant (eg. ~64kB per metric), but at the same providing out of the box useful insights into the basic system behavior over time. This data could be persisted to the .system collection as blobs, and it could be also presented in the Admin UI as graphs.",
    "attachments": {
        "jvm-list.json": "https://issues.apache.org/jira/secure/attachment/12923531/jvm-list.json",
        "jvm.json": "https://issues.apache.org/jira/secure/attachment/12923533/jvm.json",
        "d2.png": "https://issues.apache.org/jira/secure/attachment/12923497/d2.png",
        "c2.png": "https://issues.apache.org/jira/secure/attachment/12923501/c2.png",
        "jvm-string.json": "https://issues.apache.org/jira/secure/attachment/12923532/jvm-string.json",
        "SOLR-11779.patch": "https://issues.apache.org/jira/secure/attachment/12923338/SOLR-11779.patch",
        "core.json": "https://issues.apache.org/jira/secure/attachment/12923530/core.json",
        "o1.png": "https://issues.apache.org/jira/secure/attachment/12923502/o1.png",
        "d1.png": "https://issues.apache.org/jira/secure/attachment/12923496/d1.png",
        "d3.png": "https://issues.apache.org/jira/secure/attachment/12923498/d3.png",
        "c1.png": "https://issues.apache.org/jira/secure/attachment/12923500/c1.png",
        "u1.png": "https://issues.apache.org/jira/secure/attachment/12923499/u1.png"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2018-03-16T13:17:36+0000",
            "content": "Cool. See also SOLR-8207 which is related, adding a \"nodes\" tab\u00a0to the UI. ",
            "author": "Jan H\u00f8ydahl",
            "id": "comment-16401863"
        },
        {
            "date": "2018-03-16T14:02:57+0000",
            "content": "Couldn't Solr itself hold the metrics in a natural form \u2013 one doc with time and various stats measured? \u00a0Then Solr could be queried leveraging Solr's power. \u00a0I don't know anything about RRD4j but I wonder how putting data in blobs allows for efficient analysis.\n\nBTW you may find http://www.chronix.io\u00a0interesting (Solr based). \u00a0The I saw a presentation at Apache Big Data and it was outstanding. ",
            "author": "David Smiley",
            "id": "comment-16401946"
        },
        {
            "date": "2018-03-19T19:36:34+0000",
            "content": "IMHO don't do it.\u00a0\u00a0Investing in APIs and building tools around Solr that consume\u00a0Solr metrics, events, etc. is a much better investment than keeping things self-contained.\u00a0 A platform and ecosystem it enables win over a tool that tries to do everything. ",
            "author": "Otis Gospodnetic",
            "id": "comment-16405324"
        },
        {
            "date": "2018-03-19T19:51:32+0000",
            "content": "We need this feature to understand cluster behaviour. This helps us build more sophisticated autoscaling strategies. We need historical values of only a few key metrics and this is not intended to replace or obviate proper metric stores (for which we have built extensive support through the metric reporter APIs). But even if we ignore that requirement, I think some amount of historical cluster statistics would be nice to expose as APIs and on the Solr UI without forcing people to setup external systems. ",
            "author": "Shalin Shekhar Mangar",
            "id": "comment-16405341"
        },
        {
            "date": "2018-03-19T21:18:50+0000",
            "content": "Otis Gospodnetic Is there some standard/common API for Solr to query such an external system without depending on a particular implementation?  If not I suppose a few could be coded to some internal plugin API \u2013 just one at first.  \n\nTo Otis's point, I think it's pretty reasonable to say that the \"sophisticated\" autoscaling strategies require the user to do more \u2013 like install some thingamajig.  In doing so, we keep our code base simpler? ",
            "author": "David Smiley",
            "id": "comment-16405471"
        },
        {
            "date": "2018-03-20T10:24:17+0000",
            "content": "I agree that complex metrics analytics\u00a0is definitely something outside the scope of core Solr, excellent external tools to do that already exist and I'm not proposing that we add this functionality here.\n\nAgain, the goal is to have an out-of-the-box\u00a0simple API for storing and tracking some of the key metrics, with minimum impact on cluster resources, in order to better understand the momentary and long-term cluster behavior and using it in autoscaling strategies, as well as for the purpose of basic (with the stress on \"basic\"!) diagnostics and admin UI presentation.\n\nThis would provide a good way for users to be able to report and discuss these metrics without requiring any particular setup on their part, or exposing too many details about their cluster - just take a screenshot of a graph in the admin UI.\n\nChronix looks really cool, but its functionality is overkill for this goal, and we don't actually need detailed historical data for this purpose so we're ok with the loss of resolution over time.\n\nStoring each data point as a separate SolrDocument is probably too wasteful\u00a0and it would also mean reimplementing all sampling and\u00a0consolidation algorithms that are needed for maintaining multi-resolution time-series, as well as simple graphing, all of which are already implemented in RRD4j. Individual datapoints or their ranges can be easily retrieved from RrdDb blobs and can be represented as Solr docs as needed. ",
            "author": "Andrzej Bialecki",
            "id": "comment-16406079"
        },
        {
            "date": "2018-05-14T20:19:13+0000",
            "content": "Patch that implements the collection of metrics in RRD4j databases, which are then stored in .system collection. This data can then be retrieved from new /admin/metrics/history endpoint, either as numeric data or as PNG graphs.\n\n(Note: in order to test this you need to also manually create the .system collection, which is not created by default). ",
            "author": "Andrzej Bialecki",
            "id": "comment-16474749"
        },
        {
            "date": "2018-05-15T13:20:00+0000",
            "content": "Each RRD database takes ~36kB (edit: 11kB per metric, 3 related metrics in a db) in the configuration proposed in the patch, which consists of 5 time-series:\n\n\n\t240 samples 60 sec apart (4 hours)\n\t288 samples 600 sec apart (48 hours)\n\t336 samples 1h apart (2 weeks)\n\t180 samples 4h apart (2 months)\n\t365 samples 1 day apart (1 year)\n\n\n\nI'll attach example screenshots of graphs generated using /admin/metrics/history handler. Graphs are sent as base64-encoded PNG data, so they could be directly used by the UI in a data URI like this:  data:image/png;base64,iVBORw0KG.... ",
            "author": "Andrzej Bialecki",
            "id": "comment-16475818"
        },
        {
            "date": "2018-05-15T18:24:03+0000",
            "content": "I attached also example responses for GRAPH, LIST and STRING formats. ",
            "author": "Andrzej Bialecki",
            "id": "comment-16476307"
        },
        {
            "date": "2018-05-15T20:05:27+0000",
            "content": "Updated patch with unit and integration tests. ",
            "author": "Andrzej Bialecki",
            "id": "comment-16476406"
        },
        {
            "date": "2018-05-22T20:11:38+0000",
            "content": "Updated patch:\n\n\n\tOverseer leader node now collects aggregated metrics from all nodes. Aggregation method is just addition for now, which makes sense with the default metrics that this patch collects. There's one history DB per each collection, and one for solr.jvm and solr.node representing sort of global view of the cluster.\n\tadded support for configuration via solr.xml:/solr/metrics/history or via /clusterprops.json:/metrics/history which overrides values specified in solr.xml. Currently supported config options are:\n\t\n\t\tenable - boolean, default is true: enables collection of metrics history (note that it's always possible to retrieve existing metrics history even when enable == false)\n\t\tenableReplicas - boolean, default is false: enables collection of local per-replica (core) metrics history\n\t\tenableNodes - boolean, default is false: enables collection of local node and jvm metrics history.\n\t\tcollectPeriod - int, in seconds, default is 60: metrics are collected and updated this often.\n\t\tsyncPeriod - int, in seconds, default is 60: in-memory DBs are persisted at most this often (if modified).\n\t\n\t\n\n ",
            "author": "Andrzej Bialecki",
            "id": "comment-16484495"
        },
        {
            "date": "2018-05-22T21:23:56+0000",
            "content": "Maybe it doesn't make sense in 7x to have enable=true by default? \u00a0(thus enable=false)? \u00a0Or would it be completely benign so no big deal? \u00a0Would an existing collection suddenly start getting metrics collected for it? ",
            "author": "David Smiley",
            "id": "comment-16484599"
        },
        {
            "date": "2018-05-23T07:47:27+0000",
            "content": "This is cool. Looking forward to the RefGuide part to understand the API. I can imagine fetching metrics from here for display in SOLR-8207\u00a0As I understand a call to the history API would be much cheaper than to scrape the /admin/metrics API of all nodes in real-time.\u00a0Are you planning to track GC history too, e.g. #minor/major collections or GC cpu percentage? ",
            "author": "Jan H\u00f8ydahl",
            "id": "comment-16486866"
        },
        {
            "date": "2018-05-23T10:16:32+0000",
            "content": "Maybe it doesn't make sense in 7x to have enable=true by default?\nThe way defaults are set for now it would only collect aggregated metrics history (one history db per collection, plus one for aggregated nodes and one for aggregated jvms). Considering the small memory impact of each DB (~30kB) and small CPU impact (metrics are polled every 60 sec) I'd say it's benign. But I've been wrong before ... \n\nJan H\u00f8ydahl definitely, the format of the graphs is suitable for just copy/pasting the data into an <img src=\"data:image/png;base64, .... \"/> element.\n\nTracking the history of ephemeral resources such as individual replicas and nodes is somewhat complicated due to their relatively shorter life-cycle (I know, it may sound weird if you run 3 nodes with 3 collections, but there are users running very large clusters that experience high churn). There's a config option to collect selected per-node metrics so it's possible to do so (see the patch description above). However, there's no mechanism in place yet to automatically clean up these DBs when nodes and replicas go permanently away (though we could add it as a scheduled maintenance task, there's already a predefined trigger for this). There's an API for doing this manually.\n\nThe list of metrics that are currently collected is as follows:\n\n\tCORE and COLLECTION level metrics\n\t\n\t\tQUERY./select.requests\n\t\tUPDATE./update.requests\n\t\tINDEX.sizeInBytes\n\t\tnumShards (active)\n\t\tnumReplicas (active)\n\t\n\t\n\tNODE level metrics\n\t\n\t\tCONTAINER.fs.coreRoot.usableSpace\n\t\tnumNodes\n\t\n\t\n\tJVM level metrics\n\t\n\t\tmemory.heap.used\n\t\tos.processCpuLoad\n\t\tos.systemLoadAverage\n\t\n\t\n\n\n\nCurrently one DB is created for each these groups. However, RRD4j doesn't allow adding new datasources once the DB is created, so this list is not configurable on the fly (yet - there are ways to work-around it that I'm exploring). ",
            "author": "Andrzej Bialecki",
            "id": "comment-16487032"
        },
        {
            "date": "2018-05-23T10:19:26+0000",
            "content": "Oh, and before we all get carried away, I'd like to again stress the word \"basic\" in the issue title - we don't want to put a full-blown monitoring system into Solr. ",
            "author": "Andrzej Bialecki",
            "id": "comment-16487039"
        },
        {
            "date": "2018-05-23T10:38:52+0000",
            "content": "Would an existing collection suddenly start getting metrics collected for it?\nYes. The MetricsHistoryHandler simply pulls selected metrics from all solr.core. registries on each node. ",
            "author": "Andrzej Bialecki",
            "id": "comment-16487063"
        },
        {
            "date": "2018-05-25T19:10:16+0000",
            "content": "Updated patch. Jan H\u00f8ydahl : this includes the RefGuide documentation that describes the design, configuration and REST API.\n\nIf there are no objections I'd like to commit this to master to let it bake for a while, and then merge it to branch_7x. ",
            "author": "Andrzej Bialecki",
            "id": "comment-16491174"
        },
        {
            "date": "2018-05-29T09:28:06+0000",
            "content": "Commit 6bbce38b77d5850f2d62d62fe87254e2ac8bd447 in lucene-solr's branch refs/heads/master from Andrzej Bialecki \n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=6bbce38 ]\n\nSOLR-11779: Basic long-term collection of aggregated metrics. ",
            "author": "ASF subversion and git services",
            "id": "comment-16493297"
        },
        {
            "date": "2018-05-30T15:36:38+0000",
            "content": "Commit 090159f9aa6d0285e674bcdc172386c4f4925847 in lucene-solr's branch refs/heads/branch_7x from Andrzej Bialecki \n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=090159f ]\n\nSOLR-11779: Basic long-term collection of aggregated metrics. ",
            "author": "ASF subversion and git services",
            "id": "comment-16495322"
        },
        {
            "date": "2018-05-30T15:36:39+0000",
            "content": "Commit 1676c08b73084152e0727cfd5c0e984ca4fa641d in lucene-solr's branch refs/heads/branch_7x from Andrzej Bialecki \n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=1676c08 ]\n\nSOLR-11779: Use fixed Locale for graph labels. ",
            "author": "ASF subversion and git services",
            "id": "comment-16495323"
        },
        {
            "date": "2018-05-30T15:37:40+0000",
            "content": "Commit 0e4512c23149a0c9968ccf5a49dd9e3ea01072e7 in lucene-solr's branch refs/heads/master from Andrzej Bialecki \n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=0e4512c ]\n\nSOLR-11779: Use fixed Locale for graph labels. ",
            "author": "ASF subversion and git services",
            "id": "comment-16495325"
        },
        {
            "date": "2018-06-11T10:22:47+0000",
            "content": "Commit d00f6bbfa526162ad101f8768b5ca4221a35447c in lucene-solr's branch refs/heads/branch_7x from Andrzej Bialecki\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=d00f6bb ]\n\nSOLR-11779: Improve stability of this test - use predictable timestamps and avoid sampling races. ",
            "author": "ASF subversion and git services",
            "id": "comment-16507891"
        },
        {
            "date": "2018-06-11T10:23:14+0000",
            "content": "Commit 16e0c234ed8ab75700bc7a99783f7ba40a08f9f1 in lucene-solr's branch refs/heads/master from Andrzej Bialecki\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=16e0c23 ]\n\nSOLR-11779: Improve stability of this test - use predictable timestamps and avoid sampling races. ",
            "author": "ASF subversion and git services",
            "id": "comment-16507892"
        },
        {
            "date": "2018-06-11T20:55:35+0000",
            "content": "Commit 7773bf67643a152e1d12bed253345a40ef14f0e9 in lucene-solr's branch refs/heads/master from Cassandra Targett\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=7773bf67 ]\n\nSOLR-11779: Ref Guide: minor typos; capitalize section titles; remove monospace from section titles ",
            "author": "ASF subversion and git services",
            "id": "comment-16508722"
        },
        {
            "date": "2018-06-11T20:56:16+0000",
            "content": "Commit 4505e40846fa1d560bb7e24bc794a85cd7ac9e00 in lucene-solr's branch refs/heads/branch_7x from Cassandra Targett\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=4505e40 ]\n\nSOLR-11779: Ref Guide: minor typos; capitalize section titles; remove monospace from section titles ",
            "author": "ASF subversion and git services",
            "id": "comment-16508725"
        },
        {
            "date": "2018-06-11T20:59:20+0000",
            "content": "Commit 30ed80092b789359e00b12097a5f6ed02aa1f995 in lucene-solr's branch refs/heads/branch_7_4 from Cassandra Targett\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=30ed800 ]\n\nSOLR-11779: Ref Guide: minor typos; capitalize section titles; remove monospace from section titles ",
            "author": "ASF subversion and git services",
            "id": "comment-16508731"
        },
        {
            "date": "2018-06-12T03:54:13+0000",
            "content": "I don't know if it's this issue or a related issue, but all basic tests as well as \"bin/solr start\" now throw the following exception:\n\n2018-06-12 03:45:57.146 WARN  (main) [   ] o.a.s.h.a.MetricsHistoryHandler Error querying .system collection, keeping metrics history in memory\norg.apache.solr.common.SolrException: No such core: .system\n\tat org.apache.solr.client.solrj.embedded.EmbeddedSolrServer.request(EmbeddedSolrServer.java:161) ~[solr-core-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT 7773bf67643a152e1d12bed253345a40ef14f0e9 - yonik - 2018-06-11 20:14:07]\n\tat org.apache.solr.client.solrj.SolrRequest.process(SolrRequest.java:194) ~[solr-solrj-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT 7773bf67643a152e1d12bed253345a40ef14f0e9 - yonik - 2018-06-11 20:14:12]\n\tat org.apache.solr.client.solrj.SolrClient.query(SolrClient.java:942) ~[solr-solrj-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT 7773bf67643a152e1d12bed253345a40ef14f0e9 - yonik - 2018-06-11 20:14:12]\n\tat org.apache.solr.handler.admin.MetricsHistoryHandler.checkSystemCollection(MetricsHistoryHandler.java:282) [solr-core-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT 7773bf67643a152e1d12bed253345a40ef14f0e9 - yonik - 2018-06-11 20:14:07]\n\tat org.apache.solr.handler.admin.MetricsHistoryHandler.<init>(MetricsHistoryHandler.java:235) [solr-core-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT 7773bf67643a152e1d12bed253345a40ef14f0e9 - yonik - 2018-06-11 20:14:07]\n\tat org.apache.solr.core.CoreContainer.createMetricsHistoryHandler(CoreContainer.java:780) [solr-core-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT 7773bf67643a152e1d12bed253345a40ef14f0e9 - yonik - 2018-06-11 20:14:07]\n\tat org.apache.solr.core.CoreContainer.load(CoreContainer.java:578) [solr-core-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT 7773bf67643a152e1d12bed253345a40ef14f0e9 - yonik - 2018-06-11 20:14:07]\n\tat org.apache.solr.servlet.SolrDispatchFilter.createCoreContainer(SolrDispatchFilter.java:252) [solr-core-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT 7773bf67643a152e1d12bed253345a40ef14f0e9 - yonik - 2018-06-11 20:14:07]\n\tat org.apache.solr.servlet.SolrDispatchFilter.init(SolrDispatchFilter.java:172) [solr-core-8.0.0-SNAPSHOT.jar:8.0.0-SNAPSHOT 7773bf67643a152e1d12bed253345a40ef14f0e9 - yonik - 2018-06-11 20:14:07]\n\tat org.eclipse.jetty.servlet.FilterHolder.initialize(FilterHolder.java:139) [jetty-servlet-9.4.10.v20180503.jar:9.4.10.v20180503]\n\tat org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:741) [jetty-servlet-9.4.10.v20180503.jar:9.4.10.v20180503]\n\tat org.eclipse.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:374) [jetty-servlet-9.4.10.v20180503.jar:9.4.10.v20180503]\n\tat org.eclipse.jetty.webapp.WebAppContext.startWebapp(WebAppContext.java:1497) [jetty-webapp-9.4.10.v20180503.jar:9.4.10.v20180503]\n\tat org.eclipse.jetty.webapp.WebAppContext.startContext(WebAppContext.java:1459) [jetty-webapp-9.4.10.v20180503.jar:9.4.10.v20180503]\n\tat org.eclipse.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:785) [jetty-server-9.4.10.v20180503.jar:9.4.10.v20180503]\n\tat org.eclipse.jetty.servlet.ServletContextHandler.doStart(ServletContextHandler.java:287) [jetty-servlet-9.4.10.v20180503.jar:9.4.10.v20180503]\n\tat org.eclipse.jetty.webapp.WebAppContext.doStart(WebAppContext.java:545) [jetty-webapp-9.4.10.v20180503.jar:9.4.10.v20180503]\n\tat org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68) [jetty-util-9.4.10.v20180503.jar:9.4.10.v20180503]\n\tat org.eclipse.jetty.deploy.bindings.StandardStarter.processBinding(StandardStarter.java:46) [jetty-deploy-9.4.10.v20180503.jar:9.4.10.v20180503]\n\tat org.eclipse.jetty.deploy.AppLifeCycle.runBindings(AppLifeCycle.java:192) [jetty-deploy-9.4.10.v20180503.jar:9.4.10.v20180503]\n\tat org.eclipse.jetty.deploy.DeploymentManager.requestAppGoal(DeploymentManager.java:505) [jetty-deploy-9.4.10.v20180503.jar:9.4.10.v20180503]\n\tat org.eclipse.jetty.deploy.DeploymentManager.addApp(DeploymentManager.java:151) [jetty-deploy-9.4.10.v20180503.jar:9.4.10.v20180503]\n\tat org.eclipse.jetty.deploy.providers.ScanningAppProvider.fileAdded(ScanningAppProvider.java:180) [jetty-deploy-9.4.10.v20180503.jar:9.4.10.v20180503]\n\tat org.eclipse.jetty.deploy.providers.WebAppProvider.fileAdded(WebAppProvider.java:453) [jetty-deploy-9.4.10.v20180503.jar:9.4.10.v20180503]\n\tat org.eclipse.jetty.deploy.providers.ScanningAppProvider$1.fileAdded(ScanningAppProvider.java:64) [jetty-deploy-9.4.10.v20180503.jar:9.4.10.v20180503]\n\tat org.eclipse.jetty.util.Scanner.reportAddition(Scanner.java:610) [jetty-util-9.4.10.v20180503.jar:9.4.10.v20180503]\n\tat org.eclipse.jetty.util.Scanner.reportDifferences(Scanner.java:529) [jetty-util-9.4.10.v20180503.jar:9.4.10.v20180503]\n\tat org.eclipse.jetty.util.Scanner.scan(Scanner.java:392) [jetty-util-9.4.10.v20180503.jar:9.4.10.v20180503]\n\tat org.eclipse.jetty.util.Scanner.doStart(Scanner.java:313) [jetty-util-9.4.10.v20180503.jar:9.4.10.v20180503]\n\tat org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68) [jetty-util-9.4.10.v20180503.jar:9.4.10.v20180503]\n\tat org.eclipse.jetty.deploy.providers.ScanningAppProvider.doStart(ScanningAppProvider.java:150) [jetty-deploy-9.4.10.v20180503.jar:9.4.10.v20180503]\n\tat org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68) [jetty-util-9.4.10.v20180503.jar:9.4.10.v20180503]\n\tat org.eclipse.jetty.deploy.DeploymentManager.startAppProvider(DeploymentManager.java:579) [jetty-deploy-9.4.10.v20180503.jar:9.4.10.v20180503]\n\tat org.eclipse.jetty.deploy.DeploymentManager.doStart(DeploymentManager.java:240) [jetty-deploy-9.4.10.v20180503.jar:9.4.10.v20180503]\n\tat org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68) [jetty-util-9.4.10.v20180503.jar:9.4.10.v20180503]\n\tat org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:138) [jetty-util-9.4.10.v20180503.jar:9.4.10.v20180503]\n\tat org.eclipse.jetty.server.Server.start(Server.java:419) [jetty-server-9.4.10.v20180503.jar:9.4.10.v20180503]\n\tat org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117) [jetty-util-9.4.10.v20180503.jar:9.4.10.v20180503]\n\tat org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:113) [jetty-server-9.4.10.v20180503.jar:9.4.10.v20180503]\n\tat org.eclipse.jetty.server.Server.doStart(Server.java:386) [jetty-server-9.4.10.v20180503.jar:9.4.10.v20180503]\n\tat org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68) [jetty-util-9.4.10.v20180503.jar:9.4.10.v20180503]\n\tat org.eclipse.jetty.xml.XmlConfiguration$1.run(XmlConfiguration.java:1569) [jetty-xml-9.4.10.v20180503.jar:9.4.10.v20180503]\n\tat org.eclipse.jetty.xml.XmlConfiguration$1.run(XmlConfiguration.java:1509) [jetty-xml-9.4.10.v20180503.jar:9.4.10.v20180503]\n\tat java.security.AccessController.doPrivileged(Native Method) [?:?]\n\tat org.eclipse.jetty.xml.XmlConfiguration.main(XmlConfiguration.java:1508) [jetty-xml-9.4.10.v20180503.jar:9.4.10.v20180503]\n\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]\n\tat jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:?]\n\tat jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]\n\tat java.lang.reflect.Method.invoke(Method.java:564) ~[?:?]\n\tat org.eclipse.jetty.start.Main.invokeMain(Main.java:220) [jetty-start-9.4.10.v20180503-shaded.jar:9.4.10.v20180503]\n\tat org.eclipse.jetty.start.Main.start(Main.java:486) [jetty-start-9.4.10.v20180503-shaded.jar:9.4.10.v20180503]\n\tat org.eclipse.jetty.start.Main.main(Main.java:77) [jetty-start-9.4.10.v20180503-shaded.jar:9.4.10.v20180503]\n\n ",
            "author": "Yonik Seeley",
            "id": "comment-16509136"
        },
        {
            "date": "2018-06-12T08:28:31+0000",
            "content": "Yonik Seeley this is relatively harmless, it simply means that while .system is absent the metrics history will be maintained in memory. We can probably skip logging the full stack trace. ",
            "author": "Andrzej Bialecki",
            "id": "comment-16509333"
        },
        {
            "date": "2018-06-12T08:39:30+0000",
            "content": "Commit 5598d2f882e3d5db0dd1e9e4f8462f2a002899f3 in lucene-solr's branch refs/heads/branch_7_4 from Andrzej Bialecki\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=5598d2f ]\n\nSOLR-11779: Improve stability of this test - use predictable timestamps and avoid sampling races. ",
            "author": "ASF subversion and git services",
            "id": "comment-16509339"
        },
        {
            "date": "2018-06-12T13:08:56+0000",
            "content": "I'd consider it a minor bug for our default configs to be throwing exceptions by default when nothing is wrong.\nI'd suggest that this should not be a WARN level message (and definitely shouldn't log an exception).\nThe text of the log message could be changed to remove the word Error as well, since it's not an error case.\n\nPerhaps \"No .system collection, keeping metrics history in memory\"\n\n\u00a0 ",
            "author": "Yonik Seeley",
            "id": "comment-16509609"
        },
        {
            "date": "2018-06-12T21:08:17+0000",
            "content": "Sounds good - I'll make the change shortly. ",
            "author": "Andrzej Bialecki",
            "id": "comment-16510213"
        }
    ]
}