{
    "id": "SOLR-5808",
    "title": "collections?action=SPLITSHARD running out of heap space due to large segments",
    "details": {
        "affect_versions": "4.7",
        "status": "Resolved",
        "fix_versions": [],
        "components": [
            "update"
        ],
        "type": "Bug",
        "priority": "Major",
        "labels": "",
        "resolution": "Duplicate"
    },
    "description": "This issue is related to https://issues.apache.org/jira/browse/SOLR-5214. Although memory issues due to merging have been resolved, we still run out of memory when splitting a shard containing a large segment (created by optimizing). The Lucene MultiPassIndexSplitter is able to split the index without error.",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-14014530",
            "date": "2014-05-31T05:31:48+0000",
            "content": "I just ran into this as well. A large segment on a 500M doc index (12GB heap) took down the node. I'll investigate and try to reduce the memory requirements. "
        },
        {
            "author": "Guido",
            "id": "comment-14661878",
            "date": "2015-08-07T14:14:13+0000",
            "content": "Hello, I just ran into this problem as well with Solr version 5.2.1. While you try to fix this problem, can you please confirm if the Lucene MultiPassIndexSplitter can actually be a workaround for this problem? If it can be a workaround, can you please suggest me how to manually do what the 'split shard' does by using the Lucene MultiPassIndexSplitter?\nI suppose that I need to stop ZK and Solr and then launch the split; once it finishes, restart Zk and Solr. But, for instance, since I am using the out-of-the-box composite id routing, should I set the 'seq' parameter to 'false'? And do I need to do anything to notify to Solr that the shard has been splitted in order to properly route the documents that I will add in the future (maybe by manually modifying the state.json)?\nSorry for it and I understand that this bug fix requires time, but unfortunately I cannot wait furthermore to split the shard and I am trying to find a workaround as soon as possible.\nThank you very much "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-14661992",
            "date": "2015-08-07T15:31:41+0000",
            "content": "Guido - Sadly, no. MultiPassIndexSplitter won't work for Solr because it has no idea about the sharding scheme of Solr so even if it splits the index, the documents will be in the wrong shards. Thanks for reminding me of this issue, I'll carve out some time to work on this. "
        },
        {
            "author": "Guido",
            "id": "comment-14680263",
            "date": "2015-08-10T15:35:52+0000",
            "content": "Hello. As a workaround, what if I create a replica of each shard and then I split the replicas? If the creation of the replica re-builds completely the index on the replica, then each replica will contain several segments of reduced dimensions and the shard split will not go in oom. Could it be a workaround or the creation of the replica just copies the same index keeping the same number of segments? Thanks "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-16097005",
            "date": "2017-07-21T23:50:01+0000",
            "content": "Shalin Shekhar MangarChristine Poerschke Hop in the way-back machine. Is this a duplicate of SOLR-5214 and can thus be closed? "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-16153946",
            "date": "2017-09-05T16:38:26+0000",
            "content": "this looks like a duplicate of SOLR-5214, we can reopen if it's a separate issue. "
        }
    ]
}