{
    "id": "LUCENE-2111",
    "title": "Wrapup flexible indexing",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [
            "core/index"
        ],
        "type": "Improvement",
        "fix_versions": [
            "4.0-ALPHA"
        ],
        "affect_versions": "4.0-ALPHA",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "Spinoff from LUCENE-1458.\n\nThe flex branch is in fairly good shape \u2013 all tests pass, initial search performance testing looks good, it survived several visits from the Unicode policeman \n\nBut it still has a number of nocommits, could use some more scrutiny especially on the \"emulate old API on flex index\" and vice/versa code paths, and still needs some more performance testing.  I'll do these under this issue, and we should open separate issues for other self contained fixes.\n\nThe end is in sight!",
    "attachments": {
        "LUCENE-2111.patch": "https://issues.apache.org/jira/secure/attachment/12427038/LUCENE-2111.patch",
        "LUCENE-2111_experimental.patch": "https://issues.apache.org/jira/secure/attachment/12436846/LUCENE-2111_experimental.patch",
        "LUCENE-2111_mtqNull.patch": "https://issues.apache.org/jira/secure/attachment/12438102/LUCENE-2111_mtqNull.patch",
        "LUCENE-2111-EmptyTermsEnum.patch": "https://issues.apache.org/jira/secure/attachment/12435424/LUCENE-2111-EmptyTermsEnum.patch",
        "LUCENE-2111_mtqTest.patch": "https://issues.apache.org/jira/secure/attachment/12438136/LUCENE-2111_mtqTest.patch",
        "benchUtil.py": "https://issues.apache.org/jira/secure/attachment/12439953/benchUtil.py",
        "Make2BTermsIndex.java": "https://issues.apache.org/jira/secure/attachment/12440414/Make2BTermsIndex.java",
        "flexBench.py": "https://issues.apache.org/jira/secure/attachment/12439954/flexBench.py",
        "LUCENE-2111_toString.patch": "https://issues.apache.org/jira/secure/attachment/12436857/LUCENE-2111_toString.patch",
        "LUCENE-2111_fuzzy.patch": "https://issues.apache.org/jira/secure/attachment/12435411/LUCENE-2111_fuzzy.patch",
        "flex_backwards_merge_912395.patch": "https://issues.apache.org/jira/secure/attachment/12437151/flex_backwards_merge_912395.patch",
        "LUCENE-2111_bytesRef.patch": "https://issues.apache.org/jira/secure/attachment/12436728/LUCENE-2111_bytesRef.patch",
        "flex_merge_916543.patch": "https://issues.apache.org/jira/secure/attachment/12437150/flex_merge_916543.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2009-12-03T23:48:24+0000",
            "content": "Also the current flex branch produces lots of unchecked warnings... The Generics policeman will visit them and will hopefully help fixing! ",
            "author": "Uwe Schindler",
            "id": "comment-12785648"
        },
        {
            "date": "2009-12-04T00:03:08+0000",
            "content": "The Generics policeman will visit them and will hopefully help fixing!\n\nUh-oh... I sense heavy committing in flex branch's future! ",
            "author": "Michael McCandless",
            "id": "comment-12785656"
        },
        {
            "date": "2009-12-04T02:16:31+0000",
            "content": "What would the branch name for flex indexing ?   ",
            "author": "Karthik K",
            "id": "comment-12785715"
        },
        {
            "date": "2009-12-04T08:02:08+0000",
            "content": "I Mike,\n\nmaybe I found an issue in LegacyFieldsEnum & Co:\n\n\n\tThe LegacyTermsEnum correctly seeks to the first Term/TermRef but as the deprec TermEnum still iterates after the last term, the TermsEnum returns all terms from all later fields, too. So seek() and next() should also do a field==Term.field() comparison and set SeekStatus/return value correctly.\n\tAlso (you see it because missing @Override): The new abstract Enums have no close method / not implement java.io.Closeable, so the underlying old enums are never closed by client code. Shouldn't all the enum classes not also be Closeable, even when the new Codec API current would implement these as a no-op for core classes. But maybe someone creates a codec that needs close?\n\n\n\nUh-oh... I sense heavy committing in flex branch's future!\n\nIt is not so much, mainly in code added before the final Java 1.5 switch. Should be easy to fix, will look into it in a few days. So the police inspector only has few minor complaints  ",
            "author": "Uwe Schindler",
            "id": "comment-12785809"
        },
        {
            "date": "2009-12-04T11:32:02+0000",
            "content": "What would the branch name for flex indexing ?\n\nIt's https://svn.apache.org/repos/asf/lucene/java/branches/flex_1458 ",
            "author": "Michael McCandless",
            "id": "comment-12785885"
        },
        {
            "date": "2009-12-04T13:19:19+0000",
            "content": "The LegacyTermsEnum correctly seeks to the first Term/TermRef but as the deprec TermEnum still iterates after the last term, the TermsEnum returns all terms from all later fields, too. So seek() and next() should also do a field==Term.field() comparison and set SeekStatus/return value correctly.\n\nNice catch \u2013 I'll open a new issue & fix.\n\nAlso (you see it because missing @Override): The new abstract Enums have no close method / not implement java.io.Closeable, so the underlying old enums are never closed by client code. Shouldn't all the enum classes not also be Closeable, even when the new Codec API current would implement these as a no-op for core classes. But maybe someone creates a codec that needs close?\n\nI actually intentionally left .close() out of all *Enums.\n\nFirst, to strongly bias impls from doing such costly things that close\nis necessary.  These enums are used in hotspots during searching.\n\nSecond, because for Lucene's core impls, close() is [almost?] always a\nno-op: these impls are very lightweight.\n\nThird, because in Lucene we don't consistently close the enums we\npull, today, so we have confusion (there have been posts to java-user\nabout this \u2013 \"do I need to close the TermEnum/TermDocs\").  I'd rather\nnot add a \"close\" that for all core impls is a no-op and so Lucene\ndoesn't have to call close.\n\nFourth, because it complicates our impls if we really must close\nwhenever we pull a enum \u2013 eg our Scorers pull enums today, but never\nclose them. ",
            "author": "Michael McCandless",
            "id": "comment-12785921"
        },
        {
            "date": "2009-12-05T10:22:02+0000",
            "content": "Attached patch \u2013 will commit soon.  I found a bug in the \"flex API on\nnon-flex\" layer (the preflex codec) \u2013 exposed with a new test case in\nTestBackCompat, and fixed.  Also cleaned up some nocommits, added\nindexDivisor to the loadTermsIndex API, and fixed preflex to actually\nimplement it. ",
            "author": "Michael McCandless",
            "id": "comment-12786369"
        },
        {
            "date": "2009-12-19T19:56:25+0000",
            "content": "Attached patch, which adds some nice test coverage of the back compat layers.  We still need more tests but this is a good step forward... ",
            "author": "Michael McCandless",
            "id": "comment-12792891"
        },
        {
            "date": "2009-12-20T22:51:55+0000",
            "content": "New patch attached \u2013 strengthened the back compat testing, which\nuncovered some issues in the back compat layers, that I've now\nfixed.\n\nI ran the FlexTestUtil.verifyFlexVsPreFlex on a 5M doc pre-flex\nwikipedia index, and a 1M doc flex wikipedia index, with no problems.\n\nI also ran my NRT stress test, starting from a pre-flex 5M wikipedia,\nand indexing using flex, so this is a good test of mixed pre/post flex\nsegments, with no problems.\n\nGetting closer... ",
            "author": "Michael McCandless",
            "id": "comment-12793050"
        },
        {
            "date": "2010-01-17T11:52:00+0000",
            "content": "Attached patch, changing oal.index.TermRef -> oal.util.BytesRef.\n\nI think, eventually, we should fix the various places that refer to byte slices, eg Field.get/setBinary*, Payload, UnicodeUtil.UTF8Result, IndexOutput.writeBytes, IndexInput.readBytes, to use BytesRef instead. ",
            "author": "Michael McCandless",
            "id": "comment-12801380"
        },
        {
            "date": "2010-01-19T13:35:58+0000",
            "content": "Attached patch w/ various fixes:\n\n\n\tSwitch over payloads to use BytesRef, in flex API\n\n\n\n\n\tDocsEnum.positions now returns null if no positions were indexed\n    (ie omitTFAP was set for the field).  Also fixed Phrase/SpanQuery\n    to throw IllegalStateException when run against an omitTFAP\n    field.\n\n\n\n\n\tRename PositionsConsumer.addPosition -> .add\n\n ",
            "author": "Michael McCandless",
            "id": "comment-12802249"
        },
        {
            "date": "2010-01-28T10:54:41+0000",
            "content": "Attached patch with a major reworking of some parts of flex:\n\n\n\tSimplified how the StandardTermsDictReader/Writer interacts with\n    the postings impl.  The PostingsReader for the codec is now\n    stateless, capturing all state for a given term in a dedicated\n    TermState class (which also works well w/ caching, since we needed\n    to capture state for that anyway).\n\n\n\n\n\tMerged docs & positions readers, in the codec's impl and in the\n    exposed flex API.  It was just too hairy before, with separate\n    classes for reading docs & positions.  This is a step back towards\n    current trunk API, ie, up front you ask for either a DocsEnum or a\n    DocsAndPositionsEnum.\n\n\n\n\n\tModified API semantics: if a field or term does not exist, then\n    IndexReader.termDocs/PositionsEnum may now return null (previously\n    they returned a fake empty enum).  This means more Weight.scorer()\n    may return null.\n\n\n\n\n\tI added IndexReader.getSubReaderDocBase (there is a separate jira\n    issue open for this) \u2013 this is now more important because a\n    filter can no longer guess its doc base by adding up docCount of\n    all readers it sees since if the scorer for that segment is null,\n    Filter.getDocIdSet will not be called.\n\n\n\n\n\tChanged the reuse of Docs/AndPositionsEnum to be explicit.\n    Previously the Terms or TermsEnum instance was holding a private\n    reused instance... but that was no good because typically we can\n    share the TermsEnum but cannot share postings enums.\n\n\n\n\n\tLikeways, changed the public flex reading API, so that you don't\n    separately ask for positions enum at each doc.  Instead, up front\n    you either ask for a DocsEnum or a DocsAndPositionsEnum.  This\n    matches how the current Lucene APIs work.\n\n\n\n\n\tTerms dict cache is now at the top level, not per field (this\n    matches how trunk works, ie all fields share the 1024 sized cache)\n\n\n\nI cutover all codecs to the new API... all tests pass if you switch\nthe default codec (in oal.index.codec.Codecs.getWriter) to any of the\nfour. ",
            "author": "Michael McCandless",
            "id": "comment-12805868"
        },
        {
            "date": "2010-02-09T11:43:12+0000",
            "content": "New flex patch attached:\n\n\n\tI factored out separate public Multi* (Fields, Terms, etc.) from\n    DirectoryReader, DirectoryReader.  These classes merge multiple\n    flex \"sub readers\" into a single flex API on the fly.\n\n\n\n\n\tRefactored all places that need to merge sub-readers to use this\n    API (DirectoryReader, MultiReader, SegmentMerger).  This is\n    cleaner because previously SegmentMerger had its own duplicated\n    code for doing this merging; now we have a single source for it\n    (though merging swaps in its own docs/positions enum, to remap\n    docIDs around deletions).\n\n\n\n\n\tChanged the semantics of IndexReader.fields() \u2013 for a multi\n    reader (any reader that consist of sequential sub readers),\n    fields() now throws UOE.\n\n\n\nThis is an important change with flex \u2013 the caller now bears\nresponsibility for create a MultiFields if they really need it.\n\nMy thinking is that primary places in Lucene that consume postings now\noperate per-segment, so a multi reader (Dir/MultiReader) should not\nautomatically \"join up high\" because it entails a hidden performance\nhit.  So consumers that must access the flex API at the multi reader\nlevel should be explicit about it...\n\nHowever, to make this simple, I created a sugar static methods on\nMultiFields (eg, MultiFields.getFields(IndexReader)) to easily do\nthis, and cutover places in Lucene that may need direct postings from\na multi-reader to use this method.\n\nI've updated the javadocs explaining this. ",
            "author": "Michael McCandless",
            "id": "comment-12831425"
        },
        {
            "date": "2010-02-10T04:31:33+0000",
            "content": "Mike, here is a patch for removal of fuzzy nocommits:\n\n\tremove synchronization (not necessary, history here: LUCENE-296)\n\treuse char[] rather than create Strings\n\tremove unused ctors\n\n ",
            "author": "Robert Muir",
            "id": "comment-12831856"
        },
        {
            "date": "2010-02-10T05:02:06+0000",
            "content": "btw, i benched that patch with my contrived benchmark for LUCENE-2089, wierd that flex was slower than trunk before.\nnumbers are stable across many iterations.\n\n\n\nunpatched flex\npatched flex\ntrunk\n\n\n4362ms\n3239ms\n3459ms\n\n\n\n ",
            "author": "Robert Muir",
            "id": "comment-12831865"
        },
        {
            "date": "2010-02-10T08:00:40+0000",
            "content": "Mike: I reviewed this EmptyTermsEnum in MTQ. I would leave it in, but simply make EmptyTermsEnum a singleton (which is perfectly fine, because its stateless). Returning null here makes no performance in MTQs, it only makes the code in MTQ#rewrite and MTQWF#getDocIdSet ugly. The biggest problem with returning null here is the backwards layer that must be fixed then (because it checks if getTermsEnum return null and falls back to FilteredTermEnum from trunk). If you really want null, getTermsEnum should per default (if not overriddden) throw UOE and the rewrite code should catch this UOE and only then delegate to backwards layer. ",
            "author": "Uwe Schindler",
            "id": "comment-12831901"
        },
        {
            "date": "2010-02-10T08:48:04+0000",
            "content": "Here the EmptyTermsEnum singleton patch (against flex trunk). ",
            "author": "Uwe Schindler",
            "id": "comment-12831909"
        },
        {
            "date": "2010-02-10T10:16:23+0000",
            "content": "Robert, I think flex was faster before because the previous impl of Multi*Enums was using the same Docs/AndPositionsEnums before.  This patch fixes that. ",
            "author": "Michael McCandless",
            "id": "comment-12831935"
        },
        {
            "date": "2010-02-10T11:36:19+0000",
            "content": "Updated patch for empty TermsEnum. It is now a singleton in TermsEnum class itsself. ",
            "author": "Uwe Schindler",
            "id": "comment-12831951"
        },
        {
            "date": "2010-02-10T11:44:58+0000",
            "content": "New patch looks good Uwe \u2013 thanks for re-merging! ",
            "author": "Michael McCandless",
            "id": "comment-12831957"
        },
        {
            "date": "2010-02-10T12:00:41+0000",
            "content": "Robert, I think flex was faster before because the previous impl of Multi*Enums was using the same Docs/AndPositionsEnums before. This patch fixes that.\n\nAhh, and also because your patch switches from String to char[], which should improve perf.\n\nYour patch looks good Robert!  Thanks. ",
            "author": "Michael McCandless",
            "id": "comment-12831962"
        },
        {
            "date": "2010-02-10T13:14:16+0000",
            "content": "Ahh, and also because your patch switches from String to char[], which should improve perf.\n\nactually i didnt apply your LUCENE-2111 when running the benchmark (the improvement is simply the char[]).\nthe test is now actually slightly slower now with the rest of LUCENE-2111 ",
            "author": "Robert Muir",
            "id": "comment-12831980"
        },
        {
            "date": "2010-02-23T17:55:39+0000",
            "content": "here is a rough patch, that merges BytesRef/UnicodeUtil\n\n\tadded a fn to UnicodeUtil that computes the hash as it encodes, for termshash\n\twhen doing utf16->utf8 conversion, remove an if for every character by simple allocating utf16*4\n\tsome method signatures were generalized from String -> CharSequence (i.e. so you could create a BytesRef from a StringBuilder if you want)\n\n\n\nthere are some breaks (e.g. binary api compat), but its an internal api. ",
            "author": "Robert Muir",
            "id": "comment-12837347"
        },
        {
            "date": "2010-02-23T18:24:59+0000",
            "content": "Patch looks good Robert!  Thanks \n\nWhy not just remove UTF8Result altogether?  (ie don't bother deprecating).  It's an internal API...\n\nThe new method to compute hash is great, saving the extra pass in THPF. ",
            "author": "Michael McCandless",
            "id": "comment-12837359"
        },
        {
            "date": "2010-02-23T20:51:51+0000",
            "content": "ok, i ditched UTF8 result entirely, committed in revision 915511 ",
            "author": "Robert Muir",
            "id": "comment-12837438"
        },
        {
            "date": "2010-02-24T13:27:09+0000",
            "content": "attached is a patch that changes various exposed apis to use @lucene.experimental\n\ni didnt mess with IndexFileNames as there is an open issue about it right now. ",
            "author": "Robert Muir",
            "id": "comment-12837781"
        },
        {
            "date": "2010-02-24T14:09:09+0000",
            "content": "these tags are added in revision 915791. ",
            "author": "Robert Muir",
            "id": "comment-12837795"
        },
        {
            "date": "2010-02-24T16:06:10+0000",
            "content": "Attached patch, fixing some more nocommits, and renaming BytesRef.toString -> BytesRef.utf8ToString. ",
            "author": "Michael McCandless",
            "id": "comment-12837845"
        },
        {
            "date": "2010-02-24T16:43:06+0000",
            "content": "Here is a few more toString -> utf8ToString.\nwill look at the backwards tests now ",
            "author": "Robert Muir",
            "id": "comment-12837870"
        },
        {
            "date": "2010-02-25T20:08:03+0000",
            "content": "a few more easy nocommits ",
            "author": "Robert Muir",
            "id": "comment-12838515"
        },
        {
            "date": "2010-02-25T23:52:40+0000",
            "content": "Attached patch, fixes flex APIs to not return null (instead return .EMPTY objects). ",
            "author": "Michael McCandless",
            "id": "comment-12838619"
        },
        {
            "date": "2010-02-26T09:24:38+0000",
            "content": "patch for review of flex merge ",
            "author": "Robert Muir",
            "id": "comment-12838780"
        },
        {
            "date": "2010-02-26T09:25:04+0000",
            "content": "patch for review, backwards tests merge to flex ",
            "author": "Robert Muir",
            "id": "comment-12838782"
        },
        {
            "date": "2010-03-06T12:49:56+0000",
            "content": "Cuts over to returning .EMPTY instead of null when requesting enums.\n\nAlso disallows Multi/DirReader.getDeletedDocs in favor of static convenience method MultiFields.getDeletedDocs.\n\nBut... we now need a way to determine that a codec does not store positions.  I [illegally, adding nocommits] had to add a few places where I check the return result against .EMPTY. ",
            "author": "Michael McCandless",
            "id": "comment-12842253"
        },
        {
            "date": "2010-03-06T12:57:06+0000",
            "content": "But... we now need a way to determine that a codec does not store positions.\n\nThinking more about this... I think we should switch back to a null return from .docsAndPositionsEnum if the codec doesn't support positions.  We only return .EMPTY if the enum is really just empty. ",
            "author": "Michael McCandless",
            "id": "comment-12842255"
        },
        {
            "date": "2010-03-06T18:10:53+0000",
            "content": "Patch for MTQ to not use null in getTermsEnum for backwards compat, \nso null can have some other meaning. Instead it uses VirtualMethod, \nwith the default implementatinos throwing UOE. ",
            "author": "Robert Muir",
            "id": "comment-12842285"
        },
        {
            "date": "2010-03-07T14:34:25+0000",
            "content": "Uwe asked for a test for the MTQ back compat... attached is one.\nI think it looks kinda dumb but if its useful, I'll commit it. ",
            "author": "Robert Muir",
            "id": "comment-12842431"
        },
        {
            "date": "2010-03-07T16:10:03+0000",
            "content": "Changed .iterator() to never return null, MTQ.getTermsEnum() to never return null, but IR.fields() and Fields.terms(String field), and .docs/.docsAndPositions can return null.\n\nAlso whittled down more nocommits \u2013 down to 53 now! ",
            "author": "Michael McCandless",
            "id": "comment-12842445"
        },
        {
            "date": "2010-03-07T16:23:53+0000",
            "content": "Back compat test for MTQ looks good Robert... thanks! ",
            "author": "Michael McCandless",
            "id": "comment-12842447"
        },
        {
            "date": "2010-03-07T23:26:22+0000",
            "content": "Down to 15 nocommits! ",
            "author": "Michael McCandless",
            "id": "comment-12842504"
        },
        {
            "date": "2010-03-08T00:43:21+0000",
            "content": "Same patch, just fixes the Java 1.6 only changes (adding @Override to interface). ",
            "author": "Michael McCandless",
            "id": "comment-12842513"
        },
        {
            "date": "2010-03-08T11:52:46+0000",
            "content": "New rev, just a few changes:\n\n\n\tRename BytesRef.toBytesString -> toString (thanks Robert!)\n\n\n\n\n\tNo more BytesRef.Comparator \u2013 just use java.util.Comparator<BytesRef> (thanks Uwe!)\n\n\n\n\n\tUse Set<String> not Collection<String> when asking Codec for its files/extensions (thanks Mark!)\n\n\n\nI'll commit (on flex branch) sometime today.  Making me nervous carrying such a large patch... ",
            "author": "Michael McCandless",
            "id": "comment-12842634"
        },
        {
            "date": "2010-03-10T21:15:18+0000",
            "content": "More nocommit reductions and other fixes:\n\n\n\tRename Codecs -> CodecProvider\n\n\n\n\n\tTry to optimize flex API on pre-flex index (don't clone the\n    SegmentTermEnum during seek)\n\n\n\n\n\tUse SegmentReadState class when getting fieldsProducer (matches\n    SegmentWriteState)\n\n\n\n\n\tCuts over to a new bulk-read API on DocsEnum that's designed to\n    let int block codecs provide direct access to the int[] they have\n    (saves extra copy).\n\n\n\n\n\tDown to 9 nocommits!!\n\n ",
            "author": "Michael McCandless",
            "id": "comment-12843774"
        },
        {
            "date": "2010-03-10T21:35:34+0000",
            "content": "Forgot to add SegmentReadState.java ",
            "author": "Michael McCandless",
            "id": "comment-12843782"
        },
        {
            "date": "2010-03-10T22:20:41+0000",
            "content": "Also adds reuse to pre-flex API when getting a new TermsEnum. ",
            "author": "Michael McCandless",
            "id": "comment-12843800"
        },
        {
            "date": "2010-03-19T22:29:27+0000",
            "content": "Thanks Shai! ",
            "author": "Michael McCandless",
            "id": "comment-12847619"
        },
        {
            "date": "2010-03-19T22:33:56+0000",
            "content": "Duh \u2013 wrong issue!  I only wish....  ",
            "author": "Michael McCandless",
            "id": "comment-12847622"
        },
        {
            "date": "2010-03-24T09:37:56+0000",
            "content": "Attached patch, eliminating all remaining nocommits on flex branch!  I turned most of them into TODOs  ",
            "author": "Michael McCandless",
            "id": "comment-12849126"
        },
        {
            "date": "2010-03-27T09:38:08+0000",
            "content": "I'm benchmarking flex vs trunk, but uncovered a strange performance loss with WildcardQuery.  I'm attaching the python wrapper around contrib/benchmark that I'm using.  Hopefully this is something silly...\n\nYou have to edit flexBench.py, specificaly the TRUNK_DIR and FLEX_DIR must point to the .../contrib/benchmark of each source area, and you have to edit the WIKI_LINE_FILE and/or WIKI_FILE (I think WIKI_LINE_FILE can be None in which case it should (but I haven't tested recently!) fallback to parsing the .xml.bz2 wikipedia export).\n\nI'll first build an index of the first 5M wikipedia docs, once for flex and once for trunk, and then run the test queries.  It also tests the \"flex API on trunk index\" case, to test perf of the flex emulation layer... this layer is looking a bit slowish now but I'm not sure how much we can do to speed it up...\n\nRun like this:\n\npython -u flexBench.py -run test\n\n\n\nI have it set to only test only the wildcard query uni*t right now... and I'm getting this result:\n\nJAVA:\njava version \"1.6.0_17\"\nJava(TM) SE Runtime Environment (build 1.6.0_17-b04)\nJava HotSpot(TM) 64-Bit Server VM (build 14.3-b01, mixed mode)\n\n\nOS:\nLinux centos 2.6.18-164.6.1.el5 #1 SMP Tue Nov 3 16:12:36 EST 2009 x86_64 x86_64 x86_64 GNU/Linux\n\nIndex /x/lucene/flex.work.wiki.nd5M already exists...\nIndex /x/lucene/trunk.work.wiki.nd5M already exists...\nIndex /x/lucene/flex.work.random.nd5M already exists...\nIndex /x/lucene/trunk.work.random.nd5M already exists...\n\nRUN: source=wiki query=un*t sort=None\n  run trunk...\n    cd /root/src/clean/lucene/contrib/benchmark\n    log: /root/src/clean/lucene/contrib/benchmark/logs/trunk.0\n    62.49 QPS\n  run flex on trunk index...\n    cd /root/src/flex.clean/contrib/benchmark\n    log: /root/src/flex.clean/contrib/benchmark/logs/flexOnTrunk.1\n    25.87 QPS [-58.6% worse]\n  run flex on flex index...\n    cd /root/src/flex.clean/contrib/benchmark\n    log: /root/src/flex.clean/contrib/benchmark/logs/flexOnFlex.2\n    39.30 QPS [-37.1% worse]\n  124623 hits\n\n\n\nOther queries I've tested look OK so far... ",
            "author": "Michael McCandless",
            "id": "comment-12850499"
        },
        {
            "date": "2010-03-30T12:36:03+0000",
            "content": "Towards wrapping up flex, I ran a set of tests to benchmark flex's\nsearch performance vs trunk.\n\nAll tests are on a 5M doc Wikipedia index, best qps of 5 runs where\neach run runs the query for 5.0 seconds.  Env is:\n\nJAVA:\njava version \"1.6.0_17\"\nJava(TM) SE Runtime Environment (build 1.6.0_17-b04)\nJava HotSpot(TM) 64-Bit Server VM (build 14.3-b01, mixed mode)\n\nOS:\nLinux centos 2.6.18-164.6.1.el5 #1 SMP Tue Nov 3 16:12:36 EST 2009 x86_64 x86_64 x86_64 GNU/Linux\n\n\n\nFirst table compares trunk against \"flex on flex\", ie, a flex index\n(fully reindexed after upgrading to flex):\n\n\n\n\nQuery\nTot hits\nSort\nQPS trunk\nQPS new\nPct change\n\n\n1\n591225\n\u00a0\n68.36\n80.64\n18.0%\n\n\n\u00a0\n\u00a0\ntitle\n64.12\n68.53\n6.9%\n\n\n1 OR 2\n953081\n\u00a0\n19.35\n20.80\n7.5%\n\n\n\u00a0\n\u00a0\ntitle\n16.50\n17.48\n5.9%\n\n\n1 OR 2 OR 3\n1131679\n\u00a0\n14.37\n15.50\n7.9%\n\n\n\u00a0\n\u00a0\ntitle\n12.42\n13.26\n6.8%\n\n\n1 OR 2 OR 3 OR 4\n1266805\n\u00a0\n10.94\n12.76\n16.6%\n\n\n\u00a0\n\u00a0\ntitle\n10.36\n11.05\n6.7%\n\n\n1 AND 2\n239303\n\u00a0\n21.19\n22.32\n5.3%\n\n\n\u00a0\n\u00a0\ntitle\n22.77\n24.25\n6.5%\n\n\n1 AND 2 AND 3\n109513\n\u00a0\n18.83\n19.17\n1.8%\n\n\n\u00a0\n\u00a0\ntitle\n19.30\n20.06\n3.9%\n\n\n1 AND 2 AND 3 AND 4\n60795\n\u00a0\n16.21\n17.51\n8.0%\n\n\n\u00a0\n\u00a0\ntitle\n16.75\n18.29\n9.2%\n\n\n\"united states\"\n528845\n\u00a0\n7.54\n8.54\n13.3%\n\n\n\u00a0\n\u00a0\ntitle\n7.36\n8.14\n10.6%\n\n\n\"united states of america\"\n12144\n\u00a0\n20.64\n21.48\n4.1%\n\n\n\u00a0\n\u00a0\ntitle\n20.45\n21.06\n3.0%\n\n\nun*\n2250238\n\u00a0\n9.31\n11.54\n24.0%\n\n\n\u00a0\n\u00a0\ntitle\n8.42\n10.96\n30.2%\n\n\n*ent\n2482701\n\u00a0\n0.32\n0.92\n187.5%\n\n\n\u00a0\n\u00a0\ntitle\n0.32\n0.91\n184.4%\n\n\nu*t\n169192\n\u00a0\n18.53\n47.97\n158.9%\n\n\n\u00a0\n\u00a0\ntitle\n17.26\n40.10\n132.3%\n\n\nuni*\n1308332\n\u00a0\n18.54\n23.49\n26.7%\n\n\n\u00a0\n\u00a0\ntitle\n16.28\n20.02\n23.0%\n\n\nun*t\n124623\n\u00a0\n62.13\n105.23\n69.4%\n\n\n\u00a0\n\u00a0\ntitle\n50.38\n74.99\n48.8%\n\n\n?t\n554722\n\u00a0\n0.51\n29.31\n5647.1%\n\n\n\u00a0\n\u00a0\ntitle\n0.51\n26.25\n5047.1%\n\n\n??t\n1605437\n\u00a0\n0.60\n6.69\n1015.0%\n\n\n\u00a0\n\u00a0\ntitle\n0.60\n6.22\n936.7%\n\n\n???t\n3100067\n\u00a0\n0.54\n1.92\n255.6%\n\n\n\u00a0\n\u00a0\ntitle\n0.53\n1.89\n256.6%\n\n\n????t\n2973045\n\u00a0\n0.51\n0.71\n39.2%\n\n\n\u00a0\n\u00a0\ntitle\n0.51\n0.70\n37.3%\n\n\n?????t\n2323871\n\u00a0\n0.51\n0.39\n-23.5%\n\n\n\u00a0\n\u00a0\ntitle\n0.50\n0.39\n-22.0%\n\n\n??????t\n2459025\n\u00a0\n0.49\n0.31\n-36.7%\n\n\n\u00a0\n\u00a0\ntitle\n0.48\n0.15\n-68.7%\n\n\nun?t\n86664\n\u00a0\n92.45\n241.46\n161.2%\n\n\n\u00a0\n\u00a0\ntitle\n72.59\n151.28\n108.4%\n\n\nun??t\n2860\n\u00a0\n222.11\n408.52\n83.9%\n\n\n\u00a0\n\u00a0\ntitle\n220.91\n405.84\n83.7%\n\n\nun???t\n5828\n\u00a0\n117.38\n99.64\n-15.1%\n\n\n\u00a0\n\u00a0\ntitle\n111.47\n98.64\n-11.5%\n\n\nun????t\n1426\n\u00a0\n207.03\n100.60\n-51.4%\n\n\n\u00a0\n\u00a0\ntitle\n207.23\n101.36\n-51.1%\n\n\nunited~0.5\n872873\n\u00a0\n0.35\n0.31\n-11.4%\n\n\n\u00a0\n\u00a0\ntitle\n0.35\n0.31\n-11.4%\n\n\nunited~0.6\n764041\n\u00a0\n0.46\n5.22\n1034.8%\n\n\n\u00a0\n\u00a0\ntitle\n0.45\n5.00\n1011.1%\n\n\nunited~0.7\n695756\n\u00a0\n0.59\n21.19\n3491.5%\n\n\n\u00a0\n\u00a0\ntitle\n0.60\n19.10\n3083.3%\n\n\nunited~0.8\n693134\n\u00a0\n0.59\n21.44\n3533.9%\n\n\n\u00a0\n\u00a0\ntitle\n0.58\n19.55\n3270.7%\n\n\nunited~0.9\n692299\n\u00a0\n57.06\n67.80\n18.8%\n\n\n\u00a0\n\u00a0\ntitle\n55.28\n57.87\n4.7%\n\n\n\n\n\nI also ran the same queries through, but this time using the trunk\n(pre-flex) index with flex, ie to perf test the \"flex on pre-flex\"\nemulation layer.  This is the initial experience users will see if\nthey upgrade to flex but don't reindex:\n\n\n\n\nQuery\nTot hits\nSort\nQPS trunk\nQPS new\nPct change\n\n\n1\n591225\n\u00a0\n68.36\n66.91\n-2.1%\n\n\n\u00a0\n\u00a0\ntitle\n64.12\n58.47\n-8.8%\n\n\n1 OR 2\n953081\n\u00a0\n19.35\n19.06\n-1.5%\n\n\n\u00a0\n\u00a0\ntitle\n16.50\n16.03\n-2.8%\n\n\n1 OR 2 OR 3\n1131679\n\u00a0\n14.37\n14.14\n-1.6%\n\n\n\u00a0\n\u00a0\ntitle\n12.42\n12.11\n-2.5%\n\n\n1 OR 2 OR 3 OR 4\n1266805\n\u00a0\n10.94\n11.61\n6.1%\n\n\n\u00a0\n\u00a0\ntitle\n10.36\n10.04\n-3.1%\n\n\n1 AND 2\n239303\n\u00a0\n21.19\n21.12\n-0.3%\n\n\n\u00a0\n\u00a0\ntitle\n22.77\n22.46\n-1.4%\n\n\n1 AND 2 AND 3\n109513\n\u00a0\n18.83\n18.81\n-0.1%\n\n\n\u00a0\n\u00a0\ntitle\n19.30\n19.29\n-0.1%\n\n\n1 AND 2 AND 3 AND 4\n60795\n\u00a0\n16.21\n17.18\n6.0%\n\n\n\u00a0\n\u00a0\ntitle\n16.75\n17.46\n4.2%\n\n\n\"united states\"\n528845\n\u00a0\n7.54\n7.63\n1.2%\n\n\n\u00a0\n\u00a0\ntitle\n7.36\n7.12\n-3.3%\n\n\n\"united states of america\"\n12144\n\u00a0\n20.64\n19.33\n-6.3%\n\n\n\u00a0\n\u00a0\ntitle\n20.45\n19.50\n-4.6%\n\n\nun*\n2250238\n\u00a0\n9.31\n9.79\n5.2%\n\n\n\u00a0\n\u00a0\ntitle\n8.42\n9.65\n14.6%\n\n\n*ent\n2482701\n\u00a0\n0.32\n0.45\n40.6%\n\n\n\u00a0\n\u00a0\ntitle\n0.32\n0.45\n40.6%\n\n\nu*t\n169192\n\u00a0\n18.53\n24.75\n33.6%\n\n\n\u00a0\n\u00a0\ntitle\n17.26\n21.96\n27.2%\n\n\nuni*\n1308332\n\u00a0\n18.54\n19.39\n4.6%\n\n\n\u00a0\n\u00a0\ntitle\n16.28\n15.86\n-2.6%\n\n\nun*t\n124623\n\u00a0\n62.13\n59.73\n-3.9%\n\n\n\u00a0\n\u00a0\ntitle\n50.38\n48.51\n-3.7%\n\n\n?t\n554722\n\u00a0\n0.51\n23.65\n4537.3%\n\n\n\u00a0\n\u00a0\ntitle\n0.51\n21.42\n4100.0%\n\n\n??t\n1605437\n\u00a0\n0.60\n5.13\n755.0%\n\n\n\u00a0\n\u00a0\ntitle\n0.60\n4.61\n668.3%\n\n\n???t\n3100067\n\u00a0\n0.54\n1.28\n137.0%\n\n\n\u00a0\n\u00a0\ntitle\n0.53\n1.24\n134.0%\n\n\n????t\n2973045\n\u00a0\n0.51\n0.55\n7.8%\n\n\n\u00a0\n\u00a0\ntitle\n0.51\n0.54\n5.9%\n\n\n?????t\n2323871\n\u00a0\n0.51\n0.29\n-43.1%\n\n\n\u00a0\n\u00a0\ntitle\n0.50\n0.29\n-42.0%\n\n\n??????t\n2459025\n\u00a0\n0.49\n0.18\n-63.3%\n\n\n\u00a0\n\u00a0\ntitle\n0.48\n0.21\n-56.2%\n\n\nun?t\n86664\n\u00a0\n92.45\n202.48\n119.0%\n\n\n\u00a0\n\u00a0\ntitle\n72.59\n134.55\n85.4%\n\n\nun??t\n2860\n\u00a0\n222.11\n187.05\n-15.8%\n\n\n\u00a0\n\u00a0\ntitle\n220.91\n186.81\n-15.4%\n\n\nun???t\n5828\n\u00a0\n117.38\n69.30\n-41.0%\n\n\n\u00a0\n\u00a0\ntitle\n111.47\n68.59\n-38.5%\n\n\nun????t\n1426\n\u00a0\n207.03\n60.98\n-70.5%\n\n\n\u00a0\n\u00a0\ntitle\n207.23\n60.62\n-70.7%\n\n\nunited~0.5\n872873\n\u00a0\n0.35\n0.23\n-34.3%\n\n\n\u00a0\n\u00a0\ntitle\n0.35\n0.23\n-34.3%\n\n\nunited~0.6\n764041\n\u00a0\n0.46\n3.84\n734.8%\n\n\n\u00a0\n\u00a0\ntitle\n0.45\n3.76\n735.6%\n\n\nunited~0.7\n695756\n\u00a0\n0.59\n17.45\n2857.6%\n\n\n\u00a0\n\u00a0\ntitle\n0.60\n15.53\n2488.3%\n\n\nunited~0.8\n693134\n\u00a0\n0.59\n17.56\n2876.3%\n\n\n\u00a0\n\u00a0\ntitle\n0.58\n15.97\n2653.4%\n\n\nunited~0.9\n692299\n\u00a0\n57.06\n56.02\n-1.8%\n\n\n\u00a0\n\u00a0\ntitle\n55.28\n49.26\n-10.9%\n\n\n\n\n\nThere are alot of numbers to absorb... but here's my take:\n\n\n\tFlex is generally faster.\n\n\n\n\n\tFuzzy queries and certain wildcard queries (using AutomatonQuery)\n    are insanely faster.\n\n\n\n\n\tThere are certain specific wildcard corner cases where we are\n    slower, but these are likely rarely used in practice (many ?'s\n    followed by a suffix).\n\n\n\n\n\tFlex API on a trunk index does take a perf hit but it looks contained enough\n    that we don't need to spend any time optimizing that emulation layer...\n\n\n\nI also ran an indexing test (index first 10M docs of wikipedia) and\nflex and trunk had similar times.\n\nI think net/net we are good to land flex! ",
            "author": "Michael McCandless",
            "id": "comment-12851372"
        },
        {
            "date": "2010-03-30T13:56:35+0000",
            "content": "I think net/net we are good to land flex!\n\n+1. The tests have been passing for some time now, and Solr tests pass too. \n\nIt would be nice to look at merging flex into the trunk soon so that it gets more exposure. ",
            "author": "Robert Muir",
            "id": "comment-12851400"
        },
        {
            "date": "2010-03-30T15:31:03+0000",
            "content": "Small fixes for flex \u2013 fixes SpanTermQuerty to throw exc if it's run on a field that omitTFAPs (matches PhraseQuery), fixes all jdoc warnings, spells out back compat breaks in changes. ",
            "author": "Michael McCandless",
            "id": "comment-12851437"
        },
        {
            "date": "2010-03-30T16:18:57+0000",
            "content": "Flex is generally faster.\n\nAwesome work!  What changes make those queries run faster with the default codec?  Mostly terms dict changes and automaton for fuzzy/wildcard?\n\nHow's the indexing performance?\n\n\nI think net/net we are good to land flex!\n\n+1!  Even if there are still small things to change/fix I think it makes sense to merge with trunk now. ",
            "author": "Michael Busch",
            "id": "comment-12851452"
        },
        {
            "date": "2010-03-30T16:33:14+0000",
            "content": "\nThere are certain specific wildcard corner cases where we are\nslower, but these are likely rarely used in practice (many ?'s\nfollowed by a suffix).\n\nI think it would be good to fix this in the future, but I certainly think its a rare case.\nThe problem is similar to where an SQL engine decides to just table-scan instead\nof using a btree index... In this case we are trying to be too smart and just seek\nto the correct term based on the query instead of scanning, but this causes too\nmany seeks.\n\nAt the same time, you have to be careful or you make the wrong decision\nand give O(n) performance instead of O(log n). \n\nIn my opinion it would be better to think in the future how we can improve lucene\nin the following ways:\n\n\tThe term dictionary should be more \"DFA-friendly\", e.g. the whole concept of TermsEnum is wrong,\nlinear enumeration of terms is inefficient for any big index. we should get away from it.\n\tInstead it would be nice to think of the index like an FST, and instead of enumerating things and filtering them,\nwe provide a DFA and enumerate the transduced results.\n\tWe need to eliminate the UTF-8/UTF-16 impedence mismatch which causes so much\ncomplication and unnecessary hairy code today.\n\n\n\nAll this being said, I think flex is a great move forward for multitermqueries, at least\nwe have a seeking-friendly API! One step at a time.\n ",
            "author": "Robert Muir",
            "id": "comment-12851456"
        },
        {
            "date": "2010-03-30T18:58:36+0000",
            "content": "Awesome work! What changes make those queries run faster with the default codec? Mostly terms dict changes and automaton for fuzzy/wildcard?\n\nThe AutomatonQuery (for fuzzy/wildcard) gives the biggest gains   Other MTQs (prefix) see gains I think because of more efficient terms enum.  The TermQuery speedup surprises me \u2013 that can't be a terms dict thing (just one lookup); i'm not sure offhand why it's faster.  That code is not very different than trunk.\n\nHow's the indexing performance?\n\nUnchanged \u2013 I indexed first 10M docs of wikipedia and the times were nearly identical. ",
            "author": "Michael McCandless",
            "id": "comment-12851508"
        },
        {
            "date": "2010-03-30T19:01:06+0000",
            "content": "\nThe term dictionary should be more \"DFA-friendly\", e.g. the whole concept of TermsEnum is wrong,\nlinear enumeration of terms is inefficient for any big index. we should get away from it.\nInstead it would be nice to think of the index like an FST, and instead of enumerating things and filtering them,\nwe provide a DFA and enumerate the transduced results.\nWe need to eliminate the UTF-8/UTF-16 impedence mismatch which causes so much\ncomplication and unnecessary hairy code today.\n\n+1 \u2013 we already see these limitations now in making AutomatonQuery consume the straight enum.  If we flipped the problem around (you pass a DFA to the codec and it does the intersection & enums the result), and we used byte-based DFAs, I think we'd get a good speedup. ",
            "author": "Michael McCandless",
            "id": "comment-12851511"
        },
        {
            "date": "2010-03-31T22:44:01+0000",
            "content": "Flex has some trouble making > 2B terms \u2013 attached patch creates such an index.  I'm still getting to the bottom of it... ",
            "author": "Michael McCandless",
            "id": "comment-12852151"
        },
        {
            "date": "2010-04-01T10:09:29+0000",
            "content": "Patch fixes standard codec's terms dict to handle > 2B terms; I also strengthened CheckIndex to verify that .ord() of the TermsEnum always returns the right result, for codecs that implement .ord.  I'll commit shortly... ",
            "author": "Michael McCandless",
            "id": "comment-12852313"
        }
    ]
}