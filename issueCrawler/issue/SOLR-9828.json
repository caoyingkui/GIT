{
    "id": "SOLR-9828",
    "title": "Very long young generation stop the world GC pause",
    "details": {
        "components": [],
        "type": "Bug",
        "labels": "",
        "fix_versions": [],
        "affect_versions": "5.3.2",
        "status": "Closed",
        "resolution": "Invalid",
        "priority": "Major"
    },
    "description": "We are using oracle jdk8u92 64bit.\nThe jvm memory related options:\n-Xms32768m \n-Xmx32768m \n-XX:+HeapDumpOnOutOfMemoryError \n-XX:HeapDumpPath=/mnt/solrdata1/log \n-XX:+UseG1GC \n-XX:+PerfDisableSharedMem \n-XX:+ParallelRefProcEnabled \n-XX:G1HeapRegionSize=8m \n-XX:MaxGCPauseMillis=100 \n-XX:InitiatingHeapOccupancyPercent=35 \n-XX:+AggressiveOpts \n-XX:+AlwaysPreTouch \n-XX:ConcGCThreads=16 \n-XX:ParallelGCThreads=18 \n-XX:+HeapDumpOnOutOfMemoryError \n-XX:HeapDumpPath=/mnt/solrdata1/log \n-verbose:gc \n-XX:+PrintHeapAtGC \n-XX:+PrintGCDetails \n-XX:+PrintGCDateStamps \n-XX:+PrintGCTimeStamps \n-XX:+PrintTenuringDistribution \n-XX:+PrintGCApplicationStoppedTime \n-Xloggc:/mnt/solrdata1/log/solr_gc.log\n\nIt usually works fine. But recently we met very long stop the world young generation GC pause. Some snippets of the gc log are as below:\n2016-11-22T20:43:16.436+0000: 2942054.483: Total time for which application threads were stopped: 0.0005510 seconds, Stopping threads took: 0.0000894 seconds\n2016-11-22T20:43:16.463+0000: 2942054.509: Total time for which application threads were stopped: 0.0029195 seconds, Stopping threads took: 0.0000804 seconds\n{Heap before GC invocations=2246 (full 0):\n garbage-first heap   total 26673152K, used 4683965K [0x00007f0c10000000, 0x00007f0c108065c0, 0x00007f1410000000)\n  region size 8192K, 162 young (1327104K), 17 survivors (139264K)\n Metaspace       used 56487K, capacity 57092K, committed 58368K, reserved 59392K\n2016-11-22T20:43:16.555+0000: 2942054.602: [GC pause (G1 Evacuation Pause) (young)\nDesired survivor size 88080384 bytes, new threshold 15 (max 15)\n\n\tage   1:   28176280 bytes,   28176280 total\n\tage   2:    5632480 bytes,   33808760 total\n\tage   3:    9719072 bytes,   43527832 total\n\tage   4:    6219408 bytes,   49747240 total\n\tage   5:    4465544 bytes,   54212784 total\n\tage   6:    3417168 bytes,   57629952 total\n\tage   7:    5343072 bytes,   62973024 total\n\tage   8:    2784808 bytes,   65757832 total\n\tage   9:    6538056 bytes,   72295888 total\n\tage  10:    6368016 bytes,   78663904 total\n\tage  11:     695216 bytes,   79359120 total\n, 97.2044320 secs]\n   [Parallel Time: 19.8 ms, GC Workers: 18]\n      [GC Worker Start (ms): Min: 2942054602.1, Avg: 2942054604.6, Max: 2942054612.7, Diff: 10.6]\n      [Ext Root Scanning (ms): Min: 0.0, Avg: 2.4, Max: 6.7, Diff: 6.7, Sum: 43.5]\n      [Update RS (ms): Min: 0.0, Avg: 3.0, Max: 15.9, Diff: 15.9, Sum: 54.0]\n         [Processed Buffers: Min: 0, Avg: 10.7, Max: 39, Diff: 39, Sum: 192]\n      [Scan RS (ms): Min: 0.0, Avg: 0.0, Max: 0.1, Diff: 0.1, Sum: 0.6]\n      [Code Root Scanning (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0]\n      [Object Copy (ms): Min: 0.1, Avg: 9.2, Max: 13.4, Diff: 13.3, Sum: 165.9]\n      [Termination (ms): Min: 0.0, Avg: 2.5, Max: 2.7, Diff: 2.7, Sum: 44.1]\n         [Termination Attempts: Min: 1, Avg: 1.5, Max: 3, Diff: 2, Sum: 27]\n      [GC Worker Other (ms): Min: 0.0, Avg: 0.0, Max: 0.1, Diff: 0.0, Sum: 0.6]\n      [GC Worker Total (ms): Min: 9.0, Avg: 17.1, Max: 19.7, Diff: 10.6, Sum: 308.7]\n      [GC Worker End (ms): Min: 2942054621.8, Avg: 2942054621.8, Max: 2942054621.8, Diff: 0.0]\n   [Code Root Fixup: 0.1 ms]\n   [Code Root Purge: 0.0 ms]\n   [Clear CT: 0.2 ms]\n   [Other: 97184.3 ms]\n      [Choose CSet: 0.0 ms]\n      [Ref Proc: 8.5 ms]\n      [Ref Enq: 0.2 ms]\n      [Redirty Cards: 0.2 ms]\n      [Humongous Register: 0.1 ms]\n      [Humongous Reclaim: 0.1 ms]\n      [Free CSet: 0.4 ms]\n   [Eden: 1160.0M(1160.0M)->0.0B(1200.0M) Survivors: 136.0M->168.0M Heap: 4574.2M(25.4G)->3450.8M(26.8G)]\nHeap after GC invocations=2247 (full 0):\n garbage-first heap   total 28049408K, used 3533601K [0x00007f0c10000000, 0x00007f0c10806b00, 0x00007f1410000000)\n  region size 8192K, 21 young (172032K), 21 survivors (172032K)\n Metaspace       used 56487K, capacity 57092K, committed 58368K, reserved 59392K\n}\n [Times: user=0.00 sys=94.28, real=97.19 secs] \n2016-11-22T20:44:53.760+0000: 2942151.806: Total time for which application threads were stopped: 97.2053747 seconds, Stopping threads took: 0.0001373 seconds\n2016-11-22T20:44:53.762+0000: 2942151.809: Total time for which application threads were stopped: 0.0008138 seconds, Stopping threads took: 0.0001258 seconds\n\n\n\nAnd CPU reached near 100% during the GC.\nThe load is normal at that time according to the stats of solr update/select/delete handler and jetty request log.",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "date": "2016-12-06T14:08:46+0000",
            "author": "Shawn Heisey",
            "content": "What exactly do you want the Solr project to do about this?  Long garbage collections are a fact of life in a Java program with a large heap.  32GB is a large heap.  \n\nYou are not running with the GC settings that version 5.3.2 shipped with.  If you change the GC tuning, you're on your own.  Any problems that result are not an indication of a bug in Solr, they are at most a bug in the implementation of Java that you're running.  This problem should have been mentioned on the mailing list or IRC channel, not in this issue tracker.  I'm going to close this issue.  A bug in Solr is VERY unlikely, and this issue tracker is not the correct place for support.\n\nPart of the GC tuning that you've done is assign 34 threads to the garbage collector \u2013 16 for the concurrent collector, 18 for the parallel collector.  How many CPU cores do you have in the machine (not counting hyperthreading)?  Typical CPU counts for a modern server are somewhere between 4 and 16.  It's possible that all your CPU cores are involved in the garbage collection, so CPU usage of 100 percent would not be surprising.  Even with a CPU count of 32, the thread counts you've configured might cause this.\n\nI have created a wiki page with some GC tuning parameters for Solr, both G1 and CMS:\n\nhttps://wiki.apache.org/solr/ShawnHeisey\n\nOne thing you can do here that might help is to decrease your heap to 31GB.  The effective amount of usable heap memory would actually probably go UP because Java will switch to 32-bit pointers.  With a 32GB heap, Java must use 64-bit pointers, so each one takes twice as much memory.\n\nI'm not sure your heap needs to be that high at all.  The GC log above shows that the long collection reduced the heap from 4.5GB to 3.4GB.  If these numbers are typical after Solr has been running for a while, a heap size of 8GB, maybe less, might be enough.  You won't know for sure without long-term experimentation.\n\nThe following page discusses a way to determine how much heap is needed using jconsole graphing:\n\nhttps://wiki.apache.org/solr/SolrPerformanceProblems ",
            "id": "comment-15725578"
        },
        {
            "date": "2016-12-06T14:11:25+0000",
            "author": "Shawn Heisey",
            "content": "Support requests should happen on the mailing list or the IRC channel.  If discussion there determines that there really is a bug in Solr, then we can reopen the issue.\n\nhttp://lucene.apache.org/solr/resources.html#mailing-lists\nhttps://wiki.apache.org/solr/IRCChannels ",
            "id": "comment-15725586"
        },
        {
            "date": "2016-12-08T13:53:44+0000",
            "author": "Forest Soup",
            "content": "Thanks Shawn, \n\nI'll use this mail thread talking on it instead of this JIRA. \n\nCould you please help comment on the question in the mail thread? Thanks!\n\n1, As you can see in the gc log, the long GC pause is not a full GC. It's a young generation GC instead.   \nIn our case, full gc is fast and young gc got some long stw pause. \nDo you have any comments on that, as we usually believe full gc may cause longer pause, but young generation should be ok? \n\n2, Will these JVM options make it better? \n-XX:+UnlockExperimentalVMOptions -XX:G1NewSizePercent=10\u00a0\n\n2016-11-22T20:43:16.463+0000: 2942054.509: Total time for which application threads were stopped: 0.0029195 seconds, Stopping threads took: 0.0000804 seconds \n{Heap before GC invocations=2246 (full 0): \n garbage-first heap   total 26673152K, used 4683965K [0x00007f0c10000000, 0x00007f0c108065c0, 0x00007f1410000000) \n  region size 8192K, 162 young (1327104K), 17 survivors (139264K) \n Metaspace       used 56487K, capacity 57092K, committed 58368K, reserved 59392K \n2016-11-22T20:43:16.555+0000: 2942054.602: [GC pause (G1 Evacuation Pause) (young) \nDesired survivor size 88080384 bytes, new threshold 15 (max 15) \n\n\tage   1:   28176280 bytes,   28176280 total\n\tage   2:    5632480 bytes,   33808760 total\n\tage   3:    9719072 bytes,   43527832 total\n\tage   4:    6219408 bytes,   49747240 total\n\tage   5:    4465544 bytes,   54212784 total\n\tage   6:    3417168 bytes,   57629952 total\n\tage   7:    5343072 bytes,   62973024 total\n\tage   8:    2784808 bytes,   65757832 total\n\tage   9:    6538056 bytes,   72295888 total\n\tage  10:    6368016 bytes,   78663904 total\n\tage  11:     695216 bytes,   79359120 total\n, 97.2044320 secs] \n   [Parallel Time: 19.8 ms, GC Workers: 18] \n      [GC Worker Start (ms): Min: 2942054602.1, Avg: 2942054604.6, Max: 2942054612.7, Diff: 10.6] \n      [Ext Root Scanning (ms): Min: 0.0, Avg: 2.4, Max: 6.7, Diff: 6.7, Sum: 43.5] \n      [Update RS (ms): Min: 0.0, Avg: 3.0, Max: 15.9, Diff: 15.9, Sum: 54.0] \n         [Processed Buffers: Min: 0, Avg: 10.7, Max: 39, Diff: 39, Sum: 192] \n      [Scan RS (ms): Min: 0.0, Avg: 0.0, Max: 0.1, Diff: 0.1, Sum: 0.6] \n      [Code Root Scanning (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0] \n      [Object Copy (ms): Min: 0.1, Avg: 9.2, Max: 13.4, Diff: 13.3, Sum: 165.9] \n      [Termination (ms): Min: 0.0, Avg: 2.5, Max: 2.7, Diff: 2.7, Sum: 44.1] \n         [Termination Attempts: Min: 1, Avg: 1.5, Max: 3, Diff: 2, Sum: 27] \n      [GC Worker Other (ms): Min: 0.0, Avg: 0.0, Max: 0.1, Diff: 0.0, Sum: 0.6] \n      [GC Worker Total (ms): Min: 9.0, Avg: 17.1, Max: 19.7, Diff: 10.6, Sum: 308.7] \n      [GC Worker End (ms): Min: 2942054621.8, Avg: 2942054621.8, Max: 2942054621.8, Diff: 0.0] \n   [Code Root Fixup: 0.1 ms] \n   [Code Root Purge: 0.0 ms] \n   [Clear CT: 0.2 ms] \n   [Other: 97184.3 ms] \n      [Choose CSet: 0.0 ms] \n      [Ref Proc: 8.5 ms] \n      [Ref Enq: 0.2 ms] \n      [Redirty Cards: 0.2 ms] \n      [Humongous Register: 0.1 ms] \n      [Humongous Reclaim: 0.1 ms] \n      [Free CSet: 0.4 ms] \n   [Eden: 1160.0M(1160.0M)->0.0B(1200.0M) Survivors: 136.0M->168.0M Heap: 4574.2M(25.4G)->3450.8M(26.8G)] \nHeap after GC invocations=2247 (full 0): \n garbage-first heap   total 28049408K, used 3533601K [0x00007f0c10000000, 0x00007f0c10806b00, 0x00007f1410000000) \n  region size 8192K, 21 young (172032K), 21 survivors (172032K) \n Metaspace       used 56487K, capacity 57092K, committed 58368K, reserved 59392K \n} \n [Times: user=0.00 sys=94.28, real=97.19 secs] \n2016-11-22T20:44:53.760+0000: 2942151.806: Total time for which application threads were stopped: 97.2053747 seconds, Stopping threads took: 0.0001373 seconds\n\n ",
            "id": "comment-15732269"
        },
        {
            "date": "2016-12-08T13:54:37+0000",
            "author": "Forest Soup",
            "content": "The mail thread:\nhttp://lucene.472066.n3.nabble.com/Very-long-young-generation-stop-the-world-GC-pause-td4308911.html ",
            "id": "comment-15732274"
        }
    ]
}