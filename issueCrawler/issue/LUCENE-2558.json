{
    "id": "LUCENE-2558",
    "title": "Use sequence ids for deleted docs",
    "details": {
        "labels": "",
        "priority": "Minor",
        "components": [
            "core/search"
        ],
        "type": "Improvement",
        "fix_versions": [
            "6.0"
        ],
        "affect_versions": "Realtime Branch",
        "resolution": "Unresolved",
        "status": "Open"
    },
    "description": "Utilizing the sequence ids created via the update document\nmethods, we will enable IndexReader deleted docs over a sequence\nid array. \n\nOne of the decisions is what primitive type to use. We can start\noff with an int[], then possibly move to a short[] (for lower\nmemory consumption) that wraps around.",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "date": "2010-07-28T00:37:18+0000",
            "content": "I tried to start on this however, nothing can be deleted without the terms dictionary and the terms docs working in order to obtain the doc ids to delete. ",
            "author": "Jason Rutherglen",
            "id": "comment-12893004"
        },
        {
            "date": "2010-07-29T10:34:54+0000",
            "content": "Resolving deleted terms -> doc IDs doesn't require a sorted terms dict right?  Ie a simple hash lookup suffices? ",
            "author": "Michael McCandless",
            "id": "comment-12893579"
        },
        {
            "date": "2010-07-29T14:04:47+0000",
            "content": "Resolving deleted terms -> doc IDs doesn't require a\nsorted terms dict right? Ie a simple hash lookup suffices?\n\nTrue, however I figured it'd be best to try our own dog food, or\nAPIs. I think the main issue right now is the concurrency of the\n*BlockPools from LUCENE-2575. Then we should be able to\nimplement deleting, which doesn't require skip lists. I guess if\nwe really wanted to, we could simply buffer terms and only apply\nthem in getReader.  getReader would block any writes that could\nbe altering the *BlockPools. Maybe this is a good first step? Is there\nany reason we need to apply deletes in the actual updateDoc and\ndeleteDoc methods?   ",
            "author": "Jason Rutherglen",
            "id": "comment-12893619"
        },
        {
            "date": "2010-07-30T02:06:05+0000",
            "content": "I'm implementing a basic doc id iterator per DWPT which will allow us to implement delete by term, and the deleted docs sequence ids.  This is for merging of segments?  However we're using readers to do the merging so this really won't be useful? ",
            "author": "Jason Rutherglen",
            "id": "comment-12893911"
        },
        {
            "date": "2010-09-22T05:20:00+0000",
            "content": "For the deleted docs sequence id array, perhaps I'm a little bit\nconfused, but how will we signify in the sequence id array if a\ndocument is deleted? I believe we need a secondary sequence id\narray for deleted docs that is init'd to -1. When a document is\ndeleted, the sequence id is set for that doc in the\ndel-docs-seq-arr. When the deleted docs Bits is being accessed,\nfor a given doc, we'll compare the IRs seq-id-up-to with the\ndel-docs-seq-id, and if the IR seq-id is greater than or equal\nto, the Bits.get method will return true, meaning the document\nis deleted. \n\nI am forgetting how concurrency will work in this case, ie,\ninsuring multi-threaded visibility due to the JMM. Actually,\nbecause we're pausing the writes/deletes when get reader is\ncalled on the DWPT, JMM concurrency should be OK. ",
            "author": "Jason Rutherglen",
            "id": "comment-12913400"
        },
        {
            "date": "2011-01-20T19:06:48+0000",
            "content": "If we implement deletes via sequence id across all segments, then the .del file should probably remain the same (a set of bits)?  Also, when we load up the BV on IW start, then I guess we'll need to init the array appropriately. ",
            "author": "Jason Rutherglen",
            "id": "comment-12984331"
        },
        {
            "date": "2011-01-20T19:31:51+0000",
            "content": "We could also [someday] move deletes to a stacked model... where we only write \"deltas\" (newly deleted docs in the current session) against the segment, and on open we coalesce these.  Merging would also periodically coalesce and write a new full vector... ",
            "author": "Michael McCandless",
            "id": "comment-12984350"
        },
        {
            "date": "2011-01-20T20:43:02+0000",
            "content": "In regards to the deltas, when they're in RAM (ie, for norm and DF updates), I'm guessing we'd need to place the updates into a hash map (that hopefully uses primitives instead of objects to save RAM)?  We could instantiate a new array when the map reached a certain size? ",
            "author": "Jason Rutherglen",
            "id": "comment-12984389"
        },
        {
            "date": "2011-01-21T14:18:44+0000",
            "content": "In regards to the deltas, when they're in RAM (ie, for norm and DF updates), I'm guessing we'd need to place the updates into a hash map (that hopefully uses primitives instead of objects to save RAM)? We could instantiate a new array when the map reached a certain size?\n\nActually I think all lookups for a del doc should still be against the BV.\n\nThe \"generations\"/replay log would only be used to properly do the recycling of an old BV (ie, so you know which parts of the log to \"replay\" against this BV).\n\nAnd, for saving the new deletes in the directory (though this is not really important for the RT case). ",
            "author": "Michael McCandless",
            "id": "comment-12984742"
        },
        {
            "date": "2011-10-19T21:59:50+0000",
            "content": "Does anybody know where to checkout the realtime branch? I am very interested in it! Thanks!  ",
            "author": "hao yan",
            "id": "comment-13131051"
        },
        {
            "date": "2011-10-19T22:29:38+0000",
            "content": "Does anybody know where to checkout the realtime branch? I am very interested in it! Thanks!\nthere is no realtime branch open right now. We had to delete it since we re-integrated it for DocumentsWriterPerThread. (SVN requires that once you have re-integrated) However, there is no development happening along those lines right now and we didn't decide if we move forward since for general purpose the NRT features we have is reasonably fast. Anyway, I think there is still a need for this if we can provide it as a non-default option? ",
            "author": "Simon Willnauer",
            "id": "comment-13131080"
        }
    ]
}