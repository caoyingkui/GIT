{
    "id": "LUCENE-760",
    "title": "Spellchecker could/should use n-gram tokenizers instead of rolling its own n-gramming",
    "details": {
        "labels": "",
        "priority": "Minor",
        "components": [
            "modules/analysis"
        ],
        "type": "Improvement",
        "fix_versions": [],
        "affect_versions": "None",
        "resolution": "Won't Fix",
        "status": "Closed"
    },
    "description": "The SpellChecker.java under contrib/spellchecker currently does its own creation of n-grams while it creates the index to search for alternative spelling suggestions, and then it again creates appropriate n-grams when it receives a query string/word to lookup alternative spelling suggestions for.  Very clear sentence, I know.\n\nI think it might be better if n-gram chomping could be outsourced to n-gram tokenizers that just made their way into contrib/analyzers via LUCENE-759.\n\nIf I see nods or if I don't get any nays I'll go and refactor SpellChecker.java a little bit to allow this.\nSpellChecker has a page on the Wiki: http://wiki.apache.org/jakarta-lucene/SpellChecker\n\nThoughts?",
    "attachments": {},
    "issue_links": {},
    "comments": []
}