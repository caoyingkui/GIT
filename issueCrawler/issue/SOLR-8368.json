{
    "id": "SOLR-8368",
    "title": "Investigate a leader using older versions than it's replicas has for leader election peer sync after a 'crash' shutdown.",
    "details": {
        "components": [],
        "type": "Bug",
        "labels": "",
        "fix_versions": [],
        "affect_versions": "None",
        "status": "Open",
        "resolution": "Unresolved",
        "priority": "Major"
    },
    "description": "If we do it after like now, the correct leader may not be able to become leader.",
    "attachments": {
        "SOLR-8368.patch": "https://issues.apache.org/jira/secure/attachment/12776614/SOLR-8368.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2015-12-04T16:12:57+0000",
            "author": "Mike Drob",
            "content": "This could take a long time, though, right? Is there any danger/downside to not having a leader while waiting for replay? ",
            "id": "comment-15041686"
        },
        {
            "date": "2015-12-04T16:17:05+0000",
            "author": "Mark Miller",
            "content": "It could take a long time, but it's simply necessary for the architecture to prevent data loss. There is plenty of downside in it taking a long time. ",
            "id": "comment-15041691"
        },
        {
            "date": "2015-12-04T16:18:27+0000",
            "author": "Mark Miller",
            "content": "Of course, replaying a tlog when everything works well should be an exceptional case. ",
            "id": "comment-15041693"
        },
        {
            "date": "2015-12-04T17:55:20+0000",
            "author": "Mark Miller",
            "content": "I keep trying to think of reasons we don't have to do this. But I end up thinking more about the possible issues if we don't with the current system. ",
            "id": "comment-15041855"
        },
        {
            "date": "2015-12-07T17:58:37+0000",
            "author": "Gregory Chanan",
            "content": "1.  On the taking a long time concern, there is a lot we could do to speed up the tlog replaying, right?  Particularly if on a shared/distributed filesystem.\n\n2.  We can't figure out who should be the leader by looking at the end of the tlog(s) (again, on a shared/distributed filesystem), but not actually replaying them before waiting for the election? ",
            "id": "comment-15045352"
        },
        {
            "date": "2015-12-08T05:08:03+0000",
            "author": "Mark Miller",
            "content": "1\n\nProbably the best thing that could be done is multithreaded replay. As far as anything being a lot better on a shared filesystem, that doesn't help me at all for general issues like this.\n\n2\n\nThe current leader election system is a lot more involved than simply looking at what replica has the greatest version for it\u2019s last update.\n\nPerhaps when the min replication param is fully first class and full featured we can considering getting fairly wild in how we deal with this, but in the current state of things, we are careful to minimize data loss as much as possible\n\nBy the way, this would really going to complicate / upset my shared index / tlog on a shared filesystem solution ",
            "id": "comment-15046364"
        },
        {
            "date": "2015-12-08T12:23:30+0000",
            "author": "Mark Miller",
            "content": "By the way, this would really going to complicate / upset my shared index / tlog on a shared filesystem solution\n\nActually, hopefully I was over thinking that and it won't.  ",
            "id": "comment-15046801"
        },
        {
            "date": "2015-12-09T16:19:36+0000",
            "author": "Mark Miller",
            "content": "Yonik Seeley, you have any thoughts on this whole issue? ",
            "id": "comment-15048905"
        },
        {
            "date": "2015-12-09T18:11:33+0000",
            "author": "Mark Miller",
            "content": "Okay, I guess one thing that should be noted: this is not like when we replay buffered documents, which also has to deal with documents coming in. Replay being slow has a large impact there because it's very hard for it to be faster than a decent amount of doc/s coming in.\n\nWith realistic hard auto commit and a lack of bugs, you should not end up having to replay a very large tlog file on startup though.\n\nSo really, this should be an exceptional case and even when it happens, the tlog file should be relatively manageable and relatively quick to replay. ",
            "id": "comment-15049106"
        },
        {
            "date": "2015-12-09T18:16:47+0000",
            "author": "Mark Miller",
            "content": "The patch (attached) should be pretty straightforward.\n\nThe only change beyond calling tlog replay before entering the election is that we have to remove an || isLeader check against it since it happens before we know if we will be the leader or not. ",
            "id": "comment-15049113"
        },
        {
            "date": "2015-12-09T18:47:54+0000",
            "author": "Mike Drob",
            "content": "Remove the TODO about doing replay before leader election?\n\nCould put ulog declaration in replayTransactionLogIfNeeded, cut down on a method parameter and some scope that way.\n\nThe only change beyond calling tlog replay before entering the election is that we have to remove an || isLeader check against it since it happens before we know if we will be the leader or not.\nThis means that a non-leader in shard construction state will no longer do a replay. I don't know enough about how shard splits work to know if this is ok, but I think the impact is that replicas will take longer to come online since they will need to do an additional recovery once the sub-shard leader is active. If that's the case then the rest of the patch LGTM.\n\nI see a couple of minor places where we could clarify things, but it's not worth it for this issue. ",
            "id": "comment-15049172"
        },
        {
            "date": "2015-12-09T18:57:47+0000",
            "author": "Mark Miller",
            "content": "an additional recovery once the sub-shard leader is active.\n\nRecovery and replaying the tlog are two different things. The recovery process does not involve replaying a tlog in this sense - just buffering and replaying updates during replication.\n\nThese sub shards should not have any tlogs to replay anyway though. If on some crazy failure case they did, replaying tlogs after a crash should never be a bad thing to do. ",
            "id": "comment-15049191"
        },
        {
            "date": "2015-12-09T18:59:51+0000",
            "author": "Mark Miller",
            "content": "Would be good for Shalin Shekhar Mangar or someone that knows shard splitting like him to take a look at it though. ",
            "id": "comment-15049195"
        },
        {
            "date": "2015-12-09T22:11:28+0000",
            "author": "Yonik Seeley",
            "content": "Hmmm, it looks like \"startingVersions\" are the most recent versions, regardless of whether the tlog has been replayed or not?\n\nUpdateLog.init\n\n    // TODO: these startingVersions assume that we successfully recover from all non-complete tlogs.\n    try (RecentUpdates startingUpdates = getRecentUpdates()) {\n\n ",
            "id": "comment-15049463"
        },
        {
            "date": "2015-12-09T22:26:27+0000",
            "author": "Mark Miller",
            "content": "Yes, they are loaded up before log replay before and after this change. I don't get the insinuation though. ",
            "id": "comment-15049484"
        },
        {
            "date": "2015-12-09T22:27:19+0000",
            "author": "Mark Miller",
            "content": "// TODO: these startingVersions assume that we successfully recover from all non-complete tlogs.\n\nDoes that mean we should be loading them up after log replay then? ",
            "id": "comment-15049487"
        },
        {
            "date": "2015-12-09T23:59:49+0000",
            "author": "Yonik Seeley",
            "content": "Yes, they are loaded up before log replay before and after this change. I don't get the insinuation though.\n\nI guess I was making assumptions about what goes wrong with leader election if tlogs aren't replayed first.  The issue description simply says \"If we do it after like now, the correct leader may not be able to become leader.\"  I assumed that meant that we wouldn't be using the actual latest versions, but only versions of completed or replayed tlogs.  But looking at the code, it seems like the latest versions we have (replayed or not) will be used for the purposes of leader election. ",
            "id": "comment-15049669"
        },
        {
            "date": "2015-12-10T01:11:01+0000",
            "author": "Mark Miller",
            "content": "It's going to pull from the uncapped log?\nIn the incident that brought this to attention, an uncapped log was not yet replayed, and when the leader attempted to peer sync with its replica(s) it was using versions from before the last hard commit it appeared, rather than what was in the uncapped tlog. The only explanation I can think of for seeing this is the uncapped tlog disappeared or the leader election peer sync process was not using updates from that uncapped log.  ",
            "id": "comment-15049798"
        },
        {
            "date": "2015-12-10T01:12:51+0000",
            "author": "Mark Miller",
            "content": "I'll work on a specific test.  ",
            "id": "comment-15049799"
        },
        {
            "date": "2015-12-10T01:50:25+0000",
            "author": "Mark Miller",
            "content": "So one thing to note is that the leader election peersync does not currently set starting versions. So it's using a fresh recent versions call. Though I suppose all of that should be using uncapped tlogs?\n\nI'm still seeing a 4.10.3 + backports version of Solr that has had a non clean shutdown, comes back up, and it tries to become leader with versions much older than what it has sent its replicas (and we add locally before sending to replicas at all). And they are about the length of a hard autocommit (60s) older. ",
            "id": "comment-15049846"
        },
        {
            "date": "2015-12-10T16:17:43+0000",
            "author": "Shalin Shekhar Mangar",
            "content": "This means that a non-leader in shard construction state will no longer do a replay. I don't know enough about how shard splits work to know if this is ok, but I think the impact is that replicas will take longer to come online since they will need to do an additional recovery once the sub-shard leader is active. If that's the case then the rest of the patch LGTM.\n\nThese sub shards should not have any tlogs to replay anyway though. If on some crazy failure case they did, replaying tlogs after a crash should never be a bad thing to do.\n\nWould be good for Shalin Shekhar Mangar or someone that knows shard splitting like him to take a look at it though.\n\nYou are right Mark. We only need to skip log replay for the sub-shard leader (because it starts buffering updates coming from parent shard leader during core construction). Non-leaders in construction don't really need log replay (they shouldn't have anything in their tlogs at all). \n\n\n// disable recovery in case shard is in construction state (for shard splits)\n\n\nThis comment can be fixed to say \"disable log replay in case shard is in construction state (for shard splits)\". ",
            "id": "comment-15051166"
        },
        {
            "date": "2015-12-16T18:02:01+0000",
            "author": "Mark Miller",
            "content": "I've renamed this 'investigation'. Given we work from uncapped tlogs, something else happened here. I've been trying to figure out what using logs and attempting to replicate, but so far I don't have it. I have some more ideas to try, but the current attached patch is unnecessary. ",
            "id": "comment-15060426"
        }
    ]
}