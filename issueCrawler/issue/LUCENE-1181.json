{
    "id": "LUCENE-1181",
    "title": "Token reuse is not ideal for avoiding array copies",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [
            "modules/analysis"
        ],
        "type": "Improvement",
        "fix_versions": [],
        "affect_versions": "2.3",
        "resolution": "Won't Fix",
        "status": "Resolved"
    },
    "description": "The way the Token API is currently written results in two unnecessary array copies which could be avoided by changing the way it works.\n\n1. setTermBuffer(char[],int,int) calls resizeTermBuffer(int) which copies the original term text even though it's about to be overwritten.\n\n#1 should be trivially fixable by introducing a private resizeTermBuffer(int,boolean) where the new boolean parameter specifies whether the existing term data gets copied over or not.\n\n2. setTermBuffer(char[],int,int) copies what you pass in, instead of actually setting the term buffer.\n\nSetting aside the fact that the setTermBuffer method is misleadingly named, consider a token filter which performs Unicode normalisation on each token.\n\nHow it has to be implemented at present:\n  once:\n\n\tcreate a reusable char[] for storing the normalisation result\n  every token:\n\tuse getTermBuffer() and getTermLength() to get the buffer and relevant length\n\tnormalise the original string into our temporary buffer   (if it isn't big enough, grow the temp buffer size.)\n\tsetTermBuffer(byte[],int,int) - this does an extra copy.\n\n\n\nThe following sequence would be much better:\n  once:\n\n\tcreate a reusable char[] for storing the normalisation result\n  every token:\n\tuse getTermBuffer() and getTermLength() to get the buffer and relevant length\n\tnormalise the original string into our temporary buffer   (if it isn't big enough, grow the temp buffer size.)\n\tsetTermBuffer(byte[],int,int) sets in our buffer by reference\n\tset the term buffer which used to be in the Token such that it becomes our new temp buffer.\n\n\n\nThe latter sequence results in no copying with the exception of the normalisation itself, which is unavoidable.",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "date": "2008-02-21T17:41:40+0000",
            "content": "\n1. setTermBuffer(char[],int,int) calls resizeTermBuffer(int) which copies the original term text even though it's about to be overwritten.\nTrue, although the cost should be negligible in practice since that copy only occurs if the term buffer isn't already big enough.  A very small number of reallocations should occur in practice when a single Token is shared.\n\n\n2. setTermBuffer(char[],int,int) copies what you pass in, instead of actually setting the term buffer.\nI thought about holding a reference to what was passed in, but, it made me nervous because 1) this may cause alot of excess reallocations (ie if you keep setting a smaller buffer than downstream filters need), and, 2) it makes things sneakier since filters downstream are allowed to alter that buffer directly.  It felt safer to have a single \"private\" buffer in Token.\n\nMaybe one possible workaround is to use two Tokens (one temp, one real) and swap which one you are working on for your Unicode normalization on every token? ",
            "author": "Michael McCandless",
            "id": "comment-12571112"
        }
    ]
}