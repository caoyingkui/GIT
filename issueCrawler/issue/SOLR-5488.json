{
    "id": "SOLR-5488",
    "title": "Fix up test failures for Analytics Component",
    "details": {
        "affect_versions": "6.0",
        "status": "Resolved",
        "fix_versions": [
            "6.0"
        ],
        "components": [],
        "type": "Bug",
        "priority": "Major",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "The analytics component has a few test failures, perhaps environment-dependent. This is just to collect the test fixes in one place for convenience when we merge back into 4.x",
    "attachments": {
        "eoe.errors": "https://issues.apache.org/jira/secure/attachment/12625161/eoe.errors",
        "SOLR-5488.patch": "https://issues.apache.org/jira/secure/attachment/12615478/SOLR-5488.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Erick Erickson",
            "id": "comment-13828883",
            "date": "2013-11-21T12:46:11+0000",
            "content": "Let's collect fixes here. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13829228",
            "date": "2013-11-21T19:09:44+0000",
            "content": "Steven Bower\nHere's the bits from the enhanced error output:\n\n1 tests failed.\nFAILED:  org.apache.solr.analytics.NoFacetTest.stddevTest\n\nError Message:\nOops: (double raws) 4631318898052956160 - 4628496337733101339 < 4442235333156365461 Calculated diff 4625071700926640586\n\nStack Trace:\njava.lang.AssertionError: Oops: (double raws) 4631318898052956160 - 4628496337733101339 < 4442235333156365461 Calculated diff 4625071700926640586\n        at __randomizedtesting.SeedInfo.seed([94AAF7392EB49CCD:916AB78C1ED798C2]:0)\n        at org.junit.Assert.fail(Assert.java:93)\n        at org.junit.Assert.assertTrue(Assert.java:43)\n        at org.apache.solr.analytics.NoFacetTest.stddevTest(NoFacetTest.java:227)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13829236",
            "date": "2013-11-21T19:12:56+0000",
            "content": "Here's the other error I've seen go by:\n\nBuild: http://jenkins.thetaphi.de/job/Lucene-Solr-trunk-Linux/8408/\nJava: 64bit/ibm-j9-jdk7 -Xjit:exclude=\n{org/apache/lucene/util/fst/FST.pack(IIF)Lorg/apache/lucene/util/fst/FST;}\n\n7 tests failed.\nREGRESSION:  org.apache.solr.analytics.expression.ExpressionTest.multiplyTest\n\nError Message:\nFor input string: \"\" encoding=\"UTF-8\"?> <response>  <lst name=\"responseHeader\">   <int name=\"status\">0</int>   <int name=\"QTime\">1060</int> </lst> <result name=\"response\" numFound=\"100\" start=\"0\"> </result> <lst name=\"stats\">   <lst name=\"stats_fields\"/> </lst> <lst name=\"stats\">   <lst name=\"rr\">     <str name=\"max\">str9</str>     <str name=\"min\">str0</str>     <str name=\"rmax\">9rts</str>     <str name=\"rmin\">0rts</str>   </lst>   <lst name=\"cdr\">     <date name=\"cd1\">1800-12-31T23:59:59Z</date>     <date name=\"cd2\">1804-06-30T23:59:59Z</date>     <str name=\"cs1\">1800-12-31T23:59:59Z</str>     <str name=\"cs2\">1804-06-30T23:59:59Z</str>   </lst>   <lst name=\"ar\">     <long name=\"count\">100</long>     <null name=\"mcm\"/>     <null name=\"mean\"/>     <null name=\"median\"/>     <null name=\"su\"/>     <null name=\"sum\"/>     <null name=\"unique\"/>   </lst>   <lst name=\"csr\">     <str name=\"cs1\">this is the first</str>     <str name=\"cs2\">this is the second</str>     <str name=\"cs3\">this is the third</str>   </lst>   <lst name=\"pr\">     <long name=\"count\">100</long>     <null name=\"mc\"/>     <null name=\"mean\"/>     <null name=\"su\"/>     <null name=\"sum\"/>     <null name=\"unique\"/>   </lst>   <lst name=\"nr\">     <double name=\"c\">-100.0\"\n\nStack Trace:\njava.lang.NumberFormatException: For input string: \"\" encoding=\"UTF-8\"?>\n<response>\n\n<lst name=\"responseHeader\">\n  <int name=\"status\">0</int>\n  <int name=\"QTime\">1060</int>\n</lst>\n<result name=\"response\" numFound=\"100\" start=\"0\">\n</result>\n<lst name=\"stats\">\n  <lst name=\"stats_fields\"/>\n</lst>\n<lst name=\"stats\">\n  <lst name=\"rr\">\n    <str name=\"max\">str9</str>\n    <str name=\"min\">str0</str>\n    <str name=\"rmax\">9rts</str>\n    <str name=\"rmin\">0rts</str>\n  </lst>\n  <lst name=\"cdr\">\n    <date name=\"cd1\">1800-12-31T23:59:59Z</date>\n    <date name=\"cd2\">1804-06-30T23:59:59Z</date>\n    <str name=\"cs1\">1800-12-31T23:59:59Z</str>\n    <str name=\"cs2\">1804-06-30T23:59:59Z</str>\n  </lst>\n  <lst name=\"ar\">\n    <long name=\"count\">100</long>\n    <null name=\"mcm\"/>\n    <null name=\"mean\"/>\n    <null name=\"median\"/>\n    <null name=\"su\"/>\n    <null name=\"sum\"/>\n    <null name=\"unique\"/>\n  </lst>\n  <lst name=\"csr\">\n    <str name=\"cs1\">this is the first</str>\n    <str name=\"cs2\">this is the second</str>\n    <str name=\"cs3\">this is the third</str>\n  </lst>\n  <lst name=\"pr\">\n    <long name=\"count\">100</long>\n    <null name=\"mc\"/>\n    <null name=\"mean\"/>\n    <null name=\"su\"/>\n    <null name=\"sum\"/>\n    <null name=\"unique\"/>\n  </lst>\n  <lst name=\"nr\">\n    <double name=\"c\">-100.0\"\n        at __randomizedtesting.SeedInfo.seed([77B88168ED57D455:1C399F16D859E23B]:0)\n        at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:1312)\n        at java.lang.Double.parseDouble(Double.java:551)\n        at org.apache.solr.analytics.expression.ExpressionTest.getStatResult(ExpressionTest.java:240)\n        at org.apache.solr.analytics.expression.ExpressionTest.multiplyTest(ExpressionTest.java:96)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:88)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55) "
        },
        {
            "author": "Houston Putman",
            "id": "comment-13829254",
            "date": "2013-11-21T19:31:35+0000",
            "content": "The first error looks pretty different from what I wrote in NoFacetTest, so I'm kind of confused as to what is going on. Are those the standard deviation calculations, both the actual and calculated? Since there are so many decimal digits in standard deviations usually, I had to write the test to make sure that the calculation is almost identical to the real value because it was usually around .0000000000001 off. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13829283",
            "date": "2013-11-21T20:01:28+0000",
            "content": "Houston:\n\nRight, the original looked something like:\n\nassertTrue(Math.abs(floatResult - floatTest) < .00000000001);\n\nThat doesn't give much data to go on though, so Dawid Weiss suggested something like this so we'd have some idea what the values were in their raw format. The test is the same, it just dumps a bunch more info out.:\n\n    assertTrue(\"Oops: (double raws) \" + Double.doubleToRawLongBits(floatResult) + \" - \"\n        + Double.doubleToRawLongBits(floatTest) + \" < \" + Double.doubleToRawLongBits(.00000000001) +\n        \" Calculated diff \" + Double.doubleToRawLongBits(floatResult - floatTest),\n        Math.abs(floatResult - floatTest) < .00000000001); "
        },
        {
            "author": "Dawid Weiss",
            "id": "comment-13829396",
            "date": "2013-11-21T22:02:52+0000",
            "content": "There is something seriously odd with this test \u2013 I'm guessing it depends on previous context somehow.\n\nWhen I re-run it with the same seed I get consistently a different set of numbers. The above are clearly wrong because these raw bits correspond to:\n\n\n263901.0 - 27.72225134241226 < ...\n\n\n\nWhen I look at the dumped log the most recent query is also consistent in my runs:\n\n\noasc.SolrCore.execute [collection1] webapp=null path=null params={o.cr.s.long_ld=count(long_ld)&o.ur.s.double_dd=unique(double_dd)&o.str.s.int_id=stddev(int_id)&o.p6r.s.string_sd=percentile(60,string_sd)&o.p2r.s.string_sd=percentile(20,string_sd)&o.mr.s.double_dd=mean(double_dd)&o.st.s.float_fd=stddev(float_fd)&o.mar.s.float_fd=max(float_fd)&o.sosr.s.long_ld=sumofsquares(long_ld)&o.ur.s.date_dtd=unique(date_dtd)&o.ur.s.string_sd=unique(string_sd)&o.mir.s.float_fd=min(float_fd)&o.misr.s.int_id=missing(int_id)&o.misr.s.double_dd=missing(double_dd)&o.p2r.s.int_id=percentile(20,int_id)&o.medr.s.date_dtd=median(date_dtd)&o.p6r.s.int_id=percentile(60,int_id)&indent=true&o.ur.s.long_ld=unique(long_ld)&o.misr.s.string_sd=missing(string_sd)&o.sosr.s.float_fd=sumofsquares(float_fd)&o.misr.s.date_dtd=missing(date_dtd)&o.mr.s.long_ld=mean(long_ld)&o.medr.s.long_ld=median(long_ld)&o.str.s.double_dd=stddev(double_dd)&o.p2r.s.float_fd=percentile(20,float_fd)&o.cr.s.float_fd=count(float_fd)&o.p6r.s.float_fd=percentile(60,float_fd)&o.sr.s.double_dd=sum(double_d)&o.mr.s.float_fd=mean(float_fd)&o.mir.s.long_ld=min(long_ld)&o.medr.s.double_dd=median(double_dd)&o.misr.s.long_ld=missing(long_ld)&olap=true&o.sr.s.float_fd=sum(float_f)&o.mar.s.date_dtd=max(date_dtd)&o.ur.s.float_fd=unique(float_fd)&o.medr.s.int_id=median(int_id)&o.mar.s.long_ld=max(long_ld)&o.cr.s.double_dd=count(double_dd)&o.mir.s.date_dtd=min(date_dtd)&rows=0&o.sosr.s.int_id=sumofsquares(int_id)&o.mir.s.double_dd=min(double_dd)&o.sosr.s.double_dd=sumofsquares(double_dd)&o.p6r.s.long_ld=percentile(60,long_ld)&o.p2r.s.long_ld=percentile(20,long_ld)&o.cr.s.string_sd=count(string_sd)&o.str.s.long_ld=stddev(long_ld)&o.mar.s.double_dd=max(double_dd)&o.medr.s.float_fd=median(float_fd)&o.cr.s.int_id=count(int_id)&o.mir.s.string_sd=min(string_sd)&o.misr.s.float_fd=missing(float_fd)&o.sr.s.long_ld=sum(long_l)&o.mr.s.int_id=mean(int_id)&q=*:*&o.p6r.s.double_dd=percentile(60,double_dd)&o.mar.s.int_id=max(int_id)&o.mar.s.string_sd=max(string_sd)&o.sr.s.int_id=sum(int_i)&o.p2r.s.double_dd=percentile(20,double_dd)&o.ur.s.int_id=unique(int_id)&o.p2r.s.date_dtd=percentile(20,date_dtd)&o.mir.s.int_id=min(int_id)&o.cr.s.date_dtd=count(date_dtd)&o.p6r.s.date_dtd=percentile(60,date_dtd)} hits=100 status=0 QTime=22 \n\n\n\nBut it's vastly different in the failed log:\n\n\noasc.SolrCore.execute [collection1] webapp=null path=null params={o.medr.s.int_id=median(int_id)&o.p2r.s.string_sd=percentile(20,string_sd)&o.sr.s.long_ld=sum(long_l)&o.misr.s.string_sd=missing(string_sd)&o.mir.s.long_ld=min(long_ld)&o.ur.s.string_sd=unique(string_sd)&o.misr.s.float_fd=missing(float_fd)&o.p2r.s.date_dtd=percentile(20,date_dtd)&o.medr.s.date_dtd=median(date_dtd)&o.p2r.s.long_ld=percentile(20,long_ld)&o.cr.s.float_fd=count(float_fd)&o.p2r.s.double_dd=percentile(20,double_dd)&o.mar.s.int_id=max(int_id)&o.cr.s.long_ld=count(long_ld)&o.mr.s.int_id=mean(int_id)&o.medr.s.long_ld=median(long_ld)&o.p2r.s.int_id=percentile(20,int_id)&o.misr.s.int_id=missing(int_id)&o.p6r.s.date_dtd=percentile(60,date_dtd)&o.medr.s.double_dd=median(double_dd)&o.sosr.s.double_dd=sumofsquares(double_dd)&o.mir.s.int_id=min(int_id)&o.misr.s.long_ld=missing(long_ld)&o.cr.s.double_dd=count(double_dd)&o.str.s.double_dd=stddev(double_dd)&indent=true&o.p6r.s.long_ld=percentile(60,long_ld)&o.p6r.s.int_id=percentile(60,int_id)&o.st.s.float_fd=stddev(float_fd)&o.misr.s.date_dtd=missing(date_dtd)&rows=0&o.cr.s.string_sd=count(string_sd)&o.sr.s.int_id=sum(int_i)&o.ur.s.date_dtd=unique(date_dtd)&o.medr.s.float_fd=median(float_fd)&o.cr.s.date_dtd=count(date_dtd)&o.ur.s.long_ld=unique(long_ld)&o.misr.s.double_dd=missing(double_dd)&o.mar.s.string_sd=max(string_sd)&o.mir.s.double_dd=min(double_dd)&o.mir.s.date_dtd=min(date_dtd)&o.mir.s.string_sd=min(string_sd)&o.p6r.s.string_sd=percentile(60,string_sd)&o.mir.s.float_fd=min(float_fd)&o.sr.s.double_dd=sum(double_d)&o.str.s.int_id=stddev(int_id)&o.ur.s.float_fd=unique(float_fd)&o.cr.s.int_id=count(int_id)&o.str.s.long_ld=stddev(long_ld)&o.mar.s.long_ld=max(long_ld)&o.mr.s.long_ld=mean(long_ld)&o.mr.s.float_fd=mean(float_fd)&o.mar.s.date_dtd=max(date_dtd)&o.p6r.s.double_dd=percentile(60,double_dd)&o.sr.s.float_fd=sum(float_f)&o.ur.s.int_id=unique(int_id)&o.p6r.s.float_fd=percentile(60,float_fd)&o.ur.s.double_dd=unique(double_dd)&o.sosr.s.int_id=sumofsquares(int_id)&o.p2r.s.float_fd=percentile(20,float_fd)&q=*:*&o.sosr.s.long_ld=sumofsquares(long_ld)&o.mr.s.double_dd=mean(double_dd)&o.sosr.s.float_fd=sumofsquares(float_fd)&olap=true&o.mar.s.double_dd=max(double_dd)&o.mar.s.float_fd=max(float_fd)} hits=100 status=0 QTime=164 \n\n\n\nDon't know what may be the cause of this, sorry.\n "
        },
        {
            "author": "Houston Putman",
            "id": "comment-13829435",
            "date": "2013-11-21T22:51:41+0000",
            "content": "Y'alls output is much better, thanks. As for the difference in the logs I don't think that the actual key-value pairs are different, just their ordering. The order they come in is basically random, so I am not surprised to see that it is different between the two logs.\n\nI have no idea what is happening with the standard deviation, so I will look into it later. "
        },
        {
            "author": "Dawid Weiss",
            "id": "comment-13829443",
            "date": "2013-11-21T23:00:52+0000",
            "content": "Hi Houston. I explained the reason for the ordering in my post to the dev list (Jira was down). Quoting:\n\n\nJust looking randomly at the code (pretty hairy...) I noticed this in\nTestHarness.java\n\n\n  public class LocalRequestFactory {\n    public String qtype = null;\n    public int start = 0;\n    public int limit = 1000;\n    public Map<String,String> args = new HashMap<String,String>();\n\n\n\nWe should not be using HashMaps for anything that later on requires\niteration over map elements (as this is the case here) because hash\nmaps are jvm-dependent and pretty much don't have a reliable iteration\norder. This should be changed to LinkedHashMap.\n\n... and sure the problem does reproduce 100% if you use IBM J9, as in\nthe failed build. I would fix the bug first (don't know how , using\nJ9 to diagnose the problem, then correct the code not to use the\nHashMap order.\n\nHope this helps you in finding out what the heck is wrong. Install IBM's JVM (J9) and rerun with the seed from the log above \u2013 the problem reproduces for me all the time.  "
        },
        {
            "author": "Steven Bower",
            "id": "comment-13830040",
            "date": "2013-11-22T15:26:43+0000",
            "content": "gonna take a spin with ibm j9... see whats going on.. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13830463",
            "date": "2013-11-23T00:44:57+0000",
            "content": "In case you don't see the dev list stuff, I added a bit more data to the output, here it is....\n\n1 tests failed.\nFAILED:  org.apache.solr.analytics.NoFacetTest.stddevTest\n\nError Message:\nOops: (double raws) 4631318898052956160 - 4628496337733101339 < 4442235333156365461 Calculated diff 4625071700926640586 Let's see what the JVM thinks these bits are. FloatResult:  43.5 floatTest: 27.72225134241226 Diff 15.77774865758774 "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13830466",
            "date": "2013-11-23T00:47:02+0000",
            "content": "FWIW, second test fail output:\n\nError Message:\nOops: (double raws) 4631318898052956160 - 4628496337733101339 < 4442235333156365461 Calculated diff 4625071700926640586 Let's see what the JVM thinks these bits are. FloatResult:  43.5 floatTest: 27.72225134241226 Diff 15.77774865758774\n\nLooks identical which is kind of good since it seems to be reproducible. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13830468",
            "date": "2013-11-23T00:51:05+0000",
            "content": "BTW. In case you're feeling beaten up by these failures, let me say I'm absolutely thrilled that you supplied test cases that fail in different environments! It's far better this way; finding errors in different environments before releasing this stuff into the wild, than having poor tests that fail in mysterious ways later. I should know, I've been guilty of some of the latter. "
        },
        {
            "author": "Houston Putman",
            "id": "comment-13830470",
            "date": "2013-11-23T00:53:23+0000",
            "content": "I tried replicating the failures with the J9 JVM, but I can't get any of the tests to fail. Is there anything else I should change about my environment? "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13830475",
            "date": "2013-11-23T01:03:07+0000",
            "content": "Did you try this exact command?\n\n ant test  -Dtestcase=NoFacetTest -Dtests.method=stddevTest -Dtests.seed=3E70166A97842517 -Dtests.multiplier=3 -Dtests.slow=true -Dtests.locale=sr_ME -Dtests.timezone=US/Samoa -Dtests.file.encoding=UTF-8\n\nAccording to Dawid, this fails every time. "
        },
        {
            "author": "Dawid Weiss",
            "id": "comment-13830710",
            "date": "2013-11-23T17:34:45+0000",
            "content": "You need to run with the same seed as the one failing. I used a different run to Eric's, but it fails even when executed from within Eclipse (if J9 is used):\n\nJVM args:\n\n-ea -server -Dtests.seed=77B88168ED57D455 -Dtests.multiplier=3 -Dtests.slow=true -Dtests.locale=ca_ES_PREEURO -Dtests.timezone=Pacific/Kiritimati -Dtests.file.encoding=ISO-8859-1\n\nThe JVM is:\n\nJava(TM) SE Runtime Environment (build pwa6470sr1-20120405_01(SR1))\nIBM J9 VM (build 2.6, JRE 1.7.0 Windows 7 amd64-64 20120322_106209 (JIT enabled, AOT enabled)\nJ9VM - R26_Java726_SR1_20120322_1720_B106209\nJIT  - r11_20120322_22976 "
        },
        {
            "author": "Dawid Weiss",
            "id": "comment-13830722",
            "date": "2013-11-23T17:51:14+0000",
            "content": "From a quick debug session the problem is that it doesn't make sense?  \n\nThis line in the test:\n\n    //Float\n    Double floatResult = (Double)getStatResult(response, \"str\", \"double\", \"float_fd\");\n\n\n\nmatches an invalid value. The response object is:\n\n\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<response>\n\n<lst name=\"responseHeader\">\n  <int name=\"status\">0</int>\n  <int name=\"QTime\">184</int>\n</lst>\n<result name=\"response\" numFound=\"100\" start=\"0\">\n</result>\n<lst name=\"stats\">\n  <lst name=\"st\">\n    <double name=\"float_fd\">27.722251342412257</double>\n  </lst>\n  <lst name=\"mr\">\n    <double name=\"double_dd\">24.257731958762886</double>\n    <double name=\"float_fd\">43.86734693877551</double>\n    <double name=\"int_id\">29.5</double>\n    <double name=\"long_ld\">16.88659793814433</double>\n  </lst>\n  <lst name=\"medr\">\n    <date name=\"date_dtd\">1806-12-31T23:59:59Z</date>\n    <double name=\"double_dd\">24.0</double>\n    <double name=\"float_fd\">43.5</double>\n    <double name=\"int_id\">25.0</double>\n    <double name=\"long_ld\">17.0</double>\n  </lst>\n  <lst name=\"p6r\">\n    <date name=\"date_dtd\">1807-12-31T23:59:59Z</date>\n    <double name=\"double_dd\">29.0</double>\n    <float name=\"float_fd\">53.0</float>\n    <int name=\"int_id\">31</int>\n    <long name=\"long_ld\">20</long>\n    <str name=\"string_sd\">str24</str>\n  </lst>\n  <lst name=\"cr\">\n    <long name=\"date_dtd\">91</long>\n    <long name=\"double_dd\">97</long>\n    <long name=\"float_fd\">98</long>\n    <long name=\"int_id\">98</long>\n    <long name=\"long_ld\">97</long>\n    <long name=\"string_sd\">96</long>\n  </lst>\n  <lst name=\"p2r\">\n    <date name=\"date_dtd\">1803-12-31T23:59:59Z</date>\n    <double name=\"double_dd\">10.0</double>\n    <float name=\"float_fd\">14.0</float>\n    <int name=\"int_id\">10</int>\n    <long name=\"long_ld\">7</long>\n    <str name=\"string_sd\">str13</str>\n  </lst>\n  <lst name=\"str\">\n    <double name=\"double_dd\">13.984732728771194</double>\n    <double name=\"int_id\">20.006249023742555</double>\n    <double name=\"long_ld\">9.680330028304972</double>\n  </lst>\n  <lst name=\"mir\">\n    <date name=\"date_dtd\">1801-12-31T23:59:59Z</date>\n    <double name=\"double_dd\">1.0</double>\n    <float name=\"float_fd\">1.0</float>\n    <int name=\"int_id\">1</int>\n    <long name=\"long_ld\">1</long>\n    <str name=\"string_sd\">str1</str>\n  </lst>\n  <lst name=\"sosr\">\n    <double name=\"double_dd\">76049.0</double>\n    <double name=\"float_fd\">263901.0</double>\n    <double name=\"int_id\">124509.0</double>\n    <double name=\"long_ld\">36750.0</double>\n  </lst>\n  <lst name=\"misr\">\n    <long name=\"date_dtd\">9</long>\n    <long name=\"double_dd\">3</long>\n    <long name=\"float_fd\">2</long>\n    <long name=\"int_id\">2</long>\n    <long name=\"long_ld\">3</long>\n    <long name=\"string_sd\">4</long>\n  </lst>\n  <lst name=\"ur\">\n    <long name=\"date_dtd\">11</long>\n    <long name=\"double_dd\">48</long>\n    <long name=\"float_fd\">92</long>\n    <long name=\"int_id\">70</long>\n    <long name=\"long_ld\">35</long>\n    <long name=\"string_sd\">27</long>\n  </lst>\n  <lst name=\"mar\">\n    <date name=\"date_dtd\">1811-12-31T23:59:59Z</date>\n    <double name=\"double_dd\">48.0</double>\n    <float name=\"float_fd\">92.0</float>\n    <int name=\"int_id\">70</int>\n    <long name=\"long_ld\">35</long>\n    <str name=\"string_sd\">str9</str>\n  </lst>\n  <lst name=\"sr\">\n    <double name=\"double_dd\">2353.0</double>\n    <double name=\"float_fd\">4299.0</double>\n    <double name=\"int_id\">2891.0</double>\n    <double name=\"long_ld\">1638.0</double>\n  </lst>\n</lst>\n</response>\n\n\n\nThe computed stddev should be what's in:\n\n<lst name=\"st\">\n    <double name=\"float_fd\">27.722251342412257</double>\n  </lst>\n\n\n\nI really don't like this kind of indexOf/indexOf matching \u2013 the test should parse that XML and extract whatever value is needed using XPath... "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13830791",
            "date": "2013-11-23T22:47:47+0000",
            "content": "And it appears with good reason. The response in question has a <lst name=\"str\"> section. The code is looking for a float_fd in that section, but it isn't there.\n\nI found this while converting to DOM parsing. I'll have a patch (that fails) up in a bit that switches to DOM parsing, but I'll leave it up to others to fix the underlying problem...\n\nWhy IBM J9 fails here and not others is a mystery. But the indexOf process in the base class is finding the first \"float_fd\" after the <lst name=\"str\">, whether or not it's in the same lst as far as I can tell.\n\nAt least that's what I'm seeing now, maybe I'm hallucinating. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13830794",
            "date": "2013-11-23T23:03:36+0000",
            "content": "This patch uses the DOM to get the values to return. There are now two tests that fail all of the time, one is the one that's giving us the problem and another is in the other test file.\n\nShould give people a good place to start finding the real problem... "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13830807",
            "date": "2013-11-23T23:54:22+0000",
            "content": "Slightly different version of the patch that takes explicit control of the VAL_TYPEs members toString method rather than relying on toString.toLowerCase.\n\nIt may be that these failures are just bad tests? "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13830816",
            "date": "2013-11-24T00:41:12+0000",
            "content": "Take a look at AnalyticsRequestFactory:\n\nThe following tries to remove a QueryFacetRequest object from a Set<String>:\n\n\n  private static void addQueryFacet(List<QueryFacetRequest> currentList, QueryFacetRequest queryFacet) {\n    Set<String> depends = queryFacet.getDependencies();\n    int place = 0;\n    for (QueryFacetRequest qfr : currentList) {\n      if (qfr.getDependencies().remove(queryFacet)) {\n        break;\n      }\n      place++;\n      depends.remove(qfr.getName());\n    }\n    currentList.add(place,queryFacet);\n    for (int count = place+1; count < currentList.size(); count++) {\n      currentList.get(count).getDependencies().remove(queryFacet.getName());\n    }\n  }\n\n "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13830817",
            "date": "2013-11-24T00:41:59+0000",
            "content": "\n\tDon't know this has anything to do with any test failures - just seemed a decent place to note it without creating a whole new issue.\n\n "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13830939",
            "date": "2013-11-24T13:16:46+0000",
            "content": "Mark's comment lead me to apply the patch fresh to 4x and run IntelliJ's analysis on it. Here's what that process found:\n\n1> Some possible class cast exceptions, but I don't think these are all that important.\n\n2> ExpressionFactory about line 166. The escapedCharacter variable is always false in the test, at the end of the loop there's this code then !escapedCharacter at the top:\nif (escapedCharacter) \n{\n        escapedCharacter=false;\n      }\n\n3> FieldFacetTest, line 1191. The variable 'b' cannot be false inside the for loop. This doesn't matter, but it's useless there.\n\n4> SolrCore, line 2269. \n if (cd != null) {\n      if (null != cd && cd.getCoreContainer() != null) {\n\ncd is never null.\n\n5> StatsCollectionSupplierFactory, line 454. Claim is that src can never be a DateFieldSource. DateFieldSource extends LongFieldSource which is tested above.\n\n6> Mark's comment, this line is removing something other than a String from a Set<String>: \nif (qfr.getDependencies().remove(queryFacet)) {\n\nI'm not sure how relevant some of these are, but they're probably worth examining. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13830973",
            "date": "2013-11-24T16:42:49+0000",
            "content": "This one's been cropping up lately:\n\nBuild: http://jenkins.thetaphi.de/job/Lucene-Solr-trunk-Linux/8448/\nJava: 32bit/jdk1.7.0_45 -server -XX:+UseG1GC\n\n1 tests failed.\nFAILED:  org.apache.solr.analytics.facet.QueryFacetTest.queryTest\n\nError Message:\nThe query facet dependencies [float3] either do not exist or are defined in a dependency looop.\n\nStack Trace:\norg.apache.solr.common.SolrException: The query facet dependencies [float3] either do not exist or are defined in a dependency looop.\n        at __randomizedtesting.SeedInfo.seed([3B67895930059F7A:A67EC7B856AFD0EF]:0)\n        at org.apache.solr.analytics.request.AnalyticsRequestFactory.parse(AnalyticsRequestFactory.java:148)\n        at org.apache.solr.analytics.request.AnalyticsStats.execute(AnalyticsStats.java:66)\n        at org.apache.solr.handler.component.AnalyticsComponent.process(AnalyticsComponent.java:44)\n        at org.apache.solr.handler.component.SearchHandler.handleRequestBody(SearchHandler.java:209)\n        at org.apache.solr.handler.RequestHandlerBase.handleRequest(RequestHandlerBase.java:135)\n        at org.apache.solr.core.SolrCore.execute(SolrCore.java:1866) "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13830977",
            "date": "2013-11-24T16:48:12+0000",
            "content": "Seems to involve map ordering somewhere. Those were only failing on Java 8, but Robert committed a change to have random ordering before 8 as well - that's what a ton of the recent fails are about. So now we should start seeing this one a lot more often - I think I've fixed most of the others, though I'm still verifying/working on that. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13830979",
            "date": "2013-11-24T16:52:12+0000",
            "content": "org.apache.solr.analytics.NoFacetTest.stddevTest\n\nI'm fairly sure that one is the random map ordering only because I never saw it locally until Robert turned on the random map ordering for java 7 - now I see all the time. "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-13830982",
            "date": "2013-11-24T17:12:06+0000",
            "content": "Commit 1545009 from Mark Miller in branch 'dev/trunk'\n[ https://svn.apache.org/r1545009 ]\n\nSOLR-5488: fix set removal bug "
        },
        {
            "author": "Dawid Weiss",
            "id": "comment-13831021",
            "date": "2013-11-24T19:22:52+0000",
            "content": "Mark, can you take a look at my comment above (https://issues.apache.org/jira/browse/SOLR-5488?focusedCommentId=13829443#comment-13829443)? Seems like that fragment of code is hashmap-order dependent, don't know what this may be affecting. "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-13831022",
            "date": "2013-11-24T19:23:45+0000",
            "content": "Commit 1545053 from Mark Miller in branch 'dev/trunk'\n[ https://svn.apache.org/r1545053 ]\n\nSOLR-5488: ignore this test for now "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-13831023",
            "date": "2013-11-24T19:25:44+0000",
            "content": "Commit 1545054 from Mark Miller in branch 'dev/trunk'\n[ https://svn.apache.org/r1545054 ]\n\nSOLR-5488: fix ignore import "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13831043",
            "date": "2013-11-24T20:31:37+0000",
            "content": "Thanks Dawid Weiss - I had only skimmed above and didn't see your comment. I tried making that a linked hashmap and unfortunately the test still fails.\n\nEarlier, I also tried making every hashmap in the analytics code i could find a linked hashmap and this particular test (NoFacetTest.stddevTest) still fails. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13831045",
            "date": "2013-11-24T20:38:51+0000",
            "content": "1 tests failed.\nFAILED: org.apache.solr.analytics.facet.QueryFacetTest.queryTest \n\nI think I stopped seeing this after I fixed the first bug I mentioned above... "
        },
        {
            "author": "Dawid Weiss",
            "id": "comment-13831046",
            "date": "2013-11-24T20:39:55+0000",
            "content": "This is a bummer. I'll see if I can help sometime this week, unless somebody beats me to it. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13831053",
            "date": "2013-11-24T21:04:52+0000",
            "content": "Hold on. You can't rely on the test results given the fact that parsing the response\npackets is done using indexOf etc., see my comments along with the patch.\nUntil that's fixed, things are going to be unreliable.\n\nI'll commit that fix in a few, first I'll @Ignore the tests that now fail all of the time\n "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13831057",
            "date": "2013-11-24T21:21:57+0000",
            "content": "I think it's just that one test failing all the time and I've already ignored it - see the commit comment above.  "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13831058",
            "date": "2013-11-24T21:32:13+0000",
            "content": "There is one more that fails all the time when using XML parsing.\nThe point is that doing the indexOf bit puts everything\nin doubt in my mind. Perhaps there's an \"interesting\" interaction with the\nHashMap issue that you and Dawid have been dealing with. Because any\nchange in the ordering of the output could potentially trigger getting bogus\nfailures (or successes for that matter) in the tests.\n\nI'm actually unclear whether DOM parsing will lead to more or fewer failures,\nbut we'll see starting in about 10 minutes. "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-13831059",
            "date": "2013-11-24T21:33:46+0000",
            "content": "Commit 1545080 from Erick Erickson in branch 'dev/trunk'\n[ https://svn.apache.org/r1545080 ]\n\nSOLR-5488: Added DOM parsing to the test cases rather than string manipulation "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13831067",
            "date": "2013-11-24T22:16:03+0000",
            "content": "There is one more that fails all the time when using XML parsing.\n\nI've been running tests all day and the only one left that fails a lot for me was NoFacetTest.stddevTest. Hopefully your commit has fixed that one. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13831079",
            "date": "2013-11-24T22:51:04+0000",
            "content": "I meant with the proper (well, at least with the version I just committed), there\nwas one more test that failed every time, I assume picking up bogus values\ndue to indexOf getting stuff outside the proper node.\n "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13831084",
            "date": "2013-11-24T23:02:15+0000",
            "content": "Interesting - I think I saw something different unless one of those tests was already ignored by you. I just saw two tests fail a lot - one that stopped failing when I committed the fix for removing the wrong type from Set<String> and the other that I ignored and that has stopped failing with your fix. Any others fails I saw were and some time ago now. "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-13831156",
            "date": "2013-11-25T03:16:29+0000",
            "content": "Commit 1545143 from Mark Miller in branch 'dev/trunk'\n[ https://svn.apache.org/r1545143 ]\n\nSOLR-5488: fix forbidden api call "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13831470",
            "date": "2013-11-25T13:44:58+0000",
            "content": "Thanks, Mark! Sorry I let the forbidden API call slip through...\n\nOK, I'm going to try to summarize where we're at, quite a bit happened over the weekend:\n\n1> Mark, Dawid and I kicked things around and committed some changes that we think are helpful. It would be good if people who know the code (Houston Putman [~Steven bower] are you listening  ) would review the changes to see if they do violence to the intent of the code.\n\n2> There are now two tests that are @Ignore'd. I have no clue whether these are just test errors or point to deeper issues. Again, if Houston and/or Steven can look at them to see and render a judgement call, that would be good.\n\n3> The major take-away is that so far I don't think the test problems we were seeing are due to obscure float conversions, compiler differences, etc, but that the string operations in the tests were producing bogus failures. I'll defer to people who know the code. Un-ignoring the two tests and understanding the consequences is key here.\n\n4> We aren't seeing failures at this point, at least since yesterday. But two tests are ignored. If we can get a resolution to the two @Ignore'd tests, then I can probably commit this to 4x next week. [~Mark Miller][~Dawid Weiss] or anyone else for that matter, does that seem reasonable? Premature? "
        },
        {
            "author": "Steven Bower",
            "id": "comment-13831516",
            "date": "2013-11-25T14:59:29+0000",
            "content": "Will take a look ASAP.. been buried under some other priorities the last few days... "
        },
        {
            "author": "Steven Bower",
            "id": "comment-13831630",
            "date": "2013-11-25T17:11:41+0000",
            "content": "\nIndex: solr/core/src/test-files/analytics/requestFiles/noFacets.txt\n===================================================================\n--- solr/core/src/test-files/analytics/requestFiles/noFacets.txt\t(revision 1545323)\n+++ solr/core/src/test-files/analytics/requestFiles/noFacets.txt\t(working copy)\n@@ -15,7 +15,7 @@\n \n o.str.s.int_id=stddev(int_id)\n o.str.s.long_ld=stddev(long_ld)\n-o.st.s.float_fd=stddev(float_fd)\n+o.str.s.float_fd=stddev(float_fd)\n o.str.s.double_dd=stddev(double_dd)\n \n o.medr.s.int_id=median(int_id)\n\n\n\nChanging the above gets the NoFacets test to work.. basically was missing an 'r' in the input query file.. not sure this fixes everything about this test but certainly wasn't working without this.. obvi need to remove the @Ignore from NoFacetTest stddev test\n "
        },
        {
            "author": "Dawid Weiss",
            "id": "comment-13831633",
            "date": "2013-11-25T17:15:00+0000",
            "content": "> certainly wasn't working without this\n\nThe problem seems to be that it was sometimes working!... It's not like it was failing consistently. "
        },
        {
            "author": "Steven Bower",
            "id": "comment-13831639",
            "date": "2013-11-25T17:20:18+0000",
            "content": "Same for functions test.. input file had errors in it.. although it fails still after the change.. the failure is similar to the NoFacet one... when I do the Double.doubleToRawLongBits the numbers are the same (and assert true on the long bits works but not the double values...\n\n\nIndex: solr/core/src/test-files/analytics/requestFiles/functions.txt\n===================================================================\n--- solr/core/src/test-files/analytics/requestFiles/functions.txt\t(revision 1545323)\n+++ solr/core/src/test-files/analytics/requestFiles/functions.txt\t(working copy)\n@@ -23,10 +23,10 @@\n o.nr.s.mean=mean(neg(long_ld))\n o.nr.s.meanc=mean(neg_l_dd)\n \n-o.nr.s.sum=sum(abs(neg(int_id)))\n-o.nr.s.sumc=sum(int_id)\n-o.nr.s.mean=mean(abs(neg(long_ld)))\n-o.nr.s.meanc=mean(int_id)\n+o.avr.s.sum=sum(abs(neg(int_id)))\n+o.avr.s.sumc=sum(int_id)\n+o.avr.s.mean=mean(abs(neg(long_ld)))\n+o.avr.s.meanc=mean(int_id)\n \n o.cnr.s.sum=sum(const_num(8))\n o.cnr.s.sumc=sum(const_8_dd)\n\n "
        },
        {
            "author": "Houston Putman",
            "id": "comment-13831646",
            "date": "2013-11-25T17:25:01+0000",
            "content": "I'll try to look at the updated stuff tonight. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13831686",
            "date": "2013-11-25T18:16:25+0000",
            "content": "OK, I incorporated your changes into my local copy, seeing what you are.\n\nIt's probably worth keeping the assertEquals idiom in mind with\ndoubles & such, rather than assertTrue(expected == acutal), it's probably more\nrobust to do something like\nassertEquals(\"your message here\", expected, actual, epsilon)\n\nwhere \"epsilon it the amount the values can differ by, i.e.\nMath.abs(expected - actual) < epsilon\n\nThat said, I see result == 17.38 and \n                       calculated == 29.91\n\nso the assertEquals bit isn't going to be super helpful...\n\nI can say that the raw response is consistent here:\n\n  <lst name=\"avr\">\n    <double name=\"mean\">17.38</double>\n    <double name=\"meanc\">29.91</double>\n    <double name=\"sum\">2991.0</double>\n    <double name=\"sumc\">2991.0</double>\n  </lst> "
        },
        {
            "author": "Steven Bower",
            "id": "comment-13831809",
            "date": "2013-11-25T19:26:35+0000",
            "content": "Is that with J9? "
        },
        {
            "author": "Steven Bower",
            "id": "comment-13831837",
            "date": "2013-11-25T19:47:33+0000",
            "content": "Bah.. this test is just broken... its testing:\n\nmean(abs(neg(long_ld))) == mean(int_id) which was just wrong... ie int_id != long_ld\n\nafter fixing that up the test works... will add a more complete patch in a sec "
        },
        {
            "author": "Houston Putman",
            "id": "comment-13831844",
            "date": "2013-11-25T19:53:08+0000",
            "content": "How did all of these tests get mixed up?  "
        },
        {
            "author": "Steven Bower",
            "id": "comment-13831853",
            "date": "2013-11-25T20:00:20+0000",
            "content": "Fixes issues in NoFacetTest and FunctionTest unIgnores the ignored tests "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-13831962",
            "date": "2013-11-25T21:59:10+0000",
            "content": "Commit 1545417 from Erick Erickson in branch 'dev/trunk'\n[ https://svn.apache.org/r1545417 ]\n\nSOLR-5488: Fixing up tests for analytics component "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13831963",
            "date": "2013-11-25T21:59:25+0000",
            "content": "OK, committed. We'll see how the various test environments like this configuration. Works on my machine... "
        },
        {
            "author": "Houston Putman",
            "id": "comment-13832014",
            "date": "2013-11-25T22:46:09+0000",
            "content": "Erick Erickson, addressing some of what IntelliJ found: (You can ignore them if they were already fixed.)\n\n\n2> ExpressionFactory about line 166. The escapedCharacter variable is always false in the test, at the end of the loop there's this code then !escapedCharacter at the top:\nif (escapedCharacter)\n{ escapedCharacter=false; }\nEscaped Character is completely unnecessary. It was something that I added to escape things in strings, such as '(' and ',', but I realized that escaping these characters was not necessary. So any use of it can be removed.\n\n\n3> FieldFacetTest, line 1191. The variable 'b' cannot be false inside the for loop. This doesn't matter, but it's useless there.\nTrue\n\n\nStatsCollectionSupplierFactory, line 454. Claim is that src can never be a DateFieldSource. DateFieldSource extends LongFieldSource which is tested above.\nI'm glad this got caught, and I'm curious as to why it doesn't break things... But it should easily be fixed by checking if it is a DateFieldSource before checking if it is a LongFieldSource. \n\n\n6> Mark's comment, this line is removing something other than a String from a Set<String>: \nif (qfr.getDependencies().remove(queryFacet)) {\nIt should be :\nif (qfr.getDependencies().remove(queryFacet.getName())) {\n\nSorry I would update these and make a patch myself, but my desktop is currently not cooperating.  "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-13832226",
            "date": "2013-11-26T02:42:19+0000",
            "content": "Commit 1545514 from Erick Erickson in branch 'dev/trunk'\n[ https://svn.apache.org/r1545514 ]\n\nSOLR-5488: Fix up test failures for analytics component. Some cleanups suggested by IntelliJ's analysis "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13832227",
            "date": "2013-11-26T02:43:19+0000",
            "content": "I cleaned up the IntelliJ analysis stuff, tests pass. So unless something crops up over the next week, I'll probably merge this into 4x sometime next week. "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-13832572",
            "date": "2013-11-26T13:25:25+0000",
            "content": "Commit 1545650 from Erick Erickson in branch 'dev/trunk'\n[ https://svn.apache.org/r1545650 ]\n\nSOLR-5488: Revamped ExpressionTest to use the DOM parsing in AbstractAnalyticsStatsTest rather than string operations "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13832582",
            "date": "2013-11-26T13:29:34+0000",
            "content": "Found this when looking at the remaining test failure, we'll see if the failure crops up again.\n\nTests run on my machine, but that doesn't mean much since I couldn't reproduce the error from the build log with the seed.\n\nFWIW, I'm trying to put together the 4x stuff on my local machine with all the commits that have been done so far in preparation for back-porting next week if we're lucky. "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-13833869",
            "date": "2013-11-27T15:24:26+0000",
            "content": "Commit 1546074 from Erick Erickson in branch 'dev/trunk'\n[ https://svn.apache.org/r1546074 ]\n\nSOLR-5488: Changing Facets testing to use DOM rather than string operations "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13833874",
            "date": "2013-11-27T15:31:05+0000",
            "content": "I noticed that the Facets testing was also using the indexOf operations, so I fixed that up.\n\nWhat I also did was changed all the assert statements to dump the raw response on failure so we can see what the actual data we're working with is. At least I think I got them all, there are a lot of them, which is good.\n\nWe'll see how this bakes.\n "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-13834494",
            "date": "2013-11-28T03:17:33+0000",
            "content": "Commit 1546263 from Erick Erickson in branch 'dev/trunk'\n[ https://svn.apache.org/r1546263 ]\n\nSOLR-5488: Added more test info output. Somehow lost some of what I did yesterday "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13834900",
            "date": "2013-11-28T14:48:41+0000",
            "content": "OK, I've finally managed to put in the dumps that tell us something.\nIt took me long enough....\n\nSee:  http://jenkins.thetaphi.de/job/Lucene-Solr-trunk-Linux/8492/\nHere's the crux:\n\nLooking for:  /response/lst[@name='stats']/lst[@name='ar']/double[@name='sum'] \n\nin the response. Here's the \"ar\" section. Obviously no \"sum\" value, and the parser\nbarfs. So, is this ever expected? In which it's just a test fix, don't try to parse an\nempty number. If it's not expected, we need to fix the underlying analytics code.\n\nOver to Steven Bower and Houston Putman for a reading on whether this is an\nunderlying code problem or a test issue. Let me know if having empty values is\never expected, and if so I'll fix the tests. If not, I'll look for a patch from someone\nelse that fixes the underlying code.\n\n <lst name=\"ar\">\n    <long name=\"count\">100</long>\n    <null name=\"mcm\"/>\n    <null name=\"mean\"/>\n    <null name=\"median\"/>\n    <null name=\"su\"/>\n    <null name=\"sum\"/>\n    <null name=\"unique\"/>\n  </lst> "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13834920",
            "date": "2013-11-28T15:26:35+0000",
            "content": "Actually, when I look at it, the structure is\njust wrong with the <null name=\"sum\"/> bits.\n\nSo a better question is why is the response \nbeing assembled like this? "
        },
        {
            "author": "Steven Bower",
            "id": "comment-13836560",
            "date": "2013-12-02T14:48:21+0000",
            "content": "That link to jenkins doesn't work for me.. do you have another link or list of tests that failed? "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13836566",
            "date": "2013-12-02T14:54:32+0000",
            "content": "I can do one of several things:\n1> Put the fix for the remaining test issue in tomorrow (Tuesday) night and merge into 4x. Someone needs to supply it  Steven Bower Houston Putman what do you think?\nor\n2> just merge the current code into 4x and have someone apply the fix in both places.\nor\n3> pass it off to someone else for the foreseeable future.\nor\n4> just skip it for 4x and call it a 5x feature.\n\nThe current state is this is in trunk, but not 4x and it's failing tests occasionally. But otherwise things seem fine.\n\nLet me know what people think. This is a significant new feature I don't want it to languish.\n\n\nHere's a list of the merges. I've been trying to keep up with them, I have a local copy with all of them applied, precommit and tests all succeed. I had to do some minor reconciliations along the way.\n\nsvn merge -c 1543651 https://svn.apache.org/repos/asf/lucene/dev/trunk\nsvn merge -c 1545009 https://svn.apache.org/repos/asf/lucene/dev/trunk\nsvn merge -c 1545053 https://svn.apache.org/repos/asf/lucene/dev/trunk\nsvn merge -c 1545054 https://svn.apache.org/repos/asf/lucene/dev/trunk\nsvn merge -c 1545080 https://svn.apache.org/repos/asf/lucene/dev/trunk\nsvn merge -c 1545143 https://svn.apache.org/repos/asf/lucene/dev/trunk\nsvn merge -c 1545417 https://svn.apache.org/repos/asf/lucene/dev/trunk\nsvn merge -c 1545514 https://svn.apache.org/repos/asf/lucene/dev/trunk\nsvn merge -c 1545650 https://svn.apache.org/repos/asf/lucene/dev/trunk\nsvn merge -c 1546074 https://svn.apache.org/repos/asf/lucene/dev/trunk\nsvn merge -c 1546263 https://svn.apache.org/repos/asf/lucene/dev/trunk\n "
        },
        {
            "author": "Steven Bower",
            "id": "comment-13836583",
            "date": "2013-12-02T15:04:50+0000",
            "content": "I think we should try to get it fixed on trunk then merge.. I don't mind doing the merge... Do you have a list of the currently failing issues?\n\nThat being said I'd love to get this in 4.x (it would make my life easier as I wouldn't have to keep my copy in my local source control along with keeping this version up-to-date.. "
        },
        {
            "author": "Steven Bower",
            "id": "comment-13836584",
            "date": "2013-12-02T15:05:58+0000",
            "content": "Per your comment on the original issue.. lets just move forward with 4x.. more people using it will lead to more issues found.. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13836608",
            "date": "2013-12-02T15:31:57+0000",
            "content": "Steven Bower\n\nHere's the most recent failure, this link still works; it's the same pattern:\nhttp://jenkins.thetaphi.de/job/Lucene-Solr-trunk-Linux/8534/consoleFull\n\nHere's the log output, it's not all that helpful though I don't think, it just shows that there are nulls in the sections returned. There's no exception being thrown by the analytics code, it's happily putting nulls in sometimes, e.g. <null name=\"mean\"/>.\n\n[junit4] Suite: org.apache.solr.analytics.expression.ExpressionTest\n   [junit4]   2> 133086 T539 oas.SolrTestCaseJ4.initCore ####initCore\n   [junit4]   2> Creating dataDir: /mnt/ssd/jenkins/workspace/Lucene-Solr-trunk-Linux/solr/build/solr-core/test/J0/./solrtest-ExpressionTest-1385918695507\n   [junit4]   2> 133087 T539 oasc.SolrResourceLoader.<init> new SolrResourceLoader for directory: '/mnt/ssd/jenkins/workspace/Lucene-Solr-trunk-Linux/solr/build/solr-core/test-files/solr/collection1/'\n   [junit4]   2> 133087 T539 oasc.SolrResourceLoader.replaceClassLoader Adding 'file:/mnt/ssd/jenkins/workspace/Lucene-Solr-trunk-Linux/solr/build/solr-core/test-files/solr/collection1/lib/classes/' to classloader\n   [junit4]   2> 133088 T539 oasc.SolrResourceLoader.replaceClassLoader Adding 'file:/mnt/ssd/jenkins/workspace/Lucene-Solr-trunk-Linux/solr/build/solr-core/test-files/solr/collection1/lib/README' to classloader\n   [junit4]   2> 133125 T539 oasc.SolrConfig.<init> Using Lucene MatchVersion: LUCENE_50\n   [junit4]   2> 133160 T539 oasc.SolrConfig.<init> Loaded SolrConfig: solrconfig-basic.xml\n   [junit4]   2> 133161 T539 oass.IndexSchema.readSchema Reading Solr Schema from schema-analytics.xml\n   [junit4]   2> 133165 T539 oass.IndexSchema.readSchema [null] Schema name=schema-docValues\n   [junit4]   2> 133201 T539 oass.IndexSchema.readSchema unique key field: id\n   [junit4]   2> 133203 T539 oasc.SolrResourceLoader.locateSolrHome JNDI not configured for solr (NoInitialContextEx)\n   [junit4]   2> 133203 T539 oasc.SolrResourceLoader.locateSolrHome using system property solr.solr.home: /mnt/ssd/jenkins/workspace/Lucene-Solr-trunk-Linux/solr/build/solr-core/test-files/solr\n   [junit4]   2> 133203 T539 oasc.SolrResourceLoader.<init> new SolrResourceLoader for directory: '/mnt/ssd/jenkins/workspace/Lucene-Solr-trunk-Linux/solr/build/solr-core/test-files/solr/'\n   [junit4]   2> 133211 T539 oasc.SolrResourceLoader.locateSolrHome JNDI not configured for solr (NoInitialContextEx)\n   [junit4]   2> 133211 T539 oasc.SolrResourceLoader.locateSolrHome using system property solr.solr.home: /mnt/ssd/jenkins/workspace/Lucene-Solr-trunk-Linux/solr/build/solr-core/test-files/solr\n   [junit4]   2> 133212 T539 oasc.SolrResourceLoader.<init> new SolrResourceLoader for deduced Solr Home: '/mnt/ssd/jenkins/workspace/Lucene-Solr-trunk-Linux/solr/build/solr-core/test-files/solr/'\n   [junit4]   2> 133251 T539 oasc.CoreContainer.<init> New CoreContainer 1424968760\n   [junit4]   2> 133251 T539 oasc.CoreContainer.load Loading cores into CoreContainer [instanceDir=/mnt/ssd/jenkins/workspace/Lucene-Solr-trunk-Linux/solr/build/solr-core/test-files/solr/]\n   [junit4]   2> 133252 T539 oashc.HttpShardHandlerFactory.getParameter Setting socketTimeout to: 0\n   [junit4]   2> 133253 T539 oashc.HttpShardHandlerFactory.getParameter Setting urlScheme to: http://\n   [junit4]   2> 133253 T539 oashc.HttpShardHandlerFactory.getParameter Setting connTimeout to: 0\n   [junit4]   2> 133253 T539 oashc.HttpShardHandlerFactory.getParameter Setting maxConnectionsPerHost to: 20\n   [junit4]   2> 133254 T539 oashc.HttpShardHandlerFactory.getParameter Setting corePoolSize to: 0\n   [junit4]   2> 133254 T539 oashc.HttpShardHandlerFactory.getParameter Setting maximumPoolSize to: 2147483647\n   [junit4]   2> 133254 T539 oashc.HttpShardHandlerFactory.getParameter Setting maxThreadIdleTime to: 5\n   [junit4]   2> 133255 T539 oashc.HttpShardHandlerFactory.getParameter Setting sizeOfQueue to: -1\n   [junit4]   2> 133255 T539 oashc.HttpShardHandlerFactory.getParameter Setting fairnessPolicy to: false\n   [junit4]   2> 133260 T539 oasl.LogWatcher.createWatcher SLF4J impl is org.slf4j.impl.Log4jLoggerFactory\n   [junit4]   2> 133260 T539 oasl.LogWatcher.newRegisteredLogWatcher Registering Log Listener [Log4j (org.slf4j.impl.Log4jLoggerFactory)]\n   [junit4]   2> 133261 T539 oasc.CoreContainer.load Host Name: \n   [junit4]   2> 133264 T540 oasc.CoreContainer.create Creating SolrCore 'collection1' using instanceDir: /mnt/ssd/jenkins/workspace/Lucene-Solr-trunk-Linux/solr/build/solr-core/test-files/solr/collection1\n   [junit4]   2> 133265 T540 oasc.SolrResourceLoader.<init> new SolrResourceLoader for directory: '/mnt/ssd/jenkins/workspace/Lucene-Solr-trunk-Linux/solr/build/solr-core/test-files/solr/collection1/'\n   [junit4]   2> 133265 T540 oasc.SolrResourceLoader.replaceClassLoader Adding 'file:/mnt/ssd/jenkins/workspace/Lucene-Solr-trunk-Linux/solr/build/solr-core/test-files/solr/collection1/lib/classes/' to classloader\n   [junit4]   2> 133266 T540 oasc.SolrResourceLoader.replaceClassLoader Adding 'file:/mnt/ssd/jenkins/workspace/Lucene-Solr-trunk-Linux/solr/build/solr-core/test-files/solr/collection1/lib/README' to classloader\n   [junit4]   2> 133293 T540 oasc.SolrConfig.<init> Using Lucene MatchVersion: LUCENE_50\n   [junit4]   2> 133318 T540 oasc.SolrConfig.<init> Loaded SolrConfig: solrconfig-basic.xml\n   [junit4]   2> 133319 T540 oass.IndexSchema.readSchema Reading Solr Schema from schema-analytics.xml\n   [junit4]   2> 133323 T540 oass.IndexSchema.readSchema [collection1] Schema name=schema-docValues\n   [junit4]   2> 133346 T540 oass.IndexSchema.readSchema unique key field: id\n   [junit4]   2> 133348 T540 oasc.SolrCore.initDirectoryFactory org.apache.solr.core.MockDirectoryFactory\n   [junit4]   2> 133348 T540 oasc.SolrCore.<init> [collection1] Opening new SolrCore at /mnt/ssd/jenkins/workspace/Lucene-Solr-trunk-Linux/solr/build/solr-core/test-files/solr/collection1/, dataDir=/mnt/ssd/jenkins/workspace/Lucene-Solr-trunk-Linux/solr/build/solr-core/test/J0/./solrtest-ExpressionTest-1385918695507/\n   [junit4]   2> 133348 T540 oasc.SolrCore.<init> JMX monitoring not detected for core: collection1\n   [junit4]   2> 133349 T540 oasc.CachingDirectoryFactory.get return new directory for /mnt/ssd/jenkins/workspace/Lucene-Solr-trunk-Linux/solr/build/solr-core/test/J0/./solrtest-ExpressionTest-1385918695507\n   [junit4]   2> 133349 T540 oasc.SolrCore.getNewIndexDir New index directory detected: old=null new=/mnt/ssd/jenkins/workspace/Lucene-Solr-trunk-Linux/solr/build/solr-core/test/J0/./solrtest-ExpressionTest-1385918695507/index/\n   [junit4]   2> 133349 T540 oasc.SolrCore.initIndex WARN [collection1] Solr index directory '/mnt/ssd/jenkins/workspace/Lucene-Solr-trunk-Linux/solr/build/solr-core/test/J0/./solrtest-ExpressionTest-1385918695507/index' doesn't exist. Creating new index...\n   [junit4]   2> 133350 T540 oasc.CachingDirectoryFactory.get return new directory for /mnt/ssd/jenkins/workspace/Lucene-Solr-trunk-Linux/solr/build/solr-core/test/J0/./solrtest-ExpressionTest-1385918695507/index\n   [junit4]   2> 133350 T540 oasu.RandomMergePolicy.<init> RandomMergePolicy wrapping class org.apache.lucene.index.AlcoholicMergePolicy: [AlcoholicMergePolicy: minMergeSize=0, mergeFactor=10, maxMergeSize=1514715327, maxMergeSizeForForcedMerge=9223372036854775807, calibrateSizeByDeletes=true, maxMergeDocs=2147483647, maxCFSSegmentSizeMB=8.796093022207999E12, noCFSRatio=0.1]\n   [junit4]   2> 133351 T540 oasc.SolrDeletionPolicy.onCommit SolrDeletionPolicy.onCommit: commits: num=1\n   [junit4]   2> \t\tcommit\n{dir=MockDirectoryWrapper(org.apache.lucene.store.RAMDirectory@455604eb lockFactory=org.apache.lucene.store.SingleInstanceLockFactory@d39bbae0),segFN=segments_1,generation=1}\n   [junit4]   2> 133351 T540 oasc.SolrDeletionPolicy.updateCommits newest commit generation = 1\n   [junit4]   2> 133352 T540 oasc.SolrCore.loadUpdateProcessorChains no updateRequestProcessorChain defined as default, creating implicit default\n   [junit4]   2> 133352 T540 oasc.RequestHandlers.initHandlersFromConfig created standard: solr.StandardRequestHandler\n   [junit4]   2> 133353 T540 oasc.RequestHandlers.initHandlersFromConfig created /update: solr.UpdateRequestHandler\n   [junit4]   2> 133354 T540 oashl.XMLLoader.init xsltCacheLifetimeSeconds=60\n   [junit4]   2> 133356 T540 oasu.CommitTracker.<init> Hard AutoCommit: disabled\n   [junit4]   2> 133356 T540 oasu.CommitTracker.<init> Soft AutoCommit: disabled\n   [junit4]   2> 133358 T540 oasu.RandomMergePolicy.<init> RandomMergePolicy wrapping class org.apache.lucene.index.TieredMergePolicy: [TieredMergePolicy: maxMergeAtOnce=46, maxMergeAtOnceExplicit=15, maxMergedSegmentMB=10.669921875, floorSegmentMB=2.173828125, forceMergeDeletesPctAllowed=1.9684768928228613, segmentsPerTier=46.0, maxCFSSegmentSizeMB=8.796093022207999E12, noCFSRatio=0.5299946473124797\n   [junit4]   2> 133359 T540 oasc.SolrDeletionPolicy.onInit SolrDeletionPolicy.onInit: commits: num=1\n   [junit4]   2> \t\tcommit{dir=MockDirectoryWrapper(org.apache.lucene.store.RAMDirectory@455604eb lockFactory=org.apache.lucene.store.SingleInstanceLockFactory@d39bbae0),segFN=segments_1,generation=1}\n   [junit4]   2> 133359 T540 oasc.SolrDeletionPolicy.updateCommits newest commit generation = 1\n   [junit4]   2> 133359 T540 oass.SolrIndexSearcher.<init> Opening Searcher@ae603fb5 main\n   [junit4]   2> 133360 T540 oasc.CoreContainer.registerCore registering core: collection1\n   [junit4]   2> 133360 T541 oasc.SolrCore.registerSearcher [collection1] Registered new searcher Searcher@ae603fb5 main\n{StandardDirectoryReader(segments_1:1:nrt)}\n   [junit4]   2> 133361 T539 oas.SolrTestCaseJ4.initCore ####initCore end\n   [junit4]   2> ASYNC  NEW_CORE C195 name=collection1 org.apache.solr.core.SolrCore@2cb9c3c2\n   [junit4]   2> 133365 T539 C195 oasu.DirectUpdateHandler2.deleteAll [collection1] REMOVING ALL DOCUMENTS FROM INDEX\n   [junit4]   2> 133366 T539 C195 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{deleteByQuery=*:*}\n 0 1\n   [junit4]   2> 133370 T539 C195 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[10000]}\n 0 1\n   [junit4]   2> 133377 T539 C195 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[10001]}\n 0 1\n   [junit4]   2> 133382 T539 C195 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[10002]}\n 0 1\n   [junit4]   2> 133387 T539 C195 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[10003]}\n 0 1\n   [junit4]   2> 133392 T539 C195 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[10004]}\n 0 1\n   [junit4]   2> 133397 T539 C195 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[10005]}\n 0 1\n   [junit4]   2> 133403 T539 C195 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[10006]}\n 0 1\n   [junit4]   2> 133408 T539 C195 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[10007]}\n 0 1\n   [junit4]   2> 133413 T539 C195 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[10008]}\n 0 1\n   [junit4]   2> 133417 T539 C195 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[10009]}\n 0 0\n   [junit4]   2> 133422 T539 C195 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100010]}\n 0 0\n   [junit4]   2> 133427 T539 C195 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100011]}\n 0 1\n   [junit4]   2> 133432 T539 C195 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100012]}\n 0 1\n   [junit4]   2> 133437 T539 C195 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100013]}\n 0 1\n   [junit4]   2> 133442 T539 C195 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100014]}\n 0 1\n   [junit4]   2> 133447 T539 C195 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100015]}\n 0 0\n   [junit4]   2> 133452 T539 C195 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100016]}\n 0 0\n   [junit4]   2> 133457 T539 C195 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100017]}\n 0 0\n   [junit4]   2> 133462 T539 C195 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100018]}\n 0 1\n   [junit4]   2> 133467 T539 C195 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100019]}\n 0 1\n   [junit4]   2> 133472 T539 C195 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100020]}\n 0 1\n   [junit4]   2> 133477 T539 C195 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100021]}\n 0 1\n   [junit4]   2> 133481 T539 C195 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100022]}\n 0 0\n   [junit4]   2> 133486 T539 C195 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100023]}\n 0 0\n   [junit4]   2> 133491 T539 C195 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100024]}\n 0 0\n   [junit4]   2> 133497 T539 C195 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100025]}\n 0 1\n   [junit4]   2> 133502 T539 C195 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100026]}\n 0 1\n   [junit4]   2> 133507 T539 C195 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100027]}\n 0 1\n   [junit4]   2> 133512 T539 C195 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100028]}\n 0 1\n   [junit4]   2> 133517 T539 C195 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100029]}\n 0 1\n   [junit4]   2> 133522 T539 C195 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100030]}\n 0 1\n   [junit4]   2> 133527 T539 C195 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100031]}\n 0 1\n   [junit4]   2> 133534 T539 C195 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100032]}\n 0 1\n   [junit4]   2> 133540 T539 C195 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100033]}\n 0 1\n   [junit4]   2> 133545 T539 C195 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100034]}\n 0 0\n   [junit4]   2> 133550 T539 C195 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100035]}\n 0 0\n   [junit4]   2> 133555 T539 C195 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100036]}\n 0 0\n   [junit4]   2> ASYNC  NEW_CORE C196 name=collection1 org.apache.solr.core.SolrCore@2cb9c3c2\n   [junit4]   2> 133566 T539 C196 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100037]}\n 0 1\n   [junit4]   2> 133570 T539 C196 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100038]}\n 0 0\n   [junit4]   2> 133575 T539 C196 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100039]}\n 0 0\n   [junit4]   2> 133580 T539 C196 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100040]}\n 0 1\n   [junit4]   2> 133585 T539 C196 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100041]}\n 0 1\n   [junit4]   2> 133589 T539 C196 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100042]}\n 0 0\n   [junit4]   2> 133594 T539 C196 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100043]}\n 0 0\n   [junit4]   2> 133599 T539 C196 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100044]}\n 0 1\n   [junit4]   2> 133604 T539 C196 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100045]}\n 0 1\n   [junit4]   2> 133608 T539 C196 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100046]}\n 0 0\n   [junit4]   2> 133613 T539 C196 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100047]}\n 0 0\n   [junit4]   2> 133618 T539 C196 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100048]}\n 0 1\n   [junit4]   2> 133623 T539 C196 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100049]}\n 0 1\n   [junit4]   2> 133628 T539 C196 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100050]}\n 0 1\n   [junit4]   2> 133633 T539 C196 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100051]}\n 0 1\n   [junit4]   2> 133638 T539 C196 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100052]}\n 0 1\n   [junit4]   2> 133643 T539 C196 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100053]}\n 0 1\n   [junit4]   2> 133648 T539 C196 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100054]}\n 0 1\n   [junit4]   2> 133653 T539 C196 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100055]}\n 0 0\n   [junit4]   2> 133660 T539 C196 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100056]}\n 0 1\n   [junit4]   2> 133665 T539 C196 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100057]}\n 0 0\n   [junit4]   2> 133670 T539 C196 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100058]}\n 0 1\n   [junit4]   2> 133675 T539 C196 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100059]}\n 0 1\n   [junit4]   2> 133680 T539 C196 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100060]}\n 0 1\n   [junit4]   2> 133684 T539 C196 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100061]}\n 0 0\n   [junit4]   2> 133689 T539 C196 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100062]}\n 0 0\n   [junit4]   2> 133694 T539 C196 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100063]}\n 0 1\n   [junit4]   2> 133699 T539 C196 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100064]}\n 0 1\n   [junit4]   2> 133704 T539 C196 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100065]}\n 0 1\n   [junit4]   2> 133708 T539 C196 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100066]}\n 0 0\n   [junit4]   2> 133713 T539 C196 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100067]}\n 0 0\n   [junit4]   2> 133718 T539 C196 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100068]}\n 0 0\n   [junit4]   2> 133723 T539 C196 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100069]}\n 0 1\n   [junit4]   2> 133728 T539 C196 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100070]}\n 0 1\n   [junit4]   2> 133733 T539 C196 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100071]}\n 0 1\n   [junit4]   2> 133738 T539 C196 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100072]}\n 0 1\n   [junit4]   2> 133743 T539 C196 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100073]}\n 0 1\n   [junit4]   2> 133747 T539 C196 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100074]}\n 0 0\n   [junit4]   2> 133752 T539 C196 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100075]}\n 0 1\n   [junit4]   2> 133757 T539 C196 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100076]}\n 0 1\n   [junit4]   2> 133762 T539 C196 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100077]}\n 0 1\n   [junit4]   2> 133766 T539 C196 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100078]}\n 0 0\n   [junit4]   2> 133771 T539 C196 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100079]}\n 0 0\n   [junit4]   2> 133777 T539 C196 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100080]}\n 0 1\n   [junit4]   2> 133784 T539 C196 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100081]}\n 0 1\n   [junit4]   2> 133791 T539 C196 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100082]}\n 0 0\n   [junit4]   2> 133799 T539 C196 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100083]}\n 0 0\n   [junit4]   2> 133807 T539 C196 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100084]}\n 0 1\n   [junit4]   2> 133814 T539 C196 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100085]}\n 0 0\n   [junit4]   2> 133822 T539 C196 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100086]}\n 0 1\n   [junit4]   2> 133829 T539 C196 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100087]}\n 0 0\n   [junit4]   2> 133835 T539 C196 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100088]}\n 0 1\n   [junit4]   2> 133840 T539 C196 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100089]}\n 0 1\n   [junit4]   2> 133845 T539 C196 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100090]}\n 0 1\n   [junit4]   2> 133850 T539 C196 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100091]}\n 0 1\n   [junit4]   2> 133855 T539 C196 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100092]}\n 0 1\n   [junit4]   2> 133860 T539 C196 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100093]}\n 0 1\n   [junit4]   2> 133865 T539 C196 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100094]}\n 0 1\n   [junit4]   2> 133870 T539 C196 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100095]}\n 0 1\n   [junit4]   2> 133875 T539 C196 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100096]}\n 0 1\n   [junit4]   2> 133880 T539 C196 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100097]}\n 0 0\n   [junit4]   2> 133885 T539 C196 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100098]}\n 0 0\n   [junit4]   2> 133890 T539 C196 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100099]}\n 0 0\n   [junit4]   2> 133895 T539 C196 oasu.DirectUpdateHandler2.commit start commit\n{,optimize=false,openSearcher=true,waitSearcher=true,expungeDeletes=false,softCommit=false,prepareCommit=false}\n   [junit4]   2> 133919 T539 C196 oasc.SolrDeletionPolicy.onCommit SolrDeletionPolicy.onCommit: commits: num=2\n   [junit4]   2> \t\tcommit\n{dir=MockDirectoryWrapper(org.apache.lucene.store.RAMDirectory@455604eb lockFactory=org.apache.lucene.store.SingleInstanceLockFactory@d39bbae0),segFN=segments_1,generation=1}\n   [junit4]   2> \t\tcommit\n{dir=MockDirectoryWrapper(org.apache.lucene.store.RAMDirectory@455604eb lockFactory=org.apache.lucene.store.SingleInstanceLockFactory@d39bbae0),segFN=segments_2,generation=2}\n   [junit4]   2> 133919 T539 C196 oasc.SolrDeletionPolicy.updateCommits newest commit generation = 2\n   [junit4]   2> 133927 T539 C196 oass.SolrIndexSearcher.<init> Opening Searcher@b94c4bdc main\n   [junit4]   2> 133929 T539 C196 oasu.DirectUpdateHandler2.commit end_commit_flush\n   [junit4]   2> 133929 T541 oasc.SolrCore.registerSearcher [collection1] Registered new searcher Searcher@b94c4bdc main\n{StandardDirectoryReader(segments_2:4:nrt _0(5.0):C100)}\n   [junit4]   2> 133930 T539 C196 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{commit=}\n 0 35\n   [junit4]   2> 133972 T539 C196 oasc.SolrCore.execute [collection1] webapp=null path=null params=\n{stats=true&o.csr.s.cs2=const_str(this+is+the+second)&o.pr.s.mean=mean(int_id)&o.cr.s.ccmin=concat(const_str(this+is+the+first),min(string_sd))&o.dmr.s.max=max(date_dtd)&o.mr.s.count=count(long_ld)&o.cdr.s.cs1=const_str(1800-12-31T23:59:59Z)&o.cr.s.min=min(string_sd)&o.dr.s.su=div(sum(int_id),unique(long_ld))&o.mr.s.median=median(int_id)&o.nr.s.s=neg(sum(int_id))&o.cr.s.csmax=const_str(this+is+the+second)&o.dr.s.mean=mean(int_id)&o.pr.s.mc=pow(mean(int_id),count(long_ld))&o.avr.s.count=count(long_ld)&o.cdr.s.cd1=const_date(1800-12-31T23:59:59Z)&o.cdr.s.cd2=const_date(1804-06-30T23:59:59Z)&o.ar.s.mcm=add(mean(int_id),count(long_ld),median(int_id))&o.pr.s.su=pow(sum(int_id),unique(long_ld))&rows=0&o.dr.s.mc=div(mean(int_id),count(long_ld))&o.ar.s.unique=unique(long_ld)&o.csr.s.cs3=const_str(this+is+the+third)&o.dmr.s.dmma=date_math(max(date_dtd),const_str(%2B2MONTHS))&o.ar.s.median=median(int_id)&o.csr.s.cs1=const_str(this+is+the+first)&o.ar.s.su=add(sum(int_id),unique(long_ld))&o.mr.s.mean=mean(int_id)&o.cr.s.ccmax=concat(const_str(this+is+the+second),max(string_sd))&o.cdr.s.cs2=const_str(1804-06-30T23:59:59Z)&o.dmr.s.median=median(date_dtd)&o.mr.s.unique=unique(long_ld)&o.pr.s.count=count(long_ld)&olap=true&o.avr.s.c=abs(neg(count(long_ld)))&o.rr.s.max=max(string_sd)&o.mr.s.sum=sum(int_id)&o.cnr.s.c8=const_num(8)&o.mr.s.su=mult(sum(int_id),unique(long_ld))&indent=true&o.dr.s.unique=unique(long_ld)&o.dr.s.count=count(long_ld)&o.ar.s.mean=mean(int_id)&o.avr.s.s=abs(neg(sum(int_id)))&o.mr.s.mcm=mult(mean(int_id),count(long_ld),median(int_id))&o.avr.s.sum=sum(int_id)&o.nr.s.sum=sum(int_id)&o.pr.s.unique=unique(long_ld)&o.cnr.s.c10=const_num(10)&o.dr.s.sum=sum(int_id)&o.ar.s.count=count(long_ld)&o.dmr.s.dmme=date_math(median(date_dtd),const_str(%2B2YEARS))&o.rr.s.rmin=rev(min(string_sd))&o.cr.s.max=max(string_sd)&o.rr.s.rmax=rev(max(string_sd))&o.ar.s.sum=sum(int_id)&o.nr.s.count=count(long_ld)&o.pr.s.sum=sum(int_id)&o.rr.s.min=min(string_sd)&o.cr.s.csmin=const_str(this+is+the+first)&o.dmr.s.cma=const_str(%2B2MONTHS)&q=*:*&o.dmr.s.cme=const_str(%2B2YEARS)&o.nr.s.c=neg(count(long_ld))}\n hits=100 status=0 QTime=38 \n   [junit4]   2> 133982 T539 oas.SolrTestCaseJ4.setUp ###Starting divideTest\n   [junit4]   2> 133989 T539 oas.SolrTestCaseJ4.tearDown ###Ending divideTest\n   [junit4]   2> 133996 T539 oas.SolrTestCaseJ4.setUp ###Starting concatenateTest\n   [junit4]   2> 134002 T539 oas.SolrTestCaseJ4.tearDown ###Ending concatenateTest\n   [junit4]   2> 134009 T539 oas.SolrTestCaseJ4.setUp ###Starting constantDateTest\n   [junit4]   2> 134015 T539 oas.SolrTestCaseJ4.tearDown ###Ending constantDateTest\n   [junit4]   2> 134021 T539 oas.SolrTestCaseJ4.setUp ###Starting constantStringTest\n   [junit4]   2> 134023 T539 oas.SolrTestCaseJ4.tearDown ###Ending constantStringTest\n   [junit4]   2> 134027 T539 oas.SolrTestCaseJ4.setUp ###Starting powerTest\n   [junit4]   2> 134032 T539 oas.SolrTestCaseJ4.tearDown ###Ending powerTest\n   [junit4]   2> 134036 T539 oas.SolrTestCaseJ4.setUp ###Starting reverseTest\n   [junit4]   2> 134039 T539 oas.SolrTestCaseJ4.tearDown ###Ending reverseTest\n   [junit4]   2> 134047 T539 oas.SolrTestCaseJ4.setUp ###Starting addTest\n   [junit4]   2> 134052 T539 oas.SolrTestCaseJ4.tearDown ###Ending addTest\n   [junit4]   2> 134057 T539 oas.SolrTestCaseJ4.setUp ###Starting negateTest\n   [junit4]   2> 134060 T539 oas.SolrTestCaseJ4.tearDown ###Ending negateTest\n   [junit4]   2> 134065 T539 oas.SolrTestCaseJ4.setUp ###Starting dateMathTest\n   [junit4]   2> 134070 T539 oas.SolrTestCaseJ4.tearDown ###Ending dateMathTest\n   [junit4]   2> 134077 T539 oas.SolrTestCaseJ4.setUp ###Starting absoluteValueTest\n   [junit4]   2> 134082 T539 oas.SolrTestCaseJ4.tearDown ###Ending absoluteValueTest\n   [junit4]   2> 134090 T539 oas.SolrTestCaseJ4.setUp ###Starting multiplyTest\n   [junit4]   2> 134092 T539 oas.SolrTestCaseJ4.tearDown ###Ending multiplyTest\n   [junit4]   2> NOTE: reproduce with: ant test  -Dtestcase=ExpressionTest -Dtests.method=multiplyTest -Dtests.seed=865248978DC22F8C -Dtests.multiplier=3 -Dtests.slow=true -Dtests.locale=th_TH_TH_#u-nu-thai -Dtests.timezone=Europe/Prague -Dtests.file.encoding=ISO-8859-1\n   [junit4] FAILURE 0.02s J0 | ExpressionTest.multiplyTest <<<\n   [junit4]    > Throwable #1: java.lang.AssertionError: Caught exception in getStatResult, xPath = /response/lst[@name='stats']/lst[@name='mr']/double[@name='sum'] \n   [junit4]    > raw data: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n   [junit4]    > <response>\n   [junit4]    > <lst name=\"responseHeader\">\n   [junit4]    >   <int name=\"status\">0</int>\n   [junit4]    >   <int name=\"QTime\">38</int>\n   [junit4]    > </lst>\n   [junit4]    > <result name=\"response\" numFound=\"100\" start=\"0\">\n   [junit4]    > </result>\n   [junit4]    > <lst name=\"stats\">\n   [junit4]    >   <lst name=\"stats_fields\"/>\n   [junit4]    > </lst>\n   [junit4]    > <lst name=\"stats\">\n   [junit4]    >   <lst name=\"cnr\">\n   [junit4]    >     <double name=\"c10\">10.0</double>\n   [junit4]    >     <double name=\"c8\">8.0</double>\n   [junit4]    >   </lst>\n   [junit4]    >   <lst name=\"dr\">\n   [junit4]    >     <long name=\"count\">100</long>\n   [junit4]    >     <double name=\"mc\">0.2891</double>\n   [junit4]    >     <double name=\"mean\">28.91</double>\n   [junit4]    >     <double name=\"su\">80.30555555555556</double>\n   [junit4]    >     <double name=\"sum\">2891.0</double>\n   [junit4]    >     <long name=\"unique\">36</long>\n   [junit4]    >   </lst>\n   [junit4]    >   <lst name=\"cr\">\n   [junit4]    >     <str name=\"ccmax\">this is the secondstr9</str>\n   [junit4]    >     <str name=\"ccmin\">this is the firststr0</str>\n   [junit4]    >     <str name=\"csmax\">this is the second</str>\n   [junit4]    >     <str name=\"csmin\">this is the first</str>\n   [junit4]    >     <str name=\"max\">str9</str>\n   [junit4]    >     <str name=\"min\">str0</str>\n   [junit4]    >   </lst>\n   [junit4]    >   <lst name=\"pr\">\n   [junit4]    >     <long name=\"count\">100</long>\n   [junit4]    >     <double name=\"mc\">1.2729436151389237E146</double>\n   [junit4]    >     <double name=\"mean\">28.91</double>\n   [junit4]    >     <double name=\"su\">3.9603293116911423E124</double>\n   [junit4]    >     <double name=\"sum\">2891.0</double>\n   [junit4]    >     <long name=\"unique\">36</long>\n   [junit4]    >   </lst>\n   [junit4]    >   <lst name=\"mr\">\n   [junit4]    >     <long name=\"count\">100</long>\n   [junit4]    >     <null name=\"mcm\"/>\n   [junit4]    >     <null name=\"mean\"/>\n   [junit4]    >     <null name=\"median\"/>\n   [junit4]    >     <null name=\"su\"/>\n   [junit4]    >     <null name=\"sum\"/>\n   [junit4]    >     <null name=\"unique\"/>\n   [junit4]    >   </lst>\n   [junit4]    >   <lst name=\"avr\">\n   [junit4]    >     <double name=\"c\">100.0</double>\n   [junit4]    >     <long name=\"count\">100</long>\n   [junit4]    >     <double name=\"s\">2891.0</double>\n   [junit4]    >     <double name=\"sum\">2891.0</double>\n   [junit4]    >   </lst>\n   [junit4]    >   <lst name=\"cdr\">\n   [junit4]    >     <date name=\"cd1\">1800-12-31T23:59:59Z</date>\n   [junit4]    >     <date name=\"cd2\">1804-06-30T23:59:59Z</date>\n   [junit4]    >     <str name=\"cs1\">1800-12-31T23:59:59Z</str>\n   [junit4]    >     <str name=\"cs2\">1804-06-30T23:59:59Z</str>\n   [junit4]    >   </lst>\n   [junit4]    >   <lst name=\"dmr\">\n   [junit4]    >     <str name=\"cma\">+2MONTHS</str>\n   [junit4]    >     <str name=\"cme\">+2YEARS</str>\n   [junit4]    >     <date name=\"dmma\">1812-02-29T23:59:59Z</date>\n   [junit4]    >     <date name=\"dmme\">1807-12-31T23:59:59Z</date>\n   [junit4]    >     <date name=\"max\">1811-12-31T23:59:59Z</date>\n   [junit4]    >     <date name=\"median\">1805-12-31T23:59:59Z</date>\n   [junit4]    >   </lst>\n   [junit4]    >   <lst name=\"rr\">\n   [junit4]    >     <str name=\"max\">str9</str>\n   [junit4]    >     <str name=\"min\">str0</str>\n   [junit4]    >     <str name=\"rmax\">9rts</str>\n   [junit4]    >     <str name=\"rmin\">0rts</str>\n   [junit4]    >   </lst>\n   [junit4]    >   <lst name=\"ar\">\n   [junit4]    >     <long name=\"count\">100</long>\n   [junit4]    >     <double name=\"mcm\">153.41</double>\n   [junit4]    >     <double name=\"mean\">28.91</double>\n   [junit4]    >     <double name=\"median\">24.5</double>\n   [junit4]    >     <double name=\"su\">2927.0</double>\n   [junit4]    >     <double name=\"sum\">2891.0</double>\n   [junit4]    >     <long name=\"unique\">36</long>\n   [junit4]    >   </lst>\n   [junit4]    >   <lst name=\"csr\">\n   [junit4]    >     <str name=\"cs1\">this is the first</str>\n   [junit4]    >     <str name=\"cs2\">this is the second</str>\n   [junit4]    >     <str name=\"cs3\">this is the third</str>\n   [junit4]    >   </lst>\n   [junit4]    >   <lst name=\"nr\">\n   [junit4]    >     <double name=\"c\">-100.0</double>\n   [junit4]    >     <long name=\"count\">100</long>\n   [junit4]    >     <double name=\"s\">-2891.0</double>\n   [junit4]    >     <double name=\"sum\">2891.0</double>\n   [junit4]    >   </lst>\n   [junit4]    > </lst>\n   [junit4]    > </response>\n   [junit4]    > \tat __randomizedtesting.SeedInfo.seed([865248978DC22F8C:EDD356E9B8CC19E2]:0)\n   [junit4]    > \tat org.apache.solr.analytics.AbstractAnalyticsStatsTest.getStatResult(AbstractAnalyticsStatsTest.java:113)\n   [junit4]    > \tat org.apache.solr.analytics.expression.ExpressionTest.multiplyTest(ExpressionTest.java:92)\n   [junit4]    > \tat java.lang.Thread.run(Thread.java:780)\n   [junit4]   2> 134107 T539 oas.SolrTestCaseJ4.setUp ###Starting constantNumberTest\n   [junit4]   2> 134110 T539 oas.SolrTestCaseJ4.tearDown ###Ending constantNumberTest\n   [junit4]   2> 134112 T539 oas.SolrTestCaseJ4.deleteCore ###deleteCore\n   [junit4]   2> 134112 T539 oasc.CoreContainer.shutdown Shutting down CoreContainer instance=1424968760\n   [junit4]   2> 134113 T539 oasc.SolrCore.close [collection1]  CLOSING SolrCore org.apache.solr.core.SolrCore@2cb9c3c2\n   [junit4]   2> 134113 T539 oasu.DirectUpdateHandler2.close closing DirectUpdateHandler2\n{commits=1,autocommits=0,soft autocommits=0,optimizes=0,rollbacks=0,expungeDeletes=0,docsPending=0,adds=0,deletesById=0,deletesByQuery=0,errors=0,cumulative_adds=100,cumulative_deletesById=0,cumulative_deletesByQuery=1,cumulative_errors=0}\n   [junit4]   2> 134114 T539 oasu.SolrCoreState.decrefSolrCoreState Closing SolrCoreState\n   [junit4]   2> 134114 T539 oasu.DefaultSolrCoreState.closeIndexWriter SolrCoreState ref count has reached 0 - closing IndexWriter\n   [junit4]   2> 134115 T539 oasu.DefaultSolrCoreState.closeIndexWriter closing IndexWriter with IndexWriterCloser\n   [junit4]   2> 134119 T539 oasc.SolrCore.closeSearcher [collection1] Closing main searcher on request.\n   [junit4]   2> 134119 T539 oasc.CachingDirectoryFactory.close Closing MockDirectoryFactory - 2 directories currently being tracked\n   [junit4]   2> 134120 T539 oasc.CachingDirectoryFactory.closeCacheValue looking to close /mnt/ssd/jenkins/workspace/Lucene-Solr-trunk-Linux/solr/build/solr-core/test/J0/./solrtest-ExpressionTest-1385918695507 [CachedDir<<refCount=0;path=/mnt/ssd/jenkins/workspace/Lucene-Solr-trunk-Linux/solr/build/solr-core/test/J0/./solrtest-ExpressionTest-1385918695507;done=false>>]\n   [junit4]   2> 134120 T539 oasc.CachingDirectoryFactory.close Closing directory: /mnt/ssd/jenkins/workspace/Lucene-Solr-trunk-Linux/solr/build/solr-core/test/J0/./solrtest-ExpressionTest-1385918695507\n   [junit4]   2> 134121 T539 oasc.CachingDirectoryFactory.closeCacheValue looking to close /mnt/ssd/jenkins/workspace/Lucene-Solr-trunk-Linux/solr/build/solr-core/test/J0/./solrtest-ExpressionTest-1385918695507/index [CachedDir<<refCount=0;path=/mnt/ssd/jenkins/workspace/Lucene-Solr-trunk-Linux/solr/build/solr-core/test/J0/./solrtest-ExpressionTest-1385918695507/index;done=false>>]\n   [junit4]   2> 134121 T539 oasc.CachingDirectoryFactory.close Closing directory: /mnt/ssd/jenkins/workspace/Lucene-Solr-trunk-Linux/solr/build/solr-core/test/J0/./solrtest-ExpressionTest-1385918695507/index\n   [junit4]   2> NOTE: test params are: codec=Lucene46: \n{string_sd=PostingsFormat(name=FSTPulsing41), float_fd=PostingsFormat(name=FSTPulsing41), id=FST41, int_id=PostingsFormat(name=FSTPulsing41), double_dd=PostingsFormat(name=MockRandom), long_ld=FST41, date_dtd=FST41}\n, docValues:\n{intdv=DocValuesFormat(name=SimpleText), int_id=DocValuesFormat(name=SimpleText), stringdvm=DocValuesFormat(name=Memory), long_ld=DocValuesFormat(name=Disk), stringdv=DocValuesFormat(name=Disk), floatdv=DocValuesFormat(name=Memory), float_fd=DocValuesFormat(name=Disk), string_sd=DocValuesFormat(name=SimpleText), longdv=DocValuesFormat(name=Memory), date_dtd=DocValuesFormat(name=Disk), datedv=DocValuesFormat(name=Lucene45), double_dd=DocValuesFormat(name=Memory), doubledv=DocValuesFormat(name=Disk)}\n, sim=DefaultSimilarity, locale=th_TH_TH_#u-nu-thai, timezone=Europe/Prague\n   [junit4]   2> NOTE: Linux 3.8.0-33-generic amd64/IBM Corporation 1.7.0 (64-bit)/cpus=8,threads=1,free=106032912,total=168886272\n   [junit4]   2> NOTE: All tests run in this JVM: [TestShardHandlerFactory, ShardRoutingTest, TestFunctionQuery, TestSort, DateMathParserTest, IndexSchemaTest, SOLR749Test, TestSimpleQParserPlugin, InfoHandlerTest, TestModifyConfFiles, TestSuggestSpellingConverter, TestNonNRTOpen, SliceStateTest, TestPerFieldSimilarity, TestSolrIndexConfig, BJQParserTest, TestSolrDeletionPolicy1, RangeFacetTest, TestDistributedMissingSort, SpellPossibilityIteratorTest, UpdateParamsTest, FieldMutatingUpdateProcessorTest, TestNoOpRegenerator, TestDocSet, TestQueryUtils, FunctionTest, DistributedTermsComponentTest, DistributedQueryElevationComponentTest, DeleteInactiveReplicaTest, JsonLoaderTest, DocumentBuilderTest, BasicFunctionalityTest, TestRemoteStreaming, MBeansHandlerTest, TestStressUserVersions, TestInfoStreamLogging, TestValueSourceCache, TestNRTOpen, SolrCoreTest, LukeRequestHandlerTest, TestConfig, LeaderElectionTest, TestElisionMultitermQuery, URLClassifyProcessorTest, HdfsSyncSliceTest, TestDefaultSearchFieldResource, CacheHeaderTest, MoreLikeThisHandlerTest, CopyFieldTest, TermsComponentTest, TestMaxScoreQueryParser, UUIDFieldTest, ExpressionTest]\n   [junit4] Completed on J0 in 1.06s, 12 tests, 1 failure <<< FAILURES! "
        },
        {
            "author": "Houston Putman",
            "id": "comment-13836982",
            "date": "2013-12-02T22:14:56+0000",
            "content": "I'm all for putting this in 4.x. \n\nRegarding the test failures with weird nulls in the results, I don't know what the issue is... How often does it happen? "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13836998",
            "date": "2013-12-02T22:26:12+0000",
            "content": "It seems to happen at least once or twice a night on some of the test machines. I cannot make it happen at will, or at all on my machine for that matter.\n\nIf you subscribe to the dev list, you'll see them pretty much each day, particularly in the morning. It may be this happens with some of the @nightly. But I can't seem to reproduce this, even with the seeds. See: http://lucene.apache.org/solr/discussion.html and the dev@lucene.apache.org "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13837693",
            "date": "2013-12-03T13:43:52+0000",
            "content": "I'm going to commit this to 4x this afternoon unless there are objections. The test that fails isn't a regression, so... I don't like putting code in 4x that has a sproadic test failure, but life isn't always tidy and I have a time limit.\n\nOr a committer can volunteer to take this over until I can work with it again. "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-13837710",
            "date": "2013-12-03T14:00:40+0000",
            "content": "Hi Erick,\nCan you simply add an @Ignore to the test with a message mentioning the issue? "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13837726",
            "date": "2013-12-03T14:21:27+0000",
            "content": "The test that fails varies, and since it's intermittent we need some test machines to generate it to track I think. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13838402",
            "date": "2013-12-04T00:43:21+0000",
            "content": "OK, there are objections. I wasn't all that comfortable checking in known-test-failing code anyway.\n\nSo, anyone who wants to take this over for the foreseeable future please take this (and SOLR-5302 as well).\n\nHere's the current merge list for getting the trunk code to 4x (repeated from above). This will merge back in 5302 and all the testing changes from this JIRA.\n\nIf this isn't committed by the time I can pick it up again, I'll come back to it. But it'll be a while.\n\nsvn merge -c 1543651 https://svn.apache.org/repos/asf/lucene/dev/trunk\nsvn merge -c 1545009 https://svn.apache.org/repos/asf/lucene/dev/trunk\nsvn merge -c 1545053 https://svn.apache.org/repos/asf/lucene/dev/trunk\nsvn merge -c 1545054 https://svn.apache.org/repos/asf/lucene/dev/trunk\nsvn merge -c 1545080 https://svn.apache.org/repos/asf/lucene/dev/trunk\nsvn merge -c 1545143 https://svn.apache.org/repos/asf/lucene/dev/trunk\nsvn merge -c 1545417 https://svn.apache.org/repos/asf/lucene/dev/trunk\nsvn merge -c 1545514 https://svn.apache.org/repos/asf/lucene/dev/trunk\nsvn merge -c 1545650 https://svn.apache.org/repos/asf/lucene/dev/trunk\nsvn merge -c 1546074 https://svn.apache.org/repos/asf/lucene/dev/trunk\nsvn merge -c 1546263 https://svn.apache.org/repos/asf/lucene/dev/trunk "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13865470",
            "date": "2014-01-08T14:21:42+0000",
            "content": "What's our status here? There are still occasional test failures on trunk, all relating to returning <null> values. I'm reluctant to merge this back into 4x until they're resolved. I've been out of country for the last month, so I'm catching back up.\n\nIt's reasonable to put some temporary logging in to see if we can track this down, since the failures don't seem to be reproducible at will. If you do, please flag them with something like \"remove me\" so we can find them all. Do not flag them with //nocommit since that'll cause problems....\n\nLet me know,\nErick "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13865483",
            "date": "2014-01-08T14:36:37+0000",
            "content": "It's not reproducible by will, but it's pretty easy to reproduce. I see it fairly frequently in my local runs. "
        },
        {
            "author": "Steven Bower",
            "id": "comment-13865520",
            "date": "2014-01-08T15:05:59+0000",
            "content": "Mark Miller what environment are you running in where you see the failures? (i've not been able to reproduce on my end).. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13865657",
            "date": "2014-01-08T17:20:36+0000",
            "content": "Linux. The occur pretty frequently in the jenkins runs too, but I have not paid attention to if it's just a specific OS. I assumed it was a timing issue. Those can be hard to duplicate sometimes either due to raw hardware speed differences or other differences leading to different tests running at the same time, etc. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13868758",
            "date": "2014-01-11T12:33:59+0000",
            "content": "Mark Miller Steven Bower\n\nHow should we proceed? We're really back to debugging by println, shades of my youth.\n\nMark:\nWhat's your linux setup? A VM or bare metal? I can't seem to get this to happen locally, although I'll give it a concentrated effort today on my Mac. Otherwise I could install a VM I suppose.... Or would you be willing to apply some debug-only patches and run? \n\nSteve:\nIn order to track this down, and since it's on trunk, what do you think about providing some debug patches (let's call them something like SOLR-5488-debug.patch). If nobody objects we can put them on trunk and let Jenkins reproduce the problems and examine the tracing. Maybe this would just be changing the log level...\n\nOf course if I can get this to happen locally I can run things, but I haven't seen this locally yet.\n\nLet me know... "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13868815",
            "date": "2014-01-11T15:46:32+0000",
            "content": "OK, I can see failures on my Mac. I bumped the iterations to 10,000. First run was OK, second run showed failures. Here's the command:\n\nant test -Dtestcase=ExpressionTest -Dtests.iters=10000\n\nI'd set the heap to 4G FWIW, not sure it was necessary but I was getting memory problems when trying to iterate 100,000 times...\n\nSet the heap with:\nexport ANT_OPTS=-Xmx4G\n\nSo, if Steve and/or Houston have things to try, I should be able to verify/report on what happens reasonably easily.\n\nPossibly useful observation: It appears that once it's in this state it stays in this state. That is each iteration seems to be failing now.\n\nFWIW "
        },
        {
            "author": "Steven Bower",
            "id": "comment-13869769",
            "date": "2014-01-13T18:04:37+0000",
            "content": "will attempt to reconcile ... backed up on some other work.. will try to repro using your suggested approach "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13874735",
            "date": "2014-01-17T12:58:30+0000",
            "content": "Steven Bower I may have some cycles over the next couple of weeks to see if I can understand what's going on. On the surface, it looks like a race condition....\n\nBefore I poke around blindly in the code, can you point me to where you'd start trying to diagnose?\n\nThanks... "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-13876558",
            "date": "2014-01-20T16:31:13+0000",
            "content": "Commit 1559770 from Mark Miller in branch 'dev/trunk'\n[ https://svn.apache.org/r1559770 ]\n\nSOLR-5488: print exception stack trace rather than eating it "
        },
        {
            "author": "Steven Bower",
            "id": "comment-13880182",
            "date": "2014-01-23T18:25:21+0000",
            "content": "Erik Eriksson Sorry for the delay.. I am looking at this today.. I think i was able to reproduce on my windows box using the 10k iters above... "
        },
        {
            "author": "Steven Bower",
            "id": "comment-13880248",
            "date": "2014-01-23T19:19:22+0000",
            "content": "one thing i noticed in the output above is this:\n\n\n[junit4] > <lst name=\"mr\">\n[junit4] > <long name=\"count\">100</long>\n[junit4] > <null name=\"mcm\"/>\n[junit4] > <null name=\"mean\"/>\n[junit4] > <null name=\"median\"/>\n[junit4] > <null name=\"su\"/>\n[junit4] > <null name=\"sum\"/>\n[junit4] > <null name=\"unique\"/>\n[junit4] > </lst>\n\n\n\nnotice the <null in the response... trying to track this down now.. this is certainly why the test is failing.. "
        },
        {
            "author": "Steven Bower",
            "id": "comment-13880420",
            "date": "2014-01-23T22:06:31+0000",
            "content": "Attached is a patch (to trunk) that fixes a few issues as well as adding some additional checks/exceptions/logging:\n\n\n\tcheck that getStatResult resturns non-null/empty strings. There were a few tests that were actually failing but not reporting as such (eg get to string stats and concat them but when both werent there it would concat 2 empty strings and succeed\n\tWhen we fail to create an accumulator it was just println'ing the exception vs logging it so we can see a full stack trace\n\tMoved call to docs.getTopFilter() out of the loop through analytics request. There is no need to rebuild this each time. In fact I may refactor this entire section in the future (once this all works)\n\tUpdated FunctionTest as some date based tests where using the STRING VAL_TYPE instead of DATE\n\n "
        },
        {
            "author": "Steven Bower",
            "id": "comment-13880444",
            "date": "2014-01-23T22:21:52+0000",
            "content": "The output above (ie the <null items in the response) I am quite certain is caused by the \"return null\" in the MinMaxStatsCollector. I have turned this into an IllegalArgException that should lead us to why this is happening.\n\nNote: I have not been able to actually repro this on my side (i thought I had but it was something else failing).. But I traced down when/how the nulls could propagate to the response .. hopefully this puts this issue to bed.. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13880570",
            "date": "2014-01-24T00:53:23+0000",
            "content": "OK, I'll run it through my local tests, then commit it if I don't see a test failure in a couple of runs with iters set. I wasn't able to get failures the other day but Jenkins seems to fail pretty regularly....\n\nMore later. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13881014",
            "date": "2014-01-24T14:50:10+0000",
            "content": "Got two failures on my Mac first time running. Relevant bits of the output below. Is this enough to go on? \n\nAnd they seem to be reproducible on my Mac at least with these commands!\nant test  -Dtestcase=FunctionTest -Dtests.seed=66075F976AAA8705 -Dtests.slow=true -Dtests.locale=sq -Dtests.timezone=US/Aleutian -Dtests.file.encoding=ISO-8859-1\nant test  -Dtestcase=FieldFacetTest -Dtests.seed=66075F976AAA8705 -Dtests.slow=true -Dtests.locale=es_PR -Dtests.timezone=Africa/Timbuktu -Dtests.file.encoding=ISO-8859-1\n\nIn fact, on my machine none of the sys vars are necessary (at least on one try), for FieldFacet test, which I can also get to fail in IntelliJ\nant test  -Dtestcase=FieldFacetTest\nfailed. Although\nant test  -Dtestcase=FuncitonTest\nsucceeded both independently and in IntelliJ.\n\n [junit4] Suite: org.apache.solr.analytics.util.valuesource.FunctionTest\n   [junit4]   2> 98963 T499 oas.SolrTestCaseJ4.initCore ####initCore\n   [junit4]   2> Creating dataDir: /Users/Erick/apache/trunk_5488/solr/build/solr-core/test/J1/./solrtest-FunctionTest-1390572998971\n   [junit4]   2> 98964 T499 oasc.SolrResourceLoader.<init> new SolrResourceLoader for directory: '/Users/Erick/apache/trunk_5488/solr/build/solr-core/test-files/solr/collection1/'\n   [junit4]   2> 98964 T499 oasc.SolrResourceLoader.replaceClassLoader Adding 'file:/Users/Erick/apache/trunk_5488/solr/build/solr-core/test-files/solr/collection1/lib/classes/' to classloader\n   [junit4]   2> 98965 T499 oasc.SolrResourceLoader.replaceClassLoader Adding 'file:/Users/Erick/apache/trunk_5488/solr/build/solr-core/test-files/solr/collection1/lib/README' to classloader\n   [junit4]   2> 99005 T499 oasc.SolrConfig.<init> Using Lucene MatchVersion: LUCENE_50\n   [junit4]   2> 99035 T499 oasc.SolrConfig.<init> Loaded SolrConfig: solrconfig-basic.xml\n   [junit4]   2> 99035 T499 oass.IndexSchema.readSchema Reading Solr Schema from schema-analytics.xml\n   [junit4]   2> 99043 T499 oass.IndexSchema.readSchema [null] Schema name=schema-docValues\n   [junit4]   2> 99060 T499 oass.IndexSchema.readSchema unique key field: id\n   [junit4]   2> 99061 T499 oasc.SolrResourceLoader.locateSolrHome JNDI not configured for solr (NoInitialContextEx)\n   [junit4]   2> 99061 T499 oasc.SolrResourceLoader.locateSolrHome using system property solr.solr.home: /Users/Erick/apache/trunk_5488/solr/build/solr-core/test-files/solr\n   [junit4]   2> 99061 T499 oasc.SolrResourceLoader.<init> new SolrResourceLoader for directory: '/Users/Erick/apache/trunk_5488/solr/build/solr-core/test-files/solr/'\n   [junit4]   2> 99071 T499 oasc.SolrResourceLoader.locateSolrHome JNDI not configured for solr (NoInitialContextEx)\n   [junit4]   2> 99071 T499 oasc.SolrResourceLoader.locateSolrHome using system property solr.solr.home: /Users/Erick/apache/trunk_5488/solr/build/solr-core/test-files/solr\n   [junit4]   2> 99072 T499 oasc.SolrResourceLoader.<init> new SolrResourceLoader for deduced Solr Home: '/Users/Erick/apache/trunk_5488/solr/build/solr-core/test-files/solr/'\n   [junit4]   2> 99103 T499 oasc.CoreContainer.<init> New CoreContainer 1741081513\n   [junit4]   2> 99103 T499 oasc.CoreContainer.load Loading cores into CoreContainer [instanceDir=/Users/Erick/apache/trunk_5488/solr/build/solr-core/test-files/solr/]\n   [junit4]   2> 99104 T499 oashc.HttpShardHandlerFactory.getParameter Setting socketTimeout to: 0\n   [junit4]   2> 99104 T499 oashc.HttpShardHandlerFactory.getParameter Setting urlScheme to: http://\n   [junit4]   2> 99104 T499 oashc.HttpShardHandlerFactory.getParameter Setting connTimeout to: 0\n   [junit4]   2> 99105 T499 oashc.HttpShardHandlerFactory.getParameter Setting maxConnectionsPerHost to: 20\n   [junit4]   2> 99105 T499 oashc.HttpShardHandlerFactory.getParameter Setting corePoolSize to: 0\n   [junit4]   2> 99105 T499 oashc.HttpShardHandlerFactory.getParameter Setting maximumPoolSize to: 2147483647\n   [junit4]   2> 99105 T499 oashc.HttpShardHandlerFactory.getParameter Setting maxThreadIdleTime to: 5\n   [junit4]   2> 99105 T499 oashc.HttpShardHandlerFactory.getParameter Setting sizeOfQueue to: -1\n   [junit4]   2> 99105 T499 oashc.HttpShardHandlerFactory.getParameter Setting fairnessPolicy to: false\n   [junit4]   2> 99108 T499 oasl.LogWatcher.createWatcher SLF4J impl is org.slf4j.impl.Log4jLoggerFactory\n   [junit4]   2> 99108 T499 oasl.LogWatcher.newRegisteredLogWatcher Registering Log Listener [Log4j (org.slf4j.impl.Log4jLoggerFactory)]\n   [junit4]   2> 99108 T499 oasc.CoreContainer.load Host Name: \n   [junit4]   2> 99111 T500 oasc.CoreContainer.create Creating SolrCore 'collection1' using instanceDir: /Users/Erick/apache/trunk_5488/solr/build/solr-core/test-files/solr/collection1\n   [junit4]   2> 99111 T500 oasc.SolrResourceLoader.<init> new SolrResourceLoader for directory: '/Users/Erick/apache/trunk_5488/solr/build/solr-core/test-files/solr/collection1/'\n   [junit4]   2> 99112 T500 oasc.SolrResourceLoader.replaceClassLoader Adding 'file:/Users/Erick/apache/trunk_5488/solr/build/solr-core/test-files/solr/collection1/lib/classes/' to classloader\n   [junit4]   2> 99112 T500 oasc.SolrResourceLoader.replaceClassLoader Adding 'file:/Users/Erick/apache/trunk_5488/solr/build/solr-core/test-files/solr/collection1/lib/README' to classloader\n   [junit4]   2> 99140 T500 oasc.SolrConfig.<init> Using Lucene MatchVersion: LUCENE_50\n   [junit4]   2> 99168 T500 oasc.SolrConfig.<init> Loaded SolrConfig: solrconfig-basic.xml\n   [junit4]   2> 99168 T500 oass.IndexSchema.readSchema Reading Solr Schema from schema-analytics.xml\n   [junit4]   2> 99175 T500 oass.IndexSchema.readSchema [collection1] Schema name=schema-docValues\n   [junit4]   2> 99214 T500 oass.IndexSchema.readSchema unique key field: id\n   [junit4]   2> 99215 T500 oasc.SolrCore.initDirectoryFactory org.apache.solr.core.MockDirectoryFactory\n   [junit4]   2> 99216 T500 oasc.SolrCore.<init> [collection1] Opening new SolrCore at /Users/Erick/apache/trunk_5488/solr/build/solr-core/test-files/solr/collection1/, dataDir=/Users/Erick/apache/trunk_5488/solr/build/solr-core/test/J1/./solrtest-FunctionTest-1390572998971/\n   [junit4]   2> 99216 T500 oasc.SolrCore.<init> JMX monitoring not detected for core: collection1\n   [junit4]   2> 99217 T500 oasc.CachingDirectoryFactory.get return new directory for /Users/Erick/apache/trunk_5488/solr/build/solr-core/test/J1/./solrtest-FunctionTest-1390572998971\n   [junit4]   2> 99217 T500 oasc.SolrCore.getNewIndexDir New index directory detected: old=null new=/Users/Erick/apache/trunk_5488/solr/build/solr-core/test/J1/./solrtest-FunctionTest-1390572998971/index/\n   [junit4]   2> 99217 T500 oasc.SolrCore.initIndex WARN [collection1] Solr index directory '/Users/Erick/apache/trunk_5488/solr/build/solr-core/test/J1/./solrtest-FunctionTest-1390572998971/index' doesn't exist. Creating new index...\n   [junit4]   2> 99217 T500 oasc.CachingDirectoryFactory.get return new directory for /Users/Erick/apache/trunk_5488/solr/build/solr-core/test/J1/./solrtest-FunctionTest-1390572998971/index\n   [junit4]   2> 99218 T500 oasu.RandomMergePolicy.<init> RandomMergePolicy wrapping class org.apache.lucene.index.TieredMergePolicy: [TieredMergePolicy: maxMergeAtOnce=30, maxMergeAtOnceExplicit=21, maxMergedSegmentMB=64.615234375, floorSegmentMB=0.7724609375, forceMergeDeletesPctAllowed=21.084994298715163, segmentsPerTier=35.0, maxCFSSegmentSizeMB=8.796093022207999E12, noCFSRatio=1.0\n   [junit4]   2> 99218 T500 oasc.SolrDeletionPolicy.onCommit SolrDeletionPolicy.onCommit: commits: num=1\n   [junit4]   2> \t\tcommit\n{dir=MockDirectoryWrapper(org.apache.lucene.store.RAMDirectory@7adaab5d lockFactory=org.apache.lucene.store.SingleInstanceLockFactory@4acd08e2),segFN=segments_1,generation=1}\n   [junit4]   2> 99219 T500 oasc.SolrDeletionPolicy.updateCommits newest commit generation = 1\n   [junit4]   2> 99220 T500 oasc.SolrCore.loadUpdateProcessorChains no updateRequestProcessorChain defined as default, creating implicit default\n   [junit4]   2> 99220 T500 oasc.RequestHandlers.initHandlersFromConfig created standard: solr.StandardRequestHandler\n   [junit4]   2> 99220 T500 oasc.RequestHandlers.initHandlersFromConfig created /update: solr.UpdateRequestHandler\n   [junit4]   2> 99225 T500 oashl.XMLLoader.init xsltCacheLifetimeSeconds=60\n   [junit4]   2> 99227 T500 oasu.CommitTracker.<init> Hard AutoCommit: disabled\n   [junit4]   2> 99227 T500 oasu.CommitTracker.<init> Soft AutoCommit: disabled\n   [junit4]   2> 99227 T500 oasu.RandomMergePolicy.<init> RandomMergePolicy wrapping class org.apache.lucene.index.AlcoholicMergePolicy: [AlcoholicMergePolicy: minMergeSize=0, mergeFactor=10, maxMergeSize=853865222, maxMergeSizeForForcedMerge=9223372036854775807, calibrateSizeByDeletes=true, maxMergeDocs=2147483647, maxCFSSegmentSizeMB=8.796093022207999E12, noCFSRatio=0.1]\n   [junit4]   2> 99228 T500 oasc.SolrDeletionPolicy.onInit SolrDeletionPolicy.onInit: commits: num=1\n   [junit4]   2> \t\tcommit{dir=MockDirectoryWrapper(org.apache.lucene.store.RAMDirectory@7adaab5d lockFactory=org.apache.lucene.store.SingleInstanceLockFactory@4acd08e2),segFN=segments_1,generation=1}\n   [junit4]   2> 99228 T500 oasc.SolrDeletionPolicy.updateCommits newest commit generation = 1\n   [junit4]   2> 99228 T500 oass.SolrIndexSearcher.<init> Opening Searcher@5e861b21 main\n   [junit4]   2> 99228 T501 oasc.SolrCore.registerSearcher [collection1] Registered new searcher Searcher@5e861b21 main\n{StandardDirectoryReader(segments_1:1:nrt)}\n   [junit4]   2> 99228 T500 oasc.CoreContainer.registerCore registering core: collection1\n   [junit4]   2> 99230 T499 oas.SolrTestCaseJ4.initCore ####initCore end\n   [junit4]   2> ASYNC  NEW_CORE C313 name=collection1 org.apache.solr.core.SolrCore@1ab35146\n   [junit4]   2> 99231 T499 C313 oasu.DirectUpdateHandler2.deleteAll [collection1] REMOVING ALL DOCUMENTS FROM INDEX\n   [junit4]   2> 99231 T499 C313 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{deleteByQuery=*:*}\n 0 1\n   [junit4]   2> 99245 T499 C313 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[10000]} 0 11\n   [junit4]   2> 99249 T499 C313 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[10001]} 0 1\n   [junit4]   2> 99252 T499 C313 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[10002]} 0 2\n   [junit4]   2> 99254 T499 C313 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[10003]} 0 1\n   [junit4]   2> 99257 T499 C313 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[10004]} 0 1\n   [junit4]   2> 99260 T499 C313 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[10005]} 0 2\n   [junit4]   2> 99262 T499 C313 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[10006]} 0 1\n   [junit4]   2> ASYNC  NEW_CORE C314 name=collection1 org.apache.solr.core.SolrCore@1ab35146\n   [junit4]   2> 99271 T499 C314 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[10007]} 0 1\n   [junit4]   2> 99274 T499 C314 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[10008]} 0 1\n   [junit4]   2> 99277 T499 C314 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[10009]} 0 2\n   [junit4]   2> 99279 T499 C314 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100010]} 0 1\n   [junit4]   2> 99282 T499 C314 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100011]} 0 1\n   [junit4]   2> 99285 T499 C314 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100012]} 0 2\n   [junit4]   2> 99287 T499 C314 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100013]} 0 1\n   [junit4]   2> 99290 T499 C314 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100014]} 0 1\n   [junit4]   2> 99293 T499 C314 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100015]} 0 2\n   [junit4]   2> 99296 T499 C314 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100016]} 0 2\n   [junit4]   2> 99300 T499 C314 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100017]} 0 2\n   [junit4]   2> 99304 T499 C314 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100018]} 0 2\n   [junit4]   2> 99308 T499 C314 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100019]} 0 2\n   [junit4]   2> 99311 T499 C314 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100020]} 0 2\n   [junit4]   2> 99315 T499 C314 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100021]} 0 2\n   [junit4]   2> 99318 T499 C314 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100022]} 0 2\n   [junit4]   2> 99322 T499 C314 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100023]} 0 2\n   [junit4]   2> 99327 T499 C314 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100024]} 0 3\n   [junit4]   2> 99330 T499 C314 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100025]} 0 1\n   [junit4]   2> 99335 T499 C314 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100026]} 0 2\n   [junit4]   2> 99339 T499 C314 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100027]} 0 2\n   [junit4]   2> 99343 T499 C314 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100028]} 0 2\n   [junit4]   2> 99346 T499 C314 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100029]} 0 1\n   [junit4]   2> 99349 T499 C314 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100030]} 0 1\n   [junit4]   2> 99352 T499 C314 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100031]} 0 1\n   [junit4]   2> 99355 T499 C314 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100032]} 0 1\n   [junit4]   2> 99358 T499 C314 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100033]} 0 1\n   [junit4]   2> 99361 T499 C314 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100034]} 0 1\n   [junit4]   2> 99365 T499 C314 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100035]} 0 2\n   [junit4]   2> 99368 T499 C314 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100036]} 0 2\n   [junit4]   2> 99372 T499 C314 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100037]} 0 2\n   [junit4]   2> ASYNC  NEW_CORE C315 name=collection1 org.apache.solr.core.SolrCore@1ab35146\n   [junit4]   2> 99381 T499 C315 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100038]} 0 2\n   [junit4]   2> 99385 T499 C315 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100039]} 0 2\n   [junit4]   2> 99389 T499 C315 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100040]} 0 2\n   [junit4]   2> 99394 T499 C315 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100041]} 0 2\n   [junit4]   2> 99398 T499 C315 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100042]} 0 2\n   [junit4]   2> 99403 T499 C315 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100043]} 0 3\n   [junit4]   2> 99407 T499 C315 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100044]} 0 2\n   [junit4]   2> 99411 T499 C315 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100045]} 0 2\n   [junit4]   2> 99415 T499 C315 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100046]} 0 2\n   [junit4]   2> 99419 T499 C315 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100047]} 0 2\n   [junit4]   2> 99423 T499 C315 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100048]} 0 2\n   [junit4]   2> 99427 T499 C315 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100049]} 0 2\n   [junit4]   2> 99431 T499 C315 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100050]} 0 2\n   [junit4]   2> 99436 T499 C315 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100051]} 0 2\n   [junit4]   2> 99439 T499 C315 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100052]} 0 2\n   [junit4]   2> 99444 T499 C315 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100053]} 0 3\n   [junit4]   2> 99448 T499 C315 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100054]} 0 2\n   [junit4]   2> 99451 T499 C315 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100055]} 0 2\n   [junit4]   2> 99455 T499 C315 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100056]} 0 2\n   [junit4]   2> 99459 T499 C315 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100057]} 0 2\n   [junit4]   2> 99462 T499 C315 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100058]} 0 2\n   [junit4]   2> 99466 T499 C315 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100059]} 0 2\n   [junit4]   2> 99470 T499 C315 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100060]} 0 2\n   [junit4]   2> 99475 T499 C315 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100061]} 0 3\n   [junit4]   2> 99479 T499 C315 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100062]} 0 2\n   [junit4]   2> 99483 T499 C315 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100063]} 0 3\n   [junit4]   2> 99487 T499 C315 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100064]} 0 2\n   [junit4]   2> 99491 T499 C315 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100065]} 0 2\n   [junit4]   2> 99495 T499 C315 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100066]} 0 2\n   [junit4]   2> 99499 T499 C315 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100067]} 0 2\n   [junit4]   2> ASYNC  NEW_CORE C316 name=collection1 org.apache.solr.core.SolrCore@1ab35146\n   [junit4]   2> 99508 T499 C316 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100068]} 0 2\n   [junit4]   2> 99512 T499 C316 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100069]} 0 2\n   [junit4]   2> 99516 T499 C316 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100070]} 0 2\n   [junit4]   2> 99519 T499 C316 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100071]} 0 1\n   [junit4]   2> 99523 T499 C316 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100072]} 0 2\n   [junit4]   2> 99527 T499 C316 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100073]} 0 2\n   [junit4]   2> 99531 T499 C316 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100074]} 0 3\n   [junit4]   2> 99535 T499 C316 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100075]} 0 2\n   [junit4]   2> 99539 T499 C316 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100076]} 0 2\n   [junit4]   2> 99543 T499 C316 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100077]} 0 2\n   [junit4]   2> 99547 T499 C316 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100078]} 0 2\n   [junit4]   2> 99551 T499 C316 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100079]} 0 2\n   [junit4]   2> 99555 T499 C316 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100080]} 0 2\n   [junit4]   2> 99559 T499 C316 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100081]} 0 2\n   [junit4]   2> 99563 T499 C316 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100082]} 0 2\n   [junit4]   2> 99567 T499 C316 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100083]} 0 2\n   [junit4]   2> 99571 T499 C316 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100084]} 0 2\n   [junit4]   2> 99575 T499 C316 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100085]} 0 2\n   [junit4]   2> 99579 T499 C316 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100086]} 0 2\n   [junit4]   2> 99583 T499 C316 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100087]} 0 2\n   [junit4]   2> 99585 T499 C316 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100088]} 0 1\n   [junit4]   2> 99589 T499 C316 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100089]} 0 2\n   [junit4]   2> 99593 T499 C316 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100090]} 0 2\n   [junit4]   2> 99596 T499 C316 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100091]} 0 2\n   [junit4]   2> 99599 T499 C316 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100092]} 0 2\n   [junit4]   2> 99602 T499 C316 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100093]} 0 2\n   [junit4]   2> 99604 T499 C316 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100094]} 0 1\n   [junit4]   2> 99607 T499 C316 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100095]} 0 1\n   [junit4]   2> 99609 T499 C316 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100096]} 0 1\n   [junit4]   2> 99611 T499 C316 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100097]} 0 1\n   [junit4]   2> ASYNC  NEW_CORE C317 name=collection1 org.apache.solr.core.SolrCore@1ab35146\n   [junit4]   2> 99617 T499 C317 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100098]} 0 1\n   [junit4]   2> 99619 T499 C317 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[100099]} 0 1\n   [junit4]   2> 99621 T499 C317 oasu.DirectUpdateHandler2.commit start commit{,optimize=false,openSearcher=true,waitSearcher=true,expungeDeletes=false,softCommit=false,prepareCommit=false}\n   [junit4]   2> 99709 T499 C317 oasc.SolrDeletionPolicy.onCommit SolrDeletionPolicy.onCommit: commits: num=2\n   [junit4]   2> \t\tcommit{dir=MockDirectoryWrapper(org.apache.lucene.store.RAMDirectory@7adaab5d lockFactory=org.apache.lucene.store.SingleInstanceLockFactory@4acd08e2),segFN=segments_1,generation=1}\n   [junit4]   2> \t\tcommit{dir=MockDirectoryWrapper(org.apache.lucene.store.RAMDirectory@7adaab5d lockFactory=org.apache.lucene.store.SingleInstanceLockFactory@4acd08e2),segFN=segments_2,generation=2}\n   [junit4]   2> 99710 T499 C317 oasc.SolrDeletionPolicy.updateCommits newest commit generation = 2\n   [junit4]   2> 99732 T499 C317 oass.SolrIndexSearcher.<init> Opening Searcher@7aa06858 main\n   [junit4]   2> 99733 T499 C317 oasu.DirectUpdateHandler2.commit end_commit_flush\n   [junit4]   2> 99733 T501 oasc.SolrCore.registerSearcher [collection1] Registered new searcher Searcher@7aa06858 main{StandardDirectoryReader(segments_2:4:nrt _0(5.0):c100)}\n   [junit4]   2> 99733 T499 C317 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {commit=} 0 113\n   [junit4]   2> ASYNC  NEW_CORE C318 name=collection1 org.apache.solr.core.SolrCore@1ab35146\n   [junit4]   2> 100007 T499 C318 oasc.SolrException.log ERROR java.lang.IllegalArgumentException: No stat named 'median' in this collector\n   [junit4]   2> \t\tat org.apache.solr.analytics.statistics.MinMaxStatsCollector.getStat(MinMaxStatsCollector.java:86)\n   [junit4]   2> \t\tat org.apache.solr.analytics.expression.BaseExpression.getValue(BaseExpression.java:38)\n   [junit4]   2> \t\tat org.apache.solr.analytics.accumulator.BasicAccumulator.export(BasicAccumulator.java:109)\n   [junit4]   2> \t\tat org.apache.solr.analytics.request.AnalyticsStats.execute(AnalyticsStats.java:132)\n   [junit4]   2> \t\tat org.apache.solr.handler.component.AnalyticsComponent.process(AnalyticsComponent.java:44)\n   [junit4]   2> \t\tat org.apache.solr.handler.component.SearchHandler.handleRequestBody(SearchHandler.java:215)\n   [junit4]   2> \t\tat org.apache.solr.handler.RequestHandlerBase.handleRequest(RequestHandlerBase.java:135)\n   [junit4]   2> \t\tat org.apache.solr.core.SolrCore.execute(SolrCore.java:1915)\n   [junit4]   2> \t\tat org.apache.solr.util.TestHarness.query(TestHarness.java:291)\n   [junit4]   2> \t\tat org.apache.solr.util.TestHarness.query(TestHarness.java:273)\n   [junit4]   2> \t\tat org.apache.solr.analytics.util.valuesource.FunctionTest.beforeClass(FunctionTest.java:85)\n   [junit4]   2> \t\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n   [junit4]   2> \t\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n   [junit4]   2> \t\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n   [junit4]   2> \t\tat java.lang.reflect.Method.invoke(Method.java:601)\n   [junit4]   2> \t\tat com.carrotsearch.randomizedtesting.RandomizedRunner.invoke(RandomizedRunner.java:1559)\n   [junit4]   2> \t\tat com.carrotsearch.randomizedtesting.RandomizedRunner.access$600(RandomizedRunner.java:79)\n   [junit4]   2> \t\tat com.carrotsearch.randomizedtesting.RandomizedRunner$4.evaluate(RandomizedRunner.java:677)\n   [junit4]   2> \t\tat com.carrotsearch.randomizedtesting.RandomizedRunner$5.evaluate(RandomizedRunner.java:693)\n   [junit4]   2> \t\tat com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)\n   [junit4]   2> \t\tat com.carrotsearch.randomizedtesting.rules.SystemPropertiesRestoreRule$1.evaluate(SystemPropertiesRestoreRule.java:53)\n   [junit4]   2> \t\tat org.apache.lucene.util.AbstractBeforeAfterRule$1.evaluate(AbstractBeforeAfterRule.java:46)\n   [junit4]   2> \t\tat org.apache.lucene.util.TestRuleStoreClassName$1.evaluate(TestRuleStoreClassName.java:42)\n   [junit4]   2> \t\tat com.carrotsearch.randomizedtesting.rules.SystemPropertiesInvariantRule$1.evaluate(SystemPropertiesInvariantRule.java:55)\n   [junit4]   2> \t\tat com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:39)\n   [junit4]   2> \t\tat com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:39)\n   [junit4]   2> \t\tat com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)\n   [junit4]   2> \t\tat org.apache.lucene.util.TestRuleAssertionsRequired$1.evaluate(TestRuleAssertionsRequired.java:43)\n   [junit4]   2> \t\tat org.apache.lucene.util.TestRuleMarkFailure$1.evaluate(TestRuleMarkFailure.java:48)\n   [junit4]   2> \t\tat org.apache.lucene.util.TestRuleIgnoreAfterMaxFailures$1.evaluate(TestRuleIgnoreAfterMaxFailures.java:70)\n   [junit4]   2> \t\tat org.apache.lucene.util.TestRuleIgnoreTestSuites$1.evaluate(TestRuleIgnoreTestSuites.java:55)\n   [junit4]   2> \t\tat com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)\n   [junit4]   2> \t\tat com.carrotsearch.randomizedtesting.ThreadLeakControl$StatementRunner.run(ThreadLeakControl.java:358)\n   [junit4]   2> \t\tat java.lang.Thread.run(Thread.java:722)\n   [junit4]   2> \t\n   [junit4]   2> 100007 T499 C318 oasc.SolrCore.execute [collection1] webapp=null path=null params={o.rr.s.min=min(rev(string_sd))&o.cr.s.minc=min(concat_first_sd)&o.cr.s.max=max(concat(const_str(this+is+the+second),string_sd))&rows=0&o.ar.s.meanc=mean(add_ldf_dd)&o.cr.s.maxc=max(concat_second_sd)&o.cdr.s.median=median(const_date(1800-06-30T23:59:59Z))&o.dmr.s.median=median(date_math(date_dtd,const_str(%2B2YEARS)))&o.rr.s.minc=min(rev_sd)&o.cdr.s.medianc=median(const_00_dtd)&o.avr.s.sum=sum(abs(neg(int_id)))&o.avr.s.sumc=sum(int_id)&o.ms.s.max=max(miss_dd)&o.pr.s.mean=mean(pow(long_ld,double_dd))&o.mr.s.meanc=mean(mult_ldf_dd)&o.pr.s.meanc=mean(pow_ld_dd)&o.rr.s.maxc=max(rev_sd)&o.nr.s.sum=sum(neg(int_id))&o.cnr.s.mean=mean(const_num(10))&o.dmr.s.max=max(date_math(date_dtd,const_str(%2B2MONTHS)))&o.cnr.s.sumc=sum(const_8_dd)&o.nr.s.mean=mean(neg(long_ld))&o.dr.s.sum=sum(div(int_id,float_fd))&o.nr.s.sumc=sum(neg_i_dd)&o.csr.s.min=min(const_str(this+is+the+first))&o.ar.s.sum=sum(add(int_id,float_fd))&o.csr.s.minc=min(const_first_sd)&o.pr.s.sum=sum(pow(int_id,float_fd))&o.cdr.s.max=max(const_date(1804-06-30T23:59:59Z))&o.ar.s.sumc=sum(add_if_dd)&o.dr.s.mean=mean(div(long_ld,double_dd))&o.ar.s.mean=mean(add(long_ld,double_dd,float_fd))&o.dr.s.meanc=mean(div_ld_dd)&o.avr.s.mean=mean(abs(neg(int_id)))&o.cdr.s.maxc=max(const_04_dtd)&o.dr.s.sumc=sum(div_if_dd)&o.mr.s.sum=sum(mult(int_id,float_fd))&o.avr.s.meanc=mean(int_id)&o.pr.s.sumc=sum(pow_if_dd)&o.csr.s.maxc=max(const_second_sd)&olap=true&o.cnr.s.meanc=mean(const_10_dd)&o.cr.s.min=min(concat(const_str(this+is+the+first),string_sd))&o.mr.s.mean=mean(mult(long_ld,double_dd,float_fd))&o.ms.s.min=min(miss_dd)&o.rr.s.max=max(rev(string_sd))&o.nr.s.meanc=mean(neg_l_dd)&indent=true&o.dmr.s.maxc=max(dm_2m_dtd)&o.cnr.s.sum=sum(const_num(8))&o.csr.s.max=max(const_str(this+is+the+second))&o.mr.s.sumc=sum(mult_if_dd)&o.dmr.s.medianc=median(dm_2y_dtd)&q=*:*} hits=100 status=500 QTime=267 \n   [junit4]   2> 100008 T499 oas.SolrTestCaseJ4.deleteCore ###deleteCore\n   [junit4]   2> 100008 T499 oasc.CoreContainer.shutdown Shutting down CoreContainer instance=1741081513\n   [junit4]   2> 100009 T499 oasc.SolrCore.close [collection1]  CLOSING SolrCore org.apache.solr.core.SolrCore@1ab35146\n   [junit4]   2> 100009 T499 oasu.DirectUpdateHandler2.close closing DirectUpdateHandler2{commits=1,autocommits=0,soft autocommits=0,optimizes=0,rollbacks=0,expungeDeletes=0,docsPending=0,adds=0,deletesById=0,deletesByQuery=0,errors=0,cumulative_adds=100,cumulative_deletesById=0,cumulative_deletesByQuery=1,cumulative_errors=0}\n   [junit4]   2> 100009 T499 oasu.SolrCoreState.decrefSolrCoreState Closing SolrCoreState\n   [junit4]   2> 100009 T499 oasu.DefaultSolrCoreState.closeIndexWriter SolrCoreState ref count has reached 0 - closing IndexWriter\n   [junit4]   2> 100009 T499 oasu.DefaultSolrCoreState.closeIndexWriter closing IndexWriter with IndexWriterCloser\n   [junit4]   2> 100010 T499 oasc.SolrCore.closeSearcher [collection1] Closing main searcher on request.\n   [junit4]   2> 100010 T499 oasc.CachingDirectoryFactory.close Closing MockDirectoryFactory - 2 directories currently being tracked\n   [junit4]   2> 100010 T499 oasc.CachingDirectoryFactory.closeCacheValue looking to close /Users/Erick/apache/trunk_5488/solr/build/solr-core/test/J1/./solrtest-FunctionTest-1390572998971/index [CachedDir<<refCount=0;path=/Users/Erick/apache/trunk_5488/solr/build/solr-core/test/J1/./solrtest-FunctionTest-1390572998971/index;done=false>>]\n   [junit4]   2> 100011 T499 oasc.CachingDirectoryFactory.close Closing directory: /Users/Erick/apache/trunk_5488/solr/build/solr-core/test/J1/./solrtest-FunctionTest-1390572998971/index\n   [junit4]   2> 100011 T499 oasc.CachingDirectoryFactory.closeCacheValue looking to close /Users/Erick/apache/trunk_5488/solr/build/solr-core/test/J1/./solrtest-FunctionTest-1390572998971 [CachedDir<<refCount=0;path=/Users/Erick/apache/trunk_5488/solr/build/solr-core/test/J1/./solrtest-FunctionTest-1390572998971;done=false>>]\n   [junit4]   2> 100011 T499 oasc.CachingDirectoryFactory.close Closing directory: /Users/Erick/apache/trunk_5488/solr/build/solr-core/test/J1/./solrtest-FunctionTest-1390572998971\n   [junit4]   2> NOTE: test params are: codec=Lucene46: {date_dtd=PostingsFormat(name=NestedPulsing), const_04_dtd=FST41, const_00_dtd=FST41, concat_second_sd=FST41, pow_ld_dd=Pulsing41(freqCutoff=9 minBlockSize=77 maxBlockSize=235), dm_2m_dtd=PostingsFormat(name=MockSep), long_ld=PostingsFormat(name=NestedPulsing), neg_l_dd=PostingsFormat(name=MockSep), div_if_dd=PostingsFormat(name=MockSep), div_ld_dd=FST41, const_first_sd=PostingsFormat(name=MockSep), const_second_sd=PostingsFormat(name=MockSep), mult_ldf_dd=Pulsing41(freqCutoff=9 minBlockSize=77 maxBlockSize=235), add_ldf_dd=PostingsFormat(name=NestedPulsing), const_10_dd=Pulsing41(freqCutoff=9 minBlockSize=77 maxBlockSize=235), add_if_dd=Pulsing41(freqCutoff=9 minBlockSize=77 maxBlockSize=235), id=PostingsFormat(name=NestedPulsing), miss_dd=PostingsFormat(name=NestedPulsing), float_fd=FST41, string_sd=PostingsFormat(name=NestedPulsing), dm_2y_dtd=PostingsFormat(name=MockSep), concat_first_sd=PostingsFormat(name=NestedPulsing), mult_if_dd=PostingsFormat(name=NestedPulsing), neg_i_dd=FST41, rev_sd=FST41, pow_if_dd=PostingsFormat(name=NestedPulsing), const_8_dd=PostingsFormat(name=NestedPulsing), double_dd=Pulsing41(freqCutoff=9 minBlockSize=77 maxBlockSize=235), int_id=PostingsFormat(name=NestedPulsing)}, docValues:{date_dtd=DocValuesFormat(name=SimpleText), const_04_dtd=DocValuesFormat(name=Disk), floatdv=DocValuesFormat(name=Memory), const_00_dtd=DocValuesFormat(name=Disk), concat_second_sd=DocValuesFormat(name=Disk), pow_ld_dd=DocValuesFormat(name=Memory), dm_2m_dtd=DocValuesFormat(name=Lucene45), longdv=DocValuesFormat(name=Memory), long_ld=DocValuesFormat(name=SimpleText), neg_l_dd=DocValuesFormat(name=Lucene45), div_if_dd=DocValuesFormat(name=Lucene45), div_ld_dd=DocValuesFormat(name=Disk), datedv=DocValuesFormat(name=Lucene45), const_first_sd=DocValuesFormat(name=Lucene45), intdv=DocValuesFormat(name=Disk), mult_ldf_dd=DocValuesFormat(name=Memory), const_second_sd=DocValuesFormat(name=Lucene45), add_ldf_dd=DocValuesFormat(name=SimpleText), const_10_dd=DocValuesFormat(name=Memory), add_if_dd=DocValuesFormat(name=Memory), miss_dd=DocValuesFormat(name=SimpleText), stringdvm=DocValuesFormat(name=Memory), float_fd=DocValuesFormat(name=Disk), string_sd=DocValuesFormat(name=SimpleText), dm_2y_dtd=DocValuesFormat(name=Lucene45), concat_first_sd=DocValuesFormat(name=SimpleText), mult_if_dd=DocValuesFormat(name=SimpleText), doubledv=DocValuesFormat(name=SimpleText), neg_i_dd=DocValuesFormat(name=Disk), rev_sd=DocValuesFormat(name=Disk), const_8_dd=DocValuesFormat(name=SimpleText), pow_if_dd=DocValuesFormat(name=SimpleText), double_dd=DocValuesFormat(name=Memory), stringdv=DocValuesFormat(name=SimpleText), int_id=DocValuesFormat(name=SimpleText)}, sim=RandomSimilarityProvider(queryNorm=false,coord=yes): {}, locale=sq, timezone=US/Aleutian\n   [junit4]   2> NOTE: Mac OS X 10.9.1 x86_64/Oracle Corporation 1.7.0_13 (64-bit)/cpus=8,threads=1,free=26361960,total=71200768\n   [junit4]   2> NOTE: All tests run in this JVM: [SolrIndexConfigTest, FullSolrCloudDistribCmdsTest, ConvertedLegacyTest, NoCacheHeaderTest, BadIndexSchemaTest, ZkNodePropsTest, TestFieldTypeCollectionResource, SimpleFacetsTest, UniqFieldsUpdateProcessorFactoryTest, TestCollationField, TestComponentsName, TermsComponentTest, TestDistribDocBasedVersion, LukeRequestHandlerTest, TestMultiCoreConfBootstrap, RequiredFieldsTest, TestStressUserVersions, TestPerFieldSimilarity, PrimitiveFieldTypeTest, TestZkChroot, TestSuggestSpellingConverter, FunctionTest]\n   [junit4]   2> NOTE: reproduce with: ant test  -Dtestcase=FunctionTest -Dtests.seed=66075F976AAA8705 -Dtests.slow=true -Dtests.locale=sq -Dtests.timezone=US/Aleutian -Dtests.file.encoding=ISO-8859-1\n   [junit4] ERROR   0.00s J1 | FunctionTest (suite) <<<\n   [junit4]    > Throwable #1: java.lang.IllegalArgumentException: No stat named 'median' in this collector\n   [junit4]    > \tat __randomizedtesting.SeedInfo.seed([66075F976AAA8705]:0)\n   [junit4]    > \tat org.apache.solr.analytics.statistics.MinMaxStatsCollector.getStat(MinMaxStatsCollector.java:86)\n   [junit4]    > \tat org.apache.solr.analytics.expression.BaseExpression.getValue(BaseExpression.java:38)\n   [junit4]    > \tat org.apache.solr.analytics.accumulator.BasicAccumulator.export(BasicAccumulator.java:109)\n   [junit4]    > \tat org.apache.solr.analytics.request.AnalyticsStats.execute(AnalyticsStats.java:132)\n   [junit4]    > \tat org.apache.solr.handler.component.AnalyticsComponent.process(AnalyticsComponent.java:44)\n   [junit4]    > \tat org.apache.solr.handler.component.SearchHandler.handleRequestBody(SearchHandler.java:215)\n   [junit4]    > \tat org.apache.solr.handler.RequestHandlerBase.handleRequest(RequestHandlerBase.java:135)\n   [junit4]    > \tat org.apache.solr.core.SolrCore.execute(SolrCore.java:1915)\n   [junit4]    > \tat org.apache.solr.util.TestHarness.query(TestHarness.java:291)\n   [junit4]    > \tat org.apache.solr.util.TestHarness.query(TestHarness.java:273)\n   [junit4]    > \tat org.apache.solr.analytics.util.valuesource.FunctionTest.beforeClass(FunctionTest.java:85)\n   [junit4]    > \tat java.lang.Thread.run(Thread.java:722)\n   [junit4] Completed on J1 in 1.11s, 0 tests, 1 error <<< FAILURES!\n   [junit4] \n  \n\n*************************\n\n   [junit4] \n   [junit4] Suite: org.apache.solr.analytics.facet.FieldFacetTest\n   [junit4]   2> 486315 T2792 oas.SolrTestCaseJ4.initCore ####initCore\n   [junit4]   2> Creating dataDir: /Users/Erick/apache/trunk_5488/solr/build/solr-core/test/J0/./solrtest-FieldFacetTest-1390573386248\n   [junit4]   2> 486316 T2792 oasc.SolrResourceLoader.<init> new SolrResourceLoader for directory: '/Users/Erick/apache/trunk_5488/solr/build/solr-core/test-files/solr/collection1/'\n   [junit4]   2> 486316 T2792 oasc.SolrResourceLoader.replaceClassLoader Adding 'file:/Users/Erick/apache/trunk_5488/solr/build/solr-core/test-files/solr/collection1/lib/classes/' to classloader\n   [junit4]   2> 486316 T2792 oasc.SolrResourceLoader.replaceClassLoader Adding 'file:/Users/Erick/apache/trunk_5488/solr/build/solr-core/test-files/solr/collection1/lib/README' to classloader\n   [junit4]   2> 486354 T2792 oasc.SolrConfig.<init> Using Lucene MatchVersion: LUCENE_50\n   [junit4]   2> 486378 T2792 oasc.SolrConfig.<init> Loaded SolrConfig: solrconfig-basic.xml\n   [junit4]   2> 486378 T2792 oass.IndexSchema.readSchema Reading Solr Schema from schema-analytics.xml\n   [junit4]   2> 486381 T2792 oass.IndexSchema.readSchema [null] Schema name=schema-docValues\n   [junit4]   2> 486398 T2792 oass.IndexSchema.readSchema unique key field: id\n   [junit4]   2> 486399 T2792 oasc.SolrResourceLoader.locateSolrHome JNDI not configured for solr (NoInitialContextEx)\n   [junit4]   2> 486399 T2792 oasc.SolrResourceLoader.locateSolrHome using system property solr.solr.home: /Users/Erick/apache/trunk_5488/solr/build/solr-core/test-files/solr\n   [junit4]   2> 486400 T2792 oasc.SolrResourceLoader.<init> new SolrResourceLoader for directory: '/Users/Erick/apache/trunk_5488/solr/build/solr-core/test-files/solr/'\n   [junit4]   2> 486406 T2792 oasc.SolrResourceLoader.locateSolrHome JNDI not configured for solr (NoInitialContextEx)\n   [junit4]   2> 486407 T2792 oasc.SolrResourceLoader.locateSolrHome using system property solr.solr.home: /Users/Erick/apache/trunk_5488/solr/build/solr-core/test-files/solr\n   [junit4]   2> 486407 T2792 oasc.SolrResourceLoader.<init> new SolrResourceLoader for deduced Solr Home: '/Users/Erick/apache/trunk_5488/solr/build/solr-core/test-files/solr/'\n   [junit4]   2> 486443 T2792 oasc.CoreContainer.<init> New CoreContainer 31339713\n   [junit4]   2> 486443 T2792 oasc.CoreContainer.load Loading cores into CoreContainer [instanceDir=/Users/Erick/apache/trunk_5488/solr/build/solr-core/test-files/solr/]\n   [junit4]   2> 486444 T2792 oashc.HttpShardHandlerFactory.getParameter Setting socketTimeout to: 0\n   [junit4]   2> 486444 T2792 oashc.HttpShardHandlerFactory.getParameter Setting urlScheme to: http://\n   [junit4]   2> 486444 T2792 oashc.HttpShardHandlerFactory.getParameter Setting connTimeout to: 0\n   [junit4]   2> 486444 T2792 oashc.HttpShardHandlerFactory.getParameter Setting maxConnectionsPerHost to: 20\n   [junit4]   2> 486444 T2792 oashc.HttpShardHandlerFactory.getParameter Setting corePoolSize to: 0\n   [junit4]   2> 486444 T2792 oashc.HttpShardHandlerFactory.getParameter Setting maximumPoolSize to: 2147483647\n   [junit4]   2> 486445 T2792 oashc.HttpShardHandlerFactory.getParameter Setting maxThreadIdleTime to: 5\n   [junit4]   2> 486445 T2792 oashc.HttpShardHandlerFactory.getParameter Setting sizeOfQueue to: -1\n   [junit4]   2> 486445 T2792 oashc.HttpShardHandlerFactory.getParameter Setting fairnessPolicy to: false\n   [junit4]   2> 486447 T2792 oasl.LogWatcher.createWatcher SLF4J impl is org.slf4j.impl.Log4jLoggerFactory\n   [junit4]   2> 486447 T2792 oasl.LogWatcher.newRegisteredLogWatcher Registering Log Listener [Log4j (org.slf4j.impl.Log4jLoggerFactory)]\n   [junit4]   2> 486448 T2792 oasc.CoreContainer.load Host Name: \n   [junit4]   2> 486450 T2793 oasc.CoreContainer.create Creating SolrCore 'collection1' using instanceDir: /Users/Erick/apache/trunk_5488/solr/build/solr-core/test-files/solr/collection1\n   [junit4]   2> 486450 T2793 oasc.SolrResourceLoader.<init> new SolrResourceLoader for directory: '/Users/Erick/apache/trunk_5488/solr/build/solr-core/test-files/solr/collection1/'\n   [junit4]   2> 486451 T2793 oasc.SolrResourceLoader.replaceClassLoader Adding 'file:/Users/Erick/apache/trunk_5488/solr/build/solr-core/test-files/solr/collection1/lib/classes/' to classloader\n   [junit4]   2> 486451 T2793 oasc.SolrResourceLoader.replaceClassLoader Adding 'file:/Users/Erick/apache/trunk_5488/solr/build/solr-core/test-files/solr/collection1/lib/README' to classloader\n   [junit4]   2> 486471 T2793 oasc.SolrConfig.<init> Using Lucene MatchVersion: LUCENE_50\n   [junit4]   2> 486499 T2793 oasc.SolrConfig.<init> Loaded SolrConfig: solrconfig-basic.xml\n   [junit4]   2> 486499 T2793 oass.IndexSchema.readSchema Reading Solr Schema from schema-analytics.xml\n   [junit4]   2> 486502 T2793 oass.IndexSchema.readSchema [collection1] Schema name=schema-docValues\n   [junit4]   2> 486522 T2793 oass.IndexSchema.readSchema unique key field: id\n   [junit4]   2> 486523 T2793 oasc.SolrCore.initDirectoryFactory org.apache.solr.core.MockDirectoryFactory\n   [junit4]   2> 486524 T2793 oasc.SolrCore.<init> [collection1] Opening new SolrCore at /Users/Erick/apache/trunk_5488/solr/build/solr-core/test-files/solr/collection1/, dataDir=/Users/Erick/apache/trunk_5488/solr/build/solr-core/test/J0/./solrtest-FieldFacetTest-1390573386248/\n   [junit4]   2> 486524 T2793 oasc.SolrCore.<init> JMX monitoring not detected for core: collection1\n   [junit4]   2> 486524 T2793 oasc.CachingDirectoryFactory.get return new directory for /Users/Erick/apache/trunk_5488/solr/build/solr-core/test/J0/./solrtest-FieldFacetTest-1390573386248\n   [junit4]   2> 486524 T2793 oasc.SolrCore.getNewIndexDir New index directory detected: old=null new=/Users/Erick/apache/trunk_5488/solr/build/solr-core/test/J0/./solrtest-FieldFacetTest-1390573386248/index/\n   [junit4]   2> 486524 T2793 oasc.SolrCore.initIndex WARN [collection1] Solr index directory '/Users/Erick/apache/trunk_5488/solr/build/solr-core/test/J0/./solrtest-FieldFacetTest-1390573386248/index' doesn't exist. Creating new index...\n   [junit4]   2> 486525 T2793 oasc.CachingDirectoryFactory.get return new directory for /Users/Erick/apache/trunk_5488/solr/build/solr-core/test/J0/./solrtest-FieldFacetTest-1390573386248/index\n   [junit4]   2> 486525 T2793 oasu.RandomMergePolicy.<init> RandomMergePolicy wrapping class org.apache.lucene.index.TieredMergePolicy: [TieredMergePolicy: maxMergeAtOnce=48, maxMergeAtOnceExplicit=44, maxMergedSegmentMB=36.087890625, floorSegmentMB=2.041015625, forceMergeDeletesPctAllowed=5.091866165642269, segmentsPerTier=10.0, maxCFSSegmentSizeMB=8.796093022207999E12, noCFSRatio=1.0\n   [junit4]   2> 486525 T2793 oasc.SolrDeletionPolicy.onCommit SolrDeletionPolicy.onCommit: commits: num=1\n   [junit4]   2> \t\tcommit{dir=MockDirectoryWrapper(org.apache.lucene.store.RAMDirectory@680d46ed lockFactory=org.apache.lucene.store.SingleInstanceLockFactory@f29f95),segFN=segments_1,generation=1}\n   [junit4]   2> 486526 T2793 oasc.SolrDeletionPolicy.updateCommits newest commit generation = 1\n   [junit4]   2> 486526 T2793 oasc.SolrCore.loadUpdateProcessorChains no updateRequestProcessorChain defined as default, creating implicit default\n   [junit4]   2> 486526 T2793 oasc.RequestHandlers.initHandlersFromConfig created standard: solr.StandardRequestHandler\n   [junit4]   2> 486527 T2793 oasc.RequestHandlers.initHandlersFromConfig created /update: solr.UpdateRequestHandler\n   [junit4]   2> 486531 T2793 oashl.XMLLoader.init xsltCacheLifetimeSeconds=60\n   [junit4]   2> 486533 T2793 oasu.CommitTracker.<init> Hard AutoCommit: disabled\n   [junit4]   2> 486534 T2793 oasu.CommitTracker.<init> Soft AutoCommit: disabled\n   [junit4]   2> 486534 T2793 oasu.RandomMergePolicy.<init> RandomMergePolicy wrapping class org.apache.lucene.index.TieredMergePolicy: [TieredMergePolicy: maxMergeAtOnce=41, maxMergeAtOnceExplicit=23, maxMergedSegmentMB=99.375, floorSegmentMB=1.2001953125, forceMergeDeletesPctAllowed=6.7083922302964725, segmentsPerTier=26.0, maxCFSSegmentSizeMB=8.796093022207999E12, noCFSRatio=0.30206276009451294\n   [junit4]   2> 486535 T2793 oasc.SolrDeletionPolicy.onInit SolrDeletionPolicy.onInit: commits: num=1\n   [junit4]   2> \t\tcommit{dir=MockDirectoryWrapper(org.apache.lucene.store.RAMDirectory@680d46ed lockFactory=org.apache.lucene.store.SingleInstanceLockFactory@f29f95),segFN=segments_1,generation=1}\n   [junit4]   2> 486535 T2793 oasc.SolrDeletionPolicy.updateCommits newest commit generation = 1\n   [junit4]   2> 486535 T2793 oass.SolrIndexSearcher.<init> Opening Searcher@19fcf1c5 main\n   [junit4]   2> 486536 T2794 oasc.SolrCore.registerSearcher [collection1] Registered new searcher Searcher@19fcf1c5 main{StandardDirectoryReader(segments_1:1:nrt)}\n   [junit4]   2> 486536 T2793 oasc.CoreContainer.registerCore registering core: collection1\n   [junit4]   2> 486538 T2792 oas.SolrTestCaseJ4.initCore ####initCore end\n   [junit4]   2> ASYNC  NEW_CORE C999 name=collection1 org.apache.solr.core.SolrCore@32554176\n   [junit4]   2> 486538 T2792 C999 oasu.DirectUpdateHandler2.deleteAll [collection1] REMOVING ALL DOCUMENTS FROM INDEX\n   [junit4]   2> 486539 T2792 C999 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {deleteByQuery=*:*} 0 1\n   [junit4]   2> 486540 T2792 C999 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} {add=[10000]}\n 0 0\n   [junit4]   2> 486545 T2792 C999 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[10001]}\n 0 1\n   [junit4]   2> 486549 T2792 C999 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[10002]}\n 0 2\n   [junit4]   2> 486552 T2792 C999 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[10003]}\n 0 1\n   [junit4]   2> 486556 T2792 C999 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[10004]}\n 0 2\n   [junit4]   2> 486559 T2792 C999 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[10005]}\n 0 1\n   [junit4]   2> 486561 T2792 C999 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[10006]}\n 0 1\n   [junit4]   2> 486564 T2792 C999 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[10007]}\n 0 1\n   [junit4]   2> 486566 T2792 C999 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[10008]}\n 0 1\n   [junit4]   2> 486569 T2792 C999 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[10009]}\n 0 1\n   [junit4]   2> 486571 T2792 C999 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100010]}\n 0 1\n   [junit4]   2> 486573 T2792 C999 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100011]}\n 0 1\n   [junit4]   2> 486576 T2792 C999 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100012]}\n 0 1\n   [junit4]   2> 486578 T2792 C999 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100013]}\n 0 1\n   [junit4]   2> 486580 T2792 C999 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100014]}\n 0 1\n   [junit4]   2> 486583 T2792 C999 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100015]}\n 0 2\n   [junit4]   2> 486585 T2792 C999 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100016]}\n 0 1\n   [junit4]   2> 486587 T2792 C999 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100017]}\n 0 1\n   [junit4]   2> 486590 T2792 C999 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100018]}\n 0 1\n   [junit4]   2> 486593 T2792 C999 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100019]}\n 0 1\n   [junit4]   2> 486596 T2792 C999 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100020]}\n 0 1\n   [junit4]   2> 486600 T2792 C999 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100021]}\n 0 2\n   [junit4]   2> 486603 T2792 C999 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100022]}\n 0 1\n   [junit4]   2> 486606 T2792 C999 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100023]}\n 0 1\n   [junit4]   2> 486610 T2792 C999 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100024]}\n 0 2\n   [junit4]   2> 486613 T2792 C999 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100025]}\n 0 1\n   [junit4]   2> 486617 T2792 C999 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100026]}\n 0 2\n   [junit4]   2> 486621 T2792 C999 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100027]}\n 0 2\n   [junit4]   2> 486624 T2792 C999 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100028]}\n 0 1\n   [junit4]   2> 486628 T2792 C999 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100029]}\n 0 2\n   [junit4]   2> 486631 T2792 C999 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100030]}\n 0 1\n   [junit4]   2> ASYNC  NEW_CORE C1000 name=collection1 org.apache.solr.core.SolrCore@32554176\n   [junit4]   2> 486647 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100031]}\n 0 1\n   [junit4]   2> 486651 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100032]}\n 0 2\n   [junit4]   2> 486654 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100033]}\n 0 1\n   [junit4]   2> 486658 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100034]}\n 0 2\n   [junit4]   2> 486662 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100035]}\n 0 2\n   [junit4]   2> 486665 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100036]}\n 0 1\n   [junit4]   2> 486669 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100037]}\n 0 2\n   [junit4]   2> 486673 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100038]}\n 0 2\n   [junit4]   2> 486677 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100039]}\n 0 2\n   [junit4]   2> 486680 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100040]}\n 0 1\n   [junit4]   2> 486684 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100041]}\n 0 2\n   [junit4]   2> 486688 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100042]}\n 0 2\n   [junit4]   2> 486691 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100043]}\n 0 1\n   [junit4]   2> 486695 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100044]}\n 0 2\n   [junit4]   2> 486698 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100045]}\n 0 1\n   [junit4]   2> 486702 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100046]}\n 0 2\n   [junit4]   2> 486706 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100047]}\n 0 2\n   [junit4]   2> 486710 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100048]}\n 0 2\n   [junit4]   2> 486713 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100049]}\n 0 1\n   [junit4]   2> 486719 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100050]}\n 0 4\n   [junit4]   2> 486722 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100051]}\n 0 2\n   [junit4]   2> 486725 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100052]}\n 0 1\n   [junit4]   2> 486727 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100053]}\n 0 1\n   [junit4]   2> 486730 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100054]}\n 0 1\n   [junit4]   2> 486733 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100055]}\n 0 1\n   [junit4]   2> 486736 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100056]}\n 0 1\n   [junit4]   2> 486738 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100057]}\n 0 1\n   [junit4]   2> 486740 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100058]}\n 0 1\n   [junit4]   2> 486743 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100059]}\n 0 1\n   [junit4]   2> 486746 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100060]}\n 0 1\n   [junit4]   2> 486749 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100061]}\n 0 1\n   [junit4]   2> 486753 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100062]}\n 0 2\n   [junit4]   2> 486756 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100063]}\n 0 1\n   [junit4]   2> 486760 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100064]}\n 0 2\n   [junit4]   2> 486762 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100065]}\n 0 1\n   [junit4]   2> 486765 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100066]}\n 0 1\n   [junit4]   2> 486768 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100067]}\n 0 1\n   [junit4]   2> 486772 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100068]}\n 0 2\n   [junit4]   2> 486775 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100069]}\n 0 2\n   [junit4]   2> 486778 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100070]}\n 0 1\n   [junit4]   2> 486782 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100071]}\n 0 2\n   [junit4]   2> 486785 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100072]}\n 0 1\n   [junit4]   2> 486788 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100073]}\n 0 2\n   [junit4]   2> 486791 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100074]}\n 0 1\n   [junit4]   2> 486795 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100075]}\n 0 2\n   [junit4]   2> 486798 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100076]}\n 0 2\n   [junit4]   2> 486802 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100077]}\n 0 2\n   [junit4]   2> 486805 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100078]}\n 0 2\n   [junit4]   2> 486808 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100079]}\n 0 1\n   [junit4]   2> 486811 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100080]}\n 0 1\n   [junit4]   2> 486815 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100081]}\n 0 2\n   [junit4]   2> 486818 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100082]}\n 0 2\n   [junit4]   2> 486821 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100083]}\n 0 1\n   [junit4]   2> 486824 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100084]}\n 0 1\n   [junit4]   2> 486828 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100085]}\n 0 2\n   [junit4]   2> 486831 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100086]}\n 0 2\n   [junit4]   2> 486834 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100087]}\n 0 2\n   [junit4]   2> 486837 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100088]}\n 0 1\n   [junit4]   2> 486840 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100089]}\n 0 1\n   [junit4]   2> 486843 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100090]}\n 0 1\n   [junit4]   2> 486846 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100091]}\n 0 1\n   [junit4]   2> 486849 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100092]}\n 0 1\n   [junit4]   2> 486852 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100093]}\n 0 1\n   [junit4]   2> 486855 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100094]}\n 0 1\n   [junit4]   2> 486858 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100095]}\n 0 1\n   [junit4]   2> 486861 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100096]}\n 0 1\n   [junit4]   2> 486864 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100097]}\n 0 2\n   [junit4]   2> 486867 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100098]}\n 0 2\n   [junit4]   2> 486869 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{add=[100099]}\n 0 1\n   [junit4]   2> 486870 T2792 C1000 oasu.DirectUpdateHandler2.commit start commit\n{,optimize=false,openSearcher=true,waitSearcher=true,expungeDeletes=false,softCommit=false,prepareCommit=false}\n   [junit4]   2> 486890 T2792 C1000 oasc.SolrDeletionPolicy.onCommit SolrDeletionPolicy.onCommit: commits: num=2\n   [junit4]   2> \t\tcommit\n{dir=MockDirectoryWrapper(org.apache.lucene.store.RAMDirectory@680d46ed lockFactory=org.apache.lucene.store.SingleInstanceLockFactory@f29f95),segFN=segments_1,generation=1}\n   [junit4]   2> \t\tcommit\n{dir=MockDirectoryWrapper(org.apache.lucene.store.RAMDirectory@680d46ed lockFactory=org.apache.lucene.store.SingleInstanceLockFactory@f29f95),segFN=segments_2,generation=2}\n   [junit4]   2> 486891 T2792 C1000 oasc.SolrDeletionPolicy.updateCommits newest commit generation = 2\n   [junit4]   2> 486893 T2792 C1000 oass.SolrIndexSearcher.<init> Opening Searcher@6485c386 main\n   [junit4]   2> 486894 T2792 C1000 oasu.DirectUpdateHandler2.commit end_commit_flush\n   [junit4]   2> 486894 T2794 oasc.SolrCore.registerSearcher [collection1] Registered new searcher Searcher@6485c386 main\n{StandardDirectoryReader(segments_2:4:nrt _0(5.0):C100)}\n   [junit4]   2> 486895 T2792 C1000 oasup.LogUpdateProcessor.finish [collection1] webapp=null path=null params={} \n{commit=}\n 0 25\n   [junit4]   2> ASYNC  NEW_CORE C1001 name=collection1 org.apache.solr.core.SolrCore@32554176\n   [junit4]   2> 487440 T2792 C1001 oasc.SolrException.log ERROR java.lang.IllegalArgumentException: No stat named 'max' in this collector\n   [junit4]   2> \t\tat org.apache.solr.analytics.statistics.MinMaxStatsCollector.getStat(MinMaxStatsCollector.java:86)\n   [junit4]   2> \t\tat org.apache.solr.analytics.expression.BaseExpression.getValue(BaseExpression.java:38)\n   [junit4]   2> \t\tat org.apache.solr.analytics.accumulator.FacetingAccumulator.export(FacetingAccumulator.java:541)\n   [junit4]   2> \t\tat org.apache.solr.analytics.accumulator.FacetingAccumulator.export(FacetingAccumulator.java:489)\n   [junit4]   2> \t\tat org.apache.solr.analytics.request.AnalyticsStats.execute(AnalyticsStats.java:132)\n   [junit4]   2> \t\tat org.apache.solr.handler.component.AnalyticsComponent.process(AnalyticsComponent.java:44)\n   [junit4]   2> \t\tat org.apache.solr.handler.component.SearchHandler.handleRequestBody(SearchHandler.java:215)\n   [junit4]   2> \t\tat org.apache.solr.handler.RequestHandlerBase.handleRequest(RequestHandlerBase.java:135)\n   [junit4]   2> \t\tat org.apache.solr.core.SolrCore.execute(SolrCore.java:1915)\n   [junit4]   2> \t\tat org.apache.solr.util.TestHarness.query(TestHarness.java:291)\n   [junit4]   2> \t\tat org.apache.solr.util.TestHarness.query(TestHarness.java:273)\n   [junit4]   2> \t\tat org.apache.solr.analytics.facet.FieldFacetTest.beforeClass(FieldFacetTest.java:391)\n   [junit4]   2> \t\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n   [junit4]   2> \t\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n   [junit4]   2> \t\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n   [junit4]   2> \t\tat java.lang.reflect.Method.invoke(Method.java:601)\n   [junit4]   2> \t\tat com.carrotsearch.randomizedtesting.RandomizedRunner.invoke(RandomizedRunner.java:1559)\n   [junit4]   2> \t\tat com.carrotsearch.randomizedtesting.RandomizedRunner.access$600(RandomizedRunner.java:79)\n   [junit4]   2> \t\tat com.carrotsearch.randomizedtesting.RandomizedRunner$4.evaluate(RandomizedRunner.java:677)\n   [junit4]   2> \t\tat com.carrotsearch.randomizedtesting.RandomizedRunner$5.evaluate(RandomizedRunner.java:693)\n   [junit4]   2> \t\tat com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)\n   [junit4]   2> \t\tat com.carrotsearch.randomizedtesting.rules.SystemPropertiesRestoreRule$1.evaluate(SystemPropertiesRestoreRule.java:53)\n   [junit4]   2> \t\tat org.apache.lucene.util.AbstractBeforeAfterRule$1.evaluate(AbstractBeforeAfterRule.java:46)\n   [junit4]   2> \t\tat org.apache.lucene.util.TestRuleStoreClassName$1.evaluate(TestRuleStoreClassName.java:42)\n   [junit4]   2> \t\tat com.carrotsearch.randomizedtesting.rules.SystemPropertiesInvariantRule$1.evaluate(SystemPropertiesInvariantRule.java:55)\n   [junit4]   2> \t\tat com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:39)\n   [junit4]   2> \t\tat com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:39)\n   [junit4]   2> \t\tat com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)\n   [junit4]   2> \t\tat org.apache.lucene.util.TestRuleAssertionsRequired$1.evaluate(TestRuleAssertionsRequired.java:43)\n   [junit4]   2> \t\tat org.apache.lucene.util.TestRuleMarkFailure$1.evaluate(TestRuleMarkFailure.java:48)\n   [junit4]   2> \t\tat org.apache.lucene.util.TestRuleIgnoreAfterMaxFailures$1.evaluate(TestRuleIgnoreAfterMaxFailures.java:70)\n   [junit4]   2> \t\tat org.apache.lucene.util.TestRuleIgnoreTestSuites$1.evaluate(TestRuleIgnoreTestSuites.java:55)\n   [junit4]   2> \t\tat com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)\n   [junit4]   2> \t\tat com.carrotsearch.randomizedtesting.ThreadLeakControl$StatementRunner.run(ThreadLeakControl.java:358)\n   [junit4]   2> \t\tat java.lang.Thread.run(Thread.java:722)\n   [junit4]   2> \t\n   [junit4]   2> 487440 T2792 C1001 oasc.SolrCore.execute [collection1] webapp=null path=null params=\n{rows=0&o.percentile_20n.ff=string_sd&o.percentile_20n.ff=date_dtd&o.minn.ff=string_sd&o.minn.ff=date_dtd&o.uniquen.s.float=unique(float_fd)&o.maxn.s.long=max(long_ld)&o.maxn.s.int=max(int_id)&o.stddev.s.long=stddev(long_ld)&o.mean.s.int=mean(int_id)&o.missingn.s.long=missing(long_ld)&o.unique.s.date=unique(date_dtd)&o.missingn.s.double=missing(double_dd)&o.unique.s.str=unique(string_sd)&o.maxn.s.float=max(float_fd)&o.minn.s.int=min(int_id)&o.min.ff=int_id&o.min.ff=long_ld&o.missingf.ff.string_sd.sm=true&o.sum.ff=string_sd&o.sum.ff=date_dtd&o.missing.s.str=missing(string_sd)&o.percentile_60n.s.float=percentile(60,float_fd)&o.sumOfSquares.ff=string_sd&o.sumOfSquares.ff=date_dtd&o.mean.s.double=mean(double_dd)&o.sum.s.float=sum(float_fd)&o.percentile_60n.s.long=percentile(60,long_ld)&o.missingf.ff.date_dtdm.sm=true&o.multivalued.s.mean=mean(int_id)&o.missingn.s.float=missing(float_fd)&o.sumOfSquares.s.double=sumofsquares(double_dd)&o.count.ff=int_id&o.count.ff=long_ld&o.percentile_60n.s.double=percentile(60,double_dd)&o.missing.ff=int_id&o.missing.ff=long_ld&o.uniquen.s.int=unique(int_id)&o.median.s.int=median(int_id)&o.unique.ff=int_id&o.unique.ff=long_ld&o.uniquen.s.long=unique(long_ld)&q=*:*&o.mean.s.long=mean(long_ld)&o.min.s.date=min(date_dtd)&o.missingf.ff=date_dtd&o.missingf.ff=string_sd&o.missingf.ff=date_dtdm&o.max.ff=int_id&o.max.ff=long_ld&o.stddev.s.float=stddev(float_fd)&o.sum.s.int=sum(int_id)&o.missingf.ff.date_dtd.dim=true&o.sumOfSquares.s.long=sumofsquares(long_ld)&o.count.s.str=count(string_sd)&o.max.s.str=max(string_sd)&o.missingn.ff=string_sd&o.missingn.ff=date_dtd&o.max.s.date=max(date_dtd)&o.countn.s.float=count(float_fd)&o.countn.s.long=count(long_ld)&o.sum.s.long=sum(long_ld)&o.median.s.double=median(double_dd)&o.stddev.s.double=stddev(double_dd)&o.median.s.long=median(long_ld)&o.percentile_60n.ff=string_sd&o.percentile_60n.ff=date_dtd&o.sum.s.double=sum(double_dd)&o.percentile_20n.s.double=percentile(20,double_dd)&o.countn.ff=string_sd&o.countn.ff=date_dtd&o.missing.s.date=missing(date_dtd)&o.percentile_60.s.str=percentile(60,string_sd)&o.uniquen.s.double=unique(double_dd)&o.mean.ff=string_sd&o.mean.ff=date_dtd&o.median.ff=string_sd&o.median.ff=date_dtd&o.percentile_20.ff=int_id&o.percentile_20.ff=long_ld&o.stddev.ff=string_sd&o.stddev.ff=date_dtd&o.multivalued.ff=long_ldm&o.multivalued.ff=string_sdm&o.multivalued.ff=date_dtdm&o.countn.s.int=count(int_id)&o.missingn.s.int=missing(int_id)&o.minn.s.float=min(float_fd)&o.uniquen.ff=string_sd&o.uniquen.ff=date_dtd&o.sumOfSquares.s.float=sumofsquares(float_fd)&o.percentile_20n.s.long=percentile(20,long_ld)&indent=true&o.mean.s.float=mean(float_fd)&o.sumOfSquares.s.int=sumofsquares(int_id)&o.count.s.date=count(date_dtd)&o.percentile_20n.s.float=percentile(20,float_fd)&o.minn.s.long=min(long_ld)&o.countn.s.double=count(double_dd)&o.min.s.str=min(string_sd)&o.percentile_60.s.date=percentile(60,date_dtd)&o.maxn.ff=string_sd&o.maxn.ff=date_dtd&o.median.s.float=median(float_fd)&o.percentile_20.s.str=percentile(20,string_sd)&o.minn.s.double=min(double_dd)&o.percentile_20.s.date=percentile(20,date_dtd)&o.missingf.ff.string_sd.dim=true&olap=true&o.percentile_60.ff=int_id&o.percentile_60.ff=long_ld&o.percentile_20n.s.int=percentile(20,int_id)&o.missingf.s.mean=mean(int_id)&o.maxn.s.double=max(double_dd)&o.stddev.s.int=stddev(int_id)&o.percentile_60n.s.int=percentile(60,int_id)}\n hits=100 status=500 QTime=537 \n   [junit4]   2> 487441 T2792 oas.SolrTestCaseJ4.deleteCore ###deleteCore\n   [junit4]   2> 487441 T2792 oasc.CoreContainer.shutdown Shutting down CoreContainer instance=31339713\n   [junit4]   2> 487441 T2792 oasc.SolrCore.close [collection1]  CLOSING SolrCore org.apache.solr.core.SolrCore@32554176\n   [junit4]   2> 487441 T2792 oasu.DirectUpdateHandler2.close closing DirectUpdateHandler2\n{commits=1,autocommits=0,soft autocommits=0,optimizes=0,rollbacks=0,expungeDeletes=0,docsPending=0,adds=0,deletesById=0,deletesByQuery=0,errors=0,cumulative_adds=100,cumulative_deletesById=0,cumulative_deletesByQuery=1,cumulative_errors=0}\n   [junit4]   2> 487442 T2792 oasu.SolrCoreState.decrefSolrCoreState Closing SolrCoreState\n   [junit4]   2> 487442 T2792 oasu.DefaultSolrCoreState.closeIndexWriter SolrCoreState ref count has reached 0 - closing IndexWriter\n   [junit4]   2> 487442 T2792 oasu.DefaultSolrCoreState.closeIndexWriter closing IndexWriter with IndexWriterCloser\n   [junit4]   2> 487442 T2792 oasc.SolrCore.closeSearcher [collection1] Closing main searcher on request.\n   [junit4]   2> 487443 T2792 oasc.CachingDirectoryFactory.close Closing MockDirectoryFactory - 2 directories currently being tracked\n   [junit4]   2> 487443 T2792 oasc.CachingDirectoryFactory.closeCacheValue looking to close /Users/Erick/apache/trunk_5488/solr/build/solr-core/test/J0/./solrtest-FieldFacetTest-1390573386248 [CachedDir<<refCount=0;path=/Users/Erick/apache/trunk_5488/solr/build/solr-core/test/J0/./solrtest-FieldFacetTest-1390573386248;done=false>>]\n   [junit4]   2> 487443 T2792 oasc.CachingDirectoryFactory.close Closing directory: /Users/Erick/apache/trunk_5488/solr/build/solr-core/test/J0/./solrtest-FieldFacetTest-1390573386248\n   [junit4]   2> 487443 T2792 oasc.CachingDirectoryFactory.closeCacheValue looking to close /Users/Erick/apache/trunk_5488/solr/build/solr-core/test/J0/./solrtest-FieldFacetTest-1390573386248/index [CachedDir<<refCount=0;path=/Users/Erick/apache/trunk_5488/solr/build/solr-core/test/J0/./solrtest-FieldFacetTest-1390573386248/index;done=false>>]\n   [junit4]   2> 487443 T2792 oasc.CachingDirectoryFactory.close Closing directory: /Users/Erick/apache/trunk_5488/solr/build/solr-core/test/J0/./solrtest-FieldFacetTest-1390573386248/index\n   [junit4]   2> NOTE: test params are: codec=Lucene46: \n{long_ldm=PostingsFormat(name=Lucene41WithOrds), double_dd=PostingsFormat(name=Lucene41WithOrds), long_ld=PostingsFormat(name=Memory doPackFST= true), int_id=PostingsFormat(name=Memory doPackFST= true), date_dtdm=PostingsFormat(name=Lucene41WithOrds), string_sdm=PostingsFormat(name=Lucene41WithOrds), string_sd=PostingsFormat(name=Memory doPackFST= true), float_fd=MockFixedIntBlock(blockSize=781), id=PostingsFormat(name=Memory doPackFST= true), date_dtd=PostingsFormat(name=Memory doPackFST= true)}\n, docValues:\n{double_dd=DocValuesFormat(name=Lucene45), doubledv=DocValuesFormat(name=Disk), int_id=DocValuesFormat(name=Disk), date_dtdm=DocValuesFormat(name=Lucene45), stringdvm=DocValuesFormat(name=Lucene45), string_sdm=DocValuesFormat(name=Lucene45), longdv=DocValuesFormat(name=Lucene45), float_fd=DocValuesFormat(name=SimpleText), long_ldm=DocValuesFormat(name=Lucene45), stringdv=DocValuesFormat(name=Disk), long_ld=DocValuesFormat(name=Disk), string_sd=DocValuesFormat(name=Disk), intdv=DocValuesFormat(name=SimpleText), date_dtd=DocValuesFormat(name=Disk), datedv=DocValuesFormat(name=Memory), floatdv=DocValuesFormat(name=Lucene45)}\n, sim=DefaultSimilarity, locale=es_PR, timezone=Africa/Timbuktu\n   [junit4]   2> NOTE: Mac OS X 10.9.1 x86_64/Oracle Corporation 1.7.0_13 (64-bit)/cpus=8,threads=1,free=107524728,total=199987200\n   [junit4]   2> NOTE: All tests run in this JVM: [TestCharFilters, TestShardHandlerFactory, CSVRequestHandlerTest, HdfsCollectionsAPIDistributedZkTest, DistributedDebugComponentTest, SpellCheckCollatorTest, ParsingFieldUpdateProcessorsTest, TestLMJelinekMercerSimilarityFactory, TestSolrCoreProperties, TestConfig, JSONWriterTest, FieldAnalysisRequestHandlerTest, HdfsBasicDistributedZkTest, TestBadConfig, CursorPagingTest, RecoveryZkTest, OverseerTest, SolrPluginUtilsTest, TestSolrIndexConfig, DirectSolrConnectionTest, TestTrie, TestFreeTextSuggestions, SynonymTokenizerTest, TestNoOpRegenerator, TestRTGBase, BJQParserTest, FieldMutatingUpdateProcessorTest, TestRandomFaceting, ShardSplitTest, DistributedSuggestComponentTest, ShowFileRequestHandlerTest, PrimUtilsTest, TestFastLRUCache, ResourceLoaderTest, TestSerializedLuceneMatchVersion, TestLMDirichletSimilarityFactory, TestPartialUpdateDeduplication, TestDocumentBuilder, TestQueryUtils, PeerSyncTest, DistributedSpellCheckComponentTest, RequestHandlersTest, TestIndexingPerformance, NumericFieldsTest, BasicDistributedZk2Test, LeaderElectionIntegrationTest, ShardRoutingTest, ClusterStateUpdateTest, ZkSolrClientTest, ShardRoutingCustomTest, ZkControllerTest, DistributedTermsComponentTest, TestRangeQuery, TestGroupingSearch, TestFunctionQuery, OverseerCollectionProcessorTest, DistributedQueryElevationComponentTest, TestExtendedDismaxParser, DocValuesTest, TestStressLucene, SchemaVersionSpecificBehaviorTest, TestWordDelimiterFilterFactory, DocValuesMultiTest, XsltUpdateRequestHandlerTest, StandardRequestHandlerTest, XmlUpdateRequestHandlerTest, RegexBoostProcessorTest, QueryParsingTest, SearchHandlerTest, UpdateParamsTest, TestMergePolicyConfig, ExternalFileFieldSortTest, SpellPossibilityIteratorTest, TestSweetSpotSimilarityFactory, TestFastOutputStream, TestSolrXMLSerializer, DOMUtilTest, TestUtils, FileUtilsTest, AbstractAnalyticsStatsTest, FieldFacetTest]\n   [junit4]   2> NOTE: reproduce with: ant test  -Dtestcase=FieldFacetTest -Dtests.seed=66075F976AAA8705 -Dtests.slow=true -Dtests.locale=es_PR -Dtests.timezone=Africa/Timbuktu -Dtests.file.encoding=ISO-8859-1\n   [junit4] ERROR   0.00s J0 | FieldFacetTest (suite) <<<\n   [junit4]    > Throwable #1: java.lang.IllegalArgumentException: No stat named 'max' in this collector\n   [junit4]    > \tat __randomizedtesting.SeedInfo.seed([66075F976AAA8705]:0)\n   [junit4]    > \tat org.apache.solr.analytics.statistics.MinMaxStatsCollector.getStat(MinMaxStatsCollector.java:86)\n   [junit4]    > \tat org.apache.solr.analytics.expression.BaseExpression.getValue(BaseExpression.java:38)\n   [junit4]    > \tat org.apache.solr.analytics.accumulator.FacetingAccumulator.export(FacetingAccumulator.java:541)\n   [junit4]    > \tat org.apache.solr.analytics.accumulator.FacetingAccumulator.export(FacetingAccumulator.java:489)\n   [junit4]    > \tat org.apache.solr.analytics.request.AnalyticsStats.execute(AnalyticsStats.java:132)\n   [junit4]    > \tat org.apache.solr.handler.component.AnalyticsComponent.process(AnalyticsComponent.java:44)\n   [junit4]    > \tat org.apache.solr.handler.component.SearchHandler.handleRequestBody(SearchHandler.java:215)\n   [junit4]    > \tat org.apache.solr.handler.RequestHandlerBase.handleRequest(RequestHandlerBase.java:135)\n   [junit4]    > \tat org.apache.solr.core.SolrCore.execute(SolrCore.java:1915)\n   [junit4]    > \tat org.apache.solr.util.TestHarness.query(TestHarness.java:291)\n   [junit4]    > \tat org.apache.solr.util.TestHarness.query(TestHarness.java:273)\n   [junit4]    > \tat org.apache.solr.analytics.facet.FieldFacetTest.beforeClass(FieldFacetTest.java:391)\n   [junit4]    > \tat java.lang.Thread.run(Thread.java:722)\n   [junit4] Completed on J0 in 1.19s, 0 tests, 1 error <<< FAILURES!\n   [junit4]  "
        },
        {
            "author": "Steven Bower",
            "id": "comment-13881110",
            "date": "2014-01-24T16:24:20+0000",
            "content": "New patch.. your test failures led me to one issue with MinMax collector where it was checking if the stat was \"max\" but checking min != null...\n "
        },
        {
            "author": "Steven Bower",
            "id": "comment-13881330",
            "date": "2014-01-24T19:18:24+0000",
            "content": "Here is a new patch.. I have a theory about how this is happening but I can't repro so I can't validate.. but I re-org'd a bit of code and added some additional logging that will hopefully give more insight when this happens.. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13881549",
            "date": "2014-01-25T00:01:53+0000",
            "content": "Still the same problem, or a close variant:\nant test  -Dtestcase=FunctionTest -Dtests.seed=32D06837FE8C4122 -Dtests.slow=true -Dtests.locale=et -Dtests.timezone=Etc/GMT+3 -Dtests.file.encoding=US-ASCII\n\n  2> 570438 T4357 C1115 oasc.SolrException.log ERROR java.lang.IllegalArgumentException: No stat named 'median' in this collector\n   [junit4]   2> \t\tat org.apache.solr.analytics.statistics.MinMaxStatsCollector.getStat(MinMaxStatsCollector.java:86)\n   [junit4]   2> \t\tat org.apache.solr.analytics.expression.BaseExpression.getValue(BaseExpression.java:38)\n   [junit4]   2> \t\tat org.apache.solr.analytics.accumulator.BasicAccumulator.export(BasicAccumulator.java:116)\n   [junit4]   2> \t\tat org.apache.solr.analytics.request.AnalyticsStats.execute(AnalyticsStats.java:132)\n   [junit4]   2> \t\tat org.apache.solr.handler.component.AnalyticsComponent.process(AnalyticsComponent.java:44)\n   [junit4]   2> \t\tat org.apache.solr.handler.component.SearchHandler.handleRequestBody(SearchHandler.java:215)\n   [junit4]   2> \t\tat org.apache.solr.handler.RequestHandlerBase.handleRequest(RequestHandlerBase.java:135)\n   [junit4]   2> \t\tat org.apache.solr.core.SolrCore.execute(SolrCore.java:1915)\n   [junit4]   2> \t\tat org.apache.solr.util.TestHarness.query(TestHarness.java:291)\n   [junit4]   2> \t\tat org.apache.solr.util.TestHarness.query(TestHarness.java:273)\n   [junit4]   2> \t\tat org.apache.solr.analytics.util.valuesource.FunctionTest.beforeClass(FunctionTest.java:85)\n   [junit4]   2> \t\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n   [junit4]   2> \t\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n   [junit4]   2> \t\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n   [junit4]   2> \t\tat java.lang.reflect.Method.invoke(Method.java:601)\n   [junit4]   2> \t\tat com.carrotsearch.randomizedtesting.RandomizedRunner.invoke(RandomizedRunner.java:1559)\n   [junit4]   2> \t\tat com.carrotsearch.randomizedtesting.RandomizedRunner.access$600(RandomizedRunner.java:79)\n   [junit4]   2> \t\tat com.carrotsearch.randomizedtesting.RandomizedRunner$4.evaluate(RandomizedRunner.java:677)\n   [junit4]   2> \t\tat com.carrotsearch.randomizedtesting.RandomizedRunner$5.evaluate(RandomizedRunner.java:693)\n   [junit4]   2> \t\tat com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)\n   [junit4]   2> \t\tat com.carrotsearch.randomizedtesting.rules.SystemPropertiesRestoreRule$1.evaluate(SystemPropertiesRestoreRule.java:53)\n   [junit4]   2> \t\tat org.apache.lucene.util.AbstractBeforeAfterRule$1.evaluate(AbstractBeforeAfterRule.java:46)\n   [junit4]   2> \t\tat org.apache.lucene.util.TestRuleStoreClassName$1.evaluate(TestRuleStoreClassName.java:42)\n   [junit4]   2> \t\tat com.carrotsearch.randomizedtesting.rules.SystemPropertiesInvariantRule$1.evaluate(SystemPropertiesInvariantRule.java:55)\n   [junit4]   2> \t\tat com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:39)\n   [junit4]   2> \t\tat com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:39)\n   [junit4]   2> \t\tat com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)\n   [junit4]   2> \t\tat org.apache.lucene.util.TestRuleAssertionsRequired$1.evaluate(TestRuleAssertionsRequired.java:43)\n   [junit4]   2> \t\tat org.apache.lucene.util.TestRuleMarkFailure$1.evaluate(TestRuleMarkFailure.java:48)\n   [junit4]   2> \t\tat org.apache.lucene.util.TestRuleIgnoreAfterMaxFailures$1.evaluate(TestRuleIgnoreAfterMaxFailures.java:70)\n   [junit4]   2> \t\tat org.apache.lucene.util.TestRuleIgnoreTestSuites$1.evaluate(TestRuleIgnoreTestSuites.java:55)\n   [junit4]   2> \t\tat com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)\n   [junit4]   2> \t\tat com.carrotsearch.randomizedtesting.ThreadLeakControl$StatementRunner.run(ThreadLeakControl.java:358)\n   [junit4]   2> \t\tat java.lang.Thread.run(Thread.java:722)   [junit4]   2> \t\n   [junit4]   2> ASYNC  NEW_CORE C1116 name=collection1 org.apache.solr.core.SolrCore@412cebbe\n   [junit4]   2> 570450 T4357 C1116 oasc.SolrCore.execute [collection1] webapp=null path=null params=\n{o.ar.s.sum=sum(add(int_id,float_fd))&o.cdr.s.median=median(const_date(1800-06-30T23:59:59Z))&rows=0&o.ar.s.mean=mean(add(long_ld,double_dd,float_fd))&o.cr.s.maxc=max(concat_second_sd)&o.rr.s.max=max(rev(string_sd))&o.rr.s.min=min(rev(string_sd))&o.cnr.s.sum=sum(const_num(8))&o.mr.s.meanc=mean(mult_ldf_dd)&o.dmr.s.max=max(date_math(date_dtd,const_str(%2B2MONTHS)))&o.nr.s.sum=sum(neg(int_id))&o.mr.s.sum=sum(mult(int_id,float_fd))&o.avr.s.sumc=sum(int_id)&o.dr.s.mean=mean(div(long_ld,double_dd))&o.nr.s.sumc=sum(neg_i_dd)&o.cnr.s.meanc=mean(const_10_dd)&o.rr.s.minc=min(rev_sd)&o.csr.s.max=max(const_str(this+is+the+second))&o.cr.s.minc=min(concat_first_sd)&o.ms.s.min=min(miss_dd)&o.dr.s.meanc=mean(div_ld_dd)&o.dmr.s.median=median(date_math(date_dtd,const_str(%2B2YEARS)))&o.cdr.s.maxc=max(const_04_dtd)&o.avr.s.mean=mean(abs(neg(int_id)))&o.nr.s.mean=mean(neg(long_ld))&o.mr.s.mean=mean(mult(long_ld,double_dd,float_fd))&o.cr.s.max=max(concat(const_str(this+is+the+second),string_sd))&o.mr.s.sumc=sum(mult_if_dd)&o.csr.s.minc=min(const_first_sd)&o.dr.s.sum=sum(div(int_id,float_fd))&o.avr.s.meanc=mean(int_id)&o.cdr.s.max=max(const_date(1804-06-30T23:59:59Z))&o.rr.s.maxc=max(rev_sd)&o.nr.s.meanc=mean(neg_l_dd)&o.cnr.s.sumc=sum(const_8_dd)&o.dmr.s.maxc=max(dm_2m_dtd)&o.ms.s.max=max(miss_dd)&o.dr.s.sumc=sum(div_if_dd)&o.cr.s.min=min(concat(const_str(this+is+the+first),string_sd))&o.pr.s.sumc=sum(pow_if_dd)&o.pr.s.meanc=mean(pow_ld_dd)&o.avr.s.sum=sum(abs(neg(int_id)))&o.ar.s.meanc=mean(add_ldf_dd)&olap=true&o.csr.s.min=min(const_str(this+is+the+first))&o.pr.s.sum=sum(pow(int_id,float_fd))&o.ar.s.sumc=sum(add_if_dd)&indent=true&q=*:*&o.cnr.s.mean=mean(const_num(10))&o.csr.s.maxc=max(const_second_sd)&o.pr.s.mean=mean(pow(long_ld,double_dd))&o.dmr.s.medianc=median(dm_2y_dtd)&o.cdr.s.medianc=median(const_00_dtd)}\n hits=100 status=500 QTime=113 \n   [junit4]   2> 570451 T4357 oas.SolrTestCaseJ4.deleteCore ###deleteCore\n\n\n******\nant test  -Dtestcase=FieldFacetTest -Dtests.seed=32D06837FE8C4122 -Dtests.slow=true -Dtests.locale=et_EE -Dtests.timezone=Europe/Isle_of_Man -Dtests.file.encoding=US-ASCII\n   [junit4]   2> 574920 T2148 C1719 oasc.SolrException.log ERROR java.lang.IllegalArgumentException: No stat named 'min' in this collector\n   [junit4]   2> \t\tat org.apache.solr.analytics.statistics.MinMaxStatsCollector.getStat(MinMaxStatsCollector.java:86)\n   [junit4]   2> \t\tat org.apache.solr.analytics.expression.BaseExpression.getValue(BaseExpression.java:38)\n   [junit4]   2> \t\tat org.apache.solr.analytics.accumulator.FacetingAccumulator.export(FacetingAccumulator.java:541)\n   [junit4]   2> \t\tat org.apache.solr.analytics.accumulator.FacetingAccumulator.export(FacetingAccumulator.java:489)\n   [junit4]   2> \t\tat org.apache.solr.analytics.request.AnalyticsStats.execute(AnalyticsStats.java:132)\n   [junit4]   2> \t\tat org.apache.solr.handler.component.AnalyticsComponent.process(AnalyticsComponent.java:44)\n   [junit4]   2> \t\tat org.apache.solr.handler.component.SearchHandler.handleRequestBody(SearchHandler.java:215)\n   [junit4]   2> \t\tat org.apache.solr.handler.RequestHandlerBase.handleRequest(RequestHandlerBase.java:135)\n   [junit4]   2> \t\tat org.apache.solr.core.SolrCore.execute(SolrCore.java:1915)\n   [junit4]   2> \t\tat org.apache.solr.util.TestHarness.query(TestHarness.java:291)\n   [junit4]   2> \t\tat org.apache.solr.util.TestHarness.query(TestHarness.java:273)\n   [junit4]   2> \t\tat org.apache.solr.analytics.facet.FieldFacetTest.beforeClass(FieldFacetTest.java:391)\n   [junit4]   2> \t\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n   [junit4]   2> \t\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n   [junit4]   2> \t\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n   [junit4]   2> \t\tat java.lang.reflect.Method.invoke(Method.java:601)\n   [junit4]   2> \t\tat com.carrotsearch.randomizedtesting.RandomizedRunner.invoke(RandomizedRunner.java:1559)\n   [junit4]   2> \t\tat com.carrotsearch.randomizedtesting.RandomizedRunner.access$600(RandomizedRunner.java:79)\n   [junit4]   2> \t\tat com.carrotsearch.randomizedtesting.RandomizedRunner$4.evaluate(RandomizedRunner.java:677)\n   [junit4]   2> \t\tat com.carrotsearch.randomizedtesting.RandomizedRunner$5.evaluate(RandomizedRunner.java:693)\n   [junit4]   2> \t\tat com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)\n   [junit4]   2> \t\tat com.carrotsearch.randomizedtesting.rules.SystemPropertiesRestoreRule$1.evaluate(SystemPropertiesRestoreRule.java:53)\n   [junit4]   2> \t\tat org.apache.lucene.util.AbstractBeforeAfterRule$1.evaluate(AbstractBeforeAfterRule.java:46)\n   [junit4]   2> \t\tat org.apache.lucene.util.TestRuleStoreClassName$1.evaluate(TestRuleStoreClassName.java:42)\n   [junit4]   2> \t\tat com.carrotsearch.randomizedtesting.rules.SystemPropertiesInvariantRule$1.evaluate(SystemPropertiesInvariantRule.java:55)\n   [junit4]   2> \t\tat com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:39)\n   [junit4]   2> \t\tat com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:39)\n   [junit4]   2> \t\tat com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)\n   [junit4]   2> \t\tat org.apache.lucene.util.TestRuleAssertionsRequired$1.evaluate(TestRuleAssertionsRequired.java:43)\n   [junit4]   2> \t\tat org.apache.lucene.util.TestRuleMarkFailure$1.evaluate(TestRuleMarkFailure.java:48)\n   [junit4]   2> \t\tat org.apache.lucene.util.TestRuleIgnoreAfterMaxFailures$1.evaluate(TestRuleIgnoreAfterMaxFailures.java:70)\n   [junit4]   2> \t\tat org.apache.lucene.util.TestRuleIgnoreTestSuites$1.evaluate(TestRuleIgnoreTestSuites.java:55)\n   [junit4]   2> \t\tat com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)\n   [junit4]   2> \t\tat com.carrotsearch.randomizedtesting.ThreadLeakControl$StatementRunner.run(ThreadLeakControl.java:358)\n   [junit4]   2> \t\tat java.lang.Thread.run(Thread.java:722)\n   [junit4]   2> \t\n   [junit4]   2> 574921 T2148 C1719 oasc.SolrCore.execute [collection1] webapp=null path=null params=\n{o.max.s.str=max(string_sd)&o.percentile_60n.s.float=percentile(60,float_fd)&o.percentile_60.ff=int_id&o.percentile_60.ff=long_ld&o.mean.s.long=mean(long_ld)&o.max.s.date=max(date_dtd)&o.maxn.ff=string_sd&o.maxn.ff=date_dtd&o.sumOfSquares.s.double=sumofsquares(double_dd)&o.median.s.double=median(double_dd)&o.sum.s.float=sum(float_fd)&o.unique.ff=int_id&o.unique.ff=long_ld&o.percentile_60n.ff=string_sd&o.percentile_60n.ff=date_dtd&o.sumOfSquares.s.int=sumofsquares(int_id)&o.sumOfSquares.ff=string_sd&o.sumOfSquares.ff=date_dtd&o.multivalued.s.mean=mean(int_id)&o.missingf.ff.string_sd.sm=true&o.min.ff=int_id&o.min.ff=long_ld&o.stddev.ff=string_sd&o.stddev.ff=date_dtd&o.count.s.str=count(string_sd)&o.percentile_60n.s.double=percentile(60,double_dd)&o.unique.s.str=unique(string_sd)&o.maxn.s.double=max(double_dd)&o.maxn.s.float=max(float_fd)&o.max.ff=int_id&o.max.ff=long_ld&o.mean.ff=string_sd&o.mean.ff=date_dtd&o.median.s.int=median(int_id)&o.median.ff=string_sd&o.median.ff=date_dtd&o.minn.s.int=min(int_id)&o.missingn.ff=string_sd&o.missingn.ff=date_dtd&o.percentile_20n.s.long=percentile(20,long_ld)&o.uniquen.s.float=unique(float_fd)&o.minn.ff=string_sd&o.minn.ff=date_dtd&o.missingf.ff.date_dtd.dim=true&o.count.ff=int_id&o.count.ff=long_ld&o.percentile_60n.s.int=percentile(60,int_id)&o.percentile_60.s.date=percentile(60,date_dtd)&o.sumOfSquares.s.float=sumofsquares(float_fd)&o.uniquen.s.double=unique(double_dd)&o.stddev.s.float=stddev(float_fd)&q=*:*&o.percentile_20n.ff=string_sd&o.percentile_20n.ff=date_dtd&o.missingf.ff=date_dtd&o.missingf.ff=string_sd&o.missingf.ff=date_dtdm&o.uniquen.s.long=unique(long_ld)&o.percentile_20n.s.float=percentile(20,float_fd)&o.minn.s.float=min(float_fd)&o.missingn.s.float=missing(float_fd)&o.min.s.str=min(string_sd)&o.sum.s.long=sum(long_ld)&o.sumOfSquares.s.long=sumofsquares(long_ld)&o.missing.ff=int_id&o.missing.ff=long_ld&o.uniquen.s.int=unique(int_id)&o.minn.s.double=min(double_dd)&o.percentile_20.s.str=percentile(20,string_sd)&rows=0&o.percentile_20.ff=int_id&o.percentile_20.ff=long_ld&o.missingf.s.mean=mean(int_id)&o.min.s.date=min(date_dtd)&o.missingn.s.int=missing(int_id)&o.stddev.s.double=stddev(double_dd)&o.stddev.s.int=stddev(int_id)&o.sum.s.int=sum(int_id)&o.percentile_20.s.date=percentile(20,date_dtd)&o.minn.s.long=min(long_ld)&o.maxn.s.long=max(long_ld)&o.multivalued.ff=long_ldm&o.multivalued.ff=string_sdm&o.multivalued.ff=date_dtdm&o.median.s.long=median(long_ld)&o.unique.s.date=unique(date_dtd)&o.countn.ff=string_sd&o.countn.ff=date_dtd&o.missing.s.str=missing(string_sd)&o.countn.s.float=count(float_fd)&o.countn.s.int=count(int_id)&indent=true&o.countn.s.double=count(double_dd)&o.countn.s.long=count(long_ld)&o.sum.s.double=sum(double_dd)&o.missingf.ff.string_sd.dim=true&o.median.s.float=median(float_fd)&o.stddev.s.long=stddev(long_ld)&o.percentile_60.s.str=percentile(60,string_sd)&o.missing.s.date=missing(date_dtd)&o.sum.ff=string_sd&o.sum.ff=date_dtd&o.percentile_20n.s.int=percentile(20,int_id)&o.missingf.ff.date_dtdm.sm=true&o.missingn.s.double=missing(double_dd)&o.uniquen.ff=string_sd&o.uniquen.ff=date_dtd&o.maxn.s.int=max(int_id)&o.mean.s.double=mean(double_dd)&o.mean.s.int=mean(int_id)&o.percentile_20n.s.double=percentile(20,double_dd)&o.percentile_60n.s.long=percentile(60,long_ld)&o.missingn.s.long=missing(long_ld)&o.count.s.date=count(date_dtd)&olap=true&o.mean.s.float=mean(float_fd)}\n hits=100 status=500 QTime=167 \n   [junit4]   2> 574922 T2148 oas.SolrTestCaseJ4.deleteCore ###deleteCore "
        },
        {
            "author": "Steven Bower",
            "id": "comment-13881574",
            "date": "2014-01-25T01:01:15+0000",
            "content": "Could provide the logs from above the exception.. this is where the new logging info should be..\n\nthanks! I'm going to try to repro on another computer to see if I can possibly get it to repro as this is a painful process (which I appreciate your patience with) "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13881591",
            "date": "2014-01-25T01:23:03+0000",
            "content": "Here it is. "
        },
        {
            "author": "Steven Bower",
            "id": "comment-13883117",
            "date": "2014-01-27T19:01:32+0000",
            "content": "I finally got a linux box at home to repro this issue (well at least a similar one).. I think the issue in how it identifies individual components of a query so that they are not duplicated throughout the query execution.. i think its just associating the wrong stats collectors with query components.. i've narrowed it down to that but not quite sure exactly where this is or why it is so ephemeral.. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13892227",
            "date": "2014-02-05T15:29:45+0000",
            "content": "Steven Bower We've alit at our rental after a cross-country move. Anything I can to to expedite this? Point me at the code you suspect and perhaps I can be another set of eyes....\n "
        },
        {
            "author": "Mehmet Erkek",
            "id": "comment-13920661",
            "date": "2014-03-05T08:55:25+0000",
            "content": "Gentlemen, I think we have some room to involve in testing this. Is the latest code in the 5.0 trunk? "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13920825",
            "date": "2014-03-05T13:26:42+0000",
            "content": "Mehmet [~merkek@reidin.com]\n\nThe more the merrier! Note the issue here isn't so much correctness testing as it is trying to understand the sproadic test failures and\n1> whether they're just test artifacts\nor\n2> if they do point to some underlying code issues.\n\nIn either case we're trying to get them to disappear.\n\nIt's very sporadic test failure, I can reproduce them fairly quickly by executing:\nant test -Dtestcase=ExpressionTest -Dtests.iters=10000\nalthough other's can't necessarily.\n\nThanks!\nErick "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13936293",
            "date": "2014-03-15T20:26:00+0000",
            "content": "Takes of @Ignore and @BadApple.\n\nSee comments here:\nhttps://issues.apache.org/jira/browse/SOLR-5685\n\nThis fix suddently caused FieldFacetTest to start failing. It fails first time, every time. Interestingly, when it does fail it's because MinMaxStatsCollection.getStat is looking for the stat \"min\", but this.min is null. Seems like it may be related to the mysterious failures we were seeing, but I'm grasping at straws. \n\nI'll be trying ExpressionTest repeatedly to see if we're back now... "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13936313",
            "date": "2014-03-15T21:30:16+0000",
            "content": "OK, maybe we're on to something, ExpressionTest (run with a bunch of iterations) failed with a very similar message to FieldFacetTest.\n\nFWIW "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13937255",
            "date": "2014-03-16T18:28:20+0000",
            "content": "re: SOLR-5685 and all of the sudden FieldFacetTest started breaking.\n\nSteven Bower and Houston Putman I need a quick reply to this to make progress:\n\nI got past the first problem by changing the fieldFacets.txt, i.e. \n\no.min.ff=int_id <- o.min.ff=string_sd\no.min.ff=long_ld <- o.min.ff=date_dtd\n\no.max.ff=int_id <- o.max.ff=string_sd\no.max.ff=long_ld <- o.max.ff=date_dtd\n\nI just noticed that it looked odd, and when I changed it I got past the first problem, but this is making changes without real understanding. There are other places with the older pattern like this one that don't seem to break the test in BeforeClass so it makes me nervous:\n\no.count.s.str=count(string_sd)\no.count.s.date=count(date_dtd)\no.count.ff=int_id\no.count.ff=long_ld\n\nSo I'm not sure whether the changes I made are just irrelevant or perhaps mask something completely different.\n\n**************\nSecond problem:\n\nEverything else is failing, things like:\n\nExpected :[25.0, 26.0, 28.5, 27.0, 22.5, 23.5, 24.5, 25.5, 26.5, 27.5, 24.0]\nActual      :[25.0, 26.0, 27.0, 22.5, 23.5, 24.5, 25.5, 26.5, 27.5, 28.5, 24.0]\n\nSame numbers, just not in the same order. This one from:\n\tat org.apache.solr.analytics.facet.FieldFacetTest.medianFacetAscTest(FieldFacetTest.java:561)\n\nSo is ordering important here or should the values be sorted before passing to\nassertEquals? As you an tell I have no real deep-level understanding of what this code is supposed to do, which makes it difficult to have confidence if I sorted the expected and actual before passing to assertEquals or used  .\n\nI can make the changes above if I have some clue that I'm not doing something foolish. That is, change all the patterns in the fieldFacets.txt and change the collections passed in to assertEquals to be sorted or some such.\n\nThanks! "
        },
        {
            "author": "Houston Putman",
            "id": "comment-13937298",
            "date": "2014-03-16T19:37:23+0000",
            "content": "*** First Problem ***\nIn the fieldFacets,txt did you change it like this?\nturning 'o.min.ff=string_sd' into 'o.min.ff=int_id' and 'o.min.ff=date_dtd' into 'o.min.ff=long_ld'\n\nIf so that doesn't really make since. Because these are calculating the minimum integer value faceting over the string values, and the minimum long value faceting over the date values. If you made the changes above, then you would be calculating the mininum int value faceting over all of the int values, etc. So the change isn't a good test even if it passes.\n*************************\n\n*** Second Problem ***\nSo the ordering is somewhat important. Solr, and the analytics component, automatically sort the results of field facet by the field being faceted on. I assumed this when writing the tests so if the results are coming back misordered, then either the test is either splitting up the values incorrectly or the analytics component is. Or the sorting gets mesed up somewhere in the test. I don't think the sorting is an issue in the component.\n\nLooking through the test code, a lot has been changed from what I wrote. The part that I don't recognize at all is the parsing of the response through methods like getDoubleList() etc. in AbstractAnalyticsFacetTest.java. Since the tests worked before those methods were changed, I would suggest looking at those parsing methods first. \n\n(Side note: the methods in FieldFacetTest.java that still have FacetAsc, like medianFacetAscTest and sumOfSquaresFacetAscTest, should be renamed without the FacetAsc part so that they are named like the rest of the methods. (The FacetAsc functionality was taken out a while ago.) So the methods mentioned above should be renamed to medianTest and sumOfSquaresTest, respectively, in addition to the similarly named methods.\n*****************************\n\nI would highly discourage you from changing the patterns in the fieldFacets.txt. I had trouble keeping all of that stuff straight while writing it and I don't think that is where the issue is. \n\nI'm not able to run the tests right now, so that's all of the help I can give. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13937326",
            "date": "2014-03-16T20:29:55+0000",
            "content": "bq: I would highly discourage you from changing the patterns in the fieldFacets.txt. I had trouble keeping all of that stuff straight while writing it and I don't think that is where the issue is.\n\nThat's what I was worried about, although it seemed like interesting information that may shed light on what the real issue is.\n\nI disagree with the statement that these tests worked before. The whole point of the changes that have been made was because the tests never worked consistently across all the test machine environments, which is why they were never merged into 4x. There would be random failures that have been going on for over three months. There haven't been any recently reported because the tests are ignored (see @BadApple in ExpressionTest and @Ignore in FieldFacetTest).\n\nAh well, I've got to go out now and won't get back to this for a bit.\n "
        },
        {
            "author": "Steven Bower",
            "id": "comment-13937883",
            "date": "2014-03-17T14:58:12+0000",
            "content": "For field facet test this is def an ordering thing.. i started looking at this but haven't finished.. although i think i removed the @Ignore which is why is started failing always..\n\nthat being said I found some rather interesting issues internally that may have been causing some of the intermittent failures..\n\nare these tests with the most recent patch i applied?\n\nstill working.. will update when I get further.. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13937896",
            "date": "2014-03-17T15:06:33+0000",
            "content": "Hey Steve!\n\nSorry, should have updated things yesterday. Yes, these are with all the latest patches applied. That said, I re-wound based on Houston's comments and undid the changes to fieldFacets.txt (which were local anyway, of course I didn't check them in). So essentially, just trunk with your latest patch and removing @Ignore and/or @BadApple.\n\nThe FieldFacetTest is the more interesting since it fails all the time. Why that would be related to the assertU around the commits I have no clue. That seems out in left field somewhere.\n\nI'll be able to look at any changes intermittently starting this evening CA time, got a busy day ahead. "
        },
        {
            "author": "Tom\u00e1s Fern\u00e1ndez L\u00f6bbe",
            "id": "comment-13938167",
            "date": "2014-03-17T18:24:47+0000",
            "content": "\nSecond problem:\n\nEverything else is failing, things like:\n\nExpected :[25.0, 26.0, 28.5, 27.0, 22.5, 23.5, 24.5, 25.5, 26.5, 27.5, 24.0]\nActual :[25.0, 26.0, 27.0, 22.5, 23.5, 24.5, 25.5, 26.5, 27.5, 28.5, 24.0]\n\nSame numbers, just not in the same order. This one from:\nat org.apache.solr.analytics.facet.FieldFacetTest.medianFacetAscTest(FieldFacetTest.java:561)\n\nSo is ordering important here or should the values be sorted before passing to\nassertEquals? As you an tell I have no real deep-level understanding of what this code is supposed to do, which makes it difficult to have confidence if I sorted the expected and actual before passing to assertEquals or used .\nSee my comments in SOLR-5716. The test assumed that the results would be always in the same order, but since SOLR-5685 was fixed, the test started creating multiple segments, which made the component return different ordering (random, depending on when commit/merges occur). I was not aware of this jira, so my attempt to solve this is in SOLR-5716. I changed the test to allow unordered results... but, if this is an undesired behavior of the AnalyticsComponent, then it's a code issue and not a test one.  "
        },
        {
            "author": "Vitaliy Zhovtyuk",
            "id": "comment-13949061",
            "date": "2014-03-27T09:08:49+0000",
            "content": "The following changes were done:\n1. Removed throw new IllegalArgumentException(\"No stat named '\"stat\"' in this collector \" + this); in org.apache.solr.analytics.statistics.MinMaxStatsCollector#getStat because when no stats collected and this method requested it's not excpetional case.\n2. Fixed \norg.apache.solr.analytics.facet.FieldFacetTest#perc20Test\norg.apache.solr.analytics.facet.FieldFacetTest#perc60Test\nThe reason is stats name incompatibility in org.apache.solr.analytics.expression.BaseExpression#getValue like \"percentile\" and \"precentile_60\". Fixed by composible stat name for percentile calls from \"percentile_\" + second function argument in org.apache.solr.analytics.statistics.StatsCollectorSupplierFactory#create.\n3. Fixed \norg.apache.solr.analytics.util.valuesource.FunctionTest#constantStringTest\nand org.apache.solr.analytics.util.valuesource.FunctionTest#multiplyTest.\nThe reason order incompetibility in Maps containing stats in \norg.apache.solr.analytics.statistics.StatsCollectorSupplierFactory#create\nChanged to TreeMap since order by stat string should be same.\n\n4. Fixed org.apache.solr.analytics.facet.FieldFacetTest#missingFacetTest\nby adding to org.apache.solr.analytics.accumulator.FacetingAccumulator#FacetingAccumulator always same order for facet fields.\n\n5. Tests in org.apache.solr.analytics.facet.FieldFacetTest was working unstable because they depended on facet fields order returned from query. Added sorting of result and then assert Also added sorting of stdev results between assert.\n\n6. Removed //nocommit in row in org.apache.solr.analytics.AbstractAnalyticsStatsTest since it did not pass precommit. "
        },
        {
            "author": "Steven Bower",
            "id": "comment-13951344",
            "date": "2014-03-28T20:36:03+0000",
            "content": "Vitaliy Zhovtyuk is your new patch inclusive of my patch from the 14th march? "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13954489",
            "date": "2014-03-29T22:36:00+0000",
            "content": "Hmmm, I'm pretty sure Vitaliy's patch incorporates yours, Steve.\n\nSo I applied Vitaliy's patch and ran the ExpressionTest test 30,000 iterations and no problems so far. The @Ignore and @BadApple annotations are gone.\n\nSo, I'll commit this patch in a bit (running full test suite now). If no test failures happen over the rest of the weekend I propose to merge it into 4x early next week. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13954516",
            "date": "2014-03-29T23:59:47+0000",
            "content": "So I can't check this in yet, although we're much closer. Now we have a failure in FieldFacetExtrasTest. Not quite sure what's going on here, but this line in offsetTest (line 132 or so) is reporting 22 entries rather than 2\n\n assertEquals(getRawResponse(), lon.size(),2);\n\n\nThe other test cases also fail in FieldFacetExtrasTest\n\nGetting closer though! "
        },
        {
            "author": "Vitaliy Zhovtyuk",
            "id": "comment-13954630",
            "date": "2014-03-30T09:23:23+0000",
            "content": "Fixed FieldFacetExtrasTest. Tests passing for me now. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13954706",
            "date": "2014-03-30T15:12:03+0000",
            "content": "Whoppppeeee! All tests pass with Vitaliy Zhovtyuk's changes.\n\nSteven Bower and Houston Putman any thoughts on the changes Vitaliy made? I know this code is tricky....\n\nIf there are no objections, I'll commit this early next week to trunk, and if nothing pops out in a few days merge it into 4x.\n\nErick "
        },
        {
            "author": "Steven Bower",
            "id": "comment-13955223",
            "date": "2014-03-31T14:34:54+0000",
            "content": "Reviewed.. looks good "
        },
        {
            "author": "Houston Putman",
            "id": "comment-13955264",
            "date": "2014-03-31T15:03:04+0000",
            "content": "The changes look good to me. Thanks for the fixes Vitaliy Zhovtyuk. Steven Bower does the performance look the same? Just curious since we have switched maps and are sorting more. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13955281",
            "date": "2014-03-31T15:13:34+0000",
            "content": "If there are no objections, I'll commit this early next week to trunk, and if nothing pops out in a few days merge it into 4x.\n\nRemember, this was only committed to trunk not because of test failures (which we didn't know about when it was committed to trunk), but to give time to solidify the API (which is much harder to change once it's \"released\").  After a quick look, there's probably more to do here.  The biggest thing that popped out at me was the structure of the response - NamedList in some places that should probably be SimpleOrderedMap.  Add \"wt=json&indent=true\" to some sample requests and it's much easier to see. "
        },
        {
            "author": "Steven Bower",
            "id": "comment-13955283",
            "date": "2014-03-31T15:15:33+0000",
            "content": "I've not perf tested since but the sorts seem to over things that are very short (lists of requests/etc..) so I doubt there will be much of a change\n\nAlso I moved the call to getTopFilter() out of loop over requests so this might actually make things a bit faster when there is a large number of requests "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13955382",
            "date": "2014-03-31T17:00:22+0000",
            "content": "OK, I'll probably commit this to trunk tonight and hold off on merging into 4.x for a bit to address the interface questions. I want to get some assurance that the test errors are gone in all environments.\n\nI'd really like to get them addressed and be able to merge in the near future though, but that'll be another JIRA I'd expect. "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-13956419",
            "date": "2014-04-01T11:43:29+0000",
            "content": "Commit 1583636 from Erick Erickson in branch 'dev/trunk'\n[ https://svn.apache.org/r1583636 ]\n\nSOLR-5488: Fix up test failures for Analytics Component. Runs clean locally. "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13959431",
            "date": "2014-04-03T23:36:37+0000",
            "content": "...if nothing pops out in a few days merge it into 4x.\nRemember, this was only committed to trunk not because of test failures (which we didn't know about when it was committed to trunk), but to give time to solidify the API (which is much harder to change once it's \"released\").\n\nMaybe i'm missing something \u2013 but isn't discussions of if/when to backport this to 4x and/or concerns about the API/functionality stuff that should be brought up & debated in SOLR-5302?\n\nIf the tests are now fixed on trunk, then it seems like this issue (SOLR-5488) can be resolved. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13959446",
            "date": "2014-04-03T23:55:36+0000",
            "content": "Right, I've been slammed the last few days so this has lingered.\n\nProblem is that there are about a dozen merges that have to happen in order to get this thing merged into 4x.\n\nI was hoping to have the API question resolved and just be able to do it all at once, but maybe the right thing to do is close both this one and 5302 and raise a new JIRA \"backport analytics component to 4x after solidifying the interface\" or some such.\n\nHmmm, I'm kind of liking that idea. I could list the merges that need to happen right up front and we could go from there.\n\nBoth this and 5302 are so long that the API discussion would be pretty easily lost...\n\nDoes that work? "
        },
        {
            "author": "Steven Bower",
            "id": "comment-13960151",
            "date": "2014-04-04T17:21:12+0000",
            "content": "its probably easier to just manually merge no? just need to copy analytics folder from java/test/test-files and then merge the very minor changes in SearchHandler/SolrCore back ... "
        },
        {
            "author": "Steven Bower",
            "id": "comment-13960156",
            "date": "2014-04-04T17:24:42+0000",
            "content": "Erick Erickson I agree btw...\n\nAlso per me prev comment.. this is how I internally manage the upstream changes to analytics (from trunk) into our internal repo (now against 4.7.1) and it works without any additional changes.. this may just be \"cleaner\" although you lose the history "
        },
        {
            "author": "Steven Bower",
            "id": "comment-13960294",
            "date": "2014-04-04T19:06:06+0000",
            "content": " scratch that.. there are changes in 4.7.1 that make a direct copy a pain.. but i can post up a trunk -> 4.7.1 patch if needed "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13960771",
            "date": "2014-04-04T23:16:39+0000",
            "content": "We seem to have stabilized this in trunk, so we need to back port it to 4x when we get any outstanding interface issues resolved. See: SOLR-5963 i "
        }
    ]
}