{
    "id": "LUCENE-5084",
    "title": "EliasFanoDocIdSet",
    "details": {
        "components": [],
        "fix_versions": [
            "4.5",
            "6.0"
        ],
        "affect_versions": "None",
        "priority": "Minor",
        "labels": "",
        "type": "Improvement",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "DocIdSet in Elias-Fano encoding",
    "attachments": {
        "LUCENE-5084.patch": "https://issues.apache.org/jira/secure/attachment/12590207/LUCENE-5084.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2013-06-30T15:02:09+0000",
            "content": "For the patch of 30 June 2013:\n\nThis consists of the class EliasFanoDocIdSet and the two classes that it uses, EliasFanoEncoder and EliasFanoDecoder.\nThe last two are implemented on long, EliasFanoDocIdSet does the casting to and from int for DocIdSet.\n\nThere are various ways in which the decoding speed could still be improved:\nAddition of an index on the high bits, see the Vigna paper.\nUse of broadword bit searching, actually better done at another issue, this uses Long method bitCount and numberOfTrailingZeros.\nI have not yet profiled for performance bottlenecks.\n\nThe decoder is not really complete, it has an advanceToIndex method but no backToIndex method yet.\n\nNevertheless this is usable now because the compression works and the linear searches that are done (because of the lack on indexing) will access no more than roughly 3N bits, where N is the number of doc ids in the set, and FixedBitSet.nextDoc() can (theoretically) access a number of bits equal to the number of docs in a segment.\n\n\nTestEliasFanoSequence tests EliasFanoEncoder and EliasFanoDecoder.\n\nTestEliasFanoDocIdSet tests EliasFanoDocIdSet.\n\nI have used package o.a.l.util.eliasfano, this could be changed to o.a.l.util.packed for example.\n\nThere is a NOCOMMIT for a static longHex method that dumps a long in fixed width hex format, is there a better place for this method? ",
            "author": "Paul Elschot",
            "id": "comment-13696352"
        },
        {
            "date": "2013-06-30T19:54:44+0000",
            "content": "I have not dug much through the code but I tested it against various randomly-generated sets with numDocs=10M, and the compression looks great:\n\n\n\n\nLoad\nFixedBitSet\nWAH8DocIdSet(LUCENE-5081)\nEliasFanoDocIdSet(this issue)\nPForDeltaDocIdSet(from kamikaze, LUCENE-2750)\n\n\n0.001%\t\n1.2 MB\t\n424 bytes\t\n344 bytes\t\n9 KB\n\n\n0.01%\t\n1.2 MB\t\n3.4 KB\t\n2 KB\t\n10.6 KB\n\n\n0.1%\t\n1.2 MB\t\n28.4 KB\t\n14.7 KB\t\n25.1 KB\n\n\n1%\t\n1.2 MB\t\n223.2 KB\t\n104.6 KB\t\n132.3 KB\n\n\n10%\t\n1.2 MB\t\n1 MB\t\n641 KB\t\n860.5 KB\n\n\n30%\t\n1.2 MB\t\n1.2 MB\t\n1.3 MB\t\n1.9 MB\n\n\n50%\t\n1.2 MB\t\n1.2 MB\t\n1.8 MB\t\n2.7 MB\n\n\n70%\t\n1.2 MB\t\n1.2 MB\t\n2 MB\t\n3 MB\n\n\n90%\t\n1.2 MB\t\n1.2 MB\t\n2.3 MB\t\n3.1 MB\n\n\n\n\n\nI especially like the fact that it saves almost half the memory even for pretty large sets that contain 1/10th of all doc IDs.\n\nI have used package o.a.l.util.eliasfano, this could be changed to o.a.l.util.packed for example.\n\nIndeed maybe we don't need a dedicated package for this DocIdSet. oal.util.packed would be fine I think.\n\nThere is a NOCOMMIT for a static longHex method that dumps a long in fixed width hex format, is there a better place for this method?\n\nI think it is OK to leave it here.\n\nI'll try to dig more thoroughly into the patch in the next few days... ",
            "author": "Adrien Grand",
            "id": "comment-13696404"
        },
        {
            "date": "2013-06-30T21:08:07+0000",
            "content": "Coo bitset \n\nWhat's up with the kamikaze bitset, also an option? ",
            "author": "Uwe Schindler",
            "id": "comment-13696412"
        },
        {
            "date": "2013-06-30T21:45:33+0000",
            "content": "That was fast \nThe results posted above seem to be in line with the formula below, and that is quite nice to see.\n\nThe upper bound for the size in bits per encoded number in an EliasFanoDocIdSet is:\n\n2 + ceil(2log(upperBound/numValues))\n\nand a few constant size objects also have to be added in there.\n\n\n\nPlease note that there is no index yet. The index will be relatively small, for example for the 10% case above with 641 kB I expect an index size of about 12 kB, adding about 2% to the size.\nThis index will consist of N/256 entries of a single number  with max value 3N, i.e. ceil(2log(3N)) bits per index entry.\n\n\nThe code posted here is still young. So even though it has some test cases, I'd like be reassured that in the code that produced the posted results, there is at least a basic test that verifies that all input docs are available after compression. Is that the case? ",
            "author": "Paul Elschot",
            "id": "comment-13696415"
        },
        {
            "date": "2013-06-30T22:06:01+0000",
            "content": "Uwe,\n\nThe EliasFanoDocIdSet is not a bitset, but it is definitely cool, please have a look at the Vigna article I mentioned at LUCENE-5081.\n\nThe upper bound above on the bits per encoded number is valid for every sorted permutation of non negative whole numbers bounded by upperBound, and this size bound is no more than half a bit larger than the smallest possible representation. ",
            "author": "Paul Elschot",
            "id": "comment-13696417"
        },
        {
            "date": "2013-06-30T22:10:35+0000",
            "content": "Please note that there is no index yet. The index will be relatively small, for example for the 10% case above with 641 kB I expect an index size of about 12 kB, adding about 2% to the size. This index will consist of N/256 entries of a single number with max value 3N, i.e. ceil(2log(3N)) bits per index entry.\n\nThis sounds good!\n\nThe code posted here is still young. So even though it has some test cases, I'd like be reassured that in the code that produced the posted results, there is at least a basic test that verifies that all input docs are available after compression. Is that the case?\n\nYes, I checked that all doc ID sets have the same content. ",
            "author": "Adrien Grand",
            "id": "comment-13696418"
        },
        {
            "date": "2013-06-30T22:12:53+0000",
            "content": "What's up with the kamikaze bitset, also an option?\n\nI'll take some time to evaluate all the options we have for compressed doc ID sets, and the kamikaze implementation is one of them. ",
            "author": "Adrien Grand",
            "id": "comment-13696420"
        },
        {
            "date": "2013-06-30T22:39:19+0000",
            "content": "The number of index entries may actually be 2N/256 instead of N/256.\nThat would be about 4% size in the case above.\n\nI am about to implement such an index, but my tempo is going to be slow. So in case anyone can do that faster...\n ",
            "author": "Paul Elschot",
            "id": "comment-13696424"
        },
        {
            "date": "2013-07-01T03:07:38+0000",
            "content": "Sorry if this sounds uninformed, but what is the CPU tradeoff for all these compressions and how does query speed compare across all of them?  What is the logic behind never looking at that when making memory comparisons?  I skimmed the paper Paul references and saw the main comparisons were really more about query speed and less about memory savings. Thanks. ",
            "author": "Otis Gospodnetic",
            "id": "comment-13696450"
        },
        {
            "date": "2013-07-01T22:19:56+0000",
            "content": "Have you considered creating a PostingFormat with this? I was thinking in something like DirectPostingsFormat but instead of using an array of ints for storing the docIds using an Elias-Fano compressed bit stream.\nFacebook is using an in-memory index for its graph search and they are compressing the posting lists with Elias Fano (https://www.facebook.com/download/138915572976390/UnicornVLDB-final.pdf) ",
            "author": "Emmanuel Espina",
            "id": "comment-13697263"
        },
        {
            "date": "2013-07-01T23:34:36+0000",
            "content": "I think LUCENE-5052 will explore that (using a bitset to represent DOCS_ONLY postings)... ",
            "author": "Michael McCandless",
            "id": "comment-13697329"
        },
        {
            "date": "2013-07-02T07:45:32+0000",
            "content": "Have you considered creating a PostingFormat with this? I was thinking in something like DirectPostingsFormat but instead of using an array of ints for storing the docIds using an Elias-Fano compressed bit stream.\n\nThe Vigna paper is all about posting formats.\nBecause of this I first implemented an encoder and a decoder in a long format, and then used these here for a DocIdSet that works on int.\n\nFor a postings format, the encoder would need an additional constructor from index data. That might involve merging the currently separate long arrays for high bits and low bits into a single array. ",
            "author": "Paul Elschot",
            "id": "comment-13697584"
        },
        {
            "date": "2013-07-02T08:11:42+0000",
            "content": "... what is the CPU tradeoff for all these compressions and how does query speed compare across all of them?\n\nWe don't really know.\nOne conclusion from the Vigna paper is that a tuned implementation of an Elias-Fano decoder is faster than a tuned PForDelta implementation for highly selective phrase queries.\nI would guess that that is because Elias-Fano uses random access to the low bits where PForDelta only uses bulk decompression of the low bits, which compensates for  Elias-Fano decoding its high bits somewhat slower than PForDelta can decode its exceptions.\n\nOne reason to use Elias-Fano for a DocIdSet here is that its high bits are encoded in unary coding which can easily be decoded in two directions, and that makes it useful for block joins. The other reason is that its compression is quite good, which makes it a nice candidate for in memory filters. ",
            "author": "Paul Elschot",
            "id": "comment-13697601"
        },
        {
            "date": "2013-07-02T19:29:30+0000",
            "content": "I had a deeper look at the patch, here are some thoughts about it:\n\n\tthe patch looks great, really, I especially like all the integrity checks!\n\tafter having read more of it, I think moving it to oal.util.packed makes perfect sense\n\tthe documentation mentions the fact that a FixedBitSet will be more storage efficient if numValues >= (upperBound/3), maybe we should have a static utility method to check that so that consumers of this API can opt for a FixedBitSet if their doc set is going to be dense?\n\tin EliasFanoEncoder constructor, the ceil of the log in base 2 is computed through a loop, can we use Integer.numberOfLeadingZeros instead (as explained in http://docs.oracle.com/javase/7/docs/api/java/lang/Integer.html#numberOfLeadingZeros(int) )\n\tI think it would make sense to use PackedInts.getMutable to store the low-order bits instead of a raw long[] (this abstraction will hide the complexity of the bit packing or even use a more appropriate structure, eg. if the number of bits required is 8, it will use a byte[])\n\tI'm not sure but shouldn't the iterator's getCost method return efDecoder.numValues instead of efEncoder.numValues?\n\n\n\nEven though storing longs is more general, it forces us to use a different value to encode NO_MORE_DOCS which adds a little complexity to the DocIdSet implementation. Maybe we could just support the encoding of monotonically increasing sequences of ints to make things simpler? (just thinking out loud). ",
            "author": "Adrien Grand",
            "id": "comment-13698122"
        },
        {
            "date": "2013-07-02T22:10:27+0000",
            "content": "maybe we should have a static utility method to check that so that consumers of this API can opt for a FixedBitSet if their doc set is going to be dense?\n\nWe could, but in which class? For example, in CachingWrapperFilter it might be good to save memory, so it could be there.\nAlso, would the expected size be the only thing to check for? When decoding speed is also important, other DocIdSets might be preferable.\n\n\nthe ceil of the log in base 2 is computed through a loop\nnumberOfLeadingZeros is indeed better than a loop. We need the Long variant here.\n\nuse PackedInts.getMutable to store the low-order bits instead of a raw long[]\nCan PackedInts.getMutable also be used in a codec? Longs are needed for the high bits, see below, and the high and low bits can be conveniently stored next to each other in an index.\n\nshouldn't the iterator's getCost method return efDecoder.numValues instead of efEncoder.numValues?\nYes.\n\nMaybe we could just support the encoding of monotonically increasing sequences of ints to make things simpler?\n\nI considered a decoder that returns ints but that would require a lot more casting in the decoder.\nDecoding the unary encoded high bits is best done on longs, so mixing longs and ints in the encoder is not really an option.\nWe could pass the actual NO_MORE_VALUES to be used as an argument to the decoder, would that help?\n\nAs to why decoding the unary encoded high bits is best done on longs, see Algorithm 2 in \"Broadword Implementation of Rank/Select Queries\", Sebastiano Vigna, January 30, 2012, http://vigna.di.unimi.it/ftp/papers/Broadword.pdf .\nI also have an initial java implementation of that, but it is not used here yet, there are only a few comments in the code here that it might be used. I'll open another issue for broadword bit selection later.\n\n\n ",
            "author": "Paul Elschot",
            "id": "comment-13698319"
        },
        {
            "date": "2013-07-03T09:10:25+0000",
            "content": "We could, but in which class? For example, in CachingWrapperFilter it might be good to save memory, so it could be there.\n\nThis new doc id set might be used for other use-cases in the future, so maybe we should have this method on the EliasFanoDocIdSet class?\n\nAlso, would the expected size be the only thing to check for? When decoding speed is also important, other DocIdSets might be preferable.\n\nSure, this is something we need to give users control on. For filter caches, it is already possible to override CachingWrapperFilter.docIdSetToCache to decide whether speed or memory usage is more important. The decision can even depend on the cardinality of the set to cache or on its implementation. So we just need to provide users with good defaults I think?\n\nI haven't run performance benchmarks on this set implementation yet, but if it is faster than the DocIdSets iterators of our default postings format, then they are not going to be a bottleneck and I think it makes sense to use the implementation that saves the most memory. If they are slower or not faster enough, then maybe other implementations such as kamikaze's p-for-delta-based doc ID sets (LUCENE-2750) would make more sense as a default.\n\nCan PackedInts.getMutable also be used in a codec?\n\nThe PackedInts API can return readers that can read directly from an IndexInput if this is the question but if we want to be able to store high and low bits contiguously then they are not going to be a good fit.\n\nI considered a decoder that returns ints but that would require a lot more casting in the decoder.\n\nOK. I just wanted to have your opinion on this, we can keep everything as a long.\n\nI'll open another issue for broadword bit selection later.\n\nSounds good! I think backwards iteration and efficient skipping should be done in separate issues as well, even without them this new doc ID set would be a very nice addition. ",
            "author": "Adrien Grand",
            "id": "comment-13698767"
        },
        {
            "date": "2013-07-04T15:40:33+0000",
            "content": "Ok, I'll post a new patch that\n\n\tis in package oal.util.packed,\n\tuses numberOfLeadingZeros instead of a loop,\n\thas a correct getCost, and\n\thas a static method sufficientlySmallerThanBitSet, deliberately imprecise...\n\n ",
            "author": "Paul Elschot",
            "id": "comment-13700152"
        },
        {
            "date": "2013-07-04T17:56:02+0000",
            "content": "As announced on 4 July 2013. ",
            "author": "Paul Elschot",
            "id": "comment-13700257"
        },
        {
            "date": "2013-07-05T07:25:29+0000",
            "content": "The patch looks ready. I think we should just add a bit more randomization to the tests before committing. ",
            "author": "Adrien Grand",
            "id": "comment-13700499"
        },
        {
            "date": "2013-07-05T15:38:50+0000",
            "content": "Would you have any specific purpose for randomized testing?\n\nRandomized test cases with uniform data distributions are not likely to test exceptional situations in the high bits such as long high bit words with all zeros or all ones. ",
            "author": "Paul Elschot",
            "id": "comment-13700938"
        },
        {
            "date": "2013-07-05T17:51:43+0000",
            "content": "I tend to like testing different scenarii every time tests are run (and tests, especially lucene-core tests, are run very very often by the CI servers), this helped find many unsuspected bugs in the past. For example, the random variable can be used to compute slight variations from the exceptional situations which are interesting to test. ",
            "author": "Adrien Grand",
            "id": "comment-13701030"
        },
        {
            "date": "2013-07-05T18:53:39+0000",
            "content": "Randomized test cases with uniform data distributions are not likely to test exceptional situations in the high bits such as long high bit words with all zeros or all ones.\n\nThe exceptional situations you can test separately. I am constantly surprised at how many exceptional conditions in pretty much regular code one can overlook. Like Adrien said \u2013 it doesn't hurt to be in there and if it catches something, it's even better. ",
            "author": "Dawid Weiss",
            "id": "comment-13701067"
        },
        {
            "date": "2013-07-06T06:54:54+0000",
            "content": "At the moment I don't know how to do better random testing than the code that produced the results posted above, so for now I'll concentrate on adding an index. ",
            "author": "Paul Elschot",
            "id": "comment-13701263"
        },
        {
            "date": "2013-07-09T15:18:58+0000",
            "content": "for now I'll concentrate on adding an index.\n\nHave you started working on it? Otherwise I would like to commit your patch, I think it is already a very good improvement and we can work on the index on another issue, what do you think? ",
            "author": "Adrien Grand",
            "id": "comment-13703369"
        },
        {
            "date": "2013-07-09T15:22:51+0000",
            "content": "Otherwise I would like to commit your patch, I think it is already a very good improvement and we can work on the index on another issue\n\n+1 definitely.  One step at a time.  Thanks Paul & Adrien. ",
            "author": "David Smiley",
            "id": "comment-13703373"
        },
        {
            "date": "2013-07-09T18:11:31+0000",
            "content": "For now the indexed version is in subclasses of the encoder and decoder.\nIn these I only expect some changes in method signatures from private to protected, so I don't mind either way. ",
            "author": "Paul Elschot",
            "id": "comment-13703581"
        },
        {
            "date": "2013-07-09T19:08:34+0000",
            "content": "Broadword bit selection is at LUCENE-5098 . ",
            "author": "Paul Elschot",
            "id": "comment-13703662"
        },
        {
            "date": "2013-07-09T21:49:06+0000",
            "content": "Commit 1501576 from Adrien Grand\n[ https://svn.apache.org/r1501576 ]\n\nLUCENE-5084: EliasFanoDocIdSet. ",
            "author": "ASF subversion and git services",
            "id": "comment-13703846"
        },
        {
            "date": "2013-07-09T21:53:13+0000",
            "content": "Commit 1501577 from Adrien Grand\n[ https://svn.apache.org/r1501577 ]\n\nLUCENE-5084: Move Elias-Fano encoding from Lucene 4.4 to 4.5... ",
            "author": "ASF subversion and git services",
            "id": "comment-13703853"
        },
        {
            "date": "2013-07-09T21:55:58+0000",
            "content": "Commit 1501578 from Adrien Grand\n[ https://svn.apache.org/r1501578 ]\n\nLUCENE-5084: EliasFanoDocIdSet (merged from r1501576 and r1501577). ",
            "author": "ASF subversion and git services",
            "id": "comment-13703856"
        },
        {
            "date": "2013-07-09T23:15:48+0000",
            "content": "Committed, thanks Paul! ",
            "author": "Adrien Grand",
            "id": "comment-13703978"
        },
        {
            "date": "2013-10-05T10:19:29+0000",
            "content": "4.5 release -> bulk close ",
            "author": "Adrien Grand",
            "id": "comment-13787153"
        }
    ]
}