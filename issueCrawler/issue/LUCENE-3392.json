{
    "id": "LUCENE-3392",
    "title": "Combining analyzers output",
    "details": {
        "labels": "",
        "priority": "Minor",
        "components": [
            "modules/analysis"
        ],
        "type": "New Feature",
        "fix_versions": [
            "4.9",
            "6.0"
        ],
        "affect_versions": "None",
        "resolution": "Unresolved",
        "status": "Open"
    },
    "description": "It should be easy to combine the output of multiple Analyzers, or TokenStreams.\nA ComboAnalyzer and a ComboTokenStream class would take multiple instances, and multiplex their output, keeping a rough order of tokens like increasing position then increasing start offset then increasing end offset.",
    "attachments": {
        "ComboAnalyzer-lucene3x.patch": "https://issues.apache.org/jira/secure/attachment/12491336/ComboAnalyzer-lucene3x.patch",
        "ComboAnalyzer-lucene-trunk.patch": "https://issues.apache.org/jira/secure/attachment/12491343/ComboAnalyzer-lucene-trunk.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2011-08-23T12:06:48+0000",
            "content": "Patch for lucene-3x.\nTested with Sun's Java 1.6.0_26-b03.\nUses a special factory for cloning Readers, some implementation use reflection to gain access to private fields in order to reduce the need to read and copy a Readers' content. ",
            "author": "Olivier Favre",
            "id": "comment-13089413"
        },
        {
            "date": "2011-08-23T12:17:04+0000",
            "content": "The proposed implementation may a have tight bond with the JVM implementation of some classes (StringReader, BufferedReader and FilterReader), as they rely on a named private field (respectively \"str\", \"in\" and \"in\").\nThis can be avoided, but any Reader should then be fully read and stored as a String or a char[], which can have a huge overhead.\nConsidering each clone would get read relatively at the same speed (well, only for word delimiting analysis, not for a KeywordAnalyzer) an implementation could only retain in memory the portion read by at least one cloned reader but not all clones, in order to implement a \"multi read head\" reader.\n\nAnother implementation would be to change the API to give a CloneableReader interface with a \"giveAClone()\" function instead of a Reader for tokenStream and reusableTokenStream functions.\nBut this involves massive refactoring (>13,000 lines) and introduces an important API break.\n\nThe proposed implementation is the best solution I found.\nAny suggestions are welcome! ",
            "author": "Olivier Favre",
            "id": "comment-13089415"
        },
        {
            "date": "2011-08-23T14:32:25+0000",
            "content": "Patch for lucene-trunk.\nTested with sun's Java 1.6.0_26-b03.\nAdds support for Reader cloning in lucene's core, and the analysis stuff in modules/analysis/common ",
            "author": "Olivier Favre",
            "id": "comment-13089504"
        },
        {
            "date": "2011-08-23T14:58:20+0000",
            "content": "Moved analysis related changes into contrib/analysers/common, like the patch for the trunk.\n\nSmall changes:\n\n\t2 space indentation (was 4 before, my personal default value)\n\tremoved a few useless imports\n\tsimplified ComboTokenStream, and fixes, as I saw functions have become final in the trunk.\n\n ",
            "author": "Olivier Favre",
            "id": "comment-13089522"
        },
        {
            "date": "2012-03-21T18:14:25+0000",
            "content": "Bulk of fixVersion=3.6 -> fixVersion=4.0 for issues that have no assignee and have not been updated recently.\n\nemail notification suppressed to prevent mass-spam\npsuedo-unique token identifying these issues: hoss20120321nofix36 ",
            "author": "Hoss Man",
            "id": "comment-13234779"
        },
        {
            "date": "2013-07-23T18:44:54+0000",
            "content": "Bulk move 4.4 issues to 4.5 and 5.0 ",
            "author": "Steve Rowe",
            "id": "comment-13717097"
        },
        {
            "date": "2014-04-16T12:54:25+0000",
            "content": "Move issue to Lucene 4.9. ",
            "author": "Uwe Schindler",
            "id": "comment-13970745"
        }
    ]
}