{
    "id": "SOLR-1270",
    "title": "Legacy Numeric Field types need to be more consistent in their input/output error checking & documentation",
    "details": {
        "affect_versions": "1.2,                                            1.3,                                            1.4",
        "status": "Closed",
        "fix_versions": [
            "1.4"
        ],
        "components": [
            "search"
        ],
        "type": "Bug",
        "priority": "Minor",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "FloatField, IntField, ByteField, LongField. and DoubleField have inconsistent behavior at response writing time when dealing with \"garbage\" data in the index.  the behavior should be standardized, and better documented.\n\n\u2013\n\nThis issue originally came from my php client issue tracker: http://code.google.com/p/solr-php-client/issues/detail?id=13",
    "attachments": {
        "SOLR-1270.patch": "https://issues.apache.org/jira/secure/attachment/12413826/SOLR-1270.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Hoss Man",
            "id": "comment-12732220",
            "date": "2009-07-16T22:50:59+0000",
            "content": "\n\n\tFloatField is doing what it's suppose to (being fast and trusting the user input)\n\tJSONWriter is doing what it's suppose to (being fast and trusting that the data in the fields is valid.\n\n\n\nThe only way (i know of) to get invalid JSON output from the JSONWriter from a numeric field is for the client to index invalid data.\n\nGarbage in, Garbage out.\n\nIf there is a way to make JSONWriter error on a legal float value, then there is a bug in JSONWriter and we should fix it.  but if the problem is users indexing bogus data, then either the users should clean up their data, or we should add a \"ParanoidFloatField\" that validates the input (at the expense of performance).\n\nIf you have suggestions for documentation improvements to make users more aware of their responsibilities when using FloatField (and IntField, etc...) they would definitely be appreciated.\n "
        },
        {
            "author": "Matt Schraeder",
            "id": "comment-12732294",
            "date": "2009-07-17T01:28:44+0000",
            "content": "The data being indexed is valid.  It is a float value less than 1.  This means a \"0.0\" or a \"0.5\" or the like.  The JSONWriter is outputting \".5\" and \".0\" rather than with the leading zero.  This causes an invalid JSON encode because \".5\" is not a valid float in JSON. You need the leading 0 before the decimal.\n\nYou can verify this in the example code that Donovan wrote. "
        },
        {
            "author": "Donovan Jimenez",
            "id": "comment-12732330",
            "date": "2009-07-17T04:14:02+0000",
            "content": "Matt is refering to the code I posted in http://code.google.com/p/solr-php-client/issues/detail?id=13#c8 Where I indexed php values null, 0, \"0\", and \".0\" as FloatField.   \n\nI agree with Hoss here, the \".0\" or null IS garbage according to the JSON numeric (json.org) and Java Floating Point Literal specifations (http://java.sun.com/docs/books/jls/second_edition/html/lexical.doc.html#230798).   \n\nWhat I don't understand is why it wouldn't be beneficial for the FloatField type to use Float.parseFloat() for value checking at index time. My opinion is that the pro of directly letting the user know their input document does not match the expectations of their schema outweighs the con of  the time it takes to parse the value.  It doesn't remove the need for separate documentation, but getting the error at index time makes more sense then getting a JSON parsing error when querying. The cause and effect become less detached. "
        },
        {
            "author": "Matt Schraeder",
            "id": "comment-12732344",
            "date": "2009-07-17T04:59:56+0000",
            "content": "Let me clarify a bit, because I don't think I came across how I meant to.  There are two issues at work here.\n\n1) The fact that the index lets you add invalid data to an index. Solr should either do it's best to parse the value as a float that it's expecting, or it should throw an error saying you gave it invalid data that doesn't match the field.  If speed is more important that verification, that's your decision and I can agree with that\n\n2) When I WAS passing in valid data to the index, I was passing in small float values such as 0.0 and 0.5. Basically, any value < 1.  Solr's JSONWriter wasn't returning these values as 0.0 or 0.5, which would be the proper return.  They were returning the value without the leading 0.  By not having the leading 0, php's JSON decode fails because the value it's receiving is \".0\" or \".5\".  The period before hand it interprets as a string, rather than a decimal, but as long as there was a number before the decimal it was fine (1.5 came out as 1.5 and was interpreted as a float by JSON decode properly.\n\nThese, in my opinion, are the same bug: JSON Writer is returning invalid JSON.  In issue 1, yes it's because of invalid data in the index.  If the index is bad I cannot expect the JSON to be valid.  In issue 2 the data in SOLR is valid and stored/returned properly as 0.5 with the leading 0, but in the JSON not having the leading 0 is breaking validation and keeping the user from being able to properly decode the JSON string. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12732576",
            "date": "2009-07-17T15:29:06+0000",
            "content": "I agree we should strive to generate valid transfer syntax, and that is probably more important than maintaining the correct (float) type since that is at a higher level.\n\nThe plain numeric types were really meant for back compatibility with existing Lucene indexes being read by Solr - so trying to normalize during indexing (in Solr) won't solve all of the problems.  Once the new numeric types in Solr (the Trie based ones) get full support, these plain types should only be used for back compatibility with older indexes.\n\nWhat do people thing about the attached patch?  It tries to always return valid transfer syntax, and not to destroy information, at the cost of not always returning a float type. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12732577",
            "date": "2009-07-17T15:30:25+0000",
            "content": "targeting to 1.4 since there is a simple proposed patch.  we can move back out if there is a lack of consensus. "
        },
        {
            "author": "Matt Schraeder",
            "id": "comment-12732582",
            "date": "2009-07-17T15:53:15+0000",
            "content": "Personally I think that's a perfect compromise. As long as the JSON coming back is valid I'm a happy camper and can deal with accidentally indexing invalid data.  The patch looks good to me, with my limited knowledge of Solr's source. "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12732850",
            "date": "2009-07-18T06:02:19+0000",
            "content": "What do people thing about the attached patch? It tries to always return valid transfer syntax, and not to destroy information, at the cost of not always returning a float type.\n\nPatch looks good. "
        },
        {
            "author": "Hoss Man",
            "id": "comment-12734263",
            "date": "2009-07-22T19:19:55+0000",
            "content": "What do people thing about the attached patch?\n\n+0\n\nThis slows down query time response writing for the 95% case:  people who have indexed clean data and don't need it to be sanity checked.  it seems like it violates the whole point of FloatField: be fast and trust the data.\n\nBut if yonik thinks it's worth the trade off - i won't argue. \n\nPersonally: if we're going to make FloatField more paranoid, it seems like validation when input (indexing) would be saner then validating on output since input tends to happen less often then output, and users are typically more concerned about query speed then indexing speed.\n\nAlthough it looks like Yonik already made a similar change to IntField and LongField back in SOLR-424 (how did i miss seeing that before?) so i guess we should at least make all the basic types consistent. (which means we shouldn't forget DoubleField and ByteField)\n\n(In an ideal world, FloatField would have been named \"SimpleUncheckedFloatField\" and the javadocs would have made it clear that it was for backwards compatibility with existing lucene indexes, that it did no sanity checking of the input, and it's only distinction from StrField was to preserve metadata about the datatype (ie: float) for use by the response writers.  Then we could have reserved the name \"FloatField\" for a much more stringent FieldType that sanity checked the data coming in and going out \u2013 which is essentially what SortableFloatField is) "
        },
        {
            "author": "Matt Schraeder",
            "id": "comment-12734267",
            "date": "2009-07-22T19:34:14+0000",
            "content": "Hoss:  You're misunderstanding something.  In the case that the float field is less than 1, for example: \"0.5\", then the JSON encoder spits out \".0\" without the quotes.  This is invalid JSON.  In THIS particular example, the value stored is valid, and the value returned is NOT valid JSON. In order to be valid JSON, a float value of less than 1 needs a preceding 0 before the decimal point or JSON thinks it should be a string and fails reading the value.\n\nYour argument for not making it more paranoid is fine, I have no problems with that, but when given valid data it should ALSO return valid data and in this case it is not.   "
        },
        {
            "author": "Hoss Man",
            "id": "comment-12734335",
            "date": "2009-07-22T21:32:04+0000",
            "content": "Hoss: You're misunderstanding something.\n\ni must be\n\nfor example: \"0.5\", then the JSON encoder spits out \".0\" without the quotes.\n\nI do not see how that is even remotely possible.  I think there must be a typo there in your comment \u2013 if not, please provide a unit test demonstrating what you are seeing.\n\nI'm guessing that what you ment to say, was \"if i index the value of '0.5' then JSON outputs '.5'\" ... which i'm also not seeing when I attempt it myself (tested using the trunk, indexing docs using raw XML).\n\nIf you are seeing this behavior (input: '0.5'; json output: '.5') then I suggest there may be a bug in whatever mechanism you are using to create the index (DataImportHandler, CSVUpdateRequestHandler, some client library, acts_as_solr, etc...)  What does the value look like in the XML response? what does the LukeRequestHandler say your indexed values look like (because they should all be exactly the same) ... if your initial data has '0.5' in it but those three handlers all display '.5' then please let us know how you built your index because it sounds like that has a bug)\n\nThe other possibility is that you might have ment to say \"if i index the value of '.5' then JSON outputs '.5'\" ... which is exactly my point before: garbage in, garbage out.\n\n'.5' is not the canonical representation of any float value \u2013 there may be some parsers that are tolerant of it (Float.valueOf() in java for example) but that doesn't mean it's a legal float value.  parsers can make sense of '0.00006' as well, but that's not the proper string representation, '6.0E-5' is the correct way to represent that float value as a string. "
        },
        {
            "author": "Donovan Jimenez",
            "id": "comment-12734358",
            "date": "2009-07-22T22:18:41+0000",
            "content": "I'm preferential to doing the check at add document time if one is going to be done at all because it fails early for the user. \n\nHowever, I have a counter proposal to changing the FloatField type.\n\nSince FloatField is meant primarily for legacy purposes, why don't we change the distributed example schema.xml to not use it for the \"float\" field type. If we're going for the 80/20 type mantra, then SortableFloatField is probably what most new users of Solr mean when they want to specify a \"float\" field.  \n\nDoes that seem like a workable idea to try and remove the confusion around this issue?\n "
        },
        {
            "author": "Matt Schraeder",
            "id": "comment-12734375",
            "date": "2009-07-22T23:11:03+0000",
            "content": "I just tried to replicate the problem I was having on a super small, fresh, install of solr, and I can't duplicate the problem either.  Which means I have no idea what I was doing to cause that.  There's a chance that since the data that I saw this happening with was coming from a database that there was some sort of float->string or string->float screwup when it was coming out of the database into PHP.  I might try and replicate the problem at work and narrow down what was going on a bit further, but I'll just assume I've been wrong about what was going on this whole time. My apologies to Hoss Man.\n\nSince it seems this is all just invalid in, invalid out and I was mistaken about what was going on, I do think clarification needs to happen somewhere.  As a newer user to Solr, I was confused by two things:\n\n1) The example schema.xml's wording is vague for these fields.  When FloatField says it stores/indexes the \"text value verbatim\" it isn't easily understood that this also means it does not have to be a valid float. I understood this as meaning it's still storing/indexing a valid float, and the only difference between it and a sortable version was that FloatField is sorted as text (1,10,11,2,23,3 rather than 1,2,3,10,11,23) and not numerically.  Instead, this should clarify that it is identical to StrField with the exception in how it is output assuming the data is a valid integer, and warn the user that no verification of the input is done. It also would help if this clarifies that it is meant for legacy support and that most users should be using SortableFloatField.\n\n2) My first index build was done with sfloat.  After the first build was finished, I opened the index in Luke to verify things were being stored and values were being displayed as I expected. When looking at the stored documents in Luke, it was unable to display the sfloat fields, which led me to believe that the sortable float field also wouldn't be readable when I went to display the output from Solr.  This is when I added a copy field so that I would have both a float and an sfloat thinking I had to search/sort on sfloat, but display the float.  This is when I began having problems.  The Sortable fields should clarify that Solr's internal form isn't readable and if lucene apps other than solr try and read those fields it will not be readable, but that Solr's output will be human readable.\n\nI would recommend reordering the fields in the example, so that the first field type a new user comes across is the sortable version.  Comment out the non-sortable versions and say they are for legacy support, and to uncomment if for some reason you need to use them. Also warn about sane inputs/outputs. "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12738650",
            "date": "2009-08-03T22:40:17+0000",
            "content": "What's the status on this?  Is there something to fix or not? "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12738655",
            "date": "2009-08-03T22:44:50+0000",
            "content": "I actually accidentally committed a fix for this along with another commit (but just for float field).\nAll of the plain numeric types should probably get the same treatment.  "
        },
        {
            "author": "Hoss Man",
            "id": "comment-12739116",
            "date": "2009-08-04T19:44:59+0000",
            "content": "revised issue summarydescription to clarify full scope of issue, assigning to yonik "
        },
        {
            "author": "Hoss Man",
            "id": "comment-12739118",
            "date": "2009-08-04T19:54:07+0000",
            "content": "FYI: since 1.3 was released, the usages of FloatField (and it's ilk) in the example schema have already been largely removed.  So i think the big issue here is just making the behavior of the legacy classes consistent, and improving their javadocs.\n\nDonovan/Matt: FloatField (and it's ilk) is still listed in the example schema.xml on the trunk, it's just no longer used in any of the example fields \u2013 so if you think there are improvements to be made to the comments associate with those field types, please give a specific example of how you think it should be documented. "
        },
        {
            "author": "Hoss Man",
            "id": "comment-12739123",
            "date": "2009-08-04T19:57:11+0000",
            "content": "sorry, one last comment i forgot to mention before...\n\nYonik: i assigned to you to make the final call about how to make all the behavior consistent.  (i'm guessing based on the inadvertent commit you made to FloatField that you prefer they all sanity check on output, but i didn't want to make any assumptions).  I'm -0 on any sanity checking, but I do agree they should be consistent. "
        },
        {
            "author": "Donovan Jimenez",
            "id": "comment-12739152",
            "date": "2009-08-04T20:42:24+0000",
            "content": "Yonik has already started standardizing output time checking. So keep going there and we're good.\n\nThe trunk example schema now uses Trie fields for the default numeric types with precisionStep of 0. This should be fine since this seems to be the preferred / suggested field type implementations. The main idea of our argument was that the default make sense for the new user - I believe that change accomplishes this.  So again, we're good.\n\nI also see new comments about which example field types are considered legacy -  good. The Trie field also mentions a little about how it generates tokens which can help when examining the index with tools like luke - a point of confusion that matt mentioned - so again, good.  The sortable numeric definitions might benefit from similar info in the comments. Probably the only thing I could offer as a suggestion.\n\nPersonally, I think you could remove more of the unused configuration from the example, but that's subjective opinion - some people like adding to a minimum, others like to prune from a maximum. I think that solr as a community is of the \"let them prune\" persuasion. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12739156",
            "date": "2009-08-04T20:53:29+0000",
            "content": "I've committed the same changes for all plain numeric types.  Since these are special cases, the small performance impact is not outweighed by the need to produce valid transfer syntax. "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12775803",
            "date": "2009-11-10T15:52:10+0000",
            "content": "Bulk close for Solr 1.4 "
        }
    ]
}