{
    "id": "LUCENE-5145",
    "title": "Added AppendingPackedLongBuffer & extended AbstractAppendingLongBuffer family (customizable compression ratio + bulk retrieval)",
    "details": {
        "components": [],
        "fix_versions": [
            "4.5",
            "6.0"
        ],
        "affect_versions": "None",
        "priority": "Major",
        "labels": "",
        "type": "Improvement",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "Made acceptableOverheadRatio configurable \nAdded bulk get to AbstractAppendingLongBuffer classes, for faster retrieval.\nIntroduced a new variant, AppendingPackedLongBuffer which solely relies on PackedInts as a back-end. This new class is useful where people have non-negative numbers with a fairly uniform distribution over a fixed (limited) range. Ex. facets ordinals.\nTo distinguish it from AppendingPackedLongBuffer, delta based AppendingLongBuffer was renamed to AppendingDeltaPackedLongBuffer\nFixed an Issue with NullReader where it didn't respect it's valueCount in bulk gets.",
    "attachments": {
        "LUCENE-5145.patch": "https://issues.apache.org/jira/secure/attachment/12594678/LUCENE-5145.patch",
        "LUCENE-5145.v2.patch": "https://issues.apache.org/jira/secure/attachment/12594906/LUCENE-5145.v2.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2013-07-29T12:21:44+0000",
            "content": "While making the above changes I did some measurements which I feel is also useful to share.\n\nPackedInts trade CPU for better CPU cache & memory usage. PackedInts gives you an acceptableOverheadRatio parameter to control the trade off but is not exposed in the AbstractAppendingLongBuffer family is based on those. This is especially important when you do no rely on the AbstractAppendingLongBuffer.iterator() to extract your data. Here is some experiments I run on my laptop, using BenchmarkAppendLongBufferRead which is included in the patch. The program allows you to play with different read strategies and data size and measure reading times.\n\nThis is the result of using AppendingDeltaPackedLongBuffer (previously called AppendingLongBuffer) to sequential read an array of 500000 elements, using it's get method. The data was uniformly distributed numbers between 0 & 7. The program measure 10,000 such read. The total time is the time it took to perform all of them. You also see in the output the number of bits used to store the elements and the storage class used.\n\n------- Storage: DELTA_PACKED, Read: SEQUENTIAL, Read size: 1\nSINGLE GET:    3 bits ratio 0.00 (i.e.,    3 bits) total time:  22.18s avg:  2.22ms, total read: 2500000000 elm (class org.apache.lucene.util.packed.Packed64, 223.76kb)\nSINGLE GET:    3 bits ratio 7.00 (i.e.,    8 bits) total time:  19.14s avg:  1.91ms, total read: 2500000000 elm (class org.apache.lucene.util.packed.Direct8, 521.13kb)\n\nAs you can see, when retrieving elements one by one, the byte based implementation slightly faster. For comparison, the new AppendingPackedLongBuffer with the same setup:\n\n------- Storage: PACKED, Read: SEQUENTIAL, Read size: 1\nSINGLE GET:    3 bits ratio 0.00 (i.e.,    3 bits) total time:  16.69s avg:  1.67ms, total read: 2500000000 elm (class org.apache.lucene.util.packed.Packed64, 219.76kb)\nSINGLE GET:    3 bits ratio 7.00 (i.e.,    8 bits) total time:  13.47s avg:  1.35ms, total read: 2500000000 elm (class org.apache.lucene.util.packed.Direct8, 517.13kb)\nNext to the fact that is faster, you see the same behavior. \n\nFor random reads, the classes display similar behavior:\n\n------- Storage: DELTA_PACKED, Read: RANDOM, Read size: 1\nSINGLE GET:    3 bits ratio 0.00 (i.e.,    3 bits) total time:  23.13s avg:  2.31ms, total read: 2500000000 elm (class org.apache.lucene.util.packed.Packed64, 223.76kb)\nSINGLE GET:    3 bits ratio 7.00 (i.e.,    8 bits) total time:  19.38s avg:  1.94ms, total read: 2500000000 elm (class org.apache.lucene.util.packed.Direct8, 521.13kb)\n\n------- Storage: PACKED, Read: RANDOM, Read size: 1\nSINGLE GET:    3 bits ratio 0.00 (i.e.,    3 bits) total time:  19.23s avg:  1.92ms, total read: 2500000000 elm (class org.apache.lucene.util.packed.Packed64, 219.76kb)\nSINGLE GET:    3 bits ratio 7.00 (i.e.,    8 bits) total time:  15.95s avg:  1.60ms, total read: 2500000000 elm (class org.apache.lucene.util.packed.Direct8, 517.13kb)\n\n\nNext I looked at the effect of exposing the bulk reads offered by the PackedInts structures in the AppendingLongBuffer family. Here is some results from the new packed implementation, this time reading 4 & 16 consecutive elements in a single read.\n\n------- Storage: PACKED, Read: SEQUENTIAL, Read size: 4\nSINGLE GET:    3 bits ratio 0.00 (i.e.,    3 bits) total time:  11.16s avg:  1.12ms, total read: 2500000000 elm (class org.apache.lucene.util.packed.Packed64, 219.76kb)\nBULK   GET:    3 bits ratio 0.00 (i.e.,    3 bits) total time:  24.22s avg:  2.42ms, total read: 2500000000 elm (class org.apache.lucene.util.packed.Packed64, 219.76kb)\nSINGLE GET:    3 bits ratio 7.00 (i.e.,    8 bits) total time:   8.35s avg:  0.84ms, total read: 2500000000 elm (class org.apache.lucene.util.packed.Direct8, 517.13kb)\nBULK   GET:    3 bits ratio 7.00 (i.e.,    8 bits) total time:   8.44s avg:  0.84ms, total read: 2500000000 elm (class org.apache.lucene.util.packed.Direct8, 517.13kb)\n\n------- Storage: PACKED, Read: SEQUENTIAL, Read size: 16\nSINGLE GET:    3 bits ratio 0.00 (i.e.,    3 bits) total time:   9.63s avg:  0.96ms, total read: 2500000000 elm (class org.apache.lucene.util.packed.Packed64, 219.76kb)\nBULK   GET:    3 bits ratio 0.00 (i.e.,    3 bits) total time:  12.52s avg:  1.25ms, total read: 2500000000 elm (class org.apache.lucene.util.packed.Packed64, 219.76kb)\nSINGLE GET:    3 bits ratio 7.00 (i.e.,    8 bits) total time:   7.46s avg:  0.75ms, total read: 2500000000 elm (class org.apache.lucene.util.packed.Direct8, 517.13kb)\nBULK   GET:    3 bits ratio 7.00 (i.e.,    8 bits) total time:   3.22s avg:  0.32ms, total read: 2500000000 elm (class org.apache.lucene.util.packed.Direct8, 517.13kb)\n\nAs you can see the bulk read api for the Direct8 class, starts to pay off when reading 4 elements or more. For the Packed64 it still slower when reading 16 elements at a time. On my MacBook Air, it only started paying off at around 32 elements. This may be different on systems with more CPU caches.\n\nThose tests (and many more I played with) are of course very synthetic. I also run the new classes under our implementation of faceted search. The results were similar. ",
            "author": "Boaz Leskes",
            "id": "comment-13722388"
        },
        {
            "date": "2013-07-29T18:20:27+0000",
            "content": "Thanks Boaz, the patch looks very good!\n\n\tI like the fact that the addition of the new bulk API helped make fillValues final!\n\tOrdinalMap.subIndexes, SortedDocValuesWriter.pending and SortedSetDocValuesWriter.pending are 0-based so they could use the new AppendingPackedLongBuffer instead of AppendingDeltaPackedLongBuffer, can you update the patch?\n\n\n ",
            "author": "Adrien Grand",
            "id": "comment-13722770"
        },
        {
            "date": "2013-07-30T08:59:15+0000",
            "content": "Based on Adrien's comments, I changed MultiDocValues.subIndexes, SortedDocValuesWriter.pending , SortedSetDocValuesWriter.pending use new AppendingPackedLongBuffer (see v2 patch) ",
            "author": "Boaz Leskes",
            "id": "comment-13723590"
        },
        {
            "date": "2013-07-30T12:42:40+0000",
            "content": "Commit 1508423 from Adrien Grand in branch 'dev/trunk'\n[ https://svn.apache.org/r1508423 ]\n\nLUCENE-5145: AppendingPackedLongBuffer and added suport for bulk get operations to the Appending*Buffers.\n\nIntroduced bulk retrieval to AbstractAppendingLongBuffer\nclasses, for faster retrieval. Introduced a new variant,\nAppendingPackedLongBuffer which solely relies on PackedInts as a backend.\nThis new class is useful where people have non-negative numbers with a\nuniform distribution over a fixed (limited) range. Ex. facets ordinals. To\ndistinguish it from AppendingPackedLongBuffer, delta based\nAppendingLongBuffer was renamed to AppendingDeltaPackedLongBuffer Fixed an\nIssue with NullReader where it didn't respect it's valueCount in bulk gets. ",
            "author": "ASF subversion and git services",
            "id": "comment-13723804"
        },
        {
            "date": "2013-07-30T12:57:15+0000",
            "content": "Commit 1508430 from Adrien Grand in branch 'dev/branches/branch_4x'\n[ https://svn.apache.org/r1508430 ]\n\nLUCENE-5145: AppendingPackedLongBuffer and added suport for bulk get operations to the Appending*Buffers.\n\nIntroduced bulk retrieval to AbstractAppendingLongBuffer\nclasses, for faster retrieval. Introduced a new variant,\nAppendingPackedLongBuffer which solely relies on PackedInts as a backend.\nThis new class is useful where people have non-negative numbers with a\nuniform distribution over a fixed (limited) range. Ex. facets ordinals. To\ndistinguish it from AppendingPackedLongBuffer, delta based\nAppendingLongBuffer was renamed to AppendingDeltaPackedLongBuffer Fixed an\nIssue with NullReader where it didn't respect it's valueCount in bulk gets. ",
            "author": "ASF subversion and git services",
            "id": "comment-13723818"
        },
        {
            "date": "2013-07-30T12:58:13+0000",
            "content": "Committed. Thanks Boaz! ",
            "author": "Adrien Grand",
            "id": "comment-13723821"
        },
        {
            "date": "2013-10-05T10:18:44+0000",
            "content": "4.5 release -> bulk close ",
            "author": "Adrien Grand",
            "id": "comment-13787014"
        }
    ]
}