{
    "id": "SOLR-9050",
    "title": "IndexFetcher not retrying after SocketTimeoutException correctly, which leads to trying a full download again",
    "details": {
        "components": [
            "replication (java)"
        ],
        "type": "Bug",
        "labels": "",
        "fix_versions": [],
        "affect_versions": "5.3.1",
        "status": "Resolved",
        "resolution": "Cannot Reproduce",
        "priority": "Major"
    },
    "description": "I'm seeing a problem where reading a large file from the leader (in SolrCloud mode) during index replication leads to a SocketTimeoutException:\n\n\n2016-04-28 16:22:23.568 WARN  (RecoveryThread-foo_shard11_replica2) [c:foo s:shard11 r:core_node139 x:foo_shard11_replica2] o.a.s.h.IndexFetcher Error in fetching file: _405k.cfs (downloaded 7314866176 of 9990844536 bytes)\njava.net.SocketTimeoutException: Read timed out\n        at java.net.SocketInputStream.socketRead0(Native Method)\n        at java.net.SocketInputStream.read(SocketInputStream.java:150)\n        at java.net.SocketInputStream.read(SocketInputStream.java:121)\n        at org.apache.http.impl.io.AbstractSessionInputBuffer.fillBuffer(AbstractSessionInputBuffer.java:160)\n        at org.apache.http.impl.io.SocketInputBuffer.fillBuffer(SocketInputBuffer.java:84)\n        at org.apache.http.impl.io.AbstractSessionInputBuffer.readLine(AbstractSessionInputBuffer.java:273)\n        at org.apache.http.impl.io.ChunkedInputStream.getChunkSize(ChunkedInputStream.java:253)\n        at org.apache.http.impl.io.ChunkedInputStream.nextChunk(ChunkedInputStream.java:227)\n        at org.apache.http.impl.io.ChunkedInputStream.read(ChunkedInputStream.java:186)\n        at org.apache.http.conn.EofSensorInputStream.read(EofSensorInputStream.java:137)\n        at org.apache.solr.common.util.FastInputStream.readWrappedStream(FastInputStream.java:80)\n        at org.apache.solr.common.util.FastInputStream.refill(FastInputStream.java:89)\n        at org.apache.solr.common.util.FastInputStream.read(FastInputStream.java:140)\n        at org.apache.solr.common.util.FastInputStream.readFully(FastInputStream.java:167)\n        at org.apache.solr.common.util.FastInputStream.readFully(FastInputStream.java:161)\n        at org.apache.solr.handler.IndexFetcher$FileFetcher.fetchPackets(IndexFetcher.java:1312)\n        at org.apache.solr.handler.IndexFetcher$FileFetcher.fetchFile(IndexFetcher.java:1275)\n        at org.apache.solr.handler.IndexFetcher.downloadIndexFiles(IndexFetcher.java:800)\n\n\n\nand this leads to the following error in cleanup:\n\n\n2016-04-28 16:26:04.332 ERROR (RecoveryThread-foo_shard11_replica2) [c:foo s:shard11 r:core_node139 x:foo_shard11_replica2] o.a.s.h.ReplicationHandler Index fetch failed :org.apache.solr.common.SolrException: Unable to download _405k.cfs completely. Downloaded 7314866176!=9990844536\n        at org.apache.solr.handler.IndexFetcher$FileFetcher.cleanup(IndexFetcher.java:1406)\n        at org.apache.solr.handler.IndexFetcher$FileFetcher.fetchFile(IndexFetcher.java:1286)\n        at org.apache.solr.handler.IndexFetcher.downloadIndexFiles(IndexFetcher.java:800)\n        at org.apache.solr.handler.IndexFetcher.fetchLatestIndex(IndexFetcher.java:423)\n        at org.apache.solr.handler.IndexFetcher.fetchLatestIndex(IndexFetcher.java:254)\n        at org.apache.solr.handler.ReplicationHandler.doFetch(ReplicationHandler.java:380)\n        at org.apache.solr.cloud.RecoveryStrategy.replicate(RecoveryStrategy.java:162)\n        at org.apache.solr.cloud.RecoveryStrategy.doRecovery(RecoveryStrategy.java:437)\n        at org.apache.solr.cloud.RecoveryStrategy.run(RecoveryStrategy.java:227)\n\n2016-04-28 16:26:04.332 ERROR (RecoveryThread-foo_shard11_replica2) [c:foo s:shard11 r:core_node139 x:foo_shard11_replica2] o.a.s.c.RecoveryStrategy Error while trying to recover:org.apache.solr.common.SolrException: Replication for recovery failed.\n        at org.apache.solr.cloud.RecoveryStrategy.replicate(RecoveryStrategy.java:165)\n        at org.apache.solr.cloud.RecoveryStrategy.doRecovery(RecoveryStrategy.java:437)\n        at org.apache.solr.cloud.RecoveryStrategy.run(RecoveryStrategy.java:227)\n\n\n\nSo a simple read timeout exception leads to re-downloading the whole index again, and again, and again ...\n\nIt also looks like any exception raised in fetchPackets would be squelched if an exception is raised in cleanup (called in the finally block)",
    "attachments": {
        "SOLR-9050.patch": "https://issues.apache.org/jira/secure/attachment/12801417/SOLR-9050.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2016-04-29T07:54:34+0000",
            "author": "Timothy Potter",
            "content": "What's not clear to me is how we're getting into the cleanup method? I'm not seeing multiple retries to download the file after the first WARN is logged. There's about 4 minutes between the SocketTimeoutException and the Unable to download ERROR. ",
            "id": "comment-15263708"
        },
        {
            "date": "2016-04-29T07:57:16+0000",
            "author": "Timothy Potter",
            "content": "Start of a patch that does not yet solve anything. It logs the error in the fetchPackets method in case the exception gets squelched by the exception raised in the cleanup method and tries to use the timeouts from solr.xml. I need to come up with a way to reproduce this locally w/o huge indexes to try to see what's really going on. ",
            "id": "comment-15263712"
        },
        {
            "date": "2016-04-29T19:13:27+0000",
            "author": "Timothy Potter",
            "content": "hmmm ... I reproduced the STE locally, but the request gets retried multiple times (as expected) locally, but I didn't see that in my prod env? Or maybe I just got incomplete logs from my ops team  ",
            "id": "comment-15264572"
        },
        {
            "date": "2016-04-29T19:50:31+0000",
            "author": "Timothy Potter",
            "content": "Updated patch (against 5.3.1 branch since that's the one I'm having issues with in prod). I've replicated the SocketTimeoutException locally but the IndexFetcher retries as expected locally, but I'm not seeing that in my prod server logs?\n\nThis patch uses the distribUpdate Timeouts from UpdateShardHandler (config in solr.xml) and adds some better logging so we can get a better picture of what's happening with these re-downloads after a STE. ",
            "id": "comment-15264625"
        }
    ]
}