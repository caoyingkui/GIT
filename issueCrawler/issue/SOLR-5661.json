{
    "id": "SOLR-5661",
    "title": "PriorityQueue has OOM (Requested array size exceeds VM limit) issue",
    "details": {
        "affect_versions": "4.3.1,                                            4.4,                                            4.5,                                            4.5.1,                                            4.6",
        "status": "Resolved",
        "fix_versions": [
            "4.7",
            "6.0"
        ],
        "components": [
            "contrib - Solr Cell (Tika extraction)"
        ],
        "type": "Bug",
        "priority": "Major",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "It look like JDK7 change the design for max_array_length logic, it isn't max_jint, and it should be  max_jint - header_size(type).\n\nIf you deliver the Integer.MaxValue to create the PriorityQueue and have enough memory, you will find it is ok in JVM6 but not work in JVM7.\n\nJVM7 will throw OOM error while do array rang checking.\n\nIt should the compatible issue between JVM6 and JVM7.\n\nMaybe need protect in the code logic, throw OOM look like big issues for customer.",
    "attachments": {
        "patch-5661.txt": "https://issues.apache.org/jira/secure/attachment/12625169/patch-5661.txt"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Michael McCandless",
            "id": "comment-13880869",
            "date": "2014-01-24T10:16:05+0000",
            "content": "Hmm, how were you able to get an OOME from Solr?\n\nLucene's IndexSearcher tries to prevent this, when you ask for Integer.MAX_VALUE as the topN hits to the search method, it drops that to the maxDoc for the reader.\n\nStill, we should fix oal.util.PriorityQueue to use ArrayUtil.MAX_ARRAY_LENGTH, not Integer.MAX_VALUE. "
        },
        {
            "author": "Raintung Li",
            "id": "comment-13881610",
            "date": "2014-01-25T02:23:18+0000",
            "content": "If you have multiple shard for one collection, send the query url for max integer rowid, it can easy replicate.\nCaused by: java.lang.OutOfMemoryError: Requested array size exceeds VM limit\n\tat org.apache.lucene.util.PriorityQueue.<init>(PriorityQueue.java:64)\n\tat org.apache.lucene.util.PriorityQueue.<init>(PriorityQueue.java:37)\n\tat org.apache.solr.handler.component.ShardFieldSortedHitQueue.<init>(ShardDoc.java:113)\n\tat org.apache.solr.handler.component.QueryComponent.mergeIds(QueryComponent.java:790)\n\tat org.apache.solr.handler.component.QueryComponent.handleRegularResponses(QueryComponent.java:649)\n\tat org.apache.solr.handler.component.QueryComponent.handleResponses(QueryComponent.java:628)\n\tat org.apache.solr.handler.component.SearchHandler.handleRequestBody(SearchHandler.java:311)\n\tat org.apache.solr.handler.RequestHandlerBase.handleRequest(RequestHandlerBase.java:135)\n\tat org.apache.solr.core.SolrCore.execute(SolrCore.java:1859)\n\tat org.apache.solr.servlet.SolrDispatchFilter.execute(SolrDispatchFilter.java:710)\n\tat org.apache.solr.servlet.SolrDispatchFilter.doFilter(SolrDispatchFilter.java:413) "
        },
        {
            "author": "Raintung Li",
            "id": "comment-13881615",
            "date": "2014-01-25T02:28:44+0000",
            "content": "add the protection logic. "
        },
        {
            "author": "Michael McCandless",
            "id": "comment-13881975",
            "date": "2014-01-25T18:24:48+0000",
            "content": "I think that's a good low-level fix for Lucene; but I'm not sure how to fix Solr here: somewhere it should limit the size it passes to the PQ constructor? "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-13881993",
            "date": "2014-01-25T19:09:29+0000",
            "content": "Commit 1561369 from Michael McCandless in branch 'dev/trunk'\n[ https://svn.apache.org/r1561369 ]\n\nSOLR-5661: catch too-large priority queue "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-13881994",
            "date": "2014-01-25T19:11:14+0000",
            "content": "Commit 1561370 from Michael McCandless in branch 'dev/branches/branch_4x'\n[ https://svn.apache.org/r1561370 ]\n\nSOLR-5661: catch too-large priority queue "
        },
        {
            "author": "Michael McCandless",
            "id": "comment-13881995",
            "date": "2014-01-25T19:12:05+0000",
            "content": "Thanks Raintung, I committed your patch (tweaked the message) to 4.7 & 5.0, but I'll leave this open for someone else to fix the Solr part ... "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-13882338",
            "date": "2014-01-26T16:25:27+0000",
            "content": "\nIf you have multiple shard for one collection, send the query url for max integer rowid, it can easy replicate.\nCaused by: java.lang.OutOfMemoryError: Requested array size exceeds VM limit\nat org.apache.lucene.util.PriorityQueue.<init>(PriorityQueue.java:64)\nat org.apache.lucene.util.PriorityQueue.<init>(PriorityQueue.java:37)\nat org.apache.solr.handler.component.ShardFieldSortedHitQueue.<init>(ShardDoc.java:113)\nat org.apache.solr.handler.component.QueryComponent.mergeIds(QueryComponent.java:790)\n\nRaintung, please correct me if I am wrong but the max integer value is being used in the constructor only because you have explicitly asked for that many rows? Solr doesn't pass such a big value to the PriorityQueue constructor by itself.\n\nAlso, I think the fix committed to Lucene takes care of the problem on Solr's side as well. Even if we implement a check on Solr's side, the error message can't be any different. "
        },
        {
            "author": "Raintung Li",
            "id": "comment-13882535",
            "date": "2014-01-27T03:00:05+0000",
            "content": "Yes, I ask the many rows that it is max integer. The root node will collect the results from different node(shards) to combin and meger the results. For this case, will directly create the queue .\n\nFix the Lucene side, it is enough.\n\nFor solr issue, should be how to handle the biggest rowid, for biggest rowid should have the different logic. Can't direct create the biggest queue. "
        },
        {
            "author": "Raintung Li",
            "id": "comment-13885114",
            "date": "2014-01-29T07:39:39+0000",
            "content": "I create the other issue SOLR-5674 to distinguish track biggest rows issue. "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-13970943",
            "date": "2014-04-16T12:56:41+0000",
            "content": "Move issue to Solr 4.9. "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-14038855",
            "date": "2014-06-20T14:49:10+0000",
            "content": "This was resolved in 4.7 "
        }
    ]
}