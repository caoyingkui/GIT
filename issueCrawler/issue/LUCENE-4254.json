{
    "id": "LUCENE-4254",
    "title": "ICUCollationKeyAnalyzer fail to tokenize Thai word",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [
            "modules/analysis"
        ],
        "type": "Bug",
        "fix_versions": [],
        "affect_versions": "Realtime Branch",
        "resolution": "Invalid",
        "status": "Resolved"
    },
    "description": "Current implementation is:\nKeywordTokenizer tokenizer = new KeywordTokenizer(factory, reader, KeywordTokenizer.DEFAULT_BUFFER_SIZE);\nreturn new TokenStreamComponents(tokenizer, tokenizer);\n\nI tried change tokenizer from KeywordTokenizer to ICUTokenizer. It return a proper tokenized word.",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "date": "2012-07-25T10:23:22+0000",
            "content": "This is not a bug. ICUCollationKeyAnalyzer is not for tokenization, so it will never split words. Its solely use case is to create exactly one binary, non-human-readable token, to be able to sort search results by this binary value. The binary token will allow sorting by locale-dependent settings (\"collation\"). If it would produce more than one token, it would break sorting.\n\nIn general you use this Tokenizer for a specific field (e.g. with PerFieldAnalyzerWrapper), so you can sort against this field. For all other fields use a different Analyzer. ",
            "author": "Uwe Schindler",
            "id": "comment-13422138"
        },
        {
            "date": "2012-07-25T10:28:28+0000",
            "content": "One note: \"Java 1.7.0-b147\"\n\nDon't use that old Java version, it is broken with Lucene and creates corrupt indexes!!! Upgrade to at least (as absolute minimum) to Java 7u1, see http://blog.thetaphi.de/2011/07/real-story-behind-java-7-ga-bugs.html ",
            "author": "Uwe Schindler",
            "id": "comment-13422142"
        },
        {
            "date": "2012-07-25T10:33:33+0000",
            "content": "Thanks for your promptly reply.\nI have a question.\nIf a field that i required must be both tokenized and using ICUCollationKeyAnalyzer, do i have to use method Field.setTokenStream() only ? ",
            "author": "Nattapong Sirilappanich",
            "id": "comment-13422146"
        },
        {
            "date": "2012-07-25T11:21:44+0000",
            "content": "It is an option to do it (a clever one)! Ignore the analyzer and set the TokenStream directly. No need to use PerFieldAnalyzerWrapper then. I recommend to use ICUCollationKeyAnalyzer.reuseableTokenStream() to get it and set it on the field. ",
            "author": "Uwe Schindler",
            "id": "comment-13422161"
        },
        {
            "date": "2012-07-25T13:52:05+0000",
            "content": "\nIf a field that i required must be both tokenized and using ICUCollationKeyAnalyzer, do i have to use method Field.setTokenStream() only\n\nIf you have a field \"title\" that you want tokenized (for search) but collated (for sort), I think its best\nto create \"title\" and \"title_sort\". \n\nIn general sort really only works if the field has a single value, so you dont want to mix the two. You can\nthen optimize the sort field: disable storing (Field.Store.NO) for \"title_sort\" since its already stored\nin \"title\", and usually also omitNorms(), and set the index options to DOCS_ONLY. ",
            "author": "Robert Muir",
            "id": "comment-13422271"
        },
        {
            "date": "2012-07-26T11:03:17+0000",
            "content": "I'll keep that in mind.\nThank you both. ",
            "author": "Nattapong Sirilappanich",
            "id": "comment-13423010"
        }
    ]
}