{
    "id": "LUCENE-3178",
    "title": "Native MMapDir",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [
            "core/store"
        ],
        "type": "Improvement",
        "fix_versions": [],
        "affect_versions": "None",
        "resolution": "Unresolved",
        "status": "Open"
    },
    "description": "Spinoff from LUCENE-2793.\n\nJust like we will create native Dir impl (UnixDirectory) to pass the right OS level IO flags depending on the IOContext, we could in theory do something similar with MMapDir.\n\nThe problem is MMap is apparently quite hairy... and to pass the flags the native code would need to invoke mmap (I think?), unlike UnixDir where the code \"only\" has to open the file handle.",
    "attachments": {
        "LUCENE-3178.patch": "https://issues.apache.org/jira/secure/attachment/12633730/LUCENE-3178.patch",
        "LUCENE-3178-Native-MMap-implementation.patch": "https://issues.apache.org/jira/secure/attachment/12563702/LUCENE-3178-Native-MMap-implementation.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2011-06-07T14:50:37+0000",
            "content": "can the flags you need all be set with madvise() or are some only available as flags to mmap() ?\n\nIf so, it might not be that bad. ",
            "author": "Robert Muir",
            "id": "comment-13045461"
        },
        {
            "date": "2011-06-07T16:45:36+0000",
            "content": "I think we want to call madvise, and not change the flags passed to the original mmap invocation?  But I'm not sure... ",
            "author": "Michael McCandless",
            "id": "comment-13045526"
        },
        {
            "date": "2011-08-31T18:04:28+0000",
            "content": "Can we use the NativePosixUtil class and call the posix_madvise/madvise methods?\nNMapDir#openInput() and NMapDir#createSlicer takes a IOContext. I'm not quite sure what createSlicer does though? ",
            "author": "Varun Thacker",
            "id": "comment-13094733"
        },
        {
            "date": "2011-08-31T18:10:17+0000",
            "content": "It might even be worth doing the mmap from NativePosixUtil, dealing with all the round-to-pagesize etc that you need, and accessing it with sun.misc.Unsafe.\n\nI did a little prototype a while back that stole the address from MappedByteBuffer and used Unsafe for all ops with no bounds checks, and the performance improvements were pretty interesting  But the problem with that approach is you still can't FileChannel.map a file > Integer.MAX_VALUE, meaning we have to handle all the stupidity of multiple mappings, but I think with a native mmap call you could just map the whole thing and avoid this hassle... ",
            "author": "Robert Muir",
            "id": "comment-13094740"
        },
        {
            "date": "2011-08-31T18:27:05+0000",
            "content": "Here are the old benchmarks from such a technique, with no bounds checks (only asserts) and unsafe, versus using a mappedbytebuffer\n\n\n\nTask\nQPS base\nStdDev base\nQPS unsafemmap\nStdDev unsafemmap\nPct diff\n\n\nFuzzy2\n21.83\n0.58\n21.94\n1.32\n-7% - 9%\n\n\nRespell\n25.68\n0.13\n26.01\n0.91\n-2% - 5%\n\n\nFuzzy1\n27.70\n0.78\n28.39\n1.48\n-5% - 10%\n\n\nTermGroup1M\n35.96\n1.38\n38.92\n0.53\n2% - 14%\n\n\nPKLookup\n41.56\n1.05\n46.04\n1.82\n3% - 18%\n\n\nSloppyPhrase\n7.06\n0.26\n7.93\n0.43\n2% - 22%\n\n\nTermBGroup1M\n29.09\n1.57\n32.70\n0.70\n4% - 21%\n\n\nTermBGroup1M1P\n32.13\n1.94\n36.86\n0.44\n6% - 23%\n\n\nSpanNear\n6.71\n0.12\n7.89\n0.13\n13% - 21%\n\n\nWildcard\n37.62\n3.83\n44.39\n1.41\n3% - 35%\n\n\nAndHighHigh\n14.53\n0.50\n17.56\n1.12\n9% - 33%\n\n\nPhrase\n12.20\n0.63\n14.82\n0.35\n12% - 31%\n\n\nOrHighHigh\n11.77\n0.79\n14.31\n0.26\n11% - 32%\n\n\nOrHighMed\n11.49\n0.75\n14.02\n0.26\n12% - 32%\n\n\nPrefix3\n32.70\n4.10\n40.06\n1.77\n4% - 46%\n\n\nTerm\n92.02\n6.37\n114.13\n1.68\n14% - 35%\n\n\nAndHighMed\n55.38\n1.60\n69.02\n5.48\n11% - 38%\n\n\nIntNRQ\n7.17\n1.19\n8.96\n0.63\n0% - 60%\n\n\n\n ",
            "author": "Robert Muir",
            "id": "comment-13094754"
        },
        {
            "date": "2011-09-01T15:15:35+0000",
            "content": "If we pass down IOContext to NMapIndexInput and in the ctor use mmap and then use madvise with the appropriate flag ( depending on the Context). Is that the correct way to go about it ?\n\nAlso slightly off topic but the the javadocs for NMapoDir#openInput still shows bufferSize as a parameter. In the java file nothing is specified as the @param values. Where is it coming from? It's probably my mistake from LUCENE-2793 but I would like to correct it here.  ",
            "author": "Varun Thacker",
            "id": "comment-13095341"
        },
        {
            "date": "2011-09-01T15:26:33+0000",
            "content": "Also slightly off topic but the the javadocs for NMapoDir#openInput still shows bufferSize as a parameter. In the java file nothing is specified as the @param values. Where is it coming from? It's probably my mistake from LUCENE-2793 but I would like to correct it here.\n\nI don't see the @param, which file r u referring to?\n ",
            "author": "Simon Willnauer",
            "id": "comment-13095349"
        },
        {
            "date": "2011-09-01T15:41:00+0000",
            "content": "Just realized what was wrong. I was using the javadocs from version 3.3 on not from the trunk. Stupid mistake on my part. Sorry to bring that up. ",
            "author": "Varun Thacker",
            "id": "comment-13095356"
        },
        {
            "date": "2011-09-05T15:33:40+0000",
            "content": "If we pass down IOContext to NMapIndexInput and in the ctor use mmap and then use madvise with the appropriate flag ( depending on the Context). Is that the correct way to go about it ?\n\nAny suggestions on this? ",
            "author": "Varun Thacker",
            "id": "comment-13097182"
        },
        {
            "date": "2012-12-11T05:27:00+0000",
            "content": "Tangentially I have been futzing a little with this based on some observations I noticed around madvise http://people.apache.org/~gbowyer/madvise-perf/index.html ",
            "author": "Greg Bowyer",
            "id": "comment-13528681"
        },
        {
            "date": "2012-12-11T05:39:07+0000",
            "content": "Robert, do you still have you \"old approach\" code kicking about anywhere ",
            "author": "Greg Bowyer",
            "id": "comment-13528687"
        },
        {
            "date": "2012-12-11T07:02:42+0000",
            "content": "No unfortunately I don't... but its not too complicated. \n\nMight be interesting to revisit now that we use block compression that doesn't readByte(), readByte(), readByte() and hopefully avoids some of the bounds checks and so on that I think it helped with. ",
            "author": "Robert Muir",
            "id": "comment-13528743"
        },
        {
            "date": "2013-01-08T01:34:44+0000",
            "content": "Rough cut of a native mmap (does not do any madvise, probably insanely buggy etc etc) ",
            "author": "Greg Bowyer",
            "id": "comment-13546493"
        },
        {
            "date": "2013-01-08T05:26:32+0000",
            "content": "Temp skip unit test until fixed ",
            "author": "Greg Bowyer",
            "id": "comment-13546617"
        },
        {
            "date": "2013-01-09T12:49:01+0000",
            "content": "I haven't looked closely at the patch, but I ran an initial perf test:\n\n                    Task    QPS base      StdDev    QPS comp      StdDev                Pct diff\n              AndHighLow     1024.41      (3.1%)      856.52      (2.0%)  -16.4% ( -20% -  -11%)\n               LowPhrase       69.04      (1.7%)       58.90      (0.9%)  -14.7% ( -16% -  -12%)\n              AndHighMed      193.16      (1.0%)      169.24      (1.4%)  -12.4% ( -14% -  -10%)\n                 Respell       55.65      (3.0%)       50.01      (3.3%)  -10.1% ( -15% -   -3%)\n                  Fuzzy2       67.18      (3.3%)       60.52      (3.6%)   -9.9% ( -16% -   -3%)\n                  Fuzzy1       68.83      (3.4%)       62.65      (3.4%)   -9.0% ( -15% -   -2%)\n         LowSloppyPhrase       85.35      (1.8%)       78.64      (1.6%)   -7.9% ( -11% -   -4%)\n             LowSpanNear       38.05      (2.9%)       35.14      (3.1%)   -7.6% ( -13% -   -1%)\n                Wildcard       99.78      (3.0%)       93.39      (2.9%)   -6.4% ( -12% -    0%)\n             MedSpanNear       77.91      (2.2%)       74.26      (2.3%)   -4.7% (  -9% -    0%)\n            HighSpanNear        9.24      (2.7%)        8.86      (2.5%)   -4.1% (  -9% -    1%)\n        HighSloppyPhrase        2.25      (4.0%)        2.16      (3.8%)   -4.0% ( -11% -    3%)\n         MedSloppyPhrase       78.44      (2.2%)       75.35      (2.4%)   -3.9% (  -8% -    0%)\n              HighPhrase       30.39      (8.1%)       29.27      (7.9%)   -3.7% ( -18% -   13%)\n                 LowTerm      808.93      (5.0%)      779.29      (5.4%)   -3.7% ( -13% -    7%)\n               MedPhrase      176.20      (5.9%)      169.98      (5.5%)   -3.5% ( -14% -    8%)\n                 Prefix3       51.16      (6.0%)       49.53      (4.9%)   -3.2% ( -13% -    8%)\n             AndHighHigh       69.32      (2.3%)       67.21      (2.4%)   -3.0% (  -7% -    1%)\n                  IntNRQ       10.99     (10.0%)       10.86      (9.0%)   -1.2% ( -18% -   19%)\n                 MedTerm      329.36     (10.0%)      325.83     (11.9%)   -1.1% ( -20% -   23%)\n               OrHighMed       67.18      (2.2%)       66.64      (4.5%)   -0.8% (  -7% -    6%)\n              OrHighHigh       42.91      (2.5%)       42.59      (4.8%)   -0.7% (  -7% -    6%)\n               OrHighLow       62.96      (2.3%)       62.58      (4.9%)   -0.6% (  -7% -    6%)\n                HighTerm      120.76     (11.6%)      121.21     (14.9%)    0.4% ( -23% -   30%)\n\n\n\nThis is a \"hot\" test, with 10M no-stopwords English Wikipedia.  Baseline is normal MMapDir and comp is NativePosixMMapDirectory.  Not sure why some queries are slower ... ",
            "author": "Michael McCandless",
            "id": "comment-13548466"
        },
        {
            "date": "2013-01-09T19:39:04+0000",
            "content": "Frustrating, it echos what I have been seeing so at least my benchmarking is not playing me up, I guess I will have to do some digging. ",
            "author": "Greg Bowyer",
            "id": "comment-13548885"
        },
        {
            "date": "2013-01-10T12:28:17+0000",
            "content": "I think this is largely related to Robert's comment:\nMight be interesting to revisit now that we use block compression that doesn't readByte(), readByte(), readByte() and hopefully avoids some of the bounds checks and so on that I think it helped with.\n\nSince we moved to block codecs, the use of single-byte get's on the byte buffer is largely reduced. It now just reads blocks of data, so MappedByteBuffer can do that efficently using a memcpy(). Some MTQs are still faster because they read much more blocks for a large number of terms. I would have expected no significant speed up at all for, e.g., NRQ.\n\nAdditionally, when using the ByteBuffer methods to get bytes, I think newer java versions use intrinsics, that may no longer be used with your directory impl.\n\nI would not provide a custom MMapDir at all, it is too risky and does not really brings a large speed up anymore (Java 7 + block postings). ",
            "author": "Uwe Schindler",
            "id": "comment-13549567"
        },
        {
            "date": "2013-01-10T21:25:03+0000",
            "content": "\nI think this is largely related to Robert's comment:\nMight be interesting to revisit now that we use block compression that doesn't readByte(), readByte(), readByte() and hopefully avoids some of the bounds checks and so on that I think it helped with.\n\nActually there still is quite a lot of that, I wrote locally a Directory implementation that dumps out all of the called operations, I can share the file if wanted (although its huge)\n\n\nSince we moved to block codecs, the use of single-byte get's on the byte buffer is largely reduced. It now just reads blocks of data, so MappedByteBuffer can do that efficently using a memcpy(). Some MTQs are still faster because they read much more blocks for a large number of terms. I would have expected no significant speed up at all for, e.g., NRQ.\n\nBetter the JVM doesnt do memcpy in all cases but often does cpu aware operations that are faster.\n\n\nAdditionally, when using the ByteBuffer methods to get bytes, I think newer java versions use intrinsics, that may no longer be used with your directory impl.\n\nThis is what I am leaning towards, so far the only speedups I have seen are when I apt most of the behaviors of the JVM, the biggest win really is that the code becomes a lot simpler (partly because we don't have to worry about the \"cleaner\", and partly because we are not bound to int32 sizes so no more slice nonsense); despite the simpler code I don't think there is a sizable win in performance to warrant this approach.\n\nI am still poking at this for a bit longer, but I am leaning towards calling this bust.\n\nThe other reason for this was to see if I get better behavior along the MADV_WILLNEED / page alignment fronts; but again I have nothing scientifically provable there.\n\n(This is all assuming that I don't have some gross oversight in my implementation that makes it stupid slow by accident)\n\n\nI would not provide a custom MMapDir at all, it is too risky and does not really brings a large speed up anymore (Java 7 + block postings).\nI quite agree, even if this gave huge performance wins I would still put it in the bucket of \"its in misc, its not default and your on your own if it breaks\". The fact it yields AFAICT no performance gains is both maddening for me and even more damning .  ",
            "author": "Greg Bowyer",
            "id": "comment-13550436"
        },
        {
            "date": "2013-01-29T00:15:36+0000",
            "content": "So I was going to shut this down today, and just to make sure I ran the benchmark on the simplest code possible\n\n... and suddenly I got good results, this is idiopathic :S\n\n\nReport after iter 19:\n                    TaskQPS baseline      StdDevQPS mmap_tests      StdDev                Pct diff\n              OrHighHigh        1.68     (11.2%)        1.73     (10.3%)    3.0% ( -16% -   27%)\n                PKLookup      129.89      (5.8%)      135.03      (6.0%)    4.0% (  -7% -   16%)\n                HighTerm        8.09     (13.6%)        8.43     (12.8%)    4.2% ( -19% -   35%)\n               OrHighMed        4.46     (10.4%)        4.67      (9.5%)    4.7% ( -13% -   27%)\n               OrHighLow        4.82     (10.6%)        5.09     (10.3%)    5.6% ( -13% -   29%)\n            HighSpanNear        0.92      (8.1%)        0.97      (7.3%)    5.9% (  -8% -   23%)\n                  IntNRQ        2.51     (10.2%)        2.67      (9.9%)    6.6% ( -12% -   29%)\n              HighPhrase        0.30     (11.7%)        0.32     (12.8%)    6.7% ( -16% -   35%)\n               MedPhrase        2.93      (6.8%)        3.12      (8.2%)    6.7% (  -7% -   23%)\n             AndHighHigh        5.46      (6.6%)        5.86      (7.0%)    7.2% (  -5% -   22%)\n                 Respell       19.68      (5.9%)       21.15      (6.6%)    7.5% (  -4% -   21%)\n               LowPhrase        0.46      (9.5%)        0.50     (10.2%)    7.6% ( -11% -   30%)\n                 Prefix3        5.25      (8.2%)        5.66      (7.7%)    7.9% (  -7% -   25%)\n        HighSloppyPhrase        1.54      (8.0%)        1.67     (13.1%)    8.5% ( -11% -   32%)\n             MedSpanNear        5.25      (7.0%)        5.72      (8.2%)    9.0% (  -5% -   25%)\n                Wildcard       12.44      (5.7%)       13.59      (6.5%)    9.2% (  -2% -   22%)\n         MedSloppyPhrase        2.27      (7.2%)        2.49      (8.5%)    9.5% (  -5% -   27%)\n                 MedTerm       28.16     (10.3%)       30.89      (9.9%)    9.7% (  -9% -   33%)\n                  Fuzzy1       18.91      (6.0%)       20.82      (6.7%)   10.1% (  -2% -   24%)\n                  Fuzzy2       19.69      (6.6%)       21.68      (7.5%)   10.1% (  -3% -   25%)\n              AndHighMed        7.79      (7.5%)        8.58      (6.1%)   10.1% (  -3% -   25%)\n             LowSpanNear        1.45      (5.7%)        1.60      (9.3%)   10.5% (  -4% -   27%)\n         LowSloppyPhrase       22.84      (7.7%)       25.45      (9.7%)   11.4% (  -5% -   31%)\n                 LowTerm       46.46      (6.8%)       52.90      (7.6%)   13.9% (   0% -   30%)\n              AndHighLow       35.92      (5.3%)       42.38      (7.1%)   18.0% (   5% -   32%)\n\n ",
            "author": "Greg Bowyer",
            "id": "comment-13564880"
        },
        {
            "date": "2014-03-07T10:42:37+0000",
            "content": "... and suddenly I got good results, this is idiopathic :S\n\nLovely \n\nIt is odd, because we do relatively \"few\" IO ops, since we read a big byte[] blob, and then do all decode from that (128 packed ints) in RAM.\n\nIt do think it'd be interesting to pair up a NativeMMapDir with a custom postings format that instead uses IndexInput.readLong (via Unsafe.getLong) to pull longs from disk; this should save some cost we now have in packed ints to reconstitute longs from byte[] in Java.  But, we'd need to fix the byte order in the index to match the CPU used at search time.  Or, maybe we could use a DirectByteBuffer and set the byte order (but this may mean byte swapping for every access, which maybe is not so bad). ",
            "author": "Michael McCandless",
            "id": "comment-13923769"
        },
        {
            "date": "2014-03-10T16:51:11+0000",
            "content": "It do think it'd be interesting to pair up a NativeMMapDir with a custom postings format that instead uses IndexInput.readLong (via Unsafe.getLong) to pull longs from disk\n\nI was curious about this so I coded up a prototype patch.  It's a\nNativeMMapDirectory.java/cpp that does the mmap/munmap in C, and then\na new postings format (NativeMMapPostingsFormat) which requires this\nDirectory impl and then uses Unsafe.getLong to read the longs for\npacked int decode.\n\nThis bypasses the extra step we do today of first reading into a\nbyte[], and then decoding from that, and instead pulls long directly\nfrom the map and decodes from that.  It requires that the byte-order\nin the index matches the CPU; e.g. for x86 (little-endian) it's\nopposite from the big-endian order that DataInput.write/readLong\nexpect.\n\nIt does not align the long reads; doing so would increase the index\nsize somewhat because we'd need to insert pad bytes to align the long\nreads to every 8 bytes.  But I think on recent x86 CPUs unaligned\nreads are not adding much of a penalty...\n\nThe patch is very unsafe / tons of nocommits, but seems to work\ncorrectly.  Here's the results:\n\n\n                    Task    QPS base      StdDev    QPS comp      StdDev                Pct diff\n                  Fuzzy2       47.61      (3.1%)       46.98      (2.9%)   -1.3% (  -7% -    4%)\n            HighSpanNear        8.34      (5.8%)        8.42      (5.9%)    0.9% ( -10% -   13%)\n                 Respell       48.79      (4.1%)       50.00      (3.3%)    2.5% (  -4% -   10%)\n                  IntNRQ        3.68      (1.5%)        3.78      (7.8%)    2.7% (  -6% -   12%)\n            OrHighNotMed       37.79      (3.8%)       38.90      (2.8%)    3.0% (  -3% -    9%)\n            OrHighNotLow       31.19      (4.2%)       32.13      (3.3%)    3.0% (  -4% -   10%)\n                 Prefix3       91.92      (1.9%)       95.11      (6.2%)    3.5% (  -4% -   11%)\n               OrHighMed       32.99      (4.0%)       34.15      (3.1%)    3.5% (  -3% -   11%)\n                  Fuzzy1       60.40      (3.3%)       62.56      (3.4%)    3.6% (  -3% -   10%)\n           OrNotHighHigh       11.17      (3.9%)       11.57      (2.7%)    3.6% (  -2% -   10%)\n                HighTerm       69.60     (11.2%)       72.19     (15.5%)    3.7% ( -20% -   34%)\n               LowPhrase       13.17      (2.1%)       13.67      (2.7%)    3.8% (   0% -    8%)\n              AndHighMed       34.52      (1.0%)       35.85      (1.5%)    3.8% (   1% -    6%)\n            OrNotHighLow       25.04      (3.5%)       26.00      (0.4%)    3.8% (   0% -    8%)\n               OrHighLow       23.60      (4.2%)       24.50      (3.3%)    3.8% (  -3% -   11%)\n                Wildcard       19.93      (2.8%)       20.73      (5.0%)    4.0% (  -3% -   12%)\n         MedSloppyPhrase        3.52      (3.8%)        3.67      (4.5%)    4.2% (  -3% -   12%)\n           OrHighNotHigh       13.88      (3.7%)       14.46      (2.5%)    4.2% (  -1% -   10%)\n              OrHighHigh       10.23      (3.9%)       10.68      (3.1%)    4.4% (  -2% -   11%)\n                 LowTerm      330.50      (6.7%)      345.35      (8.9%)    4.5% ( -10% -   21%)\n             AndHighHigh       28.53      (1.1%)       29.82      (1.4%)    4.5% (   2% -    7%)\n            OrNotHighMed       24.13      (3.4%)       25.23      (0.5%)    4.6% (   0% -    8%)\n             LowSpanNear       10.55      (2.7%)       11.06      (3.6%)    4.8% (  -1% -   11%)\n              HighPhrase        4.30      (6.7%)        4.55      (6.2%)    5.9% (  -6% -   20%)\n                 MedTerm      106.81      (9.0%)      113.26     (12.9%)    6.0% ( -14% -   30%)\n        HighSloppyPhrase        3.41      (4.2%)        3.67      (7.2%)    7.7% (  -3% -   19%)\n             MedSpanNear       31.66      (3.0%)       34.15      (3.8%)    7.9% (   0% -   15%)\n               MedPhrase      212.86      (6.1%)      233.14      (6.1%)    9.5% (  -2% -   23%)\n         LowSloppyPhrase       44.91      (2.4%)       49.77      (2.3%)   10.8% (   6% -   15%)\n              AndHighLow      404.75      (2.5%)      506.81      (3.6%)   25.2% (  18% -   32%)\n\n\n\nNet net, a very minor improvement!  I think this is good news: it\nmeans that the extra abstractions here, which are useful so we can be\nsafe (not use Unsafe) and agnostic to byte-order are not costing us\ntoo much. ",
            "author": "Michael McCandless",
            "id": "comment-13925888"
        },
        {
            "date": "2014-03-24T23:44:38+0000",
            "content": "Interesting, its also somewhat interesting to see that AndHighLow gets a big jump in performance, any ideas on why that might be ",
            "author": "Greg Bowyer",
            "id": "comment-13945878"
        },
        {
            "date": "2014-03-25T16:12:55+0000",
            "content": "Not sure about AndHighLow; I guess this query is \"wasteful\" since it goes and decodes a block and typically has 0 or 1 actual matches in that block, so maybe it amplifies the low-level gains since the query itself is so cheap?\n\nBut then, making super fast queries 25% faster does not matter in practice; it's the super-slow queries that matter. ",
            "author": "Michael McCandless",
            "id": "comment-13946732"
        },
        {
            "date": "2014-03-25T23:41:13+0000",
            "content": "Shall we call these experiments done, I think it concludes that where we do get wins they are minor and the baggage that comes with is a bit too much ",
            "author": "Greg Bowyer",
            "id": "comment-13947339"
        }
    ]
}