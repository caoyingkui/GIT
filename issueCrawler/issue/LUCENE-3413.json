{
    "id": "LUCENE-3413",
    "title": "CombiningFilter to recombine tokens into a single token for sorting",
    "details": {
        "labels": "",
        "priority": "Minor",
        "components": [
            "modules/analysis"
        ],
        "type": "New Feature",
        "fix_versions": [],
        "affect_versions": "2.9.3",
        "resolution": "Unresolved",
        "status": "Open"
    },
    "description": "I whipped up this CombiningFilter for the following use case:\n\nI've got a bunch of titles of e.g., Books, such as:\n\nThe Grapes of Wrath\nTommy Tommerson saves the World\nTop of the World\nThe Tales of Beedle the Bard\nBorn Free\n\netc.\n\nI want to sort these titles using a String field that includes stopword analysis (e.g., to remove \"The\"), and synonym filtering (e.g., for grouping), etc. I created an analysis chain in Solr for this that was based off of alphaOnlySort, which looks like this:\n\n\n<fieldType name=\"alphaOnlySort\" class=\"solr.TextField\" sortMissingLast=\"true\" omitNorms=\"true\">\n   <analyzer>\n        <!-- KeywordTokenizer does no actual tokenizing, so the entire\n             input string is preserved as a single token\n          -->\n        <tokenizer class=\"solr.KeywordTokenizerFactory\"/>\n        <!-- The LowerCase TokenFilter does what you expect, which can be\n             when you want your sorting to be case insensitive\n          -->\n        <filter class=\"solr.LowerCaseFilterFactory\" />\n        <!-- The TrimFilter removes any leading or trailing whitespace -->\n        <filter class=\"solr.TrimFilterFactory\" />\n        <!-- The PatternReplaceFilter gives you the flexibility to use\n             Java Regular expression to replace any sequence of characters\n             matching a pattern with an arbitrary replacement string, \n             which may include back references to portions of the original\n             string matched by the pattern.\n             \n             See the Java Regular Expression documentation for more\n             information on pattern and replacement string syntax.\n             \n             http://java.sun.com/j2se/1.5.0/docs/api/java/util/regex/package-summary.html\n          -->\n        <filter class=\"solr.PatternReplaceFilterFactory\"\n                pattern=\"([^a-z])\" replacement=\"\" replace=\"all\"\n        /> \n    </analyzer>       \n    </fieldType>\n\n\n\n\nThe issue with alphaOnlySort is that it doesn't support stopword remove or synonyms because those are based on the original token level instead of the full strings produced by the KeywordTokenizer (which does not do tokenization). I needed a filter that would allow me to change alphaOnlySort and its analysis chain from using KeywordTokenizer to using WhitespaceTokenizer, and then a way to recombine the tokens at the end. So, take \"The Grapes of Wrath\". I needed a way for it to get turned into:\n\n\ngrapes of wrath\n\n\n\nAnd then to combine those tokens into a single token:\n\n\ngrapesofwrath\n\n\n\nThe attached CombiningFilter takes care of that. It doesn't do it super efficiently I'm guessing (since I used a StringBuffer), but I'm open to suggestions on how to make it better. \n\nOne other thing is that apparently this analyzer works fine for analysis (e.g., it produces the desired tokens), however, for sorting in Solr I'm getting null sort tokens. Need to figure out why. \n\nHere ya go!",
    "attachments": {
        "LUCENE-3413.Mattmann.090311.patch.txt": "https://issues.apache.org/jira/secure/attachment/12492923/LUCENE-3413.Mattmann.090311.patch.txt",
        "LUCENE-3413.Mattmann.090511.patch.txt": "https://issues.apache.org/jira/secure/attachment/12493111/LUCENE-3413.Mattmann.090511.patch.txt"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2011-09-03T21:49:27+0000",
            "content": "The problem with this implementation of the filter is the fact, that it consumes the underlying TokenStream in the constructor, concats everything and then wraps a KeywordTokenizer.\n\nThe problem is that the TokenFilters are not full initialized in the constructor.\n\nThe filter should do the mergin direct inside incrementToken():\n\n\ton the first call to incrementToken, it should do a while(input.incrementToken()) loop and collect all tokens into a buffer and at then end copy the buffer into the term attribute\n\ton second call return false\n\n ",
            "author": "Uwe Schindler",
            "id": "comment-13096765"
        },
        {
            "date": "2011-09-04T01:03:32+0000",
            "content": "\n\tupdated patch per Uwe's comments, and unit tests. Passes unit tests, but still fails in Solr ville to generate non-null sort strings.\n\n ",
            "author": "Chris A. Mattmann",
            "id": "comment-13096781"
        },
        {
            "date": "2011-09-04T01:05:11+0000",
            "content": "Hey Uwe, thanks for the advice. I went ahead and updated the code (and attached a unit test). This patch, like my last one, passes the attached unit test. However, in Solr-land, when defining a customization of alphaOnlySort that uses the WhitespaceTokenizer (instead of the KeywordTokenizer), and then uses the CombiningFilter to merge the tokens at the end, analysis in solr's analysis.jsp looks fine, but I get null sort tokens (when I set fsv=true). \n\nSo, long story short, after I made the updates you suggested, I still get null sort keys. Any ideas? ",
            "author": "Chris A. Mattmann",
            "id": "comment-13096782"
        },
        {
            "date": "2011-09-04T01:24:14+0000",
            "content": "For reference, here is the fieldType definition from Solr-ville that I am using:\n\n\n    <fieldType name=\"alphaOnlySort\" class=\"solr.TextField\" sortMissingLast=\"true\" omitNorms=\"true\">\n      <analyzer>\n        <tokenizer class=\"solr.WhitespaceTokenizerFactory\"/>        \n        <!-- The LowerCase TokenFilter does what you expect, which can be\n             when you want your sorting to be case insensitive\n          -->\n        <filter class=\"solr.LowerCaseFilterFactory\" />\n        <!-- The TrimFilter removes any leading or trailing whitespace -->\n        <filter class=\"solr.TrimFilterFactory\" />\n        <filter class=\"solr.StopFilterFactory\" words=\"stopwords.txt\" ignoreCase=\"true\"/>\n        <!-- The PatternReplaceFilter gives you the flexibility to use\n             Java Regular expression to replace any sequence of characters\n             matching a pattern with an arbitrary replacement string, \n             which may include back references to portions of the original\n             string matched by the pattern.\n             \n             See the Java Regular Expression documentation for more\n             information on pattern and replacement string syntax.\n             \n             http://java.sun.com/j2se/1.5.0/docs/api/java/util/regex/package-summary.html\n          -->          \n        <filter class=\"solr.PatternReplaceFilterFactory\"\n                pattern=\"([^a-z])\" replacement=\"\" replace=\"all\"\n        />\n        \n        <filter class=\"org.apache.solr.analysis.CombiningFilterFactory\"/>\n      </analyzer>\n    </fieldType>\n\n ",
            "author": "Chris A. Mattmann",
            "id": "comment-13096785"
        },
        {
            "date": "2011-09-04T05:59:56+0000",
            "content": "Hmmm, maybe #reset is getting called somewhere. I wrote another unit test to call reset and then test calling incrementToken again. As it turns out, it fails, because calling input.reset in CombiningFilter calls e.g., LowerCaseFilter.reset, which in turn calls KeywordTokenizer.reset. The call to KeywordTokenizer.reset does nothing, and it just uses the stub method in TokenStream, even though KeywordTokenizer has a method #reset that takes a Reader input. \n\nI wonder if the lack of having a working reset method is messing stuff up. What tells me that's probably wrong though is that LowerCaseFilter just uses the default parent class #reset (which just calls its input.reset), so I don't think that's an issue. Sigh. ",
            "author": "Chris A. Mattmann",
            "id": "comment-13096819"
        },
        {
            "date": "2011-09-04T06:09:36+0000",
            "content": "ooops I meant WhitespaceTokenizer.reset, not KeywordTokenizer.reset. Sorry. ",
            "author": "Chris A. Mattmann",
            "id": "comment-13096822"
        },
        {
            "date": "2011-09-04T06:20:53+0000",
            "content": "From a quick look at this:\n\n\n\tWhat version of Solr is this against?\n\tI believe your problem is that CombiningFilter is not resetting its firstCall variable.  Therefore when the TokenFilter is reused, firstCall is always false and therefore incrementToken returns false (so nothing is ever emitted)\n\n\n\nAdd:\n\n\n@Override\npublic void reset() {\n  super.reset();\n  this.firstCall = true;\n}\n\n ",
            "author": "Chris Male",
            "id": "comment-13096823"
        },
        {
            "date": "2011-09-04T06:38:01+0000",
            "content": "why do you use the firstCall member at all? I mean you can just do:\n\n\nfinal StringBuilder builder = new StringBuilder();\nboolean returnVal = false;\nwhile(input.incrementToken()) {\n  returnVal = true;\n  builder.append(ta.term());\n}\nta.setTermBuffer(buf.toString());\nreturn returnVal;\n\n\n\nand you don't need a reset call. \n\nStringBuffer btw. is almost never a good choice. Rather use StringBuilder\n\n ",
            "author": "Simon Willnauer",
            "id": "comment-13096826"
        },
        {
            "date": "2011-09-04T06:56:51+0000",
            "content": "Thanks guys! Your updates fixed it! It's not sorting correctly!\n\nI'll prepare two patches. One for Lucene that implements your suggestions. And another for Solr (containing the super trivial factory to instantiate this).\n\nThanks, again! ",
            "author": "Chris A. Mattmann",
            "id": "comment-13096829"
        },
        {
            "date": "2011-09-04T06:57:14+0000",
            "content": "errr, I meant now instead of not. IOW, It's now sorting correctly. Thanks guys! ",
            "author": "Chris A. Mattmann",
            "id": "comment-13096830"
        },
        {
            "date": "2011-09-04T06:58:47+0000",
            "content": "I'll prepare two patches. One for Lucene that implements your suggestions. And another for Solr (containing the super trivial factory to instantiate this).\nyou can do it in one patch  ",
            "author": "Simon Willnauer",
            "id": "comment-13096831"
        },
        {
            "date": "2011-09-06T04:22:10+0000",
            "content": "\n\tupdated patch addressing comments from Simon. Chris Male suggested renaming it, but I couldn't come up with a better name. Maybe we could call it CombiningTokenFilter, or something for specificity, but I'll leave that part up to you guys.\n\n ",
            "author": "Chris A. Mattmann",
            "id": "comment-13097733"
        },
        {
            "date": "2011-09-06T04:23:45+0000",
            "content": "\n\tupdated patch fix package names. This patch applies against the latest trunk.\n\n ",
            "author": "Chris A. Mattmann",
            "id": "comment-13097734"
        },
        {
            "date": "2011-09-06T04:31:27+0000",
            "content": "\n\tfinal updated patch\n\n ",
            "author": "Chris A. Mattmann",
            "id": "comment-13097735"
        },
        {
            "date": "2011-09-06T04:35:01+0000",
            "content": "BTW, I couldn't get it to work by removing the firstCall variable using Simon's suggestion, so I left it in there. If you guys want to figure it out, go for it, but the patch I attached right now is working...thanks! ",
            "author": "Chris A. Mattmann",
            "id": "comment-13097737"
        },
        {
            "date": "2012-12-27T17:54:13+0000",
            "content": "Hi Guys, there seems to be some interest on list for such a capability: http://lucene.472066.n3.nabble.com/Which-token-filter-can-combine-2-terms-into-1-td4028482.html (or at least sounds similar). Any interest from someone to work with me to commit this? ",
            "author": "Chris A. Mattmann",
            "id": "comment-13540073"
        },
        {
            "date": "2012-12-27T23:05:19+0000",
            "content": "For sorting, would you want 'grapes_of_wrath\"? This distinguishes the word 'grapes' from words that might start with 'grapes'. (I don't know of any, but you see the problem \n\nAlso, in this use case numerical canonicalization makes sense for searching and sorting. Twenty-two -> 22, and also 'twenty two' -> 22. Or maybe 'twenty two' -> 'twenty-two'.\n ",
            "author": "Lance Norskog",
            "id": "comment-13540206"
        },
        {
            "date": "2012-12-28T15:58:15+0000",
            "content": "A few comments:\n\n\tTestCombiningFilter should extend BaseTokenStreamTestCase, build an Analyzer with MockTokenizer+this filter and use BaseTokenStreamTestCase asserts (see http://svn.apache.org/viewvc/lucene/dev/trunk/lucene/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestJapaneseKatakanaStemFilter.java?view=markup as a good example of an analysis unit test).\n\t@author tags should be removed\n\tindentation should be 2 spaces not tabs.\n\tinstead of throwing away the return value of addAttribute(TermAttribute.class) in the ctor, just initialize this as an instance variable:\n\n\n\n\npublic class CombiningFilter extends TokenFilter {\n  private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n\n\n\nThis way you dont have to constantly look it up from the attribute map for each token, instead you just access \"termAtt\".\n\n\tonce the code is updated to CharTermAttribute, the various string creations can be eliminated, since it implements Appendable and CharSequence. so instead of\n\n\n\n\nbuilder.append(ta.term());\n\n\n\njust do:\n\nbuilder.append(termAtt);\n\n\n\nand same at the end, instead of\n\nta.setTermBuffer(builder.toString());\n\n\n\njust do:\n\ntermAtt.setEmpty().append(builder);\n\n\n\n\n\tin reset(), i would just call super.reset() instead of \"this.input.reset()\". This is a little cleaner and accomplishes the same thing (its how the other tokenfilters do this).\n\n ",
            "author": "Robert Muir",
            "id": "comment-13540503"
        },
        {
            "date": "2012-12-29T05:20:50+0000",
            "content": "Thanks for the comments Robert. I'll take a pass at updating the patch per your comments. Lance, I think I get what you're saying. This is now in production at a fairly large company that I was doing consulting for and is working fine for their titles, etc, so I think it's still pretty useful. ",
            "author": "Chris A. Mattmann",
            "id": "comment-13540773"
        },
        {
            "date": "2013-01-09T02:32:02+0000",
            "content": "Any chance this filter could take an optional 'connector' parameter to put between tokens when joining them?\n\nThat way one could use '_' for sorting and (my need) a ' ' for recreating original string after stripping some token types. ",
            "author": "Alexandre Rafalovitch",
            "id": "comment-13547555"
        },
        {
            "date": "2013-01-09T02:34:11+0000",
            "content": "Hey Alexandre happy to try and code it up if you find it useful. Still working on the update for Robert's review. ",
            "author": "Chris A. Mattmann",
            "id": "comment-13547557"
        }
    ]
}