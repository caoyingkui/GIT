{
    "id": "LUCENE-136",
    "title": "StandardTokenzier with CJK support(sigram)",
    "details": {
        "labels": "",
        "priority": "Minor",
        "components": [
            "modules/analysis"
        ],
        "type": "Improvement",
        "fix_versions": [],
        "affect_versions": "None",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "diff -ub StandardTokenizer.jj StandardTokenizer.jj.orig \n\u2014 StandardTokenizer.jj        Sun Sep 28 01:52:18 2003\n+++ StandardTokenizer.jj.orig   Sun Sep 28 01:51:57 2003\n@@ -54,12 +54,12 @@\n\n options \n{\n     STATIC = false;\n-    //IGNORE_CASE = true;\n-    //BUILD_PARSER = false;\n-    UNICODE_INPUT = true;\n+//IGNORE_CASE = true;\n+//BUILD_PARSER = false;\n+//UNICODE_INPUT = true;\n     USER_CHAR_STREAM = true;\n     OPTIMIZE_TOKEN_MANAGER = true;\n-    //DEBUG_TOKEN_MANAGER = true;\n+//DEBUG_TOKEN_MANAGER = true;\n }\n PARSER_BEGIN(StandardTokenizer)\n\n@@ -89,7 +89,7 @@\n TOKEN : \n{                                        // token patterns\n \n     // basic word: a sequence of digits & letters\n-<ALPHANUM: (<LETTER>|<DIGIT>)+ >\n+  <ALPHANUM: (<LETTER>|<DIGIT>)+ >\n \n     // internal apostrophes: O'Reilly, you're, O'Reilly's\n     // use a post-filter to remove possesives\n@@ -118,7 +118,6 @@\n              | <HAS_DIGIT> <P> <ALPHANUM> (<P> <HAS_DIGIT> <P> <ALPHANUM>)+\n             )\n     >\n-| <SIGRAM: (<CJK>) >\n | <#P: (\"_\"|\"-\"|\"/\"|\".\"|\",\") >\n | <#HAS_DIGIT:                                   // at least one digit\n     (<LETTER>|<DIGIT>)*\n@@ -127,18 +126,14 @@\n     >\n \n | < #ALPHA: (<LETTER>)+>\n-| < #LETTER:                                     // alphabets\n+| < #LETTER:                                     // unicode letters\n     [\n         \"\\u0041\"-\"\\u005a\",\n         \"\\u0061\"-\"\\u007a\",\n         \"\\u00c0\"-\"\\u00d6\",\n         \"\\u00d8\"-\"\\u00f6\",\n         \"\\u00f8\"-\"\\u00ff\",\n-        \"\\u0100\"-\"\\u1fff\"\n-    ]\n-    >\n-|  < #CJK:       // non-alphabets\n-      [\n+       \"\\u0100\"-\"\\u1fff\",\n        \"\\u3040\"-\"\\u318f\",\n        \"\\u3300\"-\"\\u337f\",\n        \"\\u3400\"-\"\\u3d2d\",\n@@ -168,7 +163,7 @@\n }\n\n SKIP : \n{                                         // skip unrecognized chars\n-<NOISE: ~[] >\n+ <NOISE: ~[] >\n }\n\n /** Returns the next token in the stream, or null at EOS.\n@@ -187,7 +182,6 @@\n         token = <EMAIL> |\n         token = <HOST> |\n         token = <NUM> |\n\n\ttoken = <SIGRAM> |\n         token = <EOF>\n     )\n     {",
    "attachments": {
        "ASF.LICENSE.NOT.GRANTED--CJK_StandardTokenizer.jj.txt": "https://issues.apache.org/jira/secure/attachment/12312252/ASF.LICENSE.NOT.GRANTED--CJK_StandardTokenizer.jj.txt"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2003-09-30T05:58:47+0000",
            "content": "Ok, maybe I\"m just clueless on applying patches, so enlighten me on how to use what you \nprovided to patch my local version.  It doesn't look like you provided a 'cvs diff -u' patch, since \nyou're going against a .orig file.  I tried several variations to no avail with the patch command.  \nAlso, it would be most helpful if patches were sent as text file attachments rather than inline as \nline wrapping and such can cause issues. ",
            "author": "Erik Hatcher",
            "id": "comment-12321375"
        },
        {
            "date": "2003-09-30T23:24:43+0000",
            "content": "Created an attachment (id=8397)\nPatch file for proposed change ",
            "author": "Dan Rapp",
            "id": "comment-12321376"
        },
        {
            "date": "2003-09-30T23:35:06+0000",
            "content": "Thanks, patch applied! ",
            "author": "Erik Hatcher",
            "id": "comment-12321377"
        },
        {
            "date": "2003-10-01T23:30:01+0000",
            "content": "With the modification to StandardTokenizer.jj, the 'javacc' target should be \nrun to regenerate:\n\nStandardTokenizer.java\nStandardTokenizerConstants.java\nStandardTokenizerTokenManager.java\n\nIf you'd like, I can attach patch files for these as well (I'm using javacc \nv3.2, though I don't think that matters in this case). Which brings up the \nquestion, why store generated files in the repository? ",
            "author": "Dan Rapp",
            "id": "comment-12321378"
        },
        {
            "date": "2003-10-01T23:44:50+0000",
            "content": "Sorry about the generated files... I just regenerated them (using JavaCC 3.2 also) and committed \nthem.  We store the generated files in CVS because not everyone has JavaCC and it makes the build \nprocess a lot easier for them.  Eventually if this becomes an issue, we can add some <uptodate> \nchecks and fail a build if the .jj files are newer than the .java files (with perhaps some forced \noverride mechanism) or if the licensing is loose enough simply put JavaCC JAR's in our CVS. ",
            "author": "Erik Hatcher",
            "id": "comment-12321379"
        }
    ]
}