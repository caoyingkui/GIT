{
    "id": "LUCENE-6212",
    "title": "Remove IndexWriter's per-document analyzer add/updateDocument APIs",
    "details": {
        "resolution": "Fixed",
        "affect_versions": "None",
        "components": [],
        "labels": "",
        "fix_versions": [
            "5.0",
            "5.1",
            "6.0"
        ],
        "priority": "Major",
        "status": "Closed",
        "type": "Improvement"
    },
    "description": "IndexWriter already takes an analyzer up-front (via\nIndexWriterConfig), but it also allows you to specify a different one\nfor each add/updateDocument.\n\nI think this is quite dangerous/trappy since it means you can easily\nindex tokens for that document that don't match at search-time based\non the search-time analyzer.\n\nI think we should remove this trap in 5.0.",
    "attachments": {
        "LUCENE-6212.patch": "https://issues.apache.org/jira/secure/attachment/12695530/LUCENE-6212.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "id": "comment-14298666",
            "author": "Michael McCandless",
            "date": "2015-01-30T14:16:54+0000",
            "content": "Patch, I think it's ready. "
        },
        {
            "id": "comment-14298686",
            "author": "Uwe Schindler",
            "date": "2015-01-30T14:27:33+0000",
            "content": "+1 to get this in 5.0 "
        },
        {
            "id": "comment-14298893",
            "author": "Ryan Ernst",
            "date": "2015-01-30T17:17:44+0000",
            "content": "+1 "
        },
        {
            "id": "comment-14300122",
            "author": "ASF subversion and git services",
            "date": "2015-02-01T09:12:11+0000",
            "content": "Commit 1656272 from Michael McCandless in branch 'dev/trunk'\n[ https://svn.apache.org/r1656272 ]\n\nLUCENE-6212: remove per-doc analyzers "
        },
        {
            "id": "comment-14300126",
            "author": "ASF subversion and git services",
            "date": "2015-02-01T09:27:36+0000",
            "content": "Commit 1656273 from Michael McCandless in branch 'dev/branches/branch_5x'\n[ https://svn.apache.org/r1656273 ]\n\nLUCENE-6212: remove per-doc analyzers "
        },
        {
            "id": "comment-14300128",
            "author": "ASF subversion and git services",
            "date": "2015-02-01T09:39:32+0000",
            "content": "Commit 1656274 from Michael McCandless in branch 'dev/branches/lucene_solr_5_0'\n[ https://svn.apache.org/r1656274 ]\n\nLUCENE-6212: remove per-doc analyzers "
        },
        {
            "id": "comment-14300132",
            "author": "ASF subversion and git services",
            "date": "2015-02-01T09:50:27+0000",
            "content": "Commit 1656276 from Michael McCandless in branch 'dev/branches/lucene_solr_4_10'\n[ https://svn.apache.org/r1656276 ]\n\nLUCENE-6212: deprecate per-doc analyzers "
        },
        {
            "id": "comment-14300135",
            "author": "Shai Erera",
            "date": "2015-02-01T09:59:13+0000",
            "content": "How do you index multi-lingual documents in one index then? We used to do it by pulling the correct Analyzer per the document's language and call addDoc(doc, langAnazlyer). What's the alternative without that API? Is there any easy alternative, or should we add all fields to a document with a language-specific TokenStream, which is much less convenient, but still an alternative.\n\nIs it worth having a CHANGES / MIGRATION entry for this? I think if users depend on that API for good reasons (i.e. it's not a 'trap' for them), it should be mentioned somewhere.. "
        },
        {
            "id": "comment-14300153",
            "author": "Uwe Schindler",
            "date": "2015-02-01T11:02:31+0000",
            "content": "PerFieldAnalyzerWrapper? "
        },
        {
            "id": "comment-14300154",
            "author": "Shai Erera",
            "date": "2015-02-01T11:05:31+0000",
            "content": "That doesn't help. If all your documents have a 'title' and 'body' fields (with an additional 'language'), you want the content to be indexed under the 'title' and 'body' fields, and not 'title_en' and 'title_de'. Well maybe you do/should but the point is that you have a single schema for your documents. The only thing that changes is how they are tokenized, and that's on a per-document basis, depending on its language. "
        },
        {
            "id": "comment-14332661",
            "author": "Anshum Gupta",
            "date": "2015-02-23T05:01:12+0000",
            "content": "Bulk close after 5.0 release. "
        },
        {
            "id": "comment-14336553",
            "author": "Christopher Cudennec",
            "date": "2015-02-25T14:39:08+0000",
            "content": "Hi! Do you have any updates on this issue? We have just tried to upgrade from 4.3.1 to 5.0.0 and have exactly the same problem as Shai Erera. "
        },
        {
            "id": "comment-14339432",
            "author": "Ryan Ernst",
            "date": "2015-02-26T23:50:58+0000",
            "content": "you want the content to be indexed under the 'title' and 'body' fields, and not 'title_en' and 'title_de'. Well maybe you do/should but the point is that you have a single schema for your documents.\n\nShai Erera Christopher Cudennec That is exactly the problem.  It wasn't really a single schema.  It was a trappy API that required deciding at query time which analyzer to use.  It also means term statistics can be skewed, so the results could be skewed.  Using separate fields for each language is much better.  It's not really anymore work, since you would have had separate analyzers for each of those languages anyways. "
        },
        {
            "id": "comment-14506673",
            "author": "ASF subversion and git services",
            "date": "2015-04-22T08:55:10+0000",
            "content": "Commit 1675278 from Michael McCandless in branch 'dev/branches/branch_5x'\n[ https://svn.apache.org/r1675278 ]\n\nLUCENE-6212: add MIGRATE.txt entry "
        },
        {
            "id": "comment-14608156",
            "author": "Sanne Grinovero",
            "date": "2015-06-30T11:39:36+0000",
            "content": "Hello,\nI understand there are good reasons to prevent this for the \"average user\" but I would beg you to restore the functionality for those who know what they are doing.\n\nThere are perfectly valid use cases to use a different Analyzer at query time rather than indexing time, for example when handling synonyms at indexing time you don't need to apply the substitutions again at query time.\nBeyond synonyms, it's also possible to have text of different sources which has been pre-processed in different ways, so needs to be tokenized differently to get a consistent output.\n\nI love the idea of Lucene to become more strict regarding to consistent schema choices, but I would hope we could stick to field types and encoding, while Analyzer mappings can use a bit more flexibility?\n\nWould you accept a patch to overload\n\norg.apache.lucene.index.IndexWriter.updateDocument(Term, Iterable<? extends IndexableField>)\n\nwith the expert version:\n\norg.apache.lucene.index.IndexWriter.updateDocument(Term, Iterable<? extends IndexableField>, Analyzer overrideAnalyzer)\n\n ?\n\nThat would greatly help me to migrate to Lucene 5. My alternatives are to close/open the IndexWriter for each Analyzer change but that would have a significant performance impact; I'd rather cheat and pass an Analyzer instance which is mutable, even if that would prevent me from using the IndexWriter concurrently. "
        },
        {
            "id": "comment-14608354",
            "author": "Adrien Grand",
            "date": "2015-06-30T14:16:39+0000",
            "content": "There are perfectly valid use cases to use a different Analyzer at query time rather than indexing time\n\nThis change doesn't force you to use the same analyzer at index time and search time, just to always use the same analyzer at index time.\n\nit's also possible to have text of different sources which has been pre-processed in different ways, so needs to be tokenized differently to get a consistent output\n\nOne way that this feature was misused was to handle multi-lingual content, but this would break term statistics as different words could be filtered to the same stem and a single word could be filtered to two different stems depending on the language. In general, if different analysis chains are required, it's better to just use different fields or even different indices. "
        },
        {
            "id": "comment-14608407",
            "author": "Sanne Grinovero",
            "date": "2015-06-30T14:52:00+0000",
            "content": "Hi Adrien, thanks for replying!\nYes I agree with you that in general this could be abused and I understand the caveats, still I would like to do it. Since Lucene is a library for developers and it's not an \"end user product\" I would prefer it could give me a bit more flexibility. "
        },
        {
            "id": "comment-14627163",
            "author": "Hoss Man",
            "date": "2015-07-14T22:26:24+0000",
            "content": "Since Lucene is a library for developers and it's not an \"end user product\" I would prefer it could give me a bit more flexibility.\n\nUnless i'm missunderstanding the context of your concern, totally flexability in the terms indexed is still available because you can index Documents containing IndexableFields that produce whatever TokenStream you want \u2013 ignoring the Analyzer specified on the IndexWriter if you so choose.  \n\nWhat this change did is make \"the uncommon and easy to mess up case\" (ask indexwriter to analyze your text using a diff analyzer for each doc) impossible \u2013 but meanwhile both \"the simple common case\" (same analyzer for all docs) and \"the expert level case\" (i want to produce an arbitrary set of terms for each field and each document) are both still possible and easy.\n\n\n\nIn any event \u2013 trying to have a discussion about this in the comments of a Jira that's been closed for several months is a really bad idea \u2013 if you have questions/concerns about how to use the API, or how to upgrade your existing code, please address those to the java-user@lucene list where the entire community can help you (not just the handful of devs watching every jira issue) "
        }
    ]
}