{
    "id": "LUCENE-1787",
    "title": "Standard Tokenizer doesn't recognise I.B.M as Acronym, it requires it ends with a dot i.e I.B.M.",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [
            "modules/analysis"
        ],
        "type": "Improvement",
        "fix_versions": [],
        "affect_versions": "2.9",
        "resolution": "Won't Fix",
        "status": "Closed"
    },
    "description": "Standard Tokenzizer doesn't recognise I.B.M it requires it end with a dot i.e I.B.M. This is particulary problematic if I.B.M is added tot the index, with the StandardAnalyser it will get added as  IBM , a search for I.B.M will not match because I.B.M will be left as is, I would expect a match in this scenario\n\nI think it could be fixed by modifying the  grammar ACRONYM_DEP  in StandardTokenizerImpl.jflex so that it also supports\n\n{ALPHANUM} (\".\" {ALPHANUM}\n)+\n\ndot only required between each character, (I'm not familiar with jflex syntax )",
    "attachments": {
        "LUCENE-1787.patch": "https://issues.apache.org/jira/secure/attachment/12417460/LUCENE-1787.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2009-08-06T20:09:45+0000",
            "content": "You would want it to be greedy such that it would match a trailing period if it did exist though.\n\nA(\".\"A)+\".\"? ",
            "author": "Yonik Seeley",
            "id": "comment-12740232"
        },
        {
            "date": "2009-08-06T20:13:20+0000",
            "content": "We should fix ACRONYM, not ACRONYM_DEP right? ACRONYM_DEP is deprecated and will be removed in 3.0. Instead, you can change ACRONYM to\n{LETTER} (\".\" {LETTER}\n)+ (\".\")?  which will match I.B.M. and I.B.M. For the first example, it will eat the last dot as well, which IMO is important.\n\nBTW, my ACRONYM rule looks like this:\n\n// Acronyms: U.S.A., I.B.M., however also U.S.A (without the last \".\"). In addition, it recognizes R&D, AT&T, A&B&C.\nACRONYM =  \n{LETTER} (\".\" {LETTER}\n)+ (\".\")? \n\n\n\n \n{LETTER}{1,2} ((\"&\") {LETTER}\n)+\n\n\n\n\n\nDon't know if this change is allowed at this point though. ",
            "author": "Shai Erera",
            "id": "comment-12740233"
        },
        {
            "date": "2009-08-21T16:47:34+0000",
            "content": "Fix so that Acronymns without trailing dot are parsed as acronym, amended related Acronymn test in Analyser.\n\n(Sources were flexed and compiled using ant build, assume this uses correct Java version for flex file generation) ",
            "author": "Paul taylor",
            "id": "comment-12746076"
        },
        {
            "date": "2009-08-24T09:53:04+0000",
            "content": "renamed patch , and added changes to CHANGES.txt as described in http://wiki.apache.org/lucene-java/HowToContribute ",
            "author": "Paul taylor",
            "id": "comment-12746795"
        },
        {
            "date": "2009-08-24T10:16:28+0000",
            "content": "The big challenge here is back compat.  Ie, if we make this fix (which is a good fix!), then users upgrade to 2.9, suddenly queries may stop hitting the right documents because those documents had been indexed against the old StandardAnalyzer that has this bug.  Ie, the bug is \"cached\" in their index.\n\nThis is why we added \"matchVersion\" to StandardAnalyzer, but unfortunately we don't yet have a clean means of carrying out matchVersion when changes to the JFlex grammar are entailed. ",
            "author": "Michael McCandless",
            "id": "comment-12746802"
        },
        {
            "date": "2011-01-26T11:55:24+0000",
            "content": "The old StandardTokenizer behaviour was deprecated in Lucene 3.1 and replaced by a new one doing Unicode Standard Annex #29 segmentation. The deprecated code will not get any fixes anymore. ",
            "author": "Uwe Schindler",
            "id": "comment-12986958"
        }
    ]
}