{
    "id": "LUCENE-7996",
    "title": "Should we require positive scores?",
    "details": {
        "labels": "",
        "priority": "Minor",
        "resolution": "Fixed",
        "affect_versions": "None",
        "status": "Resolved",
        "type": "Wish",
        "components": [],
        "fix_versions": [
            "master (8.0)"
        ]
    },
    "description": "Having worked on MAXSCORE recently, things would be simpler if we required that scores are positive. Practically, this would mean \n\n\tforbidding/fixing similarities that may produce negative scores (we have some of them)\n\tforbidding things like negative boosts\n\n\n\nSo I'd be curious to have opinions whether this would be a sane requirement or whether we need to be able to cope with negative scores eg. because some similarities that we want to support produce negative scores by design.",
    "attachments": {
        "LUCENE-7996.patch": "https://issues.apache.org/jira/secure/attachment/12899978/LUCENE-7996.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "id": "comment-16208509",
            "date": "2017-10-17T22:22:13+0000",
            "content": "+1 we try to fix similarities that produce negative scores because it hurts relevance, too. Classic example is an unmodified bm25 IDF, goes negative for stopword-like terms.\n\nIn some cases formulas can not so easily be \"hacked\" to avoid these problems, it results in a less robust ranking algorithm. For example in the case above, if someone's stopword list isn't perfect for their collection, then queries will suffer.\n\nCurrently the problematic algorithms just have big javadocs warnings. But I think its ok to look at putting them in the sandbox or deprecatinoulg or removing like that instead. \n\nAt the end of the day, we should at least add better tests, so we know about the problems. Thats step 1 I think. I have some ideas. ",
            "author": "Robert Muir"
        },
        {
            "id": "comment-16209381",
            "date": "2017-10-18T14:08:01+0000",
            "content": "+1 ",
            "author": "Michael McCandless"
        },
        {
            "id": "comment-16272424",
            "date": "2017-11-30T09:21:48+0000",
            "content": "Here is a patch:\n\n\tboosts must be positive.\n\tAssertingScorer checks that scores are positive.\n\tAssertingSimilarity checks that scores are positive regardless of the boost.\n\tFunctionScoreQuery fails when the value source produces a negative value, but unfortunately this only occurs at runtime.\n\n\n\nAny opinions? ",
            "author": "Adrien Grand"
        },
        {
            "id": "comment-16272506",
            "date": "2017-11-30T10:41:27+0000",
            "content": "Rather than throwing errors from BoostingQuery and FunctionScoreQuery, could we just set the score to 0?  And document that functions that return negative values will be truncated to 0 for scoring purposes. ",
            "author": "Alan Woodward"
        },
        {
            "id": "comment-16272516",
            "date": "2017-11-30T10:51:49+0000",
            "content": "This might be a better option indeed. ",
            "author": "Adrien Grand"
        },
        {
            "id": "comment-16274222",
            "date": "2017-12-01T10:30:14+0000",
            "content": "New patch that maps negative scores to 0. The explanation says when this happens so that this change is not too trappy. ",
            "author": "Adrien Grand"
        },
        {
            "id": "comment-16278884",
            "date": "2017-12-05T17:16:15+0000",
            "content": "I polished explanations a bit, I think it's ready. ",
            "author": "Adrien Grand"
        },
        {
            "id": "comment-16278893",
            "date": "2017-12-05T17:22:05+0000",
            "content": "Just FYI for upstream impact, LTR models tend to output negative scores. For example Ranklib gradient boosting models range from -100 to 100. Of course this can be changed by always adding 100 to the score, but there's appeal in seeing the expected score from an LTR query being identical to the score you'd get from the model if you ran it outside of Solr/Elasticsearch. ",
            "author": "Doug Turnbull"
        },
        {
            "id": "comment-16279003",
            "date": "2017-12-05T18:27:50+0000",
            "content": "Agreed some users are going to be annoyed by the impact of this change. I wouldn't have considered it if it wasn't a requirement to get speedups in the order of what we are observing on LUCENE-4100 and LUCENE-7993. ",
            "author": "Adrien Grand"
        },
        {
            "id": "comment-16280154",
            "date": "2017-12-06T13:06:28+0000",
            "content": "Commit a8a63464e7da63b3dbc884634fd0e00b3f0c140b in lucene-solr's branch refs/heads/master from Adrien Grand\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=a8a6346 ]\n\nLUCENE-7996: Queries are now required to produce positive scores. ",
            "author": "ASF subversion and git services"
        },
        {
            "id": "comment-16280611",
            "date": "2017-12-06T18:17:14+0000",
            "content": "Commit 187849f9b67ba6b7e6c2d06cc25359bf53b2ce9f in lucene-solr's branch refs/heads/master from Adrien Grand\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=187849f ]\n\nLUCENE-7996: PayloadScoreQuery must produce positive scores. ",
            "author": "ASF subversion and git services"
        },
        {
            "id": "comment-16287778",
            "date": "2017-12-12T15:49:52+0000",
            "content": "Commit f525ce8fbb30367be2d816be303ee7c1b8d4d0ae in lucene-solr's branch refs/heads/master from Adrien Grand\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=f525ce8 ]\n\nLUCENE-7996: Add a note to the changes in runtime behaviour and to the solr upgrade notes. ",
            "author": "ASF subversion and git services"
        },
        {
            "id": "comment-16641096",
            "date": "2018-10-07T15:14:15+0000",
            "content": "Agreed some users are going to be annoyed by the impact of this change. I wouldn't have considered it if it wasn't a requirement to get speedups in the order of what we are observing on LUCENE-4100 and LUCENE-7993.\n\nBut maxscore/impact optimizations can only be used in certain circumstances anyway, right?  Given that we need fallback to score-all for things that aren't supported, falling back rather than prohibiting negative scores would avoid the back compat breaks. ",
            "author": "Yonik Seeley"
        },
        {
            "id": "comment-16645052",
            "date": "2018-10-10T14:34:44+0000",
            "content": "WAND and other optimizations were the reason why I opened this issue and moved it forward, though Robert made a good point in his initial comment on this issue that negative scores are not only an implementation problem for WAND and other optimizations, it also hurts relevance.\n\nDoug mentioned that preventing negative scores might be an issue for LTR, but I've come to think that these optimizations are actually interesting for learning to rank since simple models could leverage these optimizations. If they use a reasonable number of features (using FeatureField) and combine scores via a linear combination, then the resulting query could be a boolean query that efficiently skips irrelevant documents. ",
            "author": "Adrien Grand"
        },
        {
            "id": "comment-16645147",
            "date": "2018-10-10T15:26:31+0000",
            "content": "WAND and other optimizations were the reason why I opened this issue and moved it forward\n\nI understand why we wouldn't want to produce negative scores by default, as that would complicate or prevent such optimizations by default.\nWhat I don't understand is what we gain by prohibiting negative scores across the board.  We can only do these optimizations in certain cases anyway, so we don't gain anything by prohibiting a function query (for example) from producing negative values.  This would seem to limit the use cases without any corresponding gain in optimization opportunities. ",
            "author": "Yonik Seeley"
        },
        {
            "id": "comment-16649501",
            "date": "2018-10-14T19:05:00+0000",
            "content": "The gain is a lot of simplicity. If we don't require non-negative scores, then we would need some way for scorers to tell whether they may produce negative scores and/or additional care to make sure that things still work if negative scores are returned via sub scorers or passed to Scorer#setMinCompetitiveScore.\n\nFunctionScoreQuery is probably the easiest way to mistakenly create a scorer that returns negative scores, in which case one should sort by the function rather than using this function to compute scores (ie. follow the 1st example at https://lucene.apache.org/core/7_5_0/expressions/org/apache/lucene/expressions/Expression.html rather than the 2nd one). ",
            "author": "Adrien Grand"
        },
        {
            "id": "comment-16649521",
            "date": "2018-10-14T20:14:12+0000",
            "content": "If we don't require non-negative scores, then we would need some way for scorers to tell whether they may produce negative scores \n\nI assumed we already had logic to disable the optimizations for certain scorers.  For example, isn't it true that if I embed an arbitrary function query today (even one with all positive scores), these optimizations are already disabled? ",
            "author": "Yonik Seeley"
        },
        {
            "id": "comment-16649524",
            "date": "2018-10-14T20:38:46+0000",
            "content": "In such a case, these optimizations are not disabled but since we assume unbounded scores for any range of doc ids, they are inefficient in practice (see eg. https://github.com/apache/lucene-solr/blob/master/lucene/queries/src/java/org/apache/lucene/queries/function/FunctionScoreQuery.java#L218-L220). ",
            "author": "Adrien Grand"
        },
        {
            "id": "comment-16649548",
            "date": "2018-10-14T22:21:06+0000",
            "content": "Ah, I see.  Thanks for the pointer! ",
            "author": "Yonik Seeley"
        }
    ]
}