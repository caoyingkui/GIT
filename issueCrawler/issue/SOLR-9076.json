{
    "id": "SOLR-9076",
    "title": "Update to Hadoop 2.7.2",
    "details": {
        "components": [],
        "type": "Improvement",
        "labels": "",
        "fix_versions": [
            "6.2",
            "7.0"
        ],
        "affect_versions": "None",
        "status": "Closed",
        "resolution": "Fixed",
        "priority": "Major"
    },
    "description": "",
    "attachments": {
        "SOLR-9076.patch": "https://issues.apache.org/jira/secure/attachment/12802490/SOLR-9076.patch",
        "SOLR-9076-fixnetty.patch": "https://issues.apache.org/jira/secure/attachment/12813991/SOLR-9076-fixnetty.patch",
        "SOLR-9076-Fix-dependencies.patch": "https://issues.apache.org/jira/secure/attachment/12815502/SOLR-9076-Fix-dependencies.patch",
        "SOLR-9076-Hack.patch": "https://issues.apache.org/jira/secure/attachment/12814153/SOLR-9076-Hack.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2016-05-05T21:48:48+0000",
            "author": "Mark Miller",
            "content": "I hit SOLR-7115 for some reason trying to get this to work. A workaround is currently included in this patch. ",
            "id": "comment-15273162"
        },
        {
            "date": "2016-05-06T17:31:42+0000",
            "author": "Mike Drob",
            "content": "\n+/org.apache.htrace/htrace-core = 3.2.0-incubating\n+/org.apache.htrace/htrace-core4 = 4.0.1-incubating\nWe don't need both of these, do we? Just the 4.0.1 version, I'd expect. ",
            "id": "comment-15274409"
        },
        {
            "date": "2016-05-09T15:50:01+0000",
            "author": "Mark Miller",
            "content": "Seem to need both to avoid class not found issues. ",
            "id": "comment-15276535"
        },
        {
            "date": "2016-05-09T16:32:02+0000",
            "author": "Mark Miller",
            "content": "Okay, that seems to be because there is a little more to sort out. Another patch coming.\n\nI hit SOLR-7115 for some reason trying to get this to work.\n\nOddly, with no changes to what I was doing, even without the workaround, I'm not seeing this today. Need to investigate more. ",
            "id": "comment-15276587"
        },
        {
            "date": "2016-06-22T23:41:05+0000",
            "author": "Gregory Chanan",
            "content": "rebased patch \u2013 looks like the TestRecoveryHdfs.java change already went in. ",
            "id": "comment-15345409"
        },
        {
            "date": "2016-06-23T20:34:41+0000",
            "author": "Gregory Chanan",
            "content": "Here's a patch that passed the test and precommits.  Only change from previous patch is it removes the org.htrace versions (which error'ed out in the precommit because they aren't used anymore) and removes the org.htrace license/notice/sha1.\n\nI will commit this shortly. ",
            "id": "comment-15347128"
        },
        {
            "date": "2016-06-23T20:42:28+0000",
            "author": "ASF subversion and git services",
            "content": "Commit f273cb1b3ae722ee58b289653ad8a3bc5066838f in lucene-solr's branch refs/heads/master from Gregory Chanan\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=f273cb1 ]\n\nSOLR-9076: Update to Hadoop 2.7.2 ",
            "id": "comment-15347139"
        },
        {
            "date": "2016-06-23T21:59:01+0000",
            "author": "ASF subversion and git services",
            "content": "Commit b76f64fdc0559a7b94feb2b97c78c9c151f8f477 in lucene-solr's branch refs/heads/branch_6x from Gregory Chanan\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=b76f64f ]\n\nSOLR-9076: Update to Hadoop 2.7.2 ",
            "id": "comment-15347282"
        },
        {
            "date": "2016-06-23T22:01:30+0000",
            "author": "Gregory Chanan",
            "content": "Committed to 7.0 and 6.2.  Thanks Mark! ",
            "id": "comment-15347283"
        },
        {
            "date": "2016-06-25T13:20:46+0000",
            "author": "Steve Rowe",
            "content": "My Jenkins found reproducing nightly failures in the map-reduce contrib of MorphlineBasicMiniMRTest on master and branch_6x - any seed triggers the same error.  On master when I rollback to before the commit on this issue, the failure stops.\n\nHere's the master failure:\n\n\nChecking out Revision d730f4a1caddac1f28b60a118904f0c1d5290fa0 (refs/remotes/origin/master)\n[...]\n   [junit4]   2> NOTE: reproduce with: ant test  -Dtestcase=MorphlineBasicMiniMRTest -Dtests.seed=939E67829C51091F -Dtests.multiplier=2 -Dtests.nightly=true -Dtests.slow=true -Dtests.linedocsfile=/home/jenkins/lucene-data/enwiki.random.lines.txt -Dtests.locale=uk-UA -Dtests.timezone=Europe/Riga -Dtests.asserts=true -Dtests.file.encoding=UTF-8\n   [junit4] ERROR   0.00s J1 | MorphlineBasicMiniMRTest (suite) <<<\n   [junit4]    > Throwable #1: org.apache.hadoop.yarn.exceptions.YarnRuntimeException: java.lang.NoClassDefFoundError: org/jboss/netty/channel/ChannelPipelineFactory\n   [junit4]    >        at __randomizedtesting.SeedInfo.seed([939E67829C51091F]:0)\n   [junit4]    >        at org.apache.solr.hadoop.hack.MiniYARNCluster$NodeManagerWrapper.serviceStart(MiniYARNCluster.java:334)\n   [junit4]    >        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)\n   [junit4]    >        at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:120)\n   [junit4]    >        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)\n   [junit4]    >        at org.apache.solr.hadoop.hack.MiniMRClientClusterFactory.create(MiniMRClientClusterFactory.java:83)\n   [junit4]    >        at org.apache.solr.hadoop.hack.MiniMRCluster.<init>(MiniMRCluster.java:181)\n   [junit4]    >        at org.apache.solr.hadoop.hack.MiniMRCluster.<init>(MiniMRCluster.java:169)\n   [junit4]    >        at org.apache.solr.hadoop.MorphlineBasicMiniMRTest.setupClass(MorphlineBasicMiniMRTest.java:180)\n   [junit4]    >        at java.lang.Thread.run(Thread.java:745)\n   [junit4]    > Caused by: java.lang.NoClassDefFoundError: org/jboss/netty/channel/ChannelPipelineFactory\n   [junit4]    >        at java.lang.Class.forName0(Native Method)\n   [junit4]    >        at java.lang.Class.forName(Class.java:348)\n   [junit4]    >        at org.apache.hadoop.conf.Configuration.getClassByNameOrNull(Configuration.java:2134)\n   [junit4]    >        at org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:2099)\n   [junit4]    >        at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2193)\n   [junit4]    >        at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2219)\n   [junit4]    >        at org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices.serviceInit(AuxServices.java:121)\n   [junit4]    >        at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)\n   [junit4]    >        at org.apache.hadoop.service.CompositeService.serviceInit(CompositeService.java:107)\n   [junit4]    >        at org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.serviceInit(ContainerManagerImpl.java:245)\n   [junit4]    >        at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)\n   [junit4]    >        at org.apache.hadoop.service.CompositeService.serviceInit(CompositeService.java:107)\n   [junit4]    >        at org.apache.hadoop.yarn.server.nodemanager.NodeManager.serviceInit(NodeManager.java:260)\n   [junit4]    >        at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)\n   [junit4]    >        at org.apache.solr.hadoop.hack.MiniYARNCluster$NodeManagerWrapper.serviceStart(MiniYARNCluster.java:316)\n   [junit4]    >        ... 31 more\n   [junit4]    > Caused by: java.lang.ClassNotFoundException: org.jboss.netty.channel.ChannelPipelineFactory\n   [junit4]    >        at java.net.URLClassLoader.findClass(URLClassLoader.java:381)\n   [junit4]    >        at java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n   [junit4]    >        at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)\n   [junit4]    >        at java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n   [junit4]    >        ... 46 more\n\n ",
            "id": "comment-15349641"
        },
        {
            "date": "2016-06-27T20:56:12+0000",
            "author": "Gregory Chanan",
            "content": "Strange, I wonder why that didn't show up when I ran the tests?  Maybe I need a different profile.\n\nI'll take a look. ",
            "id": "comment-15351795"
        },
        {
            "date": "2016-06-27T21:43:38+0000",
            "author": "Gregory Chanan",
            "content": "Strange, I wonder why that didn't show up when I ran the tests? Maybe I need a different profile.\n\nIt's a nightly test.  I was able to reproduce it. ",
            "id": "comment-15351895"
        },
        {
            "date": "2016-06-27T22:28:39+0000",
            "author": "Gregory Chanan",
            "content": "I added org.jboss.netty.netty version 3.2.4.Final and now I get this:\n\n 2> java.lang.reflect.InvocationTargetException\n   [junit4]   2> \tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n   [junit4]   2> \tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n   [junit4]   2> \tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n   [junit4]   2> \tat java.lang.reflect.Method.invoke(Method.java:498)\n   [junit4]   2> \tat org.apache.hadoop.metrics2.lib.MethodMetric$2.snapshot(MethodMetric.java:111)\n   [junit4]   2> \tat org.apache.hadoop.metrics2.lib.MethodMetric.snapshot(MethodMetric.java:144)\n   [junit4]   2> \tat org.apache.hadoop.metrics2.lib.MetricsRegistry.snapshot(MetricsRegistry.java:401)\n   [junit4]   2> \tat org.apache.hadoop.metrics2.lib.MetricsSourceBuilder$1.getMetrics(MetricsSourceBuilder.java:79)\n   [junit4]   2> \tat org.apache.hadoop.metrics2.impl.MetricsSourceAdapter.getMetrics(MetricsSourceAdapter.java:194)\n   [junit4]   2> \tat org.apache.hadoop.metrics2.impl.MetricsSourceAdapter.updateJmxCache(MetricsSourceAdapter.java:172)\n   [junit4]   2> \tat org.apache.hadoop.metrics2.impl.MetricsSourceAdapter.getMBeanInfo(MetricsSourceAdapter.java:151)\n   [junit4]   2> \tat com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getClassName(DefaultMBeanServerInterceptor.java:1804)\n   [junit4]   2> \tat com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.safeGetClassName(DefaultMBeanServerInterceptor.java:1595)\n   [junit4]   2> \tat com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.checkMBeanPermission(DefaultMBeanServerInterceptor.java:1813)\n   [junit4]   2> \tat com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.exclusiveUnregisterMBean(DefaultMBeanServerInterceptor.java:430)\n   [junit4]   2> \tat com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.unregisterMBean(DefaultMBeanServerInterceptor.java:415)\n   [junit4]   2> \tat com.sun.jmx.mbeanserver.JmxMBeanServer.unregisterMBean(JmxMBeanServer.java:546)\n   [junit4]   2> \tat org.apache.hadoop.metrics2.util.MBeans.unregister(MBeans.java:81)\n   [junit4]   2> \tat org.apache.hadoop.metrics2.impl.MetricsSourceAdapter.stopMBeans(MetricsSourceAdapter.java:226)\n   [junit4]   2> \tat org.apache.hadoop.metrics2.impl.MetricsSourceAdapter.stop(MetricsSourceAdapter.java:211)\n   [junit4]   2> \tat org.apache.hadoop.metrics2.impl.MetricsSystemImpl.stopSources(MetricsSystemImpl.java:463)\n   [junit4]   2> \tat org.apache.hadoop.metrics2.impl.MetricsSystemImpl.stop(MetricsSystemImpl.java:213)\n   [junit4]   2> \tat org.apache.hadoop.metrics2.impl.MetricsSystemImpl.shutdown(MetricsSystemImpl.java:594)\n   [junit4]   2> \tat org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.shutdownInstance(DefaultMetricsSystem.java:72)\n   [junit4]   2> \tat org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.shutdown(DefaultMetricsSystem.java:68)\n   [junit4]   2> \tat org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics.shutdown(NameNodeMetrics.java:171)\n   [junit4]   2> \tat org.apache.hadoop.hdfs.server.namenode.NameNode.stop(NameNode.java:872)\n   [junit4]   2> \tat org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:1726)\n   [junit4]   2> \tat org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:1705)\n   [junit4]   2> \tat org.apache.solr.hadoop.MorphlineBasicMiniMRTest.teardownClass(MorphlineBasicMiniMRTest.java:196)\n   [junit4]   2> \tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n   [junit4]   2> \tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n   [junit4]   2> \tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n   [junit4]   2> \tat java.lang.reflect.Method.invoke(Method.java:498)\n   [junit4]   2> \tat com.carrotsearch.randomizedtesting.RandomizedRunner.invoke(RandomizedRunner.java:1764)\n   [junit4]   2> \tat com.carrotsearch.randomizedtesting.RandomizedRunner$7.evaluate(RandomizedRunner.java:834)\n   [junit4]   2> \tat com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)\n   [junit4]   2> \tat com.carrotsearch.randomizedtesting.rules.SystemPropertiesRestoreRule$1.evaluate(SystemPropertiesRestoreRule.java:57)\n   [junit4]   2> \tat org.apache.lucene.util.AbstractBeforeAfterRule$1.evaluate(AbstractBeforeAfterRule.java:45)\n   [junit4]   2> \tat com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)\n   [junit4]   2> \tat org.apache.lucene.util.TestRuleStoreClassName$1.evaluate(TestRuleStoreClassName.java:41)\n   [junit4]   2> \tat com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:40)\n   [junit4]   2> \tat com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:40)\n   [junit4]   2> \tat com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)\n   [junit4]   2> \tat com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)\n   [junit4]   2> \tat com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)\n   [junit4]   2> \tat org.apache.lucene.util.TestRuleAssertionsRequired$1.evaluate(TestRuleAssertionsRequired.java:53)\n   [junit4]   2> \tat org.apache.lucene.util.TestRuleMarkFailure$1.evaluate(TestRuleMarkFailure.java:47)\n   [junit4]   2> \tat org.apache.lucene.util.TestRuleIgnoreAfterMaxFailures$1.evaluate(TestRuleIgnoreAfterMaxFailures.java:64)\n   [junit4]   2> \tat org.apache.lucene.util.TestRuleIgnoreTestSuites$1.evaluate(TestRuleIgnoreTestSuites.java:54)\n   [junit4]   2> \tat com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)\n   [junit4]   2> \tat com.carrotsearch.randomizedtesting.ThreadLeakControl$StatementRunner.run(ThreadLeakControl.java:367)\n   [junit4]   2> \tat java.lang.Thread.run(Thread.java:745)\n   [junit4]   2> Caused by: java.lang.NullPointerException\n   [junit4]   2> \tat org.apache.hadoop.hdfs.server.blockmanagement.BlocksMap.size(BlocksMap.java:203)\n   [junit4]   2> \tat org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.getTotalBlocks(BlockManager.java:3370)\n   [junit4]   2> \tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlocksTotal(FSNamesystem.java:5729)\n   [junit4]   2> \t... 53 more\n\n ",
            "id": "comment-15351964"
        },
        {
            "date": "2016-06-28T00:19:47+0000",
            "author": "Gregory Chanan",
            "content": "Here's a patch that adds the netty dependency.  I'm still seeing test failures locally, not sure if they are a product of my environment or not yet. ",
            "id": "comment-15352112"
        },
        {
            "date": "2016-06-28T00:23:04+0000",
            "author": "Gregory Chanan",
            "content": "Saw this on another machine:\n\n\n   [junit4]    > Throwable #1: java.io.IOException: Failed on local exception: java.io.IOException: Broken pipe; Host Details : local host is: \"ubuntu14-ec2-beefy-slave-03a7.vpc.cloudera.com/172.26.18.223\"; destination host is: \"ubuntu14-ec2-beefy-slave-03a7.vpc.cloudera.com\":53094; \n   [junit4]    > \tat __randomizedtesting.SeedInfo.seed([F57BFC0B596FCED0:FB29480558F9FCDF]:0)\n   [junit4]    > \tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:776)\n   [junit4]    > \tat org.apache.hadoop.ipc.Client.call(Client.java:1479)\n   [junit4]    > \tat org.apache.hadoop.ipc.Client.call(Client.java:1412)\n   [junit4]    > \tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)\n   [junit4]    > \tat com.sun.proxy.$Proxy112.getClusterMetrics(Unknown Source)\n   [junit4]    > \tat org.apache.hadoop.yarn.api.impl.pb.client.ApplicationClientProtocolPBClientImpl.getClusterMetrics(ApplicationClientProtocolPBClientImpl.java:206)\n   [junit4]    > \tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)\n   [junit4]    > \tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)\n   [junit4]    > \tat com.sun.proxy.$Proxy113.getClusterMetrics(Unknown Source)\n   [junit4]    > \tat org.apache.hadoop.yarn.client.api.impl.YarnClientImpl.getYarnClusterMetrics(YarnClientImpl.java:487)\n   [junit4]    > \tat org.apache.hadoop.mapred.ResourceMgrDelegate.getClusterMetrics(ResourceMgrDelegate.java:151)\n   [junit4]    > \tat org.apache.hadoop.mapred.YARNRunner.getClusterMetrics(YARNRunner.java:179)\n   [junit4]    > \tat org.apache.hadoop.mapreduce.Cluster.getClusterStatus(Cluster.java:247)\n   [junit4]    > \tat org.apache.hadoop.mapred.JobClient$3.run(JobClient.java:748)\n   [junit4]    > \tat org.apache.hadoop.mapred.JobClient$3.run(JobClient.java:746)\n   [junit4]    > \tat java.security.AccessController.doPrivileged(Native Method)\n   [junit4]    > \tat javax.security.auth.Subject.doAs(Subject.java:422)\n   [junit4]    > \tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)\n   [junit4]    > \tat org.apache.hadoop.mapred.JobClient.getClusterStatus(JobClient.java:746)\n   [junit4]    > \tat org.apache.solr.hadoop.MapReduceIndexerTool.run(MapReduceIndexerTool.java:642)\n   [junit4]    > \tat org.apache.solr.hadoop.MapReduceIndexerTool.run(MapReduceIndexerTool.java:605)\n   [junit4]    > \tat org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)\n   [junit4]    > \tat org.apache.solr.hadoop.MorphlineBasicMiniMRTest.mrRun(MorphlineBasicMiniMRTest.java:364)\n   [junit4]    > \tat java.lang.Thread.run(Thread.java:745)\n   [junit4]    > Caused by: java.io.IOException: Broken pipe\n   [junit4]    > \tat sun.nio.ch.FileDispatcherImpl.write0(Native Method)\n   [junit4]    > \tat sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:47)\n   [junit4]    > \tat sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:93)\n   [junit4]    > \tat sun.nio.ch.IOUtil.write(IOUtil.java:65)\n   [junit4]    > \tat sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)\n   [junit4]    > \tat org.apache.hadoop.net.SocketOutputStream$Writer.performIO(SocketOutputStream.java:63)\n   [junit4]    > \tat org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)\n   [junit4]    > \tat org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:159)\n   [junit4]    > \tat org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:117)\n   [junit4]    > \tat java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)\n   [junit4]    > \tat java.io.BufferedOutputStream.flush(BufferedOutputStream.java:140)\n   [junit4]    > \tat java.io.DataOutputStream.flush(DataOutputStream.java:123)\n   [junit4]    > \tat org.apache.hadoop.ipc.Client$Connection$3.run(Client.java:1043)\n   [junit4]    > \tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n   [junit4]    > \tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n   [junit4]    > \tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n   [junit4]    > \tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n   [junit4]    > \t... 1 more\n\n ",
            "id": "comment-15352114"
        },
        {
            "date": "2016-06-28T01:20:09+0000",
            "author": "Mark Miller",
            "content": "I took the .hack test classes out to rule those out as a source. I still see the same strange issues around missing netty classes. Which is odd, because this drove moving to Netty 4 as well, so why does it want Netty 3 classes - does it have conflicting Netty reqs? We really want to avoid bringing in more than one version if we can help it, even for tests. But then it seems you got past that, so I'm not sure why I still saw class not found problems with Netty even with the patch. ",
            "id": "comment-15352165"
        },
        {
            "date": "2016-06-28T13:48:17+0000",
            "author": "Mark Miller",
            "content": "Okay, I tried again with a clean checkout and your patch. Things seem to work on this attempt, except the mapreduce job fails, but I think that is just SOLR-9073.\n\nI still think it's really strange we need two versions of Netty though... ",
            "id": "comment-15352999"
        },
        {
            "date": "2016-06-28T14:09:32+0000",
            "author": "Mark Miller",
            "content": "Actually, the first thing I see failing in the MR job is:\n\nCaused by: java.lang.NoClassDefFoundError: org/bouncycastle/operator/OperatorCreationException\n\tat java.lang.Class.forName0(Native Method)\n\tat java.lang.Class.forName(Class.java:264)\n\tat org.apache.solr.morphlines.cell.SolrCellBuilder$SolrCell.<init>(SolrCellBuilder.java:175)\n\t... 21 more\nCaused by: java.lang.ClassNotFoundException: org.bouncycastle.operator.OperatorCreationException\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:381)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n\tat sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n\t... 24 more\n\n ",
            "id": "comment-15353043"
        },
        {
            "date": "2016-06-28T15:08:19+0000",
            "author": "Mark Miller",
            "content": "It requires a couple dependencies still:    \n <dependency org=\"org.bouncycastle\" name=\"bcpkix-jdk15on\" rev=\"1.47\" conf=\"test\"/>\n  <dependency org=\"com.rometools\" name=\"rome\" rev=\"1.6.1\" conf=\"test\"/>\n\nI'm looking at SOLR-9073 - we have to start using a core name for embedded and that causes some random grief. ",
            "id": "comment-15353155"
        },
        {
            "date": "2016-06-28T17:27:13+0000",
            "author": "Mark Miller",
            "content": "Here is a nasty hack patch that gets the test passing (including hacks for SOLR-9073).\n\nIt hacks in a couple missing dependencies, moves around some config files, and allows creating a core when a core.properties file already exists.\n\nNeed to make it all work without those hacks. ",
            "id": "comment-15353414"
        },
        {
            "date": "2016-06-28T18:57:30+0000",
            "author": "Gregory Chanan",
            "content": "Which is odd, because this drove moving to Netty 4 as well, so why does it want Netty 3 classes - does it have conflicting Netty reqs?\n\nGood question.  Looks like the dependency is coming from the bkjournal contrib \u2013 I wonder if there's some configuration we can use to disable that in the tests.\n\nHere's mvn dependency:tree output:\n\n[INFO] org.apache.hadoop.contrib:hadoop-hdfs-bkjournal:jar:2.7.2\n...\n[INFO] +- org.apache.bookkeeper:bookkeeper-server:jar:4.2.3:compile\n[INFO] |  +- org.slf4j:slf4j-api:jar:1.7.10:compile\n[INFO] |  +- org.slf4j:slf4j-log4j12:jar:1.7.10:compile\n[INFO] |  +- org.jboss.netty:netty:jar:3.2.4.Final:compile\n...\n\n ",
            "id": "comment-15353532"
        },
        {
            "date": "2016-06-30T16:39:50+0000",
            "author": "Mark Miller",
            "content": "I think this is the patch we need here. It's slightly different versions then I commented above though, so I won't have full confidence again until SOLR-9073 is resolved, and that has turned out to be quite annoying to solve nicely rather than just via hack. ",
            "id": "comment-15357429"
        },
        {
            "date": "2016-06-30T21:05:20+0000",
            "author": "Mark Miller",
            "content": "Bah, no such luck with using existing Rome and Bouncy Castle dependencies - it requires the versions I have above rather than the ones we have. ",
            "id": "comment-15357851"
        },
        {
            "date": "2016-07-01T13:07:14+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 2c96c91dd82ed692a97697ac6de26463ce26ea55 in lucene-solr's branch refs/heads/master from markrmiller\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=2c96c91 ]\n\nSOLR-9076: Add some missing dependencies. ",
            "id": "comment-15358926"
        },
        {
            "date": "2016-07-01T13:08:25+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 40d35045eacb42bef3b251f9b737e3975b463b2b in lucene-solr's branch refs/heads/branch_6x from markrmiller\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=40d3504 ]\n\nSOLR-9076: Add some missing dependencies. ",
            "id": "comment-15358930"
        },
        {
            "date": "2016-07-01T15:14:00+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 997489f78abe992677692e684458b3d9ac7115bd in lucene-solr's branch refs/heads/branch_6x from Alan Woodward\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=997489f ]\n\nSOLR-9076: Fix ivy config to pass precommit ",
            "id": "comment-15359114"
        },
        {
            "date": "2016-07-01T15:14:03+0000",
            "author": "ASF subversion and git services",
            "content": "Commit c38cdedbf2100189c068ec5d3f2ff061fd0696ac in lucene-solr's branch refs/heads/master from Alan Woodward\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=c38cded ]\n\nSOLR-9076: Fix ivy config to pass precommit ",
            "id": "comment-15359116"
        },
        {
            "date": "2016-07-14T17:00:26+0000",
            "author": "Steve Rowe",
            "content": "Looks like dependencies are still an issue?  From my Jenkins's nightly 6.x job yesterday - these reproduce for me:\n\n\n[...]\n   [junit4]   2> NOTE: reproduce with: ant test  -Dtestcase=MorphlineBasicMiniMRTest -Dtests.seed=96C0B1B6D2779A2B -Dtests.multiplier=2 -Dtests.nightly=true -Dtests.slow=true -Dtests.linedocsfile=/home/jenkins/lucene-data/enwiki.random.lines.txt -Dtests.locale=ms-MY -Dtests.timezone=AGT -Dtests.asserts=true -Dtests.file.encoding=ISO-8859-1\n   [junit4] ERROR   0.00s J1 | MorphlineBasicMiniMRTest (suite) <<<\n   [junit4]    > Throwable #1: org.apache.hadoop.yarn.exceptions.YarnRuntimeException: java.lang.NoClassDefFoundError: org/jboss/netty/channel/ChannelPipelineFactory\n\n\n\n\n   [junit4]   2> NOTE: reproduce with: ant test  -Dtestcase=MorphlineGoLiveMiniMRTest -Dtests.seed=96C0B1B6D2779A2B -Dtests.multiplier=2 -Dtests.nightly=true -Dtests.slow=true -Dtests.linedocsfile=/home/jenkins/lucene-data/enwiki.random.lines.txt -Dtests.locale=pt -Dtests.timezone=America/Aruba -Dtests.asserts=true -Dtests.file.encoding=ISO-8859-1\n   [junit4] ERROR   0.00s J0 | MorphlineGoLiveMiniMRTest (suite) <<<\n   [junit4]    > Throwable #1: org.apache.hadoop.yarn.exceptions.YarnRuntimeException: java.lang.NoClassDefFoundError: org/jboss/netty/channel/ChannelFactory\n\n\n\nGetting regular fails on my master nightly runs for the same reason.\n\nI don't understand why these failures don't show up on ASF or Policeman Jenkins? ",
            "id": "comment-15377274"
        },
        {
            "date": "2016-07-14T17:52:16+0000",
            "author": "Steve Rowe",
            "content": "I don't understand why these failures don't show up on ASF or Policeman Jenkins?\n\nI understand now: ASF and my Jenkins don't set tests.haltonfailure to false (except on ASF Clover jobs), so once a test fails in a module, further modules' tests never get run, and since Nightly tests fail with extreme regularity in Solr core, the contrib tests are never being run. (I can't see Policeman Jenkins Groovy script that sets sysprops scripts/linux-random-java8.groovy - Uwe Schindler do you know about Policeman Jenkins's use of tests.haltonfailure?)\n\nThe difference for my Jenkins is how tests are run, via a script that runs 4 Ant processes in parallel, and Solrj and contrib tests are run in a separate Ant process.  So Solr core failures don't stop contrib tests from running (though Solrj failures do).\n\nI've started a nightly manual run with tests.haltonfailure=false, and I also added that to my Jenkins scripts.  I'm not really sure why it ever makes for Jenkins to run with it set to true?  If things go well (i.e. tests.haltonfailure does what I think it does), I'll add it to all the ASF and Policeman Jenkins jobs too. ",
            "id": "comment-15377621"
        },
        {
            "date": "2016-07-14T18:12:22+0000",
            "author": "Mark Miller",
            "content": "Ill take a look.\n\nNightly tests fail with extreme regularity in Solr core\n\nI think i have a jira for this somewhere - I've tried to start tackling it before, but it's a big job. ",
            "id": "comment-15377897"
        },
        {
            "date": "2016-07-14T19:52:38+0000",
            "author": "Uwe Schindler",
            "content": "Policeman Jenkins dies mit der haltonfailure to false. I wanted to try that, too. Especially to also run all precommit and javadocs tasks.\n\nTo do this just add a line in the ant config of Jenkins jobs (don't add to cmd line, there is a separate input box for properties).\n\nI just ranted to make sure that the junit plugin on Jenkins fails build at very end after parsing the XML test reports. I think it should do this.\n\nI will try this later.\n\nIts a good idea. ",
            "id": "comment-15378241"
        },
        {
            "date": "2016-07-22T18:27:11+0000",
            "author": "ASF subversion and git services",
            "content": "Commit a6655a9d39cbfd0f8c85eceee00eab1f64d24023 in lucene-solr's branch refs/heads/branch_6x from Steve Rowe\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=a6655a9 ]\n\nSOLR-9076: disable broken nightly tests MorphlineBasicMiniMRTest and MorphlineGoLiveMiniMRTest via @AwaitsFix ",
            "id": "comment-15389994"
        },
        {
            "date": "2016-07-22T18:27:12+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 85a585c51698edd823769a159856524407cf6456 in lucene-solr's branch refs/heads/master from Steve Rowe\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=85a585c ]\n\nSOLR-9076: disable broken nightly tests MorphlineBasicMiniMRTest and MorphlineGoLiveMiniMRTest via @AwaitsFix ",
            "id": "comment-15389995"
        },
        {
            "date": "2017-03-24T17:14:18+0000",
            "author": "Steve Rowe",
            "content": "Closing now that the kite/morphlines/map-reduce contribs have been removed, so the test failures are no longer an issue: SOLR-9221. ",
            "id": "comment-15940758"
        }
    ]
}