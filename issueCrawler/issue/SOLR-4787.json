{
    "id": "SOLR-4787",
    "title": "Join Contrib",
    "details": {
        "affect_versions": "4.2.1",
        "status": "Open",
        "fix_versions": [
            "6.0"
        ],
        "components": [
            "search"
        ],
        "type": "New Feature",
        "priority": "Minor",
        "labels": "",
        "resolution": "Unresolved"
    },
    "description": "This contrib provides a place where different join implementations can be contributed to Solr. This contrib currently includes 3 join implementations. The initial patch was generated from the Solr 4.3 tag. Because of changes in the FieldCache API this patch will only build with Solr 4.2 or above.\n\nHashSetJoinQParserPlugin aka hjoin\n\nThe hjoin provides a join implementation that filters results in one core based on the results of a search in another core. This is similar in functionality to the JoinQParserPlugin but the implementation differs in a couple of important ways.\n\nThe first way is that the hjoin is designed to work with int and long join keys only. So, in order to use hjoin, int or long join keys must be included in both the to and from core.\n\nThe second difference is that the hjoin builds memory structures that are used to quickly connect the join keys. So, the hjoin will need more memory then the JoinQParserPlugin to perform the join.\n\nThe main advantage of the hjoin is that it can scale to join millions of keys between cores and provide sub-second response time. The hjoin should work well with up to two million results from the fromIndex and tens of millions of results from the main query.\n\nThe hjoin supports the following features:\n\n1) Both lucene query and PostFilter implementations. A \"cost\" > 99 will turn on the PostFilter. The PostFilter will typically outperform the Lucene query when the main query results have been narrowed down.\n\n2) With the lucene query implementation there is an option to build the filter with threads. This can greatly improve the performance of the query if the main query index is very large. The \"threads\" parameter turns on threading. For example threads=6 will use 6 threads to build the filter. This will setup a fixed threadpool with six threads to handle all hjoin requests. Once the threadpool is created the hjoin will always use it to build the filter. Threading does not come into play with the PostFilter.\n\n3) The size local parameter can be used to set the initial size of the hashset used to perform the join. If this is set above the number of results from the fromIndex then the you can avoid hashset resizing which improves performance.\n\n4) Nested filter queries. The local parameter \"fq\" can be used to nest a filter query within the join. The nested fq will filter the results of the join query. This can point to another join to support nested joins.\n\n5) Full caching support for the lucene query implementation. The filterCache and queryResultCache should work properly even with deep nesting of joins. Only the queryResultCache comes into play with the PostFilter implementation because PostFilters are not cacheable in the filterCache.\n\nThe syntax of the hjoin is similar to the JoinQParserPlugin except that the plugin is referenced by the string \"hjoin\" rather then \"join\".\n\nfq={!hjoin fromIndex=collection2 from=id_i to=id_i threads=6 fq=$qq}user:customer1&qq=group:5\n\nThe example filter query above will search the fromIndex (collection2) for \"user:customer1\" applying the local fq parameter to filter the results. The lucene filter query will be built using 6 threads. This query will generate a list of values from the \"from\" field that will be used to filter the main query. Only records from the main query, where the \"to\" field is present in the \"from\" list will be included in the results.\n\nThe solrconfig.xml in the main query core must contain the reference to the hjoin.\n\n<queryParser name=\"hjoin\" class=\"org.apache.solr.joins.HashSetJoinQParserPlugin\"/>\n\nAnd the join contrib lib jars must be registed in the solrconfig.xml.\n\n <lib dir=\"../../../contrib/joins/lib\" regex=\".*\\.jar\" />\n\nAfter issuing the \"ant dist\" command from inside the solr directory the joins contrib jar will appear in the solr/dist directory. Place the the solr-joins-4.*-.jar  in the WEB-INF/lib directory of the solr webapplication. This will ensure that the top level Solr classloader loads these classes rather then the core's classloaded. \n\n\nBitSetJoinQParserPlugin aka bjoin\n\nThe bjoin behaves exactly like the hjoin but uses a BitSet instead of a HashSet to perform the underlying join. Because of this the bjoin is much faster and can provide sub-second response times on result sets of tens of millions of records from the fromIndex and hundreds of millions of records from the main query.\n\nBut there are limitations to how the bjoin can be used. The bjoin treats the join keys as addresses in a BitSet and uses the Lucene OpenBitSet implementation which performs very well but is not sparse. So the BitSet memory is dictated by the size of the join keys. For example a bitset with a max join key of 200,000,000 will need 25 MB of memory. For this reason the BitSet join does not support long join keys. In order to keep memory usage down the join keys should also be packed at the low end, for example from 1 to 50,000,000. \n\nBelow is a sampe bjoin:\n\nfq={!bjoin fromIndex=collection2 from=id_i to=id_i threads=6 fq=$qq}user:customer1&qq=group:5\n\nTo register the bjoin the solrconfig.xml in the main query core must contain the reference to the bjoin.\n\n<queryParser name=\"bjoin\" class=\"org.apache.solr.joins.BitSetJoinQParserPlugin\"/>\n\nValueSourceJoinParserPlugin aka vjoin\n\nThe second implementation is the ValueSourceJoinParserPlugin aka \"vjoin\". This implements a ValueSource function query that can return a value from a second core based on join keys and limiting query. The limiting query can be used to select a specific subset of data from the join core. This allows customer specific relevance data to be stored in a separate core and then joined in the main query.\n\nThe vjoin is called using the \"vjoin\" function query. For example:\n\nbf=vjoin(fromCore, fromKey, fromVal, toKey, query)\n\nThis example shows \"vjoin\" being called by the edismax boost function parameter. This example will return the \"fromVal\" from the \"fromCore\". The \"fromKey\" and \"toKey\" are used to link the records from the main query to the records in the \"fromCore\". The \"query\" is used to select a specific set of records to join with in fromCore.\n\nCurrently the fromKey and toKey must be longs but this will change in future versions. Like the pjoin, the \"join\" SolrCache is used to hold the join memory structures.\n\nTo configure the vjoin you must register the ValueSource plugin in the solrconfig.xml as follows:\n\n<valueSourceParser name=\"vjoin\" class=\"org.apache.solr.joins.ValueSourceJoinParserPlugin\" />",
    "attachments": {
        "SOLR-4797-hjoin-multivaluekeys-trunk.patch": "https://issues.apache.org/jira/secure/attachment/12603892/SOLR-4797-hjoin-multivaluekeys-trunk.patch",
        "SOLR-4787-with-testcase-fix.patch": "https://issues.apache.org/jira/secure/attachment/12640234/SOLR-4787-with-testcase-fix.patch",
        "SOLR-4797-hjoin-multivaluekeys-nestedJoins.patch": "https://issues.apache.org/jira/secure/attachment/12632860/SOLR-4797-hjoin-multivaluekeys-nestedJoins.patch",
        "SOLR-4787.patch": "https://issues.apache.org/jira/secure/attachment/12581844/SOLR-4787.patch",
        "SOLR-4787-pjoin-long-keys.patch": "https://issues.apache.org/jira/secure/attachment/12593631/SOLR-4787-pjoin-long-keys.patch",
        "SOLR-4787-deadlock-fix.patch": "https://issues.apache.org/jira/secure/attachment/12589626/SOLR-4787-deadlock-fix.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Joel Bernstein",
            "id": "comment-13649506",
            "date": "2013-05-06T03:40:06+0000",
            "content": "Initial pjoin and vjoin contrib.\n\nTODO: Tests need to be created and the vjoin has some insanity issues with the FieldCache that will eventually be solved by using on-disk DocValues. "
        },
        {
            "author": "Jack Krupansky",
            "id": "comment-13649511",
            "date": "2013-05-06T03:53:46+0000",
            "content": "Is there any particular reason that only integer keys can be used for the join key, as opposed to, say, string keys?\n\nCan the implementation be readily adapted to string join keys? "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13649512",
            "date": "2013-05-06T04:04:42+0000",
            "content": "The integer keys are faster to join and take up less memory in the in-memory join structures. So, string keys won't scale nearly as well. It may be possible to make them work, but it might scale about the same as the JoinQParserPlugin. Possibly other high performance string joins can be contribed as well.  "
        },
        {
            "author": "David Smiley",
            "id": "comment-13649530",
            "date": "2013-05-06T05:27:10+0000",
            "content": "Nice Joel!  I've done a custom join query recently but it's a bit different than either of yours.  I read your pjoin code in particular and it looks very good, mostly.  Your BSearch class is the only thing that made me frown.  Instead of putting each name-value pair into their own key class (which isn't GC friendly), I suggest you take a look at Lucene's SorterTemplate which will allow you to collect your key & value integers directly into an array each, and then sort in-place when done.  I like your idea on caching the join; I should do that with mine. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13649692",
            "date": "2013-05-06T12:20:37+0000",
            "content": "Thanks David! Yeah, agreed the BSearch class is not ideal. I'll have a look at the SorterTemplate and get the integers sorted in place. "
        },
        {
            "author": "Adrien Grand",
            "id": "comment-13649695",
            "date": "2013-05-06T12:31:11+0000",
            "content": "Hi Joel. SorterTemplate has just been refactored into org.apache.lucene.util.Sorter (LUCENE-4946). You can have a look at Passage.sort() (https://svn.apache.org/repos/asf/lucene/dev/trunk/lucene/highlighter/src/java/org/apache/lucene/search/postingshighlight/Passage.java) to see how to use it to sort parallel arrays. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13649704",
            "date": "2013-05-06T12:46:08+0000",
            "content": "Hi Adrien, thanks for the information. I'll take a look at the Sorter today. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13650063",
            "date": "2013-05-06T20:15:36+0000",
            "content": "Changed the BSearch class to use the SorterTemplate rather then Collections.sort. Much more efficient inplace sorting. SorterTemplate builds with Solr 4.2.1. Will need to get this working with trunk as well using the new Sorter class.\n\nThanks David and Adrien for tips on this.\n\nFound major bug in my original logic for how segment level readers were being used between the join cores and fixed that as well. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13652704",
            "date": "2013-05-09T03:12:28+0000",
            "content": "vjoin now uses DocValues if available. "
        },
        {
            "author": "Kevin Watters",
            "id": "comment-13652997",
            "date": "2013-05-09T14:57:55+0000",
            "content": "Hey Joel, \n  It was good to meet you at the conference last week.  We talked a little bit about my GraphQuery operator.  The use case of a 1 level graph traversal can accomplish a post filter join request.  The caviot is that you won't know which record was joined to, only that it did satisfy the join requirement.  I could contribute it here, or perhaps we could create a Graph Contrib ticket?\nThanks,\n  -Kevin "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13653009",
            "date": "2013-05-09T15:17:33+0000",
            "content": "Hi Kevin,\n\nGreat to meet you as well. Very interested in your GraphQuery. Probably best to create your own ticket and then we can link the tickets. You could do a Graph contrib and we can decide later on if we want a single join contrib.\n\nThanks,\nJoel "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13653109",
            "date": "2013-05-09T19:53:11+0000",
            "content": "Fixed bug with vjoin where it was including deleted docs in the join. Now vjoin only uses live docs. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13654610",
            "date": "2013-05-10T17:06:23+0000",
            "content": "Added vjoin2 and broke out several inner classes into there own class. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13654654",
            "date": "2013-05-10T17:46:24+0000",
            "content": "Removed confusing comments from vjoin2 that were copied over from vjoin. "
        },
        {
            "author": "Kranti Parisa",
            "id": "comment-13669372",
            "date": "2013-05-29T16:11:00+0000",
            "content": "Hi Joel, idea looks really great. Is it too costly to implement this with \"long\" instead of \"integers\"? with longs we can support bigger numbers which could be part of the \"key\" fields.\n\nplease share your ideas. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13669420",
            "date": "2013-05-29T16:45:05+0000",
            "content": "Longs will double the memory overhead but performance will be the same.\n\nWhich join are you interested in?  "
        },
        {
            "author": "Kranti Parisa",
            "id": "comment-13669430",
            "date": "2013-05-29T16:55:09+0000",
            "content": "Yes, I think RAM is not that costly these days. As long as performance won't be impacted too much, longs would give greater flexibility when the \"keys\" needs to hold big numbers.\n\nI am looking at JoinValueSourceParserPlugin2, this can fetch scores/values from the \"fromCore\" right? "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13669518",
            "date": "2013-05-29T18:04:27+0000",
            "content": "Performance with longs should be as good as with ints.\n\nYes, JoinValueSourceParserPlugin2 fetches values from the fromCore. This is actually the join I'm most interested in as well.\n\nI'll be revisiting this ticket soon to add tests, long support and probably write a blog about the JoinValueSourceParserPlugin2. In the meantime let me know if you need more information to get it running.  "
        },
        {
            "author": "Kranti Parisa",
            "id": "comment-13669538",
            "date": "2013-05-29T18:22:29+0000",
            "content": "Great, thanks. I am sure it will help many use cases. I am trying to fetch the \"id\" field from the \"secondCore\" using the join between \"parentId_secondCore\" and \"id_firstCore\"\n\nI want to give it a try for the long support. do we want to have an additional param which tell us what data structures to use? and by default it uses int? what's the best way?  "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13669567",
            "date": "2013-05-29T18:50:53+0000",
            "content": "We can get this information from the schema by looking at the data types from the to and from field.\n\nJust reviewed the code and you'll have one big hurdle with getting longs to work.\n\nThe BSearch class uses the Lucene SorterTemplate to sort a parallel array. The SorteTemplate does not have long support. So if you want to use the same approach you'll have find another way to sort the parallel array. \n\nDo you have to have long support, or is it just a nice to have?\n "
        },
        {
            "author": "Kranti Parisa",
            "id": "comment-13669578",
            "date": "2013-05-29T18:57:51+0000",
            "content": "Getting info from the schema is a good approach.\n\nAbout long support, my \"key\" fields in the data set are longs.  "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13669583",
            "date": "2013-05-29T19:04:25+0000",
            "content": "If they are actual longs (greater then 2147483647) and not just defined that way in the schema, then you'll need long support.\n\nOtherwise we can cast them to ints in memory and use them. "
        },
        {
            "author": "Kranti Parisa",
            "id": "comment-13669643",
            "date": "2013-05-29T20:02:22+0000",
            "content": "yes, the numbers are greater than 2147483647! "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13670678",
            "date": "2013-05-30T20:27:59+0000",
            "content": "I'd like to switch this to a hash join rather then using the binary search anyway. For longs it would be great to use a HashMap that works with primitive keys, like Trove. Trove is LGPL I believe so I don't think we can use it though.\n\nI'll look around and see if I can find another library that does what Trove does. \n\nLet me know if you know of another one or you've got an implementation lying around. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13670679",
            "date": "2013-05-30T20:30:28+0000",
            "content": "Colt looks promising and it's under the Cern license which is very permissive. I'll test it out. "
        },
        {
            "author": "Kranti Parisa",
            "id": "comment-13671031",
            "date": "2013-05-31T01:05:34+0000",
            "content": "Even I have been using Trove lib. Along with Colt, the following looks interesting too\nhttp://javolution.org/core-java/target/apidocs/javolution/util/FastMap.html\nhttps://code.google.com/p/guava-libraries/ "
        },
        {
            "author": "David Smiley",
            "id": "comment-13671104",
            "date": "2013-05-31T03:28:50+0000",
            "content": "I suggest either FastUtil, or the similar HPPC (by Dawid Weiss here at the ASF).  \n\nFor a single class it may make sense to copy it in source from.  That kinda makes me cringe but for just one source file and for something that is externally tested and unlikely to have an unknown bug, I think it's fine. "
        },
        {
            "author": "Dawid Weiss",
            "id": "comment-13671199",
            "date": "2013-05-31T06:32:10+0000",
            "content": "Pull a class or two in source code form from fastutil or from HPPC. These are nearly identical these days, fastutil has support for Java collections interfaces (HPPC has its own API not stemming from JUC). Both of these are equally fast. "
        },
        {
            "author": "Dawid Weiss",
            "id": "comment-13671200",
            "date": "2013-05-31T06:33:15+0000",
            "content": "Oh, one more thing \u2013 Colt is no longer maintained and there were a number of bugs in it. These have been fixed when Colt was ported to Apache Mahout; those classes are not part of Mahout Math.\n\nI'd still recommend using Fastutil or Hppc since these will be faster (by an inch but always). "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13673478",
            "date": "2013-06-03T19:40:49+0000",
            "content": "Thanks for the recommendations, FastUtil looks great. I'm going to switch the JoinValueSourceParserPlugin2 over to use a hash join on long keys.\n "
        },
        {
            "author": "Kranti Parisa",
            "id": "comment-13673481",
            "date": "2013-06-03T19:43:09+0000",
            "content": "great, thanks Joel. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13677082",
            "date": "2013-06-06T15:05:25+0000",
            "content": "New patch. \n\n\nJoinValueSourceParserPlugin2 has been renamed the ValueSourceJoinParserPlugin. It also now supports long join keys only. This will be changed soon to support both int and long join keys.\n\nA README.txt has been added which explains the setup.\n\nMany other changes as well that will be reflected in the ticket description.\n\n "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13677149",
            "date": "2013-06-06T15:38:18+0000",
            "content": "Kranti,\n\nThe vjoin has two performance hotspots:\n\n1) The creation of the HashMap for the hashjoin. My testing shows that it can load 2-3 million key/pairs in around 200 milliseconds. \n\n\n2) The hash key lookup each time the vjoin is called. This will be called for each document that is scored in the result set. This should scale to support result sets into the millions. I tested with 4,000,000 results and had excellent performance.\n\n\n "
        },
        {
            "author": "Kranti Parisa",
            "id": "comment-13678038",
            "date": "2013-06-07T13:55:23+0000",
            "content": "Joel,\n\nThanks for the information. I shall update the plugin and test the same.  "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13679527",
            "date": "2013-06-10T14:17:44+0000",
            "content": "Switched from fastutil to hppc for the primitive map used for the hashjoin.\n\nAlso, further performance testing has shown that the performance on loading the LongInt hash map was much better then I initially thought. The vjoin will scale comfortably into the millions of keys as well. "
        },
        {
            "author": "Kranti Parisa",
            "id": "comment-13691612",
            "date": "2013-06-23T21:38:11+0000",
            "content": "I am trying to apply this patch on branch_4x code (http://svn.apache.org/repos/asf/lucene/dev/branches/branch_4x). but getting the following error, any idea?\n\nwget https://issues.apache.org/jira/secure/attachment/12587067/SOLR-4787.patch -O - | patch -p0 --dry-run\n\n-2013-06-23 17:35:32-  https://issues.apache.org/jira/secure/attachment/12587067/SOLR-4787.patch\nResolving issues.apache.org... 140.211.11.121\nConnecting to issues.apache.org|140.211.11.121|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 26641 (26K) [text/x-patch]\nSaving to: `STDOUT'\n\n100%[===========================================================>] 26,641       143K/s   in 0.2s\n\n2013-06-23 17:35:32 (143 KB/s) - written to stdout [26641/26641]\n\npatching file solr/example/solr/collection1/conf/solrconfig.xml\nHunk #1 FAILED at 81.\nHunk #2 succeeded at 515 (offset -2 lines).\nHunk #3 succeeded at 564 (offset -2 lines).\nHunk #4 succeeded at 1535 (offset 6 lines).\nHunk #5 succeeded at 1548 (offset 6 lines).\nHunk #6 succeeded at 1788 (offset 6 lines).\nHunk #7 succeeded at 1803 (offset 6 lines).\n1 out of 7 hunks FAILED \u2013 saving rejects to file solr/example/solr/collection1/conf/solrconfig.xml.rej\npatching file solr/example/exampledocs/mem.xml\npatching file solr/contrib/joins/ivy.xml\npatching file solr/contrib/joins/src/java/org/apache/solr/joins/CacheSet.java\npatching file solr/contrib/joins/src/java/org/apache/solr/joins/SegmentBitSetCollector.java\npatching file solr/contrib/joins/src/java/org/apache/solr/joins/PostFilterJoinQParserPlugin.java\npatching file solr/contrib/joins/src/java/org/apache/solr/joins/ValueSourceJoinParserPlugin.java\npatching file solr/contrib/joins/README.txt\npatching file solr/contrib/joins/build.xml "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13691661",
            "date": "2013-06-24T01:43:29+0000",
            "content": "Kranti,\n\nI'm going to remove the solrconfig.xml changes so the patch does not complain with 4.x branch. I'll make sure the README.txt explains the changes that need to be made in the solconfig.xml. I should be able to put this up tomorrow.\n "
        },
        {
            "author": "Kranti Parisa",
            "id": "comment-13691990",
            "date": "2013-06-24T14:05:58+0000",
            "content": "cool, thanks. "
        },
        {
            "author": "Steven Bower",
            "id": "comment-13693155",
            "date": "2013-06-25T16:55:12+0000",
            "content": "Attached is a patch (that applies on top of the latest base patch) that fixes an issue where a deadlock is caused when the fromCore is equal to the \"current\" core.. Basically I think what happens is that the searcher gets decref'd twice in this case causing the thread leak detection stuff in a unit test I wrote to hang waiting for this thread to die. "
        },
        {
            "author": "Steven Bower",
            "id": "comment-13693163",
            "date": "2013-06-25T17:05:54+0000",
            "content": "New file with proper paths and a unit test, which if run with the original PostFilterJoinQParserPlugin will produce the deadlock "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13693215",
            "date": "2013-06-25T18:01:22+0000",
            "content": "Kranti,\n\nThe latest patch will apply cleanly on Solr 4x. The README.txt file has the configuration steps that are needed to get the vjoin working.\n\nThe pjoin is not covered in the README.txt but it will be shortly. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13693218",
            "date": "2013-06-25T18:07:05+0000",
            "content": "Steven,\n\nThanks for the patch. I'll add this to the main patch this week. \n\nI'm currently working on a third, more scalable, join implementation.\n\nIf anyone knows of a good sparse bitset implementation please let me know. \n\nJoel  "
        },
        {
            "author": "Kranti Parisa",
            "id": "comment-13694851",
            "date": "2013-06-27T16:38:37+0000",
            "content": "Joel,\n\nI am able to get the fields from the other core, pretty cool. (there are minor gaps in the README.txt and ant build scripts to include joins, hpcc jar files)\n\nSeems we have limitation of returning only INTs, can we support LONGs? means can we change the implementation to use LongLongOpenHashMap?\n\n\n\tKranti\n\n "
        },
        {
            "author": "Kranti Parisa",
            "id": "comment-13694902",
            "date": "2013-06-27T17:40:16+0000",
            "content": "if we have the following case\n\nPARENT CORE\n============\nID Field\n----------\np1\np2\np3\n\nCHILD CORE\n============\nID Field    |   Parent ID field  |  ValueToFetch Field\n---------------------------------------------------------------------\nc1     |         p1          |           1234\nc2      |        p1           |          3456\n\n\nThen ValueToFetch will be the last one (in this case: 3456)\n\nMay be we should think of doing \n\n1. Allow sort parameter to the vjoin function\n\n2. consider the Sort when executing the query\n\n3. for each PARENT ID, pick up the first ValueToFetch and ignore the rest (as we are specifying the sort preference, we are saying to collect the top document)\n\n4. sort param could have multiple values like general solr sort\n\nso vjoin will look like \nvjoin(joinCore, foreignKey, foreignVal, primaryKey, query, $vSort)\n\n&vSort=field1 desc, field2 asc\n\n5. if no sort param is specified then current implementation works (picking the the value from the last document)\n\nJoel, your ideas?  "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13695221",
            "date": "2013-06-28T01:56:06+0000",
            "content": "Kranti,\n\nGlad it's working for you. The one-to-many join is tricky as it is in a relational database.\n\nThe sort idea has some implementation problems. Currently the query on the fromCore only collects the BitSet containing the matching docs. So the normal sorting collectors aren't used here. Putting them in play will cause scalability issues.\n\nOne thing we could do is either take the MIN or MAX value. There would be a performance hit here as well but not nearly as much as the sort approach. The syntax could be \n\nvjoin(fromCore, fromKey, fromValue, toKey, query, MIN|MAX)\n\nI have no problems switching to the LongLongOpenHashMap.\n\nThe next thing I planned to do on this ticket is support both integers and longs.\n\nJoel\n\n "
        },
        {
            "author": "Kranti Parisa",
            "id": "comment-13695802",
            "date": "2013-06-28T21:12:28+0000",
            "content": "Joel,\n\nYes, sort implementation would be costly, I did review the code. \nI think having the option for MIN/MAX would help in few cases, and if we pass that as null then we are same as with current implementation.\n\nHaving LongLongOpenHashMap would really help.\n\n-\nKranti "
        },
        {
            "author": "Kranti Parisa",
            "id": "comment-13715925",
            "date": "2013-07-23T00:39:40+0000",
            "content": "Joel,\n\nI wanted to try implementing pjoin for the following use case.\n\nmasterCore = 1M keys (id field, long)\nchildCore = 5M documents (with parentid field, long, whose values are equal to the values of id field in the masterCore\n\nAnd syntax looks like\nhttp://localhost:8180/solr/masterCore/select?q=title:a&fq=(\n{!pjoin%20fromIndex=childCore%20from=parentid%20to=id%20v=$childQ}\n)&childQ=(fieldOne:somevalue AND fieldTwo:[1 TO 100])\n\nI am getting SyntaxError, but the same syntax works with normal \"join\". any ideas?\n\nAlso it seems currently pjoin supports only int keys, can you please update pjoin to allow long keys\n\n-\nKranti\n "
        },
        {
            "author": "Kranti Parisa",
            "id": "comment-13715944",
            "date": "2013-07-23T00:59:32+0000",
            "content": "I did review the PostFilterJoinQParserPlugin code and found that it was expecting \"fromCore\" instead of \"fromIndex\" (like in normal Join)\n\nafter trying \"fromCore\" now getting the expected error related to INT keys, as my keys are Long.\n\n\n\t\nKranti\n\n "
        },
        {
            "author": "Kranti Parisa",
            "id": "comment-13715987",
            "date": "2013-07-23T02:32:49+0000",
            "content": "Attached the patch file (SOLR-4787-pjoin-long-keys.patch) for PostFilterJoinQParserPlugin to support LONG keys "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13716342",
            "date": "2013-07-23T12:20:24+0000",
            "content": "Kranti,\n\nLet me know how the pjoin is performing for you. I'm going to be testing out some different data structures for the pjoin to see if I can get better performance. "
        },
        {
            "author": "Kranti Parisa",
            "id": "comment-13716380",
            "date": "2013-07-23T13:25:07+0000",
            "content": "Joel,\n\nInitial performance results looks like:\n(Restarted solr - hence no caches at the beginning)\n\n\n\twith no cache: pjoin is 2-3 times faster than join\n\twith cache: pjoin is 3-4 times slower than join\n\n\n\nAgree with your idea, we should try with other data structures and may be a look at the caching strategy used in pjoin.\n\nAre the queries already running in parallel to find the intersection? "
        },
        {
            "author": "Steve Rowe",
            "id": "comment-13717174",
            "date": "2013-07-23T18:47:21+0000",
            "content": "Bulk move 4.4 issues to 4.5 and 5.0 "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13717540",
            "date": "2013-07-23T19:55:09+0000",
            "content": "Kranti,\n\nOdd that the pjoin cache is making things slower. I'll do some testing and see if I can turn up the same results. \n\nThe join query runs first and builds a data structure in memory that is used to post filter the main query. The main query then runs and the post filter is applied.\n\nI'm exploring another scenario that will perform 5x faster then the current pjoin. But the tradeoff is a longer warmup time when a new searcher is opened.\n\nDo you have real-time indexing requirements or can you live with some warm-up time.\n\n "
        },
        {
            "author": "Kranti Parisa",
            "id": "comment-13717553",
            "date": "2013-07-23T20:08:53+0000",
            "content": "Joel,\n\nThanks for the details. Yes, we do some real-time indexing. Say, every 30min we get deltas. how much warmup time that we are looking at for 5M docs?\n\nAlso, if we have more than one pjoins in the fq, each points to their own cores, can those pjoins be executed in parallel and find the intersection which will finally be applied as a filter for the main query? "
        },
        {
            "author": "Steven Bower",
            "id": "comment-13746126",
            "date": "2013-08-21T15:29:31+0000",
            "content": "When using the pJoin is relevance still applied to the results on the left side of the join? "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13746647",
            "date": "2013-08-21T18:04:23+0000",
            "content": "Yes, the main query still has relevance applied. The filter join query does not impact relevance though.\n\nThere is going to be a large set of code changes to this ticket, probably next week. The implementation of the pjoin is changing and another more scalable join will be added as well.\n\nThe vjoin is going to remain the same for the time being. "
        },
        {
            "author": "Kranti Parisa",
            "id": "comment-13746912",
            "date": "2013-08-21T22:09:20+0000",
            "content": "Joel:\n\nThat's cool, thanks. Did you ever thought of supporting \"fq\" parameter for the Join, like how we support for \"v\" for query. the idea is to use filter cache on the child core while executing the join query. \n "
        },
        {
            "author": "David Smiley",
            "id": "comment-13747147",
            "date": "2013-08-22T01:52:26+0000",
            "content": "Excellent suggestion Kranti Parisa on supporting filter queries on the from-side of the join.  I implemented a custom join query and it has a from-side filter query feature.  It can help a great deal with performance.  It wasn't that hard to add, either. "
        },
        {
            "author": "Kranti Parisa",
            "id": "comment-13747155",
            "date": "2013-08-22T02:06:26+0000",
            "content": "That's awesome! Yes, for sure it would be a big deal for performance especially it will allow us to cache the majority of the join query which could be common for all the cases. Once it's filter cached, we can run additional clases thru normal queries super fast!\n\nI was thinking to add a new local-param to support \"fq\". If you already have something, do you want to share? "
        },
        {
            "author": "David Smiley",
            "id": "comment-13747166",
            "date": "2013-08-22T02:27:40+0000",
            "content": "I don't have the rights to it but I'll share the most pertinent line of code:\n\nSolrIndexSearcher.ProcessedFilter processedFilter =\n            searcher.getProcessedFilter(null, filters);\n\n\n\nSee, Solr does most of the work with that one line call; everything else, such as parsing the queries is easy/common stuff. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13747168",
            "date": "2013-08-22T02:29:45+0000",
            "content": "I'll put up what I've been working on tomorrow. One of the joins I'll be adding supports the \"fq\" on the from side of join. These joins also support both PostFilter and traditional filter query joins.  "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13747170",
            "date": "2013-08-22T02:31:34+0000",
            "content": "Yeah, that's the exact approach I took David.\n\nThis was added to support nested joins but I see how the caching could really speed up the whole join.\n "
        },
        {
            "author": "Kranti Parisa",
            "id": "comment-13747172",
            "date": "2013-08-22T02:33:07+0000",
            "content": "Great, thanks! "
        },
        {
            "author": "Kranti Parisa",
            "id": "comment-13747175",
            "date": "2013-08-22T02:47:24+0000",
            "content": "Nested Joins! That's exactly what I am trying  and thought about adding fq to the solr joins.\n\nUsing local-param in the first join:\n\n {!join fromIndex=a from=f1 to=f2 v=$joinQ}&joinQ=(field:123 AND _query_={another join})\n\n. So here \"another join\" could be passed as a FQ and it should get results faster!! Hence the above, query would look like,\n\n\n {!join fromIndex=a from=f1 to=f2 v=$joinQ fq=$joinFQ}&joinQ=(field:123)&joinFQ={another join}\n "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13747907",
            "date": "2013-08-22T21:25:22+0000",
            "content": "That's exactly the syntax. I'm just working out the caching details and then I'll put up the code.\n\nGetting the queryResultCache and FilterCache to play nicely with nested joins is tricky. "
        },
        {
            "author": "Kranti Parisa",
            "id": "comment-13747912",
            "date": "2013-08-22T21:37:54+0000",
            "content": "Cool, will you be able to put the code up here sometime tomorrow? I want to apply that patch and see how it performs. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13747915",
            "date": "2013-08-22T21:42:24+0000",
            "content": "Yes. I'm very close now. I'll also need to write some quick docs because these joins have a lot more functionality.  "
        },
        {
            "author": "Kranti Parisa",
            "id": "comment-13747919",
            "date": "2013-08-22T21:45:20+0000",
            "content": "Awesome! "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13748467",
            "date": "2013-08-23T11:22:44+0000",
            "content": "New patch. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13749431",
            "date": "2013-08-24T17:12:51+0000",
            "content": "Any recommendations for a good sparse bitset implementation? "
        },
        {
            "author": "David Smiley",
            "id": "comment-13749462",
            "date": "2013-08-24T20:51:31+0000",
            "content": "See these exciting additions to Lucene 4.5:\n\n\tLUCENE-5084: Added new Elias-Fano encoder, decoder and DocIdSet\n  implementations. (Paul Elschot via Adrien Grand)\n\n\n\n\n\tLUCENE-5081: Added WAH8DocIdSet, an in-memory doc id set implementation based\n  on word-aligned hybrid encoding. (Adrien Grand)\n\n "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13749757",
            "date": "2013-08-25T22:27:21+0000",
            "content": "These are great additions. Not sure I can apply them here though because I'm not setting the bits in order. I'm going to need a random access sparse implementation. I've seen some but they are LGPL.  "
        },
        {
            "author": "Kranti Parisa",
            "id": "comment-13750854",
            "date": "2013-08-27T01:24:46+0000",
            "content": "Joel,\n\nSeems there is something wrong with nested hjoin.\n\nExample:\n\n\n/masterCore/select?q=*:*&fq=({!hjoin fromIndex=ACore from=parentid to=id v=$aQ fq=$BJoinQ})&aQ=(f1:false)&BJoinQ=({!join fromIndex=BCore from=bid to=aid}tag:abc)\n\n\nThe above query gives me 25558 results\n\nand when I try both joins with hjoin, as follows, it gives me 1 document\n\n\n/masterCore/select?q=*:*&fq=({!hjoin fromIndex=ACore from=parentid to=id v=$aQ fq=$BJoinQ})&aQ=(f1:false)&BJoinQ=({!hjoin fromIndex=BCore from=bid to=aid}tag:abc)\n\n\nam I missing anything? "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13751190",
            "date": "2013-08-27T11:32:41+0000",
            "content": "Are all join keys single value? Currently the hjoin and bjoin only support single value join keys. "
        },
        {
            "author": "Kranti Parisa",
            "id": "comment-13751201",
            "date": "2013-08-27T11:57:39+0000",
            "content": "The values in \"to\" fields are single values but \"from\" fields are multi valued. does this mean that the implementation need significant changes to support multi values? I will take a look at the code today. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13751206",
            "date": "2013-08-27T12:10:51+0000",
            "content": "Right now there aren't really efficient memory structures to perform the joins on multi-value fields. Our best bet right now would be the SORTED_SET docValues described http://wiki.apache.org/solr/DocValues. But this is not really designed for integers or longs.\n\nI think the best way to handle this is to fully normalize the data so that the join keys are single valued. Basically model the data the way you would in a relational database then use the nested joins to join the normalized indexes together.  "
        },
        {
            "author": "Kranti Parisa",
            "id": "comment-13751237",
            "date": "2013-08-27T13:02:36+0000",
            "content": "I have 5 million documents (might increase in future) each having 10 values in the parentid field. So if we normalize the size of the index would become 50 million documents which would slow down the indexing as well search. I don't mind trying with String keys with DocValues (SORTED_SET) if it works. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13751240",
            "date": "2013-08-27T13:06:19+0000",
            "content": "The current implementation doesn't support the multi-value fields though. So it will need to be implemented.\n "
        },
        {
            "author": "Kranti Parisa",
            "id": "comment-13765915",
            "date": "2013-09-12T21:28:54+0000",
            "content": "Joel, I modified the JoinQParserPlugin (default one) to allow FQs. It seems to be working fine, I will need to test more for caches/performance. Do you have any updates for supporting multi-valued keys with hjoin or bjoin? "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13766446",
            "date": "2013-09-13T12:46:28+0000",
            "content": "Kranti, the bjoin now supports multi-value fields. I'll work on getting the patch up here today. "
        },
        {
            "author": "Kranti Parisa",
            "id": "comment-13766601",
            "date": "2013-09-13T16:26:51+0000",
            "content": "That's cool. Once it is up, I will run some performance tests and post my findings. So it also supports FQs for nested joins and uses filter caches, right? "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13766609",
            "date": "2013-09-13T16:38:27+0000",
            "content": "Kranti, new patch is up with the bjoin that supports multi-value fields. It supports nested fq and filter caching as well.\n\nI won't be able to work on the hjoin for a while, so feel free to port the multi-value field support to hjoin. "
        },
        {
            "author": "Kranti Parisa",
            "id": "comment-13766657",
            "date": "2013-09-13T17:15:30+0000",
            "content": "Yes, will first test the bjoin for multi-valued fields and then try to extend hjoin for multi-value fields. "
        },
        {
            "author": "Kranti Parisa",
            "id": "comment-13767361",
            "date": "2013-09-14T04:09:32+0000",
            "content": "Something is missing in the Patch? I am seeing ByteArray compilation problem. Also does bjoin needs any specific types of field configs in schema.xml ? "
        },
        {
            "author": "Kranti Parisa",
            "id": "comment-13768078",
            "date": "2013-09-16T05:35:49+0000",
            "content": "I have implemented multi-value keys for hjoin using a new field UnIvertedLongField. Sanity checks looks good. Also tested with FQs (nested Joins). I will run some performance tests and prepare the patch sometime tomorrow. "
        },
        {
            "author": "Kranti Parisa",
            "id": "comment-13771116",
            "date": "2013-09-18T19:00:29+0000",
            "content": "patch for hjoin to support multi-value keys both int and longs. I have created this patch on TRUNK (Solr 5.0) "
        },
        {
            "author": "Peter Keegan",
            "id": "comment-13782179",
            "date": "2013-09-30T20:18:05+0000",
            "content": "I'm seeing ByteArray compilation problem, too. Where would I find this class? "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13782184",
            "date": "2013-09-30T20:22:59+0000",
            "content": "Yes, I noticed the latest patch is reffering to ByteArray which isn't present. I'm going to be putting up new patch shortly to resolve this. It will also include the latest work done on the BitSet join. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13782210",
            "date": "2013-09-30T20:42:50+0000",
            "content": "This patch resolves a compile issue in the last patch and has the latest work that was done for the bjoin. The hjoin work that Kranti has worked on has not yet included. "
        },
        {
            "author": "Peter Keegan",
            "id": "comment-13783110",
            "date": "2013-10-01T16:41:37+0000",
            "content": "Thanks, just tried the latest patch. For identical queries in my test index, 'bjoin' is twice as fast as 'hjoin' for both small and large inner set sizes. "
        },
        {
            "author": "Kranti Parisa",
            "id": "comment-13783124",
            "date": "2013-10-01T17:00:49+0000",
            "content": "Yes, but you might see different results (especially the memory) when you have long keys. If you don't have memory restrictions then yes \"bjoin\" should perform better. "
        },
        {
            "author": "Kranti Parisa",
            "id": "comment-13805485",
            "date": "2013-10-25T17:29:01+0000",
            "content": "I have recently extended the hjoin further to support multiple FQs separated by comma (,)\n\n\n/masterCore/select?q=*:*&fq=({!hjoin fromIndex=ACore from=parentid to=id v=$aQ fq=$BJoinQ,$AlocalFQ})&aQ=(f1:false)&BJoinQ=({!hjoin fromIndex=BCore from=bid to=aid}tag:abc)&AlocalFQ=(fieldName:value)\n\n\n\nThis will allow using the filter caches for multiple nested queries while using the hjoin like how solr supports multiple FQ params within the same request.\n\nAny feedback for the syntax? is comma separated FQs (eg: fq=$BJoinQ,$AlocalFQ) sounds ok? "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13882779",
            "date": "2014-01-27T12:26:45+0000",
            "content": "Resolved a memory leak when the bjoin is used with cache autowarming. "
        },
        {
            "author": "Upayavira",
            "id": "comment-13884156",
            "date": "2014-01-28T13:59:35+0000",
            "content": "Happy to be ignored, but wouldn't \n{!bitsetjoin}\n and \n{!hashjoin}\n be more descriptive and therefore more useful? It would mean people would get a more intuitive sense of what this is doing before they have to resort to documentation. "
        },
        {
            "author": "David Smiley",
            "id": "comment-13884248",
            "date": "2014-01-28T15:30:09+0000",
            "content": "+1 to {!bitsetjoin} and {!hashjoin} "
        },
        {
            "author": "Alexander S.",
            "id": "comment-13912786",
            "date": "2014-02-26T11:29:21+0000",
            "content": "Which release does have support for \n{!join}\n with fq parameter? I was trying with 4.5.1 but fq seems does not have any effect. "
        },
        {
            "author": "Alexander S.",
            "id": "comment-13915768",
            "date": "2014-02-28T13:16:13+0000",
            "content": "Just tried 4.7.0 and it does not work either. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13916095",
            "date": "2014-02-28T17:55:27+0000",
            "content": "Hi Alexander,\n\nThis ticket has not been committed. There are two joins described on the list of QParserPlugins here:\n\nhttps://cwiki.apache.org/confluence/display/solr/Other+Parsers\n\nJoel "
        },
        {
            "author": "Alexander S.",
            "id": "comment-13920798",
            "date": "2014-03-05T12:34:00+0000",
            "content": "Hi Joel, thanks, I seems need to perform a nested join inside a single collection, but need fq inside join as it is shown here: https://issues.apache.org/jira/browse/SOLR-4787?focusedCommentId=13750854&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13750854\n\nI have a single collection with a field type which determines the kind of document. 3 types of documents: Profile, Site, and SiteSource.\nWhen searching for Profiles I have to look in SiteSource content, so I need something like this:\n\nq = {!join from=owner_id_im to=id_i fq=$joinFilter1 v=$joinQuery1} # Profile \u2192 Site join\njoinQuery1 = {!join from=site_id_i to=id_i fq=$joinFilter2 v=$joinQuery2} # Site \u2192 SiteSource join\njoinQuery2 = {!edismax}my_keywords\njoinFilter1 = \"type:Site\"\njoinFilter2 = \"type:SiteSource\"\n\n\n\nRight now this works only partially, fq inside {!join} is ignored.\nWhen to expect this patch to be merged? Also, will it work in the way I've explained or do I understand it wrong?\n\nThank you,\nAlex "
        },
        {
            "author": "Kranti Parisa",
            "id": "comment-13920802",
            "date": "2014-03-05T12:47:31+0000",
            "content": "Alex,\n\nI will try to create a patch today for nested joins and post here. Which version of solr are you using? "
        },
        {
            "author": "Alexander S.",
            "id": "comment-13920805",
            "date": "2014-03-05T12:52:52+0000",
            "content": "Hi, 4.4 and 4.7 "
        },
        {
            "author": "Kranti Parisa",
            "id": "comment-13921113",
            "date": "2014-03-05T17:57:46+0000",
            "content": "Alex,\n\nYou may try the Patch (https://issues.apache.org/jira/secure/attachment/12632860/SOLR-4797-hjoin-multivaluekeys-nestedJoins.patch) for Nested Joins.\n "
        },
        {
            "author": "Alexander S.",
            "id": "comment-13937732",
            "date": "2014-03-17T12:15:39+0000",
            "content": "Thank you, Kranti Parisa, I am far from java development, how can I apply this patch and build solr for linux? I tried to patch, it creates a new folder \"joins\" in solr/contrib, installed ivy and launched \"ant compile\" but got this error:\n\ncommon.compile-core:\n    [mkdir] Created dir: /home/heaven/Desktop/solr-4.7.0/solr/build/contrib/solr-joins/classes/java\n    [javac] Compiling 3 source files to /home/heaven/Desktop/solr-4.7.0/solr/build/contrib/solr-joins/classes/java\n    [javac] warning: [options] bootstrap class path not set in conjunction with -source 1.6\n    [javac] /home/heaven/Desktop/solr-4.7.0/solr/contrib/joins/src/java/org/apache/solr/joins/HashSetJoinQParserPlugin.java:883: error: reached end of file while parsing\n    [javac]       return this.delegate.acceptsDocsOutOfOrder();\n    [javac]                                                    ^\n    [javac] /home/heaven/Desktop/solr-4.7.0/solr/contrib/joins/src/java/org/apache/solr/joins/HashSetJoinQParserPlugin.java:884: error: reached end of file while parsing\n    [javac] 2 errors\n    [javac] 1 warning\n\nBUILD FAILED\n/home/heaven/Desktop/solr-4.7.0/build.xml:106: The following error occurred while executing this line:\n/home/heaven/Desktop/solr-4.7.0/solr/common-build.xml:458: The following error occurred while executing this line:\n/home/heaven/Desktop/solr-4.7.0/solr/common-build.xml:449: The following error occurred while executing this line:\n/home/heaven/Desktop/solr-4.7.0/lucene/common-build.xml:471: The following error occurred while executing this line:\n/home/heaven/Desktop/solr-4.7.0/lucene/common-build.xml:1736: Compile failed; see the compiler error output for details.\n\nTotal time: 8 minutes 55 seconds "
        },
        {
            "author": "Alexander S.",
            "id": "comment-13937747",
            "date": "2014-03-17T12:33:45+0000",
            "content": "Nvm, there were 3 missing \"}\" at the end of HashSetJoinQParserPlugin.java, the build was successful, testing now. "
        },
        {
            "author": "Alexander S.",
            "id": "comment-13937845",
            "date": "2014-03-17T14:16:27+0000",
            "content": "Kranti,\n\nDo I need to update anything in my solr config/schema? I've just tried the patched version and it still ignores the fq parameter. I was using solr 4.7.0.\n\nThanks,\nAlex "
        },
        {
            "author": "Kranti Parisa",
            "id": "comment-13937868",
            "date": "2014-03-17T14:42:36+0000",
            "content": "Alex,\n\nAre you using HashSetJoin? Did you configure in solrconfig.xml? "
        },
        {
            "author": "Alexander S.",
            "id": "comment-13937887",
            "date": "2014-03-17T15:00:52+0000",
            "content": "Hi, I am using simple join, this way: \n{!join from=profile_ids_im to=id_i fq=$joinFilter1 v=$joinQuery1}\n. "
        },
        {
            "author": "Kranti Parisa",
            "id": "comment-13937895",
            "date": "2014-03-17T15:06:08+0000",
            "content": "NestedJoins (fqs) are implemented in HashSetJoin. so after applying the patch you will need to configure it in solrconfig.xml\n\n<queryParser name=\"hjoin\" class=\"org.apache.solr.search.joins.HashSetJoinQParserPlugin\"/>\n\nand use \n{!hjoin from=profile_ids_im to=id_i fq=$joinFilter1 v=$joinQuery1}\n, so you are trying to do a self join on the same core? "
        },
        {
            "author": "Alexander S.",
            "id": "comment-13937921",
            "date": "2014-03-17T15:30:50+0000",
            "content": "Ok, thx, I'll try with hjoin. And yes, I am trying to do it on the same core. "
        },
        {
            "author": "Alexander S.",
            "id": "comment-13938117",
            "date": "2014-03-17T17:58:21+0000",
            "content": "Getting this error:\n\nRSolr::Error::Http - 500 Internal Server Error\nError:     {msg=SolrCore 'crm-dev' is not available due to init failure: Error loading class 'org.apache.solr.search.joins.HashSetJoinQParserPlugin',trace=org.apache.solr.common.SolrException: SolrCore 'crm-dev' is not available due to init failure: Error loading class 'org.apache.solr.search.joins.HashSetJoinQParserPlugin'\n\tat org.apache.solr.core.CoreContainer.getCore(CoreContainer.java:827)\n\tat org.apache.solr.servlet.SolrDispatchFilter.doFilter(SolrDispatchFilter.java:309)\n\tat org.apache.solr.servlet.SolrDispatchFilter.doFilter(SolrDispatchFilter.java:217)\n\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1419)\n\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:455)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:137)\n\tat org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:557)\n\tat org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:231)\n\tat org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1075)\n\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:384)\n\n "
        },
        {
            "author": "Kranti Parisa",
            "id": "comment-13940570",
            "date": "2014-03-19T15:26:31+0000",
            "content": "can you post the query "
        },
        {
            "author": "Alexander S.",
            "id": "comment-13940740",
            "date": "2014-03-19T17:44:32+0000",
            "content": "Any query fails, seems I am doing something wrong (perhaps the patch was applied incorrectly). I see this error:\n\nSolrCore Initialization Failures\ncrm-dev: org.apache.solr.common.SolrException:org.apache.solr.common.SolrException: Error loading class 'org.apache.solr.search.joins.HashSetJoinQParserPlugin'\nwhen trying to access the web interface. "
        },
        {
            "author": "Gopal Patwa",
            "id": "comment-13941359",
            "date": "2014-03-20T03:33:04+0000",
            "content": "I am trying to use this patch (27/Jan/14 12:26) using hjoin and mismatch type issue was resolved it was my bad, I had join id with different type.\n\nIs it possible to collect data from hjoin collection i.e fromIndex and append to main query result? In my usecase I need to use hjoin and also show fields from fromIndex.\n\n "
        },
        {
            "author": "Kranti Parisa",
            "id": "comment-13941765",
            "date": "2014-03-20T14:17:13+0000",
            "content": "Gopal, you can't get the values using joins. you will need to make a second call with the result (potentially sorted and paginated on firstCore). Using FQs in the first join call, you can hit the caches in the second call. if you need more details, describe your use case "
        },
        {
            "author": "Gopal Patwa",
            "id": "comment-13941860",
            "date": "2014-03-20T15:52:24+0000",
            "content": "Thanks Kranti, here is my usecase \n\nEvent Collection:\neventId=1\ntitle=Lady Gaga\ndate=06/03/2014\n\nEventTicketStats Collection\neventId=1\nminPrice=200\nminQuantity=5\n\nWhen user search for \"lady gaga\" on event document using hjoin with EventTicketStats then result should include min price and qty data from join core.\n\nFinal Result for Event Collection:\neventId=1\ntitle=Lady Gaga\ndate=06/03/2014\nminPrice=200\nminQuantity=5\n\nAnd user has option to filter result for price and qty like show events for minPrice < 100\nThe reason we have EventStats in separate document that our ticket data changes every 5 seconds but Event data changes are like twice a day\n\nI thought using Updatable Numeric DocValue after denormalizing Event document with min price and qty fields But Solr does not have support for that feature yet. So I need to rely on using join "
        },
        {
            "author": "Kranti Parisa",
            "id": "comment-13942635",
            "date": "2014-03-21T01:31:04+0000",
            "content": "so for any query you might return one or more EVENTS matching the title search terms + filters. \n\nsay you have 30 events matching the given criteria but your pagination is 1-10, so you would be displaying the top 10 most relevant EVENTS.. this would be the docList of your first query.. and from the ResponseWriter you would need to make a call to TICKETS core, by using the original filters + the 10 event ids and execute that request (you might need to use LocalSolrQueryRequest and pre-processed filters etc to hit the caches of the first query). and collect the field info you need for each EVENT..\n\nFrom the joins implementation point of view, there is no such thing to fetch the values or scores from the secondCore.. it would be very costly to do that.. you would need to do write some custom ResponseWriters etc which does this stuff.. especially considering your requirement of maintaing EVENTS and TICKETS separately. There is also a new feature Collapse, Expand results.. but then I am not sure about using them for your use case..\n "
        },
        {
            "author": "Alexander S.",
            "id": "comment-13943153",
            "date": "2014-03-21T15:24:15+0000",
            "content": "Kranti Parisa\n\nDid you try to apply this patch to 4.7.0? I was trying to download it here: http://www.apache.org/dyn/closer.cgi/lucene/solr/4.7.0 and then did the next steps:\n\n\tant compile\n\tant ivy-bootstrap\n\tant dist\nAnd then created a package for my Linux distributive, but no luck, Solr fails to initialize with\n<queryParser name=\"hjoin\" class=\"org.apache.solr.search.joins.HashSetJoinQParserPlugin\"/>\n\n "
        },
        {
            "author": "Kranti Parisa",
            "id": "comment-13943154",
            "date": "2014-03-21T15:27:07+0000",
            "content": "Alex, I will try that tonight or tomorrow and post my findings. "
        },
        {
            "author": "Arul Kalaipandian",
            "id": "comment-13960120",
            "date": "2014-04-04T16:43:17+0000",
            "content": "Last week, we tried the patch(SOLR-4787) in our test system &  performance of hjoin is quite better than the standard join. \n\nBut with following issues,\n\n1) With 'int' join fields, bjoin throws  ArrayIndexOutOfBoundsException\n\nbjoin throws ArrayIndexOutOfBoundsException\nCaused by: org.apache.solr.client.solrj.SolrServerException: java.io.IOException: java.lang.ArrayIndexOutOfBoundsException: -1\n        at org.apache.solr.client.solrj.embedded.EmbeddedSolrServer.request(EmbeddedSolrServer.java:155)\n        ... 48 more\nCaused by: java.io.IOException: java.lang.ArrayIndexOutOfBoundsException: -1\n        at org.apache.solr.joins.BitSetJoinQParserPlugin$BitSetJoinQuery.createWeight(BitSetJoinQParserPlugin.java:282)\n        at org.apache.lucene.search.IndexSearcher.createNormalizedWeight(IndexSearcher.java:664)\n        at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:297)\n        at org.apache.solr.search.SolrIndexSearcher.getDocSetNC(SolrIndexSearcher.java:1122)\n        at org.apache.solr.search.SolrIndexSearcher.getPositiveDocSet(SolrIndexSearcher.java:825)\n        at org.apache.solr.search.SolrIndexSearcher.getProcessedFilter(SolrIndexSearcher.java:942)\n        at org.apache.solr.search.SolrIndexSearcher.getDocListNC(SolrIndexSearcher.java:1399)\n        at org.apache.solr.search.SolrIndexSearcher.getDocListC(SolrIndexSearcher.java:1366)\n        at org.apache.solr.search.SolrIndexSearcher.search(SolrIndexSearcher.java:457)\n        at org.apache.solr.handler.component.QueryComponent.process(QueryComponent.java:410)\n        at org.apache.solr.handler.component.SearchHandler.handleRequestBody(SearchHandler.java:208)\n        at org.apache.solr.handler.RequestHandlerBase.handleRequest(RequestHandlerBase.java:135)\n        at org.apache.solr.core.SolrCore.execute(SolrCore.java:1817)\n        at org.apache.solr.client.solrj.embedded.EmbeddedSolrServer.request(EmbeddedSolrServer.java:150)\n        ... 48 more\nCaused by: java.lang.ArrayIndexOutOfBoundsException: -1\n        at org.apache.lucene.util.OpenBitSet.get(OpenBitSet.java:174)\n        at org.apache.solr.joins.BitSetJoinQParserPlugin$BitSetJoinQuery.createWeight(BitSetJoinQParserPlugin.java:273)\n        ... 61 more\n\n          \n\n2) Tescases with both 'bjoin' & 'hjoin' are fails with thread leaks.\n\nBoth hjoin & bjoin (With or witout localparam 'threads')\n                Thread[id=29, name=commitScheduler-7-thread-1, state=TIMED_WAITING, group=TGRP-VolatileQueryTest]\n                at sun.misc.Unsafe.park(Native Method)\n                at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:198)\n                at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2025)\n                at java.util.concurrent.DelayQueue.take(DelayQueue.java:164)\n                at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:609)\n                at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:602)\n                at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:947)\n                at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:907)\n                at java.lang.Thread.run(Thread.java:662)\n\n\n\n\n3) 'bjoin' throws NumberFormatException  for 'long' join fields.\n   It would be nice to validate the field's type before executing the join query.\n\nException with 'long' join fields\nCaused by: java.lang.NumberFormatException: Invalid shift value in prefixCoded bytes (is encoded value really an INT?)\n\tat org.apache.lucene.util.NumericUtils.getPrefixCodedIntShift(NumericUtils.java:210)\n\tat org.apache.lucene.util.NumericUtils$2.accept(NumericUtils.java:493)\n\tat org.apache.lucene.index.FilteredTermsEnum.next(FilteredTermsEnum.java:241)\n\tat org.apache.lucene.search.FieldCacheImpl$Uninvert.uninvert(FieldCacheImpl.java:308)\n\tat org.apache.lucene.search.FieldCacheImpl$IntCache.createValue(FieldCacheImpl.java:653)\n\tat org.apache.lucene.search.FieldCacheImpl$Cache.get(FieldCacheImpl.java:212)\n\tat org.apache.lucene.search.FieldCacheImpl.getInts(FieldCacheImpl.java:571)\n\tat org.apache.lucene.search.FieldCacheImpl$IntCache.createValue(FieldCacheImpl.java:619)\n\tat org.apache.lucene.search.FieldCacheImpl$Cache.get(FieldCacheImpl.java:212)\n\tat org.apache.lucene.search.FieldCacheImpl.getInts(FieldCacheImpl.java:571)\n\tat org.apache.lucene.search.FieldCacheImpl.getInts(FieldCacheImpl.java:546)\n\tat org.apache.solr.joins.MaxInt.getMax(MaxInt.java:98)\n\tat org.apache.solr.joins.BitSetJoinQParserPlugin$BitSetJoinQuery.runJoin(BitSetJoinQParserPlugin.java:405)\n\t... 31 more\n\n\n\n\n4. Make 'fromIndex'  optional as like the standard 'join'\n\nCaused by: java.lang.NullPointerException\n        at org.apache.solr.joins.HashSetJoinQParserPlugin$HashSetJoinQuery.hashCode(HashSetJoinQParserPlugin.java:133)\n        at org.apache.solr.search.QueryResultKey.<init>(QueryResultKey.java:50)\n        at org.apache.solr.search.SolrIndexSearcher.getDocListC(SolrIndexSearcher.java:1274)\n        at org.apache.solr.search.SolrIndexSearcher.search(SolrIndexSearcher.java:457)\n        at org.apache.solr.handler.component.QueryComponent.process(QueryComponent.java:410)\n        at org.apache.solr.handler.component.SearchHandler.handleRequestBody(SearchHandler.java:208)\n        at org.apache.solr.handler.RequestHandlerBase.handleRequest(RequestHandlerBase.java:135)\n        at org.apache.solr.core.SolrCore.execute(SolrCore.java:1817)\n        at org.apache.solr.client.solrj.embedded.EmbeddedSolrServer.request(EmbeddedSolrServer.java:150)\n        ... 48 more\n\n\n\n Index details: \n   5 shards with 12 million each(11 million docs + 1 million acl)\n   Both docs & acls are in same core.\n   Tested with Solr 4.2.1  "
        },
        {
            "author": "Alexander S.",
            "id": "comment-13961733",
            "date": "2014-04-07T09:10:02+0000",
            "content": "@Kranti Parisa, hi, any luck with this? "
        },
        {
            "author": "Kranti Parisa",
            "id": "comment-13965413",
            "date": "2014-04-10T14:55:30+0000",
            "content": "Arul, thanks for posting the findings.\n\nI don't think LONG fields are supported by bjoin. "
        },
        {
            "author": "Arul Kalaipandian",
            "id": "comment-13969379",
            "date": "2014-04-15T09:30:52+0000",
            "content": "New patch(SOLR-4787-with-testcase-fix.patch  for Solr-4.2.1) with following fix & improvement,\n\n\n\tTestcase thread leaks: SolrCore(fromcore) released on 'finally'  block.\n\t'fromIndex' is optional as like the standard 'join', i.e we can do join across cores or in single core('self-join').\n\tBitSetJoinQParserPlugin, field validation added(From & to fields must be an 'int').\n\tBasic testcases added.\n\n "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-13971008",
            "date": "2014-04-16T12:56:52+0000",
            "content": "Move issue to Solr 4.9. "
        },
        {
            "author": "Alexander S.",
            "id": "comment-14077928",
            "date": "2014-07-29T16:26:41+0000",
            "content": "It seems join doesn't work as expected, please have a look: http://lucene.472066.n3.nabble.com/Search-results-inconsistency-when-using-joins-td4149810.html "
        },
        {
            "author": "Kranti Parisa",
            "id": "comment-14252796",
            "date": "2014-12-19T02:16:49+0000",
            "content": "Alexander S. Did you apply this patch to test the joins with fq? \nIf you tried with the default solr join, then fq is not a supported param for the default solr joins.  "
        },
        {
            "author": "Bill Bell",
            "id": "comment-14344601",
            "date": "2015-03-03T06:14:30+0000",
            "content": "This seems like a no-brainer.  Can we commit this into 5.xxx ? "
        },
        {
            "author": "Bill Bell",
            "id": "comment-14345727",
            "date": "2015-03-03T21:02:39+0000",
            "content": "To be consistent can we add FQ?\n\nBased on post by Yonik:\n\nThe join qparser has no \"fq\" parameter, so that is ignored. \n\n-Yonik \nhttp://heliosearch.org - native code faceting, facet functions, \nsub-facets, off-heap data  "
        },
        {
            "author": "Tom Winch",
            "id": "comment-14485282",
            "date": "2015-04-08T14:18:00+0000",
            "content": "See also the new external source join, \"xjoin\", at https://issues.apache.org/jira/browse/SOLR-7341 "
        },
        {
            "author": "Blake Howell",
            "id": "comment-14617325",
            "date": "2015-07-07T20:28:25+0000",
            "content": "New patch that brings compatability up to 4.10, based on the patch from Arul. Removes SolrCore.getSchema method calls, fixes build.xml and ivy.xml to bring them into compatability with the changes in the build system and updates some of the tests that were failing. "
        },
        {
            "author": "Gopal Patwa",
            "id": "comment-14648285",
            "date": "2015-07-30T20:44:29+0000",
            "content": "if this is not committed to solr 5.x, does anyone has this join patch for solr 5.x ? "
        },
        {
            "author": "Marcus Bergner",
            "id": "comment-15056220",
            "date": "2015-12-14T16:24:24+0000",
            "content": "I've been trying out the patches in this ticket for a while (with Solr 4.9.1) and most recently the patches by Kranti Parisa that uses UnInvertedLongField to handle multi-value \"to\"/\"from\" in a hjoin query. After stumbling on a couple of issues I think I have something that works reasonably well. The last thing that had me puzzled was that after indexing slightly more data than a very trivial test set in the index I was getting NullPointerException in the UnInvertedLongField constructor:\n\n\nTerms terms = reader.terms(field);  // returns null\n...\nTermsEnum termsEnum = terms.iterator(null);   // throws NullPointerException\n\n\n\nI've added various null checks in the code, but I don't really understand how/why reader.terms(field) would ever return null if the field name is defined in solrconfig.xml? Also, how bad would it be to simply have empty arrays in UnInvertedLongField and ignore any docId values >= length of the internal arrays if reader.terms(field) for some reason does return null? My tests so far look promising with such a patch but it gives me a somewhat bad feeling.\n\nThis was my tiny test hierarchy that worked, the ids were large integers (19 digits).\n\n\n\n\nID\nMembers\nComment\n\n\nid1\nid2\nLevel A\n\n\nid2\nid3, id4\nLevel B\n\n\nid3\n\u00a0\nLevel C\n\n\nid4\n\u00a0\nLevel C\n\n\nid5\n\u00a0\nLevel C, no parent, added later after initial tests\n\n\n\n\n\nUsing the above documents 1-4 a {!hjoin fromIndex=coll from=memberslvlB to=idlvlC}... worked and swapping to/from for the reversed search also worked. Adding an additional document to the index (id5) that was not a member of level B in this case caused the same queries to fail with NullPointerException in UnInvertedLongField constructor. Note that each \"level\" in the hierarchy here has their own field names both for their id fields and member list field (basically \"$type.id\" and \"$type.member\"). I first thought it could be related to dynamic fields but after changing my indexing and Solr schema to use real fields I could see the same problem. "
        },
        {
            "author": "Vadim Ivanov",
            "id": "comment-15503072",
            "date": "2016-09-19T10:49:19+0000",
            "content": "How to upgrade to the latest version of SOLR and be able to perform fast joins ? \n(Bjoin or something as fast as it)\nSOLR is developing and 6.x version is already available but I'm stuck on 4.10 because of joins\nI\u2019m using bjoins to join collections with 2-3 billion documents (set of products) to collections of availability (less than 10 million documents)  and managed to get response time about 200 ms, which is acceptable. \nBut, using regular joins, leads to response time greater than 10 sec\nAre there any changes in 6x versions allowing join to be as fast as bjoin? "
        },
        {
            "author": "Mikhail Khludnev",
            "id": "comment-15503138",
            "date": "2016-09-19T11:18:10+0000",
            "content": "Note: adding score=none as a local parameter can speedup join on extremely large indexes.  "
        },
        {
            "author": "Vadim Ivanov",
            "id": "comment-15503559",
            "date": "2016-09-19T13:55:18+0000",
            "content": "Thak you, Mikhail.\nBut I still have some doubts:\n1. Will SOLR use filter cache, when \"join\" is inside &fq? It seems to me that regular join is not cached. \n2. Bjoin has fq sentence and, for example, clause like this could be written:\n\n...&fq=-\n{!bjoin from=id fromIndex=hdq to=hdquotes fq=$qq}\nqt_release:1\n&qq=(qt_cnid:4 AND qt_disabled:0)...\n\nRegular solr join is without fq, so cold you drop a hint of rewriting this clause?\n "
        },
        {
            "author": "Mikhail Khludnev",
            "id": "comment-15503587",
            "date": "2016-09-19T14:04:07+0000",
            "content": "sure. now we have a wunderwaffe: filter()\nie. \n\n..&fq=-{!join from=id fromIndex=hdq to=hdquotes v=$hqquery}&hqquery=qt_release:1 filter(qt_cnid:4 AND qt_disabled:0)...\n\n\n\nbeware that space in subordinate clause after {!...} sometimes might not be recognized, thus I used v=$hqquery trick "
        },
        {
            "author": "Vadim Ivanov",
            "id": "comment-15506968",
            "date": "2016-09-20T16:03:38+0000",
            "content": "Hi, Mikhail\nRecently I've installed SOLR 6.2 and did several tests.\nscore=none parameter is very tricky. As you 've mentioned here http://blog-archive.griddynamics.com/2015/08/scoring-join-party-in-solr-53.html\n\"Enabling score and even specifying \n{!join \u2026 score=none}\n.. picks the different algorithm ... which expects \"from\" field to be string docValues\".\nSo, as my id is NUMERIC (bjoin requires it) I receive error: \"unexpected docvalues type NUMERIC for field 'id' (expected one of [SORTED, SORTED_SET]). Re-index with correct docvalues type.\"\nDo you think that changing schema (id type to string docvalues) and further reindexing worth doing? And  Lucene\u2019s JoinUtil with clause score=none might perform considerably better than the original Solr\u2019s algorithm? "
        },
        {
            "author": "David Smiley",
            "id": "comment-15507057",
            "date": "2016-09-20T16:37:28+0000",
            "content": "The algorithm in JoinUtil is very different from Solr's default join.  IMO JoinUtil will be faster for most use-cases but understand it definitely depends.  I've twice added a QParser to use JoinUtil in my projects. "
        },
        {
            "author": "Mikhail Khludnev",
            "id": "comment-15507330",
            "date": "2016-09-20T18:18:11+0000",
            "content": "right. it seems SOLR-8395 sank. You can estimate score=none search time. It's dominated by from side result size. You need to run from side query, then build long {!terms} query from result keys, and then measure its' execution time. Sum of these times gives you rough JoinUtil query time, and let judge whether or not to reindex.   "
        },
        {
            "author": "Samuel Tatipamula",
            "id": "comment-16004758",
            "date": "2017-05-10T14:22:59+0000",
            "content": "Not able to build jar using patches . Can I get solr join contrib jar ?  "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-16004864",
            "date": "2017-05-10T15:33:33+0000",
            "content": "Samuel:\n\nIn a word \"no\". Patches are built against whatever version of the source happens to be current when developing them. Until they're committed, no jars are built or archived. Once committed, the JIRA will be closed and marked \"fixed\". This particular source patch is over 2 years old and hasn't been kept up to date for whatever reason.\n\nYour choices are\n1> check out code from that time frame\n2> update the patch to build against the current code base.\n\nIf you do the latter, please contribute the patch back! "
        }
    ]
}