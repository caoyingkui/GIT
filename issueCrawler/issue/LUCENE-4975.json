{
    "id": "LUCENE-4975",
    "title": "Add Replication module to Lucene",
    "details": {
        "components": [],
        "fix_versions": [
            "4.4",
            "6.0"
        ],
        "affect_versions": "None",
        "priority": "Major",
        "labels": "",
        "type": "New Feature",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "I wrote a replication module which I think will be useful to Lucene users who want to replicate their indexes for e.g high-availability, taking hot backups etc.\n\nI will upload a patch soon where I'll describe in general how it works.",
    "attachments": {
        "LUCENE-4975.patch": "https://issues.apache.org/jira/secure/attachment/12581543/LUCENE-4975.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2013-05-02T16:08:05+0000",
            "content": "So here's an overview how the Replicator works (it's also document under oal.replicator.package.html):\n\nAt a high-level, producers (e.g. indexer) publish Revisions, and consumers update to the latest Revision available. Like SVN, if a client is on rev1 and the server has rev4, the next update request will upgrade the client to rev4, skipping all intermediate revisions.\n\nThe Replicator offers two implementations at the moment: LocalReplicator to be used by at the server side and HttpReplicator to be used by clients to e.g. update over HTTP. In the future, we may want to add other Replicator implementations, e.g. rsync, torrent... for HTTP, the package also provides a ReplicationService which acts on the Http servlet request/response following some API specification. In that sense, the HttpReplicator expects a certain HTTP impl on the server side, so ReplicationService helps you by implementation that API. The reason it's not a servlet is so that you can plug it into your application servlet freely.\n\nA Revision is basically a list of files and sources. For example, IndexRevision contains the list of files in an IndexCommit (and only one source), while IndexAndTaxonomyRevision contains the list of files from both IndexCommits with corresponding sources (index/taxonomy). When the server publishes either of these two revision, the IndexCommits are snapshotted so that files aren't deleted, and the Replicator serves file requests (by clients) from the Revision. The Revision is also responsible for releasing itself \u2013 this is done automatically by the Replicator which releases a revision when it's no longer needed (i.e. there's a new one already) and there are no clients that currently replicate its files.\n\nOn the client side, the package offers a ReplicationClient class which can be invoked either manually, or start its update-thread to periodically check for updates. The client is given a ReplicationHandler (two matching implementations: IndexReplicationHandler and IndexAndTaxonomyReplicationHandler) which is responsible to act on the replicated files. The client first obtains all needed files (i.e. those that the new Revision offers, and the client is still missing), and after they were all successfully copied over, the handler is invoked. Both handlers copy the files from their temporary location to the index directories, fsync them and kiss the index such that unused files are deleted. You can provide each handler a Callable which is invoked after the index has been safely and successfully updated, so you can e.g. searcherManager.maybeReopen().\n\nHere's a general code example that explains how to work with the Replicator:\n\n\n// ++++++++++++++ SERVER SIDE ++++++++++++++ // \nIndexWriter publishWriter; // the writer used for indexing\nReplicator replicator = new LocalReplicator();\nreplicator.publish(new IndexRevision(publishWriter));\n\n// ++++++++++++++ CLIENT SIDE ++++++++++++++ // \n// either LocalReplictor, or HttpReplicator if client and server are on different nodes\nReplicator replicator;\n\n// callback invoked after handler finished handling the revision and e.g. can reopen the reader.\nCallable&lt;Boolean&gt; callback = null; // can also be null if no callback is needed\nReplicationHandler handler = new IndexReplicationHandler(indexDir, callback);\nSourceDirectoryFactory factory = new PerSessionDirectoryFactory(workDir);\nReplicationClient client = new ReplicationClient(replicator, handler, factory);\n\n// invoke client manually\nclient.updateNow();\n\t\n// or, periodically\nclient.startUpdateThread(100); // check for update every 100 milliseconds\n\n\n\nThe package of course comes with unit tests, though I'm sure there's room for improvement (there always is!). ",
            "author": "Shai Erera",
            "id": "comment-13647655"
        },
        {
            "date": "2013-05-02T16:11:13+0000",
            "content": "Patch contains the Replicator code + all needed stuff to make it a valid module (ivy, maven, licenses etc.). A big portion of the patch is due to the ivy/maven/licenses things, so if you focus on the code, it's not that big.\n\nI ran precommit and it fails with this cryptic error:\n\n\n-documentation-lint:\n     [echo] checking for broken html...\n    [jtidy] Checking for broken html (such as invalid tags)...\n   [delete] Deleting directory D:\\dev\\lucene\\lucene-replicator\\lucene\\build\\jtidy_tmp\n     [echo] Checking for broken links...\n     [exec] Traceback (most recent call last):\n     [exec]   File \"D:\\dev\\lucene\\lucene-replicator\\dev-tools/scripts/checkJavadocLinks.py\", line 260, in\n     [exec] Crawl/parse...\n     [exec]  <module>\n     [exec]     if checkAll(sys.argv[1]):\n     [exec]   File \"D:\\dev\\lucene\\lucene-replicator\\dev-tools/scripts/checkJavadocLinks.py\", line 160, in checkAll\n     [exec]     allFiles[fullPath] = parse(fullPath, open('%s/%s' % (root, f), encoding='UTF-8').read())\n     [exec]   File \"D:\\dev\\lucene\\lucene-replicator\\dev-tools/scripts/checkJavadocLinks.py\", line 110, in parse\n     [exec]     parser.feed(html)\n     [exec]   File \"/usr/lib/python3.2/html/parser.py\", line 142, in feed\n     [exec]     self.goahead(0)\n     [exec]   File \"/usr/lib/python3.2/html/parser.py\", line 188, in goahead\n     [exec]     k = self.parse_endtag(i)\n     [exec]   File \"/usr/lib/python3.2/html/parser.py\", line 454, in parse_endtag\n     [exec]     self.handle_endtag(elem.lower())\n     [exec]   File \"D:\\dev\\lucene\\lucene-replicator\\dev-tools/scripts/checkJavadocLinks.py\", line 92, in handle_endtag\n     [exec]     raise RuntimeError('%s %s:%s: saw </%s> but expected </%s>' % (self.baseURL, self.getpos()[0], self.getpos()[1], tag, self.stack[-1]))\n     [exec] RuntimeError: file:///build/docs/core/allclasses-frame.html 680:0: saw </body> but expected </div>\n\n\n\nDoes anyone know what this is? I searched for <div> and I don't have any. Also, if I run 'ant documentation' from top-level, it passes. I ran this w/ Oracle 1.7. I did find a closing </body> tag with no opening tag under the jetty license, but I don't think it's related?\n\nOtherwise, maven check passes, and tests compile and run successfully. ",
            "author": "Shai Erera",
            "id": "comment-13647658"
        },
        {
            "date": "2013-05-02T21:12:09+0000",
            "content": "Patch updates IndexRevision and IndexAndTaxonomyRevision following the recent changes to SDP (not requiring snapshot ID). I also noticed I put grouping in pom.template rather than facet - fixed.\n\nAs for this weird error I got, I noticed that the offending files under test-framework had an extra line none of the other modules seemed to have: <div role=\"navigation\" title=\"All Classes\">. I have no idea how it got there. So I ran 'ant clean documentation' and it passed! I will run precommit tomorrow. ",
            "author": "Shai Erera",
            "id": "comment-13647908"
        },
        {
            "date": "2013-05-03T03:43:40+0000",
            "content": "Patch adds @lucene.experimental to all classes. I also excluded all the licesne files from the patch, so that it's smaller and easier to review. ",
            "author": "Shai Erera",
            "id": "comment-13648155"
        },
        {
            "date": "2013-05-05T08:00:42+0000",
            "content": "Added testConsistencyOnException to test the client and handlers' behavior when they encounter exceptions (I use MockDirWrapp diskFull and randomIOE to simulate that).\n\nI think this module is basically ready. I.e. it comes with tests, javadocs and pretty much does what it was written to do. I'm sure there's room for improvement, but I don't think this should hold off the commit. So unless there are any objections, I intend to commit in by Tuesday. If people want to do a thorough review, I don't mind waiting with the commit, but just drop a comment on the issue to let me know. ",
            "author": "Shai Erera",
            "id": "comment-13649298"
        },
        {
            "date": "2013-05-05T23:18:46+0000",
            "content": "+1 to commit and iterate from here on... this new module looks very nice!\n\nI like the new testConsistencyOnException ... maybe also call MDW.setRandomIOExceptionRateOnOpen?  This will additionally randomly throw exceptions from openInput/createOutput. ",
            "author": "Michael McCandless",
            "id": "comment-13649457"
        },
        {
            "date": "2013-05-06T07:37:25+0000",
            "content": "+1 for committing it ",
            "author": "Tommaso Teofili",
            "id": "comment-13649564"
        },
        {
            "date": "2013-05-06T09:27:06+0000",
            "content": "+1 to commit too.\n\nLooking at the code, there seems to be specialized implementations for faceting because of the need to replicate the taxonomy indexes too, so I was wondering that maybe this facet-specific code should be under lucene/facets rather than lucene/replicator so that lucene/replicator doesn't need to depend on all modules that have specific replication needs. (I'm not sure what the best option is yet, this can be addressed afterwards.) ",
            "author": "Adrien Grand",
            "id": "comment-13649613"
        },
        {
            "date": "2013-05-06T09:46:34+0000",
            "content": "I've been wondering about that too, but chose to keep the facet replication code under replicator for few reasons:\n\n\n\tA Revision contains files from multiple sources, and the taxonomy index is partly responsible for that. And ReplicationClient respects that \u2013 so I guess it's not entirely true that the Replicator is unaware of taxonomy (even though it would still work if I pulled the taxonomy stuff out of it).\n\n\n\n\n\tI think it makes less sense to require lucene-replicator.jar for every faceted search app which makes use of lucene-facet.jar. The key reason is that replicator requires few additional jars such as httpclient, httpcore, jetty, servlet-api. Requiring lucene-facet.jar seems less painful to me, than requiring every faceted search app out there to include all these jars even if it doesn't want to do replication.\n\n\n\n\n\tI like to keep things local to the module. There are many similarities between IndexAndTaxoRevision to IndexRevision (likewise for their handlers and tests). Therefore whenever I made change to one, I knew I should go make a similar change to the other.\n\n\n\nAll in all, I guess arguments can be made both ways, but I prefer for the now to keep things local to the replicator module. Even in the future, I would imagine that if we added support for replicating a suggester files, then it would make sense to put a dependency between replicator and suggester, rather than the other way around. ",
            "author": "Shai Erera",
            "id": "comment-13649631"
        },
        {
            "date": "2013-05-06T09:52:47+0000",
            "content": "maybe also call MDW.setRandomIOExceptionRateOnOpen\n\nThanks Mike! I added that and a slew of problems surfaced, most of them in the test, but I improved the handlers' implementation to cleanup after themselves if e.g. a copy or sync to the handlerDir failed. While this wasn't a bug, it leaves the target index directory clean.\n\nThere's one nocommit which bugs me though \u2013 I had to add dir.setPreventDoubleWrite(false) because when the handler fails during copying of say _2.fdt to the index dir, the file is deleted from the indexDir, and the client re-attemts to upgrade. At this point, MDW complains that _2.fdt was already written to, even though I deleted it.\n\nAdding this setPrevent was the only way I could make MDW happy, but I don't like it since I do want to catch errors in the handler/client if they e.g. attempt to copy over an existing file.\n\nMaybe we can make MDW respond somehow to delete()? I know that has bad implications on its own, e.g. code which deletes and then accidentally recreates files with older names ... any ideas? ",
            "author": "Shai Erera",
            "id": "comment-13649634"
        },
        {
            "date": "2013-05-06T09:55:03+0000",
            "content": "Good points, you convinced me.  ",
            "author": "Adrien Grand",
            "id": "comment-13649635"
        },
        {
            "date": "2013-05-06T10:37:01+0000",
            "content": "\nEven in the future, I would imagine that if we added support for replicating a suggester files, then it would make sense to put a dependency between replicator and suggester, rather than the other way around.\n\nWait: how does this make sense?!\n\nIt should be the other way around: if suggester has a sidecar it needs special logic for replication. \n\nIt does not need faceting. ",
            "author": "Robert Muir",
            "id": "comment-13649643"
        },
        {
            "date": "2013-05-06T11:04:48+0000",
            "content": "As I said, arguments can be made both ways ... I don't know what's the best way here. I can see your point, but I don't feel good about having facet depend on replicator. I see Replicator as a higher-level service that besides providing the replication framework, also comes pre-built for replicating Lucene stuff. I don't mind seeing it grow to accommodate other Revision types in the future. For example, IndexAndTaxonomyRevision is just an example for replicating multiple indexes together. It can easily be duplicated to replicate few indexes at once, e.g. a MultiIndexRevision. Where would that object be? Cannot be in core, so why should IndexAndTaxo be in facet? ",
            "author": "Shai Erera",
            "id": "comment-13649650"
        },
        {
            "date": "2013-05-06T11:13:22+0000",
            "content": "Then maybe we could have sub-modules for specific replication strategies? lucene/replicator would only know how to handle raw indexes, while lucene/replicator/facets or lucene/replicator/suggest would implement custom logic?\n\nThis way lucene/facet wouldn't need to pull all lucene/replicator transitive dependencies, and lucene/replicator wouldn't depend on any lucene module but lucene/core. ",
            "author": "Adrien Grand",
            "id": "comment-13649655"
        },
        {
            "date": "2013-05-06T11:19:46+0000",
            "content": "I still haven't had a change to look at the patch: but it sounds like some work needs to be done here to prevent dll hell.\n\nhaving replicator depend upon all sidecar modules is a no-go.\n\nit sounds like an interface is missing. ",
            "author": "Robert Muir",
            "id": "comment-13649658"
        },
        {
            "date": "2013-05-06T11:46:32+0000",
            "content": "Ok, so there are 3 options I see: (1) have Replicator depend on Facet (and in the future on other modules), (2) have Facet depend on Replicator and (3) move Revision and ReplicationHandler (interfaces) someplace else, core or a new module we call 'commons' and Replicator and Facet depend on it. Tests though will need to depend on replicator though, since they need ReplicationClient.\n\nBTW, the jetty dependencies are tests only, but I don't know how to make ivy resolve the dependencies just for tests. The only thing replicator depends on is servlet-api, for ReplicationService and httpclient for ReplicationClient. I think these need to remain in the module ...\n\nIf we made Facet depend on Replicator (I'm not totally against it), would that require you to have lucene-replicator.jar on the classpath, even if you don't use replication? If not, then perhaps this dependency isn't so bad ... it's just a compile-time dependency. Tests will still need to depend on replicator for runtime, but that's ok I think. ",
            "author": "Shai Erera",
            "id": "comment-13649674"
        },
        {
            "date": "2013-05-06T13:09:12+0000",
            "content": "Then maybe we could have sub-modules for specific replication strategies?\n\nTo make my point a little clearer, I was suggesting something pretty much like the analysis module: analyzers that require additional dependencies (such as icu or morfologik) are in their own sub-module so that you don't need to pull the ICU or Morfologik JARs if you just want to use LetterTokenizer (which is in lucene/analysis/common).\n\nLikewise, we could have the interface and the logic to replicate simple (no sidecar data) indexes in lucene/replicator/common and have sub-modules for facet (lucene/replicator/facet) or suggesters (lucene/replicator/suggesters).\n\nThis may look overkill but at least this would help us keep dependencies clean between modules. ",
            "author": "Adrien Grand",
            "id": "comment-13649727"
        },
        {
            "date": "2013-05-06T13:13:24+0000",
            "content": "I think that's not a bad idea! replicator/common will include the interfaces (Revision and ReplicationHandler) + the framework impl and also IndexRevision/Handler. replicator/facet will include the taxonomy parts and depend on replicator/common and facet.\n\nI can also move the facet related code under oal.replicator.facet and then suppress the Lucene3x codec for just these tests.\n\nIf others agree, I'll make the changes (mostly build.xml changes). ",
            "author": "Shai Erera",
            "id": "comment-13649731"
        },
        {
            "date": "2013-05-07T11:27:47+0000",
            "content": "I'm having reservations about creating a replicator/facet module which contains 2 classes ... Maybe we should proceed with the code as-is, and then refactor if it creates a problem, or the module grows? Perhaps the breakout won't be to replicator/common and replicator/facet but to replicator/infra (or common) and replicator/extras which will serve like a catchall for other modules too (e.g. facet, suggest).\n\nAnother way is to break out replicator to common and framework/infra/impl such that common contains only whatever other modules require to compile against (i.e Revision, ReplicationHandler, maybe Replicator). Then we can add the facet replication code to facet/ with a dependency on replicator/common.\n\nBut really, I think we should just get it in and start to work with it, have deeper reviews and refactor as we go. ",
            "author": "Shai Erera",
            "id": "comment-13650731"
        },
        {
            "date": "2013-05-08T10:04:23+0000",
            "content": "Patch fixes a bug in IndexReplicationHandler (still need to fix in IndexAndTaxonomy) and adds some nocommits which I want to take care before I commit it.\n\nHowever, I hit a new test failure, which reproduces with the following command ant test -Dtestcase=IndexReplicationClientTest -Dtests.method=testConsistencyOnExceptions -Dtests.seed=EAF5294292642F1:6EE70BB59A9FC3CA.\n\nThe error is weird. I ran the test w/ -Dtests.verbose=true and here's the troubling parts from the log:\n\n\nReplicationThread-index: MockDirectoryWrapper: now throw random exception during open file=segments_a\njava.lang.Throwable\n\tat org.apache.lucene.store.MockDirectoryWrapper.maybeThrowIOExceptionOnOpen(MockDirectoryWrapper.java:364)\n\tat org.apache.lucene.store.MockDirectoryWrapper.openInput(MockDirectoryWrapper.java:522)\n\tat org.apache.lucene.index.SegmentInfos.read(SegmentInfos.java:281)\n\tat org.apache.lucene.index.SegmentInfos$1.doBody(SegmentInfos.java:340)\n\tat org.apache.lucene.index.SegmentInfos$FindSegmentsFile.run(SegmentInfos.java:668)\n\tat org.apache.lucene.index.SegmentInfos$FindSegmentsFile.run(SegmentInfos.java:515)\n\tat org.apache.lucene.index.SegmentInfos.read(SegmentInfos.java:343)\n\tat org.apache.lucene.index.IndexWriter.<init>(IndexWriter.java:682)\n\tat org.apache.lucene.replicator.IndexReplicationHandler.revisionReady(IndexReplicationHandler.java:208)\n\tat org.apache.lucene.replicator.ReplicationClient.doUpdate(ReplicationClient.java:248)\n\tat org.apache.lucene.replicator.ReplicationClient.access$1(ReplicationClient.java:188)\n\tat org.apache.lucene.replicator.ReplicationClient$ReplicationThread.run(ReplicationClient.java:76)\nIFD 0 [Wed May 08 22:47:46 WST 2013; ReplicationThread-index]: init: current segments file is \"segments_9\"; deletionPolicy=org.apache.lucene.index.KeepOnlyLastCommitDeletionPolicy@117da39a\nIFD 0 [Wed May 08 22:47:46 WST 2013; ReplicationThread-index]: init: load commit \"segments_9\"\nIFD 0 [Wed May 08 22:47:46 WST 2013; ReplicationThread-index]: init: load commit \"segments_a\"\nIFD 0 [Wed May 08 22:47:46 WST 2013; ReplicationThread-index]: now checkpoint \"_0(5.0):C1 _1(5.0):C1 _2(5.0):c1 _3(5.0):c1 _4(5.0):c1 _5(5.0):c1 _6(5.0):c1 _7(5.0):c1 _8(5.0):c1\" [9 segments ; isCommit = false]\nIFD 0 [Wed May 08 22:47:46 WST 2013; ReplicationThread-index]: 0 msec to checkpoint\nIFD 0 [Wed May 08 22:47:46 WST 2013; ReplicationThread-index]: deleteCommits: now decRef commit \"segments_9\"\nIFD 0 [Wed May 08 22:47:46 WST 2013; ReplicationThread-index]: delete \"segments_9\"\nIW 0 [Wed May 08 22:47:46 WST 2013; ReplicationThread-index]: init: create=false\n\n....\n\nIW 0 [Wed May 08 22:47:46 WST 2013; ReplicationThread-index]: startCommit(): start\nIW 0 [Wed May 08 22:47:46 WST 2013; ReplicationThread-index]: startCommit index=_0(5.0):C1 _1(5.0):C1 _2(5.0):c1 _3(5.0):c1 _4(5.0):c1 _5(5.0):c1 _6(5.0):c1 _7(5.0):c1 _8(5.0):c1 changeCount=1\nIW 0 [Wed May 08 22:47:46 WST 2013; ReplicationThread-index]: done all syncs: [_2.si, _7.si, _5.cfs, _1.fnm, _4.cfs, _8.si, _4.cfe, _5.cfe, _0.si, _0.fnm, _6.cfe, _8.cfs, _3.cfs, _4.si, _7.cfe, _2.cfs, _5.si, _6.cfs, _1.fdx, _8.cfe, _1.fdt, _1.si, _7.cfs, _0.fdx, _3.si, _6.si, _3.cfe, _2.cfe, _0.fdt]\nIW 0 [Wed May 08 22:47:46 WST 2013; ReplicationThread-index]: commit: pendingCommit != null\nIW 0 [Wed May 08 22:47:46 WST 2013; ReplicationThread-index]: commit: wrote segments file \"segments_a\"\nIFD 0 [Wed May 08 22:47:46 WST 2013; ReplicationThread-index]: now checkpoint \"_0(5.0):C1 _1(5.0):C1 _2(5.0):c1 _3(5.0):c1 _4(5.0):c1 _5(5.0):c1 _6(5.0):c1 _7(5.0):c1 _8(5.0):c1\" [9 segments ; isCommit = true]\nIFD 0 [Wed May 08 22:47:46 WST 2013; ReplicationThread-index]: deleteCommits: now decRef commit \"segments_a\"\nIFD 0 [Wed May 08 22:47:46 WST 2013; ReplicationThread-index]: delete \"_9.cfe\"\nIFD 0 [Wed May 08 22:47:46 WST 2013; ReplicationThread-index]: delete \"_9.cfs\"\nIFD 0 [Wed May 08 22:47:46 WST 2013; ReplicationThread-index]: delete \"_9.si\"\nIFD 0 [Wed May 08 22:47:46 WST 2013; ReplicationThread-index]: 0 msec to checkpoint\nIW 0 [Wed May 08 22:47:46 WST 2013; ReplicationThread-index]: commit: done\nIW 0 [Wed May 08 22:47:46 WST 2013; ReplicationThread-index]: at close: _0(5.0):C1 _1(5.0):C1 _2(5.0):c1 _3(5.0):c1 _4(5.0):c1 _5(5.0):c1 _6(5.0):c1 _7(5.0):c1 _8(5.0):c1\nIndexReplicationHandler 0 [Wed May 08 22:47:46 WST 2013; ReplicationThread-index]: updateHandlerState(): currentVersion=a currentRevisionFiles={index=[Lorg.apache.lucene.replicator.RevisionFile;@9bc2e26e}\nIndexReplicationHandler 0 [Wed May 08 22:47:46 WST 2013; ReplicationThread-index]: {version=9}\n\n\n\nI debug traced it and here's what I think is happening:\n\n\n\tMDW throws FNFE for segments_a on sis.read(dir), therefore the read SegmentInfos sees segments_9 as the current good commit. IW's segmentInfos.commitData stores version=9, which corresponds to segments_9.\n\tIFD lists the files in the Directory, and finds both segments_a and segments_9 and through a series of calls, deletes segments_9 and keeps segments_a, since it is newer.\n\tIW ctor, line 719, increments changeCount, since IFD.startingCommitDeleted is true \u2013 which happens b/c IFD is initialized with segments_9, but finds segments_a and therefore deletes it.\n\tIW then makes a commit, with the commit data from segments_9 (\"version=9\"), to a new commit point generation 10 (a in hex).\n\tThe Replicator's latest version is gen=10, the handler reads gen=10 from the index, but with the wrong commitData, and therefore the test fails.\n\n\n\nI still want to review all this again, to double-check my understanding, but it looks like something bad happening between IW and IFD. At least from the perspective of the replicator, the index shouldn't \"go forward\" by new IW().close().\n\nIf I modify the handler to do:\n\nIndexWriter writer = new IndexWriter();\nwriter.deleteUnusedFiles();\nwriter.rollback();\n\n\n\nThe test passes. But is this the right solution \u2013 i.e. guarantee that IW never commits? Or is this a bug in IW? ",
            "author": "Shai Erera",
            "id": "comment-13651759"
        },
        {
            "date": "2013-05-08T10:25:44+0000",
            "content": "Ok some more insights ... I think this additional chain of events occurs:\n\n\n\tIW's ctor reads gen 9, and SegmentInfos.getSegmentsFileName returns segments_9.\n\tIFD then successfully reads both segments_9 and segments_a, ending up w/ two commit points.\n\tIFD sorts them and passes to IndexDeletionPolicy (KeepLastCommit) which deletes segments_9 and keeps segments_a\n\tIFD marks that startingCommitDeleted, as it is\n\n\n\nAnd here's what I still don't understand \u2013 for some reason, IW creates a new commit point, segments_a, with the commitData from segments_9. Still need to dig into that.\n\nIn the meanwhile, I made the above change to the hanlder (to rollback(), not close()), and 430 iterations passed. Not sure if that's the right way to go ... if IW.close() didn't commit ...  ",
            "author": "Shai Erera",
            "id": "comment-13651762"
        },
        {
            "date": "2013-05-08T10:54:45+0000",
            "content": "I'm trying really hard not to say anything sarcastic here  ",
            "author": "Robert Muir",
            "id": "comment-13651786"
        },
        {
            "date": "2013-05-08T12:26:15+0000",
            "content": "I'm trying really hard not to say anything sarcastic here\n\nHeh, I expected something from you .\n\nI chatted about this with Mike and he confirmed my reasoning. This is very slim chance, and usually indicates a truly bad (or crazy) IO subsystem (i.e. not like MDW throwing random IOEs on opening the same file over and over again). I think perhaps this can be solved in IW by having it refer to the latest commit point read by IFD and not what it read. This seems safe to me, but perhaps an overkill. Anyway, it belongs in a different issue.\n\nWhat also happened here is that IW overwrote segments_a (violating write-once policy), which MDW didn't catch because for replicator tests I need to turn off preventDoubleWrite. Mike also says that IW doesn't guarantee write-once if it hits exceptions ...\n\nSo I think the safest solution is to deleteUnused() + rollback(), as anyway the handler must ensure that commits are not created by this \"kiss\".\n\nI will resolve the remaining nocommits and post a new patch. ",
            "author": "Shai Erera",
            "id": "comment-13651839"
        },
        {
            "date": "2013-05-08T12:31:38+0000",
            "content": "\nI chatted about this with Mike and he confirmed my reasoning. This is very slim chance, and usually indicates a truly bad (or crazy) IO subsystem (i.e. not like MDW throwing random IOEs on opening the same file over and over again). I think perhaps this can be solved in IW by having it refer to the latest commit point read by IFD and not what it read. This seems safe to me, but perhaps an overkill. Anyway, it belongs in a different issue.\n\nWhat also happened here is that IW overwrote segments_a (violating write-once policy), which MDW didn't catch because for replicator tests I need to turn off preventDoubleWrite. Mike also says that IW doesn't guarantee write-once if it hits exceptions ...\n\nSorry, i disagree and am against this.\n\nThe bug is that IndexWriter.close() waits for merges and commits. Lets quit kidding ourselves ok? ",
            "author": "Robert Muir",
            "id": "comment-13651847"
        },
        {
            "date": "2013-05-08T12:36:43+0000",
            "content": "The bug is that IndexWriter.close() waits for merges and commits. Lets quit kidding ourselves ok?\n\nNot sure I agree .. the bug is real, and if somebody did new IW().commit().close() without making any change, he might be surprised about that commit too, and also IW would overwrite an existing file. The only thing \"close-not-committing\" would solve in this case is that I won't need to call rollback(), but close(). The bug won't disappear. ",
            "author": "Shai Erera",
            "id": "comment-13651850"
        },
        {
            "date": "2013-05-10T05:46:36+0000",
            "content": "Patch resolves all remaining noocmmits. I made both IndexReplicationHandler and IndexAndTaxonomyReplicationHandler more resilient to errors but carefully reverting any changes made to the target indexes on errors. Also ensure that segments_N files are written last.\n\nI also added code to write segments.gen. To do that I factored out SegmentInfos.writeSegmentsGen which takes a Directory and generation. It is now used by SIS.finishCommit and the handlers.\n\nWould appreciate if someone can review the handlers, and whether they can be written in a more resilient ways.\n\nI want to beast IndexReplicationClientTest and IndexAndTaxonomyReplictionClientTest checkConsistencyOnExceptions before committing. If anyone's interested to help, just fire ant test -Dtestcase=IndexReplicationClientTest -Dtestsm.method=testConsistencyOnExceptions -Dtests.iters=1000 (and same for IndexAndTaxonomyReplicationClientTest) and let me know the seeds that failed. ",
            "author": "Shai Erera",
            "id": "comment-13653562"
        },
        {
            "date": "2013-05-10T10:33:20+0000",
            "content": "I ran both tests w/ tests.iters=1000 and they passed. This gives me more confidence about the robustness of these two handlers. Still, other machines can dig up \"special\" seeds . ",
            "author": "Shai Erera",
            "id": "comment-13653896"
        },
        {
            "date": "2013-05-10T11:58:52+0000",
            "content": "Mike found a seed which tripped a test bug. Fixed it and on the way made the test less sensitive to time changes (i.e. it waited up to 20 seconds for the index to get updated, otherwise failed) and added some other improvements (to the test only).\n\nLet's search for more seeds . ",
            "author": "Shai Erera",
            "id": "comment-13654399"
        },
        {
            "date": "2013-05-10T12:03:53+0000",
            "content": "Forgot to include one change \u2013 handleUpdateEx should fail if the exception it hits is not IOE. Previous patch called super.handle(), which only logged it. But I think it's fair to say that the test shouldn't hit any exception, and terminate the client if it does. ",
            "author": "Shai Erera",
            "id": "comment-13654404"
        },
        {
            "date": "2013-05-10T21:05:11+0000",
            "content": "+1, I looked at the replication handlers and they look great!\n\nI wonder if we could factor out touchIndex to a static method and share from IndexReplicationHandler and IndexAndTaxoReplicationHandler? ",
            "author": "Michael McCandless",
            "id": "comment-13654829"
        },
        {
            "date": "2013-05-11T07:10:45+0000",
            "content": "Good idea Mike. I factored out touchIndex, cleanupFilesOnFailure and copyFiles to static utilities on IndexReplHandler.\n\nMaybe instead of the static utilities, we can have an abstract IRH with two impls: SingleIndexReplicationHandler and IndexAndTaxoReplHandler. It can provide the utility methods as protected, plus implement the general framework for index replication, using abstract callbacks that are implemented by the concrete handlers. But perhaps we should do it later. ",
            "author": "Shai Erera",
            "id": "comment-13655183"
        },
        {
            "date": "2013-05-12T05:45:30+0000",
            "content": "Mike tripped a seed which was reproducible only on Linux which uncovered a bug in the handlers \u2013 writing the segments.gen file should be done only after updateHandlerState() is called, and from what the handler says is its last state. Otherwise, we could write segments.gen w/ gen=7, but \"kissing\" the index, or updating the state (reading commits) trips an error, the handler is reset back to the last revision it knows is good, and we end up w/ a segments.gen file from the future. This then causes DirReader.open to fail w/ FNFE looking for a futuristic segments_N file.\n\nMockDirWrapper is a nasty bitch. It should be called WhackoIOSubSystemDirectory! \n\nPatch improves the handlers + make the tests more resilient so they don't enter an infinite loop (that's part of what Mike hit).\n\nI'm beasting more. Please review the handlers' segments.gen writing logic. ",
            "author": "Shai Erera",
            "id": "comment-13655472"
        },
        {
            "date": "2013-05-12T14:13:24+0000",
            "content": "New patch changes how handlers work:\n\n\n\tBeasting found a seed which uncovered a major problem with their current operation. They were trying to be \"too honest\" with the index and e.g. revert/delete upon any exception that occurred.\n\n\n\n\n\tThanks to MDW, Mike and I decided to keep the handlers simple \u2013 if a handler successfully copies + syncs the revision files, then this is considered the \"new revision\".\n\n\n\n\n\tKissing the index is now done not through IndexWriter, but rather deleting all files not referenced by last commit.\n\t\n\t\tThat cleanup is a best-effort only ... if it fails, it just logs this information and not act on it. Cleanup can happen later too.\n\t\n\t\n\n\n\n\n\tThat means that if you have a really nasty crazy IO system (like MDW sometimes acts), the Replicator is not the one that's going to care about it. The app will hit those weird errors in other places too, e.g. when it tries to refresh SearcherManager or perform search.\n\t\n\t\tThese errors are not caused by the Replicator or bad handler operation. I.e. if the handler successfully called fsync(), yet the IO system decides to fail later ... that's really not the handler's problem.\n\t\n\t\n\n\n\n\n\tTherefore the handlers are now simpler, don't use IW (and the crazy need to rollback()), and once files were successfully copied + sync'd, no more exceptions can occur by the handler (except callback may fail, but that's ok).\n\n\n\n\n\tI also removed the timeout behavior the test employed \u2013 now that ReplicationClient has isUpdateThreadAlive(), assertHandlerRevision loops as long as the client is alive. If there's a serious bug, test-framework will terminate the test after 2 hours ...\n\n\n\n\n\tReplicationClient.startUpdateThread is nicer \u2013 allows starting the thread if updateThread != null, but !isAlive.\n\n\n\nNow beasting this patch. ",
            "author": "Shai Erera",
            "id": "comment-13655543"
        },
        {
            "date": "2013-05-12T20:15:15+0000",
            "content": "Patch adds instance InfoStream members instead of relying on the static default. Beasted 10K+ iterations for both IndexReplicationClientTest and IndexAndTaxonomyReplicationClientTest, all pass.\n\nI think it's ready. I plan to commit it tomorrow. ",
            "author": "Shai Erera",
            "id": "comment-13655632"
        },
        {
            "date": "2013-05-13T11:57:25+0000",
            "content": "[trunk commit] shaie\nhttp://svn.apache.org/viewvc?view=revision&revision=1481804\n\nLUCENE-4975: Add Replication module to Lucene ",
            "author": "Commit Tag Bot",
            "id": "comment-13655915"
        },
        {
            "date": "2013-05-13T12:56:55+0000",
            "content": "Committed to trunk and 4x. Thanks Mike! ",
            "author": "Shai Erera",
            "id": "comment-13655938"
        },
        {
            "date": "2013-05-23T13:16:11+0000",
            "content": "Shair Erera,\nIf I want to try out this feature, how and where should I start? I'm planning to try out in a Master + 2 slaves lucene(integrted with hibernate) setup. ",
            "author": "Shyam V S",
            "id": "comment-13665156"
        },
        {
            "date": "2013-05-23T13:35:06+0000",
            "content": "Shyam, checkout this blog post (http://shaierera.blogspot.com/2013/05/the-replicator.html) which explains how the Replicator works and includes some example code. The javadocs also contain example docs. If you run into any issues, don't hesitate to email java-user@lucene.apache.org. ",
            "author": "Shai Erera",
            "id": "comment-13665171"
        },
        {
            "date": "2013-07-23T18:37:04+0000",
            "content": "Bulk close resolved 4.4 issues ",
            "author": "Steve Rowe",
            "id": "comment-13716738"
        }
    ]
}