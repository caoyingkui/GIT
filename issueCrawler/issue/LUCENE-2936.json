{
    "id": "LUCENE-2936",
    "title": "score and explain don't match",
    "details": {
        "labels": "",
        "priority": "Minor",
        "components": [],
        "type": "Bug",
        "fix_versions": [
            "3.1",
            "4.0-ALPHA"
        ],
        "affect_versions": "2.9.4,                                            3.0.3,                                            3.1,                                            4.0-ALPHA",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "I've faced this problem recently. I'll attach a program to reproduce the problem soon. The program outputs the following:\n\n\n** score = 0.10003257\n** explain\n0.050016284 = (MATCH) product of:\n  0.15004885 = (MATCH) sum of:\n    0.15004885 = weight(f1:\"note book\" in 0), product of:\n      0.3911943 = queryWeight(f1:\"note book\"), product of:\n        0.61370564 = idf(f1: note=1 book=1)\n        0.6374299 = queryNorm\n      0.38356602 = fieldWeight(f1:\"note book\" in 0), product of:\n        1.0 = tf(phraseFreq=1.0)\n        0.61370564 = idf(f1: note=1 book=1)\n        0.625 = fieldNorm(field=f1, doc=0)\n  0.33333334 = coord(1/3)",
    "attachments": {
        "LUCENE-2936.patch": "https://issues.apache.org/jira/secure/attachment/12471684/LUCENE-2936.patch",
        "LUCENE-2936.test.patch": "https://issues.apache.org/jira/secure/attachment/12471787/LUCENE-2936.test.patch",
        "TestScore.java": "https://issues.apache.org/jira/secure/attachment/12471681/TestScore.java"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2011-02-23T03:05:52+0000",
            "content": "Koji: the issue is the document boost of zero.\n\nbecause of this, the explanation does not indicate a match by default (see Explanation.java):\n\n  /**\n   * Indicates whether or not this Explanation models a good match.\n   *\n   * <p>\n   * By default, an Explanation represents a \"match\" if the value is positive.\n   * </p>\n   * @see #getValue\n   */\n  public boolean isMatch() {\n    return (0.0f < getValue());\n  }\n\n\n\nSeparately, we should decide what to do about norm values of zero. In my opinion, norm values of zero should not necessarily decode to a floating point value of zero (we might want to adjust our norm decoder by default to not do this). \n\nOtherwise, in addition to your problem, the search degrades into a pure boolean ranking model (as TF and IDF are completely zeroed out).\n\nThis is really unlikely with the default relevance ranking (unless you use a boost of zero or similar), but is possible e.g. if you use a different SmallFloat quantization. I raised this issue on LUCENE-1360 where if you were to use this \"short field\" quantization on a large document, what should we do?\n\nSo in my opinion, we should consider adjusting the NORM_TABLE in Similarity so that if the norm happens to be zero, it does not decode to a float of zero. This will have no impact on performance as its a statically calculated table. ",
            "author": "Robert Muir",
            "id": "comment-12998136"
        },
        {
            "date": "2011-02-23T03:17:44+0000",
            "content": "here's a patch along the lines i suggested. ",
            "author": "Robert Muir",
            "id": "comment-12998138"
        },
        {
            "date": "2011-02-23T03:18:45+0000",
            "content": "sorry, here is correct patch (I had issue dyslexia) ",
            "author": "Robert Muir",
            "id": "comment-12998139"
        },
        {
            "date": "2011-02-23T07:46:27+0000",
            "content": "Robert: In your patch: Why use exactly that float (looks arbitrary) and not e.g. Float.MIN_VALUE (of course not NEGATIVE_INFINITY!)?\n\nDoesn't matter, just want to understand. ",
            "author": "Uwe Schindler",
            "id": "comment-12998214"
        },
        {
            "date": "2011-02-23T11:29:59+0000",
            "content": "Hi Uwe: you are right! obviously this one needs a comment, but this is the idea:\n\n\nnorm[0]=4.656613E-10\nnorm[1]=5.820766E-10\nnorm[2]=6.9849193E-10\nnorm[3]=8.1490725E-10\n\n ",
            "author": "Robert Muir",
            "id": "comment-12998318"
        },
        {
            "date": "2011-02-23T12:18:05+0000",
            "content": "Here's a new patch...\n\napparently there was code in SmallFloat to specifically do this. This simply removes the bug.\n\nI would like to commit soon. ",
            "author": "Robert Muir",
            "id": "comment-12998341"
        },
        {
            "date": "2011-02-23T14:05:40+0000",
            "content": "\n  public boolean isMatch() {\n    return (0.0f < getValue());\n  }\n\n\n\nIsn't that a bug?\nWe fixed our search code to not discard negative scores, so explain should also handle that? ",
            "author": "Yonik Seeley",
            "id": "comment-12998373"
        },
        {
            "date": "2011-02-23T14:09:58+0000",
            "content": "This line of code was also one of the first things I was thinking about.\n\nI also think this is a bug in explain! ",
            "author": "Uwe Schindler",
            "id": "comment-12998375"
        },
        {
            "date": "2011-02-23T14:09:59+0000",
            "content": "\nIsn't that a bug?\nWe fixed our search code to not discard negative scores, so explain should also handle that?\n\nI agree this is a bad assumption really (although subclasses can override). I am just concerned what explains will 'break' if we fix this.\n\nBut still i think the float quantization issue (the root cause of this problem really) should be fixed... ideally we fix both! ",
            "author": "Robert Muir",
            "id": "comment-12998376"
        },
        {
            "date": "2011-02-23T14:27:30+0000",
            "content": "I'm not sure why this is a quantization issue... SmallFloat handles underflow by mapping to the smallest number greater than 0, so the only way to get a 0 field norm is an explicit boost of 0.\n\nAnyway, if we want to discard explicit representation for 0, some of the code that handled these edge cases should also be modified:\n\n    if (smallfloat < fzero) {\n      return (bits<=0) ?\n        (byte)0   // negative numbers and zero both map to 0 byte\n       :(byte)1;  // underflow is mapped to smallest non-zero number.\n\n ",
            "author": "Yonik Seeley",
            "id": "comment-12998383"
        },
        {
            "date": "2011-02-23T15:08:12+0000",
            "content": "OK, although underflow is generally handled, Robert found at least one case where it doesn't work.\n\nSystem.out.println(SmallFloat.floatToByte315(5.8123817E-10f));\n\nThat prints 0 for some reason.  I'll see if I can figure out why. ",
            "author": "Yonik Seeley",
            "id": "comment-12998403"
        },
        {
            "date": "2011-02-23T15:13:24+0000",
            "content": "Thanks, so the bug is really my imagination (as SmallFloat is designed to generally handle this, its just some corner case i produced in a test).\n\nSo, if we can fix smallfloat my gross hack is not necessary, as we would then only produce byte 0 norms in the case of a zero boost... we can discuss if anything needs to be done there (in my opinion, its not serious, i am only concerned about non-zero floats quantizing to a zero byte).\n\nand then separately we gotta figure out about explains: in my opinion whether or not a document was matched by a query is unrelated to the score... ",
            "author": "Robert Muir",
            "id": "comment-12998406"
        },
        {
            "date": "2011-02-23T19:40:14+0000",
            "content": "Isn't that a bug?\nWe fixed our search code to not discard negative scores, so explain should also handle that?\n\ni hav'nt read hte whole issue, but as i recall this is just a default assumption in hte legacy base class, most use cases should be using the \"Complex\" suclass where the match property can be set explicitly. ",
            "author": "Hoss Man",
            "id": "comment-12998517"
        },
        {
            "date": "2011-02-23T23:45:35+0000",
            "content": "I don't understand 95% of what yonik & robert have been saying in this issue \u2013 but fortunately i don't think that matters \u2013 it sounds like they both agree htat what they are talking about is unrelated to this bug.\n\nhaving said that: once i looked at Koji's example program, i tried making a simple one line change to TestExplanations to set a field boost of \"0\" on some docs, expecting that to trigger failures in TestSimpleExplanations \u2013 but it did not (it did however trigger lots of failures in TestComplexExplanations.\n\nSo i expanded TestSimpleExplanations to include more cases where BooleanQueries included clauses in multiple fields \u2013 one of which had gotten an index time field boost of zero for some documents, and i still couldn't make TestSimpleExplanations fail.\n\nSo then i expanded the patch to also include BooleanQueries containing phrase queries on multiple fields, and then i was finally able to make TestSimpleExplanations in similar ways to what Koji is seeing.\n\npatch with changes to tests to reproduce bug is attached ",
            "author": "Hoss Man",
            "id": "comment-12998614"
        },
        {
            "date": "2011-02-23T23:59:16+0000",
            "content": "\nI don't understand 95% of what yonik & robert have been saying in this issue \u2013 but fortunately i don't think that matters \u2013 it sounds like they both agree htat what they are talking about is unrelated to this bug.\n\n\n\nSorry for the confusion, my issues were actually a separate (corner-case) bug, which yonik fixed already in LUCENE-2937. That bug would cause you to have a field boost of 0 in some very very rare/likely-to-have-never-happened-with-our-default-sim cases when you shouldn't.\n\nSo for this issue we can address the explains, for when you explicitly set boost of zero. ",
            "author": "Robert Muir",
            "id": "comment-12998623"
        },
        {
            "date": "2011-02-24T01:08:47+0000",
            "content": "This superceeds my \"test\" patch by actually including the fix as well.\n\nwhile investigating this, i also discovered some heinous bugs in CheckHits where match and non match were naively been asserted using the explanation value instead of actaully checking \"isMatch\" (which explained why some of my earlier attempts at testing for this bug in PhraseQUery explain didn't surface the problem)\n\nThere may still be other situations where a 0 fieldNorm screws up a score explanation, but this should fix the ones we know about.\n\nwould appreciate a review so we can get this into 3.1 ",
            "author": "Hoss Man",
            "id": "comment-12998645"
        },
        {
            "date": "2011-02-24T13:39:37+0000",
            "content": "would appreciate a review so we can get this into 3.1\n\n+1 to the patch. ",
            "author": "Robert Muir",
            "id": "comment-12998844"
        },
        {
            "date": "2011-02-24T15:19:11+0000",
            "content": "Patch looks great.\n\n\nSo then i expanded the patch to also include BooleanQueries containing phrase queries on multiple fields, and then i was finally able to make TestSimpleExplanations in similar ways to what Koji is seeing.\n\nHoss's assumption is correct because the problem was found at customer site when they used a BooleanQuery containing PhraseQueries (term query on 1-gram fields). ",
            "author": "Koji Sekiguchi",
            "id": "comment-12998889"
        },
        {
            "date": "2011-02-25T00:32:06+0000",
            "content": "fixed in trunk and 3x...\n\nCommitted revision 1074357.\nCommitted revision 1074363. ",
            "author": "Hoss Man",
            "id": "comment-12999154"
        },
        {
            "date": "2011-02-25T00:38:13+0000",
            "content": "Hoss's assumption is correct because the problem was found at customer site when they used a BooleanQuery containing PhraseQueries (term query on 1-gram fields)\n\nsure .. but to be clear: the crux of the issue was really a bug in PhraseQuery \u2013 it wasn't correctly identifying where there was a match/non-match (independently of when the score was zero/non-zero).\n\nthe reason my initial attempt at exposing the bug (by setting an index boost of 0 on some of the fields) didn't cause any of the existing TestSimpleExplanations.testP* to fail was because of the bugs i mentioned in in CheckHits (it was naively looking at hte score to verify when an explanation was for a match/non-match) so the bug didn't show up in the testP* methods until i fixed that.  It did show up in the \"testMultiFieldBQofPQ*\" methods i added because BooleanQuery's explain logic was actually modifying the score of it's explanation based on the match value of the explanation for the sub-queries (because of coord) ",
            "author": "Hoss Man",
            "id": "comment-12999157"
        },
        {
            "date": "2011-03-30T15:49:58+0000",
            "content": "Bulk close for 3.1 ",
            "author": "Grant Ingersoll",
            "id": "comment-13013320"
        }
    ]
}