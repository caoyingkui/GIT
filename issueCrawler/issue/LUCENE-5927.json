{
    "id": "LUCENE-5927",
    "title": "4.9 -> 4.10 change in StandardTokenizer behavior on \\u1aa2",
    "details": {
        "type": "Bug",
        "priority": "Major",
        "labels": "",
        "resolution": "Won't Fix",
        "components": [],
        "affect_versions": "None",
        "status": "Resolved",
        "fix_versions": []
    },
    "description": "In 4.9, this string was broken into 2 tokens by StandardTokenizer:\n\"\\u1aa2\\u1a7f\\u1a6f\\u1a6f\\u1a61\\u1a72\" = \"\\u1aa2\", \" \\u1a7f\\u1a6f\\u1a6f\\u1a61\\u1a72\"\n\nHowever, in 4.10, that has changed so it is now a single token returned.",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "id": "comment-14126035",
            "author": "Robert Muir",
            "content": "From ryan's explanation to me, this only impacts stuff with line break of complex context (it will wrongly split on a combining mark). I think we can be sensible about what we do here (I suggest: nothing), because in such a case you arent getting \"useful\" tokens from the tokenizer anyway unless you are doing downstream processing... and if you are doing that, its very good that this bug is fixed. ",
            "date": "2014-09-08T20:27:35+0000"
        },
        {
            "id": "comment-14126059",
            "author": "Steve Rowe",
            "content": "These characters are in the Tai Tham block, all characters in which have the property LB:ComplexContext, sequences of which are returned as token type <SOUTHEAST_ASIAN>. \n\nThis behavior change is caused by a grammar fix I included with LUCENE-5770 - previous to 4.10, the grammar did not include WB:Format or WB:Extend chars - here are the relevant parts from the 4.9 grammar:\n\n\nContextSupp = ([])  // no supplementary characters in {{LB:ComplexContext}} in Unicode 6.3\n...\nComplexContext    = (\\p{LB:Complex_Context} | {ComplexContextSupp})\n...\n{ComplexContext}+ { return SOUTH_EAST_ASIAN_TYPE; }\n\n\n\nand the 4.10 grammar is now (note the addition of WB:Format and WB:Extend chars):\n\n\nComplexContextEx = \\p{LB:Complex_Context} [\\p{WB:Format}\\p{WB:Extend}]*\n...\n{ComplexContextEx}+ { return SOUTH_EAST_ASIAN_TYPE; }\n\n ",
            "date": "2014-09-08T20:37:24+0000"
        },
        {
            "id": "comment-14126064",
            "author": "Steve Rowe",
            "content": "Ryan Ernst mentioned to me offline that this behavior change should have triggered a version-specific implementation, which did not happen.\n\nI agree, it should have.  \n\nBut now that it's been released, should we include a version-specific implementation in a bugfix 4.10.1 release?  Or wait till 4.11?  Or just stop doing version-specific implementations (as will be the case in 5.x)?\n\nThoughts? ",
            "date": "2014-09-08T20:41:40+0000"
        },
        {
            "id": "comment-14126081",
            "author": "Steve Rowe",
            "content": "I think we can be sensible about what we do here (I suggest: nothing), because in such a case you arent getting \"useful\" tokens from the tokenizer anyway unless you are doing downstream processing... and if you are doing that, its very good that this bug is fixed.\n\nVersion-specific behavior is important for people who don't want changes; IMHO everybody impacted by this change would want it, so I agree: we should do nothing. ",
            "date": "2014-09-08T20:56:57+0000"
        },
        {
            "id": "comment-14126163",
            "author": "Robert Muir",
            "content": "\nOr just stop doing version-specific implementations (as will be the case in 5.x)?\n\nIn my opinion, thats unrelated to this issue (again for this particular issue, I think simulating the old bug is overkill because it just will not be useful). \n\nAs far as the 4.6 unicode changes, the API complexity is out of the way in 5.x.  Analyzers have getVersion/setVersion and if we want to add Lucene40StandardTokenizer and have them make use of this to emulate 4.0 (as opposed to 4.6+) grammar, thats fine. With the API ryan has, it wont cause users \"pain\" and keeps the back compat. ",
            "date": "2014-09-08T21:47:44+0000"
        },
        {
            "id": "comment-14127061",
            "author": "Steve Rowe",
            "content": "(again for this particular issue, I think simulating the old bug is overkill because it just will not be useful).\n\nRyan, are you okay with resolving this issue as won't fix? ",
            "date": "2014-09-09T14:59:05+0000"
        },
        {
            "id": "comment-14127143",
            "author": "Ryan Ernst",
            "content": "Yep, closing. ",
            "date": "2014-09-09T15:57:04+0000"
        }
    ]
}