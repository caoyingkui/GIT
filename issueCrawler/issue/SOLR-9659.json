{
    "id": "SOLR-9659",
    "title": "Add zookeeper DataWatch API",
    "details": {
        "components": [],
        "type": "Improvement",
        "labels": "",
        "fix_versions": [],
        "affect_versions": "None",
        "status": "Open",
        "resolution": "Unresolved",
        "priority": "Major"
    },
    "description": "We have several components which need to set up watches on ZooKeeper nodes for various aspects of cluster management.  At the moment, all of these components do this themselves, leading to large amounts of duplicated code, and complicated logic for dealing with reconnections, etc, scattered across the codebase.  We should replace this with a simple API controlled by SolrZkClient, which should make the code more robust, and testing considerably easier.",
    "attachments": {
        "SOLR-9659.patch": "https://issues.apache.org/jira/secure/attachment/12833936/SOLR-9659.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2016-10-18T12:26:16+0000",
            "author": "Alan Woodward",
            "content": "Patch, outlining the API, but not actually cutting over anything to use it yet.\n\nThere are two types of watch:\n\n\tDataWatch, called any time a znode is updated\n\tChildWatch, called any time a znode's children are changed\n\n\n\nBoth are registered with SolrZkClient, which maintains ZK watches and lists of interested parties.  When a znode is changed, or its children are changed, the SolrZkClient will read the new data/new children, and then send this new information to all registered watchers for that znode.  ZK connection exceptions are all handled internally.  If a connection is dropped and re-established, SolrZkClient will reset all ZK watches, read the latest data, and notify all registered watchers. ",
            "id": "comment-15585335"
        },
        {
            "date": "2016-10-18T12:26:40+0000",
            "author": "Alan Woodward",
            "content": "Paging Scott Blum ... ",
            "id": "comment-15585336"
        },
        {
            "date": "2016-10-18T14:09:06+0000",
            "author": "Keith Laban",
            "content": "It might be worth looking at Apache Curator, if not for the dependency at least to model it after. Their API is very nice and easy to work with. ",
            "id": "comment-15585540"
        },
        {
            "date": "2016-10-18T16:20:03+0000",
            "author": "Erick Erickson",
            "content": "Curator has been mentioned before, but IIRC the response was that it'd be a major undertaking to replace all the current ZK code with curator code. There's also been an enormous amount of work put into hardening the ZK code, don't know how much of that would need to be re-learned.\n\nNot saying it's a bad idea, just that it would need some pretty careful evaluation before diving in. ",
            "id": "comment-15585889"
        },
        {
            "date": "2016-10-18T16:34:46+0000",
            "author": "Keith Laban",
            "content": "I'm not implying a full cutover. But if we were to build a generic API for talking to zk and getting events we might be able to borrow some ideas from Curator.  ",
            "id": "comment-15585924"
        },
        {
            "date": "2016-10-18T17:20:06+0000",
            "author": "Scott Blum",
            "content": "This kind of use case is very much what Curator is supposed to solve.  I agree with the idea that a wholesale cutover to Curator is probably not a great a idea, especially for some of our very complicated custom recipes.  But for something like this, Curator is actually a really good fit.  I think it's worth experimenting for this use case. ",
            "id": "comment-15586042"
        },
        {
            "date": "2016-10-18T17:20:43+0000",
            "author": "Alan Woodward",
            "content": "I started out by looking at Curator, but this API ended up being at a higher level.  Here, clients don't need to care at all about Watcher objects, or ZK exceptions, or anything like that.  Instead, you just say \"I'm interesting in path x/y/z - when the data there changes, call me with the new contents\"; or \"I'm interested in the children of path z/q - when the child list changes, call me with the new list\". ",
            "id": "comment-15586044"
        },
        {
            "date": "2016-10-18T17:22:18+0000",
            "author": "Scott Blum",
            "content": "Specifically, Curator handles some of these concepts:\n1) Maintain a single set of watches with ZK, and dispatch into app code.\n2) Handle disconnect / reconnect, notify watchers of connection events\n3) Automatically re-establish watches on the new session on reconnect. ",
            "id": "comment-15586047"
        },
        {
            "date": "2016-10-18T17:26:07+0000",
            "author": "Scott Blum",
            "content": "Yeah, did you see Curator's NodeCache, PathChildrenCache, TreeCache?  They do basically exactly that, but they have a lot of mileage on them. ",
            "id": "comment-15586055"
        },
        {
            "date": "2016-10-18T17:49:50+0000",
            "author": "Keith Laban",
            "content": "I've used the *Cache recipes Scott is talking about pretty extensively for various projects. It makes doing what you describe pretty trivial. No resetting watches, dealing with timing, dealing with client connections. \n\nBasically, \n1) Create a client\n2) Create a PathChildrenCache or NodeCache for a path\n3) Add a listener for cache changes\n4) Start the cache\n\nEverything else is maintained by Curator. Which has become a pretty battle tested piece of software. ",
            "id": "comment-15586137"
        },
        {
            "date": "2016-10-18T18:19:34+0000",
            "author": "Alan Woodward",
            "content": "Aha, hadn't spotted the *Cache objects.  Yes, I can see they're trying to do the same thing.  And I like the ability to pass in an Executor for running the callbacks as well; I'll extend the patch to add that ability.\n\nMy reservation about going directly to Curator would be that I don't think we want to be maintaining two different frameworks at the same time.  Instead, I'd suggest we gradually hide all the ZK interaction behind some nicer APIs in SolrZkClient, and then we can swap in Curator behind that single point. ",
            "id": "comment-15586220"
        },
        {
            "date": "2016-10-18T18:20:07+0000",
            "author": "David Smiley",
            "content": "I very much like the idea of leveraging Curator at least a little bit.  As already indicated; perhaps Solr will never fully cut-over to that but it's not an all-or-nothing proposition. ",
            "id": "comment-15586224"
        },
        {
            "date": "2016-10-18T19:20:43+0000",
            "author": "Scott Blum",
            "content": "+1 this is really the perfect use case to start experimenting with an incremental move.  I think long term that Curator is a really good idea.  I took a quick look at your patch and it makes me sad imagining the cycle of review, bug discovery, fix etc that would ultimately have to happen when there's already code that handles so much of that subtlety, including issues around re-entrant code, data races, threading, etc. ",
            "id": "comment-15586402"
        },
        {
            "date": "2016-10-18T23:10:22+0000",
            "author": "Alan Woodward",
            "content": "this is really the perfect use case to start experimenting with an incremental move\n\nI've started playing with this now, but what concerns me immediately is that there's no way in Curator to pass in an existing ZK client.  This means that we'd need to maintain two client connections for every SolrZkClient instance, which I can see being very complex to deal with.  What happens if we get a socket error on one of the connections, but not the other, for example?  What if we start adding more security?\n\nDon't get me wrong, I think Curator is great, and it would be cool if we could start to use it.  And I definitely take on board the point that it has a lot more eyeballs than Solr's internals.  But I think an incremental cutover will be very hard, and this API is such an improvement over what we have currently that it's worth going ahead with for now. ",
            "id": "comment-15586971"
        },
        {
            "date": "2016-10-18T23:20:43+0000",
            "author": "Scott Blum",
            "content": "I hear you.  On the other hand, this patch adds a significant amount of new code to Solr that is very difficult to reason about and mentally verify correctness of.  ",
            "id": "comment-15586997"
        },
        {
            "date": "2016-11-07T11:16:51+0000",
            "author": "Alan Woodward",
            "content": "this patch adds a significant amount of new code to Solr\n\nIt's not that big, is it?  The follow-up patch is a lot bigger, but that's mainly removing code that already does what this does, only duplicated in multiple places, and wrong in a couple of them.\n\nIf people are really against this, then I'll close the ticket.  But I think it's a significant improvement, and I don't see any other ways of doing this incrementally. ",
            "id": "comment-15643903"
        },
        {
            "date": "2016-11-07T15:44:26+0000",
            "author": "Erick Erickson",
            "content": "Progress not perfection. I was puzzled a bit by the fact that this code is all additions, then saw the line \"The follow-up patch is a lot bigger\".\n\nMy vote would be to go ahead and commit this and the follow-up. I can imagine we tailor the API going forward to make switching over to Curator easier \"sometime\". Meanwhile if we get something that consolidates scattered complex code that's a win. And having the complex code in one place is a big win IMO.\n ",
            "id": "comment-15644522"
        },
        {
            "date": "2016-11-07T16:00:43+0000",
            "author": "David Smiley",
            "content": "+1 to Erick's sentiment. ",
            "id": "comment-15644559"
        },
        {
            "date": "2016-11-07T18:11:48+0000",
            "author": "Scott Blum",
            "content": "If you want to throw me a PR I'll do my best to review it.  I'm just noting that it's hard to ensure this kind of code is bug free on inspection.  It took several iterations to iron out bugs and race conditions to the new features in ZKStateReader.  You might as well press forward if you're convinced this is the right path, since you're the one with the burning desire to make progress here.  ",
            "id": "comment-15644915"
        },
        {
            "date": "2016-11-22T13:34:52+0000",
            "author": "ASF GitHub Bot",
            "content": "GitHub user romseygeek opened a pull request:\n\n    https://github.com/apache/lucene-solr/pull/118\n\n    SOLR-9659: Add DataWatch API\n\n\n\nYou can merge this pull request into a Git repository by running:\n\n    $ git pull https://github.com/romseygeek/lucene-solr topic/datawatch\n\nAlternatively you can review and apply these changes as the patch at:\n\n    https://github.com/apache/lucene-solr/pull/118.patch\n\nTo close this pull request, make a commit to your master/trunk branch\nwith (at least) the following in the commit message:\n\n    This closes #118\n\n\n\n ",
            "id": "comment-15686770"
        }
    ]
}