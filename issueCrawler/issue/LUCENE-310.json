{
    "id": "LUCENE-310",
    "title": "[PATCH] SegmentReader does unnecessary checks for existence of files",
    "details": {
        "labels": "",
        "priority": "Minor",
        "components": [
            "core/search"
        ],
        "type": "Improvement",
        "fix_versions": [],
        "affect_versions": "1.4",
        "resolution": "Won't Fix",
        "status": "Closed"
    },
    "description": "While investigating some performance issues during queries, I stumbled upon a\nsmall issue in SegmentReader in regards to compound files. Specifically, the\nopenNorms() method takes in the directory to use, but then has its own logic as\nto use that directory or the directory from its base class (IndexReader). When\nan index has many field infos, we have about 30, this logic about checking for\nfiles existing adds a significant overhead. Although this is a small\ninefficiency in a normal file system, our file system is mounted over nfs, and\nthis check is relatively expensive. \n\nThe rest of the class doesn't do this sort of check for other files. By changing\nthis code to work like the rest of the methods in the class (i.e. just using the\npassed in directory), things are a good bit quicker on my end. I don't see any\nissues with this patch.",
    "attachments": {
        "ASF.LICENSE.NOT.GRANTED--compound-file.txt": "https://issues.apache.org/jira/secure/attachment/12312445/ASF.LICENSE.NOT.GRANTED--compound-file.txt"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2004-11-14T06:34:53+0000",
            "content": "Created an attachment (id=13435)\npatch for uneccessary file existence checks ",
            "author": "Kevin Oliver",
            "id": "comment-12322032"
        },
        {
            "date": "2004-11-24T02:09:28+0000",
            "content": "Unfotunately, it is necessary to look for rewritten norm-files. If a segment\nuses a compound file and its norms are changed by setNorm, the new norm-values\ncannot be included into the compound file. You cannot write to a compound file\nafter it has been generated. The new norm-values end up in separate\nfiles and do not get into the compound file before the next merge.\n\nIndexReader allows to rewrite norms. As far as I remember this is needed\nby Nutch to adapt scores to additional information from the link database.\nThat's what Doug explained to me some time ago.\n\nI currently don't see an easy way to get rid of the described inefficiency.\nDefinitely, the patch cannot be applied. ",
            "author": "Christoph Goller",
            "id": "comment-12322033"
        },
        {
            "date": "2004-11-24T03:18:26+0000",
            "content": "Bernhard told me he has already spent considerable time without finding a good\nsolution. So probably there is none and the small performance improvement is\nnot worth to be considered further. ",
            "author": "Christoph Goller",
            "id": "comment-12322034"
        }
    ]
}