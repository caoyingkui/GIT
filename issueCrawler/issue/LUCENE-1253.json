{
    "id": "LUCENE-1253",
    "title": "LengthFilter and other TokenFilters that skip tokens ignore relative positionIncrement",
    "details": {
        "labels": "",
        "priority": "Minor",
        "components": [
            "modules/analysis"
        ],
        "type": "Bug",
        "fix_versions": [
            "3.1",
            "4.0-ALPHA"
        ],
        "affect_versions": "2.3.1",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "See for reference:\nhttp://www.nabble.com/WordDelimiterFilter%2BLenghtFilter-results-in-termPosition%3D%3D-1-td16306788.html\nand http://www.nabble.com/Lucene---Java-f24284.html\n\nIt seems that LengthFilter (at least) could produce a stream in which the first Token has a positionIncrement of 0, which make CheckIndex and Luke function \"Reconstruct&Edit\" to generate exception.\n\nShould something be done to avoid this situation, or could the error be ignored (by allowing Term with a position of -1, and relaxing CheckIndex checks?)",
    "attachments": {
        "LUCENE-1253-trunk.patch": "https://issues.apache.org/jira/secure/attachment/12469784/LUCENE-1253-trunk.patch",
        "LUCENE-1253-3x.patch": "https://issues.apache.org/jira/secure/attachment/12469773/LUCENE-1253-3x.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2008-03-30T21:01:02+0000",
            "content": "the more general question is: should LengthFilter have an option to (or by default) change the position of the Tokens it lets through to be realative the positions of the tokens it strips out.\n\nie given a stream of tokens expressed as <term,positionIncrement> ...\n\n  <a,1> <b,1> <c,1> <ddddd,0> <e,0> <f,2> <ggggg,0> <hhhhhh,1>\n\nshould the resulting stream after using a LengthFilter with min=3 be...\n\n  <ddddd,0> <ggggg,0> <hhhhhh,1>\n\n...(which i believe is the current behavior) or should it be...\n\n   <ddddd,3> <ggggg,2> <hhhhhh,1>\n\nFWIW: StopFilter seems to have code to handle this (but I haven't tested that it works correctly)\n\nThe question of whether or not it's legal for the first token of a stream to have a positionIncrement of \"0\" is being discussed on the list, most likely if it needs changed, that would be done in IndexWriter DocumentsWriter ",
            "author": "Hoss Man",
            "id": "comment-12583486"
        },
        {
            "date": "2008-03-30T21:05:02+0000",
            "content": "tweaking issue Summary to describe the more general problem with LengthFilter ",
            "author": "Hoss Man",
            "id": "comment-12583488"
        },
        {
            "date": "2011-01-26T15:27:33+0000",
            "content": "EDIT: Fixed in LUCENE-1542. ",
            "author": "Uwe Schindler",
            "id": "comment-12987053"
        },
        {
            "date": "2011-01-26T16:04:42+0000",
            "content": "After some discussion with Robert, we realized, that all TokenFilters that remove tokens from the stream must preserve the position increment like StopFilter. Else it could also happen that synonyms of a removed token appear as synonyms of the token before the removed one. If the removed one has posIncr=1, this would produce wrong synonyms.\n\nTwo filters that remove tokanes need to be fixed in the same way like StopFilter:\n\n\tLengthFilter\n\tKeepWordFilter\n\t... (find more and add here)\n\n ",
            "author": "Uwe Schindler",
            "id": "comment-12987075"
        },
        {
            "date": "2011-01-30T15:51:35+0000",
            "content": "Patch for the two broekn TokenFilters and refactoring of StopFilter. Also tests improved. No Version was added, instead the whole thing was done like for StopFilter by a ctor boolean. Tests were added for both Lucene and Solr. Also Solr's KeepWordFilter(+Factory) were changed to respect matchVersion for the CharArraySet. Also synced this filter's factory with the StopFilterFactory (params, parsing,...).\n\nAfter commit to 3.x I will port to trunk - oh no  ",
            "author": "Uwe Schindler",
            "id": "comment-12988602"
        },
        {
            "date": "2011-01-30T16:49:05+0000",
            "content": "After discussion with Robert, we optimized the code of incrementToken() in the base class a little bit to reduce number of branches and method calls for the common cases. ",
            "author": "Uwe Schindler",
            "id": "comment-12988606"
        },
        {
            "date": "2011-01-30T17:06:19+0000",
            "content": "+1, this looks really good.\n\nI looked for other filters, the only other one this could apply to is ChineseFilter, but this one is deprecated\nand we should just leave it alone (it exists for index backwards compatibility only). ",
            "author": "Robert Muir",
            "id": "comment-12988609"
        },
        {
            "date": "2011-01-30T17:21:25+0000",
            "content": "Committed 3.x revision: 1065324\n\nNow porting to trunk, damn! ",
            "author": "Uwe Schindler",
            "id": "comment-12988612"
        },
        {
            "date": "2011-01-30T18:11:29+0000",
            "content": "Merged patch for trunk, Robert can you review, I am totally clumsy now? ",
            "author": "Uwe Schindler",
            "id": "comment-12988623"
        },
        {
            "date": "2011-01-30T18:30:57+0000",
            "content": "Committed trunk revision: 1065343 ",
            "author": "Uwe Schindler",
            "id": "comment-12988628"
        },
        {
            "date": "2011-03-30T15:49:54+0000",
            "content": "Bulk close for 3.1 ",
            "author": "Grant Ingersoll",
            "id": "comment-13013297"
        }
    ]
}