{
    "id": "LUCENE-5373",
    "title": "Lucene42DocValuesProducer.ramBytesUsed is over-estimated",
    "details": {
        "type": "Bug",
        "priority": "Minor",
        "labels": "",
        "resolution": "Fixed",
        "components": [],
        "affect_versions": "None",
        "status": "Resolved",
        "fix_versions": [
            "4.6.1"
        ]
    },
    "description": "Lucene42DocValuesProducer.ramBytesUsed uses RamUsageEstimator.sizeOf(this) to return an estimation of the memory usage. One of the issues (there might be other ones) is that this class has a reference to an IndexInput that might link to other data-structures that we wouldn't want to take into account. For example, index inputs of a RAMDirectory all point to the directory itself, so Lucene42DocValuesProducer.ramBytesUsed would return the amount of memory used by the whole directory.",
    "attachments": {
        "LUCENE-5373.patch": "https://issues.apache.org/jira/secure/attachment/12619643/LUCENE-5373.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "id": "comment-13853098",
            "author": "Shay Banon",
            "content": "as someone who found this issue, on top of the wrong computation, its also very expensive. This call should be lightweight and hopefully not use sizeOf at all... . At the very least, if possible, the result of it should be cached? Maybe even introduce size caching on a higher level (calling code) if possible. ",
            "date": "2013-12-19T18:24:39+0000"
        },
        {
            "id": "comment-13853200",
            "author": "Adrien Grand",
            "content": "Here is a patch. Lucene42DocValuesProducer no more relies on RamUsageEstimator.sizeOf(Object) but instead has a member that stores its memory usage which is incremented every time we load doc values on a new field. This should be both faster and more accurate.\n\nI didn't take into account object alignment, the numeric/binary/fst entries and the size of some small hash tables on purpose to keep size estimation simple. These should be very small compared to the structures that actually store doc values anyway. ",
            "date": "2013-12-19T19:45:25+0000"
        },
        {
            "id": "comment-13853827",
            "author": "Adrien Grand",
            "content": "New patch that adds an CHANGES.txt entry and also fixes Memory and DirectDocValuesProducer. ",
            "date": "2013-12-20T09:49:11+0000"
        },
        {
            "id": "comment-13853839",
            "author": "Robert Muir",
            "content": "can we please use AtomicLong rather than volatile? ",
            "date": "2013-12-20T10:05:56+0000"
        },
        {
            "id": "comment-13853851",
            "author": "Adrien Grand",
            "content": "OK for AtomicLong, here is a new patch. I'll commit soon if there is no objection. ",
            "date": "2013-12-20T10:26:36+0000"
        },
        {
            "id": "comment-13853868",
            "author": "Adrien Grand",
            "content": "New version of the patch with Lucene40DocValuesProducer as well. Unless I missed something, RamUsageEstimator.sizeOf(Object) is not called by SegmentReader.ramBytesUsed() anymore.\n\nYou may still see calls to RamUsageEstimator.sizeOf(native array) but these methods are actually both accurate and fast: they basically just compute NUM_BYTES_ARRAY_HEADER + length * NUM_BYTES_element and return an aligned size. ",
            "date": "2013-12-20T11:10:42+0000"
        },
        {
            "id": "comment-13853871",
            "author": "Simon Willnauer",
            "content": "Thanks for fixing this as well (we spoke offline about this and adrien fixed it before I was able to comment). I actually wonder if RUE.sizeOf(Object) should be test only, it could be in a different patch but this seems very dangerous IMO. There are also classes like AnalyzingSuggester etc. that uses it and I wonder if that can have bad impact on perf. I can already see users calling it in a loop \n ",
            "date": "2013-12-20T11:13:31+0000"
        },
        {
            "id": "comment-13853998",
            "author": "Adrien Grand",
            "content": "It might be tricky in some cases. For example, if we want to keep CachingWrapperFilter.sizeInBytes(), we would probably need to add a ramBytesUsed() method on cacheable filters. Let's open another issue to review usage of RamUsageEstimator? ",
            "date": "2013-12-20T14:37:37+0000"
        },
        {
            "id": "comment-13854030",
            "author": "Simon Willnauer",
            "content": "+1 to another issue ",
            "date": "2013-12-20T15:00:07+0000"
        },
        {
            "id": "comment-13854217",
            "author": "ASF subversion and git services",
            "content": "Commit 1552751 from Adrien Grand in branch 'dev/trunk'\n[ https://svn.apache.org/r1552751 ]\n\nLUCENE-5373: Fix memory usage estimation for [Lucene40/Lucene42/Memory/Direct]DocValuesProducer. ",
            "date": "2013-12-20T17:26:52+0000"
        },
        {
            "id": "comment-13854233",
            "author": "ASF subversion and git services",
            "content": "Commit 1552753 from Adrien Grand in branch 'dev/branches/branch_4x'\n[ https://svn.apache.org/r1552753 ]\n\nLUCENE-5373: Fix memory usage estimation for [Lucene40/Lucene42/Memory/Direct]DocValuesProducer. ",
            "date": "2013-12-20T17:31:13+0000"
        },
        {
            "id": "comment-13854272",
            "author": "ASF subversion and git services",
            "content": "Commit 1552759 from Adrien Grand in branch 'dev/branches/lucene_solr_4_6'\n[ https://svn.apache.org/r1552759 ]\n\nLUCENE-5373: Fix memory usage estimation for [Lucene40/Lucene42/Memory/Direct]DocValuesProducer. ",
            "date": "2013-12-20T17:41:41+0000"
        },
        {
            "id": "comment-13854309",
            "author": "Adrien Grand",
            "content": "Thanks for the reviews! ",
            "date": "2013-12-20T17:50:01+0000"
        }
    ]
}