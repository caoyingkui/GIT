{
    "id": "LUCENE-1756",
    "title": "contrib/memory: PatternAnalyzerTest is a very, very, VERY, bad unit test",
    "details": {
        "labels": "",
        "priority": "Minor",
        "components": [
            "modules/other"
        ],
        "type": "Bug",
        "fix_versions": [
            "2.9.4",
            "3.0"
        ],
        "affect_versions": "None",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "while working on something else i was started getting consistent IllegalStateExceptions from PatternAnalyzerTest \u2013 but only when running the test from the top level.\n\nDigging into the test, i've found numerous things that are very scary...\n\n\tinstead of using assertions to test that tokens streams match, it throws an IllegalStateExceptions when they don't, and then logs a bunch of info about the token streams to System.out \u2013 having assertion messages that tell you exactly what doens't match would make a lot more sense.\n\tit builds up a list of files to analyze using patsh thta it evaluates relative to the current working directory \u2013 which means you get different files depending on wether you run the tests fro mthe contrib level, or from the top level build file\n\tthe list of files it looks for include: \"../../.txt\", \"../../.html\", \"../../*.xml\" ... so not only do you get different results when you run the tests in the contrib vs at the top level, but different people runing the tests via the top level build file will get different results depending on what types of text, html, and xml files they happen to have two directories above where they checked out lucene.\n\tthe test comments indicates that it's purpose is to show that PatternAnalyzer produces the same tokens as other analyzers - but points out this will fail for WhitespaceAnalyzer because of the 255 character token limit WhitespaceTokenizer imposes \u2013 the test then proceeds to compare PaternAnalyzer to WhitespaceTokenizer, garunteeing a test failure for anyone who happens to have a text file containing more then 255 characters of non-whitespace in a row somewhere in \"../../\" (in my case: my bookmarks.html file, and the hex encoded favicon.gif images)",
    "attachments": {
        "LUCENE-1756.patch": "https://issues.apache.org/jira/secure/attachment/12421832/LUCENE-1756.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2009-10-11T22:42:14+0000",
            "content": "improved unit test for this analyzer ",
            "author": "Robert Muir",
            "id": "comment-12764516"
        },
        {
            "date": "2009-10-11T22:50:03+0000",
            "content": "I think this test was complex because it was trying to be a both a test and a benchmark.\n\nI think removing the benchmark stuff is ok, because we can use the benchmark package for that purpose instead? ",
            "author": "Robert Muir",
            "id": "comment-12764518"
        },
        {
            "date": "2009-10-13T18:41:29+0000",
            "content": "assigning this one to myself, if there aren't any objections to the fix I would like to commit it soon. ",
            "author": "Robert Muir",
            "id": "comment-12765187"
        },
        {
            "date": "2009-10-14T12:33:48+0000",
            "content": "Committed revision 825112. ",
            "author": "Robert Muir",
            "id": "comment-12765542"
        },
        {
            "date": "2010-11-28T16:05:31+0000",
            "content": "I am reopening (not setting as blocker since its just a test issue, but it did cause tests to fail when reviewing the release).\n\nworst case, after the release, i think it would be good to backport the new test to the 2.9.x branch. ",
            "author": "Robert Muir",
            "id": "comment-12964566"
        },
        {
            "date": "2010-11-28T16:28:41+0000",
            "content": "Backported to 2.9.4 ",
            "author": "Uwe Schindler",
            "id": "comment-12964569"
        }
    ]
}