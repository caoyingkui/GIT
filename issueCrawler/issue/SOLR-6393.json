{
    "id": "SOLR-6393",
    "title": "Improve transaction log replay speed on HDFS.",
    "details": {
        "affect_versions": "None",
        "status": "Resolved",
        "fix_versions": [
            "4.10",
            "6.0"
        ],
        "components": [],
        "type": "Improvement",
        "priority": "Major",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "Replay speed is pretty slow on HDFS because we currently reopen a reader between reading each update.",
    "attachments": {
        "SOLR-6393.patch": "https://issues.apache.org/jira/secure/attachment/12662981/SOLR-6393.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Mark Miller",
            "id": "comment-14103378",
            "date": "2014-08-20T05:09:34+0000",
            "content": "Patch that only reopens a reader when we move beyond the length of the file being read rather than on every next call. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-14103383",
            "date": "2014-08-20T05:12:40+0000",
            "content": "The brings straight read speed from abysmal to something on par with the local filesystem implementation. That will be signifgant in the case the transaction log needs to be replayed on startup and updates are not coming in.\n\nread/write speed will still hit ugly reader reopens, but should also be much faster as updates will be read in larger batches than one in most cases. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-14104246",
            "date": "2014-08-20T18:04:51+0000",
            "content": "Assuming that\n\nneeds to be replayed on startup and updates are not coming in\nshould read\nneeds to be replayed on startup and updates are coming in "
        },
        {
            "author": "Mark Miller",
            "id": "comment-14104251",
            "date": "2014-08-20T18:08:09+0000",
            "content": "No, it's written right. The second paragraph addresses when updates are also coming in. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-14104262",
            "date": "2014-08-20T18:11:27+0000",
            "content": "Ah, missed that. Thanks! "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14104324",
            "date": "2014-08-20T18:46:28+0000",
            "content": "Commit 1619200 from Mark Miller in branch 'dev/trunk'\n[ https://svn.apache.org/r1619200 ]\n\nSOLR-6393: TransactionLog replay performance on HDFS is very poor. "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14104456",
            "date": "2014-08-20T20:00:55+0000",
            "content": "Commit 1619218 from Mark Miller in branch 'dev/branches/branch_4x'\n[ https://svn.apache.org/r1619218 ]\n\nSOLR-6393: TransactionLog replay performance on HDFS is very poor. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-14104475",
            "date": "2014-08-20T20:09:09+0000",
            "content": "Ah, missed that. Thanks!\n\nThe straight read speed should be really fast now, but when we are updating while reading, when we get to the end of the file we are reading, we have to try and open it again to see if there is anything new. The local fs impl uses channels and doesn't have to do this to see the latest data from the writer. So even when updates are also coming in, this should be a huge improvement, because it was previously reopening needlessly on every update it read, but we do still have to take that hit of opening a new reader every time we read up to the end of the view of the last reader. "
        }
    ]
}