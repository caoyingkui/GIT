{
    "id": "SOLR-6331",
    "title": "possible memory optimization for distributed pivot faceting",
    "details": {
        "affect_versions": "None",
        "status": "Open",
        "fix_versions": [],
        "components": [],
        "type": "Improvement",
        "priority": "Major",
        "labels": "",
        "resolution": "Unresolved"
    },
    "description": "As noted in a comment in PivotFacetField.trim()...\n\n\n// we can probably optimize the memory usage by trimming each level of the pivot once\n// we know we've fully refined the values at that level \n// (ie: fold this logic into refineNextLevelOfFacets)",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "author": "Hoss Man",
            "id": "comment-14088349",
            "date": "2014-08-06T22:05:42+0000",
            "content": "This spun out of an idea i originally floated in SOLR-2894, but didn't move forward on because it will involve quite a bit of refactoring...\n\n\n\n\tthe way refinement currently works in PivotFacetField, after we've refined our values, we mark that we no longer need refinement, and then on the next call we recursively refine the subpivots of each value \u2013 and in both cases we do the offset+limit calculations and hang on to all of the values (both below offset and above limit) as we keep iterating down hte pivots \u2013 they don't get thrown away until the final trim() call just before building up the final result.\n\ti previously suggested folding the trim() logic into the NamedList response logic \u2013 but now i'm wondering if the trim() logic should instead be folded into refinement? so once we're sure a level is fully refined, we go ahead and trim that level before drilling down and refining it's kids?\n\n "
        },
        {
            "author": "Brett Lucey",
            "id": "comment-14095575",
            "date": "2014-08-13T15:18:01+0000",
            "content": "I think that should be feasible.  Previously, we re-validated each level as we refined.  Now we mark a level as complete.  Once we know it's complete, I think we should be able to trim during refinement as you suggest and release some of the memory.  I definitely think it's worth getting SOLR-2894 committed before looking at this optimization though, and I assume you agree since you separated this out into a separate Jira issue? "
        },
        {
            "author": "Hoss Man",
            "id": "comment-14095677",
            "date": "2014-08-13T16:36:39+0000",
            "content": "I assume you agree since you separated this out into a separate Jira issue?\n\nyeah ... it seems like it could be a good memory optimization, but i'm not confident in the feasibility, and didn't want to tackle a huge refactoring like that w/o a high degree of confidence in the gains ... at least not until the existing code gets committed and beaten on by jenkins on a regular basis. "
        }
    ]
}