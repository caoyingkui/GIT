{
    "id": "LUCENE-4557",
    "title": "Indexed Offsets Can Be Lost During Merge",
    "details": {
        "components": [],
        "fix_versions": [],
        "affect_versions": "4.0",
        "priority": "Major",
        "labels": "",
        "type": "Bug",
        "resolution": "Unresolved",
        "status": "Reopened"
    },
    "description": "Primary Use case:\nStart with pre-4.0 index (no indexed offsets available)\nStart indexing new documents with indexed offsets (IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS, previously was IndexOptions.DOCS_AND_FREQS_AND_POSITIONS)\nmerge/optimize index\n\nnewly indexed documents will now no longer have offsets available\n\nIn general, it is impossible to ever change a field to have offsets indexed when starting with an existing index as a merge will cause offsets to be removed from the index.\n\nDesirable behavior would be for new documents to have offsets indexed properly, and old documents would have offset of \"0, 0\" for all positions after merging with a segment that contains offsets\n\nCurrent behavior can be very dangerous.\nfor example:\n\n\tStart indexing documents with indexed offsets\n\tchange config to not index offsets by accident\n\tindex 1 document\n\trevert config back\n\toffsets will start disappearing from documents as segments are merged",
    "attachments": {
        "OffsetsTest.java": "https://issues.apache.org/jira/secure/attachment/12553497/OffsetsTest.java"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2012-11-14T14:38:11+0000",
            "content": "Attaching test that shows issue\n ",
            "author": "Tim Smith",
            "id": "comment-13497129"
        },
        {
            "date": "2012-11-14T15:29:52+0000",
            "content": "This isn't a problem: its like omitting frequencies and positions, you cant \"get them back\" as you lost that information.\n\nIf you have a pre-4.0 index, you lost this offsets information after indexing time. so if you want offsets in the index, then re-index  ",
            "author": "Robert Muir",
            "id": "comment-13497158"
        },
        {
            "date": "2012-11-14T15:35:16+0000",
            "content": "I disagree with that assessment\n\nthe problem here is not that offsets are not available on \"old docs\" \n\nthe problem is that offsets are destroyed on documents that had them set properly. This is very much a bug.\na small temporary config mistake by a user can cause destruction of indexed data during merging. even after corrected.\n\nAs far as i'm concerned, this issue makes it unfeasible to ever use indexed offsets even though i very much want to.\n\nreindexing data is quite often out of the question when large indexes are involved.\n\n\n\n\n ",
            "author": "Tim Smith",
            "id": "comment-13497160"
        },
        {
            "date": "2012-11-14T16:25:05+0000",
            "content": "Seriously, the behavior is no different here than omitTF has been throughout past releases.\n\nThe only thing I don't like is that indexwriter doesn't throw an exception if you try to add a field\nwith incompatible indexing properties (e.g. you try to turn on offsets when they are already off,\nor you try to add norms when they are off, or you try to index with positions when you previously omitted TF).\n\nAdding fake data is out of the question: if you want to populate your index with bogus offsets,\nthen make a BogusOffsetsFilterReader, call addIndexes, and rewrite your postings with this bogus data.\n\nThen run checkIndex: we are pretty picky about what the offset values can be. ",
            "author": "Robert Muir",
            "id": "comment-13497195"
        },
        {
            "date": "2012-11-14T16:35:08+0000",
            "content": "i understand the similarity to the omitTF case, but would argue that too is a bug\n\nthe main issue here is with merging\n\nmerging currently seems to choose the most restrictive case for IndexOptions for a field instead of the most general \n\nwhen you are writing new segments and you provide contradictory IndexOptions for the same field, it is ok for the writer to produce new segments with the most restrictive set (or throw an exception at this point), i have no argument there\n\nhowever, when it comes to merging existing segments, no indexed data should be lost (as in this case)\n\nif you have 2 segments with the following:\nSegment 1: docs and freqs and positions\nSegment 2: docs and freqs and positions and offsets\n\nthe merged segment should have the following\nMerged: docs and freqs and positions and offsets\n\nthe offsets for docs that were part of segment 1 should be null/(start=0, end=0), or better yet (-1, -1) if possible\nthe offsets for docs that were part of segment 2 should be the proper offsets that were indexed for segment 2 in the first place\n\nThe same rule could also be applied to the omit tf case:\nSegment 1: Docs Only\nSegment 2: Docs And Freqs And Positions\n\nMerged: docs and freqs and positions\ndocs from segment 1 should have frequency 1 and a single position of 0\n\n\n\n\n\n\n\n\n\n\n ",
            "author": "Tim Smith",
            "id": "comment-13497208"
        },
        {
            "date": "2012-11-14T17:24:29+0000",
            "content": "I really disagree with adding fake data, as I said I think updateDocument should \nthrow an exception here if the fieldinfos disagree. Same goes for addIndexes.\n\nIf you want to add fake data to your index, thats your decision, again wrap \nyour reader with a FilterReader that adds fake data. ",
            "author": "Robert Muir",
            "id": "comment-13497242"
        },
        {
            "date": "2012-11-14T17:53:40+0000",
            "content": "i understand your aversion to what i suggest, however i still argue this is a pretty nasty bug given that indexed content is lost\n\ni also argue that it should be fully supported to change settings on fields as time goes on, especially the ability to make the field more general (add positions/offsets/insertnewfeaturehere). Old data would of course be limited to the settings the data was indexed with. However, new content should not be restricted to old settings.\n\nWithout supporting this, you are forcing full reindexes in situations that really should not require it.  This is a big red flag in my opinion.\n\n\nfrom what i understand of your FilterReader suggestion, it would require me to do the equivalent of an index optimize in order to \"upgrade/convert\" the index to the have (0,0) offsets on segments that were lacking this setting?\n\nThis seems extremely expensive, and would require me to detect this situation at index startup time, and then spend very large amounts of time performing the conversion all blocking indexing from continuing until this operation is over.\n\nControlling this behavior at merge time seems to be the appropriate place.\nAs long as i could control the merge behavior via a pluggable/configurable API i would be happy, and  any other users that encounter this issue would also have a means to address it.\nLooks like merging of segments data is not exposed at all, so right now there is no way to handle this situation properly.\n\nFor instance, if i could wrap the SegmentReader at merge time to provide null offsets that would be fine. Ideally, there would be some means to still support efficient bulk merging of stored fields/term vectors etc.\n\n\n\n\n ",
            "author": "Tim Smith",
            "id": "comment-13497278"
        },
        {
            "date": "2012-11-14T19:00:37+0000",
            "content": "\nWithout supporting this, you are forcing full reindexes in situations that really should not require it.\n\nRight, i'm intentionally forcing a reindex, because you discarded this information before (by specifying indexing these indexing options), you must reindex with the new options.\n\nThere's no possible way you can convince me that lucene should support creation of fake data. ",
            "author": "Robert Muir",
            "id": "comment-13497347"
        },
        {
            "date": "2012-11-14T19:12:34+0000",
            "content": "i know you aren't changing your mind\n\ni also disagree with calling this \"fake\" data\nthe data would be 100% representative of what was indexed\n\nwhat i would at least like to see is a reasonable means to support this functionality.\n\nI propose some means to support more pluggable segment merging:\n\nfor instance, if IndexWriter had the following method:\n\npublic AtomicReader getSegmentForMerge(SegmentReader reader) {\n  return reader; // default implementation does nothing.\n\n\n\nthen i could override this method, wrap reader and enhance its indexed content as it is merging in order to fulfill my requirements.\n\nThis would have additional benefits including but not limited to:\n\n\tSupporting migration of IndexOptions on fields\n\tSupporting migration of sort fields from indexed fields to DocValues\n\tSupport converting data types for DocValues\n\tand so on\n\n\n\nThis wrapping would just need to be smart (a good MergeSegmentReader base class that SegmentMerger is integrated with) in order to optimize bulk merges of stored fields/termvectors/etc\n\nif this is a more palatable approach for you, i can work up a patch as i find time\n\n\n\n\n\n\n\n\n\n\n\n ",
            "author": "Tim Smith",
            "id": "comment-13497354"
        },
        {
            "date": "2012-11-14T20:53:16+0000",
            "content": "\ni also disagree with calling this \"fake\" data\nthe data would be 100% representative of what was indexed\n\nWell, its fake in the sense that this segment now advertises that it was indexed with things\nlike positions, but in fact it has no positions: its essentially corrupt.\n\nSo for example, if you populate bogus frequencies, positions, offsets, and so on, and also\nhave term vectors, then later when you run CheckIndex it will report the segment is corrupt if\nthese values disagree.\n\nThis is because CheckIndex (for good reasons) exploits any possible redundancies in the index\nto detect if data is wrong.\n\n\nif this is a more palatable approach for you, i can work up a patch as i find time\n\nThis is definitely more palatable, though sneaky that it wouldnt be called if you did addIndexes(IR)?\nSo maybe the proposed method should take AtomicReader...\n\n\nThis wrapping would just need to be smart (a good MergeSegmentReader base class that SegmentMerger is integrated with) in order to optimize bulk merges of stored fields/termvectors/etc\n\nI don't think this is a good idea: I think in your case you would just return the original reader\nunless you needed to 'migrate something'. This way you get the bulk merging optimizations when its safe\nbut not when its unsafe. \n\nFor example if you are lying about positions or offsets, then you need to ensure the vectors are consistent\ntoo (or drop them). Its not safe to bulk merge them.\n ",
            "author": "Robert Muir",
            "id": "comment-13497429"
        },
        {
            "date": "2012-11-14T21:15:30+0000",
            "content": "getSegmentForMerge could of course take AtomicReader to support addIndexes as well\n\n\nCheckIndex validates indexed positions/offsets against term vectors?\nisn't this really slow?\n\n\nAlso, if term vectors were indexed with offsets, and the positions did not have offsets, and offsets are being added to positions as part of the merge, i could easily have my MergeReader enhance the indexed positions offsets from the term vectors. \nOf course this would be a slower merge, but it would then have 100% the right data and not result in the corruption you allude to. This would then make term vectors consistent and suitable for bulk merge. (right now i don't have a use case that would have offsets indexed for both term vectors and positions (it'd be one or the other), but its helpful you pointed this issue out so i can make sure it would be handled properly in the future)\n\n\nHow about i look at working on a patch going down the pluggable segment data merging and we can iterate from there?\n\n\n\n ",
            "author": "Tim Smith",
            "id": "comment-13497459"
        },
        {
            "date": "2012-11-15T15:41:08+0000",
            "content": "Spun off LUCENE-4560 for supporting filtering during segment merging.\npatch will be forthcoming shortly\n\nas long as that gains traction and makes it in, i will be happy (this will actually fulfill numerous other use cases i have).\n\nI still consider this issue a bug given indexed content is lost and would recommend against closing this ticket, however LUCENE-4560 will provide a more than adequate solution for my needs. ",
            "author": "Tim Smith",
            "id": "comment-13498079"
        }
    ]
}