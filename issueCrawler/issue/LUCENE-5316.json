{
    "id": "LUCENE-5316",
    "title": "Taxonomy tree traversing improvement",
    "details": {
        "components": [
            "modules/facet"
        ],
        "fix_versions": [],
        "affect_versions": "None",
        "priority": "Minor",
        "labels": "",
        "type": "Improvement",
        "resolution": "Unresolved",
        "status": "Open"
    },
    "description": "The taxonomy traversing is done today utilizing the ParallelTaxonomyArrays. In particular, two taxonomy-size int arrays which hold for each ordinal it's (array #1) youngest child and (array #2) older sibling.\n\nThis is a compact way of holding the tree information in memory, but it's not perfect:\n\n\tLarge (8 bytes per ordinal in memory)\n\tExposes internal implementation\n\tUtilizing these arrays for tree traversing is not straight forward\n\tLose reference locality while traversing (the array is accessed in increasing only entries, but they may be distant from one another)\n\tIn NRT, a reopen is always (not worst case) done at O(Taxonomy-size)\n\n\n\nThis issue is about making the traversing more easy, the code more readable, and open it for future improvements (i.e memory footprint and NRT cost) - without changing any of the internals. \nA later issue(s?) could be opened to address the gaps once this one is done.",
    "attachments": {
        "LUCENE-5316.patch": "https://issues.apache.org/jira/secure/attachment/12611072/LUCENE-5316.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2013-10-30T10:51:46+0000",
            "content": "+1 to make the API more \"abstract\".\n\nIt would be nice if the new API could somehow allow for efficiently accommodating \"flat\" fields, where the only hierarchy is that dim's root (e.g., \"Country/\", and then all values are immediately under that root.\n\nAnother use-case is private ords for certain dimensions (needed for LUCENE-5308.\n\nDoesn't the current impl consume 3 ints (12 bytes) per ord?  (parents, children, siblings) ",
            "author": "Michael McCandless",
            "id": "comment-13808951"
        },
        {
            "date": "2013-10-30T11:05:04+0000",
            "content": "Thanks Mike, you're right on the money.\n\nThe ram consumption is indeed an issue here.\nI'm not sure that the parent array is used during search at all... and perhaps could be removed (looking into that one as well).\nThe youngestChild/olderSibing arrays should and could be replaces with either a more compact RAM representation, or at extreme cases, even on-disk.\n\nFor a better RAM representation, the idea of a map from ord -> int[] of it's children is a start.\nIn such a case, we benefit from not holding a 'youngerChild' int for each ordinal in the flat dimension - as they have no children.\n2nd, we could benefit from the locality of ref, as all the children are near by and not spread over an array of millions. The non-huge-flat dimensions will no longer suffer because of the other dimensions.\nAlso, it would make the worst case of NRT the same as the current update (O(Taxo-size)) but might be very small if only a few ordinals were added, as only their 'family' would be reallocated and managed, rather than the entire array.\n\nAt a further phase - a compression could be allowed into that int[] of children - we know the children are in ascending order, and could only encode the DGaps, figure the largest DGAP and use packed ints instead of the int[]. It would add some (I hope) minor CPU consumption to the loop, but would benefit greatly when it comes to RAM consumption. \nI hope that all the logic could be encapsulated in the ChildrenIterator and the user will benefit from a clean API and better RAM utilization.\n\nI'll post a patch shortly, which covers the very first part - hiding the implementation detail of children arrays (making TaxoReader.getParallelTaxoArrays protected to begin with), and moving TopKFacetResultHandler to use ChildrenIterator. \n\nCurrently debugging some nasty loop-as-a-recursion related bug  ",
            "author": "Gilad Barkai",
            "id": "comment-13808968"
        },
        {
            "date": "2013-10-30T14:21:24+0000",
            "content": "TaxonomyReader.getParallelTaxonomyArrays is now protected, the implementation is only on DirectoryTaxonomyReader in which it is protected as well.\n\nParallel arrays are only used in tests ATM - all tree traversing is done using TaxonomyReader.getChildre(int ordinal) which is now abstract, and implemented in DirTaxoReader.\n\nMike, if you could please run this patch against the benchmarking maching it would be awesome - as the direct array access is now switched with a method call (iterator's .next()\n\nI hope we will not see any significant degradation. ",
            "author": "Gilad Barkai",
            "id": "comment-13809134"
        },
        {
            "date": "2013-10-30T15:40:48+0000",
            "content": "Thanks Gilad, I ran a performance test, on full English Wikipedia.  I\nindexed all dims as NO_PARENTS so we exercise visiting all children\n(rollup).  Also, two flat dims (username, categories) have high\ncardinality ... it looks like there is a high fixed cost, because the\nrelatively easy queries seem to lose the most perf:\n\n\n                    Task    QPS base      StdDev    QPS comp      StdDev                Pct diff\n              AndHighLow       59.93      (2.6%)       44.81      (4.9%)  -25.2% ( -31% -  -18%)\n               MedPhrase       42.82      (2.1%)       34.59      (4.1%)  -19.2% ( -24% -  -13%)\n                 LowTerm       40.13      (1.8%)       32.68      (3.3%)  -18.6% ( -23% -  -13%)\n            OrNotHighLow       33.20      (3.8%)       27.64      (4.2%)  -16.8% ( -23% -   -9%)\n                  Fuzzy1       30.74      (1.6%)       26.15      (3.0%)  -14.9% ( -19% -  -10%)\n                  Fuzzy2       24.95      (1.8%)       21.78      (2.9%)  -12.7% ( -17% -   -8%)\n         LowSloppyPhrase       24.11      (1.2%)       21.22      (2.8%)  -12.0% ( -15% -   -8%)\n            OrNotHighMed       19.85      (2.8%)       17.68      (3.4%)  -10.9% ( -16% -   -4%)\n             MedSpanNear       17.94      (2.3%)       16.34      (3.4%)   -8.9% ( -14% -   -3%)\n              AndHighMed       16.26      (1.3%)       14.88      (2.1%)   -8.4% ( -11% -   -5%)\n             AndHighHigh       13.95      (0.9%)       12.91      (1.9%)   -7.4% ( -10% -   -4%)\n                 Prefix3       13.24      (1.2%)       12.34      (1.9%)   -6.8% (  -9% -   -3%)\n                 MedTerm       12.85      (0.8%)       12.01      (1.8%)   -6.6% (  -9% -   -3%)\n           OrNotHighHigh        9.79      (1.5%)        9.29      (2.2%)   -5.1% (  -8% -   -1%)\n               LowPhrase        9.50      (5.5%)        9.05      (4.9%)   -4.7% ( -14% -    6%)\n                HighTerm        8.65      (1.2%)        8.28      (1.7%)   -4.2% (  -7% -   -1%)\n             LowSpanNear        7.40      (3.8%)        7.13      (4.6%)   -3.7% ( -11% -    4%)\n            OrHighNotMed        7.19      (1.4%)        6.96      (1.7%)   -3.2% (  -6% -    0%)\n               OrHighMed        5.64      (1.3%)        5.51      (1.4%)   -2.3% (  -4% -    0%)\n           OrHighNotHigh        4.80      (1.3%)        4.71      (2.1%)   -1.9% (  -5% -    1%)\n                Wildcard        4.60      (1.8%)        4.51      (1.5%)   -1.8% (  -5% -    1%)\n            OrHighNotLow        4.12      (1.1%)        4.06      (1.5%)   -1.5% (  -3% -    1%)\n               OrHighLow        2.81      (1.1%)        2.78      (1.2%)   -1.0% (  -3% -    1%)\n            HighSpanNear        3.24      (2.9%)        3.22      (3.0%)   -0.8% (  -6% -    5%)\n              OrHighHigh        2.09      (1.1%)        2.08      (1.4%)   -0.6% (  -3% -    1%)\n                  IntNRQ        1.50      (1.1%)        1.50      (0.8%)   -0.6% (  -2% -    1%)\n         MedSloppyPhrase        3.20      (5.2%)        3.19      (7.0%)   -0.5% ( -11% -   12%)\n              HighPhrase        2.73      (6.3%)        2.72      (5.7%)   -0.3% ( -11% -   12%)\n                 Respell       52.93      (2.4%)       52.76      (3.2%)   -0.3% (  -5% -    5%)\n        HighSloppyPhrase        3.28      (6.9%)        3.32      (9.3%)    1.2% ( -14% -   18%)\n\n\n\nMaybe ... we should allow .getChildren to return null when that ord\nhas no children?  I.e., I think the cost might be because are visiting\na great many ords for the \"flat\" fields.\n\nSeparately, perhaps taxo index could tell us when a dim is flat and\nthen we can avoid doing rollup.  Really for such dims, I should index\nthem as ALL_BUT_DIM, but it'd be nice if I do NO_PARENTS if the facets\ncode detected that the dim is actually flat and optimized\naccordingly... ",
            "author": "Michael McCandless",
            "id": "comment-13809247"
        },
        {
            "date": "2013-10-31T10:11:52+0000",
            "content": "I like the null for ordinals with no siblings. Made the change, and now I'm chasing all the NPEs that it caused, hope to get a new patch up and about soon.\n\nAs for allowing the taxo to say the depth for each dim - that's more trickie. Obviously, that's a temporal state, as ever flat dimension can become non flat. \nAlso figuring this our during search (more like, once per opening the taxo-reader) is o(taxoSize) at the current implementation.\n\nPerhaps, if we're willing to invest a little more time during indexing, we could \"roll up\" and tell the parents (say, in an incremental numeric field update) \"how low can you go\" with its children?\nIn such a case, we could benefit not only from a flat dimension, but whenever an ordinal has no grandchildren. Investing during indexing will make it an O(1) operation. ",
            "author": "Gilad Barkai",
            "id": "comment-13810087"
        },
        {
            "date": "2013-10-31T11:03:43+0000",
            "content": "Investing during indexing will make it an O(1) operation.\n\nRight, I think it can be very simple for starters: a per-dim boolean isFlat, that we set to false as soon as we see any grandchildren added under that dim (any CategoryPath with more than two components).  We could similarly record if ever a dim was multi-valued, but I'm not sure how we can take advantage of that.  We'd need to persist this somewhere... ",
            "author": "Michael McCandless",
            "id": "comment-13810132"
        },
        {
            "date": "2013-11-02T18:53:18+0000",
            "content": "Using NO_PARENTS is not that simple decision, since the counts of the parents will be wrong if more than one category of that dimension is added to a document. If it's a flat dimension, and you don't care about the dimension's count, that may be fine. But if it's a hierarchical dimension, the counts of the inner taxonomy nodes will be wrong in that case.\n\nWhile indexing as NO_PARENTS does exercise the API more, I think it's wrong to test it here. NO_PARENTS should be used only for hierarchical dimensions, in order to save space in the category list and eventually (hopefully) speed things up since less bytes are read and decoded during search. But for flat dimensions, it adds the rollupValues cost. If we make the search code smart to detect this is a flat dimension, we'd save that cost (no need to rollup), but I think in general you should tweak OrdPolicy to NO_PARENTS only for hierarchical dimensions. I wonder what the perf numbers will be if you used NO_PARENTS only for the hierarchical dims - that's what we recommend the users to use, so I think that's what we should benchmark.\n\nI'll review the patch later. ",
            "author": "Shai Erera",
            "id": "comment-13812112"
        },
        {
            "date": "2013-11-02T23:17:51+0000",
            "content": "OK I will re-test, using NO_PARENTS only for the hierarchical field.  The problem is, the Wikipedia docs have only one such field, date (Y/M/D), and it's low cardinality.\n\nActually, Wikipedia does have a VERY big taxonomy but I've never succeeded in extracting it...\n\nSo net/net, I will re-test, but I feel this can easily give a false sense of security since my test data does not have a \"big\" single-valued hierarchical field... ",
            "author": "Michael McCandless",
            "id": "comment-13812214"
        },
        {
            "date": "2013-11-03T04:29:31+0000",
            "content": "How about if you make up a hierarchical category, e.g. charCount/0-100K/0-10K/0-1K/0-100/0-10? If there will be candidates in all ranges, that's 100K nodes. Also, we can hack a hierarchical dimension made up of A-Z/A-Z/A-Z... and randomly assign categories at different levels to documents.\n\nBut, NO_PARENTS is not the only way to exercise the API. By asking top-K on a big flat dimension, when we compute the top-K for that dimension we currently traverse all its children, to find which of them has count>0. So the big flat dimensions also make thousands of calls to ChildrenIterator.next(). ",
            "author": "Shai Erera",
            "id": "comment-13812260"
        },
        {
            "date": "2013-11-03T07:14:19+0000",
            "content": "Updated version, iterator now returned as null if ordinal has no children.\n\nI think there are further improvements (a few {{if}}s and a loop check which could be avoided) but at least currently the .next() call is avoided as per Mike's suggestion. Hope this speed things up a bit. ",
            "author": "Gilad Barkai",
            "id": "comment-13812281"
        },
        {
            "date": "2013-11-03T08:27:41+0000",
            "content": "Few comments:\n\n\n\tIn IntRollupFacetsAggregator.rollupValues, I think we shouldn't recurse if childrenIterator == null, rather than recurse, check for null and return?\n\t\n\t\tSame for SumScoreFacetsAggregator.\n\t\n\t\n\n\n\n\n\tTopKFacetResultsHandler - the code checks that kids != null, but as far as I can tell from the patch, it later does childStack[localDepth] = kids, and then later sort of assumes childStack[localDepth] isn't null and calls .next(). Maybe I'm missing the bigger picture (I haven't applied the patch, just reviewing it) and the method exits if there are no children?\n\t\n\t\tThe same code is executed afterwards with the comment 'push next kid to the stack'.\n\t\n\t\n\n\n\n\n\tTopKInEachNodeHandler:\n\t\n\t\tThere's a nocommit which I think can be removed as the surrounding lines are commented out\n\t\tHere too I see that ChildrenIterator is assigned to the childStack, and later on it's used, assuming it's not null. Maybe it's safe because you assign ordinalStack[localDepth] = INVALID_ORDINAL, and so the loop doesn't actually gets to use childStack[localDepth]?\n\t\n\t\n\n\n\n\n\tTestDirectoryTaxonomyReader - why did you have to change the declarations from TR to DTR?\n\n\n\nSome general comments:\n\n\n\tIf we're making changes to the API already, how about if we consolidate getPTA() and getChildren() into a single getTaxonomyTree() (return TaxonomyTree) with, for now, a single getChildren(int ord) API. It can be useful for browsing the taxonomy in general, and the search code can use it too.\n\t\n\t\tI don't see where we make use of the parents() API besides tests and DirTaxoWriter.getParent(), but this needs to change too \u2013 TaxoWriter does not need to hold a TaxoTree object, only to be able to tell the parent of an ordinal (used when indexing the full path ordinals in the category list.\n\t\n\t\n\n\n\n\n\tI think that we should experiment here with a TaxoTree object which holds the children in a map. Could be that even though the ChildrenIterator may add some overhead, overall we'll see some gains.\n\t\n\t\tAlso, the title of the issue is about improving the taxonomy tree traversal, so just moving to getChildren() is not exactly an improvement .\n\t\tWe can, if it's too complicated to resolve here, think about how to allow DirTaxoReader extensions to provide their own TaxoTree object in a separate issue.\n\t\n\t\n\n ",
            "author": "Shai Erera",
            "id": "comment-13812294"
        },
        {
            "date": "2013-11-03T08:49:51+0000",
            "content": "The patch is not ready for commit - I just got a stackoverflow in my head while chasing this NPEs in the loop-as-recursion thing... \nShai, you are right in the sense that we could avoid an extra loop/recursion if the kids are null, but this now works, doesn't throw NPEs in weird places and allows returning null while not calling the extra CI.next().\nI'm still looking into that. \nI touched the recurring loop as little as possible, as I'm not 100% sure I understand it fully (also, changing a small innocent thing breaks things bad). In the old code there were hidden assumptions which are now no longer true, I traced some but not sure about others.\n\nhow about if we consolidate getPTA() and getChildren() into a single getTaxonomyTree()\nAs for the API change - getPTA is being quietly - though with determination - swapped off. getChildren is all that is left.\nI'm not sure .getChildren() should be encapsulated with a TaxononyTree object if it's the only API.\nDo you think other API should be put there as well?\n\nI think that we should experiment here with a TaxoTree object which holds the children in a map\nThe current issue is not yet done, there are still tests to consider and hiding PTA even further from the users' eyes.\nI feel that this issue is big enough to stand for itself, while the children map is also large enough? It would contain code for the iterations but also some code in the taxo-reopen phase, that will replace (hopefully ) the PTA reopen code. ",
            "author": "Gilad Barkai",
            "id": "comment-13812297"
        },
        {
            "date": "2013-11-03T10:22:10+0000",
            "content": "\nI'm not sure .getChildren() should be encapsulated with a TaxononyTree object if it's the only API.\nDo you think other API should be put there as well?\n\nWhen I wrote it, I thought it should have a parent(int ord) API as well, but then I changed my mind. I agree that we don't need a TaxoTree with a single API at the moment. Let's stick w/ getChildren. If we'll want to allow overriding how children are represented, we may want to have an internal TaxoTree object, that's not exposed on the public API, but apps can provide their own so we delegate getChildren to it.\n\n\nI feel that this issue is big enough to stand for itself, while the children map is also large enough? It would contain code for the iterations but also some code in the taxo-reopen phase, that will replace (hopefully ) the PTA reopen code.\n\nI'm not sure, but I don't weigh the issues by the sizes of their patch. If after all this hassle, it turns out that even the map approach severely hurts performance, there's no reason to make any changes to the API. I hope that this won't be the case, but judging from the benchmark Mike ran, this change doesn't look good. I still hope it will look better when we test NO_PARENTS only for the hierarchical dimensions, but we shouldn't make changes to the API if net/net we'll only lose. The RAM consumption of the arrays is not that worrying, since taxonomies are not that large (even a huge taxonomy w/ 2.5M nodes consumes only 30MB!).\n\nSo IMO this issue should be about (and it can be done in steps):\n\n\n\tAbstract the children API and verify this alone doesn't hurt performance. If so, that's great. We should also remove PTA entirely from the API in that case.\n\tExperiment with a different in-memory representation - this can be done as a hack even in the current TaxoIndexArrays \u2013 when computeChildrenSiblings is called, build a the map. That way you don't need to interfere w/ any reopen logic, it's all internal to TaxoIndexArrays.\n\t\n\t\tIf we discover that this rep loses performance, we can decide if we want to keep the API abstraction or drop it altogether. But I feel that we need to at least experiment w/ an alternative representation before we change the API. Those API abstractions hurt the performance in the past - let's not make the same mistake again.\n\t\n\t\n\n ",
            "author": "Shai Erera",
            "id": "comment-13812315"
        },
        {
            "date": "2013-11-04T11:21:13+0000",
            "content": "How about if you make up a hierarchical category, e.g. charCount/0-100K/0-10K/0-1K/0-100/0-10? \n\nOh, right, I forgot I already have this hierarchical dim ... but I ran\nPrintFacetStats and it only results in 1086 ords (less than date at\n3279 ords).\n\nI tested Gilad's latest patch still using NO_PARENTS (change one thing\nat a time):\n\n\n                    Task    QPS base      StdDev    QPS comp      StdDev                Pct diff\n              AndHighLow       60.84      (3.5%)       45.81      (0.9%)  -24.7% ( -28% -  -21%)\n               MedPhrase       43.63      (2.9%)       35.16      (1.0%)  -19.4% ( -22% -  -15%)\n                 LowTerm       40.50      (2.0%)       33.31      (0.9%)  -17.8% ( -20% -  -15%)\n            OrNotHighLow       33.70      (4.9%)       28.34      (2.9%)  -15.9% ( -22% -   -8%)\n                  Fuzzy1       30.86      (1.9%)       26.61      (0.8%)  -13.8% ( -16% -  -11%)\n         LowSloppyPhrase       24.22      (1.7%)       21.51      (0.6%)  -11.2% ( -13% -   -9%)\n                  Fuzzy2       25.05      (1.7%)       22.29      (1.0%)  -11.0% ( -13% -   -8%)\n            OrNotHighMed       20.09      (3.9%)       18.07      (2.5%)  -10.1% ( -15% -   -3%)\n             MedSpanNear       18.16      (2.7%)       16.49      (1.7%)   -9.2% ( -13% -   -4%)\n              AndHighMed       16.39      (1.4%)       15.03      (0.9%)   -8.3% ( -10% -   -6%)\n             AndHighHigh       14.05      (1.2%)       13.11      (0.7%)   -6.7% (  -8% -   -4%)\n               LowPhrase        9.71      (4.6%)        9.06      (4.8%)   -6.6% ( -15% -    2%)\n                 Prefix3       13.39      (1.5%)       12.57      (0.8%)   -6.2% (  -8% -   -3%)\n                 MedTerm       12.86      (1.1%)       12.11      (1.3%)   -5.8% (  -8% -   -3%)\n             LowSpanNear        7.54      (3.8%)        7.19      (3.3%)   -4.7% ( -11% -    2%)\n           OrNotHighHigh        9.94      (2.4%)        9.48      (1.5%)   -4.6% (  -8% -    0%)\n                HighTerm        8.65      (1.5%)        8.34      (1.4%)   -3.6% (  -6% -    0%)\n              HighPhrase        2.81      (5.1%)        2.72      (5.8%)   -3.3% ( -13% -    8%)\n            OrHighNotMed        7.23      (1.6%)        7.01      (1.2%)   -3.1% (  -5% -    0%)\n               OrHighMed        5.67      (1.9%)        5.52      (0.8%)   -2.7% (  -5% -    0%)\n            HighSpanNear        3.26      (3.1%)        3.18      (2.2%)   -2.5% (  -7% -    2%)\n           OrHighNotHigh        4.84      (2.1%)        4.73      (1.3%)   -2.4% (  -5% -    1%)\n            OrHighNotLow        4.14      (1.3%)        4.05      (1.0%)   -2.1% (  -4% -    0%)\n                Wildcard        4.61      (1.4%)        4.52      (1.1%)   -1.8% (  -4% -    0%)\n               OrHighLow        2.82      (1.5%)        2.78      (0.7%)   -1.4% (  -3% -    0%)\n         MedSloppyPhrase        3.27      (6.2%)        3.23      (7.2%)   -1.2% ( -13% -   13%)\n        HighSloppyPhrase        3.39      (6.9%)        3.36      (8.9%)   -0.9% ( -15% -   15%)\n              OrHighHigh        2.10      (1.5%)        2.08      (1.0%)   -0.9% (  -3% -    1%)\n                  IntNRQ        1.51      (1.3%)        1.50      (0.4%)   -0.5% (  -2% -    1%)\n                 Respell       52.58      (2.8%)       53.34      (1.9%)    1.4% (  -3% -    6%)\n\n\n\nCuriously, returning null when there are no children didn't seem to\nhelp?\n\nThen I switched all dims to ALL_BUT_DIM (I haven't added per-dim ord\npolicy control to luceneutil yet):\n\n\n                    Task    QPS base      StdDev    QPS comp      StdDev                Pct diff\n              AndHighLow      103.19      (4.5%)       83.12      (1.2%)  -19.4% ( -24% -  -14%)\n               MedPhrase       60.47      (3.8%)       53.05      (1.7%)  -12.3% ( -17% -   -7%)\n                 LowTerm       54.28      (3.0%)       48.32      (1.2%)  -11.0% ( -14% -   -7%)\n            OrNotHighLow       42.72      (5.3%)       38.99      (4.0%)   -8.7% ( -17% -    0%)\n                  Fuzzy1       38.65      (1.9%)       35.70      (1.0%)   -7.6% ( -10% -   -4%)\n         LowSloppyPhrase       28.79      (1.8%)       27.02      (1.0%)   -6.2% (  -8% -   -3%)\n                  Fuzzy2       29.02      (1.6%)       27.31      (1.2%)   -5.9% (  -8% -   -3%)\n             MedSpanNear       20.48      (2.2%)       19.55      (2.3%)   -4.5% (  -8% -    0%)\n            OrNotHighMed       22.49      (4.0%)       21.52      (3.3%)   -4.3% ( -11% -    3%)\n              AndHighMed       17.94      (1.2%)       17.24      (0.7%)   -3.9% (  -5% -   -2%)\n             AndHighHigh       15.04      (1.0%)       14.55      (0.5%)   -3.2% (  -4% -   -1%)\n                 Prefix3       14.02      (1.2%)       13.64      (1.0%)   -2.7% (  -4% -    0%)\n                 MedTerm       13.47      (1.5%)       13.12      (1.0%)   -2.6% (  -5% -    0%)\n               LowPhrase       10.15      (5.5%)        9.94      (5.3%)   -2.1% ( -12% -    9%)\n             LowSpanNear        7.82      (3.8%)        7.67      (3.7%)   -1.9% (  -9% -    5%)\n                HighTerm        8.83      (1.3%)        8.68      (1.1%)   -1.7% (  -3% -    0%)\n           OrNotHighHigh        9.79      (2.0%)        9.63      (1.7%)   -1.6% (  -5% -    2%)\n            OrHighNotMed        7.30      (1.7%)        7.22      (1.2%)   -1.1% (  -3% -    1%)\n            HighSpanNear        3.27      (1.9%)        3.24      (2.8%)   -0.9% (  -5% -    3%)\n               OrHighMed        5.64      (1.6%)        5.59      (1.3%)   -0.9% (  -3% -    2%)\n           OrHighNotHigh        4.78      (1.9%)        4.75      (1.5%)   -0.6% (  -3% -    2%)\n                Wildcard        4.59      (1.5%)        4.57      (1.4%)   -0.6% (  -3% -    2%)\n            OrHighNotLow        4.08      (1.6%)        4.07      (1.5%)   -0.3% (  -3% -    2%)\n        HighSloppyPhrase        3.42      (8.7%)        3.42      (8.3%)   -0.2% ( -15% -   18%)\n               OrHighLow        2.72      (1.7%)        2.72      (1.5%)   -0.1% (  -3% -    3%)\n              OrHighHigh        2.03      (1.8%)        2.03      (1.4%)   -0.0% (  -3% -    3%)\n         MedSloppyPhrase        3.30      (6.2%)        3.30      (6.1%)   -0.0% ( -11% -   13%)\n                  IntNRQ        1.43      (1.4%)        1.43      (1.2%)   -0.0% (  -2% -    2%)\n              HighPhrase        2.74      (5.7%)        2.74      (6.1%)    0.1% ( -10% -   12%)\n                 Respell       52.73      (2.5%)       53.18      (3.0%)    0.8% (  -4% -    6%)\n\n\n\nCost is definitely less ... but not \"trivial\".\n\nThen, I did ALL_BUT_DIM, but only facet on the 7 \"easy\" dims\n(i.e. exclude categories and username):\n\n\n                    Task    QPS base      StdDev    QPS comp      StdDev                Pct diff\n               LowPhrase       12.23      (6.4%)       12.07      (6.0%)   -1.4% ( -12% -   11%)\n                 Respell       55.11      (3.1%)       54.44      (2.8%)   -1.2% (  -6% -    4%)\n                  Fuzzy1       62.58      (1.6%)       61.95      (1.8%)   -1.0% (  -4% -    2%)\n                  Fuzzy2       46.58      (1.5%)       46.17      (1.7%)   -0.9% (  -3% -    2%)\n              AndHighLow      402.55      (1.9%)      399.72      (3.2%)   -0.7% (  -5% -    4%)\n              HighPhrase        4.01      (8.0%)        3.99      (7.9%)   -0.5% ( -15% -   16%)\n               MedPhrase      126.62      (4.6%)      126.18      (4.5%)   -0.3% (  -9% -    9%)\n                HighTerm       20.11      (1.5%)       20.06      (1.6%)   -0.3% (  -3% -    2%)\n         LowSloppyPhrase       39.10      (1.7%)       39.03      (1.7%)   -0.2% (  -3% -    3%)\n                 LowTerm      127.98      (1.9%)      127.81      (2.0%)   -0.1% (  -3% -    3%)\n                 Prefix3       28.04      (1.1%)       28.02      (1.3%)   -0.1% (  -2% -    2%)\n              AndHighMed       27.39      (0.9%)       27.36      (0.7%)   -0.1% (  -1% -    1%)\n             AndHighHigh       25.00      (1.0%)       24.98      (0.7%)   -0.1% (  -1% -    1%)\n                 MedTerm       26.14      (1.5%)       26.13      (1.6%)   -0.0% (  -3% -    3%)\n                  IntNRQ        2.39      (1.4%)        2.39      (1.5%)    0.0% (  -2% -    2%)\n                Wildcard        8.90      (1.7%)        8.90      (1.1%)    0.1% (  -2% -    2%)\n            OrHighNotLow        8.52      (1.5%)        8.57      (2.5%)    0.5% (  -3% -    4%)\n        HighSloppyPhrase        3.95      (8.5%)        3.98     (12.7%)    0.8% ( -18% -   24%)\n              OrHighHigh        3.48      (1.6%)        3.51      (1.6%)    0.8% (  -2% -    4%)\n            OrHighNotMed       14.44      (1.6%)       14.57      (1.7%)    0.9% (  -2% -    4%)\n               OrHighLow        4.85      (1.6%)        4.90      (1.8%)    0.9% (  -2% -    4%)\n               OrHighMed       11.37      (1.4%)       11.48      (1.4%)    1.0% (  -1% -    3%)\n             MedSpanNear       25.99      (3.5%)       26.25      (2.8%)    1.0% (  -5% -    7%)\n             LowSpanNear        8.84      (4.7%)        8.93      (4.4%)    1.1% (  -7% -   10%)\n         MedSloppyPhrase        3.62      (7.0%)        3.67      (8.1%)    1.3% ( -12% -   17%)\n            HighSpanNear        4.98      (5.2%)        5.05      (2.9%)    1.3% (  -6% -    9%)\n           OrNotHighHigh       14.23      (1.9%)       14.42      (2.0%)    1.4% (  -2% -    5%)\n           OrHighNotHigh        8.52      (1.9%)        8.65      (2.0%)    1.5% (  -2% -    5%)\n            OrNotHighMed       30.98      (3.8%)       32.05      (4.9%)    3.5% (  -5% -   12%)\n            OrNotHighLow       60.16      (5.6%)       62.95      (7.0%)    4.6% (  -7% -   18%)\n\n\n\nWhich looks like basically noise ... so it's only the high-cardinality\ndims that are affected. ",
            "author": "Michael McCandless",
            "id": "comment-13812757"
        },
        {
            "date": "2013-11-04T12:01:30+0000",
            "content": "Thanks for doing this Mike! (it's not trivial to run all these tests)\n\nThe high cardinality dims are affected because we cannot tell quickly which of a dim's children have count>0. The big loss in performance worries me some because these dims are not rare. I wonder if we could return an int[] with only the children of a category, if that improves things or not. That means changing the underlying structure from a large int[] to a Map<ord,int[]> as was suggested before. It still exposes implementation details, but I wonder if that will improve things or not. Also, it might be that if we hold only the children of a dim in the int[], the API abstraction will hurt less.\n\nIt sucks that we lose so much because we try to abstract things away. ",
            "author": "Shai Erera",
            "id": "comment-13812786"
        },
        {
            "date": "2013-11-04T12:08:30+0000",
            "content": "I looked at ParallelArraysChildrenIterator and I wonder if we made INVALID_ORDINAL = 0, we could speed it up since currently we check in every next() whether the ordinal is not INVALID_ORDINAL (-1), otherwise we'd hit AIOOBE. And we do this check twice, once inside next() and once outside (calling code). If we make INVALID_ORDINAL=0 (big Big BIG change), we can omit the checks in next(). ",
            "author": "Shai Erera",
            "id": "comment-13812790"
        },
        {
            "date": "2013-11-05T20:06:41+0000",
            "content": "Introducing a map-based children iterator, which holds for every ordinal (real parent) an int[] containing its direct children.\n\nEach such int[] has an extra last slot for TaxonomyReader.INVALID_ORDINAL which spares an if call for every ChildrenIterator.next() call. \n\nThis is a quick and dirty patch, just so we could verify the penalty for moving to the API/map is not great. If it is great, the whole issue should be reconsidered, and perhaps a move to direct int[] for iterating over children should be implemented. ",
            "author": "Gilad Barkai",
            "id": "comment-13814214"
        },
        {
            "date": "2013-11-06T14:33:16+0000",
            "content": "Here's ALL_BUT_DIM performance; it looks better!  However, I'm not sure why, but sometimes 1-3 of the queries that ran came back w/ all 0 facet counts.  Maybe a thread safety issue in the quick & dirty patch?\n\n\n                    Task    QPS base      StdDev    QPS comp      StdDev                Pct diff\n              AndHighLow       70.50      (3.1%)       63.66      (5.2%)   -9.7% ( -17% -   -1%)\n               MedPhrase       43.43      (2.2%)       40.79      (3.4%)   -6.1% ( -11% -    0%)\n                 LowTerm       38.63      (2.0%)       36.46      (3.4%)   -5.6% ( -10% -    0%)\n                  Fuzzy1       28.41      (1.5%)       27.15      (2.6%)   -4.4% (  -8% -    0%)\n            OrNotHighLow       31.95      (3.7%)       30.64      (3.9%)   -4.1% ( -11% -    3%)\n         LowSloppyPhrase       21.67      (1.5%)       20.96      (2.2%)   -3.3% (  -6% -    0%)\n                  Fuzzy2       21.39      (1.7%)       20.71      (1.9%)   -3.2% (  -6% -    0%)\n            OrNotHighMed       17.30      (2.8%)       16.90      (3.3%)   -2.3% (  -8% -    3%)\n                 Prefix3       10.68      (1.5%)       10.46      (2.2%)   -2.1% (  -5% -    1%)\n              AndHighMed       13.85      (1.2%)       13.57      (1.4%)   -2.0% (  -4% -    0%)\n             MedSpanNear       15.19      (2.7%)       14.89      (2.9%)   -2.0% (  -7% -    3%)\n             AndHighHigh       11.70      (1.0%)       11.51      (1.8%)   -1.6% (  -4% -    1%)\n        HighSloppyPhrase        2.56      (8.0%)        2.52      (7.9%)   -1.5% ( -16% -   15%)\n            OrHighNotMed        5.66      (1.4%)        5.58      (1.5%)   -1.4% (  -4% -    1%)\n               LowPhrase        7.82      (5.7%)        7.72      (5.8%)   -1.2% ( -12% -   10%)\n                 MedTerm       10.26      (2.0%)       10.14      (1.4%)   -1.1% (  -4% -    2%)\n           OrNotHighHigh        7.32      (1.7%)        7.24      (1.6%)   -1.0% (  -4% -    2%)\n         MedSloppyPhrase        2.47      (6.1%)        2.45      (5.9%)   -1.0% ( -12% -   11%)\n                HighTerm        6.85      (1.3%)        6.78      (1.8%)   -1.0% (  -4% -    2%)\n               OrHighMed        4.46      (1.6%)        4.42      (2.0%)   -0.9% (  -4% -    2%)\n             LowSpanNear        5.98      (4.0%)        5.92      (3.4%)   -0.9% (  -8% -    6%)\n            HighSpanNear        2.54      (2.6%)        2.53      (2.9%)   -0.6% (  -5% -    5%)\n              HighPhrase        2.18      (5.9%)        2.16      (6.1%)   -0.5% ( -11% -   12%)\n                 Respell       41.46      (3.6%)       41.32      (3.1%)   -0.3% (  -6% -    6%)\n               OrHighLow        2.19      (1.6%)        2.19      (1.6%)   -0.3% (  -3% -    2%)\n                Wildcard        3.65      (1.8%)        3.64      (1.5%)   -0.2% (  -3% -    3%)\n           OrHighNotHigh        3.78      (1.7%)        3.77      (1.5%)   -0.2% (  -3% -    3%)\n              OrHighHigh        1.65      (2.0%)        1.64      (1.5%)   -0.2% (  -3% -    3%)\n            OrHighNotLow        3.29      (1.5%)        3.28      (1.6%)   -0.2% (  -3% -    3%)\n                  IntNRQ        1.18      (1.8%)        1.18      (1.4%)   -0.1% (  -3% -    3%)\n\n ",
            "author": "Michael McCandless",
            "id": "comment-13814924"
        },
        {
            "date": "2013-11-06T18:30:45+0000",
            "content": "Hmm but this is the NO_PARENTS perf:\n\n\n                    Task    QPS base      StdDev    QPS comp      StdDev                Pct diff\n              AndHighLow       41.14      (2.5%)       14.32      (4.2%)  -65.2% ( -70% -  -59%)\n               MedPhrase       30.42      (2.7%)       12.74      (4.5%)  -58.1% ( -63% -  -52%)\n                 LowTerm       28.27      (1.6%)       12.33      (4.6%)  -56.4% ( -61% -  -50%)\n            OrNotHighLow       24.15      (2.6%)       11.47      (4.7%)  -52.5% ( -58% -  -46%)\n                  Fuzzy1       21.93      (1.6%)       10.94      (4.6%)  -50.1% ( -55% -  -44%)\n                  Fuzzy2       18.12      (1.7%)        9.89      (4.5%)  -45.4% ( -50% -  -39%)\n         LowSloppyPhrase       17.97      (1.8%)        9.84      (4.7%)  -45.2% ( -50% -  -39%)\n            OrNotHighMed       14.90      (2.7%)        8.89      (4.9%)  -40.4% ( -46% -  -33%)\n             MedSpanNear       13.41      (2.4%)        8.25      (4.3%)  -38.5% ( -44% -  -32%)\n              AndHighMed       12.41      (1.5%)        7.90      (4.4%)  -36.4% ( -41% -  -30%)\n             AndHighHigh       10.72      (1.1%)        7.22      (4.2%)  -32.7% ( -37% -  -27%)\n                 Prefix3       10.22      (1.8%)        6.93      (4.1%)  -32.2% ( -37% -  -26%)\n                 MedTerm        9.86      (2.2%)        6.76      (4.1%)  -31.4% ( -36% -  -25%)\n               LowPhrase        7.28      (6.0%)        5.43      (3.9%)  -25.4% ( -33% -  -16%)\n           OrNotHighHigh        7.38      (2.1%)        5.53      (3.8%)  -25.2% ( -30% -  -19%)\n                HighTerm        6.85      (2.2%)        5.20      (3.6%)  -24.1% ( -29% -  -18%)\n             LowSpanNear        5.70      (3.2%)        4.48      (4.1%)  -21.4% ( -27% -  -14%)\n            OrHighNotMed        5.69      (2.2%)        4.52      (3.2%)  -20.6% ( -25% -  -15%)\n               OrHighMed        4.57      (2.6%)        3.78      (2.6%)  -17.2% ( -21% -  -12%)\n           OrHighNotHigh        3.89      (2.5%)        3.29      (2.7%)  -15.3% ( -20% -  -10%)\n                Wildcard        3.76      (2.7%)        3.20      (2.4%)  -14.9% ( -19% -  -10%)\n            OrHighNotLow        3.36      (2.1%)        2.94      (2.1%)  -12.4% ( -16% -   -8%)\n        HighSloppyPhrase        2.51      (6.6%)        2.23      (5.9%)  -11.1% ( -22% -    1%)\n            HighSpanNear        2.58      (3.5%)        2.29      (2.8%)  -11.0% ( -16% -   -4%)\n         MedSloppyPhrase        2.43      (5.2%)        2.19      (4.8%)   -9.8% ( -18% -    0%)\n              HighPhrase        2.20      (6.8%)        2.00      (4.8%)   -9.2% ( -19% -    2%)\n               OrHighLow        2.29      (2.3%)        2.09      (1.9%)   -8.8% ( -12% -   -4%)\n              OrHighHigh        1.72      (2.6%)        1.61      (1.6%)   -6.2% ( -10% -   -2%)\n                  IntNRQ        1.25      (2.7%)        1.19      (1.1%)   -4.5% (  -8% -    0%)\n                 Respell       40.60      (2.8%)       39.77      (2.8%)   -2.0% (  -7% -    3%)\n\n ",
            "author": "Michael McCandless",
            "id": "comment-13815125"
        },
        {
            "date": "2013-11-07T18:01:23+0000",
            "content": "That's... not an optimistic result \nI think there should not be any MT issues? The initialization occurs while the taxonomy is being opened, and later on it's just read operations.. \nPerhaps this API change should be modifies, and we'd try Shai's approach - instead of a ChildrenIterator with .next() method, return an int[].\nThe Map is still applicable for this approach, just that the int[] will not be wrapped with an iterator object.\nI'll also review the patch, try to figure out what MT issues I missed. ",
            "author": "Gilad Barkai",
            "id": "comment-13816183"
        },
        {
            "date": "2013-11-10T13:51:18+0000",
            "content": "Mike, I looked at the different runs results and the QPS column (e.g. QPS Base) varies dramatically between runs. I'm not talking about \"base\" vs \"comp\", but \"base\" vs itself in all runs. E.g. in the last run when you compared ALL_BUT_DIM and NO_PARENTS, AndHighLow of ALL_BUT_DIM was 70.5 vs 41.14 respectively. In the ALL_BUT_DIM run after Gilad's patch with getChildren() returning null, it's 103.19.\n\nCan you explain the great differences? Note that I don't compare that to the \"easy\" run (w/ 7 dims only) as it does not run the same thing. But I wonder if the changes in absolute QPS may hint at some instability (maybe temporal) with the machine or the test? Still, when \"comp\" is slowest than \"base\" so ultimately I think it shows the abstraction hurts us, but I'd feel better if the test was more stable across runs.\n\nSeparately, I'm torn about what we should do here. On one hand the abstraction hurts us, but on the other hand, it eliminates any chance of doing anything smart in the taxonomy in-memory representation. For example, if a dimension is flat and some taxonomy implementation manages to assign successive ordinals to its children, we don't even need to materialize all children in an int[], and rather hold a start/end range (a'la SortedSetDocValuesReaderState.OrdRange) and implement ChildrenIterator on top. If we commit to an int[] on the API, it immediately kills any chance to further optimize that in the future (e.g. PackedInts even).\n\nI know Gilad is making progress w/ returning an int[] per ord, so I wonder what the performance will be with it. I really wish we can make that API abstraction without losing much - it feels the right thing to do ... and I'd hate to do it, knowing that we lose . ",
            "author": "Shai Erera",
            "id": "comment-13818443"
        },
        {
            "date": "2013-11-10T15:15:31+0000",
            "content": "I'm not sure why there's such a difference; I do fix the static seed in the test, so it's running the same queries every time (otherwise it would pick a different set of queries out of each category).\n\nLet me go re-run ... maybe I messed something up.\n\nIt would be best if others could run too, to avoid a stupid mistake on my part causing us to abandon what would have been a good change! ",
            "author": "Michael McCandless",
            "id": "comment-13818457"
        },
        {
            "date": "2013-11-10T16:19:10+0000",
            "content": "I re-ran ALL_BUT_DIM and NO_PARENTS on the last patch:\n\nALL_BUT_DIM:\n\n\n                    Task    QPS base      StdDev    QPS comp      StdDev                Pct diff\n         LowSloppyPhrase      195.79      (6.4%)      160.76      (6.5%)  -17.9% ( -28% -   -5%)\n             MedSpanNear      189.11      (6.1%)      155.88      (6.5%)  -17.6% ( -28% -   -5%)\n              AndHighLow      171.05      (5.4%)      142.46      (5.9%)  -16.7% ( -26% -   -5%)\n              HighPhrase      165.56      (5.6%)      140.32      (6.0%)  -15.2% ( -25% -   -3%)\n        HighSloppyPhrase      135.86      (4.7%)      117.90      (5.3%)  -13.2% ( -22% -   -3%)\n            HighSpanNear       98.69      (4.1%)       88.28      (4.5%)  -10.5% ( -18% -   -2%)\n               MedPhrase       89.68      (4.3%)       81.23      (3.7%)   -9.4% ( -16% -   -1%)\n            OrNotHighLow       93.45      (5.5%)       85.07      (4.9%)   -9.0% ( -18% -    1%)\n                 LowTerm       87.06      (3.4%)       79.50      (3.8%)   -8.7% ( -15% -   -1%)\n                  Fuzzy1       63.87      (2.5%)       59.39      (2.9%)   -7.0% ( -12% -   -1%)\n              AndHighMed       53.60      (1.9%)       50.49      (2.6%)   -5.8% ( -10% -   -1%)\n               OrHighLow       54.32      (2.2%)       51.18      (2.4%)   -5.8% ( -10% -   -1%)\n           OrNotHighHigh       62.71      (5.5%)       59.11      (5.0%)   -5.7% ( -15% -    5%)\n            OrNotHighMed       47.72      (3.4%)       45.35      (3.1%)   -5.0% ( -11% -    1%)\n                  Fuzzy2       48.40      (2.2%)       46.07      (2.4%)   -4.8% (  -9% -    0%)\n             AndHighHigh       31.48      (1.6%)       30.33      (1.5%)   -3.7% (  -6% -    0%)\n                 MedTerm       35.33      (2.0%)       34.06      (1.9%)   -3.6% (  -7% -    0%)\n         MedSloppyPhrase       17.17      (4.4%)       16.67      (4.3%)   -2.9% ( -11% -    6%)\n                 Prefix3       27.73      (1.6%)       26.93      (1.2%)   -2.9% (  -5% -    0%)\n            OrHighNotMed       24.31      (2.4%)       23.79      (1.1%)   -2.1% (  -5% -    1%)\n               LowPhrase       14.56      (4.2%)       14.28      (4.0%)   -1.9% (  -9% -    6%)\n             LowSpanNear       11.25      (2.4%)       11.04      (1.7%)   -1.9% (  -5% -    2%)\n              OrHighHigh       17.63      (1.6%)       17.38      (1.1%)   -1.4% (  -4% -    1%)\n            OrHighNotLow       18.97      (1.8%)       18.69      (0.9%)   -1.4% (  -4% -    1%)\n                Wildcard       13.21      (1.4%)       13.03      (0.9%)   -1.4% (  -3% -    0%)\n                HighTerm       16.34      (1.8%)       16.14      (1.9%)   -1.3% (  -4% -    2%)\n               OrHighMed       18.11      (1.6%)       17.93      (1.4%)   -1.0% (  -3% -    2%)\n                 Respell       89.31      (2.8%)       88.78      (2.2%)   -0.6% (  -5% -    4%)\n           OrHighNotHigh        9.09      (2.0%)        9.08      (1.4%)   -0.1% (  -3% -    3%)\n                  IntNRQ        4.87      (1.2%)        4.90      (1.2%)    0.7% (  -1% -    3%)\n\n\n\n\nNO_PARENTS:\n\n\n                    Task    QPS base      StdDev    QPS comp      StdDev                Pct diff\n         LowSloppyPhrase       98.63      (4.7%)       28.73      (2.9%)  -70.9% ( -74% -  -66%)\n             MedSpanNear       97.31      (4.7%)       28.54      (2.9%)  -70.7% ( -74% -  -66%)\n              AndHighLow       91.63      (3.9%)       28.04      (2.9%)  -69.4% ( -73% -  -65%)\n              HighPhrase       90.81      (3.6%)       27.94      (2.9%)  -69.2% ( -73% -  -65%)\n        HighSloppyPhrase       80.24      (3.2%)       26.90      (3.1%)  -66.5% ( -70% -  -62%)\n            HighSpanNear       65.93      (2.7%)       24.97      (3.3%)  -62.1% ( -66% -  -57%)\n            OrNotHighLow       64.00      (3.3%)       24.74      (3.2%)  -61.3% ( -65% -  -56%)\n               MedPhrase       62.06      (4.1%)       24.52      (3.3%)  -60.5% ( -65% -  -55%)\n                 LowTerm       61.33      (2.6%)       24.40      (3.3%)  -60.2% ( -64% -  -55%)\n           OrNotHighHigh       48.27      (2.8%)       21.97      (3.4%)  -54.5% ( -58% -  -49%)\n                  Fuzzy1       47.61      (2.2%)       21.90      (3.5%)  -54.0% ( -58% -  -49%)\n               OrHighLow       43.63      (2.6%)       21.07      (3.4%)  -51.7% ( -56% -  -46%)\n              AndHighMed       42.86      (2.6%)       20.75      (3.4%)  -51.6% ( -56% -  -46%)\n            OrNotHighMed       39.23      (2.0%)       19.93      (3.3%)  -49.2% ( -53% -  -44%)\n                  Fuzzy2       38.49      (2.3%)       19.76      (3.3%)  -48.6% ( -53% -  -44%)\n                 MedTerm       31.48      (2.6%)       17.82      (3.5%)  -43.4% ( -48% -  -38%)\n             AndHighHigh       27.49      (1.9%)       16.39      (3.3%)  -40.4% ( -44% -  -35%)\n                 Prefix3       25.17      (2.6%)       15.71      (3.3%)  -37.6% ( -42% -  -32%)\n            OrHighNotMed       22.44      (2.0%)       14.56      (3.0%)  -35.1% ( -39% -  -30%)\n            OrHighNotLow       18.01      (1.7%)       12.66      (2.8%)  -29.7% ( -33% -  -25%)\n               OrHighMed       17.37      (2.1%)       12.33      (2.8%)  -29.0% ( -33% -  -24%)\n              OrHighHigh       17.02      (2.4%)       12.15      (2.8%)  -28.6% ( -33% -  -23%)\n         MedSloppyPhrase       15.76      (4.5%)       11.26      (3.8%)  -28.6% ( -35% -  -21%)\n                HighTerm       15.80      (2.4%)       11.62      (2.9%)  -26.5% ( -30% -  -21%)\n               LowPhrase       13.51      (4.5%)       10.19      (3.0%)  -24.6% ( -30% -  -17%)\n                Wildcard       12.90      (1.5%)       10.04      (2.3%)  -22.1% ( -25% -  -18%)\n             LowSpanNear       10.56      (2.1%)        8.40      (2.5%)  -20.4% ( -24% -  -16%)\n           OrHighNotHigh        9.39      (1.5%)        7.84      (2.1%)  -16.5% ( -19% -  -13%)\n                  IntNRQ        5.15      (1.9%)        4.81      (1.4%)   -6.7% (  -9% -   -3%)\n                 Respell       84.97      (2.8%)       88.45      (3.3%)    4.1% (  -1% -   10%)\n\n\n\nI still see some queries coming back w/ all 0 facets ... not sure why. ",
            "author": "Michael McCandless",
            "id": "comment-13818469"
        },
        {
            "date": "2013-11-10T17:08:13+0000",
            "content": "Gilad still hasn't uploaded a new patch w/ the bugfix.\n\nAbout the results, again the absolute QPS differs a lot? I compared that run to the one before. ",
            "author": "Shai Erera",
            "id": "comment-13818494"
        },
        {
            "date": "2013-11-13T12:01:40+0000",
            "content": "Attaching a fixed patch with the concurrency resolved. \nThis is not yet the patch with the int[] instead of an array.\n\nI'm not sure that following the path of the int[] is right, it will block all future extensions for using e.g on-disk children.. \nWhat do you think? Perhaps it is better to keep the iterator? ",
            "author": "Gilad Barkai",
            "id": "comment-13821252"
        },
        {
            "date": "2013-11-13T13:09:51+0000",
            "content": "Can we finish the Map with int[] approach? I hope that we won't see any slowdowns, yet RAM is supposed to decrease? If so, we can still keep the int[] API, get rid of PTA (and leave only getChildren) and worry about extension later? It's not that RAM consumption is so high, but if we can reduce it and clean the API some more on the go, perfect! ",
            "author": "Shai Erera",
            "id": "comment-13821296"
        },
        {
            "date": "2013-11-17T20:08:42+0000",
            "content": "Changes:\n\n\tFixed concurrency issues\n\tMoved to an int[] getChildren(int ord)) API which should perform at least as fast as the taxonomy-arrays way.\n\n\n\nThe code is not ready for commit:\n\n\tChildren-map does not support fast reopen (using an older map and only updating with newly added ordinals)\n\tChildren-map initialization still uses the taxonomy arrays, so they are not completely removed.\n\n\n\nShould a benchmark show this change performs better I'll make the extra changes for making it commit-ready. ",
            "author": "Gilad Barkai",
            "id": "comment-13824941"
        },
        {
            "date": "2013-11-22T15:43:35+0000",
            "content": "OK, I ran the same perf tests with the last patch.  The \"sometimes all\n0 facet counts\" problem is fixed!\n\nNO_PARENTS:\n\n\n                    Task    QPS base      StdDev    QPS comp      StdDev                Pct diff\n         LowSloppyPhrase       99.22      (4.1%)       35.51      (1.9%)  -64.2% ( -67% -  -60%)\n             MedSpanNear       96.92      (4.2%)       35.23      (2.0%)  -63.6% ( -67% -  -59%)\n              AndHighLow       91.99      (3.5%)       34.57      (2.0%)  -62.4% ( -65% -  -58%)\n              HighPhrase       90.68      (3.8%)       34.35      (2.0%)  -62.1% ( -65% -  -58%)\n        HighSloppyPhrase       81.34      (2.9%)       32.74      (2.1%)  -59.7% ( -62% -  -56%)\n            HighSpanNear       65.81      (2.9%)       30.03      (2.2%)  -54.4% ( -57% -  -50%)\n            OrNotHighLow       63.44      (3.4%)       29.66      (2.0%)  -53.3% ( -56% -  -49%)\n               MedPhrase       62.66      (3.2%)       29.30      (2.0%)  -53.2% ( -56% -  -49%)\n                 LowTerm       61.47      (3.8%)       29.02      (2.0%)  -52.8% ( -56% -  -48%)\n                  Fuzzy1       47.78      (3.3%)       25.66      (2.3%)  -46.3% ( -50% -  -42%)\n           OrNotHighHigh       47.59      (3.8%)       25.73      (2.3%)  -45.9% ( -50% -  -41%)\n               OrHighLow       43.78      (1.9%)       24.41      (2.1%)  -44.2% ( -47% -  -41%)\n              AndHighMed       42.81      (2.1%)       24.04      (2.0%)  -43.9% ( -47% -  -40%)\n            OrNotHighMed       38.92      (2.6%)       22.95      (2.0%)  -41.0% ( -44% -  -37%)\n                  Fuzzy2       38.27      (2.6%)       22.86      (2.2%)  -40.3% ( -43% -  -36%)\n                 MedTerm       31.78      (2.5%)       20.14      (2.1%)  -36.6% ( -40% -  -32%)\n             AndHighHigh       27.50      (1.7%)       18.33      (1.9%)  -33.3% ( -36% -  -30%)\n                 Prefix3       25.26      (1.9%)       17.35      (1.7%)  -31.3% ( -34% -  -28%)\n            OrHighNotMed       22.27      (1.4%)       16.04      (1.4%)  -28.0% ( -30% -  -25%)\n            OrHighNotLow       18.01      (1.6%)       13.76      (1.5%)  -23.6% ( -26% -  -20%)\n               OrHighMed       17.33      (2.1%)       13.26      (1.6%)  -23.5% ( -26% -  -20%)\n              OrHighHigh       16.84      (1.9%)       13.05      (1.5%)  -22.5% ( -25% -  -19%)\n         MedSloppyPhrase       15.54      (3.9%)       12.22      (3.4%)  -21.4% ( -27% -  -14%)\n                HighTerm       15.87      (2.2%)       12.48      (1.7%)  -21.3% ( -24% -  -17%)\n               LowPhrase       13.78      (1.6%)       11.03      (1.3%)  -20.0% ( -22% -  -17%)\n                Wildcard       12.93      (1.9%)       10.65      (1.3%)  -17.7% ( -20% -  -14%)\n             LowSpanNear       10.55      (2.0%)        8.92      (1.7%)  -15.5% ( -18% -  -12%)\n           OrHighNotHigh        9.29      (1.4%)        8.16      (1.4%)  -12.2% ( -14% -   -9%)\n                  IntNRQ        5.19      (1.3%)        4.92      (1.9%)   -5.1% (  -8% -   -1%)\n                 Respell       85.48      (2.6%)       87.32      (2.6%)    2.2% (  -2% -    7%)\n\n\n\nALL_BUT_DIM:\n\n\n                    Task    QPS base      StdDev    QPS comp      StdDev                Pct diff\n                 Respell       89.86      (3.0%)       89.27      (2.2%)   -0.7% (  -5% -    4%)\n             LowSpanNear       12.01      (2.3%)       11.95      (2.1%)   -0.5% (  -4% -    3%)\n                  Fuzzy1       88.54      (2.2%)       88.41      (1.5%)   -0.2% (  -3% -    3%)\n                  Fuzzy2       62.54      (2.1%)       62.50      (2.3%)   -0.1% (  -4% -    4%)\n           OrHighNotHigh       10.10      (1.7%)       10.09      (1.9%)   -0.1% (  -3% -    3%)\n           OrNotHighHigh       85.35      (5.4%)       85.31      (5.4%)   -0.0% ( -10% -   11%)\n            OrHighNotLow       22.11      (1.4%)       22.10      (1.2%)   -0.0% (  -2% -    2%)\n         MedSloppyPhrase       18.87      (4.0%)       18.88      (4.7%)    0.1% (  -8% -    9%)\n                HighTerm       18.93      (1.5%)       18.97      (1.7%)    0.2% (  -2% -    3%)\n               OrHighMed       21.19      (1.6%)       21.26      (1.4%)    0.3% (  -2% -    3%)\n               LowPhrase       15.79      (4.4%)       15.85      (4.2%)    0.4% (  -7% -    9%)\n             AndHighHigh       38.40      (1.0%)       38.57      (1.2%)    0.4% (  -1% -    2%)\n              OrHighHigh       20.55      (1.4%)       20.64      (1.5%)    0.4% (  -2% -    3%)\n            OrHighNotMed       29.27      (1.4%)       29.40      (1.2%)    0.4% (  -2% -    3%)\n              AndHighMed       72.26      (1.1%)       72.60      (1.1%)    0.5% (  -1% -    2%)\n                Wildcard       14.92      (1.0%)       14.99      (1.3%)    0.5% (  -1% -    2%)\n            HighSpanNear      159.71      (3.5%)      160.74      (3.7%)    0.6% (  -6% -    8%)\n                  IntNRQ        5.15      (1.4%)        5.18      (1.7%)    0.7% (  -2% -    3%)\n                 Prefix3       33.93      (1.3%)       34.18      (1.8%)    0.7% (  -2% -    3%)\n                 MedTerm       44.36      (1.7%)       44.69      (1.6%)    0.8% (  -2% -    4%)\n            OrNotHighMed       62.66      (2.4%)       63.18      (3.1%)    0.8% (  -4% -    6%)\n               OrHighLow       75.94      (1.4%)       76.65      (1.5%)    0.9% (  -1% -    3%)\n            OrNotHighLow      150.08      (4.7%)      151.62      (5.0%)    1.0% (  -8% -   11%)\n               MedPhrase      138.21      (3.7%)      139.67      (3.6%)    1.1% (  -6% -    8%)\n                 LowTerm      140.27      (2.3%)      142.14      (2.6%)    1.3% (  -3% -    6%)\n        HighSloppyPhrase      283.76      (1.3%)      291.51      (1.8%)    2.7% (   0% -    5%)\n              HighPhrase      455.49      (1.5%)      476.29      (3.1%)    4.6% (   0% -    9%)\n             MedSpanNear      660.85      (2.0%)      693.91      (2.4%)    5.0% (   0% -    9%)\n              AndHighLow      482.21      (2.1%)      511.77      (2.5%)    6.1% (   1% -   11%)\n         LowSloppyPhrase      759.01      (1.9%)      816.01      (2.1%)    7.5% (   3% -   11%)\n\n ",
            "author": "Michael McCandless",
            "id": "comment-13830060"
        },
        {
            "date": "2013-11-24T06:01:39+0000",
            "content": "Thanks Mike. Looks like for the usual case, these changes do improve performance slightly (up to 7%). What's up w/ NO_PARENTS though? The code still iterates on an int[], with this patch it even iterates on an int[] w/o any skips, yet we see 70% slowdown!? And more so, the new structure should consume much less RAM than PTA, since we don't keep an int (-1) for the majority of the categories that are leaf nodes - which means more of these ints can fit into the CPU cache than in PTA? I don't think that Hashing into the map is significant since it happens once for the dim, but then the code iterates on the children[] directly?\n\nOne thing I note in the patch is that IntRollupFacetsAggregator now seems to do two 'ifs' per child: (1) the for-loop looping on all children of X, and (2) for each child, check if it has children before recursing. I think that has two effects, not present in trunk:\n\n\n\tAn extra 'if' - though it's arguable if that 'if' isn't in fact saving much more than on trunk, where we recurse in most cases for nothing. I believe recursion will be more expensive?\n\tA call to TR.getChildren(), which in turn makes all these calls:\n\t\n\t\tgetChildrenMap()\n\t\t\n\t\t\tensureOpen()\n\t\t\tif (children ==  null)\n\t\t\n\t\t\n\t\tmap.get(ordinal)\n\t\tif (kids == null)\n\t\n\t\n\n\n\nSo actually, looks like w/ this patch (since we don't have a single array), we lose in the rollup case (unlike what I wrote above), because for each child we make all these calls - none of them are present in trunk. I believe they add up .. accessing volatile members, hashing every one of the 2.5M categories ... I believe that's the slowdown that we see. What do you think?\n\nSo I see two ways to proceed:\n\n\n\tClose the issue as \"Won't Fix\" since the gains aren't high, yet the potential slowdown is substantial. We can reopen in the future if anything changes\n\tProceed w/ the map approach since it improves in the regular case, reduces RAM consumption and makes the API cleaner and more intuitive. Also, w/ Mike's changes on LUCENE-5539, we won't end up in a NO_PARENTS case for all flat dimensions...\n\t\n\t\tWell actually we could wait with this issue until LUCENE-5539 is resolved and then re-evaluate the changes. I still believe that for the hierarchical dimensions where we index leafs only, this approach will lose (because of all the extra calls I made above). But then someone will always be able to tell FacetsConfig that this is a multi-valued dim to enforce the ALL_BUT_DIM encoding, and gain speedups back ...\n\t\n\t\n\n\n\nWhat do you think?\n ",
            "author": "Shai Erera",
            "id": "comment-13830874"
        },
        {
            "date": "2013-11-24T06:57:10+0000",
            "content": "I think we don't have to wait for LUCENE-5339, we could handle some of these issues now.\n\n\n\tif (kids == null) and hashing - there's a solution to that: not hold it in a map. We could hold it in an int[][] and NO_CHILDREN for the entries which has no children. So we'll have one array at the size of the taxonomy, and the sum of others will be significantly smaller if we have flat dimensions. We'll lose some RAM compared to the Map, but it will speed things up because we'll simply return what's in children[ord].\n\n\n\n\n\tif (children == null) is done only because it's being allocated lazily. Does it make sense to keep it that way? We could compute the children upon taxonomy opening and be done with it. Today (trunk) reopen is very costly as it's in the O(TaxonomySize) which affects NRT reopen (it's not guaranteed that for each reopen someone will actually need the new facet information), , but if the computation of the children is done according to the O(new segments) than we're not wasting much.\n\n ",
            "author": "Gilad Barkai",
            "id": "comment-13830884"
        },
        {
            "date": "2013-11-24T21:01:14+0000",
            "content": "we could hold in an int[][]\n\n\n\tIf we do that, we still add an array pointer for every ordinal, which is much bigger than an int (I think it's 8 bytes?)\n\tWe'll still call taxoReader.getChildren(ord) for all the leaf nodes from the calling rollup code, so yes - we'll save some ifs and hash, but I'm not sure if overall we'll still win...\n\n\n\nWe could compute the children upon taxonomy opening and be done with it\n\nI don't object to it. I think usually if you work w/ a TaxoReader, you intend to do faceted search or traverse the taxonomy, so it makes sense to initialize it in the ctor.\n\nToday (trunk) reopen is very costly as it's in the O(TaxonomySize)\n\nThat's not entirely true, let's clarify it. While reopening a taxonomy and computing the new PTA, we do two things:\n\n\n\tgrow the parents[], children[] arrays - means arraycopy.\n\tprocess the parents of the new categories only\n\n\n\nSo it's not really O(TaxoSize). I don't think arraycopy is that expensive, compared to computing the parents[] / children[] / siblings[] (mostly parents[], since it reads a posting list). The expensive part is done only on the new segments in the taxonomy (the new category documents).  So the taxonomy is NRT is almost truly NRT. ",
            "author": "Shai Erera",
            "id": "comment-13831050"
        }
    ]
}