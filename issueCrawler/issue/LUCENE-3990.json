{
    "id": "LUCENE-3990",
    "title": "TestRandomChains failure caused by incorrect delegation in CharReader/CharFilter/CharStream API",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [
            "modules/analysis"
        ],
        "type": "Bug",
        "fix_versions": [
            "4.9",
            "6.0"
        ],
        "affect_versions": "None",
        "resolution": "Unresolved",
        "status": "Reopened"
    },
    "description": "100% reproduces for me:\n\n2> NOTE: reproduce with: ant test -Dtests.class=*.TestRandomChains -Dtests.method=testRandomChains -Dtests.seed=88CA02C2BB7B1DA -Dargs=\"-Dfile.encoding=UTF-8\"\n\nRunning org.apache.lucene.analysis.core.TestRandomChains\nFAILURE 7.22s | TestRandomChains.testRandomChains\n   > Throwable #1: java.lang.AssertionError: endOffset 1 expected:<7> but was:<8>\n   >    at __randomizedtesting.SeedInfo.seed([88CA02C2BB7B1DA:356D894D6CA5AC1A]:0)\n   >    at org.junit.Assert.fail(Assert.java:93)\n   >    at org.junit.Assert.failNotEquals(Assert.java:647)\n   >    at org.junit.Assert.assertEquals(Assert.java:128)\n   >    at org.junit.Assert.assertEquals(Assert.java:472)\n   >    at org.apache.lucene.analysis.BaseTokenStreamTestCase.assertTokenStreamContents(BaseTokenStreamTestCase.java:165)\n   >    at org.apache.lucene.analysis.BaseTokenStreamTestCase.checkAnalysisConsistency(BaseTokenStreamTestCase.java:662)\n   >    at org.apache.lucene.analysis.BaseTokenStreamTestCase.checkRandomData(BaseTokenStreamTestCase.java:486)\n   >    at org.apache.lucene.analysis.BaseTokenStreamTestCase.checkRandomData(BaseTokenStreamTestCase.java:429)\n   >    at org.apache.lucene.analysis.core.TestRandomChains.testRandomChains(TestRandomChains.java:820)\n\n\nThe root cause of this is inconsequent override of several Reader methods in subclasses of CharFilter. We should fix this urgently, thanks to the random chains we found this bug.",
    "attachments": {
        "LUCENE-3990-CharFilterFix.patch": "https://issues.apache.org/jira/secure/attachment/12522739/LUCENE-3990-CharFilterFix.patch",
        "LUCENE-3990.patch": "https://issues.apache.org/jira/secure/attachment/12522734/LUCENE-3990.patch",
        "analysis-common.tests-report.txt": "https://issues.apache.org/jira/secure/attachment/12522712/analysis-common.tests-report.txt"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2012-04-16T01:31:29+0000",
            "content": "Definitely something sneaky going on...\n\nfirst i found a minor bug in the test. the logic for determining if we should apply\nadditional offsets checks doesn't look at the return value, so if we ever try\na tokenizer in brokenOffsetsComponents (even if it throws IAE and we decide not to use it)\nthen we lose offsets checks for the eventually-working-chain.\n\nseed still works after fixing this... I'll commit a fix for that (still doesnt help this problem) ",
            "author": "Robert Muir",
            "id": "comment-13254479"
        },
        {
            "date": "2012-04-16T02:56:04+0000",
            "content": "The problem is that we are getting different results the first time we create the tokenstream components,\nversus after we reset(Reader) with the same text again.\n\nThe bug was introduced by Uwe Schindler in r1311358: when the reader-wrapper was changed to use CharFilter\ninstead. because of crazy CharFilter-Reader delegation.\n\nhttp://svn.apache.org/viewvc?view=revision&revision=1311358\n\nAttached is a patch demonstrating the bug: with a standalone testcase, and backing out that change.\nSeed now passes (in addition to the test. ",
            "author": "Robert Muir",
            "id": "comment-13254491"
        },
        {
            "date": "2012-04-16T05:54:58+0000",
            "content": "Hi Robert,\n\nif this patch fixes the problem we should fix the CharFilter interface. Simply reverting my change hides the bug, sorry. ",
            "author": "Uwe Schindler",
            "id": "comment-13254523"
        },
        {
            "date": "2012-04-16T05:57:27+0000",
            "content": "We have to fix the underlying bug. Subclassing CharFilter here is correct. ",
            "author": "Uwe Schindler",
            "id": "comment-13254527"
        },
        {
            "date": "2012-04-16T06:45:52+0000",
            "content": "Hi Robert,\n\nI investigated the problem, its indeed crazy wrapping: The problem was that CharFilter did not override read() (without char[]). The same applied to CharReader!!! By not overriding that method it was also slowing down all charfilters, because the base class Reader automatically delegates to read(char[]), creating a new char[1] every time.\n\nThe attached patch fixes this to delegate correctly. ",
            "author": "Uwe Schindler",
            "id": "comment-13254539"
        },
        {
            "date": "2012-04-16T07:02:02+0000",
            "content": "I remember looking at the fact that read() is not overridden when I was working on that pattern char filter and was surprised a bit about it, but then thought maybe it's wrapped in a buffered stream someplace else (then it doesn't matter).\n\nA good way to make sure it does get proper implementation is to make read() abstract again in CharStream... ",
            "author": "Dawid Weiss",
            "id": "comment-13254544"
        },
        {
            "date": "2012-04-16T07:03:01+0000",
            "content": "Committed trunk revision: 1326512 ",
            "author": "Uwe Schindler",
            "id": "comment-13254545"
        },
        {
            "date": "2012-04-16T07:08:45+0000",
            "content": "Dawid: I did not notice, indeed PatternCharReplaceFilter now gets a failure. I'll revert. The problem is exactly as you said. Thats completely broken, we should make that abstract! ",
            "author": "Uwe Schindler",
            "id": "comment-13254547"
        },
        {
            "date": "2012-04-16T07:20:45+0000",
            "content": "I reverted the CharFilter changes in revision: 1326515\n\nWe should really fix the broken delegation and make CharFilters require to implement both read() and read(char[], int, int) ",
            "author": "Uwe Schindler",
            "id": "comment-13254552"
        },
        {
            "date": "2012-04-16T07:21:16+0000",
            "content": "We should fix CharFilters in trunk to not have the horrible delegating. ",
            "author": "Uwe Schindler",
            "id": "comment-13254553"
        },
        {
            "date": "2012-04-16T07:24:16+0000",
            "content": "Robert: Sorry for the noise with heavy committing, and thanks for pointing to that bug! ",
            "author": "Uwe Schindler",
            "id": "comment-13254554"
        },
        {
            "date": "2012-04-16T08:07:55+0000",
            "content": "I investigated why the original commit lead to the bug:\nThe current committed stuff (Robert's revert and also my latest patch), just hide a bug in MappingCharFilter that causes this. Let me explain:\n\n\n\tWith Robert's patch (and also my current fix): read(char[],int,int) and read() both delegate to the underlying charstream.\n\tWith the original CharFilter approach, int read() was not overridden, so the default method in java.io.Reader did the following: allocate char[1], call read(buffer,0,1) -> MappingCharFilters's buffered read method was called. Unfortunately this method is behaving different than MappingCharFilter's one-character read(). And thats the bug here. So neither my code nor Roberts code is to blame, its MappingCharFilter or MockCharFilter that behave different in the two read methods.\n\n ",
            "author": "Uwe Schindler",
            "id": "comment-13254569"
        },
        {
            "date": "2012-04-16T08:35:13+0000",
            "content": "We should have a asserting method for CharFilter consistency. Indeed the read(char[],int,int) method in MappingCharFilter is failing horribly (which is caused by the underlying MockCharFilter somehow).\n\nI propose to adda CharFilter consistency method that reads two instances of the same CharFilter, one using read() and in parallel using read(char[]) with varying buffer sizes. It should check offsets (and that is what is heavy buggy in MappingCharOffsetCorrumpter / MockCharCorrumpter).\n\nI'll prepare a patch with the test method in BaseTokenStreamTestCase. ",
            "author": "Uwe Schindler",
            "id": "comment-13254583"
        },
        {
            "date": "2012-04-16T10:52:54+0000",
            "content": "Hi Uwe, i tried these same things, I know the interface is horrible but that wasnt really the bug here.\n\nIf we want to fix CharFilter/CharStream i think we should use LUCENE-2788. \n\nThat removes CharFilter/CharStream/CharReader and replaces with just one CharFilter class that extends FilterReader and is reusable. I think its a simpler way to go at least to only have one class... ",
            "author": "Robert Muir",
            "id": "comment-13254638"
        },
        {
            "date": "2012-04-16T10:54:51+0000",
            "content": "\nWe should have a asserting method for CharFilter consistency. Indeed the read(char[],int,int) method in MappingCharFilter is failing horribly (which is caused by the underlying MockCharFilter somehow).\n\nWe don't need to do all that actually. I think its enough if we have a CharFilter or Tokenizer that\nrandomly uses read(CharBuffer)/read(char[])/read()/read(char[], int,int)...\n\nthe other methods should be tested too. ",
            "author": "Robert Muir",
            "id": "comment-13254641"
        },
        {
            "date": "2012-07-11T23:03:42+0000",
            "content": "bulk cleanup of 4.0-ALPHA / 4.0 Jira versioning. all bulk edited issues have hoss20120711-bulk-40-change in a comment ",
            "author": "Hoss Man",
            "id": "comment-13412285"
        },
        {
            "date": "2012-08-07T03:41:24+0000",
            "content": "rmuir20120906-bulk-40-change ",
            "author": "Robert Muir",
            "id": "comment-13429704"
        },
        {
            "date": "2013-07-23T18:44:48+0000",
            "content": "Bulk move 4.4 issues to 4.5 and 5.0 ",
            "author": "Steve Rowe",
            "id": "comment-13717064"
        },
        {
            "date": "2014-04-16T12:54:48+0000",
            "content": "Move issue to Lucene 4.9. ",
            "author": "Uwe Schindler",
            "id": "comment-13970887"
        }
    ]
}