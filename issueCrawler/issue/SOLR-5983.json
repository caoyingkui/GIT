{
    "id": "SOLR-5983",
    "title": "HTMLStripCharFilter is treating CDATA sections incorrectly",
    "details": {
        "affect_versions": "4.7.1",
        "status": "Closed",
        "fix_versions": [
            "4.8",
            "4.9",
            "6.0"
        ],
        "components": [
            "Schema and Analysis"
        ],
        "type": "Bug",
        "priority": "Major",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "I'm hammering on this Solr Instance.  I've got three cores that I'm using to store millions of small bits of reference data.  I'm using a heavily tweaked Tika to parse xml files and ingest them into Solr, while referencing this data.  So I'm making hundreds of query requests against solr, while also making some substantial posts. (I queue up the posts, in general sending in 100 documents at a time). \n\nStack Trace:\n\n4099640 [qtp39890933-24] WARN  org.eclipse.jetty.servlet.ServletHandler  \u2013 Error for /solr/us_patent_gran\nt/update\njava.lang.AssertionError: Attempting to read past the end of a segment.\n        at org.apache.lucene.analysis.charfilter.HTMLStripCharFilter$TextSegment.nextChar(HTMLStripCharFi\nlter.java:30885)\n        at org.apache.lucene.analysis.charfilter.HTMLStripCharFilter.zzDoEOF(HTMLStripCharFilter.java:311\n50)\n        at org.apache.lucene.analysis.charfilter.HTMLStripCharFilter.nextChar(HTMLStripCharFilter.java:31\n802)\n        at org.apache.lucene.analysis.charfilter.HTMLStripCharFilter.read(HTMLStripCharFilter.java:30829)\n        at org.apache.lucene.analysis.charfilter.HTMLStripCharFilter.read(HTMLStripCharFilter.java:30842)        at org.apache.lucene.analysis.standard.std40.StandardTokenizerImpl40.zzRefill(StandardTokenizerImpl40.java:916)\n        at org.apache.lucene.analysis.standard.std40.StandardTokenizerImpl40.getNextToken(StandardTokenizerImpl40.java:1123)\n        at org.apache.lucene.analysis.standard.StandardTokenizer.incrementToken(StandardTokenizer.java:17\n5)\n        at org.apache.lucene.analysis.payloads.TokenOffsetPayloadTokenFilter.incrementToken(TokenOffsetPa\nyloadTokenFilter.java:45)\n        at org.apache.lucene.analysis.core.LowerCaseFilter.incrementToken(LowerCaseFilter.java:54)\n        at org.apache.lucene.index.DocInverterPerField.processFields(DocInverterPerField.java:182)\n        at org.apache.lucene.index.DocFieldProcessor.processDocument(DocFieldProcessor.java:248)\n        at org.apache.lucene.index.DocumentsWriterPerThread.updateDocument(DocumentsWriterPerThread.java:253)\n        at org.apache.lucene.index.DocumentsWriter.updateDocument(DocumentsWriter.java:455)\n        at org.apache.lucene.index.IndexWriter.updateDocument(IndexWriter.java:1534)\n        at org.apache.solr.update.DirectUpdateHandler2.addDoc0(DirectUpdateHandler2.java:236)\n        at org.apache.solr.update.DirectUpdateHandler2.addDoc(DirectUpdateHandler2.java:160)\n        at org.apache.solr.update.processor.RunUpdateProcessor.processAdd(RunUpdateProcessorFactory.java:\n69)\n        at org.apache.solr.update.processor.UpdateRequestProcessor.processAdd(UpdateRequestProcessor.java\n:51)\n        at org.apache.solr.update.processor.DistributedUpdateProcessor.doLocalAdd(DistributedUpdateProces\nsor.java:704)\n        at org.apache.solr.update.processor.DistributedUpdateProcessor.versionAdd(DistributedUpdateProces\nsor.java:858)\n        at org.apache.solr.update.processor.DistributedUpdateProcessor.processAdd(DistributedUpdateProces\nsor.java:557)\n        at org.apache.solr.update.processor.LogUpdateProcessor.processAdd(LogUpdateProcessorFactory.java:\n100)\n        at org.apache.solr.handler.loader.XMLLoader.processUpdate(XMLLoader.java:247)\n        at org.apache.solr.handler.loader.XMLLoader.load(XMLLoader.java:174)\n        at org.apache.solr.handler.UpdateRequestHandler$1.load(UpdateRequestHandler.java:92)\n        at org.apache.solr.handler.ContentStreamHandlerBase.handleRequestBody(ContentStreamHandlerBase.ja\nva:74)\n        at org.apache.solr.handler.RequestHandlerBase.handleRequest(RequestHandlerBase.java:135)\n        at org.apache.solr.core.SolrCore.execute(SolrCore.java:1916)\n        at org.apache.solr.servlet.SolrDispatchFilter.execute(SolrDispatchFilter.java:780)\n        at org.apache.solr.servlet.SolrDispatchFilter.doFilter(SolrDispatchFilter.java:427)\n        at org.apache.solr.servlet.SolrDispatchFilter.doFilter(SolrDispatchFilter.java:217)\n        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1419)",
    "attachments": {
        "SOLR-5983.patch": "https://issues.apache.org/jira/secure/attachment/12640593/SOLR-5983.patch",
        "temp.txt": "https://issues.apache.org/jira/secure/attachment/12640094/temp.txt"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Steve Rowe",
            "id": "comment-13968380",
            "date": "2014-04-14T14:10:49+0000",
            "content": "Hi Dan,\n\nDo you know which document triggered the problem?  If so, can you post it here, ideally in the form you're indexing (after Tika etc. pre-processing)?\n\nSteve "
        },
        {
            "author": "Dan",
            "id": "comment-13968398",
            "date": "2014-04-14T14:43:51+0000",
            "content": "Steve, it is an intermittent issue.  I can go back and re-index the same document set without a problem.   "
        },
        {
            "author": "Dan",
            "id": "comment-13968407",
            "date": "2014-04-14T14:54:37+0000",
            "content": "Well, darn it, I just proved myself wrong.  I was able to reproduce it with the same data set.  Please give me a bit to track down the exact file. "
        },
        {
            "author": "Dan",
            "id": "comment-13968498",
            "date": "2014-04-14T16:34:11+0000",
            "content": "Here is the offending solr document that is causing the error.   "
        },
        {
            "author": "Dan",
            "id": "comment-13968500",
            "date": "2014-04-14T16:35:05+0000",
            "content": "Hi Steve, I've attached the results of calling toString on the solr document that is causing this error.   "
        },
        {
            "author": "Steve Rowe",
            "id": "comment-13969036",
            "date": "2014-04-15T00:02:08+0000",
            "content": "Dan,\n\nStrings of this form (from the description_html field) trigger the exception:\n\n\n<!\u2009[CDATA[Ultraflexible Series Cable]\u2009]\u2009>\n\n\n\nThe above string alone hits the assert.  The characters between <! and [CDATA[, ] and ], and ] and > are all U+2009 THIN SPACE.\n\nI'm working on tracking down why - looks like it's related to the U+2009 char in front of [CDATA[. \n\nBy the way, if you're inserting the U+2009 intentionally to block recognition of CDATA sections and force HTML stripping, an alternate technique is to run text through HTMLStripCharFilter twice. "
        },
        {
            "author": "Steve Rowe",
            "id": "comment-13969073",
            "date": "2014-04-15T00:34:50+0000",
            "content": "Looks like there are two problems: \n\n\n\tAny chars between <! and [CDATA[ should block recognition of a CDATA section, but those chars are now passed through to the output, and a CDATA section is improperly recognized.\n\tThe immediate cause of the assert is an unclosed CDATA section. HTMLStripCharFilter requires the exact string ]]> to close out a CDATA section, following the XML spec.  When a CDATA section is started (even improperly, as in the first problem above), but the CDATA closing string is not found, the assert is hit at end-of-input.  So this is the minimal error-triggering string:\n\n\n\n\n<![CDATA[\n\n\n\nI'm working on a fix. "
        },
        {
            "author": "Steve Rowe",
            "id": "comment-13972331",
            "date": "2014-04-17T05:59:40+0000",
            "content": "Patch fixing the problem. Tests added to HTMLStripCharFilterTest, and extracted redundant char filter testing out into HTMLStripCharFilterTest.assertHTMLStripsTo() methods.\n\nCommitting shortly. "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-13972337",
            "date": "2014-04-17T06:08:19+0000",
            "content": "Commit 1588136 from sarowe@apache.org in branch 'dev/trunk'\n[ https://svn.apache.org/r1588136 ]\n\nSOLR-5983: HTMLStripCharFilter is treating CDATA sections incorrectly "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-13972341",
            "date": "2014-04-17T06:15:32+0000",
            "content": "Commit 1588137 from sarowe@apache.org in branch 'dev/branches/branch_4x'\n[ https://svn.apache.org/r1588137 ]\n\nSOLR-5983: HTMLStripCharFilter is treating CDATA sections incorrectly (merged trunk r1588136) "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-13972343",
            "date": "2014-04-17T06:24:13+0000",
            "content": "Commit 1588138 from sarowe@apache.org in branch 'dev/branches/lucene_solr_4_8'\n[ https://svn.apache.org/r1588138 ]\n\nSOLR-5983: HTMLStripCharFilter is treating CDATA sections incorrectly (merged trunk r1588136) "
        },
        {
            "author": "Steve Rowe",
            "id": "comment-13972347",
            "date": "2014-04-17T06:27:04+0000",
            "content": "Committed to trunk, branch_4x, and the lucene_solr_4_8 branch.\n\nThanks Dan! "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-13982627",
            "date": "2014-04-27T23:26:00+0000",
            "content": "Close issue after release of 4.8.0 "
        }
    ]
}