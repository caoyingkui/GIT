{
    "id": "LUCENE-2501",
    "title": "ArrayIndexOutOfBoundsException in ByteBlockPool.allocSlice",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [
            "core/index"
        ],
        "type": "Bug",
        "fix_versions": [
            "3.6",
            "4.0-BETA",
            "6.0"
        ],
        "affect_versions": "3.0.1",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "I'm seeing the following exception during indexing:\n\nCaused by: java.lang.ArrayIndexOutOfBoundsException: 14\nat org.apache.lucene.index.ByteBlockPool.allocSlice(ByteBlockPool.java:118)\nat org.apache.lucene.index.TermsHashPerField.writeByte(TermsHashPerField.java:490)\nat org.apache.lucene.index.TermsHashPerField.writeVInt(TermsHashPerField.java:511)\nat org.apache.lucene.index.FreqProxTermsWriterPerField.writeProx(FreqProxTermsWriterPerField.java:104)\nat org.apache.lucene.index.FreqProxTermsWriterPerField.newTerm(FreqProxTermsWriterPerField.java:120)\nat org.apache.lucene.index.TermsHashPerField.add(TermsHashPerField.java:468)\nat org.apache.lucene.index.DocInverterPerField.processFields(DocInverterPerField.java:174)\nat org.apache.lucene.index.DocFieldProcessorPerThread.processDocument(DocFieldProcessorPerThread.java:246)\nat org.apache.lucene.index.DocumentsWriter.updateDocument(DocumentsWriter.java:774)\nat org.apache.lucene.index.DocumentsWriter.updateDocument(DocumentsWriter.java:757)\nat org.apache.lucene.index.IndexWriter.updateDocument(IndexWriter.java:2085)\n... 37 more\n\n\n\n\nThis seems to be caused by the following code:\n\n    final int level = slice[upto] & 15;\n    final int newLevel = nextLevelArray[level];\n    final int newSize = levelSizeArray[newLevel];\n\n\n\nthis can result in \"level\" being a value between 0 and 14\nthe array nextLevelArray is only of size 10\n\ni suspect the solution would be to either max the level to 10, or to add more entries to the nextLevelArray so it has 15 entries\nhowever, i don't know if something more is going wrong here and this is just where the exception hits from a deeper issue",
    "attachments": {
        "LUCENE-2501.patch": "https://issues.apache.org/jira/secure/attachment/12538932/LUCENE-2501.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2010-06-16T16:51:56+0000",
            "content": "Hmmm, not good.  Can you boil this down to a smallish test case?\n\nlevel should never be > 9, because nextLevelArray[*] is no greater than 9.  Something more serious is up... ",
            "author": "Michael McCandless",
            "id": "comment-12879379"
        },
        {
            "date": "2010-06-16T16:58:25+0000",
            "content": "thats what i was afraid of\n\ni got this report second hand, so i don't have access to the data that was being ingested\n\nand i currently don't know enough about this section of the indexing code to guess in order to create a unit test\ni'll try to create a test, but i expect it will be difficult (especially if no one else has ever seen this) ",
            "author": "Tim Smith",
            "id": "comment-12879382"
        },
        {
            "date": "2010-06-16T17:12:43+0000",
            "content": "Is this issue repeatable, on a different machine?\n\nWe do have a randomized test for this (TestByteSlices) \u2013 I'll go start it w/ big random.multiplier.  Maybe it can uncover this  ",
            "author": "Michael McCandless",
            "id": "comment-12879389"
        },
        {
            "date": "2010-06-16T17:19:44+0000",
            "content": "What sized RAM buffer was being used for IW when this exception happened? ",
            "author": "Michael McCandless",
            "id": "comment-12879399"
        },
        {
            "date": "2010-06-16T17:23:35+0000",
            "content": "Here's all the info i have available right now (will try to get more):\n\n16 core, 18-gig ram Windows 7 machine\n1 JVM\n16 index writers (each using default settings (64M ram, etc))\n300+ docs/sec ingestion (small documents)\ncommit every 10 minutes\noptimize every hour\n\nThe report i got indicated that every now and then one of these ArrayIndexOutOfBounds exceptions would occur\nthis would result in the document being indexed failing, but otherwise things would continue normally ",
            "author": "Tim Smith",
            "id": "comment-12879403"
        },
        {
            "date": "2010-06-16T17:57:30+0000",
            "content": "Some more info:\n\ningestion is being performed in multiple threads\n\nArrayIndexOutOfBounds exception is occurring in bursts\nI suspect that these bursts of exceptions stop after the next commit (at which point the buffers are all reset) \nNOTE: i have not yet confirmed this, but i suspect it ",
            "author": "Tim Smith",
            "id": "comment-12879422"
        },
        {
            "date": "2010-06-16T20:05:31+0000",
            "content": "Looks like this may be the original source of the errors\n\n\nCaused by: org.apache.lucene.index.CorruptIndexException: docs out of order (607 <= 607 )\n\tat org.apache.lucene.index.FormatPostingsDocsWriter.addDoc(FormatPostingsDocsWriter.java:76)\n\tat org.apache.lucene.index.FreqProxTermsWriter.appendPostings(FreqProxTermsWriter.java:209)\n\tat org.apache.lucene.index.FreqProxTermsWriter.flush(FreqProxTermsWriter.java:127)\n\tat org.apache.lucene.index.TermsHash.flush(TermsHash.java:144)\n\tat org.apache.lucene.index.DocInverter.flush(DocInverter.java:72)\n\tat org.apache.lucene.index.DocFieldProcessor.flush(DocFieldProcessor.java:64)\n\tat org.apache.lucene.index.DocumentsWriter.flush(DocumentsWriter.java:583)\n\tat org.apache.lucene.index.IndexWriter.doFlushInternal(IndexWriter.java:3602)\n\tat org.apache.lucene.index.IndexWriter.doFlush(IndexWriter.java:3511)\n\tat org.apache.lucene.index.IndexWriter.flush(IndexWriter.java:3502)\n\tat org.apache.lucene.index.IndexWriter.updateDocument(IndexWriter.java:2103)\n\n ",
            "author": "Tim Smith",
            "id": "comment-12879483"
        },
        {
            "date": "2010-06-16T20:18:43+0000",
            "content": "Are you certain about IW's RAM buffer size?  If the RAM buffer size was close to 2GB it could lead to exceptions like this. ",
            "author": "Michael McCandless",
            "id": "comment-12879485"
        },
        {
            "date": "2010-06-16T20:25:47+0000",
            "content": "ram buffer size is set to 64.0 ",
            "author": "Tim Smith",
            "id": "comment-12879486"
        },
        {
            "date": "2010-06-16T20:29:14+0000",
            "content": "Can you capture IW.setInfoStream output leading up to it? ",
            "author": "Michael McCandless",
            "id": "comment-12879487"
        },
        {
            "date": "2010-06-16T20:43:40+0000",
            "content": "will do\n\nmay take some time before it occurs again\n\nalso, if this boils down to a synchronization error of some sort, the extra file io done to write the trace info to disk may add some implicit synchronization/slowdown that may result in not being able to reproduce the issue (i've seen this occur on non-lucene related synchronization issues, add the extra debug logging and it never fails anymore) ",
            "author": "Tim Smith",
            "id": "comment-12879489"
        },
        {
            "date": "2010-06-16T21:02:46+0000",
            "content": "also, if this boils down to a synchronization error of some sort, the extra file io done to write the trace info to disk may add some implicit synchronization/slowdown that may result in not being able to reproduce the issue\n\nAhh yes, the Heisenbug (http://en.wikipedia.org/wiki/Unusual_software_bug#Heisenbug).  Still it's worth a shot to see if we can catch it in action... ",
            "author": "Michael McCandless",
            "id": "comment-12879495"
        },
        {
            "date": "2010-06-23T13:02:15+0000",
            "content": "I've been informed that this exception is still happening\n\nhowever, whenever index tracing is turned on, it never seems to occur (extra logging seems to be preventing some lower level synchronization issue from surfacing)\n\n\n\n ",
            "author": "Tim Smith",
            "id": "comment-12881675"
        },
        {
            "date": "2010-06-23T22:19:27+0000",
            "content": "Could you still post the infoStream output?  I can at least look at this to see how IW is being used.\n\nDoes this occur on different machines?  (Hardware issues could lead to exceptions like this). ",
            "author": "Michael McCandless",
            "id": "comment-12881923"
        },
        {
            "date": "2012-08-02T08:40:27+0000",
            "content": "Seeing a similar issue on 3.1.0. Was this ever resolved? or there's a workaround?\n\nStack:\n\n00000049 SeedlistOpera Failed to process operation ADD java.lang.ArrayIndexOutOfBoundsException at org.apache.lucene.index.ByteBlockPool.allocSlice(ByteBlockPool.java:135) at org.apache.lucene.index.TermsHashPerField.writeByte(TermsHashPerField.java:502) at org.apache.lucene.index.TermsHashPerField.writeVInt(TermsHashPerField.java:523) at org.apache.lucene.index.FreqProxTermsWriterPerField.writeProx(FreqProxTermsWriterPerField.java:106) at org.apache.lucene.index.FreqProxTermsWriterPerField.newTerm(FreqProxTermsWriterPerField.java:126) at org.apache.lucene.index.TermsHashPerField.add(TermsHashPerField.java:479) at org.apache.lucene.index.DocInverterPerField.processFields(DocInverterPerField.java:169) at org.apache.lucene.index.DocFieldProcessorPerThread.processDocument(DocFieldProcessorPerThread.java:248) at org.apache.lucene.index.DocumentsWriter.updateDocument(DocumentsWriter.java:701) at org.apache.lucene.index.IndexWriter.updateDocument(IndexWriter.java:2194) at \n... ",
            "author": "Gili Nachum",
            "id": "comment-13427179"
        },
        {
            "date": "2012-08-02T18:25:46+0000",
            "content": "OK I found a possible cause behind this ... it was something I had\nfixed but didn't pull out and backport to 3.x LUCENE-3684.\n\nIt's a thread safety issue, when FielfInfo.indexOptions changes from\nDOCS_AND_FREQS_AND_POSITIONS to not indexing positions.  If this\nhappens in one thread while a new thread is suddenly indexing a that\nsame field there's a narrow window where the 2nd thread's\nFreqProxTermsWriterPerField can mis-report the streamCount as 1 when\nit should be 2.\n\nAttached patch (3.6.x) should fix it.  I tried to get a thread test to\nprovoke this but couldn't ... I think the window is too small (if I\nforcefully add sleeps at the \"right time\" in\nFreqProxTermsWriterPerField then I could provoke it...). ",
            "author": "Michael McCandless",
            "id": "comment-13427514"
        },
        {
            "date": "2012-08-02T18:36:31+0000",
            "content": "sneaky, glad that this stuff is single threaded in 4.0  ",
            "author": "Simon Willnauer",
            "id": "comment-13427517"
        },
        {
            "date": "2012-08-02T18:41:00+0000",
            "content": "I'm glad too! ",
            "author": "Michael McCandless",
            "id": "comment-13427518"
        },
        {
            "date": "2012-08-02T19:01:58+0000",
            "content": "+1 ",
            "author": "Robert Muir",
            "id": "comment-13427531"
        },
        {
            "date": "2012-08-02T19:47:53+0000",
            "content": "I committed the patch, but I'll leave this open until we can hear back from Tim or Gili that this has resolved the issue ... ",
            "author": "Michael McCandless",
            "id": "comment-13427554"
        },
        {
            "date": "2012-08-06T07:25:38+0000",
            "content": "Issue resolved successfully. Even when increasing the degree of concurrency, I can no longer reproduce with 16 threads over 4 core machine. \nThank you Michael! ",
            "author": "Gili Nachum",
            "id": "comment-13429006"
        },
        {
            "date": "2012-08-06T09:32:59+0000",
            "content": "Thanks for bringing closure, Gili. ",
            "author": "Michael McCandless",
            "id": "comment-13429045"
        }
    ]
}