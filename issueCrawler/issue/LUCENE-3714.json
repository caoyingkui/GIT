{
    "id": "LUCENE-3714",
    "title": "add suggester that uses shortest path/wFST instead of buckets",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [
            "modules/spellchecker"
        ],
        "type": "New Feature",
        "fix_versions": [
            "3.6",
            "4.0-ALPHA"
        ],
        "affect_versions": "None",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "Currently the FST suggester (really an FSA) quantizes weights into buckets (e.g. single byte) and puts them in front of the word.\nThis makes it fast, but you lose granularity in your suggestions.\n\nLately the question was raised, if you build lucene's FST with positiveintoutputs, does it behave the same as a tropical semiring wFST?\n\nIn other words, after completing the word, we instead traverse min(output) at each node to find the 'shortest path' to the \nbest suggestion (with the highest score).\n\nThis means we wouldnt need to quantize weights at all and it might make some operations (e.g. adding fuzzy matching etc) a lot easier.",
    "attachments": {
        "out.png": "https://issues.apache.org/jira/secure/attachment/12511408/out.png",
        "TestMe.java": "https://issues.apache.org/jira/secure/attachment/12511440/TestMe.java",
        "LUCENE-3714.patch": "https://issues.apache.org/jira/secure/attachment/12511405/LUCENE-3714.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2012-01-21T19:14:41+0000",
            "content": "patch that Mike and I came up with that finds the minimal output from an arc, and a random test showing it works. ",
            "author": "Robert Muir",
            "id": "comment-13190510"
        },
        {
            "date": "2012-01-21T20:25:39+0000",
            "content": "An problematic example where root arcs, when traversed min-to-max collect outputs, but every outgoing arc only collects a single better suggestion (and should skip possibly lots of other suggestions). This is created by the following input:\n\naa|N\nab|1\nba|N\nbb|2\nca|N\ncb|3\n..\n\ncollecting the K-th suggestion with the smallest score will require scanning pessimistically all of the arcs. Note that you can put arbitrarily large subtrees on _a|N nodes like:\n\naaa|N\naab|N\naac|N\n\netc. ",
            "author": "Dawid Weiss",
            "id": "comment-13190523"
        },
        {
            "date": "2012-01-21T20:28:04+0000",
            "content": "The patch works because it finds the first (topmost) suggestion, but collecting suggestions with max-N (or min-N) will require a priority queue so that one knows which next arc to follow next (and this will also require storing partially collected paths for pointers in the fst/queue)? ",
            "author": "Dawid Weiss",
            "id": "comment-13190524"
        },
        {
            "date": "2012-01-21T20:29:02+0000",
            "content": "Not sure it requires one, http://www.cs.nyu.edu/~mohri/pub/nbest.ps has some solutions. ",
            "author": "Robert Muir",
            "id": "comment-13190525"
        },
        {
            "date": "2012-01-21T20:33:19+0000",
            "content": "I'm sure there are solutions to the problem if you change algebra ops \u2013 the pq is a naive solutions that would work on top of positive outputs. ",
            "author": "Dawid Weiss",
            "id": "comment-13190526"
        },
        {
            "date": "2012-01-21T21:41:51+0000",
            "content": "Yeah I think we should try that first, and see how it performs. ",
            "author": "Robert Muir",
            "id": "comment-13190535"
        },
        {
            "date": "2012-01-21T21:45:04+0000",
            "content": "Dawid, by problematic example, you mean you think this approach is functionally correct but may not perform very well...?\n\nThat is definitely the worst-case performance (for either top-1 or top-K on a wFST with simple PQ), but this (number of non-competitive arcs you have to scan and discard) is a constant factor on the overall complexity right?\n\nI think we should at least test the simple PQ on PositiveIntsOutputs wFST and see how it performs in practice.  If indeed having everything \"in one bucket\" is too slow, we could combine the two approaches: still use buckets, but within each bucket we have a wFST (ie, use the \"true\" score), so we don't actually do any quantizing in the end results.  Then bucketing is purely an optimization...\n\nOr, maybe, we could keep one bucket but sort each node's arcs by their output instead of by label.  This'd mean the initial lookup-by-prefix gets slower (linear scan instead a bin search, assuming those nodes had array'd arcs), but then producing the top-N is very fast (no wasted arcs need to be scanned).  Maybe we could keep the by-label sort for nodes within depth N, and then sort by output beyond that...\n\nOr we could change the outputs algebra so that more \"lookahead\" is stored in each output so we have more guidance on which arcs are worth pursuing... ",
            "author": "Michael McCandless",
            "id": "comment-13190536"
        },
        {
            "date": "2012-01-21T22:04:34+0000",
            "content": "I thought you had a solution that collects top-N, but your patch selects one (best) matching solution only. I don't know how you planned to go around selecting top-N, but in my understanding (at that moment) top-N selection is not going to work via recursive scan because an output at the given level doesn't tell you much about which arcs to follow. \n\nI can see how this can be solved by picking the arc/direction with the \"next smallest/largest\" output among all arcs traversed so far but this will be more complex and I cannot provide any bounds on how large the queue can be or what the   worst case lookup then is. I do have a feeling a degenerate example can be devised, but then I also have a feeling these are uncommon in practice.\n\nSorting arcs by score doesn't help if you use the pq \u2013 you need to add all of them to the pq and then pick the smallest path. In a way it is like what you did, but the pq is maintaining fast access to the next-smaller-cost path. Another feeling is that the PQ can be bound to a maximum size of N? Every arc leads to at least one leaf so while traversing you'd drop those arcs that definitely would have fallen out of the first N smallest/largest weights... Yes, this could work. I'd still try to devise a degenerate example to see what the cost of maintaining the PQ can be. ",
            "author": "Dawid Weiss",
            "id": "comment-13190539"
        },
        {
            "date": "2012-01-21T22:15:16+0000",
            "content": "If I seem inconsistent above then it's because I don't have ready-to-use answers and I'm sort of thinking out loud  ",
            "author": "Dawid Weiss",
            "id": "comment-13190541"
        },
        {
            "date": "2012-01-21T22:29:07+0000",
            "content": "\nwe could combine the two approaches: still use buckets, but within each bucket we have a wFST (ie, use the \"true\" score), so we don't actually do any quantizing in the end results. Then bucketing is purely an optimization...\n\nI like this idea! ",
            "author": "Robert Muir",
            "id": "comment-13190543"
        },
        {
            "date": "2012-01-21T22:57:02+0000",
            "content": "If my feeling is right and the PQ can be kept constant-size then it won't matter much at runtime I think. With realistic data distributions the number of elements to be inserted into the PQ before you reach the top-N will be pretty much the same . And the benefit would be a much cleaner traversal (no need to deal with buckets, early termination, etc.). ",
            "author": "Dawid Weiss",
            "id": "comment-13190547"
        },
        {
            "date": "2012-01-22T19:56:15+0000",
            "content": "Patch, generalizing to a topN search from the wFST (not just top 1).  I fixed the random test to randomly pick a topN and it's passing!\n\nI think the cost is something like O(N * L) + O(N * log(N)), where N is the top N and L is the length of each completion.  The N * log(N) is because I use a TreeSet (PQ wasn't enough: I needed pollFirst and pollLast... for 3.x that'll have to be 2 method calls...)... but I suspect in practice it won't dominate, since N is typically smaller than L and the constant in front of that is tiny...\n\nEach path requires a traversal through the FST looking for the arcs with NO_OUTPUT, so if the FST has many non-competitive arcs that will definitely slow it down (by a [possibly large] constant factor).  We need to test on a real data set how slow it is.... ",
            "author": "Michael McCandless",
            "id": "comment-13190752"
        },
        {
            "date": "2012-01-22T20:04:29+0000",
            "content": "an example showing top-n with score and alpha order, pq (unbounded, but going for bounded should be simple). ",
            "author": "Dawid Weiss",
            "id": "comment-13190754"
        },
        {
            "date": "2012-01-22T20:07:37+0000",
            "content": "Damn, Again slower than McCandless... I didn't do a bounded queue but it's perfectly possible to do one. My patch just shows the algorithm, didn't check if Mike's version is the same but I suspect it must be close . ",
            "author": "Dawid Weiss",
            "id": "comment-13190756"
        },
        {
            "date": "2012-01-22T20:50:02+0000",
            "content": "Ooh, your patch is doing the same algo as mine (best-first search)... yours is much simpler/smaller though \n\nI think your tie break isn't quite right?  Because, those two arc.labels you use aren't necessarily \"comparable\", since the two paths may not be the same length (hmm or share the same \"last parent\" node)?  You need to roll back and do a full compare of the accumulated input labels down that path?  I struggled with this too...\n\nI also took advantage of a neat property that every min/+ wFST will have (Robert pointed this out): the first arc (only) will have the min output, and then there must exist a NO_OUTPUT completion path from that arc to some final node.  So, I think my patch will visit paths in the same best-first order as yours, but I avoid the push/pop/new object into the queue for each arc traversed by greedily/recursively pursuing the first NO_OUTPUT arc I can find.  I only fall back to the queue when I need to find the next top-N path to pursue...\n ",
            "author": "Michael McCandless",
            "id": "comment-13190773"
        },
        {
            "date": "2012-01-22T21:04:44+0000",
            "content": "You're correct \u2013 I should be comparing full paths so far, not the current label. Otherwise I see we're pretty much the same. I like the lower bound cutoff condition. I vaguely understand the NO_OUTPUT optimization.  \n\nI like it, this indeed is a nice improvement - if somebody wants exact scores, they can have them. ",
            "author": "Dawid Weiss",
            "id": "comment-13190778"
        },
        {
            "date": "2012-01-26T03:58:15+0000",
            "content": "patch with a prototype suggester.\n\nthere are many nocommits: especially the encoding of weights is very inefficient and slows/bloats the fst (but easy for a prototype).\n\nWe should make a better Outputs class with the algebra we need (e.g. max) and maybe think about floats in this suggester API (it seems from the API names like TermFreq that these are really frequencies so maybe we should define them as ints? I don't like floats because of all the hassles like NaN/inf)\n\nBut even with this, the performance seems promising:\n\n\n    [junit] ------------- Standard Error -----------------\n    [junit] -- prefixes: 100-200, num: 7, onlyMorePopular: true\n    [junit] JaspellLookup   queries: 50001, time[ms]: 91 [+- 6.59], ~qps: 547\n    [junit] TSTLookup       queries: 50001, time[ms]: 33 [+- 1.55], ~qps: 1532\n    [junit] FSTCompletionLookup queries: 50001, time[ms]: 163 [+- 13.04], ~qps: 307\n    [junit] WFSTCompletionLookup queries: 50001, time[ms]: 55 [+- 1.50], ~qps: 910\n    [junit] -- construction time\n    [junit] JaspellLookup   input: 50001, time[ms]: 23 [+- 0.93]\n    [junit] TSTLookup       input: 50001, time[ms]: 31 [+- 1.25]\n    [junit] FSTCompletionLookup input: 50001, time[ms]: 72 [+- 1.73]\n    [junit] WFSTCompletionLookup input: 50001, time[ms]: 69 [+- 2.50]\n    [junit] -- RAM consumption\n    [junit] JaspellLookup   size[B]:    7,869,415\n    [junit] TSTLookup       size[B]:    7,914,524\n    [junit] FSTCompletionLookup size[B]:      466,051\n    [junit] WFSTCompletionLookup size[B]:      506,662\n    [junit] -- prefixes: 6-9, num: 7, onlyMorePopular: true\n    [junit] JaspellLookup   queries: 50001, time[ms]: 129 [+- 1.37], ~qps: 389\n    [junit] TSTLookup       queries: 50001, time[ms]: 139 [+- 2.30], ~qps: 361\n    [junit] FSTCompletionLookup queries: 50001, time[ms]: 177 [+- 1.62], ~qps: 282\n    [junit] WFSTCompletionLookup queries: 50001, time[ms]: 85 [+- 12.74], ~qps: 592\n    [junit] -- prefixes: 2-4, num: 7, onlyMorePopular: true\n    [junit] JaspellLookup   queries: 50001, time[ms]: 363 [+- 16.75], ~qps: 138\n    [junit] TSTLookup       queries: 50001, time[ms]: 1112 [+- 22.57], ~qps: 45\n    [junit] FSTCompletionLookup queries: 50001, time[ms]: 140 [+- 3.16], ~qps: 356\n    [junit] WFSTCompletionLookup queries: 50001, time[ms]: 242 [+- 4.01], ~qps: 207\n    [junit] ------------- ---------------- ---------------\n\n ",
            "author": "Robert Muir",
            "id": "comment-13193548"
        },
        {
            "date": "2012-01-26T07:48:30+0000",
            "content": "Didn't look at the patch yet but this looks surprising:\n\nFSTCompletionLookup queries: 50001, time[ms]: 163 [+- 13.04], ~qps: 307\nWFSTCompletionLookup queries: 50001, time[ms]: 55 [+- 1.50], ~qps: 910\n\n\n\nWhy would the previous version be so much slower? With onlyMorePopular=true this should be a single pass. Unless it's setup to bring exact match to the top and then there's a need to check multiple buckets with lower scores \u2013 would that be it? ",
            "author": "Dawid Weiss",
            "id": "comment-13193637"
        },
        {
            "date": "2012-01-26T12:54:35+0000",
            "content": "Thats the exact match case of the benchmark where it benchmarks the entire word being typed in completely?\n\nI didn't look at it because its not very interesting (TSTLookup looks super-fast here too)\n\nI think this is the interesting part:\n\n    [junit] -- prefixes: 2-4, num: 7, onlyMorePopular: true\n    [junit] JaspellLookup   queries: 50001, time[ms]: 363 [+- 16.75], ~qps: 138\n    [junit] TSTLookup       queries: 50001, time[ms]: 1112 [+- 22.57], ~qps: 45\n    [junit] FSTCompletionLookup queries: 50001, time[ms]: 140 [+- 3.16], ~qps: 356\n    [junit] WFSTCompletionLookup queries: 50001, time[ms]: 242 [+- 4.01], ~qps: 207\n\n\n\nWe could of course toggle 'num' etc and see how this comes out. Anyway I just wanted\nto make sure the performance was 'in the ballpark' and  competitive with the other\nsuggesters, I think for a lot of users thats all that matters, and whether its\n400 QPS or 200QPS, probably doesnt matter so much... so I didnt tweak any further. ",
            "author": "Robert Muir",
            "id": "comment-13193804"
        },
        {
            "date": "2012-01-26T13:38:55+0000",
            "content": "Awesome!  I haven't looked at patch yet... but the comparison is also apples/oranges right?\n\nBecause WFSTCompletionLookup does no quantizing (bucketing), ie, it returns the \"true\" topN suggestions, so it has to do more work to differentiate hits that FSTCompletionLookup considers equal.\n\nI guess we could pre-quantize the weights into the same buckets that FSTCompletionLookup will use, when adding to WFSTCompletionLookup... then the results are comparable.\n\nBut I guess we don't need to do this since the results are \"good enough\"... ",
            "author": "Michael McCandless",
            "id": "comment-13193832"
        },
        {
            "date": "2012-01-26T13:48:57+0000",
            "content": "No, no, Mike \u2013 I'm all for going with exact, fine scores. That way even if WFSTCompletionLookup is slower it's still a real-life use case and FSTCompletionLookup (even if faster) will have a  saying it's not a complete solution.\n\nI like what Robert did (still didn't look at the patch), but I was just wondering why the hell difference for long prefixes. This is not a frequent case in real-life, just curiosity. ",
            "author": "Dawid Weiss",
            "id": "comment-13193838"
        },
        {
            "date": "2012-01-26T13:57:39+0000",
            "content": "Sorry, I'm not proposing we commit pre-quantizing the scores... I'm\njust saying we'd learn more from the perf test that way.  Ie, is WFST\nslower because 1) it's doing precise scores, or 2) the topN algo is\nslowish. ",
            "author": "Michael McCandless",
            "id": "comment-13193845"
        },
        {
            "date": "2012-01-26T14:07:03+0000",
            "content": "I think the (existing) benchmark is fair: it just measures how fast each suggester returns the top-N.\nOf course FSTSuggester buckets/early terminates and thats just a tradeoff it makes (having some impact on scores, possibly even positive).\n\nThis is just like benchmarking different relevance ranking algorithms, which also compute the top-N differently...\n\nKeep in mind, I didnt optimize the implementation at all or profile anything. So there could be easy wins here.\nBut at this stage I think we just wanted to know its in the ballpark? ",
            "author": "Robert Muir",
            "id": "comment-13193854"
        },
        {
            "date": "2012-01-26T14:11:04+0000",
            "content": "Looked through the patch. Some comments:\n\n+        // nocommit: why does the benchmark test supply duplicates? what should we do in this case?\n\nignore duplicates. I think it is allowed for the iterator to allow duplicates; I'm not sure but this may even be used when bucketing input \u2013 the same entry with a different score (before bucketing) may end up identical after sorting.\n\n+    // nocommit: shouldn't we have an option to\n+    // match exactly even if its a crappy suggestion? we would just look\n+    // for arc.isFinal here etc...\n\nYes, this should definitely be an option because if it's an exact match then you'll probably want it on top of the suggestions list, no matter what.\n\nYou could also add a generator of the \"bad case\" that I attached inside TestMe.java \u2013 this creates the case when following greedily doesn't yield correct output (requires a pq).\n\nI also checked the benchmark and yes, it uses exactMatchFirst promotion. This clarifies the speed difference for longer prefixes \u2013 not enough results are collected in any of the buckets so no early termination occurs and all buckets must be traversed.\n\nI like WFSTCompletionLookup very much, clean and simple. ",
            "author": "Dawid Weiss",
            "id": "comment-13193855"
        },
        {
            "date": "2012-01-26T14:37:07+0000",
            "content": "Dawid thanks for the comments: we can remove that first nocommit and then add an option\nfor the second one...\n\nI think as a step to move this forward we have to fix the output encoding to \nnot be (Integer.MAX_VALUE-weight). \n\nSeems like the best first step is to generify findMinPairs to T and to allow an arbitrary Comparator\nso that we can muck around with the algebra? I looked at this and it seems possible... ",
            "author": "Robert Muir",
            "id": "comment-13193865"
        },
        {
            "date": "2012-01-26T14:42:26+0000",
            "content": "also I'm not sure I'm in love with \"findMinPairs\". Maybe we should call it \"shortestPaths\" ? ",
            "author": "Robert Muir",
            "id": "comment-13193867"
        },
        {
            "date": "2012-01-26T16:35:53+0000",
            "content": "\nI think the (existing) benchmark is fair: it just measures how fast each suggester returns the top-N.\n Of course FSTSuggester buckets/early terminates and thats just a tradeoff it makes (having some impact on scores, possibly even positive).\n\nOK, I agree with that: it is a meaningful black-box comparison of two suggester impls.\n\nalso I'm not sure I'm in love with \"findMinPairs\". Maybe we should call it \"shortestPaths\" ?\n\n+1 ",
            "author": "Michael McCandless",
            "id": "comment-13193950"
        },
        {
            "date": "2012-01-26T21:07:53+0000",
            "content": "updated patch nuking a couple nocommits: added the boolean exactMatchFirst (default=on like FSTSuggester), and removed the deduping nocommit.\n\nSo the main remaining things are:\n\n\tfix the encoding of the weights\n\tuse the offline sort\n\tfigure out what onlyMorePopular means for suggesters and what we should do about it\n\n ",
            "author": "Robert Muir",
            "id": "comment-13194178"
        },
        {
            "date": "2012-01-30T00:32:40+0000",
            "content": "I've been wanting to work on this.. havent found the time.\n\nThis just syncs the patch up to trunk's FST api changes. ",
            "author": "Robert Muir",
            "id": "comment-13195893"
        },
        {
            "date": "2012-02-14T16:01:47+0000",
            "content": "I played with a lot of variations on this patch:\n\n\tgenerified the shortest path method to take things like Comparators/Comparable\n\ttried different algebra/representations with that\n\n\n\nI think we should keep the code wired to Long for now. according to the benchmark\nany generification is like a 5-10% overall perf hit, and I don't see a need for\nanything but Long.\n\nI think as far as representation, we need to integrate the offline sort, find min/max \nfloat values and scale to <precision> space, e.g. if precision is 32 then \nInteger.MAX_VALUE - scaledWeight. \n\nI tried different representations and they just add more complexity (e.g. negative outputs),\nwithout saving much space at all. This patch uses Integer precision and is only 10% larger\nthan the previous impl.\n\nWe don't even need precision to be configurable really,\nwe could wire it to integers as a start. But maybe later someone could specify it, e.g.\nif they specified 8 then they basically get the same result as bucketed algorithm today... ",
            "author": "Robert Muir",
            "id": "comment-13207798"
        },
        {
            "date": "2012-02-19T05:49:53+0000",
            "content": "Rounded out this patch: fixed it to use the offline sorting, added a random test (basically a port of the FST shortest-path test, but uses the suggester instead), and added a solr factory and some docs.\n\nI think its ready to go. ",
            "author": "Robert Muir",
            "id": "comment-13211216"
        },
        {
            "date": "2012-02-19T15:35:20+0000",
            "content": "I'll commit this soon if there are no objections.\n\nI'll mark it experimental for now when committing. ",
            "author": "Robert Muir",
            "id": "comment-13211386"
        },
        {
            "date": "2012-02-19T16:41:46+0000",
            "content": "Committed to trunk: working on the backport now.\n\nI'm gonna measure any perf difference from the pollFirst/pollLast stuff... if there is a slowdown\nwe can deal with that on a separate issue (maybe there is some way to prevent a slowdown, at least\nif java 6 is actually whats being used)... but maybe it doesn't affect overall suggest speed anyway. ",
            "author": "Robert Muir",
            "id": "comment-13211405"
        },
        {
            "date": "2012-02-19T17:03:56+0000",
            "content": "I ran the benchmarks, no measurable difference, makes it easy. Will commit \nthe backport soon after ant test/javadocs with java5 are finished. ",
            "author": "Robert Muir",
            "id": "comment-13211410"
        },
        {
            "date": "2012-02-19T17:19:08+0000",
            "content": "Backported to 3.x too, I think we can iterate from here with other issues! ",
            "author": "Robert Muir",
            "id": "comment-13211421"
        }
    ]
}