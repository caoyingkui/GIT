{
    "id": "SOLR-6220",
    "title": "Replica placement strategy for solrcloud",
    "details": {
        "affect_versions": "None",
        "status": "Closed",
        "fix_versions": [
            "5.2",
            "6.0"
        ],
        "components": [
            "SolrCloud"
        ],
        "type": "Bug",
        "priority": "Major",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "Objective\nMost cloud based systems allow to specify rules on how the replicas/nodes of a cluster are allocated . Solr should have a flexible mechanism through which we should be able to control allocation of replicas or later change it to suit the needs of the system\n\nAll configurations are per collection basis. The rules are applied whenever a replica is created in any of the shards in a given collection during\n\n\n\tcollection creation\n\tshard splitting\n\tadd replica\n\tcreatesshard\n\n\n\nThere are two aspects to how replicas are placed: snitch and placement. \n\nsnitch \nHow to identify the tags of nodes. Snitches are configured through collection create command with the snitch param  . eg: snitch=EC2Snitch or snitch=class:EC2Snitch\n\n\nImplicitSnitch \nThis is shipped by default with Solr. user does not need to specify ImplicitSnitch in configuration. If the tags known to ImplicitSnitch are present in the rules , it is automatically used,\ntags provided by ImplicitSnitch\n\n\tcores :  No:of cores in the node\n\tdisk : Disk space available in the node\n\thost : host name of the node\n\tnode: node name\n\tD.* : These are values available from systrem propertes. D.key means a value that is passed to the node as -Dkey=keyValue during the node startup. It is possible to use rules like D.key:expectedVal,shard:*\n\n\n\nRules \n\nThis tells how many replicas for a given shard needs to be assigned to nodes with the given key value pairs. These parameters will be passed on to the collection CREATE api as a multivalued parameter  \"rule\" . The values will be saved in the state of the collection as follows\n\n{\n \u201cmycollection\u201d:{\n  \u201csnitch\u201d: {\n      class:\u201cImplicitSnitch\u201d\n    }\n  \u201crules\u201d:[{\"cores\":\"4-\"}, \n             {\"replica\":\"1\" ,\"shard\" :\"*\" ,\"node\":\"*\"},\n             {\"disk\":\">100\"}]\n}\n\n\n\nA rule is specified as a pseudo JSON syntax . which is a map of keys and values\n*Each collection can have any number of rules. As long as the rules do not conflict with each other it should be OK. Or else an error is thrown\n\n\tIn each rule , shard and replica can be omitted\n\t\n\t\tdefault value of  replica is * means ANY or you can specify a count and an operand such as < (less than) or > (greater than)\n\t\tand the value of shard can be a shard name or  * means EACH  or ** means ANY.  default value is ** (ANY)\n\t\n\t\n\tThere should be exactly one extra condition in a rule other than shard and replica.\n\tall keys other than shard and replica are called tags and the tags are nothing but values provided by the snitch for each node\n\tBy default certain tags such as node, host, port are provided by the system implicitly\n\n\n\nHow are nodes picked up? \nNodes are not picked up in random. The rules are used to first sort the nodes according to affinity. For example, if there is a rule that says disk:100+ , nodes with  more disk space are given higher preference.  And if the rule is disk:100- nodes with lesser disk space will be given priority. If everything else is equal , nodes with fewer cores are given higher priority\n\nFuzzy match\nFuzzy match can be applied when strict matches fail .The values can be prefixed ~ to specify fuzziness\n\nexample rule\n\n #Example requirement \"use only one replica of a shard in a host if possible, if no matches found , relax that rule\". \nrack:*,shard:*,replica:<2~\n\n#Another example, assign all replicas to nodes with disk space of 100GB or more,, or relax the rule if not possible. This will ensure that if a node does not exist with 100GB disk, nodes are picked up the order of size say a 85GB node would be picked up over 80GB disk node\ndisk:>100~\n\n\nExamples:\n\n#in each rack there can be max two replicas of A given shard\n rack:*,shard:*,replica:<3\n//in each rack there can be max two replicas of ANY replica\n rack:*,shard:**,replica:2\n rack:*,replica:<3\n\n #in each node there should be a max one replica of EACH shard\n node:*,shard:*,replica:1-\n #in each node there should be a max one replica of ANY shard\n node:*,shard:**,replica:1-\n node:*,replica:1-\n \n#In rack 738 and shard=shard1, there can be a max 0 replica\n rack:738,shard:shard1,replica:<1\n \n #All replicas of shard1 should go to rack 730\n shard:shard1,replica:*,rack:730\n shard:shard1,rack:730\n\n #all replicas must be created in a node with at least 20GB disk\n replica:*,shard:*,disk:>20\n replica:*,disk:>20\n disk:>20\n#All replicas should be created in nodes with less than 5 cores\n#In this ANY AND each for shard have same meaning\nreplica:*,shard:**,cores:<5\nreplica:*,cores:<5\ncores:<5\n#one replica of shard1 must go to node 192.168.1.2:8080_solr\nnode:\u201d192.168.1.2:8080_solr\u201d, shard:shard1, replica:1 \n#No replica of shard1 should go to rack 738\nrack:!738,shard:shard1,replica:*\nrack:!738,shard:shard1\n#No replica  of ANY shard should go to rack 738\nrack:!738,shard:**,replica:*\nrack:!738,shard:*\nrack:!738\n\n\n\n\n\nIn the collection create API all the placement rules are provided as a parameters called rule\nexample:\n\nsnitch=EC2Snitch&rule=shard:*,replica:1,dc:dc1&rule=shard:*,replica:<2,dc:dc3&rule=shard:shard1,replica:,rack:!738}",
    "attachments": {
        "SOLR-6220.patch": "https://issues.apache.org/jira/secure/attachment/12723634/SOLR-6220.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Steven Bower",
            "id": "comment-14255216",
            "date": "2014-12-21T17:14:12+0000",
            "content": "I like where you are going with this...\n\nSome thoughts:\n\nThis snitch information I think should be exposed at a more general level than just in replica placement.. One very useful area would be in query routing for datacenter/rack/server afinity..\n\nThere seem to be several types of information the \"snitch\" is providing; System (cpu, dc, rack, etc..), Node (# cores, etc..), Collection (# shards, routing, etc..), Shard (# docs, # replicas, Core (disk size, etc..).. Plus ideally you'd like to have managed properties really at all levels... I wonder if a more robust framework for the snitches would be better:\n\nI am thinking something more hierarchical, imagine a tree where the top level elements are provided by a collection of snitches that are dynamically provided when requested...\n\n{\n  \"system\" : {\n    \"dc\" : \"east\"\n    \"rack\" : 124\n  },\n  \"collection\" : {\n    \"name\" : \"foo\",\n    \"numShards\" : 5,\n  }\n  \"...\"\n}\n\n\n\nThis way you could layer in lots of different information without having to re-implement functionality in different snitches or have some complex snitch class hierarchy... you'd simply plug snitches into different parts of the infrastructure (node, collection, etc..) Obviously this would need to be fleshed out a bit more..\n\nThe idea of Snitches is somewhat in the spirit of Chef's Ohai (https://github.com/opscode/ohai) it may be beneficial to provide something similar... and/or we could lift/port some code for things it does already outside Solr\n\nIn terms of the rule-sets.. I'm curious with the rules you describe how you'd model:\n\n\n\tN shards evenly distributed between D datacenters (for this case assume N is evenly divisible by D)\n\tAll replicas should be in separate racks (unless there is no other choice)\n\tAll replicas should be on separate hosts (unless there is no other choice)\n\n "
        },
        {
            "author": "Noble Paul",
            "id": "comment-14255653",
            "date": "2014-12-22T11:18:59+0000",
            "content": "N shards evenly distributed between D datacenters (for this case assume N is evenly divisible by D)\n\nThis does not.\u00a0Is it realy helpful to have just some shards in a DC? The design distributes every shard \n\nAll replicas should be in separate racks (unless there is no other choice)\nAll replicas should be on separate hosts (unless there is no other choice)\nnot yet. Would be a nice syntax to add "
        },
        {
            "author": "Noble Paul",
            "id": "comment-14483171",
            "date": "2015-04-07T13:48:09+0000",
            "content": "First cut with some basic tests "
        },
        {
            "author": "Noble Paul",
            "id": "comment-14496464",
            "date": "2015-04-15T16:20:19+0000",
            "content": "All planned features included. Tests will come next "
        },
        {
            "author": "Noble Paul",
            "id": "comment-14502855",
            "date": "2015-04-20T13:48:32+0000",
            "content": "More tests .  "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-14502868",
            "date": "2015-04-20T13:56:44+0000",
            "content": "\n//in each node there should be a max one replica of EACH shard\n Unknown macro: {node} \n\nInstead of \"1-\" can we use regular <, <=, >, >= operators? For example \"replica:<=1\" to signal that a maximum of 1 replica is required and \"disk:>=20\" can signal that the chosen node must have more than 20GB of space "
        },
        {
            "author": "Noble Paul",
            "id": "comment-14502881",
            "date": "2015-04-20T14:05:13+0000",
            "content": "The rules are passed as request params . example : rule=shard:*,disk=20+ \nI considered using <= , >= and !=  . But , that means the user needs to escape = in the request. Which can badly affect the readability\n\n "
        },
        {
            "author": "Noble Paul",
            "id": "comment-14504891",
            "date": "2015-04-21T12:49:15+0000",
            "content": "\n\tAdded fuzzy match option ~\n\tnodes are presorted based on rules instead of randomly picking nodes\n\tImplicitSnitch can support per node system properties\n\n "
        },
        {
            "author": "Noble Paul",
            "id": "comment-14506587",
            "date": "2015-04-22T07:35:22+0000",
            "content": "Operators + and - replaced with < and >\nThis is now feature complete.\nI'll add some more tests and commit this "
        },
        {
            "author": "Noble Paul",
            "id": "comment-14507166",
            "date": "2015-04-22T14:32:39+0000",
            "content": "More tests  "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-14517014",
            "date": "2015-04-28T13:24:12+0000",
            "content": "The latest patch doesn't compile. It has errors in OverseerCollectionProcessor. Can you please post a patch which is in sync with trunk? "
        },
        {
            "author": "Noble Paul",
            "id": "comment-14517194",
            "date": "2015-04-28T15:23:56+0000",
            "content": "Updated patch to trunk "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14526684",
            "date": "2015-05-04T14:40:07+0000",
            "content": "Commit 1677607 from Noble Paul in branch 'dev/trunk'\n[ https://svn.apache.org/r1677607 ]\n\nSOLR-6220: Rule Based Replica Assignment during collection creation "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14526734",
            "date": "2015-05-04T15:10:10+0000",
            "content": "Commit 1677614 from Noble Paul in branch 'dev/trunk'\n[ https://svn.apache.org/r1677614 ]\n\nSOLR-6220: setting eol style "
        },
        {
            "author": "Tom\u00e1s Fern\u00e1ndez L\u00f6bbe",
            "id": "comment-14526770",
            "date": "2015-05-04T15:54:11+0000",
            "content": "Ideally, most warnings should be fixed  , but at least the one in SnitchContext:\n\n\n  public SimpleSolrResponse invoke(UpdateShardHandler shardHandler,  final String url, String path, SolrParams params)\n      throws IOException, SolrServerException {\n    GenericSolrRequest request = new GenericSolrRequest(SolrRequest.METHOD.GET, path, params);\n    NamedList<Object> rsp = new HttpSolrClient(url, shardHandler.getHttpClient(), new BinaryResponseParser()).request(request);\n    request.response.nl = rsp;\n    return request.response;\n  }\n\n\nResource leak: '<unassigned Closeable value>' is never closed "
        },
        {
            "author": "Anshum Gupta",
            "id": "comment-14526772",
            "date": "2015-05-04T15:54:27+0000",
            "content": "This seems to have broken ant precommit.\n\n\n[forbidden-apis] Forbidden method invocation: java.lang.String#getBytes() [Uses default charset]\n[forbidden-apis]   in org.apache.solr.cloud.rule.RuleEngineTest (RuleEngineTest.java:63)\n[forbidden-apis] Forbidden method invocation: java.lang.String#getBytes() [Uses default charset]\n[forbidden-apis]   in org.apache.solr.cloud.rule.RuleEngineTest (RuleEngineTest.java:108)\n[forbidden-apis] Forbidden method invocation: java.lang.String#getBytes() [Uses default charset]\n[forbidden-apis]   in org.apache.solr.cloud.rule.RuleEngineTest (RuleEngineTest.java:185)\n\n "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14526783",
            "date": "2015-05-04T16:10:24+0000",
            "content": "Commit 1677622 from Anshum Gupta in branch 'dev/trunk'\n[ https://svn.apache.org/r1677622 ]\n\nSOLR-6220: Fixes forbidden method invocation String#getBytes() in RuleEngineTest "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14526826",
            "date": "2015-05-04T16:46:45+0000",
            "content": "Commit 1677635 from Noble Paul in branch 'dev/trunk'\n[ https://svn.apache.org/r1677635 ]\n\nSOLR-6220: use closeable in try block "
        },
        {
            "author": "Jessica Cheng Mallet",
            "id": "comment-14526889",
            "date": "2015-05-04T17:25:41+0000",
            "content": "It'll also be nice to have a new collection API to modify the rule for a collection so that we can add rules for an existing collection or modify a bad rule set. "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14526928",
            "date": "2015-05-04T17:52:57+0000",
            "content": "Commit 1677642 from Anshum Gupta in branch 'dev/trunk'\n[ https://svn.apache.org/r1677642 ]\n\nSOLR-6220: Fix javadocs for precommit to pass "
        },
        {
            "author": "Anshum Gupta",
            "id": "comment-14526930",
            "date": "2015-05-04T17:53:45+0000",
            "content": "That would be a good thing to have. Can you create a new JIRA for that if one doesn't already exist? "
        },
        {
            "author": "Noble Paul",
            "id": "comment-14526949",
            "date": "2015-05-04T18:00:12+0000",
            "content": "It's planned and I would like to piggy back on the modify collection API SOLR-5132 "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14526994",
            "date": "2015-05-04T18:24:55+0000",
            "content": "Commit 1677648 from Noble Paul in branch 'dev/branches/branch_5x'\n[ https://svn.apache.org/r1677648 ]\n\nSOLR-6220: Rule Based Replica Assignment during collection creation "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14527905",
            "date": "2015-05-05T04:55:32+0000",
            "content": "Commit 1677741 from shalin@apache.org in branch 'dev/branches/branch_5x'\n[ https://svn.apache.org/r1677741 ]\n\nSOLR-6220: Fix compile error on Java7 "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14532782",
            "date": "2015-05-07T14:41:37+0000",
            "content": "Commit 1678222 from Noble Paul in branch 'dev/trunk'\n[ https://svn.apache.org/r1678222 ]\n\nSOLR-6220: renamed tag names disk to freedisk, and the system property prefix to sysprop. "
        },
        {
            "author": "Jessica Cheng Mallet",
            "id": "comment-14540687",
            "date": "2015-05-12T20:48:45+0000",
            "content": "This doesn't seem to handle addReplica. I think it'd be nice to merge in the logic of the Assign class and get rid of it completely so there's just one place to handle any kind of replica assignment. "
        },
        {
            "author": "Noble Paul",
            "id": "comment-14541638",
            "date": "2015-05-13T09:16:34+0000",
            "content": "Jessica Cheng Mallet That's the plan \n\nit should be added for addReplica , createShard and splitShard  "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-14581681",
            "date": "2015-06-11T08:38:30+0000",
            "content": "This was released in 5.2 "
        },
        {
            "author": "Anshum Gupta",
            "id": "comment-14586920",
            "date": "2015-06-15T21:44:34+0000",
            "content": "Bulk close for 5.2.0. "
        }
    ]
}