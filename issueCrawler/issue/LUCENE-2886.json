{
    "id": "LUCENE-2886",
    "title": "Adaptive Frame Of Reference",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [
            "core/codecs"
        ],
        "type": "New Feature",
        "fix_versions": [
            "4.9",
            "6.0"
        ],
        "affect_versions": "None",
        "resolution": "Unresolved",
        "status": "Open"
    },
    "description": "We could test the implementation of the Adaptive Frame Of Reference [1] on the lucene-4.0 branch.\nI am providing the source code of its implementation. Some work needs to be done, as this implementation is working on the old lucene-1458 branch. \nI will attach a tarball containing a running version (with tests) of the AFOR implementation, as well as the implementations of PFOR and of Simple64 (simple family codec working on 64bits word) that has been used in the experiments in [1].\n\n[1] http://www.deri.ie/fileadmin/documents/deri-tr-afor.pdf",
    "attachments": {
        "LUCENE-2886_simple64_varint.patch": "https://issues.apache.org/jira/secure/attachment/12470155/LUCENE-2886_simple64_varint.patch",
        "LUCENE-2886_simple64.patch": "https://issues.apache.org/jira/secure/attachment/12470047/LUCENE-2886_simple64.patch",
        "LUCENE-2886.patch": "https://issues.apache.org/jira/secure/attachment/12470267/LUCENE-2886.patch",
        "lucene-afor.tar.gz": "https://issues.apache.org/jira/secure/attachment/12469182/lucene-afor.tar.gz"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2011-01-24T18:34:45+0000",
            "content": "tarball containing a maven project with source code and unit tests for:\n\n\tAFOR1\n\tAFOR2\n\tFOR\n\tPFOR Non Compulsive\n\tSimple64\n\ta basic tool for debugging IntBlock codecs.\n\n\n\nIt includes also the lucene-1458 snapshot dependencies that are necessary to compile the code and run the tests. ",
            "author": "Renaud Delbru",
            "id": "comment-12985880"
        },
        {
            "date": "2011-02-02T14:20:01+0000",
            "content": "I pulled out the simple64 implementation here and adapted it to the bulkpostings branch.\n\nThanks for uploading this code Renaud, its great and the code is easy to work with. I hope to get some more of the codecs you wrote into the branch for testing.\n\nI changed a few things that helped in benchmarking:\n\n\tthe decoder uses relative gets instead of absolute\n\twe write #longs in the block header instead of #bytes (as its always long aligned, but smaller numbers)\n\n\n\nBut mainly, for this one I think we should change it to be a VariableIntBlock codec... right now it packs 128 integers into as few longs as possible, but this is wasteful for two reasons: it has to write a per-block byte header, and also wastes bits (e.g. in the case of a block of 128 1's).\n\nWith variableintblock, we could do this differently, e.g. read a fixed number of longs per-block (say 4 longs), and our block would then be variable between 4 and 240 integers depending upon data. ",
            "author": "Robert Muir",
            "id": "comment-12989644"
        },
        {
            "date": "2011-02-03T15:45:52+0000",
            "content": "New patch, including Robert's patch, and also adding Simple64 as a VarInt codec.  We badly need more testing of the VarInt cases, so it's great Simple64 came along (thanks Renaud!).\n\nAll tests pass w/ Simple64VarInt codec. ",
            "author": "Michael McCandless",
            "id": "comment-12990137"
        },
        {
            "date": "2011-02-03T15:52:52+0000",
            "content": "OK I committed the two new Simple64 codecs (to bulk branch). ",
            "author": "Michael McCandless",
            "id": "comment-12990143"
        },
        {
            "date": "2011-02-04T03:22:07+0000",
            "content": "We are still not using 2 of the simple64 selectors, but in the simple64 paper it discusses\nusing these wasted bits to represent 120 and 240 \"all ones\"... I think we should do this? ",
            "author": "Robert Muir",
            "id": "comment-12990439"
        },
        {
            "date": "2011-02-04T10:40:58+0000",
            "content": "Hi Michael, Robert,\ngreat to hear that the code is useful, looking forward to see some benchmark.\nI think the VarIntBlock approach is a good idea. Concerning the two unused \"frame\" codes, it will not cost too much to add them. This might be useful for the frequency inverted lists. However, I am not sure they will be used that much. In our experiments, we had a version of AFOR allowing frames of size 8, 16 and 32 integers with allOnes and allZeros. The gain was very minimal, in the order to 0.x% index size reduction, because these cases were occurring very rarely. But, this is still better than nothing. However, in the case of simple64, we are not talking about small frame (up to 32 integers), but frame of 120 to 240 integers. Therefore, I expect to see a drop of probability to encounter 120 or 240 consecutive ones. Maybe we can use them for more clever configurations such as\n\n\tinter-leaved sequences of 1 bit and 2 bits integers\n\tinter-leaved sequences of 2 bits and 3 bits integers\nor something like this.\nThe best will be to do some tests to see which new configurations will make sense, like how many times a allOnes config is selected, or other configs, and choose which one to add. But this can be tedious task with only a limited benefit.\n\n ",
            "author": "Renaud Delbru",
            "id": "comment-12990509"
        },
        {
            "date": "2011-02-04T11:32:18+0000",
            "content": "Hi Michael, Robert,\ngreat to hear that the code is useful, looking forward to see some benchmark.\nI think the VarIntBlock approach is a good idea. Concerning the two unused \"frame\" codes, it will not cost too much to add them. This might be useful for the frequency inverted lists. However, I am not sure they will be used that much. \n\nIn the case of 240 1's, i was surprised to see this selector was used over 2% of the time\nfor the gov collection's doc file?\n\nBut still, for the all 1's case I'm not actually thinking about unstructured text so much... \nin this case I am thinking about metadata fields and more structured data? ",
            "author": "Robert Muir",
            "id": "comment-12990534"
        },
        {
            "date": "2011-02-04T11:46:09+0000",
            "content": "\nIn the case of 240 1's, i was surprised to see this selector was used over 2% of the time\nfor the gov collection's doc file?\nour results were performed on the wikipedia dataset and blogs dataset. I don;t know what was our selection rate, I was just referring to the gain in overall compression rate.\n\n\nBut still, for the all 1's case I'm not actually thinking about unstructured text so much...\nin this case I am thinking about metadata fields and more structured data?\n\nYes, this makes sense. In the context of SIREn (kind of simple xml node based inverted index) which is meant for indexing semi-structured data, the difference was more observable (mainly on the frequency and position files, as well as other structure node files).\nThis might be also useful on the document id file for very common terms (maybe for certain type of facets, with a very few number of values covering a large portion of the document collection). ",
            "author": "Renaud Delbru",
            "id": "comment-12990535"
        },
        {
            "date": "2011-02-04T12:01:04+0000",
            "content": "Just an additional comment on semi-structured data indexing. AFOR-2 and AFOR-3 (AFOR-3 refers to AFOR-2 with special code for allOnes frames), was able to beat Rice on two datasets, and S-64 on one (but it was very close to Rice on the others):\n\nDBpedia dataset: (structured version of wikipedia)\n\n\n\n\nMethod\nEnt\nFrq\nAtt\nVal\nPos\nTotal\n\n\nAFOR-1\n0.246\n0.043\n0.141\n0.065\n0.180\n0.816\n\n\nAFOR-2\n0.229\n0.039\n0.132\n0.059\n0.167\n0.758\n\n\nAFOR-3\n0.229\n0.031\n0.131\n0.054\n0.159\n0.736\n\n\nFOR\n0.315\n0.061\n0.170\n0.117\n0.216\n1.049\n\n\nPFOR\n0.317\n0.044\n0.155\n0.070\n0.205\n0.946\n\n\nRice\n0.240\n0.029\n0.115\n0.057\n0.152\n0.708\n\n\nS-64\n0.249\n0.041\n0.133\n0.062\n0.171\n0.791\n\n\nVByte\n0.264\n0.162\n0.222\n0.222\n0.245\n1.335\n\n\n\n\n\nGeonames Dataset: \n\n\n\n\nMethod\nEnt\nFrq\nAtt\nVal\nPos\nTotal\n\n\nAFOR-1\n0.129\n0.023\n0.058\n0.025\n0.025\n0.318\n\n\nAFOR-2\n0.123\n0.023\n0.057\n0.024\n0.024\n0.307\n\n\nAFOR-3\n0.114\n0.006\n0.056\n0.016\n0.008\n0.256\n\n\nFOR\n0.150\n0.021\n0.065\n0.025\n0.023\n0.349\n\n\nPFOR\n0.154\n0.019\n0.057\n0.022\n0.023\n0.332\n\n\nRice\n0.133\n0.019\n0.063\n0.029\n0.021\n0.327\n\n\nS-64\n0.147\n0.021\n0.058\n0.023\n0.023\n0.329\n\n\nVByte\n0.216\n0.142\n0.143\n0.143\n0.143\n0.929\n\n\n\n\n\nSindice Dataset: Very heterogeneous dataset containing hundred of thousands of web dataset\n\n\n\n\nMethod\nEnt\nFrq\nAtt\nVal\nPos\nTotal\n\n\nAFOR-1\n2.578\n0.395\n0.942\n0.665\n1.014\n6.537\n\n\nAFOR-2\n2.361\n0.380\n0.908\n0.619\n0.906\n6.082\n\n\nAFOR-3\n2.297\n0.176\n0.876\n0.530\n0.722\n5.475\n\n\nFOR\n3.506\n0.506\n1.121\n0.916\n1.440\n8.611\n\n\nPFOR\n3.221\n0.374\n1.153\n0.795\n1.227\n7.924\n\n\nRice\n2.721\n0.314\n0.958\n0.714\n0.941\n6.605\n\n\nS-64\n2.581\n0.370\n0.917\n0.621\n0.908\n6.313\n\n\nVByte\n3.287\n2.106\n2.411\n2.430\n2.488\n15.132\n\n\n\n\n\nHere, Ent refers to entity id (similar to doc id), Att and Val are structural node ids. ",
            "author": "Renaud Delbru",
            "id": "comment-12990538"
        },
        {
            "date": "2011-02-04T12:26:01+0000",
            "content": "Thanks for those numbers Renaud... yes the cases you see in e.g. Geonames\nwas one example of what I was thinking: in general you might say someone\nshould be using \"omitTFAP\" to omit freqs and positions for these fields,\nbut they might not be able to do this, if they want to support e.g. phrase\nqueries like \"washington hill\". So if we can pack long streams of 1s with \nfreqs and positions I think this is probably useful for a lot of people.\n\nAdditionally for the .doc, i see its smaller in the AFOR-3 case too. Is\nyour \"Ent\" basically a measure of doc deltas? I'm confused exactly\nwhat it is  Because I would think if you take e.g. Geonames, the place \nnames in the dataset are not in random order but actually \"batched\" by\ncountry for example, so you would have long streams of docdelta=1 for\ncountry=Germany's postings. \n\nI'm not saying we could rely upon this, but i do think in general lots\nof people's docs aren't in completely random order, and its probably\ncommon to see long streams of docdelta=1 in structured data for this reason?\n\n ",
            "author": "Robert Muir",
            "id": "comment-12990543"
        },
        {
            "date": "2011-02-04T12:52:41+0000",
            "content": "\nSo if we can pack long streams of 1s with\nfreqs and positions I think this is probably useful for a lot of people.\nYes, if the overhead is minimal, it might not be an issue in certain cases.\n\n\nAdditionally for the .doc, i see its smaller in the AFOR-3 case too. Is\nyour \"Ent\" basically a measure of doc deltas? I'm confused exactly\nwhat it is \n\nYes, Ent is jsut a delta representation of the id of the entity (which can be considered as the document id). It is just that I have changed the name of the concept, as SIREn is manipulating principally entity and not document. In my case, an entity is just a set of attribute-value pairs, similarly to a document in Lucene.\n\n\nBecause I would think if you take e.g. Geonames, the place\nnames in the dataset are not in random order but actually \"batched\" by\ncountry for example, so you would have long streams of docdelta=1 for\ncountry=Germany's postings. \nI checked, and Geonames dataset was alphabetically sorted by url names:\nhttp://sws.geonames.org/1/\nhttp://sws.geonames.org/10/\n...\nas well as dbpedia and sindice.\n\nSo, yes, this might have (good) consequences on the docdelta list for certain datasets such as geonames. And especially when indexing semi-structured data, as the schema of the data in one dataset is generally identical across entities/documents. therefore it is likely to see long runs of 1 for certain terms or schema terms. ",
            "author": "Renaud Delbru",
            "id": "comment-12990548"
        },
        {
            "date": "2011-02-04T13:36:48+0000",
            "content": "I test perf of BulkVInt vs Simple64VarInt (Linux, 10M wikipedia index, NIOFSDir, multi-seg, java -server -Xbatch -Xmx2g -Xms2g):\n\n\n\n\nQuery\nQPS bulkvint\nQPS simple64varint\nPct diff\n\n\n+united +states\n19.46\n16.47\n-15.4%\n\n\n\"united states\"\n11.92\n10.09\n-15.3%\n\n\nunit~0.5\n17.35\n16.96\n-2.2%\n\n\n\"united states\"~3\n5.70\n5.72\n0.3%\n\n\nunited~0.6\n8.24\n8.31\n0.8%\n\n\ndoctitle:.[Uu]nited.\n5.36\n5.48\n2.1%\n\n\nunited~0.75\n12.45\n12.75\n2.4%\n\n\nunit~0.7\n27.37\n28.08\n2.6%\n\n\nspanFirst(unit, 5)\n156.48\n162.78\n4.0%\n\n\nunited states\n15.35\n16.07\n4.7%\n\n\nspanNear([unit, state], 10, true)\n42.84\n46.11\n7.6%\n\n\nstates\n48.13\n52.03\n8.1%\n\n\nunit*\n32.80\n37.07\n13.0%\n\n\ndoctimesecnum:[10000 TO 60000]\n12.38\n14.16\n14.4%\n\n\nuni*\n18.66\n21.53\n15.3%\n\n\nu*d\n9.66\n11.17\n15.7%\n\n\nun*d\n19.00\n22.04\n16.0%\n\n\n+nebraska +states\n101.66\n141.83\n39.5%\n\n\n\n ",
            "author": "Michael McCandless",
            "id": "comment-12990555"
        },
        {
            "date": "2011-02-04T13:48:54+0000",
            "content": "Same as last perf test, except MMapDir instead:\n\n\n\n\nQuery\nQPS bulkvint\nQPS simple64varint\nPct diff\n\n\n\"united states\"\n12.81\n9.95\n-22.3%\n\n\n\"united states\"~3\n6.04\n5.35\n-11.4%\n\n\n+united +states\n19.18\n17.25\n-10.1%\n\n\nunited~0.6\n10.35\n10.25\n-0.9%\n\n\nunited states\n16.33\n16.29\n-0.2%\n\n\ndoctimesecnum:[10000 TO 60000]\n14.18\n14.24\n0.4%\n\n\nunit*\n36.69\n37.20\n1.4%\n\n\nunited~0.75\n14.71\n14.92\n1.4%\n\n\nunit~0.5\n22.15\n22.55\n1.8%\n\n\nuni*\n21.27\n21.73\n2.2%\n\n\nspanFirst(unit, 5)\n166.18\n171.96\n3.5%\n\n\ndoctitle:.[Uu]nited.\n6.24\n6.46\n3.6%\n\n\nunit~0.7\n34.18\n35.49\n3.8%\n\n\nspanNear([unit, state], 10, true)\n47.16\n49.53\n5.0%\n\n\nstates\n50.71\n53.52\n5.5%\n\n\nun*d\n21.51\n22.96\n6.7%\n\n\nu*d\n11.18\n12.22\n9.3%\n\n\n+nebraska +states\n127.16\n161.43\n26.9%\n\n\n\n ",
            "author": "Michael McCandless",
            "id": "comment-12990560"
        },
        {
            "date": "2011-02-04T14:42:57+0000",
            "content": "Hi Michael, \nthe first results are not that impressive. \n\n\tCould you tell me what is BulkVInt ? Is it the simple VInt codec implemented on top of the Bulk branch ?\n\tWhat the difference between '+united +states' and '+nebraska +states' ? Is nebraska a low frequency term ?\n\n ",
            "author": "Renaud Delbru",
            "id": "comment-12990568"
        },
        {
            "date": "2011-02-04T14:54:15+0000",
            "content": "Hi Renaud:\n\nThe BulkVInt codec is VInt implemented as a FixedIntBlock codec.\nSo it reads a single numBytes Vint header, then a byte[], and decodes BLOCKSIZE vints out of it.\nThe reason for this, is it has much different performance than \"StandardCodec\",\ndue to the fact StandardCodec has to readByte() readByte() readByte() ...\n\nYou can see the code here: http://svn.apache.org/repos/asf/lucene/dev/branches/bulkpostings/lucene/src/java/org/apache/lucene/index/codecs/bulkvint/BulkVIntCodec.java\n\nOne reason for this, is to differentiate performance improvements of actual compression\nalgorithms from the way that they do their underlying I/O... previously various codecs\nlooked much faster than Vint but a lot of the reason for this is due to the way Vint\nwas implemented...\n\nAnd yes, you are correct nebraska is a lower freq term. the +united +states is a more \n\"normal\" phrase query, but +nebraska +states is a phrase query intended to do a lot \nof advance()'ing...  ",
            "author": "Robert Muir",
            "id": "comment-12990570"
        },
        {
            "date": "2011-02-04T15:04:31+0000",
            "content": "Here are my performance results, same setup (-server, etc)/index etc as Mike except\nI'm using windows 64-bit (1.6.0_23/Vista), and I do not have an SSD, just a normal hard disk.\nUsing SimpleFS:\n\n\n\nQuery\nQPS bulkVint\nQPS simple64Varint\nPct diff\n\n\n+united +states\n10.95\n10.32\n-5.8%\n\n\n\"united states\"~3\n3.78\n3.67\n-2.7%\n\n\n\"united states\"\n6.81\n6.71\n-1.5%\n\n\ndoctimesecnum:[10000 TO 60000]\n8.76\n8.81\n0.5%\n\n\nspanNear([unit, state], 10, true)\n22.42\n22.92\n2.3%\n\n\nuni*\n13.75\n14.22\n3.4%\n\n\nunit*\n24.89\n25.86\n3.9%\n\n\nunited~0.75\n7.06\n7.36\n4.4%\n\n\nunit~0.7\n14.11\n14.73\n4.4%\n\n\nunited~0.6\n4.34\n4.53\n4.4%\n\n\nunit~0.5\n8.16\n8.55\n4.7%\n\n\nstates\n29.99\n31.85\n6.2%\n\n\nspanFirst(unit, 5)\n88.27\n93.78\n6.2%\n\n\nunited states\n9.97\n10.60\n6.4%\n\n\ndoctitle:.[Uu]nited.\n2.34\n2.49\n6.6%\n\n\nu*d\n5.54\n6.05\n9.3%\n\n\nun*d\n12.36\n13.59\n9.9%\n\n\n+nebraska +states\n47.58\n62.53\n31.4%\n\n\n\n\n\nUsing MMap:\n\n\n\nQuery\nQPS bulkVint\nQPS simple64Varint\nPct diff\n\n\n+united +states\n13.88\n11.95\n-13.9%\n\n\nspanFirst(unit, 5)\n123.50\n106.84\n-13.5%\n\n\n\"united states\"~3\n4.64\n4.17\n-10.1%\n\n\n\"united states\"\n8.90\n8.19\n-8.0%\n\n\ndoctimesecnum:[10000 TO 60000]\n10.72\n9.98\n-7.0%\n\n\nspanNear([unit, state], 10, true)\n33.70\n31.63\n-6.1%\n\n\nuni*\n17.26\n16.30\n-5.5%\n\n\nstates\n37.14\n35.40\n-4.7%\n\n\nunit*\n29.96\n28.57\n-4.7%\n\n\nunited states\n11.52\n11.22\n-2.6%\n\n\nunited~0.75\n10.87\n10.75\n-1.1%\n\n\nunited~0.6\n7.69\n7.68\n-0.1%\n\n\ndoctitle:.[Uu]nited.\n3.83\n3.91\n2.2%\n\n\nun*d\n16.83\n17.26\n2.6%\n\n\nunit~0.5\n16.52\n17.05\n3.2%\n\n\nu*d\n8.51\n9.08\n6.7%\n\n\nunit~0.7\n26.83\n28.93\n7.8%\n\n\n+nebraska +states\n83.69\n113.19\n35.2%\n\n\n\n\n ",
            "author": "Robert Muir",
            "id": "comment-12990573"
        },
        {
            "date": "2011-02-04T15:08:23+0000",
            "content": "based on these results, I think a good experiment would be for\nus to \"group\" Simple64, so that we arent reading blocks of just a single long value.\n\nWith NIOFS/SimpleFS, the reads are buffered so i think some of the overhead\nis taken care of, but it doesn't tend to work so well with MMap.\n\nSo, if we 'group' the long values so we are e.g. reading say N long values\nat once in a single internal 'block', I think we might get more efficiency\nvia the I/O system, and also less overhead from the bulkpostings apis.\n\nI would hope this would speed up the other queries, and likely slow down\nthe +nebraska +states type thing, but I think thats ok. ",
            "author": "Robert Muir",
            "id": "comment-12990574"
        },
        {
            "date": "2011-02-04T16:42:03+0000",
            "content": "\nThe BulkVInt codec is VInt implemented as a FixedIntBlock codec.\n\nYes, I saw the code, it is a similar implementation of the VInt we used in our experiments.\n\n\npreviously various codecs\nlooked much faster than Vint but a lot of the reason for this is due to the way Vint\nwas implemented...\n\nThis is odd, because we observed the contrary (on the lucene-1458 branch). The standard codec was by an order of magnitude faster than any other codec. We discovered that this was due to the IntBlock interface implementation that:\n\n\twas copying the buffer bytearray two times (one time from the disk to the buffer, then another time from the buffer to the IntBlock codec).\n\thad to perform more work wrt to check each of the buffer (IntBlock buffer, IndexInput buffer).\nBut this might have been improved since then. Michael told me he worked on a new version of the IntBlock interface which was more performant.\n\n\n\n\nSo, if we 'group' the long values so we are e.g. reading say N long values\nat once in a single internal 'block', I think we might get more efficiency\nvia the I/O system, and also less overhead from the bulkpostings apis.\n\nIf I understand, this is similar to increasing the boundaries of the variable block size. Indeed, it incurs some non-negligible overhead to perform a block read for each simple64 long word (simple64 frame), and this might be better to read more than one per block read. ",
            "author": "Renaud Delbru",
            "id": "comment-12990611"
        },
        {
            "date": "2011-02-04T17:22:46+0000",
            "content": "On the facility for allOnes in AFOR-3: one of the reasons why this appears to be of rather little use is that current analyzers do not index stop words. They do this for two reasons, index size and query time, both based on VByte. With an allOnes facility the first reason disappears almost completely, and query times can be also be guarded in other ways, for example by checking for document frequency and then trying to fall back on digrams.\nSo the message is: please keep this in. ",
            "author": "Paul Elschot",
            "id": "comment-12990634"
        },
        {
            "date": "2011-02-04T18:23:36+0000",
            "content": "Attached patch, adding block multiplier to Simple64VarInt.\n\nI haven't tested perf impact yet... ",
            "author": "Michael McCandless",
            "id": "comment-12990665"
        },
        {
            "date": "2011-02-04T18:45:24+0000",
            "content": "New patch, cuts over to bulk-reading the byte[] and then pulling a LongBuffer from that. ",
            "author": "Michael McCandless",
            "id": "comment-12990674"
        },
        {
            "date": "2011-02-10T12:19:13+0000",
            "content": "I spent some more time on Simple64, took Mike's previous patch and added some minor improvements:\n\n\n\tSwitched the decoding logic to the \"Simple-8-4b\" referred to in the paper. This is the same encoding, but we process with ints instead of longs.\n\tBecause our buffers are so tiny (for example 32 bytes), the overhead of NIO hurts rather than helps, so I switched to native arrays.\n\n\n\nThe performance is looking much more reasonable. Here's my tests on windows, maybe i can convince Mike to sanity-check it on linux.\n\n64-bit SimpleFS\n\n\n\nQuery\nQPS BulkVInt\nQPS Simple64VarInt4\nPct diff\n\n\n\"united states\"~3\n3.79\n3.67\n-3.3%\n\n\ndoctitle:.[Uu]nited.\n2.45\n2.46\n0.3%\n\n\nspanNear([unit, state], 10, true)\n22.13\n22.64\n2.3%\n\n\nuni*\n14.04\n14.43\n2.7%\n\n\nunited~0.75\n6.83\n7.04\n3.2%\n\n\nunit*\n25.39\n26.21\n3.2%\n\n\ndoctimesecnum:[10000 TO 60000]\n8.83\n9.16\n3.6%\n\n\nunited~0.6\n4.29\n4.47\n4.2%\n\n\nunited states\n9.35\n9.74\n4.2%\n\n\nun*d\n12.88\n13.50\n4.8%\n\n\n\"united states\"\n6.86\n7.21\n5.1%\n\n\nunit~0.7\n14.11\n14.85\n5.3%\n\n\nunit~0.5\n8.17\n8.60\n5.3%\n\n\nu*d\n5.70\n6.05\n6.1%\n\n\nstates\n30.02\n31.90\n6.3%\n\n\nspanFirst(unit, 5)\n86.56\n94.15\n8.8%\n\n\n+united +states\n11.10\n12.55\n13.1%\n\n\n+nebraska +states\n46.72\n57.90\n23.9%\n\n\n\n\n\n32-bit SimpleFS\n\n\n\nQuery\nQPS BulkVInt\nQPS Simple64VarInt4\nPct diff\n\n\nspanFirst(unit, 5)\n95.67\n91.02\n-4.9%\n\n\n\"united states\"\n5.47\n5.25\n-4.1%\n\n\n\"united states\"~3\n3.37\n3.32\n-1.6%\n\n\nunit*\n20.45\n20.33\n-0.6%\n\n\nuni*\n11.10\n11.06\n-0.3%\n\n\ndoctimesecnum:[10000 TO 60000]\n7.15\n7.16\n0.0%\n\n\ndoctitle:.[Uu]nited.\n2.26\n2.27\n0.4%\n\n\nunit~0.5\n7.73\n7.77\n0.5%\n\n\nun*d\n10.80\n10.87\n0.6%\n\n\nunited~0.75\n6.77\n6.97\n2.8%\n\n\nunit~0.7\n12.97\n13.41\n3.4%\n\n\nunited~0.6\n4.10\n4.26\n3.7%\n\n\nu*d\n4.91\n5.10\n4.0%\n\n\nspanNear([unit, state], 10, true)\n20.50\n21.72\n5.9%\n\n\nstates\n30.00\n33.15\n10.5%\n\n\n+united +states\n9.71\n10.78\n11.1%\n\n\nunited states\n9.65\n10.96\n13.6%\n\n\n+nebraska +states\n43.93\n54.38\n23.8%\n\n\n\n\n\n64-bit MMap\n\n\n\nQuery\nQPS BulkVInt\nQPS Simple64VarInt4\nPct diff\n\n\n\"united states\"\n8.99\n8.41\n-6.4%\n\n\nstates\n38.21\n36.16\n-5.4%\n\n\nspanFirst(unit, 5)\n118.11\n112.19\n-5.0%\n\n\ndoctimesecnum:[10000 TO 60000]\n10.78\n10.35\n-4.0%\n\n\nspanNear([unit, state], 10, true)\n33.78\n32.51\n-3.7%\n\n\n\"united states\"~3\n4.68\n4.54\n-3.0%\n\n\nunit*\n30.00\n29.26\n-2.4%\n\n\nuni*\n17.48\n17.06\n-2.4%\n\n\nunited states\n11.60\n11.35\n-2.1%\n\n\n+united +states\n13.95\n14.08\n1.0%\n\n\nunited~0.75\n10.76\n10.87\n1.1%\n\n\nunited~0.6\n7.75\n7.88\n1.7%\n\n\nun*d\n17.16\n17.66\n2.9%\n\n\ndoctitle:.[Uu]nited.\n3.85\n3.98\n3.3%\n\n\nunit~0.7\n27.00\n28.08\n4.0%\n\n\nunit~0.5\n16.64\n17.46\n4.9%\n\n\nu*d\n8.68\n9.31\n7.2%\n\n\n+nebraska +states\n83.30\n96.53\n15.9%\n\n\n\n\n ",
            "author": "Robert Muir",
            "id": "comment-12993021"
        },
        {
            "date": "2011-02-10T13:32:52+0000",
            "content": "Linux results, NIOFSDir:\n\n\n\n\n\nQuery\nQPS bulkvint\nQPS simple64x4\nPct diff\n\n\n\"united states\"\n11.95\n10.50\n-12.1%\n\n\n+united +states\n19.45\n18.94\n-2.6%\n\n\nunit~0.5\n18.20\n17.85\n-1.9%\n\n\ndoctitle:.[Uu]nited.\n5.38\n5.40\n0.4%\n\n\nspanNear([unit, state], 10, true)\n43.59\n44.31\n1.7%\n\n\nunited~0.6\n8.48\n8.72\n2.8%\n\n\n\"united states\"~3\n5.75\n5.96\n3.6%\n\n\nunited~0.75\n12.66\n13.14\n3.8%\n\n\nunit~0.7\n27.58\n28.84\n4.6%\n\n\nspanFirst(unit, 5)\n157.05\n165.43\n5.3%\n\n\nunited states\n15.41\n16.26\n5.6%\n\n\nstates\n48.10\n51.95\n8.0%\n\n\nunit*\n32.72\n36.24\n10.8%\n\n\nuni*\n18.66\n20.97\n12.3%\n\n\nu*d\n9.63\n10.86\n12.8%\n\n\n+nebraska +states\n103.95\n117.66\n13.2%\n\n\nun*d\n18.91\n21.45\n13.4%\n\n\ndoctimesecnum:[10000 TO 60000]\n12.33\n13.99\n13.5%\n\n\n\n\n\n\nAnd MMapDir:\n\n\n\n\nQuery\nQPS bulkvint\nQPS simple64x4\nPct diff\n\n\n\"united states\"\n12.86\n11.01\n-14.4%\n\n\n+nebraska +states\n129.23\n126.21\n-2.3%\n\n\n\"united states\"~3\n6.05\n6.06\n0.1%\n\n\nunited~0.6\n10.55\n10.72\n1.6%\n\n\nunit~0.7\n38.24\n39.00\n2.0%\n\n\n+united +states\n19.29\n19.71\n2.2%\n\n\nunited~0.75\n15.08\n15.52\n2.9%\n\n\nunited states\n16.47\n16.95\n2.9%\n\n\ndoctitle:.[Uu]nited.\n6.23\n6.46\n3.8%\n\n\nspanNear([unit, state], 10, true)\n47.26\n49.44\n4.6%\n\n\nunit*\n36.28\n38.01\n4.7%\n\n\ndoctimesecnum:[10000 TO 60000]\n14.02\n14.90\n6.3%\n\n\nuni*\n21.08\n22.46\n6.6%\n\n\nspanFirst(unit, 5)\n169.47\n180.70\n6.6%\n\n\nunit~0.5\n23.03\n24.79\n7.6%\n\n\nun*d\n21.40\n23.64\n10.5%\n\n\nstates\n50.60\n56.17\n11.0%\n\n\nu*d\n11.16\n12.59\n12.8%\n\n\n\n ",
            "author": "Michael McCandless",
            "id": "comment-12993048"
        },
        {
            "date": "2011-02-10T13:47:29+0000",
            "content": "Thanks Mike... looks improved over your previous results.\n\nShould we commit this to bulk branch? I think we should also remove the \"fixed-int\" version 1.0 of Simple64 we have there... ",
            "author": "Robert Muir",
            "id": "comment-12993053"
        },
        {
            "date": "2013-07-23T18:44:54+0000",
            "content": "Bulk move 4.4 issues to 4.5 and 5.0 ",
            "author": "Steve Rowe",
            "id": "comment-13717092"
        },
        {
            "date": "2014-04-16T12:54:30+0000",
            "content": "Move issue to Lucene 4.9. ",
            "author": "Uwe Schindler",
            "id": "comment-13970776"
        }
    ]
}