{
    "id": "LUCENE-7848",
    "title": "QueryBuilder.analyzeGraphPhrase does not handle gaps correctly",
    "details": {
        "labels": "",
        "priority": "Major",
        "resolution": "Unresolved",
        "affect_versions": "6.5,                                            6.6",
        "status": "Open",
        "type": "Bug",
        "components": [],
        "fix_versions": []
    },
    "description": "Position increments greater than 1 are ignored when the query builder creates a graph phrase query. \nInstead it should use SpanNearQuery.addGap for pos incr > 1.",
    "attachments": {
        "LUCENE-7848-delimOnly-token-offset.patch": "https://issues.apache.org/jira/secure/attachment/12877309/LUCENE-7848-delimOnly-token-offset.patch",
        "LUCENE-7848-branching-spanOr.patch": "https://issues.apache.org/jira/secure/attachment/12876900/LUCENE-7848-branching-spanOr.patch",
        "LUCENE-7848.patch": "https://issues.apache.org/jira/secure/attachment/12873088/LUCENE-7848.patch",
        "capture-3.png": "https://issues.apache.org/jira/secure/attachment/12873474/capture-3.png"
    },
    "issue_links": {},
    "comments": [
        {
            "id": "comment-16021325",
            "date": "2017-05-23T15:27:13+0000",
            "content": "Thanks Jim. I agree the output from the filter looks odd too, but that's probably another issue. If you wish to reproduce, the Solr config I used was this:\n\n      <filter class=\"solr.WordDelimiterGraphFilterFactory\"\n              preserveOriginal=\"1\"\n              generateWordParts=\"1\"\n              generateNumberParts=\"1\"\n              stemEnglishPossessive=\"1\" />\n\n\nI then reproduced the same from code as well (just pass the corresponding flags and use a whitespace tokenizer). I don't have access to that code right now, but I can attach it later if you can't reproduce it yourself. ",
            "author": "Dawid Weiss"
        },
        {
            "id": "comment-16021368",
            "date": "2017-05-23T15:50:26+0000",
            "content": "I hit a snag with QueryBuilder#createSpanQuery too, and created (for the SOLR-1485 work) org.apache.solr.util.PayloadUtils with a createSpanQuery method.   It currently also doesn't take gaps into account (but the basic use cases don't involve sophisticated analysis there, so it was intentional to keep it initially simple), but I did have to work through some Lucene analysis API hurdles that I think QueryBuilder's createSpanQuery should fix along the way too.\n\nSee my comment and implementation here: https://github.com/apache/lucene-solr/blob/5d42177b9290b61c658154e42223408944cd4bc1/solr/core/src/java/org/apache/solr/util/PayloadUtils.java#L106-L128 ",
            "author": "Erik Hatcher"
        },
        {
            "id": "comment-16026129",
            "date": "2017-05-26T10:35:50+0000",
            "content": "\n    Analyzer a4 = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String field) {\n        final int flags2 = \n            GENERATE_WORD_PARTS | PRESERVE_ORIGINAL | GENERATE_NUMBER_PARTS | STEM_ENGLISH_POSSESSIVE;\n        Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);\n        StopFilter filter = new StopFilter(tokenizer, StandardAnalyzer.STOP_WORDS_SET);\n        return new TokenStreamComponents(tokenizer, new WordDelimiterGraphFilter(filter, flags2, protWords));\n      }\n    };\n\n    String in = \"aaa,bbb foo - bar\";\n    PrintWriter pw = new PrintWriter(System.out);\n    new TokenStreamToDot(in, a4.tokenStream(\"\", in), pw).toDot();\n    pw.flush();\n\n\n\nHere's the analyzer chain that I used for testing. I can't provide a full test \u2013 it was just an ad-hoc hacking session. ",
            "author": "Dawid Weiss"
        },
        {
            "id": "comment-16050187",
            "date": "2017-06-15T08:56:42+0000",
            "content": "Here is a simple patch that support gaps in QueryBuilder#createSpanQuery and QueryBuilder#analyzeGraphPhrase.\nQueryBuilder#createSpanQuery could also handle zero increment but that's probably another issue. ",
            "author": "Jim Ferenczi"
        },
        {
            "id": "comment-16052152",
            "date": "2017-06-16T17:16:51+0000",
            "content": "On short holidays, Jim, but I'll try to review next week. Looking quickly through the patch it looks great! ",
            "author": "Dawid Weiss"
        },
        {
            "id": "comment-16053739",
            "date": "2017-06-19T10:09:11+0000",
            "content": "Hi Jim,\n\nThe patch looks ok, although it doesn't solve the original problem \u2013 why, I don't know. This is the query in Solr:\n\nfunding_program:\"SPECIAL PROJECTS - XXX,SPECIAL PROJECTS - YYY\"\n\n\n\nThis (in Solr) gets translated into:\n\n+SpanNearQuery(\n  spanNear([\n    funding_program:special, \n    funding_program:projects, \n    funding_program:-, \n    spanOr([\n        spanNear([SpanGap(:1), funding_program:xxx,special], 0, true), \n        spanNear([SpanGap(:1), funding_program:xxx, funding_program:special], 0, true)\n    ]), \n    funding_program:projects, \n    funding_program:-, \n    SpanGap(:1), \n    funding_program:yyy], 0, true))\n\n\n\nThose odd-looking span gaps are emitted by the WordDelimiterGraphFilter (with the flags above); virtually the same config is used for indexing, but the query doesn't match the indexed content. A code-based test would be much better to pinpoint the problem here. I'll try to provide one. ",
            "author": "Dawid Weiss"
        },
        {
            "id": "comment-16053766",
            "date": "2017-06-19T10:34:48+0000",
            "content": "Here's a test (testLucene7848) that reproduces the behavior observed in Solr. To me this should work (right)?\n\nI didn't take a look at token streams emitted vs. the query yet \u2013 have to switch context now, but it'd be a good start to figure out what's happening. ",
            "author": "Dawid Weiss"
        },
        {
            "id": "comment-16053770",
            "date": "2017-06-19T10:39:46+0000",
            "content": "Token graph for the input (indexing and search is the same). ",
            "author": "Dawid Weiss"
        },
        {
            "id": "comment-16053806",
            "date": "2017-06-19T11:11:39+0000",
            "content": "Couldn't resist not to look. The index is fine. The query seems to be off though \u2013 here:\n\nspanNear([field:SPECIAL, \n          field:PROJECTS, \n          field:-, \n          spanOr([spanNear([SpanGap(:1), \n                            field:xxx,SPECIAL], 0, true), \n                  spanNear([SpanGap(:1), \n                            field:xxx, \n                            field:SPECIAL], 0, true)]), \n          field:PROJECTS, \n          field:-, \n          SpanGap(:1), \n          field:yyy], 0, true)\n\n\n\nThe problem is in those gaps inside spanOr \u2013 the position increments get screwed up somehow. I created the above query manually and this one works just fine:\n\n        Query q = SpanNearQuery.newOrderedNearQuery(field)\n            .addClause(new SpanTermQuery(new Term(field, \"SPECIAL\")))\n            .addClause(new SpanTermQuery(new Term(field, \"PROJECTS\")))\n            .addClause(new SpanTermQuery(new Term(field, \"-\")))\n            .addGap(1)\n            .addClause(new SpanOrQuery(\n                SpanNearQuery.newOrderedNearQuery(field)\n                  .addClause(new SpanTermQuery(new Term(field, \"xxx,SPECIAL\")))\n                  .addGap(1)\n                  .build(),\n                SpanNearQuery.newOrderedNearQuery(field)\n                    .addClause(new SpanTermQuery(new Term(field, \"xxx\")))\n                    .addClause(new SpanTermQuery(new Term(field, \"SPECIAL\")))\n                    .build()\n            ))\n            .addClause(new SpanTermQuery(new Term(field, \"PROJECTS\")))\n            .addClause(new SpanTermQuery(new Term(field, \"-\")))\n            .addGap(1)\n            .addClause(new SpanTermQuery(new Term(field, \"yyy\")))\n            .build();\n\n\n\nNote the leading gap is pulled outside, that's pretty much all the difference (another addGap(1) inside the \"xxx,SPECIAL\" condition is irrelevant here).\n\nCould be a bug somewhere in span queries. ",
            "author": "Dawid Weiss"
        },
        {
            "id": "comment-16053875",
            "date": "2017-06-19T12:04:59+0000",
            "content": "Hi Dawid,\nSorry I am also on vacations this week but looking at your example it seems that it's a problem with graph token in general. If you have side paths with different length at indexing time you need to use the flatten graph filter. Though it will not be able to index the correct positions for this example since \"xxx,special\" and \"xxx\", \"special\" should be indexed as a graph and Lucene does not handle graph at indexing time. I wonder why your manual query works, I might be missing something but this query should also not work unless you used another configuration for the WDGF (preserve original = false for instance should work at indexing time) ? ",
            "author": "Jim Ferenczi"
        },
        {
            "id": "comment-16053892",
            "date": "2017-06-19T12:22:21+0000",
            "content": "This isn't urgent and can wait. \n\nAs for indexing graphs, I though it was the other way around, sorry about that. But even if, the index created for this particular input seems to be just fine, look:\n\nfield field\n  term -\n    doc 0\n      freq 2\n      pos 2\n      pos 7\n  term PROJECTS\n    doc 0\n      freq 2\n      pos 1\n      pos 6\n  term SPECIAL\n    doc 0\n      freq 2\n      pos 0\n      pos 5\n  term xxx\n    doc 0\n      freq 1\n      pos 4\n  term xxx,SPECIAL\n    doc 0\n      freq 1\n      pos 4\n  term yyy\n    doc 0\n      freq 1\n      pos 9 \n\n\n\nIn fact, adding a flattening filter doesn't actually change anything here: the same index (and query) is produced. ",
            "author": "Dawid Weiss"
        },
        {
            "id": "comment-16083965",
            "date": "2017-07-12T13:24:37+0000",
            "content": "\"Could be a bug somewhere in span queries.\"^ \u2013 I think the remaining problem here is that only one branch (the shortest) of a SpanOrQuery is evaluated, at which point the \"spanOr\" is designated a match (or not) of the width/positionEnd of the shortest branch. When the branches of a \"spanOr\" differ in length (as they will as a matter of course for uses of GraphFilters such as in the above test), the shorter branch is evaluated, but if a longer branch is also a match, it affects the offset of subsequent tokens, and the enclosing \"spanNear\" sees a larger-than-expected slop, and fails to match. \n\nLUCENE-7848-branching-spanOr.patch adjusts SpanOrQuery to support repeated calls to nextStartPosition() which return the same startPosition, but different endPositions. The subSpan clauses of the \"spanOr\" are popped off the priorityQueue, retained, and restored upon exhaustion of subSpans (when it's time to move on to the next potential match). Some corresponding changes were necessary to make NearSpansOrdered aware of the new \"spanOr\" behavior, and conditionally evaluate as many branches of \"spanOr\" clauses as necessary to match (or not) on the full \"nearSpan\".\n\nThere may be other modifications needed in code that can call the modified \"spanOr\" and would need to be aware of its new behavior, but with this patch applied, all the tests in the TestWordDelimiterGraphFilter pass (including the new testLucene7848()). \n\nEDIT: original patch had a bug, was re-uploaded a few hours after initially posted. ",
            "author": "Michael Gibney"
        },
        {
            "id": "comment-16084587",
            "date": "2017-07-12T20:01:18+0000",
            "content": "Could be a bug somewhere in span queries.\n\nRelated to LUCENE-7398? ",
            "author": "Tim Allison"
        },
        {
            "id": "comment-16085610",
            "date": "2017-07-13T12:06:08+0000",
            "content": "Dawid, sorry for the delay\n\n\nspanNear([field:SPECIAL, \n          field:PROJECTS, \n          field:-, \n          spanOr([spanNear([SpanGap(:1), \n                            field:xxx,SPECIAL], 0, true), \n                  spanNear([SpanGap(:1), \n                            field:xxx, \n                            field:SPECIAL], 0, true)]), \n          field:PROJECTS, \n          field:-, \n          SpanGap(:1), \n          field:yyy], 0, true)\n\n\n\nThe problem is in those gaps inside spanOr \u2013 the position increments get screwed up somehow. I created the above query manually and this one works just fine:\n\n        Query q = SpanNearQuery.newOrderedNearQuery(field)\n            .addClause(new SpanTermQuery(new Term(field, \"SPECIAL\")))\n            .addClause(new SpanTermQuery(new Term(field, \"PROJECTS\")))\n            .addClause(new SpanTermQuery(new Term(field, \"-\")))\n            .addGap(1)\n            .addClause(new SpanOrQuery(\n                SpanNearQuery.newOrderedNearQuery(field)\n                  .addClause(new SpanTermQuery(new Term(field, \"xxx,SPECIAL\")))\n                  .addGap(1)\n                  .build(),\n                SpanNearQuery.newOrderedNearQuery(field)\n                    .addClause(new SpanTermQuery(new Term(field, \"xxx\")))\n                    .addClause(new SpanTermQuery(new Term(field, \"SPECIAL\")))\n                    .build()\n            ))\n            .addClause(new SpanTermQuery(new Term(field, \"PROJECTS\")))\n            .addClause(new SpanTermQuery(new Term(field, \"-\")))\n            .addGap(1)\n            .addClause(new SpanTermQuery(new Term(field, \"yyy\")))\n            .build();\n\n\n\nThese two queries are valid and should return result. The first one represents exactly the graph produced by the WordDelimiterGraphFilter and the second one has an extra gap after \"xxx,SPECIAL\". This extra gap is not irrelevant, it's the only way to match the indexed form of the document with the path containing the term \"xxx,SPECIAL\". If you look at the indexed positions \"xxx,SPECIAL\" is at position 4 and position 5 has the term \"SPECIAL\". This is the flattened version of the graph but the query side builds the correct version and ignores that the positions are messed up by the indexer. If you add a manual gap then it allows \"xxx,SPECIAL\" to also ignore the next position (5, SPECIAL) and to jump directly to (6, PROJECTS).\nThough the other path containing the splitted terms \"xxx\" and \"SPECIAL\" should match on both queries. I think this is the real problem and the fact that the second query match is just due to the additional gap that you added.\nI don't have time at the moment to look at why the SpanQuery does not match the first query. It deserves a separate issue anyway so I think we should focus on whether the query produced by the QueryBuilder is valid or not. If it is then the patch can be merged and we can look at the other problem separately.\nMichael Gibney can you open a new issue or add your comment and patch to https://issues.apache.org/jira/browse/LUCENE-7398 ? We should focus on the query building in this issue first. ",
            "author": "Jim Ferenczi"
        },
        {
            "id": "comment-16087019",
            "date": "2017-07-14T08:19:36+0000",
            "content": "Hi Jim. Thanks for the analysis \u2013 I do understand these two queries should be identical, but they have a different match result \u2013 that's why I thought it's probably a span query issue rather than the builder's (whether you pull those gaps or push them inside the or shouldn't matter).\n\nThis time I'm on holidays, but I'll keep looking at LUCENE-7398, perhaps it sheds some light on what's going on. ",
            "author": "Dawid Weiss"
        },
        {
            "id": "comment-16087376",
            "date": "2017-07-14T14:19:08+0000",
            "content": "I think the remaining problem is that WordDelimiterGraphFilter is swallowing delim-only tokens and leaving a gap even when PRESERVE_ORIGINAL is true. LUCENE-7848-delimOnly-token-offset.patch fixes this (and addresses the problematic gaps). ",
            "author": "Michael Gibney"
        },
        {
            "id": "comment-16629705",
            "date": "2018-09-27T03:31:16+0000",
            "content": "A patch equivalent to the LUCENE-7848-delimOnly-token-offset.patch of 14/Jul/2017 has been merged with LUCENE-8395. I think the remaining problems related to this issue are more directly addressed by LUCENE-7398. ",
            "author": "Michael Gibney"
        }
    ]
}