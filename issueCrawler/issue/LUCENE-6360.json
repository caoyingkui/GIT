{
    "id": "LUCENE-6360",
    "title": "TermsQuery should rewrite to a ConstantScoreQuery over a BooleanQuery when there are few terms",
    "details": {
        "resolution": "Fixed",
        "affect_versions": "None",
        "components": [],
        "labels": "",
        "fix_versions": [
            "5.2",
            "6.0"
        ],
        "priority": "Minor",
        "status": "Closed",
        "type": "Improvement"
    },
    "description": "TermsQuery helps when there are lot of terms from which you would like to compute the union, but it is a bit harmful when you have few terms since it cannot really skip: it always consumes all documents matching the underlying terms.\n\nIt would certainly help to rewrite this query to a ConstantScoreQuery over a BooleanQuery when there are few terms in order to have actual skip support.\n\nAs usual the hard part is probably to figure out the threshold.",
    "attachments": {
        "LUCENE-6360.patch": "https://issues.apache.org/jira/secure/attachment/12734091/LUCENE-6360.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "id": "comment-14362542",
            "author": "Paul Elschot",
            "date": "2015-03-15T20:35:05+0000",
            "content": "I wonder whether a compressing DocIdSet could also help here.\nEliasFanoDocIdSet uses an internal threshold for the number of matching docs, and above that threshold it changes itself to a bitset.\nThe tradeoff for this is not directly related to skipping because building the set requires all matching docs.\nBut a small compressing docidset skips/advances faster than a bitset.\n\nSome of this can be estimated in advance by the doc frequencies of the terms involved.\n\nTo  figure out the threshold(s), real life test cases would be helpful.\nDo you have some in mind already?\n "
        },
        {
            "id": "comment-14551953",
            "author": "Adrien Grand",
            "date": "2015-05-20T07:52:03+0000",
            "content": "Sorry Paul, I had missed your comment.\n\nI wonder whether a compressing DocIdSet could also help here.\n\nThis is something we are already doing: we use BitDocIdSetBuilder which internally starts with a sparse bit set and upgrades to a dense FixedBitSet if the cardinality becomes high. I agree this is already a win. But having actual skipping support would be even better? Ie. if you intersect with a sparse filter, you would not even need to iterate over documents that don't match the filter.\n\nTo figure out the threshold(s), real life test cases would be helpful. Do you have some in mind already?\n\nMy current idea is to have the same threshold here and when running MultiTermQueries, LUCENE-6458 "
        },
        {
            "id": "comment-14552028",
            "author": "Adrien Grand",
            "date": "2015-05-20T08:59:36+0000",
            "content": "Here is a patch.\n 1. TermsQuery rewrites to a ConstantScoreQuery(BooleanQuery) when there are 16 terms or less.\n 2. If there are more than 16 terms, then still per segment TermsQuery will first try to collect terms and if there are less than 16 terms that exist on this segment, it will also execute like a disjunction.\n\nI took 16 as a threshold to use the same as MultiTermQueryConstantScoreWrapper.\n\n1. is mostly useful for caching so that if you have a short TermsQuery it will share the same cache key as a disjunction around the same terms. "
        },
        {
            "id": "comment-14552321",
            "author": "David Smiley",
            "date": "2015-05-20T13:31:36+0000",
            "content": "I reviewed the patch.  The code for #2 is pretty interesting.  I learn a lot by reading your patches.  \n\nI noticed what looks like a bug in TermsQuery.createWeight.scorer:\n\n          // comparing references is fine here\n          if (field != lastField) {\n            terms = fields.terms(field);\n            if (terms == null) {\n              termsEnum = null;\n            } else {\n              termsEnum = terms.iterator();\n            }\n          }\n\n\nYour code didn't introduce that, and yes I can read the comment    lastField is never updated, so it will fetch terms.iterator() every time.\n\nSecondly... I think the needsScores param should arguably not pass through to the ConstantScoreQuery wrapped BooleanQuery, since this should be constant scoring; no? Or maybe it's moot since it's CSQ after all.\n\nDid you mean for the changes in CoalescedUpdates and FrozenBufferedUpdates to be in this patch? "
        },
        {
            "id": "comment-14552419",
            "author": "Adrien Grand",
            "date": "2015-05-20T14:50:16+0000",
            "content": "I noticed what looks like a bug in TermsQuery.createWeight.scorer:\n\nGood catch, it's a bad bug indeed! Here is an updated patch with a test that we only pull one iterator per unique field.\n\nSecondly... I think the needsScores param should arguably not pass through to the ConstantScoreQuery wrapped BooleanQuery, since this should be constant scoring; no? Or maybe it's moot since it's CSQ after all.\n\nActually I think it does need to pass through to the CSQ. The current contract is that if you pass needsScores=false then scores are going to be undefined, so if the user passed needsScores=true we need to make sure that we build a query that will return the same scores.\n\nBy the way if we did not, it would probably break the scores since ConstantScoreQuery.createWeight returns the inner weight directly when scores are not needed.\n\nDid you mean for the changes in CoalescedUpdates and FrozenBufferedUpdates to be in this patch?\n\nYes: I needed to have the term count to rewrite so I changed PrefixCodedTerms to store the number of wrapped terms and then noticed that these other classes were maintaining this number of terms on the side, so I refactored them to use PrefixCodedTerms.size() instead? "
        },
        {
            "id": "comment-14552489",
            "author": "David Smiley",
            "date": "2015-05-20T15:29:23+0000",
            "content": "Nice; looks great now.  Thanks for the explanations.\n\nI doubt the optimal threshold for the rewrite() is the same as the optimal threshold to return a per-segment scorer... but using the same is fine. "
        },
        {
            "id": "comment-14553135",
            "author": "Adrien Grand",
            "date": "2015-05-20T21:13:15+0000",
            "content": "I doubt the optimal threshold for the rewrite() is the same as the optimal threshold to return a per-segment scorer... but using the same is fine.\n\nAgreed. The way I see it is that we have to start somewhere and starting small has the benefit of putting us on the safe side.  "
        },
        {
            "id": "comment-14554365",
            "author": "David Smiley",
            "date": "2015-05-21T14:38:34+0000",
            "content": "Like in MultiTermQueryConstantScoreWrapper ( https://issues.apache.org/jira/browse/LUCENE-6458?focusedCommentId=14554181#comment-14554181 ) which will soon have a specialized case for bulkScorer, should there similarly be a bulkScorer impl here? "
        },
        {
            "id": "comment-14554369",
            "author": "Adrien Grand",
            "date": "2015-05-21T14:39:42+0000",
            "content": "Yes indeed. I'm working on it right now.  "
        },
        {
            "id": "comment-14554582",
            "author": "Adrien Grand",
            "date": "2015-05-21T16:07:28+0000",
            "content": "Here is an updated patch. It works in a very similar way to MultiTermQueryConstantScoreWrapper for BulkScorer delegation. "
        },
        {
            "id": "comment-14554941",
            "author": "ASF subversion and git services",
            "date": "2015-05-21T19:48:42+0000",
            "content": "Commit 1680946 from Adrien Grand in branch 'dev/trunk'\n[ https://svn.apache.org/r1680946 ]\n\nLUCENE-6360: Make TermsQuery rewrite as a disjunction when there are few terms. "
        },
        {
            "id": "comment-14554942",
            "author": "ASF subversion and git services",
            "date": "2015-05-21T19:50:21+0000",
            "content": "Commit 1680947 from Adrien Grand in branch 'dev/trunk'\n[ https://svn.apache.org/r1680947 ]\n\nLUCENE-6360: Add CHANGES entry. "
        },
        {
            "id": "comment-14554971",
            "author": "ASF subversion and git services",
            "date": "2015-05-21T20:16:46+0000",
            "content": "Commit 1680948 from Adrien Grand in branch 'dev/branches/branch_5x'\n[ https://svn.apache.org/r1680948 ]\n\nLUCENE-6360: Make TermsQuery rewrite as a disjunction when there are few terms. "
        },
        {
            "id": "comment-14554976",
            "author": "Adrien Grand",
            "date": "2015-05-21T20:21:59+0000",
            "content": "Thanks again David! "
        },
        {
            "id": "comment-14586836",
            "author": "Anshum Gupta",
            "date": "2015-06-15T21:43:12+0000",
            "content": "Bulk close for 5.2.0. "
        }
    ]
}