{
    "id": "LUCENE-5052",
    "title": "bitset codec for off heap filters",
    "details": {
        "components": [
            "core/codecs"
        ],
        "fix_versions": [],
        "affect_versions": "None",
        "priority": "Major",
        "labels": "",
        "type": "New Feature",
        "resolution": "Won't Fix",
        "status": "Closed"
    },
    "description": "Colleagues,\n\nWhen we filter we don\u2019t care any of scoring factors i.e. norms, positions, tf, but it should be fast. The obvious way to handle this is to decode postings list and cache it in heap (CachingWrappingFilter, Solr\u2019s DocSet). Both of consuming a heap and decoding as well are expensive. \nLet\u2019s write a posting list as a bitset, if df is greater than segment's maxdocs/8  (what about skiplists? and overall performance?). \nBeside of the codec implementation, the trickiest part to me is to design API for this. How we can let the app know that a term query don\u2019t need to be cached in heap, but can be held as an mmaped bitset?\n\nWDYT?",
    "attachments": {
        "bitsetcodec.zip": "https://issues.apache.org/jira/secure/attachment/12613826/bitsetcodec.zip",
        "LUCENE-5052.patch": "https://issues.apache.org/jira/secure/attachment/12631227/LUCENE-5052.patch",
        "LUCENE-5052-1.patch": "https://issues.apache.org/jira/secure/attachment/12637868/LUCENE-5052-1.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2013-06-12T08:41:24+0000",
            "content": "The following paper might be informative in regard to this ticket (you can even go beyond maxdocs/8, if compared against VInt-coding):\n\nA. Moffat and J. S. Culpepper. Hybrid Bitvector Index Compression. In Proceedings of the 12th Australasian Document Computing Symposium (ADCS 2007), December 2007. pp 25-37.\navailable from: http://goanna.cs.rmit.edu.au/~e76763/publications.html\n\nMore generally, it would be nice to determine the PostingsListFormat depending on statistics of individual terms, not only per-field. ",
            "author": "Stefan Pohl",
            "id": "comment-13681049"
        },
        {
            "date": "2013-06-20T18:26:09+0000",
            "content": "Couldn't this just be a PostingsFormat, such that for DOCS_ONLY fields with high enough docFreq, it stores them as a dense bitset on disk?\n\nMaybe it could wrap another PostingsBaseFormat (like Pulsing) and 'steal' the high freq terms... ",
            "author": "Michael McCandless",
            "id": "comment-13689488"
        },
        {
            "date": "2013-06-20T19:19:23+0000",
            "content": "Yeah cool idea.  But I feel that to truly take the performance to the next level, there should be a way to intersect the bit vector with another.  The spatial Lucene filters have loops that work by populating a FixedBitSet by looping over DocsEnum.  But if behind the scene's it's just another bitset, I would love to efficiently union the bitsets.  Example snippet of existing code: \n\n\nint docid;\nwhile ((docid = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n  bitSet.set(docid);\n}\n\n\n\nI'd bet there's a lot of code like this around. ",
            "author": "David Smiley",
            "id": "comment-13689544"
        },
        {
            "date": "2013-07-10T12:34:01+0000",
            "content": "it's worth to start from trivial bitset, sortedints encodings and lately consider comprehensive Elias-Fano encoding https://issues.apache.org/jira/browse/LUCENE-5084 ",
            "author": "Mikhail Khludnev",
            "id": "comment-13704501"
        },
        {
            "date": "2013-11-14T12:59:02+0000",
            "content": "This is very simple implementation of codec which stores PostingLists as BitSets. This implementation passes BasePostingsFormatTestCase.testDocsOnly() test. \nAlso I have found difficult to implement term dictionary and feel like it's better to somehow combine this posting format with any of standard ones. ",
            "author": "Yuriy",
            "id": "comment-13822389"
        },
        {
            "date": "2014-02-26T13:57:19+0000",
            "content": "This is adopted version of BitSetCodec. It uses BlockTermsWriter/Reader infrastructure to build posting format with custom posting writer/reader and standard terms writer/reader. TODO use  Long.numberOfTrailingZeros() in advance() and nexdoc() ",
            "author": "Nina Gracheva",
            "id": "comment-13912916"
        },
        {
            "date": "2014-03-13T14:57:19+0000",
            "content": "Methods nextDoc() and advance() have been implemented using Long.numberOfTrailingZeros() approach taken from FixedBitSetIterator ",
            "author": "Dr Oleg Savrasov",
            "id": "comment-13933351"
        },
        {
            "date": "2014-03-13T18:43:02+0000",
            "content": "Hi Stefan Pohl, paper link seem broken? Gives 404 to me. ",
            "author": "Ahmet Arslan",
            "id": "comment-13933863"
        },
        {
            "date": "2014-03-14T12:00:05+0000",
            "content": "Besides other locations, the paper can now be found here:\nhttp://www.culpepper.io/publications.html ",
            "author": "Stefan Pohl",
            "id": "comment-13934921"
        },
        {
            "date": "2014-03-14T16:29:33+0000",
            "content": "This patch looks like a great start!\n\nUsing BlockTermsDict makes sense; no need to reimplement a terms dictionary (it's not easy!).\n\nOne problem I see is every term is written as a bitset?  This may be OK for some applications, but I think for wider usage, it'd be better if the postings format wrapped another postings format, and then only used the bitset when the docFreq was high enough, and otherwise delegate to the wrapped postings format?  Maybe have a look at PulsingPostingsFormat as an example of how to wrap postings formats? ",
            "author": "Michael McCandless",
            "id": "comment-13935219"
        },
        {
            "date": "2014-03-17T16:02:53+0000",
            "content": "it'd be better if the postings format wrapped another postings format, and then only used the bitset when the docFreq was high enough\n\nThere are two orthogonal conceptions: \n\n\tparticular format - let's generalize \"bitset format\" to \"no-tf format\", and use WAH8, Elas-Fano with off-heap access (TODO). Thus, it works for spare postings;\n\tAPI - how consumer can express his intention to use \"no-tf\" format? e.g. TermFilter or TermsEnum.docs() with special flag;\n\n\n\nI'd like to clarify use-case for this issue (issue summary might need to be improved). It aims Solr's fq or even Heliosearch's GC-lightness. I suppose that user can decide which fields to index with \"no-tf\" format, these are \"string\" fields. Then, user requests filtering for these fields, no scoring is needed, for sure. \n\nMichael McCandless\nHence, I don't think than conditional conditional triggering is a good choice, however I don't know how to do it. I might not understand well how pulsing codec is used (impl idea is clear, though), can you point me on its' usage.\n\nThanks! ",
            "author": "Mikhail Khludnev",
            "id": "comment-13937947"
        },
        {
            "date": "2014-03-17T17:07:18+0000",
            "content": "OK, I agree: if we use a sparse bitset, then we could use the format for all postings.  I guess we'd switch up the bitset impl depending on docFreq of each term.\n\nWe already have FieldInfo.IndexOptions.DOCS_ONLY to express that you want to index only the docIDs.  E.g. StringField sets this.\n\nAnd our default codec already makes it easy to switch up the postings format by field: just subclass it and override getPostingsFormatForField. ",
            "author": "Michael McCandless",
            "id": "comment-13938046"
        },
        {
            "date": "2014-03-25T19:53:34+0000",
            "content": "Michael McCandless let's agree on desired functionality:\n\n\tthis posting format should wrap the standard one, like pulsing;\n\tif IndexOptions.DOCS_ONLY is provided, this codec suppresses standard posting format and write the bitset file (<<should-be>> explore fancy formats then);\n\tsame logic applies on reading;\n\n\n\nI wonder what\u2019s the correct behavior if docEnum is requested with FLAG_FREQS, should it silently returns 1 on freq() or throwing exception?\n\nLet me ask one off-top question about switching to PulsingPF. I've heard that it's enabled automatically for id-like field. Can you point on where it's done particularly? Does it works for Lucene only, or for Solr also?\nThanks \n\n\n ",
            "author": "Mikhail Khludnev",
            "id": "comment-13947067"
        },
        {
            "date": "2014-03-25T19:59:20+0000",
            "content": "\nLet me ask one off-top question about switching to PulsingPF. I've heard that it's enabled automatically for id-like field. Can you point on where it's done particularly? \n\nSee LUCENE-4498\n\nif there is only one document in the postings list for a term, we just store that document id instead of a pointer to a list ... of only one document.\n\nThe freq() for that one document is redundant as well: its the totalTermFreq() for the term, so there is no frequency data recorded either. It still has a pointer for positions/payload/offsets if you have that enabled: but in most cases with an ID-like field you do not. ",
            "author": "Robert Muir",
            "id": "comment-13947075"
        },
        {
            "date": "2014-03-25T20:12:49+0000",
            "content": "this posting format should wrap the standard one, like pulsing;\n\nI don't think we need to do that (I was convinced, above)?  I think it should just be its own PF, and the app picks it to store all postings as bitsets.\n\nif IndexOptions.DOCS_ONLY is provided, this codec suppresses standard posting format and write the bitset file (<<should-be>> explore fancy formats then);\n\nI think it should ONLY accept DOCS_ONLY?  Ie, throw an exc if it gets anything else, because it's mis-use.\n\nI wonder what\u2019s the correct behavior if docEnum is requested with FLAG_FREQS, should it silently returns 1 on freq() or throwing exception?\n\nI think lie (return 1 from freq). ",
            "author": "Michael McCandless",
            "id": "comment-13947085"
        },
        {
            "date": "2014-03-31T15:55:08+0000",
            "content": "Only DOCS_ONLY index option is supported. IllegalArgumentException is thrown for anything else. ",
            "author": "Dr Oleg Savrasov",
            "id": "comment-13955328"
        },
        {
            "date": "2014-04-07T18:47:48+0000",
            "content": "Colleagues,\nWould you mind to provide a feedback for the last patch? What's the next steps you expect to move it forward? ",
            "author": "Mikhail Khludnev",
            "id": "comment-13962130"
        },
        {
            "date": "2014-04-07T20:59:30+0000",
            "content": "Is this aiming to do the same thing Yonik did for Heliosearch or something different? ",
            "author": "Otis Gospodnetic",
            "id": "comment-13962249"
        },
        {
            "date": "2014-04-07T21:20:01+0000",
            "content": "Is this aiming to do the same thing Yonik did for Heliosearch or something different?\n\nWhat I've done in Heliosearch is when you do have to allocate memory for a filter, it's allocated off-heap.\nThis issue is more about avoiding any memory allocation at all for simple term filters (since it's more like just memory mapping part of the index).  It's probably a bit misleading to describe it as \"off-heap\".  It's more like how the rest of the lucene index works (probably a better description would be \"on-disk\". ",
            "author": "Yonik Seeley",
            "id": "comment-13962270"
        },
        {
            "date": "2014-04-07T22:42:34+0000",
            "content": "I think the patch looks like a good start!  Seems like we need to support a sparse bitset form to make it more general purpose?  Do all lucene tests pass if you run with -Dtests.codec=BitSetCodec?\n\nWhy did you use the older BlockTerms dict instead of BlockTree? ",
            "author": "Michael McCandless",
            "id": "comment-13962347"
        },
        {
            "date": "2014-04-09T20:36:49+0000",
            "content": "I think the patch looks like a good start!  Seems like we need to support a sparse bitset form to make it more general purpose?\nAgree. I wonder what's the shortest path. I see WAH8 docidset impl. Is it a good idea to take it and move it to ByteBuffer? Or just create it in heap as-is and persist it on disk? Is it worth to look at Elias-Fano docid set, which is not committed afaik? Or research other formats like RLE? \nDo all lucene tests pass if you run with -Dtests.codec=BitSetCodec?\nThere is codec test for docs_only which pass. How other tests can pass if it doesn't support freqs and positions? Or we need to come through all failures and triage them?\nWhy did you use the older BlockTerms dict instead of BlockTree?\nLet's check whether we can to move. ",
            "author": "Mikhail Khludnev",
            "id": "comment-13964636"
        }
    ]
}