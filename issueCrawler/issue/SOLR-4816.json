{
    "id": "SOLR-4816",
    "title": "Add document routing to CloudSolrServer",
    "details": {
        "affect_versions": "None",
        "status": "Resolved",
        "fix_versions": [
            "4.5",
            "6.0"
        ],
        "components": [
            "SolrCloud"
        ],
        "type": "Improvement",
        "priority": "Minor",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "This issue adds the following enhancements to CloudSolrServer's update logic:\n\n1) Document routing: Updates are routed directly to the correct shard leader eliminating document routing at the server.\n\n2) Optional parallel update execution: Updates for each shard are executed in a separate thread so parallel indexing can occur across the cluster.\n\n\nThese enhancements should allow for near linear scalability on indexing throughput.\n\nUsage:\n\nCloudSolrServer cloudClient = new CloudSolrServer(zkAddress);\ncloudClient.setParallelUpdates(true); \nSolrInputDocument doc1 = new SolrInputDocument();\ndoc1.addField(id, \"0\");\ndoc1.addField(\"a_t\", \"hello1\");\nSolrInputDocument doc2 = new SolrInputDocument();\ndoc2.addField(id, \"2\");\ndoc2.addField(\"a_t\", \"hello2\");\n\nUpdateRequest request = new UpdateRequest();\nrequest.add(doc1);\nrequest.add(doc2);\nrequest.setAction(AbstractUpdateRequest.ACTION.OPTIMIZE, false, false);\n\nNamedList response = cloudClient.request(request); // Returns a backwards compatible condensed response.\n\n//To get more detailed response down cast to RouteResponse:\nCloudSolrServer.RouteResponse rr = (CloudSolrServer.RouteResponse)response;",
    "attachments": {
        "SOLR-4816.patch": "https://issues.apache.org/jira/secure/attachment/12582939/SOLR-4816.patch",
        "RequestTask-removal.patch": "https://issues.apache.org/jira/secure/attachment/12602726/RequestTask-removal.patch",
        "SOLR-4816-sriesenberg.patch": "https://issues.apache.org/jira/secure/attachment/12583323/SOLR-4816-sriesenberg.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Joel Bernstein",
            "id": "comment-13656057",
            "date": "2013-05-13T15:53:51+0000",
            "content": "Initial patch with the new \"directUpdate\" method. This is the initial implementation and has not been tested. Testing and implementation iterations to follow. Patch was generated with Solr 4.3 "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13656083",
            "date": "2013-05-13T16:34:58+0000",
            "content": "This looks like a dupe of SOLR-3154 - see that issue for more history. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13656084",
            "date": "2013-05-13T16:35:47+0000",
            "content": "This shouldn't really be an extra method - it should just be the default way the CloudSolrServer works. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13656119",
            "date": "2013-05-13T17:04:58+0000",
            "content": "OK, reviewing SOLR-3154. Thanks! "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13656178",
            "date": "2013-05-13T17:58:17+0000",
            "content": "In looking at SOLR-3154 it looks this was done pre-document routing so it will have to be changed. It also looks like it won't work with batches because it checks the first document id only.\n\nThe batches issue is why I created another method. We could get batches into the original method but the code would be pretty hairy. I like the idea of a nice clean separate method for this.\n\nLet me know how you'd like to proceed. I can work on updating the SOLR-3154 implementation or keep working this implementation.\n\nThanks "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13656232",
            "date": "2013-05-13T18:36:25+0000",
            "content": "It also looks like it won't work with batches because it checks the first document id only.\n\nYes, see the comments in the issue:\n\n\"The patch is limited, but a start: right now it's just for String and Integer Id's and it only acts upon the first document or deleteby id (favoring document) - if you use the bulk methods they are all sent along to the leader of the first id.\"\n\nI like the idea of a nice clean separate method for this.\n\nI still think it needs to be the default method, and we simply should support batching. The other limitation around types is no longer a concern now that Yonik changed the hashing.\n\nI don't know that we need to build on the patch in SOLR-3154, it was a very quick experiment, but I think that is the right implementation direction. The smart client should simply work optimally without having to use alternate methods IMO. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13656607",
            "date": "2013-05-14T01:01:30+0000",
            "content": "Ok, I'll integrate the directUpdate logic into the main request flow. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13657359",
            "date": "2013-05-14T18:44:51+0000",
            "content": "First working version of the patch. The directUpdate method is still public so it can be called directly to specify a different id field. The directUpdate method is also integrated into the main request method where it will use the field named \"id\" as the id field.\n "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13657370",
            "date": "2013-05-14T18:50:42+0000",
            "content": "where it will use the field named \"id\" as the id field.\n\nIt seems there are two easish improvements we might do - either allow setting the 'default' id field with a setter or look into using the new schema rest api to actually request the id field from Solr.\n\nI'm still not sold on the need to expose a new update method.\n\nThat's just a quick response though, I'll review your patch as soon as I get a chance. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13657376",
            "date": "2013-05-14T18:56:43+0000",
            "content": "Ok, I like the idea of the default id setter. I'll add this and make the directUpdate method private. "
        },
        {
            "author": "Stephen Riesenberg",
            "id": "comment-13657563",
            "date": "2013-05-14T21:53:57+0000",
            "content": "I tried out the patch and it had some bugs in it. Did you want me to post changes we made to it? I won't test it again until tomorrow, so we'll have to let you know whether this works. "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13657597",
            "date": "2013-05-14T22:19:52+0000",
            "content": "Side note: for testing purposes it's going to be handy to have a property/setter on CloudSolrServer that forces it to ignore the id and randomly pick a node to send the updates to, and then have the test framework randomly set that property \u2013 that way we can future proof ourselves against accidentally server side bugs where docs aren't sent to the correct shard, or docs aren't sent to a leader, etc... "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13658306",
            "date": "2013-05-15T12:36:53+0000",
            "content": "Hoss, sounds good I'll work this into the next patch.\n\nStephen, sure go ahead and post the changes. I'm going to make some changes to the patch shortly and I'll work with your changes as well. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13658360",
            "date": "2013-05-15T13:40:14+0000",
            "content": "No longer going to the core url directly with updates and instead sending to the baseUrl+/+collection. Also passing through the orignal params to each request. Added the getter/setter for the defaultId. \n\nStephen, let me know if this addresses the bugs you found. "
        },
        {
            "author": "Stephen Riesenberg",
            "id": "comment-13658363",
            "date": "2013-05-15T13:48:46+0000",
            "content": "First attempt. This patch is to fix issues with directUpdate() method and add defaultIdField. Next attempt would be to integrate it better into the request() method. This is still un-tested, as I'm going to be deploying it today for load testing. "
        },
        {
            "author": "Stephen Riesenberg",
            "id": "comment-13658364",
            "date": "2013-05-15T13:49:29+0000",
            "content": "Oops, I missed your latest. I'll check it out.\n\nEdit: Main issue is an NPE using params (params = new ...), and missing use of the defaultCollection in params.get(). "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13658386",
            "date": "2013-05-15T14:10:01+0000",
            "content": "Stephen, I see what you did with the defaultCollection. I'll work that into the patch. I made a few other changes so I'll use the patch I'm working with. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13658392",
            "date": "2013-05-15T14:20:23+0000",
            "content": "Added Stephen's code fixing NPE when params and/or collection is not set. "
        },
        {
            "author": "Stephen Riesenberg",
            "id": "comment-13658510",
            "date": "2013-05-15T16:27:07+0000",
            "content": "Fixed several other NPEs before getting to the code where it uses the DocRouter. It looks like the router that is used is the ImplicitDocRouter not the HashBasedRouter. So it returns a null Slice. Any idea how to get the correct DocRouter for hash-based from the API? Or could we just create a new HashBasedRouter instance and use it. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13658516",
            "date": "2013-05-15T16:32:03+0000",
            "content": "Stephen, let's discuss offline. Just sent you an email. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13658531",
            "date": "2013-05-15T16:48:23+0000",
            "content": "Seems we should be batching bulk docs up based on what leader they will go to and propegate the bulk adds where we can. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13658532",
            "date": "2013-05-15T16:51:21+0000",
            "content": "Ah, glanced too quickly - that is what is happening - looks a lot cleaner than your initial comment indicated, nice. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13658536",
            "date": "2013-05-15T16:54:48+0000",
            "content": "Fixed several other NPEs before getting to the code where it uses the DocRouter. \n\nWe should make sure we have tests that would have caught these as well! "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13658543",
            "date": "2013-05-15T17:00:22+0000",
            "content": "Any idea how to get the correct DocRouter for hash-based from the API?\n\nIt's collection specific.\nSee DocCollection.getRouter() "
        },
        {
            "author": "Stephen Riesenberg",
            "id": "comment-13658772",
            "date": "2013-05-15T20:36:14+0000",
            "content": "It's collection specific.\nSee DocCollection.getRouter()\n\nNo javadoc on that method. In my environment, collections were set up for implicit routing because numShards was not specified at create time. Joel straightened us out. Only thing I found was at http://wiki.apache.org/solr/SolrCloud#Creating_cores_via_CoreAdmin which doesn't talk about document routing.\n\nThe NPEs I mentioned before have been fixed, one other fix was made to set the commitWithinMS and pass params to the sub-requests and document router. Now I am running a load test against this to see how it performs. I'll post an updated patch with my changes a bit later.\n\nWe should make sure we have tests that would have caught these as well!\n\nI didn't run the test suite. Seems like a good idea! I'll get caught up eventually. Having run it now with the earlier patches, seeing the NPEs. Good stuff. Thanks. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13659946",
            "date": "2013-05-16T20:36:06+0000",
            "content": "To get the existing tests to run I needed to limit the directUpdates to only UpdateRequests that have document lists. \n\nAll other requests bypass the directUpdates method and follow the main flow.\n\nCurrently UpdateRequestExt also bypasses the directUpdates method and follows the main flow. There is a TODO in the UpdateRequestExt class to bake it into the UpdateRequest class. This would be a cleaner approach to getting UpdateRequestExt to work with directUpdates.\n\n\n "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13659950",
            "date": "2013-05-16T20:38:36+0000",
            "content": "Existing tests now run with latest patch. Still need to add tests for the new directUpdate functionality. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13660722",
            "date": "2013-05-17T13:43:07+0000",
            "content": "Reorganized conditional tests that lead to direct updates. All conditions must pass or the request will follow main flow. Added condition that docRouter must be a CompositeIdRouter for directUpdates.  "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13660723",
            "date": "2013-05-17T13:44:55+0000",
            "content": "Stephen can you post your latest patch I'd like to see how you handle the commitWithinMS. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13660864",
            "date": "2013-05-17T17:08:42+0000",
            "content": "To support UpdateRequestExt in a clean way I added a new interface called Routable which is implemented by both UpdateRequest and UpdateRequestExt. \n\nInitial patch for this design meant for review only, has not been tested. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13660961",
            "date": "2013-05-17T19:11:11+0000",
            "content": "Runnable version of the new design/implementation. Seems to work well. Since both UpdateRequest and UpdateRequestExt are now supported for direct updates I think this implementation is complete.\n\nStill needs automated tests and testing under load. "
        },
        {
            "author": "Stephen Riesenberg",
            "id": "comment-13661369",
            "date": "2013-05-18T14:51:46+0000",
            "content": "Sorry, was away yesterday. Your patch is getting beyond my original changes, so I won't post it again. In regards to commitWithin, you need the original request when you create a new sub-request. Then basically newRequest.setCommitWithin(originalRequest.getCommitWithin());\n\nYou could only do this in the new getRoutes() method if you have the original request available. Hope that helps!\n\nEdit: Also, this line:\n\n\nSlice slice = router.getTargetSlice(doc.getFieldValue(id).toString(),doc,null,col);\n\n\nWould be:\n\n\nSlice slice = router.getTargetSlice(doc.getFieldValue(id).toString(),doc,params,col);\n\n\nI got an NPE when passing null to the DocRouter. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13661400",
            "date": "2013-05-18T17:22:41+0000",
            "content": "Thanks Stephen, I'll make sure the commitWithin is accounted for at the request level. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13661406",
            "date": "2013-05-18T18:00:55+0000",
            "content": "Stephen's comments brought up other questions which need to be decided: \n\n1) How to handle delete by requests.\n2) How to handle various action requests (commit, optimize etc...).\n\nProbably a good approach to this is to process all the direct updates first and then remove the document list from the original request and let the original request execute through the main flow. \n\nI'll work on getting this scenario into the patch. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13662389",
            "date": "2013-05-20T22:00:01+0000",
            "content": "After spending more time looking at everything that an upateRequest can do I realized that not all parts of a request are routable.\n\nThe latest patch handles this by first sending all the routable updates to the correct shard. Then executing a final update request with non-routable update commands such as OPTIMIZE or deleteByQuery.\n\nThis latest patch has not been tested so is for review purposes only.\n "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13662976",
            "date": "2013-05-21T13:46:30+0000",
            "content": "Latest patch is a working version of CloudSolrServer that handles a mix of routable and nonroutable requests.\n\nAlso added a setter and getter for the boolean directUpdates. This controls whether directUpdates are on. The default is off.\n\nI added this setter/getter because the response for a directUpdate contains multiple repsonses, one from each of the shards routed to and one for the non-routable request. I figured having a compound response might break existing clients so it's off by default.\n "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13663299",
            "date": "2013-05-21T19:39:56+0000",
            "content": "Added a simple test case. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13663720",
            "date": "2013-05-22T03:22:27+0000",
            "content": "Added a much better test case which tests to see if each document was indexed to the shard it was sent to. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13666424",
            "date": "2013-05-24T16:18:56+0000",
            "content": "Latest version of the patch sends the list of urls for each replica in the slice to LBHttpSolrServer, with the leader being the first url.\n\nSo, if the leader throws an error on the request LBHttpSolrServer will try another replica in the slice. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13667074",
            "date": "2013-05-25T13:47:44+0000",
            "content": "Requests are now threaded. Documents are batched up and routed to the correct shard. Each routed request is sent in it's own thread so indexing on each Solr server can be done in parallel.\n\nWith this scenario load throughput should increase almost linearly with cluster size. "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-13667129",
            "date": "2013-05-25T16:23:06+0000",
            "content": "Joel Bernstein does the threading destroy the ability for the object to send throwables back up the stack, like ConcurrrentUpdateSolrServer and SOLR-3284?  If it does, then I am -1 to that change in CloudSolrServer.  Some people (including me) rely on exceptions being thrown on update requests that do not include optimize or commit, so that behavior cannot be lost.  If you've found a way to have multiple threads without swallowing exceptions, then I'm +1 ... and please fix CUSS as well. \n\nIf you find that you can't have threading without a handleError method that eats the exception (like CUSS), then I'd rather you create ConcurrentCloudSolrServer instead and include a note about error handling in its javadoc.  I don't see a similar note in the javadoc for CUSS. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13667138",
            "date": "2013-05-25T17:22:40+0000",
            "content": "Shawn,\n\nThe way Exceptions are handled in this patch is that each thread makes a separate update request and records an exception if one occurs. When they all complete the main thread checks to see if any exceptions occurred. If it finds an exception occurred it throws that exception.\n\nIf no exceptions occur then the main thread executes the remaining actions such as COMMIT. \n\nLet me know if that sounds like it's enough control for you.\n\nJoel "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13667154",
            "date": "2013-05-25T19:33:55+0000",
            "content": "Sounds like a fairly major back compat break we have to consider.  "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13667155",
            "date": "2013-05-25T19:40:56+0000",
            "content": "I have not had time to review the latest work, but my goal for this issue is to have a cloud server that worked as is, but by default hashes and routes on the client side. A simple backward compatible improvement that no one has to turn on. I think anything that breaks back compat heavily or requires turning on options to get this behavior should be a new cloud implementation perhaps.  "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13667400",
            "date": "2013-05-26T21:05:51+0000",
            "content": "The main backwards compatibility issue that I see is the compound response. This patch returns a response that contains the responses from each of the shard requests. This is the main reason that I made the directUpdate functionality optional.\n\nThe exception handling seems to be backwards compatible.\n\nA separate implementation makes sense too. The CloudSolrServer works fine for less demanding indexing needs. The ConcurrentCloudSolrServer could be used for higher throughput.\n\n "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13668361",
            "date": "2013-05-28T15:17:53+0000",
            "content": "OK, I've created the ConcurrentUpdateCloudSolrServer class and reverted the CloudSolrServer.\n\nI think trying to get this functionality into CloudSolrServer and not have any back compatibility issues was going to be a blocker.\n\nI'll update the ticket name and description to reflect this.\n\nThe initial ConcurrentUpdateCloudSolrServer in this patch seems to run fine. More tests are needed though. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13668454",
            "date": "2013-05-28T17:06:09+0000",
            "content": "Formatted according to the official rules, removed extra imports, but no other changes. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13668722",
            "date": "2013-05-28T21:55:55+0000",
            "content": "The exception handling seems to be backwards compatible.\n\nBy the sound of it, you changed the runtime behavior in an incompat way - with a single thread you have very tight control and knowledge of what docs got accepted in and what docs failed and the exception for every fail. It's not so easy to get that same back compat behavior with multiple threads and by the description, it sounds like a break to me.\n\nI think a multi threaded version cannot likely be back compat easily and so it begs a new class similiar to the non cloud servers.\n\nI'll look at the code when I get a chance though.\n "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13668747",
            "date": "2013-05-28T22:30:44+0000",
            "content": "The way Exceptions are handled in this patch is that each thread \n\nWith a new impl, we should consider how we want to do this carefully. \n\nIf we just go this route, it's really not much better the state the concurrent solrserver is in. This could be a good time to introduce better handling for concurrent solrservers - error detectiong and responses - you really still want to know exactly what happened with your updates, and it's currently very difficult to determine that. It's an improvement we have to get to, and it's probably going to be a back compat headache - perhaps we start by introducing something here and eventually this would become the standard client you want to use. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13668761",
            "date": "2013-05-28T22:43:23+0000",
            "content": "I guess some of that presuposes that since this thing is already multi threaded for adding to multiple servers concurrently, we would eventually also want to make it even more concurrent. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13668927",
            "date": "2013-05-29T02:14:44+0000",
            "content": "This implementation returns all the exceptions that occur as part of the response. You can see each exception and see which server it came from. \n\nIt also returns the routes that were used so you can see which docs were routed to which server. Very useful for testing.\n "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13669185",
            "date": "2013-05-29T12:24:45+0000",
            "content": "Right, but that's not back compat either anyway - so I think we really want consider what the ideal solution is for multi update responses - if we are free to do something new, lets make sure its the right thing going forward. Especially if we end up taking the concurrent* name. There are other issues open about making a concurrent cloud solrserver that works like the concurrent non Solrcloud server. The big sticking point is how responses will work. Someone does have a patch where they have looked at a response plan for this.  This is only semi concurrent in comparison, and so it may not be ideal for this impl to take the concurrent name.\n\nTo me, rather than have a hodge podge of impls, it almost makes more sense to fix the cloud solrserver to hash client side in a fully back compat way, and then tackle a concurrent version that is truly concurrent rather than just concurrent over the set of logical shards. Per has opened a couple issues in the past along those lines.\n\nJust throwing out things for discussion.  "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13669211",
            "date": "2013-05-29T13:04:52+0000",
            "content": "Related issues:\nSOLR-3018: enhance solr to support per-document results in batch mode\nSOLR-3382: Finegrained error propagation (focus on multi-document updates)\nSOLR-445: Update Handlers abort with bad documents\nSOLR-3384: Custom SolrServer chains - mixing SolrServer-subclass properties as you like to\nSOLR-3383: Async responses in SolrJ\n\n\nI think we really want to get CloudSolrServer hashing client side in the short term, but I don't think we want to rush the concurrent impl or a new response format - I think we should do it right and tackle things holistically.\n "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13669225",
            "date": "2013-05-29T13:18:21+0000",
            "content": "Mark,\n\nWhy not just add a a high performance update method to CloudSolrServer. We can document it clearly and people will find it and use it. This way we don't have to worry so much about getting it perfect.\n\nEventually when a new concurrent implementation is ready it can be released.\n\n\n "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13669238",
            "date": "2013-05-29T13:32:12+0000",
            "content": "Why not just add a a high performance update method to CloudSolrServer. \n\nHeh - and now we are back to that. I'm less hesitant about it now that we have come full circle.\n\nI think if the std path does the goodness by default - with non of the multi threading or response changing, I would be fine with another 'high performace' method that did extra stuff and has a new response.\n\nI really don't like the idea of giving up on a good default for CloudSolrServer in 4x - it's fairly easy to get done. Another method is an easy to miss hack I think - this should work nicely within the SolrServer interface.\n\nHow hard would it to be to get a single thread and the same response on the default path - and then add options to enable more threads (and a pretty small runtime change) and the fine grained response? Then we could mark those as experimental options. The default path will hash client side, and options will enable the higher performance / better response? "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13669242",
            "date": "2013-05-29T13:34:03+0000",
            "content": "New patch with ConcurrentUpdateCloudSolrServer extending CloudSolrServer.\n\nA new public update() method has been added that has the following features:\n\n1) Document Routing\n2) Sends requests to shards in parallel\n3) Uses javabin as it's transport.\n "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13669266",
            "date": "2013-05-29T13:59:59+0000",
            "content": "The problem with CloudSolrServer back compat is having the same response.\n\nWe'll be getting back a response from each shard. So do we combine those responses into a single response?\n\nIf we do a single thread we can just throw an exception and be done with it. So that would be backwards compatible.\n\nBut if we go this route I'd like to have an update method with the full performance enhancements as well. My main goal here is to be able to have true linear scalability on Solr Cloud indexing. The javabin enhancement in the latest patch is also important for maximizing Solr Cloud indexing performance.\n "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13669328",
            "date": "2013-05-29T15:02:11+0000",
            "content": "The problem with CloudSolrServer back compat is having the same response.\n\nNot if that response is enabled with a setter? Otherwise you can do the same thing as now.\n\nIf we do a single thread we can just throw an exception and be done with it. So that would be backwards compatible.\n\nRight, that's my point - you could have a single thread by default - it would be back compat - then if you flip a switch, you get a thread per server an N sized thread pool or whatever you are currently doing for this.\n\nBut if we go this route I'd like to have an update method with the full performance enhancements as well.\n\nYou shouldn't need this method exposed if options enable the multi threading.\n\nmaximizing Solr Cloud indexing performance.\n\nI think until you are using more than a single thread per server, you will be very very far from easily maxing performance - which is why the other issues interest me a lot more when considering a concurrency improvement. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13669418",
            "date": "2013-05-29T16:43:12+0000",
            "content": "Thinking about the multiple response issue.\n\nCreating one response from each of the shard responses would be basically the same thing that happens when the routing is done on the Solr servers. I see no reason to not do this.\n\nHere is what I propose:\n\nA CloudSolrServer implementation that by default does document routing with a single merged response. If you flip a switch you get document routing with:\n\n1) Parallel execution, one thread per shard.\n2) A non-backwards compatible response with responses from each shard.\n3) javabin transport.\n\n\n "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13670431",
            "date": "2013-05-30T15:46:06+0000",
            "content": "Latest patch is a version of CloudSolrServer that: \n\n1)Does document routing\n2)Sends requests to each shard in a separate thread\n3) Uses javabin transport \n4) Is backwards compatible with both the response and exception. \n\nIt does this all by default, no switches needed.\n\nThis is accomplished by returning a response or throwing an exception that condenses the info from each shard into a single response or exception.\n\nTo get the full info for the response or exception you can down cast to either RouteReponse or RouteException which gives you a detailed breakdown from each of the shards.\n\nWill update the ticket name and description accordingly.\n "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13670439",
            "date": "2013-05-30T16:04:34+0000",
            "content": "I'll do a review shortly.\n\nIt does this all by default, no switches needed.\n\nexception that condenses the info from each shard into a single response\n\nHow can that be backward compat if people are parsing the response? I'm not convinced you can do all this by default and be back compat, but I'll look at the latest patch.\n\nAnd batch will again have the slight change in runtime behavior.\n\nI still think these extras will need to be off by default until 5. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13670442",
            "date": "2013-05-30T16:08:20+0000",
            "content": "I don't see Routable in the current patch. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13670446",
            "date": "2013-05-30T16:09:44+0000",
            "content": "OK, adding it now. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13670450",
            "date": "2013-05-30T16:12:40+0000",
            "content": "Added Routable.java "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-13670456",
            "date": "2013-05-30T16:16:45+0000",
            "content": "I still think these extras will need to be off by default until 5.\n\n+1.  Even in version 5, it should still be possible to turn them off.  Advanced features (threading in particular) have a tendency to cause subtle bugs, and it's difficult to know if they are bugs in the underlying code or bugs in the advanced feature.  Being able to turn them off will greatly help with debugging.\n\nIMHO, most tests that use CloudSolrServer should randomly turn things like threading on or off, change the writer and parser, etc.  Which reminds me, I need to file an issue and work on a patch for Cloud/LBHttpSolrServer implementations that includes many of the getters/setters from HttpSolrServer. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13670457",
            "date": "2013-05-30T16:16:56+0000",
            "content": "The initial response behaves very much like a response when document routing is done on the server. On the server the Solr instance sends off the docs to the shards to be indexed and then returns a single unified response.\n\nThis does basically the same thing but let's you down cast to get more info if you want to.\n "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-13671182",
            "date": "2013-05-31T05:32:34+0000",
            "content": "Joel Bernstein I was looking into how you switched to the binary writer so I could develop a patch for SOLR-4715.  You've got it creating new writer and parser objects for every HttpSolrServer.  Shouldn't there be one instance of each?  The existing LBHttpSolrServer class shares one parser object for all of the inner HttpSolrServer objects.\n\nI'm struggling a bit on my patch, but if I can find a way to do it, there is some overlap with this issue. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13671728",
            "date": "2013-05-31T18:34:34+0000",
            "content": "Shawn, I haven't had a chance to look at this yet but I suspect you're right. I'll make this change when I next update the patch. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13680393",
            "date": "2013-06-11T14:06:37+0000",
            "content": "Mark, there were a couple of changes I still wanted to make to this ticket:\n\n1) Add a switch to turn on/off threading.\n2) Add a thread pool rather then spawning new threads each request.\n3) Add a few more tests.\n\nBut before I dive in I wanted to be sure we're on the same page.\n\nDoes this design satisfy the back compat issue for the response and exceptions? Are there other show stoppers in this design/implementation that need to be addressed? "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13680409",
            "date": "2013-06-11T14:18:14+0000",
            "content": "1 - yes, I think we need the option of using just one thread. I also think that should be the default until 5x.\n2 - yes, I think a thread pool is the way to go\n3 - always will get a +1 from me on more tests\n\nDoes this design satisfy the back compat issue for the response and exceptions?\n\nI have to review closer - it's on my short list. I think if we can use one thread and the responses have the same format by default, I won't have much concern.\n\nAre there other show stoppers in this design/implementation\n\nI won't know till I look closer, but I don't doubt we will get this in. "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-13680453",
            "date": "2013-06-11T16:24:10+0000",
            "content": "The work I've been doing (slowly) on SOLR-4715 overlaps with this issue.  I've been thinking that I need to divide it into bite-size tasks for my own purposes, but that could possibly help here too.  If I concentrate first on giving LBHttpSolrServer an easy way to set the writer to binary, that would reduce the complexity of this patch quite a bit.  Thoughts? "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-13680682",
            "date": "2013-06-11T21:15:56+0000",
            "content": "Adding setters to LBHttpSolrServer ready to go in SOLR-4919. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13681198",
            "date": "2013-06-12T13:05:44+0000",
            "content": "Shawn, the setter approach is nicer then having to extend LBHttpSolrServer. What are your thoughts on how the two patches could be worked together?  "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-13681290",
            "date": "2013-06-12T14:40:16+0000",
            "content": "I asked Mark Miller to review SOLR-4919 for me.  I think his objection to setters that only work in certain situations is reasonable, but the patch that does it the right way seems to be causing intermittent test failures.  The setter approach seems to not cause any failures.\n\nI don't want to hold up your work here, but it would be very nice if LBHttpSolrServer was more friendly to your changes. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13687080",
            "date": "2013-06-18T19:07:35+0000",
            "content": "New patch, added setter to turn off and on threaded updates, default off.\n\nAdded a thread pool for threaded updates.\n\nRemoved the javabin transport. We can add this when Shawn wraps up his work.  "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13690394",
            "date": "2013-06-21T15:33:05+0000",
            "content": "I'm going to try and review this over the weekend. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13691508",
            "date": "2013-06-23T16:22:56+0000",
            "content": "Are all tests passing for you with the latest patch Joel? My first attempt has a couple tests failing with: org.apache.solr.client.solrj.impl.HttpSolrServer$RemoteSolrException: missing content stream "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13691509",
            "date": "2013-06-23T16:29:39+0000",
            "content": "A couple quick comments:\n\n\n\tIt seems like we don't route delete by id? Why not?\n\tIt doesn't look like the new update path deals with Aliases? We should be sure to hook this up to run sometimes in the alias integration test.\n\tIt only works with CompositeIdRouter? What is the limitation there?\n\n "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13691658",
            "date": "2013-06-24T01:37:58+0000",
            "content": "Mark, I'll check on the test error.\n\nI can add the code to get delete by id routing. \n\nIt looks like aliases should be pretty straight forward to add in as well.\n\nI don't think CloudSolrServer can do document routing with the implicit router. With the implicit router we don't have any information about where to send the document. I think with the implicit router the strategy would be to use the HttpSolrSever and set the baseUrl manually for each document. \n\n\n "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13691660",
            "date": "2013-06-24T01:41:45+0000",
            "content": "I don't think CloudSolrServer can do document routing with the implicit router. With the implicit router we don't have any information about where to send the document. \n\nRight, but thats a pluggable point - we may add more impls, users can write impls - we should be able to route with any imple the same way the back end code does, no? "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13691662",
            "date": "2013-06-24T01:47:46+0000",
            "content": "Ok, I'll change this so it routes all impls but the implicit router. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13692733",
            "date": "2013-06-25T04:34:18+0000",
            "content": "\n\tAdded support for aliases\n\tAdded routing for delete by id's\n\tChanged logic so all router impls but implicit are acceptable for routing.\n\n\n\nThe test error occurs because the CloudSolrServer clears the documents after it performs the updates. It does this because it then executes the non-routable requests such as commit. So this error will only occur if you try issue the same update request again following a request with CloudSolrServer.\n\nI'll fix this tomorrow by using a different approach to executing the non-routables. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13693136",
            "date": "2013-06-25T15:54:50+0000",
            "content": "New patch that passes all existing tests.\n\nRemoved all side effects on the request and also changed how parameters were being passed to routed requests.  "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13699061",
            "date": "2013-07-03T15:06:53+0000",
            "content": "Added tests for UpdateRequestExt document routing and deleteById routing.\n\nAdded test for UpdateRequest deleteById routing "
        },
        {
            "author": "Markus Jelsma",
            "id": "comment-13712241",
            "date": "2013-07-18T11:41:26+0000",
            "content": "Joel, it is working perfectly and already runs fine in one production environment. It's about 30% more efficient when sending data from 20 Hadoop reducers to 10 Solr SSD nodes using routing than the current method. We didn't implement the routable deletes - we're still using SolrServer.deleteById(), seems UpdateRequestExt is not going to be the definitive API to talk to, right?\n\nI assume it won't make it in 4.4 but we should make an effort to get committed to trunk and/or 4.5 some day soon. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13712301",
            "date": "2013-07-18T13:18:02+0000",
            "content": "Markus, thanks for the info. Glad to hear it's working for you in production. \n\nJust wondering if you've turned on parallel updates and what batch size you're using?\n\nI'm thinking that large batch sizes with parallel updates would be very beneficial for performance. That way you would get long stretches of parallel indexing across the cluster.\n\nI suspect that UpdateRequestExt will eventually get folded into UpdateRequest based on the comments in the source.\n\nI'll ping Mark and see what he thinks about getting this committed.   "
        },
        {
            "author": "Markus Jelsma",
            "id": "comment-13712318",
            "date": "2013-07-18T13:22:34+0000",
            "content": "Batch size is about 394 iirc, not very large indeed. I don't think i enabled parallel updates.  "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13712320",
            "date": "2013-07-18T13:23:34+0000",
            "content": "It's def too late for 4.4 (we already branched and the first rc vote is ongoing), but high priority for 4.5. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13712321",
            "date": "2013-07-18T13:24:44+0000",
            "content": "Thanks Mark. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13712323",
            "date": "2013-07-18T13:29:03+0000",
            "content": "Markus,\n\ncloudClient.setParallelUpdates(true);\n\nWill turn on parallel updates, this in theory should give you much better performance. Depending on the size of docs you could probably go with a pretty high batch size. With ten servers a batch size of 5000 would send roughly 500 docs to each server. "
        },
        {
            "author": "Greg Walters",
            "id": "comment-13750177",
            "date": "2013-08-26T16:05:30+0000",
            "content": "After being able to consistently deadlock my SolrCloud cluster I've applied this patch in production and don't have any further issues. +1 on it working. "
        },
        {
            "author": "Markus Jelsma",
            "id": "comment-13751078",
            "date": "2013-08-27T08:31:35+0000",
            "content": "+1 from here as well. We're relying on this and parallel updates to keep load down and it works very well. "
        },
        {
            "author": "Jack Krupansky",
            "id": "comment-13761489",
            "date": "2013-09-08T17:36:45+0000",
            "content": "I was surprised to see that this \"high priority\" is still not committed for 4.5. Although, the actual Jira priority is still listed as \"Minor\". "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13761550",
            "date": "2013-09-08T23:47:20+0000",
            "content": "this \"high priority\" ... Jira ... is still listed as \"Minor\".\n\nMy personal priority list has nothing to do with the severity in JIRA for this issue. I'm assigned and working on this - surprising or not.\n\nI have stated that this is an important issue that is on the road map and that it is high priority for me to get into 4.5. Nothing has changed. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13761647",
            "date": "2013-09-09T06:25:15+0000",
            "content": "Here is my first pass on top of Joel's work. Comments to come. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13761648",
            "date": "2013-09-09T06:29:35+0000",
            "content": "Also, FYI, there are a few remaining issues to smooth out, so a handful of non solrcloud tests in the solrj package are failing. I'll have a second pass up that resolves these remaining issues before long. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13761797",
            "date": "2013-09-09T12:31:39+0000",
            "content": "Awesome! Looks like javabin transport is part of this as well. My earlier tests showed this provided a large performance increase.\n\nAlso looks like you cleaned up the UpdateRequestExt, which is good. \n\nHope to have a chance today to apply the patch and test things out. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13761887",
            "date": "2013-09-09T14:36:11+0000",
            "content": "Here is a cleaned up patch. All tests are passing for me.\n\nI've made some mostly minor changes as well as:\n\n\n\tRemoved UpdateRequestExt and the Router workaround for it.\n\tRandomly enable/disable parallel updates in tests.\n\tAdds SolrCloud javabin support since it was inline with merging UpdateRequestExt into UpdateRequest.\n\tEnables parallel updates by default - the more I have thought about this, the more I've started feeling we should change this default. The minor back compat issue around it is not worth the slow default.\n\n "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13761891",
            "date": "2013-09-09T14:41:33+0000",
            "content": "The patch also has the work fro SOLR-3249: \"Allow CloudSolrServer and SolrCmdDistributor to use JavaBin\", but it does not yet make it the default for CloudSolrServer or switch to it in the SolrCmdDistributor - I have made SOLR-5223 to track that change after this goes in. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13763023",
            "date": "2013-09-10T13:11:26+0000",
            "content": "I'd like to commit this soon so I can more easily noodle around on top of it. It should also make it easier to collaborate on any final tweaks or additions without large dueling patches. I'll leave the issue open for a bit so anyone else has a chance to weigh in. "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-13763072",
            "date": "2013-09-10T14:30:29+0000",
            "content": "Mark Miller The only reason I thought my issue (SOLR-4715) should come first is that I was planning to incorporate some convenience for bit-changing (solrserver, maybe some httpclient) support (including javabin) in a cleaner way (IMHO) than what Joel had done.\n\nIt's now been long enough since I put any work on my patch that I think I'd have to redo it anyway, so feel free to get this in because it's much more important.  I'll revisit my patch afterwards.\n\nI do have one question, the same one I asked early on: Does the parallel indexing support still allow exceptions to (eventually) bubble up the stack to the application, avoiding a repeat of SOLR-3284? "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13763123",
            "date": "2013-09-10T15:35:57+0000",
            "content": "Yes, exceptions are thrown with each batch request.\n\nFor example, if a batch of 10000 docs is sent to 10 servers. The batch is split up into 10 batches, one for each server. Each batch is then sent in it's own thread, while the main thread waits. When all the servers finish indexing the main thread gathers up any exceptions that happened in the request threads, and throws a RouteException, which contains a map of the servers and the exception that occurred. "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-13763804",
            "date": "2013-09-11T01:19:47+0000",
            "content": "Commit 1521713 from Mark Miller in branch 'dev/trunk'\n[ https://svn.apache.org/r1521713 ]\n\nSOLR-4816: CloudSolrServer can now route updates locally and no longer relies on inter-node update forwarding.\nSOLR-3249: Allow CloudSolrServer and SolrCmdDistributor to use JavaBin.\nSOLR-4816: CloudSolrServer now uses multiple threads to send updates by default. "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-13763939",
            "date": "2013-09-11T04:03:07+0000",
            "content": "Commit 1521726 from Mark Miller in branch 'dev/branches/branch_4x'\n[ https://svn.apache.org/r1521726 ]\n\nSOLR-4816: CloudSolrServer can now route updates locally and no longer relies on inter-node update forwarding.\nSOLR-3249: Allow CloudSolrServer and SolrCmdDistributor to use JavaBin.\nSOLR-4816: CloudSolrServer now uses multiple threads to send updates by default. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13764404",
            "date": "2013-09-11T15:22:26+0000",
            "content": "Some recent jenkins failures in org.apache.solr.cloud.SyncSliceTest to look at: https://builds.apache.org/job/Lucene-Solr-Tests-4.x-Java6/ "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-13764436",
            "date": "2013-09-11T16:05:37+0000",
            "content": "As requested via IRC, here is a reminder comment to add sugar methods like setRequestWriter to CloudSolrServer. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13764687",
            "date": "2013-09-11T19:57:19+0000",
            "content": "Just did a fresh 4x pull and org.apache.solr.cloud.SyncSliceTest ran clean for me several times. "
        },
        {
            "author": "Shikhar Bhushan",
            "id": "comment-13765114",
            "date": "2013-09-12T02:50:31+0000",
            "content": "We've run into some issues with CloudSolrServer leaking loads of LBHttpSolrServer's aliveCheckExecutor thread pools with parallelUpdates = true.\n\nThe root cause here is that the RequestTask inner class is creating a new LBHttpSolrServer for each run() rather than utilizing CloudSolrServer.lbServer which is already available to it.\n\nSome detail: LBHttpSolrServer lazily initializes a single-threaded ScheduledExecutorService for the \"aliveCheckExecutor\" when e.g. there is some kind of error talking to a server. So this issue tends to come up when Solr nodes are unavailable and exceptions are thrown. There is also no call to shutdown() on that LBHttpSolrServer which gets created from RequestTask.run(). LBHttpSolrServer does have a finalizer that tries to shutdown the aliveCheckExecutor but there's no guarantee of finalizers executing (or maybe there is some other memory leak preventing that LBHttpSolrServer from being GC'ed at all).\n\nSo the one-liner fix that should definitely go in is to simply have RequestTask use CloudSolrServer.lbServer.\n\nI have attached a patch that removes RequestTask altogether in favor of simply using Callable's and Future's which is much more idiomatic. (RequestTask-removal.patch) "
        },
        {
            "author": "Shikhar Bhushan",
            "id": "comment-13765120",
            "date": "2013-09-12T02:59:46+0000",
            "content": "This is a separate issue but worth noting: CloudSolrServer.shutdown() does not call lbServer.shutdown()\n\nIn case the lbServer is provided as a constructor arg from outside that probably make sense.\n\nBut in case of the constructors where it is created internally, IMO CloudSolrServer should assume ownership and also shut it down. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13765482",
            "date": "2013-09-12T14:43:56+0000",
            "content": "Just did a fresh 4x pull and org.apache.solr.cloud.SyncSliceTest ran clean for me several times.\n\nOh, it passes for me all the time too - it can be hard to match the Apache FreeBSD jenkins runs.\n\n\nAnother fail by the way (I've seen this once locally too, but very rare):\n\nhttps://builds.apache.org/job/Lucene-Solr-NightlyTests-trunk/378/testReport/junit/org.apache.solr.cloud/BasicDistributedZk2Test/testDistribSearch/ "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13765485",
            "date": "2013-09-12T14:44:38+0000",
            "content": "Shikhar,\n\nI ran some data through with the patch you provided and it looks good. I'll do some more testing but so far +1 Shikhar's patch.\n\nMark,\n\nWhen I started testing this morning I found that directUpdates are short circuiting now if params are null. I found this confusing because I was setting collection via the default collection setter on the client. The way this was written before might be less confusing. Before it checked the nonroutableParams.\n\nIn my local build I removed:\n\n if (params == null) {\n      return null;\n    }\n\n\n\nAnd the reverted back to checking the collection with this code:\n\n\n    String collection = nonRoutableParams.get(\"collection\", defaultCollection);\n\n\n\nThis seemed to work well.\n\nI can patch this after you make the call on Shikhar's patch. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13765486",
            "date": "2013-09-12T14:45:24+0000",
            "content": "Thanks Shikhar! "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13765491",
            "date": "2013-09-12T14:48:10+0000",
            "content": "Before it checked the nonroutableParams.\n\nThanks! Yeah, I had tried to go down a different path at one point - I didn't want to have to know which params were routable or not - but of course I quickly hit a wall. Must have missed this one when reverting back. We should try and nail this one with a test. "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-13765695",
            "date": "2013-09-12T17:51:32+0000",
            "content": "Commit 1522684 from Mark Miller in branch 'dev/trunk'\n[ https://svn.apache.org/r1522684 ]\n\nSOLR-4816: Don't create \"loads\" of LBHttpSolrServer's, shutdown LBHttpSolrServer when appropriate, get collection from nonRoutableParams. "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-13765698",
            "date": "2013-09-12T17:53:34+0000",
            "content": "Commit 1522685 from Mark Miller in branch 'dev/branches/branch_4x'\n[ https://svn.apache.org/r1522685 ]\n\nSOLR-4816: Don't create \"loads\" of LBHttpSolrServer's, shutdown LBHttpSolrServer when appropriate, get collection from nonRoutableParams. "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-13765729",
            "date": "2013-09-12T18:19:19+0000",
            "content": "Commit 1522690 from Mark Miller in branch 'dev/branches/lucene_solr_4_5'\n[ https://svn.apache.org/r1522690 ]\n\nSOLR-4816: Don't create \"loads\" of LBHttpSolrServer's, shutdown LBHttpSolrServer when appropriate, get collection from nonRoutableParams. "
        },
        {
            "author": "Shikhar Bhushan",
            "id": "comment-13765739",
            "date": "2013-09-12T18:29:55+0000",
            "content": "Thanks Mark! Also for adding call to lbServer.shutdown() when appropriate.\n\nThis is a really minor thing, but I later realized \n\nfinal Map<String, Future<NamedList<?>>> responseFutures = new HashMap<String, Future<NamedList<?>>>();\n\nis better declared with an initialCapacity as that is known\n\nfinal Map<String, Future<NamedList<?>>> responseFutures = new HashMap<String, Future<NamedList<?>>>(routes.size()); "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-13769799",
            "date": "2013-09-17T18:45:40+0000",
            "content": "Commit 1524170 from Mark Miller in branch 'dev/trunk'\n[ https://svn.apache.org/r1524170 ]\n\nSOLR-4816: deal with leader=null case and init map with known size "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-13769801",
            "date": "2013-09-17T18:46:48+0000",
            "content": "Commit 1524171 from Mark Miller in branch 'dev/branches/branch_4x'\n[ https://svn.apache.org/r1524171 ]\n\nSOLR-4816: deal with leader=null case and init map with known size "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-13769803",
            "date": "2013-09-17T18:47:55+0000",
            "content": "Commit 1524174 from Mark Miller in branch 'dev/branches/lucene_solr_4_5'\n[ https://svn.apache.org/r1524174 ]\n\nSOLR-4816: deal with leader=null case and init map with known size "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13769805",
            "date": "2013-09-17T18:48:52+0000",
            "content": "That should address some of the recent jenkins fails this has caused and addresses Shikhar's last comment. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13769806",
            "date": "2013-09-17T18:49:28+0000",
            "content": "Thanks Joel and Thanks Shikhar! "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-13769812",
            "date": "2013-09-17T18:53:45+0000",
            "content": "Commit 1524176 from Mark Miller in branch 'dev/trunk'\n[ https://svn.apache.org/r1524176 ]\n\nSOLR-4816: add missing CHANGES credit "
        },
        {
            "author": "Markus Jelsma",
            "id": "comment-13769813",
            "date": "2013-09-17T18:53:53+0000",
            "content": "Mark, is it still enabled the same way as Joel's original patches? "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-13769816",
            "date": "2013-09-17T18:55:22+0000",
            "content": "Commit 1524177 from Mark Miller in branch 'dev/branches/branch_4x'\n[ https://svn.apache.org/r1524177 ]\n\nSOLR-4816: add missing CHANGES credit "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13769836",
            "date": "2013-09-17T19:28:27+0000",
            "content": "Parallel threads is now on by default. Document routing works if the right field id is set - it defaults to \"id\". "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-13771219",
            "date": "2013-09-18T20:47:15+0000",
            "content": "I've been looking at recent updates to the ref guide via the commits alias.  One of the more recent pages to receive updates is the one about atomic updates and optimistic concurrency.  It occurred to me that ConcurrentUpdateSolrServer can't be used at all with optimistic concurrency because it won't ever fail, even if the update fails because of a version conflict.\n\nOn topic for this issue: Could optimistic concurrency be used effectively if CloudSolrServer is in parallel thread mode?  I've been assured that it won't swallow exceptions, but would the exception be associated with the correct request?  Exactly how parallel threads works in this update is a mystery to me.\n\nI'm only asking so the documentation can be correct, not to achieve different behavior. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13771236",
            "date": "2013-09-18T21:01:52+0000",
            "content": "You would get an exception that you could trace to one of the servers. The exception itself would have to have the info needed to determine what document failed due to optimistic locking. "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-13780568",
            "date": "2013-09-27T23:27:33+0000",
            "content": "Commit 1527131 from Steve Rowe in branch 'dev/branches/lucene_solr_4_5'\n[ https://svn.apache.org/r1527131 ]\n\nSOLR-4816: add missing CHANGES credit (merged branch_4x r1524177) "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-13781854",
            "date": "2013-09-30T14:25:35+0000",
            "content": "You would get an exception that you could trace to one of the servers. The exception itself would have to have the info needed to determine what document failed due to optimistic locking.\n\nJoel Bernstein - I'm a little confused about how to track failures with CloudSolrServer for update requests. Firstly, the RouteException class is private to CloudSolrServer and cannot be used at all. Secondly, since the responseFutures are per URL, won't two update requests on the same server overwrite the entries? "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13781889",
            "date": "2013-09-30T14:45:59+0000",
            "content": "There is a test case that uses the RouteResponse which has the same access level as RouteException, which works. It may be that this is because of the friendly package access. I'll test both RouteReponse and RouteException outside the package and see if they are accessible.\n\nSecondly, since the responseFutures are per URL, won't two update requests on the same server overwrite the entries?\n\nWhen an exception is thrown from one of the routed servers the batch will terminate on that server. So each URL in RouteException should have only one exception. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13781909",
            "date": "2013-09-30T15:03:39+0000",
            "content": "Let's make a new issue to make these public in 4.6. The tests can access them because they are package private - they should be public and static. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13781937",
            "date": "2013-09-30T15:33:23+0000",
            "content": "I've been mulling over how big an issue this is. If you get a number of exceptions from different servers now, you'd only see one. You'd fix the data and refeed the batch. Then you'd see the next exception and you'd have to fix that. That's no different then how you'd have to work if you had multiple exceptions in a batch on single server. So, I don't think it's such large issue. I agree with Mark's plan. "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13782042",
            "date": "2013-09-30T17:45:02+0000",
            "content": "I've been doing some more testing of the error handling. If CloudSolrServer encounters an error from any of it's shards it gathers them up into a RouteException and throws. This exception extends SolrException and can be treated as such.\n\nWhen getMessage is called, you see a typical update error returned:\n\nERROR: [doc=1100] Error adding field 'test_i'='bad' msg=For input string: \"bad\"\n\nWhat we don't know is which server to check to get the full stack trace. But it doesn't seem like we knew that info in CloudSolrServer prior to this patch. RouteException, when made public, will tell us this.  "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-13782890",
            "date": "2013-10-01T12:45:36+0000",
            "content": "bq, When an exception is thrown from one of the routed servers the batch will terminate on that server. So each URL in RouteException should have only one exception.\n\nGreat, thanks for clarifying that.\n\nbq, Let's make a new issue to make these public in 4.6.\n\n+1 "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13787341",
            "date": "2013-10-05T21:03:41+0000",
            "content": "Hey Joel! Now that you have karma, you can assign this to yourself if you want and Mark doesn't object! "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13787368",
            "date": "2013-10-05T21:45:51+0000",
            "content": "This should be resolved as fixed for 4.5. Any further work should be done in new issues. I'd do it now but I'm on mobile.  "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13787424",
            "date": "2013-10-06T00:17:58+0000",
            "content": "We missed marking this as fixed, it went out in 4.5 as per Mark Miller "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13788202",
            "date": "2013-10-07T15:00:58+0000",
            "content": "I had left this open because some jenkins fails started when it was committed. I addressed a couple of them already though - if anything remains it can get it's own issue for a future release.\n\nThanks a lot for sticking it out so well on this one Joel! "
        },
        {
            "author": "Joel Bernstein",
            "id": "comment-13788246",
            "date": "2013-10-07T15:48:53+0000",
            "content": "No problem, and thanks for all your help on this ticket. "
        },
        {
            "author": "Jessica Cheng Mallet",
            "id": "comment-13792911",
            "date": "2013-10-11T18:22:46+0000",
            "content": "I think the latest patch:\n\n\n\tif (request instanceof IsUpdateRequest && updatesToLeaders) {\n+    if (request instanceof IsUpdateRequest) {\n\n\n\nremoved the effect of the \"updatesToLeaders\" variable. Looking at http://svn.apache.org/viewvc/lucene/dev/branches/lucene_solr_4_5/solr/solrj/src/java/org/apache/solr/client/solrj/impl/CloudSolrServer.java?view=markup it's not used anywhere to make a decision anymore. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13944538",
            "date": "2014-03-23T19:06:55+0000",
            "content": "FYI SOLR-5899: CloudSolrServer's RouteResponse and RouteException should be publicly accessible. "
        }
    ]
}