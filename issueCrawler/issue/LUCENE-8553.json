{
    "id": "LUCENE-8553",
    "title": "New KoreanDecomposeFilter for KoreanAnalyzer(Nori)",
    "details": {
        "components": [
            "modules/analysis"
        ],
        "status": "Open",
        "resolution": "Unresolved",
        "fix_versions": [],
        "affect_versions": "None",
        "labels": "",
        "priority": "Major",
        "type": "New Feature"
    },
    "description": "This is a patch for KoreanDecomposeFilter.\n\nThis filter can be used to decompose Hangul.\n(ex) \ud55c\uae00 -> \u314e\u3131 or \u314e\u314f\u3134\u3131\u3161\u3139)\n\nHangul input is very unique.\n\nIf you want to type apple in English,\n\u00a0\u00a0 you can type it in the order a -> p -> p -> l -> e.\n\nHowever, if you want to input \"Hangul\" in Hangul,\n\u00a0\u00a0 you have to type it in the order of \u314e -> \u314f -> \u3134 -> \u3131 -> \u3161 -> \u3139.\n\u00a0\u00a0 (Because of the keyboard shape)\n\nThis means that spell check with existing full Hangul can be less accurate.\n\n\u00a0\n\nThe structure of Hangul consists of elements such as \"Choseong\", \"Jungseong\", and \"Jongseong\".\n\nThese three elements are called \"Jamo\".\n\nIf you have the Korean word \"\ub41c\uc7a5\ucc0c\uac1c\" (that means Soybean Paste Stew)\n\"Choseong\" means \"\u3137, \u3148, \u3149, \u3131\",\n\"Jungseong\" means \"\u315a, \u314f, \u3163, \u3150\",\n\"Jongseong\" means \"\u3134, \u3147\".\n\nThe reason for Jamo separation is explained above. (spell check)\n\nAlso, the reason we need \"Choseong Filter\" is because many Koreans use \"Choseong Search\" (especially in mobile environment).\nIf you want to search for \"\ub41c\uc7a5\ucc0c\uac1c\" you need 10 typing, which is quite a lot.\nFor that reason, I think it would be useful to provide a filter that can be searched by \"\u3137\u3148\u3149\u3131\".\n\nHangul also has dual chars, such as\n\"\u3132, \u3138, \u3141, \u3143, \u3149, \u315a (\u3157 + \u3163), \u3162 (\u3161 + \u3163), ...\".\n\nFor such reasons,\nKoreanDecompose offers 5 options,\n\nex) \ub41c\uc7a5\ucc0c\uac1c => [\ub41c\uc7a5],\u00a0[\ucc0c\uac1c]\n\n1) ORIGIN\n[\ub41c\uc7a5], [\ucc0c\uac1c]\n\n2) SINGLECHOSEONG\n[\u3137\u3148], [\u3149\u3131] \n\n3) DUALCHOSEONG\n[\u3137\u3148], [\u3148\u3148\u3131] \n\n4) SINGLEJAMO\n[\u3137\u315a\u3134\u3148\u314f\u3147], [\u3149\u3163\u3131\u3150] \n\n5) DUALJAMO\n[\u3137\u3157\u3163\u3134\u3148\u314f\u3147], [\u3148\u3148\u3163\u3131\u3150]",
    "attachments": {
        "LUCENE-8553.patch": "https://issues.apache.org/jira/secure/attachment/12946566/LUCENE-8553.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "id": "comment-16671939",
            "author": "Robert Muir",
            "content": "Can't we just use unicode normalization for this? NFD/NFKD will decompose. ",
            "date": "2018-11-01T17:55:08+0000"
        },
        {
            "id": "comment-16671955",
            "author": "Uwe Schindler",
            "content": "Can't we just use unicode normalization for this? NFD/NFKD will decompose.\n\nThat was my first idea, too. You can also provide an extended mapping like described here with the ICU4J Transformer/Transliterator: http://userguide.icu-project.org/transforms/general\nThere is aso a mapping between Jamo and Hangul. So you just need to use ICUTransformFilter (http://lucene.apache.org/core/7_5_0/analyzers-icu/org/apache/lucene/analysis/icu/ICUTransformFilter.html) and give the rules as described in above documentation, see \"Hangul-Jamo\" as example.\nIMHO, no need for this filter, ICUTransformFilter should do that with correct config: e.g., new ICUTransformFilter(stream, Transliterator.getInstance(\"Hangul-Jamo\")); ",
            "date": "2018-11-01T18:12:08+0000"
        },
        {
            "id": "comment-16672287",
            "author": "Lucene/Solr QA",
            "content": "\n\n\n  -1 overall \n\n\n\n\n\n\n\n\n\n Vote \n Subsystem \n Runtime \n Comment \n\n\n\u00a0\n\u00a0\n\u00a0\n  Prechecks  \n\n\n +1 \n  test4tests  \n   0m  0s \n  The patch appears to include 3 new or modified test files.  \n\n\n\u00a0\n\u00a0\n\u00a0\n  master Compile Tests  \n\n\n +1 \n  compile  \n   0m 34s \n  master passed  \n\n\n\u00a0\n\u00a0\n\u00a0\n  Patch Compile Tests  \n\n\n -1 \n  compile  \n   0m 28s \n  nori in the patch failed.  \n\n\n -1 \n  javac  \n   0m 28s \n  nori in the patch failed.  \n\n\n -1 \n  Release audit (RAT)  \n   0m 28s \n  nori in the patch failed.  \n\n\n -1 \n  Check forbidden APIs  \n   0m 28s \n  nori in the patch failed.  \n\n\n -1 \n  Validate source patterns  \n   0m 28s \n  nori in the patch failed.  \n\n\n\u00a0\n\u00a0\n\u00a0\n  Other Tests  \n\n\n -1 \n  unit  \n   0m  6s \n  nori in the patch failed.  \n\n\n  \n   \n   1m 20s \n   \n\n\n\n\n\n\n\n\n\n Subsystem \n Report/Notes \n\n\n JIRA Issue \n LUCENE-8553 \n\n\n JIRA Patch URL \n https://issues.apache.org/jira/secure/attachment/12946566/LUCENE-8553.patch \n\n\n Optional Tests \n  compile  javac  unit  ratsources  checkforbiddenapis  validatesourcepatterns  \n\n\n uname \n Linux lucene1-us-west 4.4.0-137-generic #163~14.04.1-Ubuntu SMP Mon Sep 24 17:14:57 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux \n\n\n Build tool \n ant \n\n\n Personality \n /home/jenkins/jenkins-slave/workspace/PreCommit-LUCENE-Build/sourcedir/dev-tools/test-patch/lucene-solr-yetus-personality.sh \n\n\n git revision \n master / cf445ba \n\n\n ant \n version: Apache Ant(TM) version 1.9.3 compiled on July 24 2018 \n\n\n Default Java \n 1.8.0_172 \n\n\n compile \n https://builds.apache.org/job/PreCommit-LUCENE-Build/116/artifact/out/patch-compile-lucene_analysis_nori.txt \n\n\n javac \n https://builds.apache.org/job/PreCommit-LUCENE-Build/116/artifact/out/patch-compile-lucene_analysis_nori.txt \n\n\n Release audit (RAT) \n https://builds.apache.org/job/PreCommit-LUCENE-Build/116/artifact/out/patch-compile-lucene_analysis_nori.txt \n\n\n Check forbidden APIs \n https://builds.apache.org/job/PreCommit-LUCENE-Build/116/artifact/out/patch-compile-lucene_analysis_nori.txt \n\n\n Validate source patterns \n https://builds.apache.org/job/PreCommit-LUCENE-Build/116/artifact/out/patch-compile-lucene_analysis_nori.txt \n\n\n unit \n https://builds.apache.org/job/PreCommit-LUCENE-Build/116/artifact/out/patch-unit-lucene_analysis_nori.txt \n\n\n  Test Results \n https://builds.apache.org/job/PreCommit-LUCENE-Build/116/testReport/ \n\n\n modules \n C: lucene/analysis/nori U: lucene/analysis/nori \n\n\n Console output \n https://builds.apache.org/job/PreCommit-LUCENE-Build/116/console \n\n\n Powered by \n Apache Yetus 0.7.0   http://yetus.apache.org \n\n\n\n\n\n\nThis message was automatically generated.\n ",
            "date": "2018-11-01T22:05:27+0000"
        },
        {
            "id": "comment-16673285",
            "author": "Namgyu Kim",
            "content": "Thank you for your comments  Robert Muir, Uwe Schindler.\n\n\u00a0\n\nYes. Both of you are right.\n\nI know that it is possible to do \"Hangul-Jamo\" separation by using ICU.\n\nHowever, I am not sure whether the \"Hangul\" -> \"Choseong\" conversion or \"Dual chars (like\" \u3132 \",\" \u3146 \",\" \u3162 \", ...)\" conversion can be performed in that library.\n\nThese functions are also important features in this TokenFilter and I have used a HashMap or a separated Array to reduce its time complexity.\n\nThat's why I didn't use the ICU library. ",
            "date": "2018-11-02T15:39:51+0000"
        }
    ]
}