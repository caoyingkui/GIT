{
    "id": "SOLR-6968",
    "title": "add hyperloglog in statscomponent as an approximate count",
    "details": {
        "components": [],
        "type": "Sub-task",
        "labels": "",
        "fix_versions": [
            "5.2",
            "6.0"
        ],
        "affect_versions": "None",
        "status": "Closed",
        "resolution": "Fixed",
        "priority": "Major"
    },
    "description": "stats component currently supports \"calcDistinct\" but it's terribly inefficient \u2013 especially in distib mode.\n\nwe should add support for using hyperloglog to compute an approximate count of distinct values (using localparams via SOLR-6349 to control the precision of the approximation)",
    "attachments": {
        "SOLR-6968.patch": "https://issues.apache.org/jira/secure/attachment/12729018/SOLR-6968.patch",
        "SOLR-6968_nosparse.patch": "https://issues.apache.org/jira/secure/attachment/12732599/SOLR-6968_nosparse.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2015-04-29T01:39:02+0000",
            "author": "Hoss Man",
            "content": "\nreally simple straw man implementation using java-hll...\n\nhttps://github.com/aggregateknowledge/java-hll\n\nThe bulk of the current patch is in test refactoring because all the special case conditionals in StatsComponentTest.testIndividualStatLocalParams were driving me insane.\n\nCurrently only cardinality of numeric fields is supported (and even then, only long fields really work \"correctly\").  Current syntax is...\n\n\n/select?q=*:*&stats=true&stats.field={!cardinality=true}fieldname_l\n\n\n\n...but i'm thinking that should change ... there's at least two types of knobs we should support, i'm just not sure which is more important, or if either should be mandatory:\n\n\tAn indication of wether or not hte input is already hashed\n\t\n\t\treading up more on HLL i'm realizing how important it is that the values be hashed (into longs).\n\t\tWe should certainly support on the fly hashing, but for people who plan to compute cardinalities a lot, particularly over large sets or strings, we should also have both:\n\t\t\n\t\t\tan easy way for them to compute those long hashes at index time (simple UpdateProcessor)\n\t\t\ta stats localparam indicate that the field they are computing cardinality over is already hashed\n\t\t\n\t\t\n\t\n\t\n\tprecisions / size tunning\n\t\n\t\tsimilar to how we have an optional \"tdigestCompression\" param we could have an \"hllOptions\" param for overriding the \"log2m\" and \"regwidth\" options\n\t\tor we could require that the value of the \"cardinality\" param be a value indicating how much the user cares about accuracy vs ram (ie: a float between 0 and 1 indicating min ram vs max accurace) and compute log2m+regwidth from those (\"false\" or negative values could disable complete, while \"true\" could be shorthand for some default)\n\t\t\n\t\t\tthis would have the benefit of being something we could continue to support even if a better cardinality algorithm comes along in the future\n\t\t\n\t\t\n\t\n\t\n\n\n\nMy next steps are to focus on more concrete tests & then refactoring to work with other field types, and think about the knobs/configuration as i go. ",
            "id": "comment-14518535"
        },
        {
            "date": "2015-04-30T00:06:32+0000",
            "author": "Hoss Man",
            "content": "\nUpdated patch with basic support for all field types (that are already supported by stats component) and some more tests.  Also SolrJ response object getter method. ",
            "id": "comment-14520564"
        },
        {
            "date": "2015-05-01T16:49:31+0000",
            "author": "Hoss Man",
            "content": "Updated patch with more tests.\n\nMy current TODO list...\n\n\n - 6 < regwidth makes no sense? \n   - even at (min) log2m==4, isn't regwidth==6 big enough for all possible (hashed) long values?\n\n - prehashed support\n   - need to sanity/error check that the field is a long\n   - add an update processor to make this easy to do at index time\n - tunning knobs\n   - memory vs accuracy (log2m)\n     - idea: (least ram) 0 < accuracy < 1 (most accurate)\n       - scale \n   - max cardinality estimatable (regwidth)\n     - perhaps hardcode regwidth==6 ? expert only option to adjust?\n     - pick regwidth based on field type? (int/enum have fewer in general)\n     - pick regwidth based on index stats? max out based on total terms in field?\n       - or for single valued fields: max out based on numDocs\n       - HLL must use same hash seed, but does it support union when log2m and regwidth are diff?\n - convinience equivilence with countDistinct in solrj response obj ?\n\n ",
            "id": "comment-14523434"
        },
        {
            "date": "2015-05-04T18:35:33+0000",
            "author": "Hoss Man",
            "content": "Updated patch now includes an \"HllOptions\" class w/tests for parsing various knobs for tunning...\n\n\n\tcardinality=true and cardinality=false still supported for basic defaults\n\tcan also specify huerstic based cardinality=N where N is a number between 0.0 and 1.0 inclusive indicating how much accuracy you care about\n\t\n\t\t0 == minimum accuracy, conserve as much ram as possible\n\t\t1.0 == maximum accuracy, spend as much ram as possible\n\t\tcardinality=true roughly the same as cardinality=0.33\n\t\n\t\n\tadditional advanced local params for overriding the hueristic based on a knowledge of HLL:\n\t\n\t\thllLog2m=N (raw int passed to HLL API)\n\t\thllRegwidth=N (raw int passed to HLL API)\n\t\t\"hll\" param prefix choosen based on implementation details similar to how percentiles supports tdigestCompression\n\t\t\n\t\t\tif/when we change the implementation details of how we compute cardinality, these can be ignored and new tunning options can be introduced.\n\t\t\n\t\t\n\t\n\t\n\thllPreHashed=BOOL\n\t\n\t\tonly works with Long based fields (by design)\n\t\n\t\n\n ",
            "id": "comment-14527019"
        },
        {
            "date": "2015-05-05T16:53:33+0000",
            "author": "Hoss Man",
            "content": "more updates...\n\n\n\tAdded hueristics for regwidth\n\t\n\t\tslightly reduced default for stats over value sets with 32bit max cardinality (5 vs 6)\n\t\tscaled default further based on cardinality=N float option\n\t\t\n\t\t\tless aggresive scaling on the low end then we have with log2m: cardinality=0.0 gives \"regwidth default - 1\"\n\t\t\twe don't want the huersitc to even generate single bit registers (regwidth==1), instead we lean on the log2m hueristic to be where most of the RAM vs accuracy tunning happens when a float option is used\n\t\t\n\t\t\n\t\n\t\n\tlicense files and misc precommit cleanup\n\n\n\n...i'm working on more involved randomized & distributed tests next. ",
            "id": "comment-14528785"
        },
        {
            "date": "2015-05-07T02:08:27+0000",
            "author": "Hoss Man",
            "content": "Updated patch now includes a TestDistributedStatsComponentCardinality \u2013 which does randomized docs & tunning options with asserts about relative error and consistnecy with prehashed values.\n\ni think this is pretty much good to go \u2013 we can open a distinct issue for adding an UpdateProcessor to support index time murmur3 hashing. ",
            "id": "comment-14531881"
        },
        {
            "date": "2015-05-07T17:59:00+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1678245 from hossman@apache.org in branch 'dev/trunk'\n[ https://svn.apache.org/r1678245 ]\n\nSOLR-6968: New 'cardinality' option for stats.field, uses HyperLogLog to efficiently estimate the cardinality of a field w/bounded RAM ",
            "id": "comment-14533090"
        },
        {
            "date": "2015-05-07T18:43:31+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1678254 from hossman@apache.org in branch 'dev/branches/branch_5x'\n[ https://svn.apache.org/r1678254 ]\n\nSOLR-6968: New 'cardinality' option for stats.field, uses HyperLogLog to efficiently estimate the cardinality of a field w/bounded RAM (merge r1678245) ",
            "id": "comment-14533164"
        },
        {
            "date": "2015-05-13T16:12:41+0000",
            "author": "Hoss Man",
            "content": "Doing some perf testing, i found that the SPARSE representation of HLL can cause some heinous response times for large sets \u2013 a minor part of the issue seems to be the slower insertion rate compared to the FULL representation (documented), but a much bigger factor is that merging multiple (large) SPARSE HLLs is almost 10x slower then merging FULL HLLs of the same size.\n\nit might be worth adding tuning options and/or hueristics to control if/when SPARSE representation should be used (in cases where folks have smaller sets and care more about memory then speed), but for now i'm just going disable it. ",
            "id": "comment-14542172"
        },
        {
            "date": "2015-05-13T16:14:36+0000",
            "author": "Hoss Man",
            "content": "patch that worked well in my perf tests to disable SPARSE (and optimize some ram usage when merging EMPTY) ... will commit once ant precommit test finishes. ",
            "id": "comment-14542173"
        },
        {
            "date": "2015-05-13T16:54:48+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1679241 from hossman@apache.org in branch 'dev/trunk'\n[ https://svn.apache.org/r1679241 ]\n\nSOLR-6968: perf tweak: eliminate use of SPARSE storage option since it has some pathologically bad behavior for some set sizes (particularly when merging shard responses) ",
            "id": "comment-14542228"
        },
        {
            "date": "2015-05-13T17:37:16+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1679250 from hossman@apache.org in branch 'dev/branches/branch_5x'\n[ https://svn.apache.org/r1679250 ]\n\nSOLR-6968: perf tweak: eliminate use of SPARSE storage option since it has some pathologically bad behavior for some set sizes (particularly when merging shard responses) (merge r1679241) ",
            "id": "comment-14542290"
        },
        {
            "date": "2015-06-15T21:44:00+0000",
            "author": "Anshum Gupta",
            "content": "Bulk close for 5.2.0. ",
            "id": "comment-14586887"
        }
    ]
}