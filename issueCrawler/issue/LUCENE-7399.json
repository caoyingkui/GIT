{
    "id": "LUCENE-7399",
    "title": "Speed up flush of points v2",
    "details": {
        "resolution": "Fixed",
        "affect_versions": "None",
        "components": [],
        "labels": "",
        "fix_versions": [
            "6.2",
            "7.0"
        ],
        "priority": "Minor",
        "status": "Closed",
        "type": "Improvement"
    },
    "description": "There are improvements we can make on top of LUCENE-7396 to get ever better flush performance.",
    "attachments": {
        "LUCENE-7399.patch": "https://issues.apache.org/jira/secure/attachment/12821008/LUCENE-7399.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "id": "comment-15399611",
            "author": "Adrien Grand",
            "date": "2016-07-29T16:25:08+0000",
            "content": "Here is a patch, it contains two main improvements:\n\n\tMutablePointsWriter gets packed values from the ByteBlockPool through a BytesRef rather than copying, this saves a lot of memcpy which seems to improve flush time by about 14% on the IndexTaxis benchmark\n\tRadix sort/select gets the ability to detect prefixes that are longer than one byte in a single pass, which seems to help by another 11%, probably by being more cache efficient.\n\n\n\nOverall the flush time of IndexTaxis with a 1GB buffer went down from 19.1 secs to 14.6 secs on my machine (-24%). "
        },
        {
            "id": "comment-15399883",
            "author": "Michael McCandless",
            "date": "2016-07-29T19:22:13+0000",
            "content": "I did before/after test indexing 1.2 B NYC taxi rides with luceneserver (https://github.com/mikemccand/luceneserver) and this patched improved total indexing throughput from 301.9 K docs/sec to 327.6 K docs/sec!\n\nI'll review the patch ... the changes sound great. "
        },
        {
            "id": "comment-15402919",
            "author": "Michael McCandless",
            "date": "2016-08-01T22:13:16+0000",
            "content": "Maybe the visitor should also take BytesRef?  Codec impls could\nread a whole byte[] values block in at once; maybe that's a savings.\nWe can explore that separately in a v3 issue!  We could also fix\nBKDWriter.writeCommonPrefixes to save the copy there, though\nthat's just once per leaf block.\n\nShouldn't the assertHistogram call be called in an assert?  It\nseems to be called directly now.\n\nIt looks like you also removed Sorter.insertionSort in favor of\nbinarySort.  Maybe add a javadoc to Sorter.binarySort saying\nit's O(N^2) and is only used once we have recursed down to <= 20 items\nto sort?\n\nHave you tweaked 20 to see if that's a good value?  Sorting BKD points\nis rather costly since when we swap, we swap whole values (docID,\nmaybe ord, then the byte[] value for this field). "
        },
        {
            "id": "comment-15403594",
            "author": "Adrien Grand",
            "date": "2016-08-02T08:19:17+0000",
            "content": "Here is a new patch, I fixed assertHistogram to be called in an assertion and added the suggested docs.\n\nMaybe the visitor should also take BytesRef? Codec impls could read a whole byte[] values block in at once\n\nI am not sure codecs could leverage this. I think a serious codec impl would do prefix compression to save space, so it could not read large byte[] anyway as it would need to concatenate the shared prefix and the suffix that is specific to the value at every iteration?\n\nWe could also fix BKDWriter.writeCommonPrefixes to save the copy there, though that's just once per leaf block.\n\nI remember trying it out and it didn't help.\n\nHave you tweaked 20 to see if that's a good value? Sorting BKD points is rather costly since when we swap, we swap whole values (docID, maybe ord, then the byte[] value for this field).\n\nI remember tweaking it a long time ago when I worked in this Sorter abstraction, and values in [20,50] looked fine when sorting a simple int[] (so both comparisons and swaps were cheap) so I picked 20 to err on the safe side. It's true it might be different with points that have costly swaps. "
        },
        {
            "id": "comment-15405814",
            "author": "Michael McCandless",
            "date": "2016-08-03T12:08:41+0000",
            "content": "+1\n\nTook me a bit to understand the histograms! "
        },
        {
            "id": "comment-15405875",
            "author": "ASF subversion and git services",
            "date": "2016-08-03T12:48:56+0000",
            "content": "Commit 33197ec98afbd3be8f9bf48aa4556fcbfab3f37e in lucene-solr's branch refs/heads/branch_6x from Adrien Grand\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=33197ec ]\n\nLUCENE-7399: Speed up flush of points. "
        },
        {
            "id": "comment-15405877",
            "author": "ASF subversion and git services",
            "date": "2016-08-03T12:48:58+0000",
            "content": "Commit 9fc4624853d170b5982a0d0c9d9e76a477a2b713 in lucene-solr's branch refs/heads/master from Adrien Grand\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=9fc4624 ]\n\nLUCENE-7399: Speed up flush of points. "
        },
        {
            "id": "comment-15405879",
            "author": "Adrien Grand",
            "date": "2016-08-03T12:50:15+0000",
            "content": "Thanks Mike. "
        },
        {
            "id": "comment-15438982",
            "author": "Michael McCandless",
            "date": "2016-08-26T13:59:18+0000",
            "content": "Bulk close resolved issues after 6.2.0 release. "
        }
    ]
}