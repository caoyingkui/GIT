{
    "id": "SOLR-12658",
    "title": "Extend support for more than 4 field in 'partitionKeys' in ParallelStream after SOLR-11598",
    "details": {
        "labels": "",
        "priority": "Minor",
        "components": [
            "streaming expressions"
        ],
        "type": "Improvement",
        "fix_versions": [],
        "affect_versions": "None",
        "resolution": "Unresolved",
        "status": "Open"
    },
    "description": "SOLR-11598 extended the capabilities for Export handler to have more than 4 fields for sorting.\n\nAs streaming expressions leverages Export handler, ParallelStream allowed maximum 4 fields in \"partitionKeys\" and silently ignored rest of the fields if more than 4 are specified.\n\n HashQParserPlugin:CompositeHash: 347\n\n  private static class CompositeHash implements HashKey {\n\n    private HashKey key1;\n    private HashKey key2;\n    private HashKey key3;\n    private HashKey key4;\n\n    public CompositeHash(HashKey[] hashKeys) {\n      key1 = hashKeys[0];\n      key2 = hashKeys[1];\n      key3 = (hashKeys.length > 2) ? hashKeys[2] : new ZeroHash();\n      key4 = (hashKeys.length > 3) ? hashKeys[3] : new ZeroHash();\n    }\n\n    public void setNextReader(LeafReaderContext context) throws IOException {\n      key1.setNextReader(context);\n      key2.setNextReader(context);\n      key3.setNextReader(context);\n      key4.setNextReader(context);\n    }\n\n    public long hashCode(int doc) throws IOException {\n      return key1.hashCode(doc)+key2.hashCode(doc)+key3.hashCode(doc)+key4.hashCode(doc);\n    }\n  }\n\n\n\nTo make sure we have documents distributed across workers when executing streaming expression parallely, all the fields specified in 'partitionKeys' should be considered in calculating to which worker particular document should go for further processing.\n\nUse-case where having this flexibility would beneficial:\n\n\nparallel(workerCollection,\n         search(collection1, q=*:*, fl=\"id, org, dept, year, month, date, hour\", \n          sort=\"org desc, dept dec, year desc, month desc, date desc, hour desc\", \n          partitionKeys=\"org, dept, year, month\"),\n          workers=\"6\",\n          zkHost=\"localhost:9983\",\n          sort=\"year desc\")\n\n\n\nIn this case, we are partitioning on \"org, dept, year, month\". \nNow look at the data:\norg dept year month date hour\n\norg1 dept1 1991 jan 24 11\norg1 dept1 1991 jan 24 12\norg1 dept1 1991 jan 24 13\n....................\n....................\norg2 dept1 1991 jan 24 11\n\n\n\nFor data to be distributed equally to stated \"6\" workers, 6 respective subsets needs to be created at first place. \nAs we can see in the data, the partition keys specified have two unique sets \n{\"org1 dept1 1991 jan\", \"org2 dept2 1991 jan\"}\n and only 2 workers will be used out of 6. \nAlso, if we look at the data we have documents for \"org1\" are much more than \"org2\", leading to one of workers doing more work than the other; where better partition of data could have optimised the processing of documents.",
    "attachments": {
        "SOLR-12658.patch": "https://issues.apache.org/jira/secure/attachment/12935247/SOLR-12658.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2018-08-11T15:05:19+0000",
            "content": "Attached patch which considers all field values specified under 'partitionKeys' for calculating CompositeHash, responsible for calculating worker a document belongs for processing. ",
            "author": "Amrit Sarkar",
            "id": "comment-16577209"
        },
        {
            "date": "2018-08-11T15:07:20+0000",
            "content": "Next step is to perform benchmarking to make sure there are no performance implications. Will share the results soon. ",
            "author": "Amrit Sarkar",
            "id": "comment-16577210"
        }
    ]
}