{
    "id": "LUCENE-4635",
    "title": "ArrayIndexOutOfBoundsException when a segment has many, many terms",
    "details": {
        "components": [],
        "fix_versions": [
            "3.6.2"
        ],
        "affect_versions": "None",
        "priority": "Major",
        "labels": "",
        "type": "Bug",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "Spinoff from Tom Burton-West's java-user thread \"CheckIndex ArrayIndexOutOfBounds error for merged index\" ( http://markmail.org/message/fatijkotwucn7hvu ).\n\nI modified Test2BTerms to instead generate a little over 10B terms, ran it (took 17 hours and created a 162 GB index) and hit a similar exception:\n\n\nTime: 62,164.058\nThere was 1 failure:\n1) test2BTerms(org.apache.lucene.index.Test2BTerms)\njava.lang.ArrayIndexOutOfBoundsException: 1246\n\tat org.apache.lucene.index.TermInfosReaderIndex.compareField(TermInfosReaderIndex.java:249)\n\tat org.apache.lucene.index.TermInfosReaderIndex.compareTo(TermInfosReaderIndex.java:225)\n\tat org.apache.lucene.index.TermInfosReaderIndex.getIndexOffset(TermInfosReaderIndex.java:156)\n\tat org.apache.lucene.index.TermInfosReader.get(TermInfosReader.java:232)\n\tat org.apache.lucene.index.TermInfosReader.get(TermInfosReader.java:172)\n\tat org.apache.lucene.index.SegmentReader.docFreq(SegmentReader.java:539)\n\tat org.apache.lucene.search.TermQuery$TermWeight$1.add(TermQuery.java:56)\n\tat org.apache.lucene.util.ReaderUtil$Gather.run(ReaderUtil.java:81)\n\tat org.apache.lucene.util.ReaderUtil$Gather.run(ReaderUtil.java:87)\n\tat org.apache.lucene.util.ReaderUtil$Gather.run(ReaderUtil.java:70)\n\tat org.apache.lucene.search.TermQuery$TermWeight.<init>(TermQuery.java:53)\n\tat org.apache.lucene.search.TermQuery.createWeight(TermQuery.java:199)\n\tat org.apache.lucene.search.Searcher.createNormalizedWeight(Searcher.java:168)\n\tat org.apache.lucene.search.IndexSearcher.createNormalizedWeight(IndexSearcher.java:664)\n\tat org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:342)\n\tat org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:330)\n\tat org.apache.lucene.index.Test2BTerms.testSavedTerms(Test2BTerms.java:205)\n\tat org.apache.lucene.index.Test2BTerms.test2BTerms(Test2BTerms.java:154)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\n\n\nThe index actually succeeded building and optimizing, but it was only when we went to run searches of the random terms we collected along the way that the AIOOBE was hit.\n\nI suspect this is a bug somewhere in the compact in-RAM terms index ... I'll dig.",
    "attachments": {
        "LUCENE-4635.patch": "https://issues.apache.org/jira/secure/attachment/12561512/LUCENE-4635.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2012-12-18T16:56:33+0000",
            "content": "I suspect this fixes the issue ... at least CheckIndex on my 162 GB index is getting beyond where it failed previously.\n\nI'll make a separate Test2BPagedBytes test! ",
            "author": "Michael McCandless",
            "id": "comment-13535042"
        },
        {
            "date": "2012-12-18T19:01:33+0000",
            "content": "New patch, with test, and fixing another place where we could overflow int.\n\nI think it's ready. ",
            "author": "Michael McCandless",
            "id": "comment-13535163"
        },
        {
            "date": "2012-12-18T21:02:54+0000",
            "content": "In general we should do a review/better testing of this pagebytes. \n\nStuff like whats going on in copy() really scares me. \n\nBut for now I think you should commit. Even if all of pagedbytes isnt totally safe, we should at least fix the terms index problems in 3.6.2 that it causes.\n\nI also think we should go for a 3.6.2 when this is fixed. We already have a nice amount of bugfixes sitting out there in the branch. ",
            "author": "Robert Muir",
            "id": "comment-13535317"
        },
        {
            "date": "2012-12-18T23:33:11+0000",
            "content": "OK turns out this same issue was fixed in LUCENE-4568 for 4.x/5.x ... we just never backported to 3.6.x. ",
            "author": "Michael McCandless",
            "id": "comment-13535449"
        },
        {
            "date": "2012-12-18T23:47:27+0000",
            "content": "[branch_4x commit] Michael McCandless\nhttp://svn.apache.org/viewvc?view=revision&revision=1423718\n\nLUCENE-4635: add test ",
            "author": "Commit Tag Bot",
            "id": "comment-13535467"
        },
        {
            "date": "2012-12-18T23:52:53+0000",
            "content": "4.x/5.x were already fixed ...\n\nThanks Tom! ",
            "author": "Michael McCandless",
            "id": "comment-13535472"
        },
        {
            "date": "2012-12-18T23:56:27+0000",
            "content": "[trunk commit] Michael McCandless\nhttp://svn.apache.org/viewvc?view=revision&revision=1423720\n\nLUCENE-4635: add test ",
            "author": "Commit Tag Bot",
            "id": "comment-13535476"
        },
        {
            "date": "2012-12-20T11:01:05+0000",
            "content": "I ran Test10BTerms (just Test2BTerms but multiply the number of terms by 5, and increase token len by 1) on 4.x and it passed!\n\nIt was faster (14 hours vs I thikn 17 hours for 3.6.x), and index was smaller (129G vs 162G). ",
            "author": "Michael McCandless",
            "id": "comment-13536944"
        },
        {
            "date": "2012-12-22T01:29:11+0000",
            "content": "Woops!  Thanks Steve.\n\nMike McCandless\n\nhttp://blog.mikemccandless.com\n ",
            "author": "Michael McCandless",
            "id": "comment-13538629"
        },
        {
            "date": "2013-05-10T10:34:05+0000",
            "content": "Closed after release. ",
            "author": "Uwe Schindler",
            "id": "comment-13654119"
        }
    ]
}