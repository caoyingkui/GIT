{
    "id": "SOLR-6517",
    "title": "CollectionsAPI call REBALANCELEADERS",
    "details": {
        "affect_versions": "5.0,                                            6.0",
        "status": "Closed",
        "fix_versions": [
            "5.0",
            "6.0"
        ],
        "components": [],
        "type": "New Feature",
        "priority": "Major",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "Perhaps the final piece of SOLR-6491. Once the preferred leadership roles are assigned, there has to be a command \"make it so Mr. Solr\". This is something of a placeholder to collect ideas. One wouldn't want to flood the system with hundreds of re-assignments at once. Should this be synchronous or asnych? Should it make the best attempt but not worry about perfection? Should it???\n\na collection=name parameter would be required and it would re-elect all the leaders that were on the 'wrong' node\n\nI'm thinking an optionally allowing one to specify a shard in the case where you wanted to make a very specific change. Note that there's no need to specify a particular replica, since there should be only a single preferredLeader per slice.\n\nThis command would do nothing to any slice that did not have a replica with a preferredLeader role. Likewise it would do nothing if the slice in question already had the leader role assigned to the node with the preferredLeader role.",
    "attachments": {
        "SOLR-6517.patch": "https://issues.apache.org/jira/secure/attachment/12674437/SOLR-6517.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Erick Erickson",
            "id": "comment-14153718",
            "date": "2014-09-30T20:31:21+0000",
            "content": "Mark Miller Noble Paul Shalin Shekhar Mangar I know you guys have been in this code a LOT, I'd appreciate any comments before I get too far into mucking around in code that's\na> complex and\nb> easy to mess up \n\nI thought I'd ask if this has any possibility of working. I'll be pursuing this no matter what, and if the conclusion is it's a horrible idea I'll chalk it up to a \"learning experience\" .\n\nAll I'm looking for here is whether this seems like a reasonable approach, I'm digging into details of how to make it happen.\n\nAssuming SOLR-6512 (assign property to a replica, preferredLeader in this case) and SOLR-6513 (distribute a unique property for one replica for each shard in a collection evenly across all the nodes hosting any replicas for that collection) are committed, I'm left with the leader-re-election problem. Each slice will have one (and only one) replica with a property \"preferredLeader:true\".\n\nWhen a node joins the election process (LeaderElector.joinElection), it could insert itself at the head of the list if preferredLeader==true. I'm looking at the LeaderElector class. There's the very interesting method: joinElection(ElectionContext context, boolean replacement,boolean joinAtHead). \n\nI'm particularly interested in the \"joinAtHead\" parameter, seems like it's exactly what I need. If this method were to look at the properties for the replica and join at head if the preferredLeader property was set, it seems ideal. It also seems like the action of re-distributing the preferred leaders command becomes triggering the leader election process for all the replicas in the collection that are currently leaders but don't have the preferredLeader property set (and some other replica for that slice does). Essentially this is a \"Hey you, stop being the leader now\" call. The rest is automatic. I hope.\n\nOf course I'll have to throttle the re-election process, don't want 50 leaders being reelected at once. How is TBD.\n\nI've done some preliminary testing and this seems to fit the bill for my needs, I'll be working up a patch sometime Real Soon Now for your delectation unless anyone sees gaping holes in the approach.\n\nOne thing I did note  in joinElection (about line 252 on trunk). The string we  create the new leader sequence from is:\nString firstInLine = nodes.get(1);\n\nSeems like it should be \nString firstInLine = nodes.get(0);\n\nProblem is, say I have the sequence numbers \nnode1-0\nnode2-1\n\nand I do the joinElection bit with joinAtHead=true (which I don't think we ever do actually). Then I wind up  with\nnode1-0\nnode2-1\nnode3-1\n\nI'll change it unless there's a good reason not to. "
        },
        {
            "author": "Noble Paul",
            "id": "comment-14154248",
            "date": "2014-10-01T02:28:49+0000",
            "content": "I am confused by the 'sliceUnique' feature.  What is the harm if I set two preferredLeaders? All that Solr needs to do is , just choose any one who is available. Users would prefer this. They can set choose 2 nodes and even if one goes down the other can take up the role. This is how overseer roles is set. I can set as many nodes as overseers\n\nAnother point I want to bring in is consistency in naming. We have something called overseer role for \"preferred overseers\" . We would need to make the naming consistent for these two features.\n\nI'm particularly interested in the \"joinAtHead\" parameter, seems like it's exactly what I need...\n\nThe joinAtHead is a part of the overseer role feature. Please read through SOLR-6095 to know how it works \n\nIt is explained well here https://issues.apache.org/jira/browse/SOLR-6095?focusedCommentId=14032386&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14032386 "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-14154339",
            "date": "2014-10-01T04:43:21+0000",
            "content": "Hmmm, the discussion at SOLR-6095 will serve me in good stead, thanks. \n\nLet's take this a bit at a time.\n\nbq: I am confused by the 'sliceUnique' feature. What is the harm if I set two preferredLeaders? \n\nSee the discussion at SOLR-6491 about why sysadmins need to impose some order. This is not an absolute thing, IOW if the preferred leader isn't electable, we'll fall back to the current election process. What we're talking about here is shard leadership and relieving hotspots that are a consequence of the current algorithm for electing shard leaders. Note that in tandem is SOLR-6513, which automatically assigns exactly one sliceUnique role per slice across all the physical nodes that host that collection. preferredLeader is a property that a-priori has this restriction. Other properties can be sliceUnique as well (or not, for properties other than preferredLeader this is up to the user).\n\nbq: All that Solr needs to do is , just choose any one who is available. Users would prefer this.\n\nI can put you in touch with users of large, complex installations who will explicitly disagree, see the discussion at SOLR-6491. Again, there's no requirement at all that any installation have anything to do at all with the preferred leader role, in which case Solr's behavior will be unchanged. The user has to either 1> assign the preferredLeader property or 2> use the (new) command to balance a property, one per shard, across all the nodes in a collection (see SOLR-6513).\n\nbq: They can set choose 2 nodes and even if one goes down the other can take up the role. This is how overseer roles is set. I can set as many nodes as overseers\n\nI'm totally unclear here. There can be only one leader per slice. And there's nothing about the special preferredLeader property that prevents this, if the preferredLeader is unavailable the current election process is followed.\n\nbq: The joinAtHead is a part of the overseer role feature.\n\nEither I'm hallucinating or it's also part of shard leadership election. I confess I hadn't tracked down why I was hitting LeaderElector.joinElection twice when bringing up a replica, now I know why. Once for adding an ephemeral node for overseer election, and again for adding an ephemeral node for shard-leader election. Very good to know so I don't screw up the overseer election! The discussion you pointed to looks like it's the model I'll look into for this bit as well. "
        },
        {
            "author": "Noble Paul",
            "id": "comment-14154720",
            "date": "2014-10-01T12:10:03+0000",
            "content": "\nLet me try to explain how I think of the feature\n\n\n\tA user wants to move the shard leader to a particular replica and he invokes a action=SETREPLICAPROP&prop=prefrerredLeader&val=true . Here I should be able to pass a param \"sliceUnique=true\" which will remove the property from other replicas if the param is not passed two replicas will have the same value\n\tWhen this command is invoked it can act exactly like the overseer role command   .If there are more than one preferred leaders choose whichever is available/first in the queue\n\tThis kicks in when a down replica comes back up also\n\n "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-14154963",
            "date": "2014-10-01T15:42:32+0000",
            "content": "bq: A user wants to move the shard leader to a particular replica and he invokes a action=SETREPLICAPROP&prop=prefrerredLeader&val=true . Here I should be able to pass a param \"sliceUnique=true\" which will remove the property from other replicas if the param is not passed two replicas will have the same value\n\nThis is exactly what happens with one twist. \"preferredLeader\" is a known property that automatically enforces the sliceUnique=true parameter. All other properties' uniqueness are completely under the control of the user. sliceUnique defaults to 'false'.\n\nI don't see the practical use of having multiple preferred leaders per slice. I can imagine having a weight attached to the property governing where it inserted itself in the ephemeral node list, but that's a complexity I'll save for another JIRA I think .\n\nedit - Or perhaps we'll add the ability to define multiple preferred leader properties per slice at some point in the future. How that interacts with SOLR-6513 where the property is auto-balanced amongst all nodes is an open question that I don't want to address right now. \"progress, not perfection\" and all that. "
        },
        {
            "author": "Noble Paul",
            "id": "comment-14155088",
            "date": "2014-10-01T16:45:05+0000",
            "content": "This is exactly what happens with one twist. \"preferredLeader\" is a known property that automatically enforces the sliceUnique=true \n\nYes, I saw it in the code and that is why I am asking why don't we push the option to a request param and the users get the power of choosing multilple preferred leaders and if one shard goes down the other can clearly take up the that role "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-14155266",
            "date": "2014-10-01T18:39:52+0000",
            "content": "bq: I am asking why don't we push the option to a request param and the users get the power of choosing multilple preferred leaders and if one shard goes down the other can clearly take up the that role\n\nBecause I feel it's an unnecessary complexity that doesn't add enough value to justify doing it now. Leadership election will still occur if the preferred leader is down, just as it does not. Additionally auto-assigning the property becomes harder if multiples are allowed. "
        },
        {
            "author": "Noble Paul",
            "id": "comment-14155277",
            "date": "2014-10-01T18:46:02+0000",
            "content": "ecause I feel it's an unnecessary complexity that doesn't add enough value to justify doing it now\n\nActually it is much simpler. If you look at the overseer roles implementation , you can figure it has not added any complexity "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-14161096",
            "date": "2014-10-06T22:07:45+0000",
            "content": "bq: Actually it is much simpler. If you look at the overseer roles implementation , you can figure it has not added any complexity\n\nI won't argue whether the code is more or less complex if there is more than one preferredLeader property is allowed per slice. I will argue that allowing this servers little practical purpose. It would also certainly make the \"redistribute the preferredLeader for collection X\" more complicated. And, IMO, confuse the functionality as far as the end users are concerned.\n\nSince slice leadership is required to be one-per-slice, it's more consistent to do the same with the preferredLeader property I think. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-14168847",
            "date": "2014-10-12T23:44:30+0000",
            "content": "Reviewboard here: https://reviews.apache.org/r/26632/\n\n\nHere's a patch for people to poke holes in. It is NOT ready to commit. I started out with a really simple throttling mechanism and then went to a more sophisiticated one. I wanted folks to have an opportunity to critique both approaches, so they're both in this patch. Of course I'll pull one out before committing.\n\nThe meat of the differences are in collectionsHandler.handleReassignLeadersA and collectionsHandler.handleReassignLeadersB. Of the two, the B variant is my favorite by far. I hope to commit this late next week...\n\nIn one approach (the original crude one, see collectionsHandler.handleReassignLeadersA), the parameter \"maxToReassign\" just queues up the indicated number of leader reassignments and returns when they are done. maxToReassign defaults to Integer.MAX_VALUE. The process here would be to keep reassigning, say, 5 leaders until the collection was balanced. But the onus is on the consumer to figure out when enough were done.\n\nThe other mode, collectionsHandler.handleReassignLeadersB also takes \"maxToReassign\", but in this flavor it's the number of outstanding reassignments to allow at once; defaults to Integer.MAX_VALUE. When the limit is reached, the process waits until at least one of them completes, then queues up enough to get back to that max. QUESTION: Is there a better way to find out when an async process is done besides the poll/sleep loop in collectionsHandler.waitForLeaderChange?\n\nAdditionally in this mode,  maxToReassignWait is the number of seconds to wait for reassignment to complete before giving up. It's a bail-out so the call isn't stuck forever. Default value is 30 seconds. It's a little loose in that even if it returns, the process may still be going on and eventually complete even if it bails out.\n\nI should emphasize that only one of the methods will make it to the final patch, almost certainly the second one unless there are howls.\n\nThere's quite a bit of information returned in the result set, which is another advantage of the second method. There's an example below, although it lacks the \"failures\" node because there weren't any...:\n\nI should also emphasize that I'm sure stuff will pop out when I look at it fresh tomorrow, but the current form is enough to have people look at and poke holes in.\n\nErick\n\nSample response (note, I'll get rid of the \"reassignleaders_\" prefix).\n\n<response>\n  <lst name=\"responseHeader\">\n    <int name=\"status\">0</int>\n    <int name=\"QTime\">523</int>\n  </lst>\n  <lst name=\"successes\">\n    <lst name=\"reassignleaders_eoe_shard1_replica3\">\n      <str name=\"status\">success</str>\n      <str name=\"msg\">\n        Assigned 'Collection: 'eoe', Shard: 'shard1', Core: 'eoe_shard1_replica3', BaseUrl:\n        'http://192.168.1.201:7600/solr'' to be leader\n      </str>\n    </lst>\n    <lst name=\"reassignleaders_eoe_shard2_replica4\">\n      <str name=\"status\">success</str>\n      <str name=\"msg\">\n        Assigned 'Collection: 'eoe', Shard: 'shard2', Core: 'eoe_shard2_replica4', BaseUrl:\n        'http://192.168.1.201:7300/solr'' to be leader\n      </str>\n    </lst>\n    <lst name=\"reassignleaders_eoe_shard3_replica4\">\n      <str name=\"status\">success</str>\n      <str name=\"msg\">\n        Assigned 'Collection: 'eoe', Shard: 'shard3', Core: 'eoe_shard3_replica4', BaseUrl:\n        'http://192.168.1.201:7400/solr'' to be leader\n      </str>\n    </lst>\n    <lst name=\"reassignleaders_eoe_shard4_replica4\">\n      <str name=\"status\">success</str>\n      <str name=\"msg\">\n        Assigned 'Collection: 'eoe', Shard: 'shard4', Core: 'eoe_shard4_replica4', BaseUrl:\n        'http://192.168.1.201:8983/solr'' to be leader\n      </str>\n    </lst>\n    <lst name=\"reassignleaders_eoe_shard6_replica3\">\n      <str name=\"status\">success</str>\n      <str name=\"msg\">\n        Assigned 'Collection: 'eoe', Shard: 'shard6', Core: 'eoe_shard6_replica3', BaseUrl:\n        'http://192.168.1.201:7500/solr'' to be leader\n      </str>\n    </lst>\n  </lst>\n  <lst name=\"alreadyLeaders\">\n    <lst name=\"core_node21\">\n      <str name=\"status\">success</str>\n      <str name=\"msg\">Already leader</str>\n      <str name=\"nodeName\">192.168.1.201:7200_solr</str>\n    </lst>\n  </lst>\n</response> "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-14173749",
            "date": "2014-10-16T13:46:48+0000",
            "content": "I think it's ready! I'll commit this probably sometime tomorrow. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-14175109",
            "date": "2014-10-17T14:49:06+0000",
            "content": "Final patch with CHANGES.txt entry. Committing momentarily "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14175217",
            "date": "2014-10-17T16:34:38+0000",
            "content": "Commit 1632628 from Erick Erickson in branch 'dev/branches/branch_5x'\n[ https://svn.apache.org/r1632628 ]\n\nSOLR-6517: CollectionsAPI call REBALANCELEADERS "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-14175218",
            "date": "2014-10-17T16:35:56+0000",
            "content": "Forgot to mention the JIRA when I committed the trunk version. SVN revision for trunk is: 1632594 .\n\nI thought the -m param on commit looked a little wrong.... Siiigggh. "
        },
        {
            "author": "Noble Paul",
            "id": "comment-14188559",
            "date": "2014-10-29T16:49:38+0000",
            "content": "I'm trying to understand how the REBALANCLEADERS command work. Is there is a small writeup on the sequence of operations performed when this command is invoked  "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-14188690",
            "date": "2014-10-29T17:58:55+0000",
            "content": "There's some information here:\nhttps://cwiki.apache.org/confluence/display/solr/Collections+API#CollectionsAPI-RebalanceLeaders\n\nBasically, though, it just queues up Overseer.OverseerAction.LEADER commands. There's a little bit of overloading here. CollectionsHandler.handleBalanceLeaders does the throttling of how many outstanding requests there are, and OverseerCollectionsProcessor.processAssignLeaders just queues up a Overseer.OverseerAction.LEADER call for the Overseer to execute.\n\nYeah, as the notes above indicate I'm perfectly aware that I should mention the JIRA in the message, just managed to forget once. "
        },
        {
            "author": "Noble Paul",
            "id": "comment-14188703",
            "date": "2014-10-29T18:06:56+0000",
            "content": "how is the leader election changed? How does it ensure that the \"preferredLeader\" gets elected? "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-14188733",
            "date": "2014-10-29T18:20:22+0000",
            "content": "First, there aren't any guarantees here, it tries its best. For instance, the node may be down etc...\n\nBarring that though, it's pretty straightforward. The meat of the processing is in\ncollecitonsHandler.handleBalanceLeaders.\n\nget the DocCollection from the cluster state.\nfor each slice {\n  for each replica \n{\n     if (the replica is active and NOT the leader and has the preferredLeader property set) queue it up to become the leader\n  }\n}\n\nThere's some bookkeeping here to respect the various parameters about how many to reassign at once and how long to wait (maxAtOnce and maxWaitSeconds) as well as construct a pretty response giving all the info it can. This latter is one benefit of the heavy lifting being in collectionsHandler rather than over in the Overseer. "
        },
        {
            "author": "Noble Paul",
            "id": "comment-14188746",
            "date": "2014-10-29T18:27:07+0000",
            "content": "(the replica is active and NOT the leader and has the preferredLeader property set) queue it up to become the leader \n\nWhat happens to the node that is leader already? evicted?\n\nWhat happens to other nodes in the queue? "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-14188976",
            "date": "2014-10-29T20:51:22+0000",
            "content": "bq: What happens to the node that is leader already?\nnothing, it's already the leader, what purpose would be served by changing anything?\n\nbq: What happens to other nodes in the queue?\nNot sure what you're asking here. The trick is that if a replica has the preferredLeader property set LeaderElector.joinElection is called with joinAtHead set to true. So it's next up in the list when the leadership is changed. The rest of the nodes are still in the queue though, ready to take over if the preferredLeader goes away.\n "
        },
        {
            "author": "Noble Paul",
            "id": "comment-14189635",
            "date": "2014-10-30T04:37:00+0000",
            "content": "Sorry for being a pain in the butt\n\nI'm exactly looking for LeaderElector.joinElection  call and I don't see where it is done.  "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-14189661",
            "date": "2014-10-30T05:23:45+0000",
            "content": "Well, I didn't tell you . Actually, I'm glad someone with more experience here is looking....\n\nIt's a little subtle in that it has nothing to do with REBALANCELEADERS, it's done at core registration time. The side effect here is that the cluster will tend to the desired state on that basis alone. It may even be that the sledgehammer of REBALANCELEADERS is made less necessary.....\n\nAnyway, look in ZkController.register...\n      // If we're a preferred leader, insert ourselves at the head of the queue\n      boolean joinAtHead = false;\n      Replica replica = zkStateReader.getClusterState().getReplica(desc.getCloudDescriptor().getCollectionName(), coreZkNodeName);\n      if (replica != null) \n{\n        joinAtHead = replica.getBool(Overseer.preferredLeaderProp, false);\n      }\n      joinElection(desc, afterExpiration, joinAtHead);\n "
        },
        {
            "author": "Noble Paul",
            "id": "comment-14189750",
            "date": "2014-10-30T07:33:38+0000",
            "content": "Thanks, got it.\n\nSo what is the command REBALANCELEADERS doing ? "
        },
        {
            "author": "Noble Paul",
            "id": "comment-14189752",
            "date": "2014-10-30T07:38:32+0000",
            "content": "Why can't I specify a 'slice' only to rebalance? "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-14190168",
            "date": "2014-10-30T14:53:42+0000",
            "content": "bq: So what is the command REBALANCELEADERS doing ?\nPerhaps nothing if all the nodes with preferredLeader=true are already leaders. But just because a node inserts itself at the head of the queue does not mean its the leader, that operation puts it just after the current leader, i.e. \"next in line\". It'll only become the leader at if the current leader goes down for some reason. So REBALANCELEADERS will cause any shard  where the current leader is not the preferredLeader to re-elect leadership.\n\nbq: Why can't I specify a 'slice' only to rebalance?\nNo technical reason at all. I didn't need that capability, my specific task was on a collection-wide basis. There's no reason that couldn't be an optional parameter though, it'd be simple to do so feel free if there's a real-world use-case you need to support. But for the situation I'm looking at, there may be 10s to 100s of slices, so it'd be tedious to do them one at a time, not to mention error-prone. "
        },
        {
            "author": "Noble Paul",
            "id": "comment-14193752",
            "date": "2014-11-02T08:06:44+0000",
            "content": "So REBALANCELEADERS will cause any shard where the current leader is not the preferredLeader to re-elect leadership.\n\nAs I see in the code code it just sends a message to overseer to change the leader of the shard.  "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-14193930",
            "date": "2014-11-02T17:40:37+0000",
            "content": "Yep. I'm not sure what you're concerned about. Do you see a problem?\n\nREBALANCELEADERS   does, indeed, do just that, there's no real magic here.\n\nLook at the code in ZkController.register if you're wondering how preferredLeaders join at the head of the queue. "
        },
        {
            "author": "Noble Paul",
            "id": "comment-14194476",
            "date": "2014-11-03T11:52:49+0000",
            "content": "Yes, there is a problem, it will not work,\n\nIdeally you should trigger the re-lection process by invoking joinElection() with joinAtHead=true . That is what the ADDROLE and role=overseer command does "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-14194635",
            "date": "2014-11-03T15:43:11+0000",
            "content": "Well, it's worked in every test, both manual and automated that I've run so far. Do you have a failure that demonstrates this?\n\nMaybe a mismatch in expectations? REBALANCELEADERS does not, and was not designed to, force the rebalancing immediately for nodes that do not have the preferredLeader property already set. It simply makes leaders out of those nodes that already have the preferredLeader property set and are not currently the leader.\n\nSo to rebalance the leaders across the cluster, you first need to BALANCESHARDUNIQUE with the preferredLeader property and then issue the REBALANCELEADERS command. That way it's not required that the entire cluster be balanced, you can selectively assign some preferredLeaders if you want.\n\nOr am I missing the boat completely? How do you see it \"not working\"? "
        },
        {
            "author": "Noble Paul",
            "id": "comment-14194644",
            "date": "2014-11-03T15:49:57+0000",
            "content": "From the code , what I see is , a message is sent to overseer to change the leader. But there is no action performed to change the actual election queue. The role in the clusterstate is just a reflection of what should be there in the election queue and not the other way around.  "
        },
        {
            "author": "Noble Paul",
            "id": "comment-14194701",
            "date": "2014-11-03T16:33:21+0000",
            "content": "Unfortunately, solrcloud failures are hard to reproduce and fix. We need to put extra care while making changes to  cloud . I've spent weeks debugging the overseer roles feature because it only failed in our 120 node cluster (never in the junit tests)  "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-14194761",
            "date": "2014-11-03T17:31:44+0000",
            "content": "Gah. OK, the fact that the state information isn't reflective of the actual state is what was throwing me.\n\nLet's move any further discussion over to SOLR-6691 (which I just created). I've tried to synopsize the discussion in that JIRA.\n\nThanks for your patience in explaining, mucking around in the cloud state kinda scares me... apparently for good reason. "
        },
        {
            "author": "Anshum Gupta",
            "id": "comment-14333004",
            "date": "2015-02-23T05:03:02+0000",
            "content": "Bulk close after 5.0 release. "
        }
    ]
}