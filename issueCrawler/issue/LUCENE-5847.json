{
    "id": "LUCENE-5847",
    "title": "Improved implementation of language models in lucene",
    "details": {
        "type": "Improvement",
        "priority": "Minor",
        "labels": "",
        "resolution": "Unresolved",
        "components": [
            "core/search"
        ],
        "affect_versions": "None",
        "status": "Open",
        "fix_versions": [
            "6.0"
        ]
    },
    "description": "The current implementation of language models in lucene is based on the paper \"A Study of Smoothing Methods for Language Models Applied to Ad Hoc Information Retrieval\" by Zhai and Lafferty ('01). Specifically, LMDiricheltSimilarity and LMJelinikMercerSimilarity use a normalized smoothed score for a matching term in a document, as suggested in the above mentioned paper.\n\nHowever, lucene doesn't assign a score to query terms that do not appear in a matched document. According to the \"pure\" LM approach, these terms should be assigned with a collection probability \"background score\". If one uses the Jelinik Mercer smoothing method, the final result list produced by lucene is rank equivalent to the one that would have been created by a full LM implementation. However, this is not the case for Dirichlet smoothing method, because the background score is document dependent. Documents in which not all query terms appear, are missing the document-dependant background score for the missing terms. This component affects the final ranking of documents in the list.\n\nSince LM is a baseline method in many works in the IR research field, I attach a patch that implements a full LM in lucene. The basic issue that should be addressed here is assigning a document with a score that depends on all the query terms, collection statistics and the document length. The general idea of what I did is adding a new getBackGroundScore(int docID) method to similarity, scorer and bulkScorer. Than, when a collector assigns a score to a document (score = scorer.score()) I added the backgound score (score=scorer.score()+scorer.background(doc)) that is assigned by the similarity class used for ranking. \n\nThe patch also includes a correction of the document length such that it will be the real document length and not the encoded one. It is required for the full LM implementation.",
    "attachments": {
        "LUCENE-2507.patch": "https://issues.apache.org/jira/secure/attachment/12657831/LUCENE-2507.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "id": "comment-14079387",
            "author": "Ryan Ernst",
            "content": "Why can't the background score be implemented in the specific scorers for Dirichlet or JM? I don't think the Scorer interface should be cluttered with something specific to one implementation. ",
            "date": "2014-07-30T15:37:17+0000"
        },
        {
            "id": "comment-14084078",
            "author": "Hadas Raviv",
            "content": "Implementing a specific scorer for Dirichlet or JM is problematic in my opinion, since language models can be used for calculating a ranking score in response to a BooleanQuery composed of several terms, TermQuery composed of a single term or SpanQuery composed of near by terms. In order to have the correct score for each of the query types, multiple specific scorers should be implemented. This would mean that we would have BackgroundAwareBooleanScorer , BackgroundAwareTermScorer  etc. Effectively, it would duplicate many existing scorers. If anyone has a suggestion for a design that does not duplicate scorers while keeping the scorer interface unchanged please share and I will try to implement it.    ",
            "date": "2014-08-03T18:30:46+0000"
        }
    ]
}