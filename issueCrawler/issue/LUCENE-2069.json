{
    "id": "LUCENE-2069",
    "title": "fix LowerCaseFilter for unicode 4.0",
    "details": {
        "labels": "",
        "priority": "Minor",
        "components": [
            "modules/analysis"
        ],
        "type": "Improvement",
        "fix_versions": [
            "4.0-ALPHA"
        ],
        "affect_versions": "None",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "lowercase suppl. characters correctly. \n\nthis only fixes the filter, the LowerCaseTokenizer is part of a more complex issue (CharTokenizer)",
    "attachments": {
        "LUCENE-2069.patch": "https://issues.apache.org/jira/secure/attachment/12425085/LUCENE-2069.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2009-11-16T17:28:11+0000",
            "content": "Simon, if you have a moment maybe you can review this one for me? ",
            "author": "Robert Muir",
            "id": "comment-12778401"
        },
        {
            "date": "2009-11-16T20:21:28+0000",
            "content": "Robert, I assume you did use those weird chars in the test on purpose - I wonder if there are some \"real\" codepoints that we could use in the test? \n\nThe code looks good to me, this is the way to go for char lowercaseing with Unicode 4.0 ",
            "author": "Simon Willnauer",
            "id": "comment-12778504"
        },
        {
            "date": "2009-11-16T20:26:05+0000",
            "content": "Simon, those \"wierd\" chars are indeed real codepoints that have lowercasing behavior in Unicode 4.0! ",
            "author": "Robert Muir",
            "id": "comment-12778508"
        },
        {
            "date": "2009-11-16T20:30:31+0000",
            "content": "we might need a changes.txt entry here too?! ",
            "author": "Simon Willnauer",
            "id": "comment-12778509"
        },
        {
            "date": "2009-11-16T20:33:05+0000",
            "content": "Simon, yes see LUCENE-1689. \nthis is my question of the day, how are we handling this which is really a backwards break in a way, but honestly a bugfix because we should have supported Unicode 4.0 in Lucene 3.0, since thats the unicode version of java 5. ",
            "author": "Robert Muir",
            "id": "comment-12778510"
        },
        {
            "date": "2009-11-16T20:37:58+0000",
            "content": "we can change it whenever we want, we must only supply a matchVersion switch.... ",
            "author": "Uwe Schindler",
            "id": "comment-12778514"
        },
        {
            "date": "2009-11-16T20:40:42+0000",
            "content": "Uwe, we can use matchVersion for all of this, this is true, and I will help.\n\nbut see my comment on LUCENE-1689 (since i feel it affects all the issues), it will result in a lot of code complexity. Just a warning. ",
            "author": "Robert Muir",
            "id": "comment-12778515"
        },
        {
            "date": "2009-11-17T21:30:10+0000",
            "content": "here is a patch that supports the old broken behavior also via Version. ",
            "author": "Robert Muir",
            "id": "comment-12779146"
        },
        {
            "date": "2009-11-17T21:35:13+0000",
            "content": "forgot javadocs describing what the version does, sorry. ",
            "author": "Robert Muir",
            "id": "comment-12779148"
        },
        {
            "date": "2009-11-17T21:46:02+0000",
            "content": "if you want my vote, it is that we treat issues like this as bugs and not do all this Version stuff.\n\ni supplied this patch (22KB versus 2KB) to show how even the smallest issue creates more complexity.\nAlso, read the javadocs for what Version does, it reads just like a bug:\n\n\tAs of 3.1, supplementary characters are properly lowercased.\n\n\n\nI mean, honestly, its not like we provided a back compat mechanism for 3.0,\nwhere this behavior changed for lots of contrib that uses String-based methods, such as String toLowerCase (they return different results on JRE5 than JRE4)\n\nbut we can go either way, doesn't matter to me. ",
            "author": "Robert Muir",
            "id": "comment-12779156"
        },
        {
            "date": "2009-11-17T21:50:38+0000",
            "content": "But we try and maintain index back compatibility with bugs too? We don't want terms to be lost in an index.\n\nBut it depends as always - if something has long been a problem and broken, then perhaps it doesn't make sense to bend over backwards about it now.  We just have to look at everything, put the priority on making life best for users while balancing somewhat with dev/maintenance headaches and come to a consensus - easy !  ",
            "author": "Mark Miller",
            "id": "comment-12779160"
        },
        {
            "date": "2009-11-17T21:54:10+0000",
            "content": "Mark, true, well give me some consensus so when 3.0 is released, we can start attacking these issues! \n\ndoesn't matter to me, I just present both alternatives! all i want is for us to make a decision. ",
            "author": "Robert Muir",
            "id": "comment-12779164"
        },
        {
            "date": "2009-11-18T06:04:05+0000",
            "content": "Simon, those \"wierd\" chars are indeed real codepoints that have lowercasing behavior in Unicode 4.0! \nthats what I guessed  otherwise it would not work though . I was just wondering if there are some more expressive once out there.\n\nMark, true, well give me some consensus so when 3.0 is released, we can start attacking these issues! \n+1 ",
            "author": "Simon Willnauer",
            "id": "comment-12779319"
        },
        {
            "date": "2009-11-18T15:50:27+0000",
            "content": "But we try and maintain index back compatibility with bugs too?\n\nMark, you are right. The Version description says this: Match settings and bugs in Lucene's 3.0 release.\nI guess we should at least try, I think we can do it. ",
            "author": "Robert Muir",
            "id": "comment-12779499"
        },
        {
            "date": "2009-11-25T12:33:01+0000",
            "content": "I revised the patch and fixed some issues:\n\n\treplaced real characters in tests\n\textended tests to boundaries\n\tRemoved \"code duplication\" in LowercaseFilter\n\n\n\nthe latter is the most important issue. I figured that if we implement a factory with the basic codePointAt method based on a version we can implement the most of the algorithms / methods just by obtaining the version correspondent instance of CharacterUtils (new class I introduced) What this class does is pretty simple - if version >= 3.1 it delegates to the Character correspondent while for earlier versions it convert a character to a codepoint without checking the for high surrogates. Once we have done this conversion we can simply use all the Character.*(int) methods as they are.\n ",
            "author": "Simon Willnauer",
            "id": "comment-12782391"
        },
        {
            "date": "2009-11-25T12:34:14+0000",
            "content": "btw. this also works for CharArraySet - that way we can easily implement it with Version without duplicating any code. Readable, clean and compatible.\n\nI will update the CharArraySet patch once I got comments on this. ",
            "author": "Simon Willnauer",
            "id": "comment-12782393"
        },
        {
            "date": "2009-11-25T13:40:58+0000",
            "content": "Hi Simon, this is a cool idea!\n\nI need to think this through, can you think of other places (non-lowercasing) where we could use this?\nEven if we can only use it there, I think it might still be a good idea to keep things simple.\n\nI do think we should mark the class deprecated and only used for lucene back compat purposes if we decide to use it. ",
            "author": "Robert Muir",
            "id": "comment-12782432"
        },
        {
            "date": "2009-11-25T13:55:48+0000",
            "content": "Simon, i took a quick look at contrib analyzers, for example.\nThis utility class could make back compat easier for a lot of the code, i.e. unicode block calculations in the CJK code, greek diacritic/lowercase folding in the greek code, ...\nI think we should go this route. ",
            "author": "Robert Muir",
            "id": "comment-12782439"
        },
        {
            "date": "2009-11-25T14:34:47+0000",
            "content": "I also found some others like\nBrazilianStemmer\nChineseTokenizer\nFrenchStemmer\nDutchStemmer\n\nand many more.... +1 for this from my side.\nAs this seems to be fundamental we should try to get it in sooner or later so we can get the rest going.\n\nsimon ",
            "author": "Simon Willnauer",
            "id": "comment-12782449"
        },
        {
            "date": "2009-11-25T19:53:49+0000",
            "content": "Added CHANGES.TXT entry for this new feature.\nWe both agreed that we can deprecated CharacterUtils later once we are close to getting rid of it. ",
            "author": "Simon Willnauer",
            "id": "comment-12782584"
        },
        {
            "date": "2009-11-25T20:23:23+0000",
            "content": "Thanks for your work here Simon. I will commit soon if no one objects. ",
            "author": "Robert Muir",
            "id": "comment-12782601"
        },
        {
            "date": "2009-11-25T21:17:19+0000",
            "content": "damn we have to use the limit form of codePointAt, just to be sure.\n\nif term text truly ends with unpaired lead surrogate, codePointAt could pair it with leftover trash trail surrogate from a previous token... ",
            "author": "Robert Muir",
            "id": "comment-12782623"
        },
        {
            "date": "2009-11-25T21:51:22+0000",
            "content": "damn we have to use the limit form of codePointAt, just to be sure. \nno we don't - at least not in this particular case\n\nif term text truly ends with unpaired lead surrogate, codePointAt could pair it with leftover trash trail surrogate from a previous token...\n\nif this rare situation occurs the term length will still prevent the changed trail surrogate from being part of the token. This includes a super tiny overhead but I guess we can simply ignore this. The lead surrogate will not be changed at all in this case - if there is a situation where this could happen I'm not aware of it! ",
            "author": "Simon Willnauer",
            "id": "comment-12782637"
        },
        {
            "date": "2009-11-25T22:07:48+0000",
            "content": "If we are too desperate about it I would suggest to have something like the following just above the loop:\n\n if(buffer.length >= length)\n        buffer[length] = 0x00;\n\n\n ",
            "author": "Simon Willnauer",
            "id": "comment-12782649"
        },
        {
            "date": "2009-11-27T10:44:26+0000",
            "content": "I updated the patch with another testcase for a trailing surrogate leftover in the termbuffer. I also added a missing @Override and fixed some wording in the javadoc ",
            "author": "Simon Willnauer",
            "id": "comment-12783089"
        },
        {
            "date": "2009-11-27T10:50:15+0000",
            "content": "Looks good, +1 to commit! ",
            "author": "Uwe Schindler",
            "id": "comment-12783094"
        },
        {
            "date": "2009-11-27T20:08:55+0000",
            "content": "Simon you are right, there is no problem.\n\nmaybe for other things in the future we will need codePointAt() with the limit param, we could just add it to CharacterUtils if/when we need it. ",
            "author": "Robert Muir",
            "id": "comment-12783158"
        },
        {
            "date": "2009-11-27T21:35:32+0000",
            "content": "Committed revision 885024. ",
            "author": "Robert Muir",
            "id": "comment-12783174"
        }
    ]
}