{
    "id": "SOLR-1726",
    "title": "Deep Paging and Large Results Improvements",
    "details": {
        "affect_versions": "None",
        "status": "Resolved",
        "fix_versions": [
            "4.0"
        ],
        "components": [],
        "type": "Improvement",
        "priority": "Minor",
        "labels": "",
        "resolution": "Incomplete"
    },
    "description": "There are possibly ways to improve collections of \"deep paging\" by passing Solr/Lucene more information about the last page of results seen, thereby saving priority queue operations.   See LUCENE-2215.\n\nThere may also be better options for retrieving large numbers of rows at a time that are worth exploring.  LUCENE-2127.",
    "attachments": {
        "QueryComponent.java": "https://issues.apache.org/jira/secure/attachment/12505124/QueryComponent.java",
        "ResponseBuilder.java": "https://issues.apache.org/jira/secure/attachment/12505125/ResponseBuilder.java",
        "CommonParams.java": "https://issues.apache.org/jira/secure/attachment/12505126/CommonParams.java",
        "SOLR-1726.patch": "https://issues.apache.org/jira/secure/attachment/12505121/SOLR-1726.patch",
        "TopScoreDocCollector.java": "https://issues.apache.org/jira/secure/attachment/12505128/TopScoreDocCollector.java",
        "SolrIndexSearcher.java": "https://issues.apache.org/jira/secure/attachment/12505123/SolrIndexSearcher.java",
        "QParser.java": "https://issues.apache.org/jira/secure/attachment/12505122/QParser.java",
        "TopDocsCollector.java": "https://issues.apache.org/jira/secure/attachment/12505127/TopDocsCollector.java"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Hoss Man",
            "id": "comment-12872539",
            "date": "2010-05-27T22:07:27+0000",
            "content": "Bulk updating 240 Solr issues to set the Fix Version to \"next\" per the process outlined in this email...\n\nhttp://mail-archives.apache.org/mod_mbox/lucene-dev/201005.mbox/%3Calpine.DEB.1.10.1005251052040.24672@radix.cryptio.net%3E\n\nSelection criteria was \"Unresolved\" with a Fix Version of 1.5, 1.6, 3.1, or 4.0.  email notifications were suppressed.\n\nA unique token for finding these 240 issues in the future: hossversioncleanup20100527 "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13043830",
            "date": "2011-06-03T16:47:17+0000",
            "content": "Bulk move 3.2 -> 3.3 "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13106311",
            "date": "2011-09-16T14:50:30+0000",
            "content": "3.4 -> 3.5 "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-13126529",
            "date": "2011-10-13T12:45:44+0000",
            "content": "Now that IndexSearcher.searchAfter() has been added, we should be able to simply hook this in by allowing the user to pass the  \"score doc\" from the previous page into Solr.  I would suggest parameters of: &pageDoc= and &pageScore=, but am open to other suggestions. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13126564",
            "date": "2011-10-13T13:31:16+0000",
            "content": "&pageDoc= and &pageScore=\n\nHaving the user pass these in seems very error prone.\nThey also aren't going to know when the searcher changes (and the internal docid is invalidated).\nAlso, it's not just pageScore that would need to be passed, but a list of the sort values (which we don't even support returning yet). "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13126579",
            "date": "2011-10-13T13:42:48+0000",
            "content": "also keep in mind that IS.searchAfter hasn't yet been implemented for the sorting collectors. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13126583",
            "date": "2011-10-13T13:46:43+0000",
            "content": "\nThey also aren't going to know when the searcher changes (and the internal docid is invalidated).\n\nSeems like this is really unrelated to deep paging though, wouldn't this cause normal paging thru search results to be screwy?! "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13126591",
            "date": "2011-10-13T13:58:01+0000",
            "content": "Seems like this is really unrelated to deep paging though, wouldn't this cause normal paging thru search results to be screwy?!\n\nWell, if pageDoc is Solr's external uniqueKey, then you're right (it's only slightly worse than normal paging across diff searchers). "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-13126626",
            "date": "2011-10-13T14:39:33+0000",
            "content": "Having the user pass these in seems very error prone.\n\nHow else would we do it?  You don't want Solr keeping state, IMO.\n\nThey also aren't going to know when the searcher changes (and the internal docid is invalidated).\n\nI was thinking it would be the external Unique ID, not Lucene's internal id, which would mean there would have to be a lookup.  And, yes, you are correct they wouldn't know when the searcher changes, but you have that issue already with paging, so it is no worse than the existing case.\n\nAlso, it's not just pageScore that would need to be passed, but a list of the sort values (which we don't even support returning yet).\n\nright, we would have to add that support to Lucene first.  For Solr, we would need to pass in either the score or the value. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13126640",
            "date": "2011-10-13T14:54:00+0000",
            "content": "\nright, we would have to add that support to Lucene first.\n\nI think this isnt bad from the high level: we just generalize searchAfter(ScoreDoc after, Query query, Filter filter, ..) to\nsearchAfter(ScoreDoc after, Query query, Filter filter, Sort sort, ...)\n\nThe problem is that there are 87 different specialized sorting collectors, and searchAfter by score seems to be the real \nlucene use case, for 'deep paging thru results not sorted by score' I would use a database instead!\n\nI'm not against us adding it, just not motivated to for those reasons. "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-13126650",
            "date": "2011-10-13T15:03:17+0000",
            "content": "Likely true.  I do tend to think this is mostly a sort by score issue as well, but I can see it being asked. "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-13126654",
            "date": "2011-10-13T15:06:29+0000",
            "content": "I would suggest we just do score for now, but name the parameter to be pageSort instead of pageScore.  Alternatively, maybe we should name them &lastId and &lastSortVal. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13126656",
            "date": "2011-10-13T15:10:02+0000",
            "content": "yeah from my perspective i would prefer for the API to be 'complete'.\n\nOne idea would be to start with one or two implementations (maybe in/out of order) for the sorting case, and dont overspecialize it yet.\n\n\tfor page 1, the ScoreDoc (FieldDoc really) will be null, so we just return the normal impl anyway.\n\teven if our searchAfter isnt huper-duper fast, the user can always make the tradeoff like with page-by-score. they can always just pass null until like page 10 or something if they compute that it only starts to 'help' then.\n\n "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13126661",
            "date": "2011-10-13T15:17:59+0000",
            "content": "I opened LUCENE-3514 with this idea. "
        },
        {
            "author": "David Smiley",
            "id": "comment-13126727",
            "date": "2011-10-13T17:04:36+0000",
            "content": "I've been following these \"large result handling\" related issues with some interest. I think there are some types of applications, the ones that I see at work, where the client essentially wants to process the entire results from Solr, ideally in a streaming manner.  Paging (that is, making multiple requests of the dataset to Solr) would ideally not happen because it's kind of a pain and there are session / stateless issues and efficiency ones.  Ideally Solr would allow SolrJ to stream the results. Aggregate information like facets would need to be calculated and retrievable up front, but anything per-document like the document's stored fields that were asked for and highlighting would be streamed.  What do you guys think of this? "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-13126749",
            "date": "2011-10-13T17:43:02+0000",
            "content": "bq Ideally Solr would allow SolrJ to stream the results. \n\nCheck:\nSolrServer.html#queryAndStreamResponse\n\nI have used it with up to 1M docs without much issue...  "
        },
        {
            "author": "David Smiley",
            "id": "comment-13126763",
            "date": "2011-10-13T17:58:44+0000",
            "content": "Awesome Ryan; thanks!  I suspected it might exist but I didn't find it after looking for it so I thought I was mistaken. "
        },
        {
            "author": "Manojkumar Rangasamy Kannadasan",
            "id": "comment-13149629",
            "date": "2011-11-14T14:02:47+0000",
            "content": "hi,\nI am working to insert a new type of query for the issue 1726 by including the lastpageScore and lastDoc in the query as stated by Grant. Can anyone please let me know the place of code where i can insert a new mapping rule for this query to a new function in SolrIndexSearcher.\nKindly reply. "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-13149723",
            "date": "2011-11-14T16:25:24+0000",
            "content": "Hi Manoj,\n\nThis shouldn't require a new query since it should work with all queries, but instead new parameters that get passed in alongside the query (see earlier comments that lay out what the parameter names are.)  You might start by looking at how something like the &rows parameter or the &start parameter are handled and passed through down to the SolrIndexSearcher. "
        },
        {
            "author": "Manojkumar Rangasamy Kannadasan",
            "id": "comment-13157210",
            "date": "2011-11-25T15:56:06+0000",
            "content": "Hi, i have attached an implementation for this issue assuming the same functionality as IS.searchAfter with no sort. Kindly review my fix and provide feedbacks. The two parameters used for paging are pageScore and pageDoc. "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-13160607",
            "date": "2011-12-01T03:00:06+0000",
            "content": "Hi Manoj,\n\nThis looks OK as a start.  Would be nice to have tests to go with it.  \n\nWhy the overriding of getTotalHits on the TopScoreDocCollector?  I don't think returning collectedHits is the right thing to do there.\n\nAlso, you should be able to avoid an extra Collector create call at:\n\n        topCollector = TopScoreDocCollector.create(len, true);\n        //Issue 1726 Start\n        if(cmd.getScoreDoc() != null)\n        {\n        \ttopCollector = TopScoreDocCollector.create(len, cmd.getScoreDoc(), true); //create the Collector with InOrderPagingCollector\n        }\n\n\n\n\nBut that is easy enough to fix.\n "
        },
        {
            "author": "Manojkumar Rangasamy Kannadasan",
            "id": "comment-13160620",
            "date": "2011-12-01T03:26:34+0000",
            "content": "Hi Grant, thanks for your comments. Regarding the collectedHits, if there are 4 docs as results and if we want to return only bottom 2 by giving appropriate pageScore and pageDoc, the expected result is to return only 2 docs as results. But totalHits returns all the 4 docs. Thats the reason i used collectedHits.\nKindly correct me if my understanding is wrong. "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-13160627",
            "date": "2011-12-01T03:43:18+0000",
            "content": "totalHits should return the count of all the hits regardless of the number that are actually being collected.  In other words, totalHits could be a million, but we only return the top 10.  collectedHits only returns the count of how many are being returned. "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-13196156",
            "date": "2012-01-30T14:57:48+0000",
            "content": "Brings this patch up to trunk, adds tests, cleans up a few areas.  I think it is ready to go. "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-13197921",
            "date": "2012-02-01T16:02:07+0000",
            "content": "Committed, thanks Manoj. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13197925",
            "date": "2012-02-01T16:10:29+0000",
            "content": "Re-opening... this doesn't implement what was discussed.  It uses an internal lucene docid, which is pretty dangerous. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13197930",
            "date": "2012-02-01T16:17:32+0000",
            "content": "pageScore should also be renamed to pageSort (or pageVal or pageSortVal) to future-proof when we can page by more than just score)\n\nQParser also seems like an odd place for handling/parsing these parameters... but I guess it's not a big deal. "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-13197934",
            "date": "2012-02-01T16:20:32+0000",
            "content": "Why is it any more dangerous than the action itself?  If the reader has changed, this whole act is unnatural to begin with. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13197947",
            "date": "2012-02-01T16:46:38+0000",
            "content": "You seemed to agree that it should be the external ID previously.\n\nWhy is it any more dangerous than the action itself? If the reader has changed, this whole act is unnatural to begin with.\n\nIt's the degree of breakage.  Small change to index should yield a small amount of potential breakage - and it can be catastrophic (in unpredictable ways) if using internal docids. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13198158",
            "date": "2012-02-01T21:15:32+0000",
            "content": "Some other issues:\n\n\tthe optimization doesn't work if the docset is also requested (i.e. if facet=true) since it's only added in one place.\n\ton a quick test, I'm getting a maxScore=NaN\n\n<result name=\"response\" numFound=\"29\" start=\"0\" maxScore=\"NaN\">\n\n\nNot sure if that's expected, but it's likely to mess up at least some clients\n\twhen using pageDoc, the results get incorrectly cached as a non-paged query (and hence other requests that use the same query will be incorrect)\n\twhen using pageDoc, any previous cached queries will be incorrectly used and hence incorrect results will be returned\n\tit was pretty easy to cause a NPE (but I haven't had time to look into the causes yet):\nhttp://localhost:8983/solr/select?q=*:*&pageDoc=20&pageScore=1.0&fl=[docid],score\n\njava.lang.NullPointerException\n\tat org.apache.solr.handler.component.QueryComponent.process(QueryComponent.java:566)\n\tat org.apache.solr.handler.component.SearchHandler.handleRequestBody(SearchHandler.java:203)\n\n\n\tif you look at the test for this, the query only ever matches a single doc!  Given that the test actually passes while trying to use paging actually means that paging isn't working (since the second page should obviously yield no results).\n\n\n\nI've disabled this for now since it's not ready for prime-time and since it messes with non-deep-paged results. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13198177",
            "date": "2012-02-01T21:38:12+0000",
            "content": "\non a quick test, I'm getting a maxScore=NaN \n\nFrom the lucene point of view,\n\nfor the first page, because scoredoc = null, this is set (in fact ordinary collector is used)\nfor subsequent pages, searchAfter never sets this in the TopDocs, it would just be telling you something you already know! (and cost extra cpu per collect) "
        },
        {
            "author": "Erik Hatcher",
            "id": "comment-13277133",
            "date": "2012-05-16T20:50:57+0000",
            "content": "What's the status of this?   We still have in trunk CHANGES.txt this:\n\n\n* SOLR-1726: Added deep paging support to search (sort by score only) which should use less memory when paging deeply into results\n by keeping the priority queue small. (Manojkumar Rangasamy Kannadasan, gsingers)\n\n\n\nbut the code has been reverted from trunk as I understand it.  Remove the CHANGES entry until this gets straightened out? "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13277266",
            "date": "2012-05-16T23:38:51+0000",
            "content": "Remove the CHANGES entry until this gets straightened out?\n\n+1 - looks like Mike has made this work with non score sort as well, for when we put it back in. "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13412166",
            "date": "2012-07-11T22:26:13+0000",
            "content": "bulk fixing the version info for 4.0-ALPHA and 4.0 all affected issues have \"hoss20120711-bulk-40-change\" in comment "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13429814",
            "date": "2012-08-07T03:43:16+0000",
            "content": "rmuir20120906-bulk-40-change "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13445482",
            "date": "2012-08-31T00:10:38+0000",
            "content": "There is no indication that anyone is actively working on this issue, so removing 4.0 from the fixVersion. "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-13644448",
            "date": "2013-04-29T12:28:11+0000",
            "content": "What's the status of this issue? Ref http://wiki.apache.org/solr/CommonQueryParameters#pageDoc_and_pageScore "
        },
        {
            "author": "Dmitry Kan",
            "id": "comment-13644450",
            "date": "2013-04-29T12:30:22+0000",
            "content": "does the deep paging issue apply to facet paging? "
        },
        {
            "author": "Otis Gospodnetic",
            "id": "comment-13686901",
            "date": "2013-06-18T16:36:34+0000",
            "content": "How ElasticSearch handles this: http://www.elasticsearch.org/guide/reference/api/search/scroll/\n(and note how this can be used to reindex from old index to new index as mentioned at http://www.elasticsearch.org/blog/changing-mapping-with-zero-downtime/ ) "
        },
        {
            "author": "Dmitry Kan",
            "id": "comment-13686964",
            "date": "2013-06-18T16:59:09+0000",
            "content": "\"Scrolling is not intended for real time user requests, it is intended for cases like scrolling over large portions of data that exists within elasticsearch to reindex it for example.\"\n\nare there any other applications for this except re-indexing?\n\nAlso, is it known, how internally the scrolling is implemented, i.e. is it efficient in transferring to the client of only what is needed? "
        },
        {
            "author": "Steve Rowe",
            "id": "comment-13717209",
            "date": "2013-07-23T18:47:29+0000",
            "content": "Bulk move 4.4 issues to 4.5 and 5.0 "
        },
        {
            "author": "Scott Stults",
            "id": "comment-13791495",
            "date": "2013-10-10T13:41:27+0000",
            "content": "Dmitry, I think \"scrolling\" would help in the case of Hadoop integration, such as pulling a few hundred thousand docs based off of a query to the local node so that you can do an aggregated calculation with Pig or M/R. "
        },
        {
            "author": "Otis Gospodnetic",
            "id": "comment-13791647",
            "date": "2013-10-10T16:33:25+0000",
            "content": "Isn't this related to SOLR-5244, Joel Bernstein? "
        },
        {
            "author": "Dmitry Kan",
            "id": "comment-13795092",
            "date": "2013-10-15T11:28:23+0000",
            "content": "Scott Stults Thanks for the use case. This leans towards offline as well, but certainly makes sense.\nOur current use case is realtime though and we attacking the problem of deep paging differently at the moment (on the querying client side). "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13826063",
            "date": "2013-11-19T01:39:55+0000",
            "content": "Since all of the existing code attached to this issue was committed prior to 4.0 \u2013 but then nearly immediately disabled by commenting out the key bits in QParser.getPaging() \u2013 i think attempting to continue building off this existing issue would just be confusing.\n\nI'm marking this issue as \"Resolution: Incomplete\" and I've opened a new issue (SOLR-5463) to track new development towards this goal "
        }
    ]
}