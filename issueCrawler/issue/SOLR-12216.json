{
    "id": "SOLR-12216",
    "title": "Add support for cross-cloud join",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [
            "search"
        ],
        "type": "Improvement",
        "fix_versions": [],
        "affect_versions": "None",
        "resolution": "Unresolved",
        "status": "Open"
    },
    "description": "This patch is to propose the idea of extending the capabilities of the built-in join to allow joining across SolrClouds. Similar to streaming's search function, the user can directly specify the zkHost of the other SolrCloud and the rest of the syntax (from, to, fromIndex) can remain the same. This join would be triggered when the zkHost parameter is specified, containing the address of the other SolrCluster. It could also be packaged as a separate plugin.\n\n\u00a0\n\nIn my testing, my current implementation is on average 4.5x faster than an equivalent streaming expression intersecting from two search queries, one of which streams from another collection on another SolrCloud.\u00a0\nHow it works\n\nSimilar to the existing join, I created a QParser, but this join works as a post-filter. The join first populates a hash set containing fields from the \u201cfrom\u201d index (i.e, the index that\u2019s not the one we\u2019re running the query from). To obtain the fields, it establishes a connection with the other SolrCloud using SolrJ through the ZooKeeper address specified, and then uses a custom request handler that performs the query on the \u201cfrom\u201d index and return back an array of strings containing a list of fields. Then, on the \u201cto\u201d index, it iterates through the array sent as JavaBin and adds it to the hash set. After that, we iterate through the NumericDocList for the \u201cto\u201d core\u2019s join field, and if there\u2019s a value within the NumericDocList that\u2019s found within our hash set, we collect it inside the DelegatingCollector.\n\nThis allows for joining across sharded collections as well.\u00a0\nHow I benchmarked\n\nI created web-app that first reloads the collections, then sends 25 AJAX requests at once to the Solr endpoint of varying query sizes (between 127 search results and 690,000), and then recorded the results. After all responses are returned, the collection is reloaded, and the equivalent streaming expressions are tested. This process is repeated 15 times, and the average of the results is taken.\u00a0\n\nNote: The first two requests are not counted in the statistics, because it \u201cwarms up\u201d the collection. For reference, after bouncing Solr and at least one query is executed, it takes on average ~890ms for joining on two collections with about 690,000 results, while it takes ~4.5 seconds using streaming expressions).\n\n\u00a0\n\nI have written unit tests written as well. I would appreciate some comments on this. Thank you.",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "date": "2018-04-12T18:51:51+0000",
            "content": "Where is the patch that you've referred to in the description? ",
            "author": "Ishan Chattopadhyaya",
            "id": "comment-16436142"
        },
        {
            "date": "2018-04-12T19:00:54+0000",
            "content": "I'm still doing some finishing touches, hoping to get it out soon, but would like some feedback at this point on the idea itself.\u00a0 ",
            "author": "Horatiu Lazu",
            "id": "comment-16436152"
        }
    ]
}