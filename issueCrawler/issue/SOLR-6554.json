{
    "id": "SOLR-6554",
    "title": "Speed up overseer operations for collections with stateFormat > 1",
    "details": {
        "affect_versions": "5.0,                                            6.0",
        "status": "Closed",
        "fix_versions": [
            "5.0",
            "6.0"
        ],
        "components": [
            "SolrCloud"
        ],
        "type": "Improvement",
        "priority": "Major",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "Right now (after SOLR-5473 was committed), a node watches a collection only if stateFormat=1 or if that node hosts at least one core belonging to that collection.\n\nThis means that a node which is the overseer operates on all collections but watches only a few. So any read goes directly to zookeeper which slows down overseer operations.\n\nLet's have the overseer node watch all collections always and never remove those watches (except when the collection itself is deleted).",
    "attachments": {
        "SOLR-6554.patch": "https://issues.apache.org/jira/secure/attachment/12678578/SOLR-6554.patch",
        "SOLR-6554-batching-refactor.patch": "https://issues.apache.org/jira/secure/attachment/12684281/SOLR-6554-batching-refactor.patch",
        "SOLR-6554-workqueue-fixes.patch": "https://issues.apache.org/jira/secure/attachment/12687737/SOLR-6554-workqueue-fixes.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-14192573",
            "date": "2014-10-31T21:56:36+0000",
            "content": "I bit the bullet and refactored the overseer to be less of a mess than it is now.\n\n\tI grouped the cluster operations into cluster, collection, slice and replica and moved them to their own classes.\n\tA new class ZkStateWriter is introduced which uses ZkWriteCommand to update the clusterstate.\n\tEach overseer operation returns a ZkWriteCommand\n\tThe force update of cluster state is no longer required inside the main overseer loop. It is read once at the start of the loop and then we use ZK compare-and-set to update the cluster states using the versions already read.\n\tThe above also means that there is no need to watch every collection with stateFormat > 1 on the overseer node anymore.\n\n\n\nTodo\n\n\tThere are some nocommits that need to be taken care of.\n\tImplement batching for collections with stateFormat > 1\n\tThere are a few newer operations such as balanceSliceUnique which aren't implemented yet so some tests fail.\n\tMore cleanup\n\n\n\nHere are some performance numbers using the new code vs branch_5x:\n\nOverseer queue size: 20000 state requests\n\nstateFormat = 1, With refactoring (trunk)\n=========================================\n250962 T13 oasc.OverseerTest.testPerformance Overseer loop finished processing: \n250964 T13 oasc.OverseerTest.printTimingStats \t totalTime: 241639.501565\n250964 T13 oasc.OverseerTest.printTimingStats \t avgRequestsPerMinute: 0.0041383582263057345\n250965 T13 oasc.OverseerTest.printTimingStats \t 5minRateRequestsPerMinute: 0.0\n250965 T13 oasc.OverseerTest.printTimingStats \t 15minRateRequestsPerMinute: 0.0\n250965 T13 oasc.OverseerTest.printTimingStats \t avgTimePerRequest: 241639.501565\n250966 T13 oasc.OverseerTest.printTimingStats \t medianRequestTime: 241639.501565\n250966 T13 oasc.OverseerTest.printTimingStats \t 75thPctlRequestTime: 241639.501565\n250966 T13 oasc.OverseerTest.printTimingStats \t 95thPctlRequestTime: 241639.501565\n250966 T13 oasc.OverseerTest.printTimingStats \t 99thPctlRequestTime: 241639.501565\n250967 T13 oasc.OverseerTest.printTimingStats \t 999thPctlRequestTime: 241639.501565\n250967 T13 oasc.OverseerTest.testPerformance op: am_i_leader, success: 163, failure: 0\n250967 T13 oasc.OverseerTest.printTimingStats \t totalTime: 27.778517\n250967 T13 oasc.OverseerTest.printTimingStats \t avgRequestsPerMinute: 40.51109030620299\n250967 T13 oasc.OverseerTest.printTimingStats \t 5minRateRequestsPerMinute: 60.52909864226439\n250968 T13 oasc.OverseerTest.printTimingStats \t 15minRateRequestsPerMinute: 67.32475977643367\n250968 T13 oasc.OverseerTest.printTimingStats \t avgTimePerRequest: 0.17042034969325154\n250968 T13 oasc.OverseerTest.printTimingStats \t medianRequestTime: 0.127852\n250968 T13 oasc.OverseerTest.printTimingStats \t 75thPctlRequestTime: 0.159049\n250968 T13 oasc.OverseerTest.printTimingStats \t 95thPctlRequestTime: 0.20707859999999995\n250968 T13 oasc.OverseerTest.printTimingStats \t 99thPctlRequestTime: 2.9894586799999168\n250968 T13 oasc.OverseerTest.printTimingStats \t 999thPctlRequestTime: 6.591979\n250968 T13 oasc.OverseerTest.testPerformance op: update_state, success: 161, failure: 0\n250969 T13 oasc.OverseerTest.printTimingStats \t totalTime: 105.56181\n250969 T13 oasc.OverseerTest.printTimingStats \t avgRequestsPerMinute: 40.02790612569949\n250969 T13 oasc.OverseerTest.printTimingStats \t 5minRateRequestsPerMinute: 48.0\n250969 T13 oasc.OverseerTest.printTimingStats \t 15minRateRequestsPerMinute: 48.0\n250970 T13 oasc.OverseerTest.printTimingStats \t avgTimePerRequest: 0.6556634161490683\n250970 T13 oasc.OverseerTest.printTimingStats \t medianRequestTime: 0.57833\n250970 T13 oasc.OverseerTest.printTimingStats \t 75thPctlRequestTime: 0.7091475\n250970 T13 oasc.OverseerTest.printTimingStats \t 95thPctlRequestTime: 0.9294200000000001\n250970 T13 oasc.OverseerTest.printTimingStats \t 99thPctlRequestTime: 3.997095759999999\n250970 T13 oasc.OverseerTest.printTimingStats \t 999thPctlRequestTime: 4.075775\n250971 T13 oasc.OverseerTest.testPerformance op: state, success: 20001, failure: 0\n250972 T13 oasc.OverseerTest.printTimingStats \t totalTime: 24677.266392\n250972 T13 oasc.OverseerTest.printTimingStats \t avgRequestsPerMinute: 4971.795405166019\n250972 T13 oasc.OverseerTest.printTimingStats \t 5minRateRequestsPerMinute: 4190.29864341858\n250972 T13 oasc.OverseerTest.printTimingStats \t 15minRateRequestsPerMinute: 3199.6744276725544\n250972 T13 oasc.OverseerTest.printTimingStats \t avgTimePerRequest: 1.2338016295185241\n250973 T13 oasc.OverseerTest.printTimingStats \t medianRequestTime: 1.1432815\n250973 T13 oasc.OverseerTest.printTimingStats \t 75thPctlRequestTime: 1.57099125\n250973 T13 oasc.OverseerTest.printTimingStats \t 95thPctlRequestTime: 1.8449494\n250973 T13 oasc.OverseerTest.printTimingStats \t 99thPctlRequestTime: 2.155266570000001\n250973 T13 oasc.OverseerTest.printTimingStats \t 999thPctlRequestTime: 4.228459292000002\n\n\nstateFormat = 1, Without refactoring (branch_5x):\n============================================================================================\n\n281984 T11 oasc.OverseerTest.testPerformance Overseer loop finished processing: \n281985 T11 oasc.OverseerTest.printTimingStats \t totalTime: 256532.804054\n281986 T11 oasc.OverseerTest.printTimingStats \t avgRequestsPerMinute: 0.0038981033718983866\n281986 T11 oasc.OverseerTest.printTimingStats \t 5minRateRequestsPerMinute: 0.0\n281986 T11 oasc.OverseerTest.printTimingStats \t 15minRateRequestsPerMinute: 0.0\n281987 T11 oasc.OverseerTest.printTimingStats \t avgTimePerRequest: 256532.804054\n281987 T11 oasc.OverseerTest.printTimingStats \t medianRequestTime: 256532.804054\n281987 T11 oasc.OverseerTest.printTimingStats \t 75thPctlRequestTime: 256532.804054\n281988 T11 oasc.OverseerTest.printTimingStats \t 95thPctlRequestTime: 256532.804054\n281988 T11 oasc.OverseerTest.printTimingStats \t 99thPctlRequestTime: 256532.804054\n281988 T11 oasc.OverseerTest.printTimingStats \t 999thPctlRequestTime: 256532.804054\n281989 T11 oasc.OverseerTest.testPerformance op: state, success: 20001, failure: 0\n281990 T11 oasc.OverseerTest.printTimingStats \t totalTime: 14883.542675\n281990 T11 oasc.OverseerTest.printTimingStats \t avgRequestsPerMinute: 4679.183238623399\n281990 T11 oasc.OverseerTest.printTimingStats \t 5minRateRequestsPerMinute: 4042.064261836551\n281990 T11 oasc.OverseerTest.printTimingStats \t 15minRateRequestsPerMinute: 3041.931602459868\n281990 T11 oasc.OverseerTest.printTimingStats \t avgTimePerRequest: 0.7441399267536623\n281991 T11 oasc.OverseerTest.printTimingStats \t medianRequestTime: 0.6902204999999999\n281991 T11 oasc.OverseerTest.printTimingStats \t 75thPctlRequestTime: 0.9253057499999999\n281991 T11 oasc.OverseerTest.printTimingStats \t 95thPctlRequestTime: 1.0441081499999998\n281991 T11 oasc.OverseerTest.printTimingStats \t 99thPctlRequestTime: 1.2398173200000007\n281991 T11 oasc.OverseerTest.printTimingStats \t 999thPctlRequestTime: 1.4717788410000001\n281991 T11 oasc.OverseerTest.testPerformance op: update_state, success: 171, failure: 0\n281992 T11 oasc.OverseerTest.printTimingStats \t totalTime: 108.786403\n281992 T11 oasc.OverseerTest.printTimingStats \t avgRequestsPerMinute: 40.00714188468187\n281992 T11 oasc.OverseerTest.printTimingStats \t 5minRateRequestsPerMinute: 48.0\n281992 T11 oasc.OverseerTest.printTimingStats \t 15minRateRequestsPerMinute: 48.0\n281992 T11 oasc.OverseerTest.printTimingStats \t avgTimePerRequest: 0.6361777953216374\n281992 T11 oasc.OverseerTest.printTimingStats \t medianRequestTime: 0.615385\n281992 T11 oasc.OverseerTest.printTimingStats \t 75thPctlRequestTime: 0.731113\n281992 T11 oasc.OverseerTest.printTimingStats \t 95thPctlRequestTime: 0.8640954000000003\n281993 T11 oasc.OverseerTest.printTimingStats \t 99thPctlRequestTime: 2.1159375600000034\n281993 T11 oasc.OverseerTest.printTimingStats \t 999thPctlRequestTime: 4.361583\n281993 T11 oasc.OverseerTest.testPerformance op: am_i_leader, success: 172, failure: 0\n281993 T11 oasc.OverseerTest.printTimingStats \t totalTime: 23.880482\n281993 T11 oasc.OverseerTest.printTimingStats \t avgRequestsPerMinute: 40.23061331599097\n281993 T11 oasc.OverseerTest.printTimingStats \t 5minRateRequestsPerMinute: 60.11834593132536\n281994 T11 oasc.OverseerTest.printTimingStats \t 15minRateRequestsPerMinute: 67.11122870391561\n281994 T11 oasc.OverseerTest.printTimingStats \t avgTimePerRequest: 0.13884001162790696\n281994 T11 oasc.OverseerTest.printTimingStats \t medianRequestTime: 0.14114549999999998\n281994 T11 oasc.OverseerTest.printTimingStats \t 75thPctlRequestTime: 0.1714525\n281994 T11 oasc.OverseerTest.printTimingStats \t 95thPctlRequestTime: 0.24251024999999998\n281994 T11 oasc.OverseerTest.printTimingStats \t 99thPctlRequestTime: 0.2920699700000001\n281994 T11 oasc.OverseerTest.printTimingStats \t 999thPctlRequestTime: 0.303612\n\n\nstateFormat = 2, 10 collections, With refactoring (trunk):\n===========================================================\n359321 T13 oasc.OverseerTest.testPerformance Overseer loop finished processing: \n359322 T13 oasc.OverseerTest.printTimingStats \t totalTime: 336222.016107\n359323 T13 oasc.OverseerTest.printTimingStats \t avgRequestsPerMinute: 0.0029742060387324683\n359323 T13 oasc.OverseerTest.printTimingStats \t 5minRateRequestsPerMinute: 0.0\n359323 T13 oasc.OverseerTest.printTimingStats \t 15minRateRequestsPerMinute: 0.0\n359324 T13 oasc.OverseerTest.printTimingStats \t avgTimePerRequest: 336222.016107\n359324 T13 oasc.OverseerTest.printTimingStats \t medianRequestTime: 336222.016107\n359324 T13 oasc.OverseerTest.printTimingStats \t 75thPctlRequestTime: 336222.016107\n359325 T13 oasc.OverseerTest.printTimingStats \t 95thPctlRequestTime: 336222.016107\n359325 T13 oasc.OverseerTest.printTimingStats \t 99thPctlRequestTime: 336222.016107\n359325 T13 oasc.OverseerTest.printTimingStats \t 999thPctlRequestTime: 336222.016107\n359325 T13 oasc.OverseerTest.testPerformance op: am_i_leader, success: 19898, failure: 0\n359326 T13 oasc.OverseerTest.printTimingStats \t totalTime: 2910.821076\n359326 T13 oasc.OverseerTest.printTimingStats \t avgRequestsPerMinute: 3551.0282475508393\n359326 T13 oasc.OverseerTest.printTimingStats \t 5minRateRequestsPerMinute: 3007.215001818593\n359327 T13 oasc.OverseerTest.printTimingStats \t 15minRateRequestsPerMinute: 1628.5124596704984\n359327 T13 oasc.OverseerTest.printTimingStats \t avgTimePerRequest: 0.14628711810232184\n359327 T13 oasc.OverseerTest.printTimingStats \t medianRequestTime: 0.127051\n359327 T13 oasc.OverseerTest.printTimingStats \t 75thPctlRequestTime: 0.16182850000000001\n359327 T13 oasc.OverseerTest.printTimingStats \t 95thPctlRequestTime: 0.22852089999999997\n359327 T13 oasc.OverseerTest.printTimingStats \t 99thPctlRequestTime: 0.30072901000000013\n359327 T13 oasc.OverseerTest.printTimingStats \t 999thPctlRequestTime: 1.135954577000003\n359327 T13 oasc.OverseerTest.testPerformance op: update_state, success: 19896, failure: 0\n359328 T13 oasc.OverseerTest.printTimingStats \t totalTime: 14968.90839\n359328 T13 oasc.OverseerTest.printTimingStats \t avgRequestsPerMinute: 3551.180599528965\n359329 T13 oasc.OverseerTest.printTimingStats \t 5minRateRequestsPerMinute: 3006.8437316469813\n359329 T13 oasc.OverseerTest.printTimingStats \t 15minRateRequestsPerMinute: 1628.3818327713007\n359329 T13 oasc.OverseerTest.printTimingStats \t avgTimePerRequest: 0.7523576794330519\n359329 T13 oasc.OverseerTest.printTimingStats \t medianRequestTime: 0.7057765\n359329 T13 oasc.OverseerTest.printTimingStats \t 75thPctlRequestTime: 0.8617165\n359329 T13 oasc.OverseerTest.printTimingStats \t 95thPctlRequestTime: 1.03365505\n359329 T13 oasc.OverseerTest.printTimingStats \t 99thPctlRequestTime: 1.1740241200000008\n359329 T13 oasc.OverseerTest.printTimingStats \t 999thPctlRequestTime: 4.014327310000006\n359330 T13 oasc.OverseerTest.testPerformance op: state, success: 20001, failure: 0\n359330 T13 oasc.OverseerTest.printTimingStats \t totalTime: 25670.317603\n359330 T13 oasc.OverseerTest.printTimingStats \t avgRequestsPerMinute: 3572.411123496283\n359330 T13 oasc.OverseerTest.printTimingStats \t 5minRateRequestsPerMinute: 3451.4741046935114\n359331 T13 oasc.OverseerTest.printTimingStats \t 15minRateRequestsPerMinute: 2559.18706643615\n359331 T13 oasc.OverseerTest.printTimingStats \t avgTimePerRequest: 1.2834517075646217\n359331 T13 oasc.OverseerTest.printTimingStats \t medianRequestTime: 1.2092995\n359331 T13 oasc.OverseerTest.printTimingStats \t 75thPctlRequestTime: 1.59053175\n359331 T13 oasc.OverseerTest.printTimingStats \t 95thPctlRequestTime: 1.8313089999999999\n359331 T13 oasc.OverseerTest.printTimingStats \t 99thPctlRequestTime: 2.0310246800000007\n359331 T13 oasc.OverseerTest.printTimingStats \t 999thPctlRequestTime: 2.4514601340000004\n\n\nstateFormat = 2, 10 collections, Without refactoring (branch_5x):\n=================================================================\n\n408300 T11 oasc.OverseerTest.testPerformance Overseer loop finished processing: \n408302 T11 oasc.OverseerTest.printTimingStats \t totalTime: 384185.906373\n408302 T11 oasc.OverseerTest.printTimingStats \t avgRequestsPerMinute: 0.0026028952612532213\n408302 T11 oasc.OverseerTest.printTimingStats \t 5minRateRequestsPerMinute: 0.0\n408302 T11 oasc.OverseerTest.printTimingStats \t 15minRateRequestsPerMinute: 0.0\n408303 T11 oasc.OverseerTest.printTimingStats \t avgTimePerRequest: 384185.906373\n408303 T11 oasc.OverseerTest.printTimingStats \t medianRequestTime: 384185.906373\n408303 T11 oasc.OverseerTest.printTimingStats \t 75thPctlRequestTime: 384185.906373\n408303 T11 oasc.OverseerTest.printTimingStats \t 95thPctlRequestTime: 384185.906373\n408303 T11 oasc.OverseerTest.printTimingStats \t 99thPctlRequestTime: 384185.906373\n408304 T11 oasc.OverseerTest.printTimingStats \t 999thPctlRequestTime: 384185.906373\n408304 T11 oasc.OverseerTest.testPerformance op: state, success: 20001, failure: 0\n408306 T11 oasc.OverseerTest.printTimingStats \t totalTime: 37886.743042\n408306 T11 oasc.OverseerTest.printTimingStats \t avgRequestsPerMinute: 3127.565044455818\n408306 T11 oasc.OverseerTest.printTimingStats \t 5minRateRequestsPerMinute: 3017.721755102994\n408307 T11 oasc.OverseerTest.printTimingStats \t 15minRateRequestsPerMinute: 2191.9117215274555\n408307 T11 oasc.OverseerTest.printTimingStats \t avgTimePerRequest: 1.8942424399780011\n408307 T11 oasc.OverseerTest.printTimingStats \t medianRequestTime: 1.805034\n408307 T11 oasc.OverseerTest.printTimingStats \t 75thPctlRequestTime: 2.33467975\n408307 T11 oasc.OverseerTest.printTimingStats \t 95thPctlRequestTime: 2.72064335\n408308 T11 oasc.OverseerTest.printTimingStats \t 99thPctlRequestTime: 3.380797200000005\n408308 T11 oasc.OverseerTest.printTimingStats \t 999thPctlRequestTime: 6.764998426000004\n408308 T11 oasc.OverseerTest.testPerformance op: update_state, success: 20011, failure: 0\n408310 T11 oasc.OverseerTest.printTimingStats \t totalTime: 15664.348411\n408310 T11 oasc.OverseerTest.printTimingStats \t avgRequestsPerMinute: 3125.8333680772357\n408310 T11 oasc.OverseerTest.printTimingStats \t 5minRateRequestsPerMinute: 3008.770952686416\n408311 T11 oasc.OverseerTest.printTimingStats \t 15minRateRequestsPerMinute: 2188.5152728989856\n408311 T11 oasc.OverseerTest.printTimingStats \t avgTimePerRequest: 0.782786887761731\n408311 T11 oasc.OverseerTest.printTimingStats \t medianRequestTime: 0.7298905\n408311 T11 oasc.OverseerTest.printTimingStats \t 75thPctlRequestTime: 0.8860805\n408311 T11 oasc.OverseerTest.printTimingStats \t 95thPctlRequestTime: 1.0464787999999998\n408312 T11 oasc.OverseerTest.printTimingStats \t 99thPctlRequestTime: 1.2055892300000004\n408312 T11 oasc.OverseerTest.printTimingStats \t 999thPctlRequestTime: 4.504650318000003\n408312 T11 oasc.OverseerTest.testPerformance op: am_i_leader, success: 20013, failure: 0\n408313 T11 oasc.OverseerTest.printTimingStats \t totalTime: 3008.698855\n408313 T11 oasc.OverseerTest.printTimingStats \t avgRequestsPerMinute: 3125.585466114684\n408313 T11 oasc.OverseerTest.printTimingStats \t 5minRateRequestsPerMinute: 3006.128012707961\n408313 T11 oasc.OverseerTest.printTimingStats \t 15minRateRequestsPerMinute: 2187.5621767051953\n408314 T11 oasc.OverseerTest.printTimingStats \t avgTimePerRequest: 0.15033722355468945\n408314 T11 oasc.OverseerTest.printTimingStats \t medianRequestTime: 0.1373615\n408314 T11 oasc.OverseerTest.printTimingStats \t 75thPctlRequestTime: 0.17162775\n408314 T11 oasc.OverseerTest.printTimingStats \t 95thPctlRequestTime: 0.23810549999999997\n408314 T11 oasc.OverseerTest.printTimingStats \t 99thPctlRequestTime: 0.28888714000000004\n408314 T11 oasc.OverseerTest.printTimingStats \t 999thPctlRequestTime: 0.36018958200000006\n\n\nstateFormat = 2, 100 collections, With refactoring (trunk):\n===========================================================\n353683 T13 oasc.OverseerTest.testPerformance Overseer loop finished processing: \n353685 T13 oasc.OverseerTest.printTimingStats \t totalTime: 344294.509037\n353686 T13 oasc.OverseerTest.printTimingStats \t avgRequestsPerMinute: 0.0029044719408401407\n353686 T13 oasc.OverseerTest.printTimingStats \t 5minRateRequestsPerMinute: 0.0\n353686 T13 oasc.OverseerTest.printTimingStats \t 15minRateRequestsPerMinute: 0.0\n353687 T13 oasc.OverseerTest.printTimingStats \t avgTimePerRequest: 344294.509037\n353687 T13 oasc.OverseerTest.printTimingStats \t medianRequestTime: 344294.509037\n353687 T13 oasc.OverseerTest.printTimingStats \t 75thPctlRequestTime: 344294.509037\n353687 T13 oasc.OverseerTest.printTimingStats \t 95thPctlRequestTime: 344294.509037\n353688 T13 oasc.OverseerTest.printTimingStats \t 99thPctlRequestTime: 344294.509037\n353688 T13 oasc.OverseerTest.printTimingStats \t 999thPctlRequestTime: 344294.509037\n353688 T13 oasc.OverseerTest.testPerformance op: am_i_leader, success: 19908, failure: 0\n353690 T13 oasc.OverseerTest.printTimingStats \t totalTime: 2899.55199\n353690 T13 oasc.OverseerTest.printTimingStats \t avgRequestsPerMinute: 3471.041899147638\n353690 T13 oasc.OverseerTest.printTimingStats \t 5minRateRequestsPerMinute: 2696.4544094117955\n353690 T13 oasc.OverseerTest.printTimingStats \t 15minRateRequestsPerMinute: 1206.322204620017\n353690 T13 oasc.OverseerTest.printTimingStats \t avgTimePerRequest: 0.1456475783604581\n353691 T13 oasc.OverseerTest.printTimingStats \t medianRequestTime: 0.1307565\n353691 T13 oasc.OverseerTest.printTimingStats \t 75thPctlRequestTime: 0.16647275\n353691 T13 oasc.OverseerTest.printTimingStats \t 95thPctlRequestTime: 0.24111169999999996\n353691 T13 oasc.OverseerTest.printTimingStats \t 99thPctlRequestTime: 0.29323824000000015\n353691 T13 oasc.OverseerTest.printTimingStats \t 999thPctlRequestTime: 2.1718927580000065\n353691 T13 oasc.OverseerTest.testPerformance op: update_state, success: 19906, failure: 0\n353693 T13 oasc.OverseerTest.printTimingStats \t totalTime: 16055.477415\n353693 T13 oasc.OverseerTest.printTimingStats \t avgRequestsPerMinute: 3471.500723620727\n353693 T13 oasc.OverseerTest.printTimingStats \t 5minRateRequestsPerMinute: 2706.077181788675\n353693 T13 oasc.OverseerTest.printTimingStats \t 15minRateRequestsPerMinute: 1216.7129526167616\n353693 T13 oasc.OverseerTest.printTimingStats \t avgTimePerRequest: 0.8065647249572993\n353694 T13 oasc.OverseerTest.printTimingStats \t medianRequestTime: 0.7490195\n353694 T13 oasc.OverseerTest.printTimingStats \t 75thPctlRequestTime: 0.93685775\n353694 T13 oasc.OverseerTest.printTimingStats \t 95thPctlRequestTime: 1.1227754\n353694 T13 oasc.OverseerTest.printTimingStats \t 99thPctlRequestTime: 1.2775636000000001\n353694 T13 oasc.OverseerTest.printTimingStats \t 999thPctlRequestTime: 5.825008328000003\n353694 T13 oasc.OverseerTest.testPerformance op: state, success: 20001, failure: 0\n353695 T13 oasc.OverseerTest.printTimingStats \t totalTime: 28055.800755\n353695 T13 oasc.OverseerTest.printTimingStats \t avgRequestsPerMinute: 3509.7301625656414\n353696 T13 oasc.OverseerTest.printTimingStats \t 5minRateRequestsPerMinute: 3387.1127858679465\n353696 T13 oasc.OverseerTest.printTimingStats \t 15minRateRequestsPerMinute: 2517.7854888232214\n353696 T13 oasc.OverseerTest.printTimingStats \t avgTimePerRequest: 1.4027199017549121\n353696 T13 oasc.OverseerTest.printTimingStats \t medianRequestTime: 1.283997\n353696 T13 oasc.OverseerTest.printTimingStats \t 75thPctlRequestTime: 1.751609\n353696 T13 oasc.OverseerTest.printTimingStats \t 95thPctlRequestTime: 1.98747225\n353697 T13 oasc.OverseerTest.printTimingStats \t 99thPctlRequestTime: 2.2288728700000013\n353697 T13 oasc.OverseerTest.printTimingStats \t 999thPctlRequestTime: 2.677476075\n\n\nstateFormat = 2, 100 collections, Without refactoring (branch_5x):\n==================================================================\n642467 T11 oasc.OverseerTest.testPerformance Overseer loop finished processing: \n642468 T11 oasc.OverseerTest.printTimingStats \t totalTime: 592456.582081\n642471 T11 oasc.OverseerTest.printTimingStats \t avgRequestsPerMinute: 0.0016878842331991438\n642471 T11 oasc.OverseerTest.printTimingStats \t 5minRateRequestsPerMinute: 0.0\n642471 T11 oasc.OverseerTest.printTimingStats \t 15minRateRequestsPerMinute: 0.0\n642471 T11 oasc.OverseerTest.printTimingStats \t avgTimePerRequest: 592456.582081\n642471 T11 oasc.OverseerTest.printTimingStats \t medianRequestTime: 592456.582081\n642471 T11 oasc.OverseerTest.printTimingStats \t 75thPctlRequestTime: 592456.582081\n642471 T11 oasc.OverseerTest.printTimingStats \t 95thPctlRequestTime: 592456.582081\n642472 T11 oasc.OverseerTest.printTimingStats \t 99thPctlRequestTime: 592456.582081\n642472 T11 oasc.OverseerTest.printTimingStats \t 999thPctlRequestTime: 592456.582081\n642472 T11 oasc.OverseerTest.testPerformance op: state, success: 20001, failure: 0\n642473 T11 oasc.OverseerTest.printTimingStats \t totalTime: 38316.042986\n642473 T11 oasc.OverseerTest.printTimingStats \t avgRequestsPerMinute: 2039.7101580674453\n642473 T11 oasc.OverseerTest.printTimingStats \t 5minRateRequestsPerMinute: 2225.3413952254627\n642473 T11 oasc.OverseerTest.printTimingStats \t 15minRateRequestsPerMinute: 1666.2656764044962\n642474 T11 oasc.OverseerTest.printTimingStats \t avgTimePerRequest: 1.9157063639818008\n642474 T11 oasc.OverseerTest.printTimingStats \t medianRequestTime: 1.9428355\n642474 T11 oasc.OverseerTest.printTimingStats \t 75thPctlRequestTime: 2.363384\n642474 T11 oasc.OverseerTest.printTimingStats \t 95thPctlRequestTime: 2.6738654\n642474 T11 oasc.OverseerTest.printTimingStats \t 99thPctlRequestTime: 2.9951339600000004\n642474 T11 oasc.OverseerTest.printTimingStats \t 999thPctlRequestTime: 4.165273211000003\n642474 T11 oasc.OverseerTest.testPerformance op: update_state, success: 20101, failure: 0\n642475 T11 oasc.OverseerTest.printTimingStats \t totalTime: 16713.560223\n642476 T11 oasc.OverseerTest.printTimingStats \t avgRequestsPerMinute: 2035.9152283337185\n642476 T11 oasc.OverseerTest.printTimingStats \t 5minRateRequestsPerMinute: 2256.420345106015\n642476 T11 oasc.OverseerTest.printTimingStats \t 15minRateRequestsPerMinute: 1779.6120090712736\n642476 T11 oasc.OverseerTest.printTimingStats \t avgTimePerRequest: 0.8314790419879609\n642476 T11 oasc.OverseerTest.printTimingStats \t medianRequestTime: 0.800087\n642476 T11 oasc.OverseerTest.printTimingStats \t 75thPctlRequestTime: 0.92331125\n642476 T11 oasc.OverseerTest.printTimingStats \t 95thPctlRequestTime: 1.08387195\n642476 T11 oasc.OverseerTest.printTimingStats \t 99thPctlRequestTime: 1.1850831800000001\n642476 T11 oasc.OverseerTest.printTimingStats \t 999thPctlRequestTime: 1.7994323630000015\n642477 T11 oasc.OverseerTest.testPerformance op: am_i_leader, success: 20103, failure: 0\n642478 T11 oasc.OverseerTest.printTimingStats \t totalTime: 3164.627444\n642478 T11 oasc.OverseerTest.printTimingStats \t avgRequestsPerMinute: 2035.9212322908609\n642478 T11 oasc.OverseerTest.printTimingStats \t 5minRateRequestsPerMinute: 2258.1746414754753\n642478 T11 oasc.OverseerTest.printTimingStats \t 15minRateRequestsPerMinute: 1785.9179009788268\n642478 T11 oasc.OverseerTest.printTimingStats \t avgTimePerRequest: 0.15742065582251405\n642478 T11 oasc.OverseerTest.printTimingStats \t medianRequestTime: 0.141227\n642478 T11 oasc.OverseerTest.printTimingStats \t 75thPctlRequestTime: 0.17663375\n642479 T11 oasc.OverseerTest.printTimingStats \t 95thPctlRequestTime: 0.23308624999999997\n642479 T11 oasc.OverseerTest.printTimingStats \t 99thPctlRequestTime: 0.31163878\n642479 T11 oasc.OverseerTest.printTimingStats \t 999thPctlRequestTime: 4.382885935000004\n\n\n\nFor the worst case (100 collections with stateFormat=2), processing time went down from 592456ms to 344294ms.\n\nThe state processing time has gone up in my patch which I'll fix. "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-14193858",
            "date": "2014-11-02T14:46:26+0000",
            "content": "Here's a better patch which takes care of some of the nocommits:\n\n\tThe live nodes information is read from the ZkStateReader's cluster state because the one in ZkStateWriter's cluster state might be stale\n\tWe force refresh the clusterstate once at the beginning of the loop and then only if there's an error in the main loop.\n\tAdded a simple TestClusterStateMutator, I'll add more.\n\n\n\nI still have a few ideas I'd like to try. "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-14203962",
            "date": "2014-11-09T15:35:04+0000",
            "content": "Patch updated to trunk. "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-14204829",
            "date": "2014-11-10T14:37:33+0000",
            "content": "\n\tRemoved most no-commits (except for the naive performance test in OverseerTest)\n\tProcesses the work queue first in case of an error while writing to ZK (most likely a bad version)\n\tThe BALANCESLICEUNIQUE tests pass (I just made it work but I didn't refactor it into a mutator-like class)\n\n\n\nI think we're very close. This might be a good time for people to review this patch.\n\nI am inclined to remove the separate work queue loop because work queue items are executed in the state update loop anyways. It will just need careful review of the synchronization. "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-14225356",
            "date": "2014-11-25T23:10:06+0000",
            "content": "Updated patch to trunk.\n\nThere's a review request open if someone is interested. See https://reviews.apache.org/r/27872/ "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-14225386",
            "date": "2014-11-25T23:30:22+0000",
            "content": "There's a test failure with the new replica properties feature which I had fixed earlier. Probably something got reverted during the merge. I'll take a look tomorrow. "
        },
        {
            "author": "Noble Paul",
            "id": "comment-14226005",
            "date": "2014-11-26T10:38:53+0000",
            "content": "This is a much needed refatoring for Overseer. good jo. I have not gotten around to do a full review  but I have seen enough of it and looks good. do we have batching of operations in stateFormat=2 now? "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-14228587",
            "date": "2014-11-29T01:45:22+0000",
            "content": "Here's a patch which passes all tests. "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-14228588",
            "date": "2014-11-29T01:46:23+0000",
            "content": "Thanks for the review Noble. No, it doesn't batch stateFormat=2 right now but that's easy to add. I'll add it in the next patch. "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-14228781",
            "date": "2014-11-29T14:51:13+0000",
            "content": "Here's a patch which adds batching of operations for stateFormat=2 as along as the consecutive messages operate on the same collection. It is not possible to preserve atomicity of writes for different collections because they are written to multiple zk nodes.\n\nI think this is ready. I'll commit this patch to trunk as a checkpoint. But I want to refactor a bit more such that the batching can be encapsulated inside ZkStateWriter further simplifying the overseer loop. "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-14228784",
            "date": "2014-11-29T15:11:45+0000",
            "content": "The last patch had some extra changes to ShardSplitTest which I have removed. I have kept the overseer performance test inside OverseerTest but marked it as ignored. I'll commit this shortly. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-14228785",
            "date": "2014-11-29T15:13:43+0000",
            "content": "Im not following this closely, so perhaps this is no help in this case, but there is a zk multi api call that lets you atomically write multiple zk nodes I believe.  "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-14228786",
            "date": "2014-11-29T15:17:58+0000",
            "content": "Im not following this closely, so perhaps this is no help in this case, but there is a zk multi api call that lets you atomically write multiple zk nodes I believe.\n\nThat is helpful. I didn't know that, thanks! If that is true then we can implement true batching for stateFormat=2 collections like what we have for the main cluster state. I'll commit this anyway and work on further changes as a second patch. "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14228801",
            "date": "2014-11-29T15:53:17+0000",
            "content": "Commit 1642437 from shalin@apache.org in branch 'dev/trunk'\n[ https://svn.apache.org/r1642437 ]\n\nSOLR-6554: Speed up overseer operations "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14228809",
            "date": "2014-11-29T16:08:09+0000",
            "content": "Commit 1642443 from shalin@apache.org in branch 'dev/trunk'\n[ https://svn.apache.org/r1642443 ]\n\nSOLR-6554: Removed one-liner methods and unused methods from overseer "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-14228825",
            "date": "2014-11-29T16:27:01+0000",
            "content": "I looked into the multi method in zk but it's limitation is that the combined payload of all the operations in a multi call must be less than 1MB (jute.maxbuffer limit) so it can be a bit tricky to implement. "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14228912",
            "date": "2014-11-29T19:25:03+0000",
            "content": "Commit 1642466 from shalin@apache.org in branch 'dev/trunk'\n[ https://svn.apache.org/r1642466 ]\n\nSOLR-6554: Add a ClusterState.copyWith method which accepts a collection directly instead of a map of collections and use it throughout "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-14228978",
            "date": "2014-11-29T23:38:20+0000",
            "content": "This patch further simplifies the overseer loop and encapsulates batching related code inside ZkStateWriter and refactors common code for message execution into a separate method. The updateState methods are no longer necessary inside Overseer. All tests pass. "
        },
        {
            "author": "Noble Paul",
            "id": "comment-14229041",
            "date": "2014-11-30T08:52:10+0000",
            "content": "IMHO multi write is not really useful . The reason for batching is to minimize the number of listeners fired and the number of clusterstate updates in the listener nodes. So, whether you write those nodes in multiple ops or in a single op does not really matter "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-14229084",
            "date": "2014-11-30T11:35:35+0000",
            "content": "There was a bug in my last refactoring. We must have two different batching checks; one which is checked before the current message is processed and the second which is checked after. Otherwise there is no way to keep messages from different state formats from being batched together. "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-14229085",
            "date": "2014-11-30T11:40:54+0000",
            "content": "IMHO multi write is not really useful . The reason for batching is to minimize the number of listeners fired and the number of clusterstate updates in the listener nodes. So, whether you write those nodes in multiple ops or in a single op does not really matter\n\nI think you may be right but it is worth testing out. The multi write will reduce writes to ZK and maybe reduce the number of watcher fires under the right conditions (interleaved messages for two different collections). I'll do a quick test to see if it helps. "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-14229100",
            "date": "2014-11-30T13:18:08+0000",
            "content": "Fixed another bug with batching code where zk writes before processing items would be lost if the next message creates a new collection. All tests pass. "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-14229830",
            "date": "2014-12-01T14:24:28+0000",
            "content": "I've added a test for the batching logic inside ZkStateWriter. This is ready. "
        },
        {
            "author": "Ramkumar Aiyengar",
            "id": "comment-14229841",
            "date": "2014-12-01T14:31:23+0000",
            "content": "Would be nice to see the updated perf numbers to confirm if the state change regression for stateFormat = 1 has gone away.. "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14229847",
            "date": "2014-12-01T14:37:10+0000",
            "content": "Commit 1642693 from shalin@apache.org in branch 'dev/trunk'\n[ https://svn.apache.org/r1642693 ]\n\nSOLR-6554: Refactored Overseer to improve reuse and put batching logic inside ZkStateWriter. Added a new ZkStateWriterTest. "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-14229852",
            "date": "2014-12-01T14:41:18+0000",
            "content": "bq, Would be nice to see the updated perf numbers to confirm if the state change regression for stateFormat = 1 has gone away..\n\nNo, I suspect the slow down still exists but the overseer itself is faster by ~5% inspite of it. I expect the real performance to be even better when ZK runs on a different box. I still need to dig in to the slowdown though before I close this issue. "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-14229939",
            "date": "2014-12-01T16:03:07+0000",
            "content": "Actually, the improvements in Overseer for stateFormat=1 (the default case) is much better than I expected. After the refactorings, the amILeader calls are very infrequent and the speed up is about 40%:\n\n\nOverseer queue size: 20000 state requests\n\nstateFormat = 1, With refactoring (trunk)\n=========================================\n\n216071 T12 oasc.OverseerTest.testPerformance Overseer loop finished processing: \n216072 T12 oasc.OverseerTest.printTimingStats \t totalTime: 201411.465265\n216072 T12 oasc.OverseerTest.printTimingStats \t avgRequestsPerMinute: 0.004964922311489345\n216073 T12 oasc.OverseerTest.printTimingStats \t 5minRateRequestsPerMinute: 0.0\n216073 T12 oasc.OverseerTest.printTimingStats \t 15minRateRequestsPerMinute: 0.0\n216073 T12 oasc.OverseerTest.printTimingStats \t avgTimePerRequest: 201411.465265\n216073 T12 oasc.OverseerTest.printTimingStats \t medianRequestTime: 201411.465265\n216073 T12 oasc.OverseerTest.printTimingStats \t 75thPctlRequestTime: 201411.465265\n216074 T12 oasc.OverseerTest.printTimingStats \t 95thPctlRequestTime: 201411.465265\n216074 T12 oasc.OverseerTest.printTimingStats \t 99thPctlRequestTime: 201411.465265\n216074 T12 oasc.OverseerTest.printTimingStats \t 999thPctlRequestTime: 201411.465265\n216075 T12 oasc.OverseerTest.testPerformance op: am_i_leader, success: 2, failure: 0\n216075 T12 oasc.OverseerTest.printTimingStats \t totalTime: 9.377281\n216075 T12 oasc.OverseerTest.printTimingStats \t avgRequestsPerMinute: 0.5969575423185497\n216075 T12 oasc.OverseerTest.printTimingStats \t 5minRateRequestsPerMinute: 12.529098642264385\n216075 T12 oasc.OverseerTest.printTimingStats \t 15minRateRequestsPerMinute: 19.324759776433687\n216075 T12 oasc.OverseerTest.printTimingStats \t avgTimePerRequest: 4.6886405\n216076 T12 oasc.OverseerTest.printTimingStats \t medianRequestTime: 4.6886405\n216076 T12 oasc.OverseerTest.printTimingStats \t 75thPctlRequestTime: 9.022041\n216076 T12 oasc.OverseerTest.printTimingStats \t 95thPctlRequestTime: 9.022041\n216076 T12 oasc.OverseerTest.printTimingStats \t 99thPctlRequestTime: 9.022041\n216076 T12 oasc.OverseerTest.printTimingStats \t 999thPctlRequestTime: 9.022041\n216077 T12 oasc.OverseerTest.testPerformance op: update_state, success: 135, failure: 0\n216077 T12 oasc.OverseerTest.printTimingStats \t totalTime: 61.333751\n216077 T12 oasc.OverseerTest.printTimingStats \t avgRequestsPerMinute: 40.31065112174398\n216077 T12 oasc.OverseerTest.printTimingStats \t 5minRateRequestsPerMinute: 48.0\n216078 T12 oasc.OverseerTest.printTimingStats \t 15minRateRequestsPerMinute: 48.0\n216078 T12 oasc.OverseerTest.printTimingStats \t avgTimePerRequest: 0.4543240814814815\n216078 T12 oasc.OverseerTest.printTimingStats \t medianRequestTime: 0.364217\n216078 T12 oasc.OverseerTest.printTimingStats \t 75thPctlRequestTime: 0.409896\n216078 T12 oasc.OverseerTest.printTimingStats \t 95thPctlRequestTime: 0.9332719999999994\n216079 T12 oasc.OverseerTest.printTimingStats \t 99thPctlRequestTime: 3.576287319999995\n216079 T12 oasc.OverseerTest.printTimingStats \t 999thPctlRequestTime: 3.700744\n216079 T12 oasc.OverseerTest.testPerformance op: state, success: 20001, failure: 0\n216081 T12 oasc.OverseerTest.printTimingStats \t totalTime: 13344.072646\n216081 T12 oasc.OverseerTest.printTimingStats \t avgRequestsPerMinute: 5973.226142698651\n216081 T12 oasc.OverseerTest.printTimingStats \t 5minRateRequestsPerMinute: 4437.949777291698\n216082 T12 oasc.OverseerTest.printTimingStats \t 15minRateRequestsPerMinute: 3247.958438006491\n216082 T12 oasc.OverseerTest.printTimingStats \t avgTimePerRequest: 0.6671702737863107\n216083 T12 oasc.OverseerTest.printTimingStats \t medianRequestTime: 0.6112960000000001\n216083 T12 oasc.OverseerTest.printTimingStats \t 75thPctlRequestTime: 0.65861125\n216083 T12 oasc.OverseerTest.printTimingStats \t 95thPctlRequestTime: 0.9373918\n216083 T12 oasc.OverseerTest.printTimingStats \t 99thPctlRequestTime: 1.179823900000002\n216083 T12 oasc.OverseerTest.printTimingStats \t 999thPctlRequestTime: 6.713780613000015\n\n\nstateFormat = 1, Without refactoring (branch_5x):\n============================================================================================\n\n354435 T11 oasc.OverseerTest.testPerformance Overseer loop finished processing: \n354437 T11 oasc.OverseerTest.printTimingStats \t totalTime: 336777.887\n354438 T11 oasc.OverseerTest.printTimingStats \t avgRequestsPerMinute: 0.0029692955509913457\n354438 T11 oasc.OverseerTest.printTimingStats \t 5minRateRequestsPerMinute: 0.0\n354438 T11 oasc.OverseerTest.printTimingStats \t 15minRateRequestsPerMinute: 0.0\n354439 T11 oasc.OverseerTest.printTimingStats \t avgTimePerRequest: 336777.887\n354439 T11 oasc.OverseerTest.printTimingStats \t medianRequestTime: 336777.887\n354439 T11 oasc.OverseerTest.printTimingStats \t 75thPctlRequestTime: 336777.887\n354440 T11 oasc.OverseerTest.printTimingStats \t 95thPctlRequestTime: 336777.887\n354440 T11 oasc.OverseerTest.printTimingStats \t 99thPctlRequestTime: 336777.887\n354440 T11 oasc.OverseerTest.printTimingStats \t 999thPctlRequestTime: 336777.887\n354441 T11 oasc.OverseerTest.testPerformance op: state, success: 20001, failure: 0\n354444 T11 oasc.OverseerTest.printTimingStats \t totalTime: 13029.408\n354444 T11 oasc.OverseerTest.printTimingStats \t avgRequestsPerMinute: 3570.0750281584515\n354444 T11 oasc.OverseerTest.printTimingStats \t 5minRateRequestsPerMinute: 3169.209724490217\n354445 T11 oasc.OverseerTest.printTimingStats \t 15minRateRequestsPerMinute: 2124.6849108211077\n354445 T11 oasc.OverseerTest.printTimingStats \t avgTimePerRequest: 0.6514378281085945\n354445 T11 oasc.OverseerTest.printTimingStats \t medianRequestTime: 0.59\n354446 T11 oasc.OverseerTest.printTimingStats \t 75thPctlRequestTime: 0.633\n354446 T11 oasc.OverseerTest.printTimingStats \t 95thPctlRequestTime: 0.8480999999999999\n354446 T11 oasc.OverseerTest.printTimingStats \t 99thPctlRequestTime: 0.9995200000000004\n354447 T11 oasc.OverseerTest.printTimingStats \t 999thPctlRequestTime: 1.736079000000002\n354447 T11 oasc.OverseerTest.testPerformance op: update_state, success: 222, failure: 0\n354448 T11 oasc.OverseerTest.printTimingStats \t totalTime: 98.244\n354448 T11 oasc.OverseerTest.printTimingStats \t avgRequestsPerMinute: 39.622607985461286\n354448 T11 oasc.OverseerTest.printTimingStats \t 5minRateRequestsPerMinute: 48.0\n354448 T11 oasc.OverseerTest.printTimingStats \t 15minRateRequestsPerMinute: 48.0\n354449 T11 oasc.OverseerTest.printTimingStats \t avgTimePerRequest: 0.44254054054054054\n354449 T11 oasc.OverseerTest.printTimingStats \t medianRequestTime: 0.3835\n354450 T11 oasc.OverseerTest.printTimingStats \t 75thPctlRequestTime: 0.463\n354450 T11 oasc.OverseerTest.printTimingStats \t 95thPctlRequestTime: 0.7994499999999999\n354450 T11 oasc.OverseerTest.printTimingStats \t 99thPctlRequestTime: 1.2152900000000026\n354451 T11 oasc.OverseerTest.printTimingStats \t 999thPctlRequestTime: 2.452\n354451 T11 oasc.OverseerTest.testPerformance op: am_i_leader, success: 223, failure: 0\n354452 T11 oasc.OverseerTest.printTimingStats \t totalTime: 43.33\n354453 T11 oasc.OverseerTest.printTimingStats \t avgRequestsPerMinute: 39.777330428482294\n354453 T11 oasc.OverseerTest.printTimingStats \t 5minRateRequestsPerMinute: 57.7576718337744\n354453 T11 oasc.OverseerTest.printTimingStats \t 15minRateRequestsPerMinute: 65.77963729636123\n354453 T11 oasc.OverseerTest.printTimingStats \t avgTimePerRequest: 0.194304932735426\n354454 T11 oasc.OverseerTest.printTimingStats \t medianRequestTime: 0.149\n354454 T11 oasc.OverseerTest.printTimingStats \t 75thPctlRequestTime: 0.188\n354454 T11 oasc.OverseerTest.printTimingStats \t 95thPctlRequestTime: 0.25839999999999996\n354454 T11 oasc.OverseerTest.printTimingStats \t 99thPctlRequestTime: 0.47591999999999895\n354455 T11 oasc.OverseerTest.printTimingStats \t 999thPctlRequestTime: 5.712\n\n\n\nDo not compare these numbers with the last ones because this test was run on a different box. Also trunk used jdk1.8.0_25 and branch_5x was run on jdk1.7.0_25. I'm running the other tests and I will report back shortly. "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14229992",
            "date": "2014-12-01T16:32:42+0000",
            "content": "Commit 1642708 from shalin@apache.org in branch 'dev/trunk'\n[ https://svn.apache.org/r1642708 ]\n\nSOLR-6554: Moved performance test factors into constants "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-14230004",
            "date": "2014-12-01T16:37:15+0000",
            "content": "Here is one more test with 10 collections all having stateFormat=2\n\n\nstateFormat = 2, 10 collections, With refactoring (trunk):\n===========================================================\n\n244536 T12 oasc.OverseerTest.testPerformance Overseer loop finished processing: \n244541 T12 oasc.OverseerTest.printTimingStats \t totalTime: 230151.969647\n244541 T12 oasc.OverseerTest.printTimingStats \t avgRequestsPerMinute: 0.004344859792294027\n244542 T12 oasc.OverseerTest.printTimingStats \t 5minRateRequestsPerMinute: 0.0\n244542 T12 oasc.OverseerTest.printTimingStats \t 15minRateRequestsPerMinute: 0.0\n244542 T12 oasc.OverseerTest.printTimingStats \t avgTimePerRequest: 230151.969647\n244543 T12 oasc.OverseerTest.printTimingStats \t medianRequestTime: 230151.969647\n244543 T12 oasc.OverseerTest.printTimingStats \t 75thPctlRequestTime: 230151.969647\n244543 T12 oasc.OverseerTest.printTimingStats \t 95thPctlRequestTime: 230151.969647\n244543 T12 oasc.OverseerTest.printTimingStats \t 99thPctlRequestTime: 230151.969647\n244544 T12 oasc.OverseerTest.printTimingStats \t 999thPctlRequestTime: 230151.969647\n244544 T12 oasc.OverseerTest.testPerformance op: am_i_leader, success: 2, failure: 0\n244544 T12 oasc.OverseerTest.printTimingStats \t totalTime: 9.364505\n244544 T12 oasc.OverseerTest.printTimingStats \t avgRequestsPerMinute: 0.5225137226108014\n244545 T12 oasc.OverseerTest.printTimingStats \t 5minRateRequestsPerMinute: 11.527327226155185\n244545 T12 oasc.OverseerTest.printTimingStats \t 15minRateRequestsPerMinute: 18.795347877757326\n244545 T12 oasc.OverseerTest.printTimingStats \t avgTimePerRequest: 4.6822525\n244545 T12 oasc.OverseerTest.printTimingStats \t medianRequestTime: 4.6822525\n244545 T12 oasc.OverseerTest.printTimingStats \t 75thPctlRequestTime: 8.98267\n244546 T12 oasc.OverseerTest.printTimingStats \t 95thPctlRequestTime: 8.98267\n244546 T12 oasc.OverseerTest.printTimingStats \t 99thPctlRequestTime: 8.98267\n244546 T12 oasc.OverseerTest.printTimingStats \t 999thPctlRequestTime: 8.98267\n244546 T12 oasc.OverseerTest.testPerformance op: update_state, success: 20011, failure: 0\n244548 T12 oasc.OverseerTest.printTimingStats \t totalTime: 12520.257356\n244549 T12 oasc.OverseerTest.printTimingStats \t avgRequestsPerMinute: 5230.413197388874\n244549 T12 oasc.OverseerTest.printTimingStats \t 5minRateRequestsPerMinute: 4052.517943905357\n244550 T12 oasc.OverseerTest.printTimingStats \t 15minRateRequestsPerMinute: 3016.875734960303\n244550 T12 oasc.OverseerTest.printTimingStats \t avgTimePerRequest: 0.6256687499875069\n244550 T12 oasc.OverseerTest.printTimingStats \t medianRequestTime: 0.5419605000000001\n244551 T12 oasc.OverseerTest.printTimingStats \t 75thPctlRequestTime: 0.6782735\n244551 T12 oasc.OverseerTest.printTimingStats \t 95thPctlRequestTime: 1.07258755\n244551 T12 oasc.OverseerTest.printTimingStats \t 99thPctlRequestTime: 1.7485102400000028\n244551 T12 oasc.OverseerTest.printTimingStats \t 999thPctlRequestTime: 8.31249523400001\n244552 T12 oasc.OverseerTest.testPerformance op: state, success: 20001, failure: 0\n244554 T12 oasc.OverseerTest.printTimingStats \t totalTime: 14652.769701\n244554 T12 oasc.OverseerTest.printTimingStats \t avgRequestsPerMinute: 5237.58427279227\n244554 T12 oasc.OverseerTest.printTimingStats \t 5minRateRequestsPerMinute: 4130.052867937011\n244555 T12 oasc.OverseerTest.printTimingStats \t 15minRateRequestsPerMinute: 3125.3532353495934\n244555 T12 oasc.OverseerTest.printTimingStats \t avgTimePerRequest: 0.7326018549572522\n244555 T12 oasc.OverseerTest.printTimingStats \t medianRequestTime: 0.6325495\n244555 T12 oasc.OverseerTest.printTimingStats \t 75thPctlRequestTime: 0.771651\n244556 T12 oasc.OverseerTest.printTimingStats \t 95thPctlRequestTime: 1.2006243999999988\n244556 T12 oasc.OverseerTest.printTimingStats \t 99thPctlRequestTime: 2.0507515900000057\n244556 T12 oasc.OverseerTest.printTimingStats \t 999thPctlRequestTime: 8.561998272000013\n\n\nstateFormat = 2, 10 collections, Without refactoring (branch_5x):\n=================================================================\n\n1329102 T11 oasc.OverseerTest.testPerformance Overseer loop finished processing: \n1329105 T11 oasc.OverseerTest.printTimingStats \t totalTime: 1312114.128\n1329106 T11 oasc.OverseerTest.printTimingStats \t avgRequestsPerMinute: 7.621263475999054E-4\n1329107 T11 oasc.OverseerTest.printTimingStats \t 5minRateRequestsPerMinute: 0.0\n1329107 T11 oasc.OverseerTest.printTimingStats \t 15minRateRequestsPerMinute: 0.0\n1329107 T11 oasc.OverseerTest.printTimingStats \t avgTimePerRequest: 1312114.128\n1329107 T11 oasc.OverseerTest.printTimingStats \t medianRequestTime: 1312114.128\n1329108 T11 oasc.OverseerTest.printTimingStats \t 75thPctlRequestTime: 1312114.128\n1329108 T11 oasc.OverseerTest.printTimingStats \t 95thPctlRequestTime: 1312114.128\n1329108 T11 oasc.OverseerTest.printTimingStats \t 99thPctlRequestTime: 1312114.128\n1329108 T11 oasc.OverseerTest.printTimingStats \t 999thPctlRequestTime: 1312114.128\n1329108 T11 oasc.OverseerTest.testPerformance op: state, success: 20001, failure: 0\n1329110 T11 oasc.OverseerTest.printTimingStats \t totalTime: 466104.173\n1329110 T11 oasc.OverseerTest.printTimingStats \t avgRequestsPerMinute: 915.6800211767887\n1329111 T11 oasc.OverseerTest.printTimingStats \t 5minRateRequestsPerMinute: 1418.8474273248714\n1329111 T11 oasc.OverseerTest.printTimingStats \t 15minRateRequestsPerMinute: 1043.4826929249386\n1329111 T11 oasc.OverseerTest.printTimingStats \t avgTimePerRequest: 23.304043447827606\n1329111 T11 oasc.OverseerTest.printTimingStats \t medianRequestTime: 2.3715\n1329111 T11 oasc.OverseerTest.printTimingStats \t 75thPctlRequestTime: 2.7197500000000003\n1329111 T11 oasc.OverseerTest.printTimingStats \t 95thPctlRequestTime: 3.977099999999994\n1329112 T11 oasc.OverseerTest.printTimingStats \t 99thPctlRequestTime: 7.936150000000027\n1329112 T11 oasc.OverseerTest.printTimingStats \t 999thPctlRequestTime: 35.16617800000001\n1329112 T11 oasc.OverseerTest.testPerformance op: update_state, success: 20011, failure: 0\n1329114 T11 oasc.OverseerTest.printTimingStats \t totalTime: 327388.98\n1329114 T11 oasc.OverseerTest.printTimingStats \t avgRequestsPerMinute: 915.6585782350854\n1329114 T11 oasc.OverseerTest.printTimingStats \t 5minRateRequestsPerMinute: 1425.935654658605\n1329115 T11 oasc.OverseerTest.printTimingStats \t 15minRateRequestsPerMinute: 1049.1858608633495\n1329115 T11 oasc.OverseerTest.printTimingStats \t avgTimePerRequest: 16.360450752086354\n1329115 T11 oasc.OverseerTest.printTimingStats \t medianRequestTime: 0.725\n1329116 T11 oasc.OverseerTest.printTimingStats \t 75thPctlRequestTime: 0.844\n1329116 T11 oasc.OverseerTest.printTimingStats \t 95thPctlRequestTime: 1.218\n1329117 T11 oasc.OverseerTest.printTimingStats \t 99thPctlRequestTime: 2.1403600000000043\n1329117 T11 oasc.OverseerTest.printTimingStats \t 999thPctlRequestTime: 12.222141000000011\n1329117 T11 oasc.OverseerTest.testPerformance op: am_i_leader, success: 20013, failure: 0\n1329119 T11 oasc.OverseerTest.printTimingStats \t totalTime: 3622.9\n1329120 T11 oasc.OverseerTest.printTimingStats \t avgRequestsPerMinute: 915.5821178966359\n1329120 T11 oasc.OverseerTest.printTimingStats \t 5minRateRequestsPerMinute: 1424.927585830734\n1329120 T11 oasc.OverseerTest.printTimingStats \t 15minRateRequestsPerMinute: 1042.4347274913655\n1329121 T11 oasc.OverseerTest.printTimingStats \t avgTimePerRequest: 0.18102733223404788\n1329121 T11 oasc.OverseerTest.printTimingStats \t medianRequestTime: 0.179\n1329121 T11 oasc.OverseerTest.printTimingStats \t 75thPctlRequestTime: 0.197\n1329122 T11 oasc.OverseerTest.printTimingStats \t 95thPctlRequestTime: 0.25909999999999994\n1329122 T11 oasc.OverseerTest.printTimingStats \t 99thPctlRequestTime: 0.5761600000000034\n1329123 T11 oasc.OverseerTest.printTimingStats \t 999thPctlRequestTime: 17.419063000000026\n\n\n\nI'm not going to run more tests simply because they take too much time  "
        },
        {
            "author": "Mark Miller",
            "id": "comment-14230056",
            "date": "2014-12-01T17:16:31+0000",
            "content": "or stateFormat = 1 has gone away\n\nWhat kind of confidence do we have for stateFormat = 2 now? It would really be nice to drop 1 from 5x rather than deal with both for a full major version again. "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-14230266",
            "date": "2014-12-01T19:10:54+0000",
            "content": "What kind of confidence do we have for stateFormat = 2 now? \n\nI am pretty confident that it works and works well. But the client side needs a fix before 5.0 \u2013 SOLR-6521.\n\nIt would really be nice to drop 1 from 5x rather than deal with both for a full major version again.\n\nI agree but how do we drop 1? I haven't thought through the migration process. It would probably need us to write the state to both places for one Solr release to auto-convert. Otherwise an upgrade would require down-time. We could definitely use stateFormat=2 as the default in 5.0 as it is already as performant as stateFormat=1 for the single collection use-case. "
        },
        {
            "author": "Ramkumar Aiyengar",
            "id": "comment-14230488",
            "date": "2014-12-01T21:23:44+0000",
            "content": "Nice, that's a pretty neat speedup \n\n+1 to make stateFormat=2 as the default. The idea of dropping support for stateFormat=1 makes me a bit nervous though \u2013 it should be tested in the wild for a while without users consciously opting in into it.  May be schedule it for removal in 6 (thereby also giving users one full release to either get downtime or recreate indices)? "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-14231762",
            "date": "2014-12-02T17:17:22+0000",
            "content": "There is one problem in my current implementation. Earlier, the work queue was guaranteed to have only those items which had been processed but not written to ZK. This condition is not true anymore after my refactoring because the batching logic is inside ZkStateWriter and it will write to ZK without the Overseer knowing about it. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-14237203",
            "date": "2014-12-07T16:54:56+0000",
            "content": "I don't think we need to support live migrations over major versions. I think this really holds back development. Major releases can break all kinds of back compat - I think the only thing we are on the hook for is a transition path - but not a live one. Live upgrades over major releases is not very realistic IMO. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-14237204",
            "date": "2014-12-07T16:58:15+0000",
            "content": "Bq. Why not in 6?\n\nSupporting both over 5x will stunt development for an unknown, but probably pretty long amount of time. \n\nI think anyone that is nervous about it should probably wait on 4 for a few point releases. The first release of a major version jump is by definition going to have some larger changes and new bugs.  "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-14249904",
            "date": "2014-12-17T14:33:49+0000",
            "content": "\n\tFixes the logic to add/remove items from workQueue so that the invariant is maintained\n\tAdds a ZkWriteListener interface which is used by Overseer to add/remove items from the workQueue depending on how/when state is flushed to ZK\n\tThe earlier patches enabled batching on work queue processing but that is wrong because we do not have any fallback if a batch fails. So batching is disabled whenever we operate on items from the work queue.\n\n "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-14250076",
            "date": "2014-12-17T16:30:35+0000",
            "content": "Slightly refactored. All tests pass. "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-14251657",
            "date": "2014-12-18T13:47:56+0000",
            "content": "Refactored a bit more. ZkWriteListener is called ZkWriteCallback instead. There was no need of a onFlushBefore and onFlushAfter methods. A single onWrite method is enough. I am not very happy with this callback API but this is the best I could come up. The other option would be to move the batching logic back to Overseer. "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14251776",
            "date": "2014-12-18T15:13:42+0000",
            "content": "Commit 1646474 from shalin@apache.org in branch 'dev/trunk'\n[ https://svn.apache.org/r1646474 ]\n\nSOLR-6554: Fix work queue handling "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14251913",
            "date": "2014-12-18T17:17:12+0000",
            "content": "Commit 1646493 from shalin@apache.org in branch 'dev/branches/branch_5x'\n[ https://svn.apache.org/r1646493 ]\n\nSOLR-6554: Speed up overseer operations "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-14251935",
            "date": "2014-12-18T17:45:23+0000",
            "content": "This is fixed. Thanks everyone.\n\nLet's discuss stateFormat=2 as default for 5.0 in it's own separate issue. "
        },
        {
            "author": "Anshum Gupta",
            "id": "comment-14332886",
            "date": "2015-02-23T05:02:26+0000",
            "content": "Bulk close after 5.0 release. "
        }
    ]
}