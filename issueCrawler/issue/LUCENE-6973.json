{
    "id": "LUCENE-6973",
    "title": "Improve TeeSinkTokenFilter",
    "details": {
        "resolution": "Fixed",
        "affect_versions": "None",
        "components": [],
        "labels": "",
        "fix_versions": [
            "5.5",
            "6.0"
        ],
        "priority": "Minor",
        "status": "Closed",
        "type": "Improvement"
    },
    "description": "TeeSinkTokenFilter can be improved in several ways, as it's written today:\n\nThe most major one is removing SinkFilter which just doesn't work and is confusing. E.g., if you set a SinkFilter which filters tokens, the attributes on the stream such as PositionIncrementAttribute are not updated. Also, if you update any attribute on the stream, you affect other SinkStreams ... It's best if we remove this confusing class, and let consumers reuse existing TokenFilters by chaining them to the sink stream.\n\nAfter we do that, we can make all the cached states a single (immutable) list, which is shared between all the sink streams, so we don't need to keep many references around, and also deal with WeakReference.\n\nBesides that there are some other minor improvements to the code that will come after we clean up this class.\n\nFrom a backwards-compatibility standpoint, I don't think that SinkFilter is actually used anywhere (since it just ... confusing and doesn't work as expected), and therefore I believe it won't affect anyone. If however someone did implement a SinkFilter, it should be trivial to convert it to a TokenFilter and chain it to the SinkStream.",
    "attachments": {
        "LUCENE-6973.patch": "https://issues.apache.org/jira/secure/attachment/12782110/LUCENE-6973.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "id": "comment-15094299",
            "author": "Paul Elschot",
            "date": "2016-01-12T17:03:31+0000",
            "content": "At LUCENE-5687 there is a PrefillTokenStream class that is basically a superclass extracted from TeeSinkTokenFilter.\nI'm using PrefillTokenStream objects as targets for splitting a token stream into multiple streams.\n\nIirc tried to use SinkFilter at first, but it was easier to extract the superclass and avoid SinkFilter.\nSo I would not mind losing SinkFilter.\n\n "
        },
        {
            "id": "comment-15094317",
            "author": "Paul Elschot",
            "date": "2016-01-12T17:14:27+0000",
            "content": "After another look at the code, I think PrefillTokenStream could be a nice starting point to improve TeeSinkTokenFilter. "
        },
        {
            "id": "comment-15096776",
            "author": "Uwe Schindler",
            "date": "2016-01-13T18:50:34+0000",
            "content": "Hi, I agree with Shai's proposal! So +1 to fix this. "
        },
        {
            "id": "comment-15096813",
            "author": "Shai Erera",
            "date": "2016-01-13T19:05:35+0000",
            "content": "Patch implements the proposed changes. "
        },
        {
            "id": "comment-15096886",
            "author": "Paul Elschot",
            "date": "2016-01-13T19:59:04+0000",
            "content": "The patch has changes to DateRecognizerFilter.java, but I don't see that in trunk.\nThere is this in trunk: lucene/analysis/common/src/java/org/apache/lucene/analysis/sinks/DateRecognizerSinkFilter.java\n\nFor which branch is the patch? "
        },
        {
            "id": "comment-15096892",
            "author": "Shai Erera",
            "date": "2016-01-13T20:04:10+0000",
            "content": "This patch is for trunk. I renamed DateRecognizerSinkFilter to DateRacognizerFilter. When I do svn stat I get this:\n\n\nA  +    lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/DateRecognizerFilter.java\n        > moved from lucene/analysis/common/src/java/org/apache/lucene/analysis/sinks/DateRecognizerSinkFilter.java\n\n "
        },
        {
            "id": "comment-15096912",
            "author": "Uwe Schindler",
            "date": "2016-01-13T20:13:56+0000",
            "content": "When you execute svn diff, add the option to show renames as adds:  --show-copies-as-adds "
        },
        {
            "id": "comment-15096926",
            "author": "Shai Erera",
            "date": "2016-01-13T20:26:45+0000",
            "content": "Patch w/ --show-copies-as-adds "
        },
        {
            "id": "comment-15096946",
            "author": "Paul Elschot",
            "date": "2016-01-13T20:37:44+0000",
            "content": "Ok, somehow I can't cleanly apply the patch, neither with patch, nor with git, nor with svn.\n\nBut as AFAICT in TeeSinkTokenFilter this uses a ArrayDeque instead of an ArrayList and it drops the accept method. That was in the way for PrefillTokenStream too, which is why I needed to extract the superclass. I'm fine with dropping that method.\n\n\nI get the best result with svn, which gives this output::\n\nsvn patch ~/patches/LUCENE-6973.patch\nU         lucene/CHANGES.txt\nSkipped missing target: 'lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/DateRecognizerFilter.java'\nA         lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/DateRecognizerFilterFactory.java\nSkipped missing target: 'lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/TokenRangeFilter.java'\nA         lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/TokenRangeFilterFactory.java\nSkipped missing target: 'lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/TokenTypeFilter.java'\nA         lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/TokenTypeFilterFactory.java\nD         lucene/analysis/common/src/java/org/apache/lucene/analysis/sinks/DateRecognizerSinkFilter.java\nU         lucene/analysis/common/src/java/org/apache/lucene/analysis/sinks/TeeSinkTokenFilter.java\nD         lucene/analysis/common/src/java/org/apache/lucene/analysis/sinks/TokenRangeSinkFilter.java\nD         lucene/analysis/common/src/java/org/apache/lucene/analysis/sinks/TokenTypeSinkFilter.java\nU         lucene/analysis/common/src/java/org/apache/lucene/analysis/sinks/package-info.java\nU         lucene/analysis/common/src/resources/META-INF/services/org.apache.lucene.analysis.util.TokenFilterFactory\nSkipped missing target: 'lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/DateRecognizerTokenFilterTest.java'\nSkipped missing target: 'lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TokenRangeFilterTest.java'\nSkipped missing target: 'lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TokenTypeFilterTest.java'\nD         lucene/analysis/common/src/test/org/apache/lucene/analysis/sinks/DateRecognizerSinkTokenizerTest.java\nU         lucene/analysis/common/src/test/org/apache/lucene/analysis/sinks/TestTeeSinkTokenFilter.java\nD         lucene/analysis/common/src/test/org/apache/lucene/analysis/sinks/TokenRangeSinkTokenizerTest.java\nD         lucene/analysis/common/src/test/org/apache/lucene/analysis/sinks/TokenTypeSinkTokenizerTest.java\nU         lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase.java\nSummary of conflicts:\n  Skipped paths: 6\n\n\n\nI'm probably doing something wrong here, but please go ahead as you see fit. "
        },
        {
            "id": "comment-15096958",
            "author": "Paul Elschot",
            "date": "2016-01-13T20:45:47+0000",
            "content": "With the 2nd patch I get this output:\n\nsvn patch ~/patches/LUCENE-6973b.patch\nU         lucene/CHANGES.txt\nA         lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/DateRecognizerFilter.java\nSkipped missing target: 'lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/DateRecognizerFilterFactory.java'\nA         lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/TokenRangeFilter.java\nSkipped missing target: 'lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/TokenRangeFilterFactory.java'\nA         lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/TokenTypeFilter.java\nSkipped missing target: 'lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/TokenTypeFilterFactory.java'\nD         lucene/analysis/common/src/java/org/apache/lucene/analysis/sinks/DateRecognizerSinkFilter.java\nU         lucene/analysis/common/src/java/org/apache/lucene/analysis/sinks/TeeSinkTokenFilter.java\nD         lucene/analysis/common/src/java/org/apache/lucene/analysis/sinks/TokenRangeSinkFilter.java\nD         lucene/analysis/common/src/java/org/apache/lucene/analysis/sinks/TokenTypeSinkFilter.java\nU         lucene/analysis/common/src/java/org/apache/lucene/analysis/sinks/package-info.java\nU         lucene/analysis/common/src/resources/META-INF/services/org.apache.lucene.analysis.util.TokenFilterFactory\nA         lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/DateRecognizerTokenFilterTest.java\nA         lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TokenRangeFilterTest.java\nA         lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TokenTypeFilterTest.java\nD         lucene/analysis/common/src/test/org/apache/lucene/analysis/sinks/DateRecognizerSinkTokenizerTest.java\nU         lucene/analysis/common/src/test/org/apache/lucene/analysis/sinks/TestTeeSinkTokenFilter.java\nD         lucene/analysis/common/src/test/org/apache/lucene/analysis/sinks/TokenRangeSinkTokenizerTest.java\nD         lucene/analysis/common/src/test/org/apache/lucene/analysis/sinks/TokenTypeSinkTokenizerTest.java\nU         lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase.java\nSummary of conflicts:\n  Skipped paths: 3\n\n\n\nThat's only half of the earlier skipped paths.\nBut I'm only interested in TeeSinkTokenFilter, and that is definitely improved. "
        },
        {
            "id": "comment-15096973",
            "author": "Paul Elschot",
            "date": "2016-01-13T20:57:22+0000",
            "content": "Btw. in case there is preference for ArrayDeque over ArrayList, CachingTokenFilter could also be changed for that.\nSee also LUCENE-6033, first patch. "
        },
        {
            "id": "comment-15097291",
            "author": "Uwe Schindler",
            "date": "2016-01-13T23:39:58+0000",
            "content": "Btw. in case there is preference for ArrayDeque over ArrayList, CachingTokenFilter could also be changed for that.\n\nI don't think we need a Deque here or there. We only add elements at the end, so ArrayList is fine, also for the States here. ArrayDeque is only better as replacement for a LinkedList, where you want to remove or insert elements at start of list (where a LinkedList is fine, but ArrayList involves copying on each insert/delete). But LinkedList was also wrong for the use-case here. We just add elements at the end and it gets unmodifiable at end. The iterator is happy, too. ArrayList is also slightly faster because it does not need to check 2 bounds.\n\nShai: The Javadocs of the SinkFilter replacements are partly misleading (they still talk about sinks, although it is no longer related to TeeSink).\n\nI will further look into this patch tomorrow, this was just my first thoughts. "
        },
        {
            "id": "comment-15097688",
            "author": "Shai Erera",
            "date": "2016-01-14T06:19:34+0000",
            "content": "Patch with following changes:\n\n\n\tChange from Deque to List. Uwe, I thought that in our discussions you mentioned that you prefer ArrayDeque, even though I agree that in this case, since we don't remove any elements, I don't think it has benefits over simple ArrayList).\n\n\n\n\n\tChange the new filters unit tests to not use TeeSinkTokenFilter at all, as it's unrelated anymore.\n\n\n\nUwe, besides that, I didn't find any javadocs that refer to SinkFilter, can you please cite an example? "
        },
        {
            "id": "comment-15097794",
            "author": "Paul Elschot",
            "date": "2016-01-14T08:14:30+0000",
            "content": "2nd and 3rd patch apply cleanly now, before applying the 2nd patch I had forgotten to remove the earlier added files that were left by \n\nsvn revert -R .\n\n\nPrefillTokenStream of LUCENE-5687 has a different constructor argument (AttributeSource), so it is not easily replaced by the TeeSinkTokenFilter here.\nI'll deal with that later there. "
        },
        {
            "id": "comment-15098108",
            "author": "Shai Erera",
            "date": "2016-01-14T13:46:15+0000",
            "content": "I missed the mention of 'sink' in DateRecognizerFilter. "
        },
        {
            "id": "comment-15098252",
            "author": "Shai Erera",
            "date": "2016-01-14T15:29:36+0000",
            "content": "I think that's ready for commit. Uwe Schindler if you don't have any more comments, I'll go ahead. "
        },
        {
            "id": "comment-15098278",
            "author": "Uwe Schindler",
            "date": "2016-01-14T15:48:12+0000",
            "content": "STOP: I think you added some missing TokenFilters to wrong SPI file! lucene/analysis/common/src/resources/META-INF/services/org.apache.lucene.analysis.util.TokenFilterFactory\n\nShould be in its own JAR file for every module. "
        },
        {
            "id": "comment-15098302",
            "author": "Uwe Schindler",
            "date": "2016-01-14T16:00:53+0000",
            "content": "Can you simple revert the addition of stempel (which is already there in its own JAR file) and phonetic filters. They are not part of analysis-common!\n\nThe test fails currently on Eclipse, because classpath is setup in wrong way. "
        },
        {
            "id": "comment-15098303",
            "author": "Uwe Schindler",
            "date": "2016-01-14T16:02:00+0000",
            "content": "org.apache.lucene.analysis.phonetic.DaitchMokotoffSoundexFilterFactory is missing in phonetic's SPI file, but thats a separate issue. Please open issue. "
        },
        {
            "id": "comment-15098338",
            "author": "Shai Erera",
            "date": "2016-01-14T16:21:07+0000",
            "content": "Good catch Uwe Schindler! Removed. "
        },
        {
            "id": "comment-15098394",
            "author": "Uwe Schindler",
            "date": "2016-01-14T16:58:17+0000",
            "content": "OK looks fine. I did not run tests, I wonder why the tests of CustomAnalyzer or similar did not catch the non-existent classes. "
        },
        {
            "id": "comment-15098798",
            "author": "Shai Erera",
            "date": "2016-01-14T20:34:29+0000",
            "content": "I ran the tests and TestRandomChains fails with this:\n\n\n   [junit4]   2> NOTE: Windows 7 6.1 amd64/Oracle Corporation 1.8.0_40 (64-bit)/cpus=8,threads=1,free=393306544,total=510656512\n   [junit4]   2> NOTE: All tests run in this JVM: [TestRandomChains]\n   [junit4]   2> NOTE: reproduce with: ant test  -Dtestcase=TestRandomChains -Dtests.seed=5FF882C20C905C54 -Dtests.slow=true -Dtests.locale=cs -Dtests.timezone=America/Buenos_Aires -Dtests.asserts=true -Dtests.file.encoding=ISO-8859-1\n   [junit4] ERROR   0.00s | TestRandomChains (suite) <<<\n   [junit4]    > Throwable #1: java.lang.AssertionError: public org.apache.lucene.analysis.miscellaneous.DateRecognizerFilter(org.apache.lucene.analysis.TokenStream,java.text.DateFormat) has unsupported parameter types\n   [junit4]    >        at __randomizedtesting.SeedInfo.seed([5FF882C20C905C54]:0)\n   [junit4]    >        at org.apache.lucene.analysis.core.TestRandomChains.beforeClass(TestRandomChains.java:233)\n   [junit4]    >        at java.lang.Thread.run(Thread.java:745)\n\n\n\nI tracked it to argProducers not having DataFormat defined. Is it OK to add it? "
        },
        {
            "id": "comment-15101221",
            "author": "Shai Erera",
            "date": "2016-01-15T05:20:28+0000",
            "content": "Patch addresses the following:\n\n\n\tRemoves TokenTypeFilter (I found TypeTokenFilter which does the same and more).\n\n\n\n\n\tRemoves TokenRangeFilter: the old one (Sink) had a bug IMO and in general I don't find this filter useful. It doesn't take into account other filters which drop tokens, so if you pass the range 3,5 it's not clear if you expect the original 3-5 terms, or any terms numbered 3-5. Anyway, I think it's trivial to implement if someone really needs such a filter, we don't have to offer it out-of-the-box.\n\n\n\n\n\tAdded an argProducer to TestRandomChains.\n\n\n\nUwe Schindler I think it's ready. Would appreciate a final review though. "
        },
        {
            "id": "comment-15101389",
            "author": "Uwe Schindler",
            "date": "2016-01-15T07:48:44+0000",
            "content": "Yes, the only way to do this. I think we have a similar one already for some other date-related stuff. "
        },
        {
            "id": "comment-15101393",
            "author": "Uwe Schindler",
            "date": "2016-01-15T07:50:59+0000",
            "content": "Oh missed last comment. Yes will do final review. I agree with the removal. Maybe make a API hint in CHANGES.txt to direct users to replacements for SinkFilters. "
        },
        {
            "id": "comment-15101399",
            "author": "Uwe Schindler",
            "date": "2016-01-15T07:54:45+0000",
            "content": "The FilterFactory for the data detection should also list a locale:\nthis.dateFormat = datePattern != null ? new SimpleDateFormat(datePattern, Locale.ROOT) : null; is not useful for custom formatted dates. E.g. the root locale has no month names in CLDR (which happened in Java 9), only \"Month 1\" \n\nSo The factory should also take a locale (we have that at other places, too).\n\nThe default in the filter should better use Locale.ENGLISH, otherwise it will likely break with Java 9. "
        },
        {
            "id": "comment-15101431",
            "author": "Shai Erera",
            "date": "2016-01-15T08:25:24+0000",
            "content": "Thanks Uwe Schindler for the review. I added some notes to CHANGES as well Locale support to the factory. "
        },
        {
            "id": "comment-15101502",
            "author": "Uwe Schindler",
            "date": "2016-01-15T09:02:28+0000",
            "content": "Hi,\n\nstill Javadocs of the default are wrong, it should say that it uses english language to detect date formats by default. Also there is Locale.ROOT used in one example with month names.\n\nCurrently, I am not sure if forLanguageTag() is a good idea, because this one may not accept the usual formatting with underscore, like \"en_US\" - haven't tried (there is also no test of factory). In LuceneTestCase we use a handwritten method static Locale localeForName(String localeName). But I am not 100% sure if this is just a relict from pre-Java-7 days. Maybe Robert Muir can comment on this. If forLanguageTag() is fine, we could also use it in LTC. "
        },
        {
            "id": "comment-15101511",
            "author": "Uwe Schindler",
            "date": "2016-01-15T09:07:54+0000",
            "content": "Robert had a comment on: LUCENE-4021 "
        },
        {
            "id": "comment-15101528",
            "author": "Uwe Schindler",
            "date": "2016-01-15T09:18:17+0000",
            "content": "I tried it: forLanguage tag does not accept \"en_US\", it returns the root locale instead!!! Not even throwing Exception! (see javadocs). So we should maybe add the LTC method into a Utility class. It works with \"en-US\", but people would not use that. So Java 7 is still missing a method to construct a Locale from their toString() output. "
        },
        {
            "id": "comment-15101551",
            "author": "Robert Muir",
            "date": "2016-01-15T09:49:37+0000",
            "content": "Try this:\n\nIf the specified language tag contains any ill-formed subtags, the first such subtag and all following subtags are ignored. Compare to Locale.Builder.setLanguageTag(java.lang.String) which throws an exception in this case.  "
        },
        {
            "id": "comment-15101554",
            "author": "Robert Muir",
            "date": "2016-01-15T09:52:49+0000",
            "content": "and i dont know if that will fix your en_US problem, i think not, but it should be less lenient at least.\n\nin general i prefer language tags rather than a ton of locale options. And it has the ability to pass some super-expert stuff just via one parameter (e.g. alternate calendar). but we may need to add some checks to prevent mistakes like what you show. "
        },
        {
            "id": "comment-15101559",
            "author": "Uwe Schindler",
            "date": "2016-01-15T10:02:46+0000",
            "content": "I also agree that language tag (because they are \"standardized\") would better match. For LTC there is no backwards problem, and the one here is new. But we should also review Solr code where it tries to parse Locale names.\n\nSo I think we should also open a separate issue:\n\n\tlet LTC print the language tag instead of toString() on failures\n\tmake LTC parse the input locale using the builder that throws exception.\n\n\n\nFor the current factory, we should use the non-lenient variant with Locale.Builder. Because resolving \"en_US\" to the root locale is a no-go. "
        },
        {
            "id": "comment-15101577",
            "author": "Uwe Schindler",
            "date": "2016-01-15T10:18:56+0000",
            "content": "I checked:\n\n\nnew Locale.Builder().setLanguageTag(\"en_US\").build()\n\n\n\nThis works as expected. On \"en_US\" it throws: java.util.IllformedLocaleException: Invalid subtag: en_US [at index 0]\n\"en-us\" or \"en-US\" works as expected. "
        },
        {
            "id": "comment-15101587",
            "author": "Shai Erera",
            "date": "2016-01-15T10:26:02+0000",
            "content": "Thanks Uwe Schindler and Robert Muir. Patch adds DateRecognizerFilterFactoryTest and moves to use Locale.Builder. I also fixed the javadocs to reflect that. "
        },
        {
            "id": "comment-15101725",
            "author": "Uwe Schindler",
            "date": "2016-01-15T12:49:25+0000",
            "content": "+1 to commit, only a small change: Use LTC.getRandomLocale(Random) in the ArgProducer. "
        },
        {
            "id": "comment-15101730",
            "author": "ASF subversion and git services",
            "date": "2016-01-15T12:55:49+0000",
            "content": "Commit 1724789 from Shai Erera in branch 'dev/trunk'\n[ https://svn.apache.org/r1724789 ]\n\nLUCENE-6973: Improve TeeSinkTokenFilter "
        },
        {
            "id": "comment-15101736",
            "author": "ASF subversion and git services",
            "date": "2016-01-15T13:02:30+0000",
            "content": "Commit 1724795 from Shai Erera in branch 'dev/branches/branch_5x'\n[ https://svn.apache.org/r1724795 ]\n\nLUCENE-6973: Improve TeeSinkTokenFilter "
        },
        {
            "id": "comment-15101738",
            "author": "Shai Erera",
            "date": "2016-01-15T13:03:37+0000",
            "content": "Thanks Uwe Schindler, I addressed your last comment in the commit. "
        },
        {
            "id": "comment-15101750",
            "author": "Uwe Schindler",
            "date": "2016-01-15T13:12:44+0000",
            "content": "I opened LUCENE-6978 about improving LTC. "
        }
    ]
}