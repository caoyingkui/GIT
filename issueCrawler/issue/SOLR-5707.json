{
    "id": "SOLR-5707",
    "title": "Lucene Expressions in Solr",
    "details": {
        "affect_versions": "None",
        "status": "Open",
        "fix_versions": [],
        "components": [],
        "type": "New Feature",
        "priority": "Major",
        "labels": "",
        "resolution": "Unresolved"
    },
    "description": "Expressions should be available for use in Solr.",
    "attachments": {
        "SOLR-5707.patch": "https://issues.apache.org/jira/secure/attachment/12627655/SOLR-5707.patch",
        "SOLR-5707_vsp.patch": "https://issues.apache.org/jira/secure/attachment/12641522/SOLR-5707_vsp.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Ryan Ernst",
            "id": "comment-13894761",
            "date": "2014-02-07T17:43:52+0000",
            "content": "Initial patch with tests.\n\nExpressions are set in the schema via a ComputedField, with an <expression> child (this allows using CDATA instead of having to escape special characters as you would in an attribute). The bindings are pluggable via a BindingsFactory.  All numeric fields in the schema are available via the default bindings.\n\nNote: I'm not happy with the difficulty in using custom xml children nodes for a field type, but I didn't want to tackle that here. "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13894844",
            "date": "2014-02-07T18:52:09+0000",
            "content": "Hey Ryan,\n\nPlease forgive my ignorance of the expression stuff, but can you comment on your choice to leverage them in Solr via this new \"ComputedField\" FieldType instead of as a new implementation of ValueSourceParser ?  (i'm trying to wrap my head around if/why this \"expression based psuedo-field declared in schema.xml\" idea is better then an \"expression based psuedo-field declared at request time via a function\".)\n\nNote: I'm not happy with the difficulty in using custom xml children nodes for a field type, but I didn't want to tackle that here.\n\nYeah ... rather then add more custom XML parsing + special method call hooks in IndexSchema, we may want to consider biting the bullet and opening a new issue to add a marker Interface any FieldType can use, and then TextField & your new ComputedField can both implement...\n\npublic interface FieldTypeThatSupportsComplexNestedXmlNodeIniti {\n  public void giveMeMyChildNodes(NodeList children) throws SolrException;\n}\n\n\n...but i know sarowe is looking towards a future where more things in the schema.xml can be programatically defined via APIs, so that would probably be a step in the direction of giving him a heart attack. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13894861",
            "date": "2014-02-07T19:01:09+0000",
            "content": "Hoss: i'd like to see something like both possibilities myself.\n\nhaving these things statically has some advantages: e.g. from the case where you see it as a modified ranking function. In this \"static case\" you compile up-front and re-use the same class and get more advantages from e.g. hotspot: its as if you wrote a comparator in java yourself. It has a performance advantage over doing it \"dynamically\" (maybe 10% or so). But the latter would be very convenient and flexible, for when the expression is query-dependent (e.g. incorporating distance-type stuff) too. "
        },
        {
            "author": "Ryan Ernst",
            "id": "comment-13894881",
            "date": "2014-02-07T19:19:04+0000",
            "content": "I think Robert summed up the reasons to allow static via a pseudo field well.  I do plan on doing the dynamic as well, but I wanted to get this in as a base, since dynamic will be more challenging, IMO.\n\n\nYeah ... rather then add more custom XML parsing + special method call hooks in IndexSchema, we may want to consider biting the bullet and opening a new issue to add a marker Interface any FieldType can use, and then TextField & your new ComputedField can both implement...\nRight, as I noted, I didn't want to chew that off here.  But if you think it is important to not make the craziness (FieldTypePluginLoader) any crazier, I can take a stab. "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13894986",
            "date": "2014-02-07T20:23:55+0000",
            "content": "... In this \"static case\" you compile up-front and re-use the same class and get more advantages from e.g. hotspot: its as if you wrote a comparator in java yourself. ...\n\nOk, yeah ... that makes sense, but I'm still wondering if a FieldType is really the right approach here, as opposed to a ValueSourceParser where the expressions are explicitly configured & pre-compiled, something along the lines of....\n\n<valueSourceParser name=\"expression\"class=\"solr.StaticExpresionValueSourceParser\">\n  <lst name=\"bindings\">\n    ...\n  </lst>\n  <lst name=\"expressions\">\n    <!-- used via function:  expression(myexpr) -->\n    <str name=\"myexpr\">price * 2</str>\n    ...\n  </lst>\n</valueSourceParser>\n\n\n\nThat seems like it could provide the same pre-compile/re-use advantage as the ComputedField approach you're using here, w/o some of the baggage of schema & FieldTypes \u2013 ie: confusion people might have about whether a ComputedField is/can/should-be indexed=\"true\" or stored=\"true\", the need for both a <fieldType/> and a <field/> and what happens if you point 2 <field/>s at the same <fieldType class=\"ComputedField\" />, etc...\n\nBasically I'm just trying to wrap my head around whether, from an abstraction standpoint, it really makes sense for Expressions to be available as a FieldType, and that we're not shoehorning them in.\n\nFor comparison: I think in hindsight, most people would agree our existing \"psuedo-fields\" like ExternalFileField and RandomSortField are kind of confusing and would probably make more sense as ValueSourceParser \u2013 we just didn't have that concept when those field types were created.\n\n\n(It's also not clear to me if it can/should be possible for expressions to wrap other value sources (via a name mapping specified in the bindings i guess?) in which case maybe that would be more straight forward via the ValueSourceParser approach? .. not really sure.)\n\nRight, as I noted, I didn't want to chew that off here. But if you think it is important to not make the craziness (FieldTypePluginLoader) any crazier, I can take a stab.\n\nSorry, i wasn't trying to push you in that direction \u2013 just tossing it out as a suggestion.\n\nLet me put it this way: if ComputedField is in fact the way to go, and if you think introducing something like the marker interface i mentioned & using it in your ComputedField would be simpler/cleaner/easier to understand then existing ComputedField explicit hacks you had to put in your patch to make it work (i've only skimmed it, and i only half thought through the idea so i'm not sure at all) then we might as well generalize it.  But: if it makes this issue more complicated, then certainly just punt on it \u2013 leave the patch like you've got it and we can open a new issue to revisit the more generalized FieldType init question. "
        },
        {
            "author": "Ryan Ernst",
            "id": "comment-13905969",
            "date": "2014-02-19T19:52:10+0000",
            "content": "\n ie: confusion people might have about whether a ComputedField is/can/should-be indexed=\"true\" or stored=\"true\"\nI was going to add checks to make sure nothing is set, but forgot.\n\n\nBasically I'm just trying to wrap my head around whether, from an abstraction standpoint, it really makes sense for Expressions to be available as a FieldType, and that we're not shoehorning them in.\n\nThat is a fair question. So doing this through a valueSourceParser would just make them accessible through a custom function in function queries?  But expressions are not equal to function queries!  Expressions can use the score and manipulate it any way they want (see examples in lucene expressions tests).  But my understanding of function queries is they add to the score, replacing it?  With expressions, you could have 3 different expressions you sort on, some of which might use the score, and get all 4 values back, in order to evaluate and debug. I think expressions make sense outside of function queries.  So I see two possibilities:\n\n\tImplement expression integration similar to how function queries work, possibly by adding \"lang\" or \"type\" or something like that to the QP so that you could choose which language (in this case, the lang would be \"js\" for current expressions, but there could be more in the future)\n\tUse pseudo fields like I have in the current patch (I'm just saying that it is an option, not that I prefer it over the other)\n\n\n\nThe advantage of #1 is that we get dynamic (defined in a search request) for free, while with pseudo fields there is no clear path.  I am not a fan of using query parsers like this (these aren't actually queries!), but it works..\n\n\n\n<lst name=\"bindings\">\n    ...\n  </lst>\n\n\n\nI think bindings are very much tied to the schema.  The default bindings should be mappings to the (numeric) fields available in the schema. "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13908689",
            "date": "2014-02-21T19:08:07+0000",
            "content": "But my understanding of function queries is they add to the score, replacing it? With expressions, you could have 3 different expressions you sort on, some of which might use the score, and get all 4 values back, in order to evaluate and debug.\n\nNo, no ... value sources (aka function queries) can be used in all those same ways in Solr,\n\nHere's an example request that works today and uses value sources in 3 different ways:\n\n\tas an argument to the \"boost\" query parser which can wrap another query - in this case the main query to affect the score (the use case you mentioned)\n\tas a psuedo field computed & returned for each doc in the response\n\tas a sort option (independent of the computed score)\n\n\n\n\nhttp://localhost:8983/solr/select?q={!boost%20f=div%28popularity,price%29}name:ipod&fl=id,score,popularity,price,weight,my_price:if%28inStock,price,-1%29&sort=div%28weight,price%29+asc,score%20desc\n\n\n\n<lst name=\"responseHeader\">\n  <int name=\"status\">0</int>\n  <int name=\"QTime\">1</int>\n  <lst name=\"params\">\n    <str name=\"sort\">div(weight,price) asc,score desc</str>\n    <str name=\"fl\">id,score,popularity,price,weight,my_price:if(inStock,price,-1)</str>\n    <str name=\"indent\">true</str>\n    <str name=\"q\">{!boost f=div(popularity,price)}name:ipod</str>\n  </lst>\n</lst>\n<result name=\"response\" numFound=\"3\" start=\"0\" maxScore=\"1.7514601\">\n  <doc>\n    <str name=\"id\">MA147LL/A</str>\n    <float name=\"weight\">5.5</float>\n    <float name=\"price\">399.0</float>\n    <int name=\"popularity\">10</int>\n    <float name=\"score\">1.0320579</float>\n    <float name=\"my_price\">399.0</float></doc>\n  <doc>\n    <str name=\"id\">IW-02</str>\n    <float name=\"weight\">2.0</float>\n    <float name=\"price\">11.5</float>\n    <int name=\"popularity\">1</int>\n    <float name=\"score\">1.7514601</float>\n    <long name=\"my_price\">-1</long></doc>\n  <doc>\n    <str name=\"id\">F8V7067-APL-KIT</str>\n    <float name=\"weight\">4.0</float>\n    <float name=\"price\">19.95</float>\n    <int name=\"popularity\">1</int>\n    <float name=\"score\">1.0320579</float>\n    <long name=\"my_price\">-1</long></doc>\n</result>\n\n\n\nThe fact that all of these possibilities already exist in Solr as ways to use value sources is why i suggested that having a new value source parser that delegated to an expression (which, with the right bindings, might be able to delegate to another value source) seemed to make so much sense to me.  \n\nIf i understand your patch, it would allow \"pre-compiled\" script expressions to be used in any place where fields could be used \u2013 but the bindings (from expression variables to underlying values) would have to be completely pre-configured and static (because of the field limitations) correct? \n\nIf instead it was implemented as a value source, then the scripts could still be pre-compiled at parser init, and there could still be static bindings preconfigured on the valueSourceParser (and yes: these could certainly default to including all field names), but other bindings could be configured so that they could be specified at request time (either as additional arguments to the \"expression(...)\" function, or possibly as inherited request params).  I don't think request time bindings would be possible with the FieldTYpe approach, unless you did similar kludgy stuff like how RandomSortField expects to be used as a DynamicField\n\nImplement expression integration similar to how function queries work, possibly by adding \"lang\" or \"type\" or something like that to the QP so that you could choose which language\n\nthat sort of blurs the line between a \"fully dynamic\" approach like what rmuir was describing \u2013 where the script syntax of the expression itself could be a function argument, and the \"static expressions, dynamic bindings\" approach i'm suggesting \u2013 where the script expression is pre-configured & compiled at init, and a \"name\" for the exprssion is specified at request time (similar to how you would use a field name in the appraoch you are suggesting).  \n\nBut yes: while we could easily have two value source parsers (one where the input was an \"expression name\" for a pre-configured & pre-compiled expression, and one where the input was \"expression script\" that would be evaluated on the fly) we could also conceivably start with a value source parser for pre-configured expressions and later expand it ot support expressions specified in a request.\n\n\n\nI guess my bottom line is: i certainly don't want to discourage you from your ultimate goal.  If you really feel like your \"ComputedField\" approach to integrating expressions makes sense then so be it \u2013 but it smells like a missuse of the FieldType API to me.  I suspect that every usecase you are trying to support here could also be supported via a value source parser, and likely with a lot less shoe-horning need to make it work with the existing code.\n\nPlease consider it, and poke around with the value source parser APIs and think about the examples i posted above for a bit.  If you don't think it's a better fit, then by all means keep going down your current path.\n\n(EDITED:  fixed example to be more readable in jira) "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13968871",
            "date": "2014-04-14T21:31:45+0000",
            "content": "FWIW: Ryan & i chatted about this at ApacheCon last week ... he helped me understand the expressions code a bit more, and i walked him through the existing ValueSourceParser stuff to explain better what's already possible and what I had in mind  suggesting we levearge that.   The net result being that I'm now very confident there is a clean way to bring the expressions stuff in using a new ValSource parser \u2013 that should be just as efficient as what ryan was aiming for with his patch w/o needing to abuse fields \u2013 and will give us a nice way to continue to enhance things ot support paramaterized expressions and dynamic expressions specified at request time.\n\ni'll hopefully have some time to work on a patch later this week "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13978548",
            "date": "2014-04-23T18:02:19+0000",
            "content": "The new SOLR-5707_vsp.patch I just posted heads down the route I mentioned before of implementing exprssions using a ValueSourceParser.  From what i can tell, this new patch provides the same level of functionality as Ryan's previous \"ComputedField\" based patch (i was able to re-use most of his tests with just some minor tweaks to the syntax) but is (in my option) a cleaner approach, and leaves us more room to move forward with uesful things like:\n\n\teasily using request params in bindings\n\tdynamicly specified expressions (which can be compiled & cached if they are reused)\n\n\n\nAt present there are a handful of nocommit's in the patch along 3 general lines:\n\n\tmore javadocs\n\tmore tests - in particular, ryan's patch had more tests of bad-config & error cases - my patch definitely needs beefed up in that area\n\tforcing \"wantsScore\" so expressions used in \"fl\" can depend on score.\n\n\n\nThis last item is problem ryan noted in his patch as well \u2013 it's no worse with the new ValueSource approach, but it's also no better... \n\nSolr currently decides if/when it needs to compte scores based on the ReturnField class - which decides based on whether \"score\" is in the \"fl\".  So at present, if you wnat to put an expression in the \"fl\" that depends on score, it won't work unless you also put \"score\" in the \"fl\".  I have some ideas on how on a generalized improvement to make this better, but it's non trivial, and i'm not sure if it should block this issue or if folks think the current situation is an acceptible workarround and we can tackle simplifying the score case later?\n\nIn any case - i wnated to get this patch up for folks to look at before investing a lot more time in polishing it.\n\nRyan Ernst: what do you think of this approach? "
        },
        {
            "author": "Ryan Ernst",
            "id": "comment-14028222",
            "date": "2014-06-11T18:54:39+0000",
            "content": "Sorry for the long turnaround on this.  The overall approach looks good! I think this could be a good base to allow dynamics. A couple specific questions:\n\n\n\tWhat do you mean by \"positional func args to names in bindings\"?\n\tI think you could get your desired minimal cycle by doing your own join, but first advancing the iterator to your current element? Also, shouldn't there be a static check that the non-expression variables are numeric fields in the schema?\n\n\n "
        },
        {
            "author": "Hoss Man",
            "id": "comment-14028877",
            "date": "2014-06-12T06:48:14+0000",
            "content": "What do you mean by \"positional func args to names in bindings\"?\n\nI don't know that i can explain what i was imaginging any better then the comment i included in the patch...\n\n\n+    // TODO: should we support mapping positional func args to names in bindings?\n+    // \n+    // ie: ...\n+    // <lst name=\"expressions\">\n+    //   <lst name=\"my_expr\">\n+    //     <str name=\"expression\">foo * bar / baz</str>\n+    //     <arr name=\"positional-bindings\">\n+    //       <str>baz</str>\n+    //       <str>bar</str>\n+    //     </arr>\n+    //   </lst>\n+    //   <str name=\"foo\">32</foo>\n+    //   ...\n+    // </lst>\n+    //  and then:  \"expr(my_expr,42,56)\" == \"32 * 56 / 42\"\n\n\n\n...i'm not really a fan of that syntax though \u2013 I haven't played around with expressions enough yet to know what kinds of \"variable\" names are allowed, but if we can use variables like $1 in expressions, then the Bindings could look for the $ prefix and map those directly to the positional function args w/o needing the explicit positional-bindings configuration which would be much cleaner.\n\nI think you could get your desired minimal cycle by doing your own join, but first advancing the iterator to your current element?\n\nI'm not following what you mean, but i'm also not sure it's worth worrying about \u2013 improving hte error messages to just be the minimal cycle is definitely something i'd be happy to punt to as a later optimization.  (the most important thing is covered: not going into an infinite loop on startup with bad config)\n\nshouldn't there be a static check that the non-expression variables are numeric fields in the schema?\n\nI don't think so...\n\n\n\twe don't ever want to explicitly enforce that the fields are numeric \u2013 any FieldType that supports getValueSource() should be fine \u2013 what matters is that any unbound variable must be a valid schema field, and the SolrBindings already checks for that\n\twe could do a static valid schema field check on parser init, but i didn't bother to add that because:\n\t\n\t\tthen we can't handle bindings that come from request params \u2013 something that isn't in the code yet because there wasn't a test for it in your previous code, but i had a TODO about it and definitely want to include.\n\t\tit wouldn't help with dynamic expressions specified at query time, so we have to check for it in the bindings anyway.\n\t\n\t\n\n\n\n\n\nFWIW: I hope to come back and revisit this in a few weeks and get all the TODOs & nocommits resolved \u2013 but it's on my backburner at the moment. "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-14028887",
            "date": "2014-06-12T07:04:34+0000",
            "content": "...i'm not really a fan of that syntax though \u2013 I haven't played around with expressions enough yet to know what kinds of \"variable\" names are allowed, but if we can use variables like $1 in expressions, then the Bindings could look for the $ prefix and map those directly to the positional function args w/o needing the explicit positional-bindings configuration which would be much cleaner.\n\n$ is not a special character in Javascript, so it can be part of a variable or function name. One famous example is the $-Function in JQuery: $('.class'). If the Lucene Expressions parser is not \"special\" it should accept $1 as variable name in the binding and the expression parser itsself.\n\nEDIT: I checked it: \n\n\n  public void testDollarVariable() throws Exception {\n    Expression expr = JavascriptCompiler.compile(\"sqrt($0)\");\n    \n    SimpleBindings bindings = new SimpleBindings();    \n    bindings.add(new SortField(\"$0\", SortField.Type.SCORE));\n    \n    Sort sort = new Sort(expr.getSortField(bindings, true));\n    Query query = new TermQuery(new Term(\"body\", \"contents\"));\n    TopFieldDocs td = searcher.search(query, null, 3, sort, true, true);\n    for (int i = 0; i < 3; i++) {\n      FieldDoc d = (FieldDoc) td.scoreDocs[i];\n      float expected = (float) Math.sqrt(d.score);\n      float actual = ((Double)d.fields[0]).floatValue();\n      assertEquals(expected, actual, CheckHits.explainToleranceDelta(expected, actual));\n    }\n  }\n\n\n\nThis fails to parse, although its technically correct Javascript: java.text.ParseException:  unexpected character '$' at position (5).\n\nWhat works: _1 as variable/binding name. But on the other hand, disallowing $ is strange to me.\n\nAnother good thing (maybe as extension to expressions): It would be cool, if the JavaScript compiler could \"report\" back all variable used in the expression after compiling. We could then somehow automatically map them (but would not help with positional args). "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-14028898",
            "date": "2014-06-12T07:21:24+0000",
            "content": "See: http://www.ecma-international.org/publications/files/ECMA-ST-ARCH/ECMA-262,%203rd%20edition,%20December%201999.pdf\n\n\nThis standard specifies one departure from the grammar given in the Unicode standard: The dollar sign ($) and the underscore (_) are permitted anywhere in an identifier. The dollar sign is intended for use only in mechanically generated code.\n\nSo this is in my opinion a bug, that the ANTLR parser does not accept $ in variables. Maybe Robert Muir knows the background about this limitation. "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-14028906",
            "date": "2014-06-12T07:35:59+0000",
            "content": "I just modified the Javascript parser to accept $ as character inside identifiers (was quite simple, because the $ sign has no other meaning in Javascript). This is maybe an idea for another issue, I just posted it here as patch, if we want to go this route.\n\nAccording to the ECMAScript official documentation is the parser already too strict, because ECMAScript allows all UnicodeLetters as ID characters, too. The ANTLR parser only allows 'A'-'Z' and 'a'-'z' in addition to other special characters and digits. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-14028997",
            "date": "2014-06-12T10:19:13+0000",
            "content": "\nAccording to the ECMAScript official documentation is the parser already too strict, because ECMAScript allows all UnicodeLetters as ID characters, too\n\nNo its not. This parser is documented as being a subset. "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-14029020",
            "date": "2014-06-12T10:59:03+0000",
            "content": "I moved the $ as identifier part to a separate issue: LUCENE-5754 "
        },
        {
            "author": "David Smiley",
            "id": "comment-14172314",
            "date": "2014-10-15T12:37:06+0000",
            "content": "This would be a great feature to get into Solr 5.0. "
        }
    ]
}