{
    "id": "SOLR-1925",
    "title": "CSV Response Writer",
    "details": {
        "affect_versions": "None",
        "status": "Closed",
        "fix_versions": [
            "3.1",
            "4.0-ALPHA"
        ],
        "components": [
            "Response Writers"
        ],
        "type": "New Feature",
        "priority": "Major",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "As part of some work I'm doing, I put together a CSV Response Writer. It currently takes all the docs resultant from a query and then outputs their metadata in simple CSV format. The use of a delimeter is configurable (by default if there are multiple values for a particular field they are separated with a | symbol).",
    "attachments": {
        "SOLR-1925.Mattmann.053010.patch.2.txt": "https://issues.apache.org/jira/secure/attachment/12445888/SOLR-1925.Mattmann.053010.patch.2.txt",
        "SOLR-1925.patch": "https://issues.apache.org/jira/secure/attachment/12450358/SOLR-1925.patch",
        "SOLR-1925.Mattmann.061110.patch.txt": "https://issues.apache.org/jira/secure/attachment/12446942/SOLR-1925.Mattmann.061110.patch.txt",
        "SOLR-1925.Chheng.071410.patch.txt": "https://issues.apache.org/jira/secure/attachment/12449494/SOLR-1925.Chheng.071410.patch.txt",
        "SOLR-1925.Mattmann.053010.patch.txt": "https://issues.apache.org/jira/secure/attachment/12445881/SOLR-1925.Mattmann.053010.patch.txt",
        "SOLR-1925.Mattmann.053010.patch.3.txt": "https://issues.apache.org/jira/secure/attachment/12445892/SOLR-1925.Mattmann.053010.patch.3.txt"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Erik Hatcher",
            "id": "comment-12871172",
            "date": "2010-05-25T14:40:33+0000",
            "content": "I was just thinking of writing this very thing the other day.   \n\nI think this should use the same default delimiters and header as the CSV update handler does so that data is easily ingested and output in the the same format (provided the field data is stored of course).    "
        },
        {
            "author": "Chris A. Mattmann",
            "id": "comment-12871180",
            "date": "2010-05-25T14:53:33+0000",
            "content": "Hey Eric cool!\n\nSure, I'd love to collaborate with you on this. Patch forthcoming, then let's work it...\n\nCheers,\nChris "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12871186",
            "date": "2010-05-25T15:02:46+0000",
            "content": "This is something that some people have asked for since my CNET days...  I thought there was already an open issue for this, but I can't seem to find it (so I guess not!) "
        },
        {
            "author": "Hoss Man",
            "id": "comment-12872576",
            "date": "2010-05-27T22:08:08+0000",
            "content": "Bulk updating 240 Solr issues to set the Fix Version to \"next\" per the process outlined in this email...\n\nhttp://mail-archives.apache.org/mod_mbox/lucene-dev/201005.mbox/%3Calpine.DEB.1.10.1005251052040.24672@radix.cryptio.net%3E\n\nSelection criteria was \"Unresolved\" with a Fix Version of 1.5, 1.6, 3.1, or 4.0.  email notifications were suppressed.\n\nA unique token for finding these 240 issues in the future: hossversioncleanup20100527 "
        },
        {
            "author": "Chris A. Mattmann",
            "id": "comment-12873456",
            "date": "2010-05-30T16:55:19+0000",
            "content": "Okey dok, here's the patch, I'll post some sample queries and response writer config to show how it's used in one sec. "
        },
        {
            "author": "Chris A. Mattmann",
            "id": "comment-12873457",
            "date": "2010-05-30T17:00:35+0000",
            "content": "Hey Guys:\n\nHere are some samples on how to call it:\n\nThis example queries Solr for children's hospital, turns on CSV output, and requests the fields site_id and agency_name\n\ncurl\"http://localhost:8080/solr/select/?q=children%27s%20AND%20hospital&version=2.2&start=0&rows=10&indent=on&wt=csv&fl=site_id,id,agency_name\"\n\n\n\nThis example queries Solr for children's hospital and turns on CSV output, requests the fields site_id and agency_name, and then changes the default delimiter to semi-colon (only in the context of this request)\n\ncurl\"http://localhost:8080/solr/select/?q=children%27s%20AND%20hospital&version=2.2&start=0&rows=10&indent=on&wt=csv&fl=site_id,id,agency_name&delimiter=;\"\n\n\n\nThis example queries Solr for children's hospital and turns on CSV output, requests the fields site_id and agency_name, and then specifies (by turning Excel off) that CR LF should be left inside of the fields and not replaced (only in the context of this request):\n\n\ncurl\"http://localhost:8080/solr/select/?q=children%27s%20AND%20hospital&version=2.2&start=0&rows=10&indent=on&wt=csv&fl=site_id,id,agency_name&excel=false\"\n\n "
        },
        {
            "author": "Chris A. Mattmann",
            "id": "comment-12873495",
            "date": "2010-05-30T21:37:06+0000",
            "content": "\n\tsmall bug in my initial patch where the field col headers didn't respect the \"delimeter\" parameter. Fixed.\n\n "
        },
        {
            "author": "Erik Hatcher",
            "id": "comment-12873496",
            "date": "2010-05-30T21:45:14+0000",
            "content": "shouldn't that be spelled \"delimiter\"?     or we hossifying this thing? "
        },
        {
            "author": "Chris A. Mattmann",
            "id": "comment-12873498",
            "date": "2010-05-30T21:48:26+0000",
            "content": "haha crap i can't spell. Hold on let me fix it...  I caught some typos in the Javadoc too, so fixing those too! "
        },
        {
            "author": "Chris A. Mattmann",
            "id": "comment-12873501",
            "date": "2010-05-30T21:54:09+0000",
            "content": "Fix typos: nice catch, Erik! "
        },
        {
            "author": "Kevin Black",
            "id": "comment-12877440",
            "date": "2010-06-10T15:03:19+0000",
            "content": "Thanks for this response writer!  \nQuestion (not sure if this is a universal problem, or a problem with my solr install):\n   if a document is missing a field value, is the CSV output missing a column?\n\ne.g. \nDoc 1:  id=121; field1=string1.1; field2=string1.2; field3=string1.3\nDoc 2:  id=122; field1=string2.1;  field3=string2.3    [field2 is empty with no value]\nDoc 3:  id=123; field1=string3.1; field2=string3.2; field3=string3.3\n\nmy CSV output is: \n\nid,field1,field2,field3\n121,string1.1,string1.2,string1.3\n122,string2.1,string2.3\n123,string3.1,string3.2,string3.3\n\nFor the 2nd record, the 3rd field appears in the 2nd column which annoys the user who downloads the CSV data  \n "
        },
        {
            "author": "Chris A. Mattmann",
            "id": "comment-12877449",
            "date": "2010-06-10T15:25:17+0000",
            "content": "Hi Kevin,\n\nThanks for the feedback! \n\nI hear ya on the annoying part. Right now the CSVResponseWriter has the following behavior:\n\n\n\tif you define output fields using fl=field1,field2 as part of your SOLR url request, then you can control the way columns are displayed and ensure that there is a uniform set of columns output in the CSV based on your indexed documents\n\tif you don't define output fields, the response writer simple assumes that your documents indexed have uniform fields and will try and simply write the output fields based on those fields indexed per document\n\n\n\nThe assumption might be limiting, but I it was the best I could think of in the case that the requested output cols aren't uniformly specified.\n\nHTH clarify what you're seeing! Of course, ideas for improvement are always welcome.\n\nCheers,\nChris "
        },
        {
            "author": "Kevin Black",
            "id": "comment-12877465",
            "date": "2010-06-10T16:06:02+0000",
            "content": "Hi Chris,\n\nIn your 1st point, are you saying that defining \"fl=field1,field2,field3\" will populate a column with empty quotes if field2 is missing in a document?\n\nhowever, in my URL, I have \"&fl=id,field3,field1,field2\", but since some Documents do not have field2 data in the index, the output is missing columns: (quotes are not shown for clarity)\n\nid,field1,field3\n121,string1.1,string1.3\n122,string2.1,string2.3\n123,string3.1,string3.2,string3.3\n\nIn this example, both the 1st and 2nd Document are missing \"field2\" data, so 'field2' is not even appearing in the header of my output, and neither record is populated with a empty placeholder for \"field2\".\n\nHopefully I'm being clear with my example.\n\nThanks! "
        },
        {
            "author": "Chris A. Mattmann",
            "id": "comment-12877467",
            "date": "2010-06-10T16:09:12+0000",
            "content": "Hey Kevin,\n\nOh ok then yep that's a bug, I can fix that. I'll throw up a new patch for that today. Should still output a blank...\n\nCheers,\nChris "
        },
        {
            "author": "Chris A. Mattmann",
            "id": "comment-12878198",
            "date": "2010-06-12T03:27:47+0000",
            "content": "Updated patch forthcoming. I tested it out by doing e.g.,:\n\n\nhttp://localhost:8080/solr/select/?wt=csv&excel=true&delimeter=;&q=%28taxonomy_term%3A%22Medicaid+Applications%22%29&start=0&rows=10&fl=site_id,site_name,site_hours,foo\n\n\n\nwhere I knew that \"foo\" wasn't a valid field, and thus would have no value in the resultant doc.  "
        },
        {
            "author": "Chris A. Mattmann",
            "id": "comment-12878200",
            "date": "2010-06-12T03:38:47+0000",
            "content": "\n\tupdated patch, that addresses the comments from Kevin.\n\n "
        },
        {
            "author": "Chris A. Mattmann",
            "id": "comment-12878201",
            "date": "2010-06-12T03:39:45+0000",
            "content": "\n\toops named it wrong the first time i attached.\n\n "
        },
        {
            "author": "Kevin Black",
            "id": "comment-12878476",
            "date": "2010-06-14T04:41:33+0000",
            "content": "Beautiful! Thanks very much Chris! "
        },
        {
            "author": "tommy chheng",
            "id": "comment-12888570",
            "date": "2010-07-14T22:12:41+0000",
            "content": "Thanks for this!\nI fixed the path of the queryResponseWriter class in the example solrconfig.xml. This was successfully applied against solr 4.0 trunk.\n\nA few quirks:\n\n\tWhen I didn't specify a default Delimiter, it printed out null as delimiter. I couldn't figure out why because init(NamedList args) specifies it'll use a default of \",\"\n\"organization\"null\"2\"null\"\n\n\n\n\n\tIf i don't specify the column names, the output doesn't put in empty \"\" correctly.\neg: output has a mismatched number of commas.\n\"organization\",\"1\",\"Test\",\"Name\",\"2\",\"   \",\"2000000\",\"8\",\n\"organization\",\"4\",\"Solar\",\"4\",\"0\",\n\n "
        },
        {
            "author": "Chris A. Mattmann",
            "id": "comment-12888581",
            "date": "2010-07-14T22:29:27+0000",
            "content": "Hi Tommy:\n\n\nI fixed the path of the queryResponseWriter class in the example solrconfig.xml. This was successfully applied against solr 4.0 trunk.\n\nWhat does \"fixing the path\" mean?\n\nOnto your comments below:\n\n\n\n\tWhen I didn't specify a default Delimiter, it printed out null as delimiter. I couldn't figure out why because init(NamedList args) specifies it'll use a default of \",\" \"organization\"null\"2\"null\"\n\n\n\nIt didn't do that for me? Where did you initialize your response writer? Note that the patch I attached included updates to solrconfig.xml, where the default delimeter is provided as an initParam.\n\n\n\n\tIf i don't specify the column names, the output doesn't put in empty \"\" correctly. eg: output has a mismatched number of commas. \"organization\",\"1\",\"Test\",\"Name\",\"2\",\" \",\"2000000\",\"8\", \"organization\",\"4\",\"Solar\",\"4\",\"0\",\n\n\n\nYep that's the intention. It's because Lucene/Solr documents can have an arbitrary # of fields in them. I saw no good, intuitive way to overcome this, so unless you tell me what the default field name list is, the writer won't do anything special (b/c I believe to do so would be somewhat limiting and non-generic), and it will simply output the fields that are in the doc, which, can be a non-uniform number, causing what you're seeing. To say that's not correct, well, I don't agree with that.\n\nI tried diffing your latest patch against my latest:\n\n\n[chipotle:~/Desktop/Apache/solr-dev] mattmann% diff -u SOLR-1925.Chheng.071410.patch.txt SOLR-1925.Mattmann.061110.patch.txt\n--- SOLR-1925.Chheng.071410.patch.txt\t2010-07-14 15:22:57.000000000 -0700\n+++ SOLR-1925.Mattmann.061110.patch.txt\t2010-06-11 20:34:58.000000000 -0700\n@@ -1,3 +1,5 @@\n+### Eclipse Workspace Patch 1.0\n+#P solrcene\n Index: solr/src/java/org/apache/solr/response/CSVResponseWriter.java\n ===================================================================\n --- solr/src/java/org/apache/solr/response/CSVResponseWriter.java\t(revision 0)\n@@ -259,7 +261,7 @@\n      <int name=\"xsltCacheLifetimeSeconds\">5</int>\n    </queryResponseWriter>\n +  \n-+  <queryResponseWriter name=\"csv\" class=\"org.apache.solr.response.CSVResponseWriter\">\n++  <queryResponseWriter name=\"csv\" class=\"solr.CSVResponseWriter\">\n +    <str name=\"delimiter\">,</str>\n +    <!--  this specifies that\n +          you are writing CSV that you expect to load into M$\n@@ -290,7 +292,6 @@\n      m.put(\"raw\", new RawResponseWriter());\n      m.put(\"javabin\", new BinaryResponseWriter());\n +    m.put(\"csv\", new CSVResponseWriter());\n-     m.put(\"velocity\", new VelocityResponseWriter());\n      DEFAULT_RESPONSE_WRITERS = Collections.unmodifiableMap(m);\n    }\n    \n[chipotle:~/Desktop/Apache/solr-dev] mattmann% \n\n\n\nAll you did was use the virtual solr package resolution string, versus using the FQDN for the class. Either one works fine. Also, I'm not sure I get the removing velocity from the default response writer map part...\n\nCheers,\nChris "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12888598",
            "date": "2010-07-14T22:54:34+0000",
            "content": "I took a quick look... here are some of the issues I see:\n\n\tloses info by removing newlines\n\talways encapsulates with quotes - not as readable\n\tdoesn't escape encapsulator in values\n\tdoesn't escape separator in multi-valued fields\n\tisn't really nested CSV, so it's not compatible with the CSVLoader\n\tuses System.getProperty(\"line.separator\")... we should avoid different behavior on different platforms\n\tdoesn't stream documents (dumping your entire index will be one use case)\n\tperformance: patterns shouldn't be compiled per-doc\n\n "
        },
        {
            "author": "Lance Norskog",
            "id": "comment-12888661",
            "date": "2010-07-15T01:22:48+0000",
            "content": "Please make sure that it does not print floats/doubles in scientific notation, but sticks with canonical. That is, it should print 0.0000001 as that, not '1e-7'. "
        },
        {
            "author": "Chris A. Mattmann",
            "id": "comment-12888670",
            "date": "2010-07-15T01:51:56+0000",
            "content": "Hi Yonik:\n\nThanks. Replies below:\n\n\n\n\tloses info by removing newlines\n\n\n\nOnly does this when \n\n&excel=true\n\n, and actually adds functionality in doing so (without doing this, you can't load the data into Excel, see my comments above and in the code).\n\n\n\n\talways encapsulates with quotes - not as readable\n\n\n\nSee the CSV spec, via Wikipedia in the links in the code. Doing so reduces ambiguity, and clearly delineates where the value starts, and where it stops.\n\n\n\n\tdoesn't escape encapsulator in values\n\n\n\nIs there a need to do this? I don't think so...\n\n\n\n\tdoesn't escape separator in multi-valued fields\n\n\n\nSame as above: no need, really.\n\n\n\n\tisn't really nested CSV, so it's not compatible with the CSVLoader\n\n\n\nWhat do you mean not compatible with CSV loader?\n\n\n\n\tuses System.getProperty(\"line.separator\")... we should avoid different behavior on different platforms\n\n\n\nHmm, I've never been dinged before for writing platform independent code. That's what they put the property in there, so line.separator means the same thing, programming-construct wise, across platforms. So, I don't really get your ding here.\n\n\n\n\tdoesn't stream documents (dumping your entire index will be one use case)\n\n\n\nI actually implemented both the streaming method (#writeDoc) and the aggregate method (#writeAllDocs). I set #isStreaming to false, because it makes for a clean CSV header writing, rather than hacky code in #writeDoc to take care of the (potential) non-uniformity. Additionally, I'm using this in production right now, on solr-1.5 branch with an index of over 1M documents, and the performance overhead for the write is quite fast.\n\n\n\n\tperformance: patterns shouldn't be compiled per-doc\n\n\n\nThis only matters when \n\nexcel=true\n\n, and I think the performance hit isn't really an issue. If you feel strongly about it though we could always compile the pattern above the loop, and reuse it... "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12888676",
            "date": "2010-07-15T02:28:05+0000",
            "content": "Excel (at least the version I just tried) handled embedded newlines just fine.\n\n> > always encapsulates with quotes - not as readable\n> See the CSV spec, via Wikipedia in the links in the code\n\nAFAIK, the CSV spec doesn't recommend always using encapsulators.\n\n> > doesn't escape encapsulator in values\n> Is there a need to do this? I don't think so...\n\nProper escaping is an absolute necessity.  You can't represent arbitrary text field values without it.\n\n> > What do you mean not compatible with CSV loader?\n\nIf we do things correctly, we should be able to round-trip with http://wiki.apache.org/solr/UpdateCSV\n\n> > uses System.getProperty(\"line.separator\")... we should avoid different behavior on different platforms\n> Hmm, I've never been dinged before for writing platform independent code.\n\nHaving a server process act differently on different hosts is bad.  We strive to never use the default locale - it's a recipe for non-portability.  All file encodings (stopword lists, etc) default to UTF-8 instead of the system locale.  Date and number formatting is standardized and does not use the system locale.  We missed some of these in the past (and sure enough, Solr wouldn't work properly when installed on a machine of a certain locale), but Robert cleaned all that up.\n "
        },
        {
            "author": "Chris A. Mattmann",
            "id": "comment-12888679",
            "date": "2010-07-15T03:00:10+0000",
            "content": "\nExcel (at least the version I just tried) handled embedded newlines just fine. \n\nWell not for me. I'm using MS Office 2008, on Mac OS X 10.5.6. I also tried on Office XP SP 2, and same behavior on a Win XP SP2 instance I have running in VMWare. What version are you looking at?\n\n\nAFAIK, the CSV spec doesn't recommend always using encapsulators.\n\nSee here: http://en.wikipedia.org/wiki/Comma-separated_values, 1st Paragraph:\n\nFields that contain a special character (comma, newline, or double quote), must be enclosed in double quotes.\n\nSince we don't know what the contents of each Field's value is, it's best to just account for that by encapsulating within double quotes. This doesn't break anything, and arguably isn't any less uglier than without (that's a judgment call). \n\n\nProper escaping is an absolute necessity. You can't represent arbitrary text field values without it.\n\nHow would you recommend doing so?\n\n\nIf we do things correctly, we should be able to round-trip with http://wiki.apache.org/solr/UpdateCSV\n\nWhat's your rationale that this isn't compatible with that? Have you tried it? Also, I think that's a good thing to make happen in the end, but not a blocker to getting this into the sources? My rationale behind that is that, e.g., for instance XML given to Solr doesn't always round trip to the XMLReponseWriter (especially if the schema weeds out fields, discards them, etc.)\n\n\nHaving a server process act differently on different hosts is bad. We strive to never use the default locale - it's a recipe for non-portability. All file encodings (stopword lists, etc) default to UTF-8 instead of the system locale. Date and number formatting is standardized and does not use the system locale. We missed some of these in the past (and sure enough, Solr wouldn't work properly when installed on a machine of a certain locale), but Robert cleaned all that up.\n\nAdmittedly, I'm not an expert here, so I'll take your word for it. What's the host-independent way to do System.getProperty(\"line.separator\")? "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12888817",
            "date": "2010-07-15T14:50:18+0000",
            "content": "I tried excel 2003 and excel 2007 - both work fine with embedded newlines.  Perhaps you're not encoding your test file correctly.\n\n> > AFAIK, the CSV spec doesn't recommend always using encapsulators.\n> See here: http://en.wikipedia.org/wiki/Comma-separated_values, 1st Paragraph:\n> Fields that contain a special character (comma, newline, or double quote), must be enclosed in double quotes.\n\nI'll repeat: \"the CSV spec doesn't recommend always using encapsulators\".  Why do you keep suggesting that it does?\n\n> > If we do things correctly, we should be able to round-trip with http://wiki.apache.org/solr/UpdateCSV\n> What's your rationale that this isn't compatible with that? Have you tried it? \n\nI didn't need to try it... I just looked at this patch, which doesn't do proper CSV encoding/escaping.\n\n> What's the host-independent way to do System.getProperty(\"line.separator\")?\n\nYou pick one (like \\n)... if there is a need for a different one, you let it be configured / specified by the client. "
        },
        {
            "author": "Chris A. Mattmann",
            "id": "comment-12888821",
            "date": "2010-07-15T15:11:55+0000",
            "content": "I tried excel 2003 and excel 2007 - both work fine with embedded newlines. Perhaps you're not encoding your test file correctly. \n\nHuh? It has nothing to do with any test file? There is no test file.\n\nProcess\n\n\n\tLoad data into Solr with embedded newlines\n\tDo query to Solr, call wt=csv and save results to a file (don't specify excel=true, preserving embedded newlines)\n\tLoad .csv file into Excel on the platforms I mentioned and watch it break\n\n\n\nYou continue to omit the platforms you're testing on. Why do you continue to do this?\n\nI'll repeat: \"the CSV spec doesn't recommend always using encapsulators\". Why do you keep suggesting that it does?\n\nBecause your statement that it doesn't recommend always using encapsulators neglects to take into account my perspective. Also the spec isn't black and white, as you imply. There is room for interpretation. I believe my interpretation allows for the most flexibility. \n\nI didn't need to try it... I just looked at this patch, which doesn't do proper CSV encoding/escaping.\n\nRight, and you selectively quoted me. If you're going to quote me, include the whole quote. Look at the 2nd part of what I wrote that mentions that there are plenty of cases with Solr data loading and Response Writers where it doesn't round trip.\n\nYou pick one (like \\n)... if there is a need for a different one, you let it be configured / specified by the client.\n\nHmmm, not sure I understand this statement.\n\nAll I know is that regardless, I'm using this and it's been working fine for me in production for weeks by applying this patch to branch-1.5.  "
        },
        {
            "author": "Robert Muir",
            "id": "comment-12888827",
            "date": "2010-07-15T15:27:06+0000",
            "content": "Hi, what happens if a field has a double quote in it?  "
        },
        {
            "author": "Chris A. Mattmann",
            "id": "comment-12888829",
            "date": "2010-07-15T15:33:17+0000",
            "content": "Hi, what happens if a field has a double quote in it? \n\nGood question. I haven't seen any glaring bad things that have happened in my use of it on a moderately sized dataset of around 1M documents. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-12888832",
            "date": "2010-07-15T15:47:01+0000",
            "content": "Good question. I haven't seen any glaring bad things that have happened in my use of it on a moderately sized dataset of around 1M documents.\n\nI dont see any code that properly \"quotes the quotes\". So if the data has even one double quote in it, I think the output is wrong.\nPersonally, I think the simplest solution to many of these problems is to use a csv lib instead (preferably the same one used on the parsing side) "
        },
        {
            "author": "Chris A. Mattmann",
            "id": "comment-12888835",
            "date": "2010-07-15T15:53:57+0000",
            "content": "I dont see any code that properly \"quotes the quotes\". So if the data has even one double quote in it, I think the output is wrong.\n\nYeah I guess it's b/c I'm looking at loading the data into Excel, and what's in there seems to work for doing that. \n\nPersonally, I think the simplest solution to many of these problems is to use a csv lib instead (preferably the same one used on the parsing side)\n\nThat's probably the easiest thing to do too. I was just looking to do it w/o adding any dependencies to the core. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-12888840",
            "date": "2010-07-15T16:05:58+0000",
            "content": "That's probably the easiest thing to do too. I was just looking to do it w/o adding any dependencies to the core.\n\nThere is already one present (commons-csv-1.0-SNAPSHOT-r609327.jar) "
        },
        {
            "author": "Chris A. Mattmann",
            "id": "comment-12888841",
            "date": "2010-07-15T16:09:52+0000",
            "content": "Hi Robert:\n\nThere is already one present (commons-csv-1.0-SNAPSHOT-r609327.jar)\n\nAh cool, I didn't know that! w00t.\n\nCheers,\nChris "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12891801",
            "date": "2010-07-23T21:19:05+0000",
            "content": "Here's a patch that produces output that can correctly round-trip with the CSV loader.\nIt uses the current version of commons CSV,  including the CSVPrinter overhaul I did in SANDBOX-322\n\nParameters:\n  csv.encapsulator  (defaults to \")\n  csv.escape (defaults to none)\n  csv.separator (defaults to ,)\n  csv.header (defaults to true... if false, we skip printing out the column headers)\n  csv.newline (defaults to \\n)\n  csv.null (defaults to \"\")\n  // csv.mv params are the defaults for how multi-valued fields are encoded\n  // per-field overrides can be done via f.myfield.csv.separator=|\n  csv.mv.encapsulator  (defaults to none)\n  csv.mv.escape (defaults to )\n  csv.mv.separator (defaults to csv.separator)\n\nNotes:\n\n\tworks on fields in the index that aren't even defined in the schema\n\tmaintains the order of fields passed in by the user (and allows the header to be omitted)\n\tefficiently streamable... avoids intermediate creation of SolrDocument instances, and reuses a single buffer & writer across all instances of multi-valued fields for the sub-CSVPrinters\n\n\n\nI'll start adding some tests now. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12892475",
            "date": "2010-07-26T21:24:21+0000",
            "content": "Here's the final patch w/ tests.\nI think we're all ready to go... I'll commit this along with updating the commons-csv lib soon.\nI think it makes sense to backport this to 3.x too? "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12892917",
            "date": "2010-07-27T20:21:19+0000",
            "content": "committed to trunk and merged to 3x.\ntodo: docs "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-13013173",
            "date": "2011-03-30T15:45:46+0000",
            "content": "Bulk close for 3.1.0 release "
        },
        {
            "author": "Sirisha",
            "id": "comment-13020352",
            "date": "2011-04-15T16:55:50+0000",
            "content": "how can we apply the csvresponsewriter to copyField.For example when we have phone and altphone(copyfield) when we retreive using csvresponsewriter it return as \"123-345-3456,126-737-5838\" but when want to return to solr using this file it stores it in phone field as a record how can parse it seperatlylike phone contains 123-345-3456 and altphone(copyfield):126-737-5838  "
        }
    ]
}