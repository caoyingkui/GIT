{
    "id": "SOLR-6450",
    "title": "Option to send pre-analyzed documents from leader to replica instead of replicas re-running analysis.",
    "details": {
        "affect_versions": "None",
        "status": "Open",
        "fix_versions": [],
        "components": [
            "SolrCloud"
        ],
        "type": "Improvement",
        "priority": "Major",
        "labels": "",
        "resolution": "Unresolved"
    },
    "description": "Given the leader has to run the full update processor chain on each document (text analysis, etc), it would be good to have it send a pre-analyzed document to replicas (to improve near realtime replication), allowing the replica to avoid re-doing expensive work.\n\nThought should be given about allowing the leader to accept pre-analyzed as well, so that you could off-load the document analysis to external processes. For instance, have 1000's of Storm workers doing the analysis and then sending pre-analyzed documents to Solr.",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "author": "Yonik Seeley",
            "id": "comment-14114785",
            "date": "2014-08-29T02:51:23+0000",
            "content": "Although the idea has always sounded good, my un-tested guess has always been that serialization+un-serialization will generally be more expensive than just running analysis on the text again (which can be thought of as a serialized form of analyzed text).  It certainly depends on the analysis being performed of course.\n\nAs an example, think of the amount of information that comes out of simple whitespace split, lowercased text... and think about marshaling and un-marshaling that vs just re-doing the splitting/lowercasing.  Of course we shouldn't pre-judge too much... if someone wants to try it out, we should look at the performance numbers! "
        },
        {
            "author": "Mark Miller",
            "id": "comment-14115174",
            "date": "2014-08-29T12:00:10+0000",
            "content": "It's almost more interesting to try working out sending the docs to replicas in parallel with indexing on the leader instead of after. "
        },
        {
            "author": "Ramkumar Aiyengar",
            "id": "comment-14115192",
            "date": "2014-08-29T12:22:36+0000",
            "content": "Although the idea has always sounded good, my un-tested guess has always been that serialization+un-serialization will generally be more expensive than just running analysis on the text again (which can be thought of as a serialized form of analyzed text). It certainly depends on the analysis being performed of course.\n\nThis in part might just be due to lack of a fast generic binary serializing mechanism. We do have javabin, but that's very limited and forces us to describe the data instead of using schemas and transferring that description only when needed. A broader (and obviously more expensive) idea might be to have an out-of-band (i.e. not using the servlet) streaming of binary serialized data (say using Avro). This might open up a lot of other possibilities for SolrCloud as such.. "
        }
    ]
}