{
    "id": "SOLR-6237",
    "title": "An option to have only leaders write and replicas read when using a shared file system with SolrCloud.",
    "details": {
        "affect_versions": "None",
        "status": "Open",
        "fix_versions": [],
        "components": [
            "hdfs",
            "SolrCloud"
        ],
        "type": "New Feature",
        "priority": "Major",
        "labels": "",
        "resolution": "Unresolved"
    },
    "description": "",
    "attachments": {
        "SOLR-6237.patch": "https://issues.apache.org/jira/secure/attachment/12849507/SOLR-6237.patch",
        "Unified Replication Design.pdf": "https://issues.apache.org/jira/secure/attachment/12770921/Unified%20Replication%20Design.pdf",
        "0001-unified.patch": "https://issues.apache.org/jira/secure/attachment/12807779/0001-unified.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Mark Miller",
            "id": "comment-14992837",
            "date": "2015-11-06T01:03:17+0000",
            "content": "A while back, Yonik and I worked on a design for this. I've spent some time getting an early patch somewhat working. I'll post a patch soon. "
        },
        {
            "author": "Ishan Chattopadhyaya",
            "id": "comment-14993047",
            "date": "2015-11-06T03:57:32+0000",
            "content": "Looks interesting. Quick first impression is that tlog being written to HDFS might reduce the indexing throughput. Do you think that will be a significant slowdown for indexing? "
        },
        {
            "author": "Ishan Chattopadhyaya",
            "id": "comment-14993048",
            "date": "2015-11-06T03:59:12+0000",
            "content": "Was also wondering what was the motivation behind this? Is this to make log replays and recovery more robust? "
        },
        {
            "author": "Mark Miller",
            "id": "comment-14993758",
            "date": "2015-11-06T14:46:17+0000",
            "content": "Solr on HDFS already writes the tlog to HDFS, this doesn't change anything there. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-14993781",
            "date": "2015-11-06T15:04:44+0000",
            "content": "Was also wondering what was the motivation behind this? Is this to make log replays and recovery more robust?\n\n\n\tIt takes non leader recovery and replica out of sync issues out of the equation. There is no real recovery stage other than the leader replaying the tlog.\n\tIt removes the double replication you currently must have at the Solr and HDFS level.\n\tLeader does not have to do work to distribute most updates to replicas.\n\tYou can add some features that would be difficult or impossible to add otherwise.\n\n\n\nIt's a good option with various tradeoffs, just like using autoAddReplicas with HDFS or using the standard model. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-14993797",
            "date": "2015-11-06T15:18:34+0000",
            "content": "Was also wondering what was the motivation behind this? \n\nAt the high level: There are a number of storage architectures that provide shared fault tolerant storage across a number of servers.\nIf one wishes to store their data on these, then replication at the Solr level is redundant and generally unwanted. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-15312735",
            "date": "2016-06-02T17:38:25+0000",
            "content": "Here is a patch demonstrating the approach I'm taking.\n\nIt's a bit stale compared to my current working state, but in trying to fix the leader promotion phase, I've walked back a few things as much as I've walked others forward.\n\nThis shows the basic idea though.\n\n\n\tOnly the leader writes to the index or tlog, the replicas are in read only mode.\n\tData dirs are published in ZK so that replicas can use the same location as leaders - this requires some juggling of init logic on startup.\n\tWe have to be careful not to use a Writer when reopening a Reader - hard commits will control visibility in this mode as well, not soft commits.\n\tRealtime get is forwarded from replicas to the leader - non leaders can't serve them.\n\tSplit shard and migrate and the like may need some additional work to operate correct.\n\tThere are still issue around index locking I need to clear up.\n\tThere are still some problems I'm working through on leader promotion involving seeing a corrupt view of the index.\n\tMore tests are needed.\n\n "
        },
        {
            "author": "Timothy Potter",
            "id": "comment-15839802",
            "date": "2017-01-26T14:59:56+0000",
            "content": "I'm curious where this issue is headed and would like to help out if we still think it is doable? I attempted to update the patch to master but still many test failures.\n\nIf we want to keep working on this, can you create PR Mark so we can work on the changes in github vs. with patch files? I'm happy to create one as well ...\n\nLastly, here are the few changes that I couldn't figure out how to apply from the unified patch ... mostly related to sliceCount=0 in tests ... unf. I haven't kept up with test refactoring so am not sure of the correct changes here?\n\n\n[master] ~/dev/lw/projects/lucene-solr$ cat ./solr/core/src/test/org/apache/solr/cloud/CollectionsAPIDistributedZkTest.java.rej\n***************\n*** 149,155 ****\n  \n    \n    public CollectionsAPIDistributedZkTest() {\n-     sliceCount = 2;\n    }\n    \n    @Override\n--- 149,155 ----\n  \n    \n    public CollectionsAPIDistributedZkTest() {\n+     sliceCount = 0;\n    }\n    \n    @Override\n***************\n*** 668,674 ****\n          createNodeList.remove(replica.getNodeName());\n        }\n      }\n-     assertEquals(createNodeList.toString(), 1, createNodeList.size());\n  \n    }\n  \n--- 668,674 ----\n          createNodeList.remove(replica.getNodeName());\n        }\n      }\n+     assertEquals(createNodeList.toString(), 0, createNodeList.size());\n  \n    }\n  \n[master] ~/dev/lw/projects/lucene-solr$ cat ./solr/core/src/test/org/apache/solr/cloud/CollectionStateFormat2Test.java.rej\n***************\n*** 28,33 ****\n  \n  public class CollectionStateFormat2Test extends AbstractFullDistribZkTestBase {\n  \n    protected String getSolrXml() {\n      return \"solr-no-core.xml\";\n    }\n--- 28,37 ----\n  \n  public class CollectionStateFormat2Test extends AbstractFullDistribZkTestBase {\n  \n+   public CollectionStateFormat2Test() {\n+     sliceCount = 0;\n+   }\n+   \n    protected String getSolrXml() {\n      return \"solr-no-core.xml\";\n    }\n[master] ~/dev/lw/projects/lucene-solr$ cat ./solr/core/src/test/org/apache/solr/cloud/CustomCollectionTest.java.rej\n***************\n*** 73,79 ****\n  \n  \n    public CustomCollectionTest() {\n-     sliceCount = 2;\n    }\n  \n    @Override\n--- 73,79 ----\n  \n  \n    public CustomCollectionTest() {\n+     sliceCount = 0;\n    }\n  \n    @Override\n[master] ~/dev/lw/projects/lucene-solr$ cat ./solr/core/src/test/org/apache/solr/cloud/DeleteLastCustomShardedReplicaTest.java.rej\n***************\n*** 55,61 ****\n    }\n  \n    public DeleteLastCustomShardedReplicaTest() {\n-     sliceCount = 2;\n    }\n  \n    @Test\n--- 55,61 ----\n    }\n  \n    public DeleteLastCustomShardedReplicaTest() {\n+     sliceCount = 0;\n    }\n  \n    @Test\n[master] ~/dev/lw/projects/lucene-solr$ cat ./solr/core/src/test/org/apache/solr/cloud/DeleteReplicaTest.java.rej\n***************\n*** 61,67 ****\n    }\n  \n    public DeleteReplicaTest() {\n-     sliceCount = 2;\n    }\n  \n    @Test\n--- 61,67 ----\n    }\n  \n    public DeleteReplicaTest() {\n+     sliceCount = 0;\n    }\n  \n    @Test\n[master] ~/dev/lw/projects/lucene-solr$ cat ./solr/core/src/test/org/apache/solr/cloud/OverseerRolesTest.java.rej\n***************\n*** 62,69 ****\n    }\n  \n    public OverseerRolesTest() {\n-     sliceCount = 2;\n-     fixShardCount(TEST_NIGHTLY ? 6 : 2);\n    }\n  \n    @Test\n--- 62,69 ----\n    }\n  \n    public OverseerRolesTest() {\n+     sliceCount = 0;\n+     fixShardCount(TEST_NIGHTLY ? 6 : 3);\n    }\n  \n    @Test\n[master] ~/dev/lw/projects/lucene-solr$ cat ./solr/core/src/test/org/apache/solr/cloud/RecoveryZkTest.java.rej\n***************\n*** 114,120 ****\n  \n      // test that leader and replica have same doc count\n      \n-     String fail = checkShardConsistency(\"shard1\", false, false);\n      if (fail != null) {\n        fail(fail);\n      }\n--- 114,120 ----\n  \n      // test that leader and replica have same doc count\n      \n+     String fail = checkShardConsistency(DEFAULT_COLLECTION, \"shard1\", false, false);\n      if (fail != null) {\n        fail(fail);\n      }\n[master] ~/dev/lw/projects/lucene-solr$ cat ./solr/core/src/test/org/apache/solr/cloud/SharedFSAutoReplicaFailoverTest.java.rej\n***************\n*** 95,101 ****\n  \n    \n    public SharedFSAutoReplicaFailoverTest() {\n-     sliceCount = 2;\n      completionService = new ExecutorCompletionService<>(executor);\n      pending = new HashSet<>();\n    }\n--- 95,101 ----\n  \n    \n    public SharedFSAutoReplicaFailoverTest() {\n+     sliceCount = 0;\n      completionService = new ExecutorCompletionService<>(executor);\n      pending = new HashSet<>();\n    }\n\n "
        },
        {
            "author": "Mark Miller",
            "id": "comment-15839858",
            "date": "2017-01-26T15:23:57+0000",
            "content": "Yeah, this is still on my list, just a ways down it.\n\nThat patch had plenty of problems, the realtime get forwarding wasn't finished correctly yet, the non leader replicas kept seeing a corrupted view of the index, and I had not worked through most tests.\n\nI do probably have a patch that is a bit more up to date with trunk but it's been awhile since I've synced it with trunk. If you want to set up something on Git that is fine with me. I can probably lend some cycles in the near term here and there. Eventually, if it doesn't move on it's own steam, I'll come back to it more full time. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-15839861",
            "date": "2017-01-26T15:26:22+0000",
            "content": "sliceCount=0 in tests \n\nI cannot remember offhand, but I think most of that was around a more general change to make some of those tests start with no preconfigured cores. The test framework has moved a lot since then. Now you would probably convert them to the new cloud style of test instead, with minisolrcloudcluster or something. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-15884047",
            "date": "2017-02-25T05:41:52+0000",
            "content": "Timothy Potter, where are you at with this? I can try and update my old checkout and push a branch if you want to start pushing this forward. "
        },
        {
            "author": "Timothy Potter",
            "id": "comment-15884296",
            "date": "2017-02-25T16:16:19+0000",
            "content": "Hi Mark Miller, I haven't picked this back up ... was waiting to see SOLR-9835 get completed, but definitely still interested in getting this in. If you post the branch, I can start working on it again. My ultimate aim here is to run Solr on Alluxio (which works already via the HDFS FileSystem API), but I want to avoid duplicating the replicas in memory. "
        },
        {
            "author": "Noble Paul",
            "id": "comment-15884408",
            "date": "2017-02-25T22:16:37+0000",
            "content": "There is somebody working on a passive replication mode for solrcloud. I hope that will work nicely with this requirement "
        },
        {
            "author": "Timothy Potter",
            "id": "comment-15884996",
            "date": "2017-02-27T01:13:26+0000",
            "content": "Hi Noble Paul ... is there a jira for that effort you mention? "
        },
        {
            "author": "Mark Miller",
            "id": "comment-15885008",
            "date": "2017-02-27T01:37:10+0000",
            "content": "He must be talking about the master slave mode in SolrCloud that's being worked on. It has some light overlap but doesn't solve the the design reqs of this issue.  "
        }
    ]
}