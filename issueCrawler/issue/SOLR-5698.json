{
    "id": "LUCENE-5472",
    "title": "Long terms should generate a RuntimeException, not just infoStream",
    "details": {
        "affect_versions": "None",
        "status": "Closed",
        "fix_versions": [
            "4.8",
            "6.0"
        ],
        "components": [],
        "type": "Improvement",
        "priority": "Major",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "As reported on the solr-user list, when a term is greater then 2^15 bytes it is silently ignored at indexing time \u2013 a message is logged in to infoStream if enabled, but no error is thrown.\n\nseems like we should change this behavior (if nothing else starting in 5.0) to throw an exception.",
    "attachments": {
        "LUCENE-5472.patch": "https://issues.apache.org/jira/secure/attachment/12631108/LUCENE-5472.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Hoss Man",
            "id": "comment-13892429",
            "date": "2014-02-05T19:03:01+0000",
            "content": "Easy steps to reproduce using the example configs...\n\n\nhossman@frisbee:~$ perl -le 'print \"a,aaa\"; print \"z,\" . (\"Z\" x 32767);' | curl 'http://localhost:8983/solr/update?header=false&fieldnames=name,long_s&rowid=id&commit=true' -H 'Content-Type: application/csv' --data-binary @- \n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<response>\n<lst name=\"responseHeader\"><int name=\"status\">0</int><int name=\"QTime\">572</int></lst>\n</response>\nhossman@frisbee:~$ curl 'http://localhost:8983/solr/select?q=*:*&fl=id,name&wt=json&indent=true'{\n  \"responseHeader\":{\n    \"status\":0,\n    \"QTime\":12,\n    \"params\":{\n      \"fl\":\"id,name\",\n      \"indent\":\"true\",\n      \"q\":\"*:*\",\n      \"wt\":\"json\"}},\n  \"response\":{\"numFound\":2,\"start\":0,\"docs\":[\n      {\n        \"name\":\"a\",\n        \"id\":\"0\"},\n      {\n        \"name\":\"z\",\n        \"id\":\"1\"}]\n  }}\nhossman@frisbee:~$ curl 'http://localhost:8983/solr/select?q=long_s:*&wt=json&indent=true'\n{\n  \"responseHeader\":{\n    \"status\":0,\n    \"QTime\":1,\n    \"params\":{\n      \"indent\":\"true\",\n      \"q\":\"long_s:*\",\n      \"wt\":\"json\"}},\n  \"response\":{\"numFound\":1,\"start\":0,\"docs\":[\n      {\n        \"name\":\"a\",\n        \"long_s\":\"aaa\",\n        \"id\":\"0\",\n        \"_version_\":1459225819107819520}]\n  }}\n\n "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13892442",
            "date": "2014-02-05T19:13:24+0000",
            "content": "Things i'm confident of...\n\n\n\tthe limit is IndexWriter.MAX_TERM_LENGTH\n\tit is not configurable\n\ta message is written to the infoStream by DocFieldProcessor when this is exceeded...\n\n    if (docState.maxTermPrefix != null && docState.infoStream.isEnabled(\"IW\")) {\n      docState.infoStream.message(\"IW\", \"WARNING: document contains at least one immense term (whose UTF8 encoding is longer than the max length \" + DocumentsWriterPerThread.MAX_TERM_LENGTH_UTF8 + \"), all of which were skipped.  Please correct the analyzer to not produce such terms.  The prefix of the first immense term is: '\" + docState.maxTermPrefix + \"...'\");\n      docState.maxTermPrefix = null;\n    }\n  }\n\n\n\n\n\nThings i think i understand, but am not certain of...\n\n\tby the time DocumentsWriterPerThread sees this problem, and logs this to the infoStream, it's already too late to throw an exception up the call stack (because it's happening in another thread)\n\n\n\nRough idea only half considered...\n\n\tupdate the tokenstream producers in Solr to explicitly check the terms they are about to return and throw an exception if they exceed this length (mention using LengthFilter in this error message)\n\tthis wouldn't help if people use their own concrete Analyzer class \u2013 but it would solve the problem with things like StrField, or anytime analysis factories are used\n\twe could conceivable wrap any user configured concrete Analyzer class to do this check \u2013 but i'm not sure we should, since it will add cycles and the Analyzer might already be well behaved.\n\n\n\nthoughts? "
        },
        {
            "author": "Michael McCandless",
            "id": "comment-13892460",
            "date": "2014-02-05T19:27:22+0000",
            "content": "Actually, I think Lucene should just throw an exc when this happens?  DWPT should be the right place (it isn't a different thread)...\n\nSeparately this limit is absurdly large "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13892571",
            "date": "2014-02-05T21:07:42+0000",
            "content": "I think Lucene should just throw an exc when this happens? ... (it isn't a different thread)\n\nI wasn't entire sure about that \u2013 and since it currently does an infoStream but does not throw an exception, i assumed that was because of the threading.\n\nIf you think we should convert this to a LUCENE issue and throw a RuntimeException i'm all for that.\n "
        },
        {
            "author": "Michael McCandless",
            "id": "comment-13892586",
            "date": "2014-02-05T21:22:58+0000",
            "content": "If you think we should convert this to a LUCENE issue and throw a RuntimeException i'm all for that.\n\n+1\n\nI don't think this leniency is good: it hides that your app is indexing trash. "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13912326",
            "date": "2014-02-26T00:39:21+0000",
            "content": "revising summary & description in prep for converting to LUCENE issue "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13912330",
            "date": "2014-02-26T00:44:32+0000",
            "content": "Here's a quick pass at trying to fix this along with a test.\n\nat the moment the test fails because i didn't see any immediately obvious way to get the fieldname into the exception message, and that seems kind of key to making it useful (yes a byte prefix of the term is there, but for most people indexing text that's not going to be immediately helpful to them to understand where to look for the long term)\n\nI haven't dug down deeper to see if it would be safe/easy to just add the fieldname to docState.maxTermPrefix (as a prefix on the prefix) nor have i run any other tests to see if throwing an exception here breaks any other existing tests that happen to depend on big ass terms being silently ignored. "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13912384",
            "date": "2014-02-26T01:38:31+0000",
            "content": "nor have i run any other tests to see if throwing an exception here breaks any other existing tests that happen to depend on big ass terms being silently ignored.\n\nno surprises jumped out at me when running all tests, although there was an un-surprising failure from TestIndexWriter.testWickedLongTerm which asserts the exact opposite of the new test i added here: that a doc with a \"wicket long\" term can still be added.\n\nAssuming people think the overall change should happen, removing/fixing that test would be trivial. "
        },
        {
            "author": "Michael McCandless",
            "id": "comment-13912713",
            "date": "2014-02-26T09:52:55+0000",
            "content": "Thanks Hoss!\n\nI tweaked the patch a bit, to get the field name into the exc message, and moved where we throw the exception.  I also fixed testWickedLongTerm to verify the exc is thrown, but other documents just indexed are not lost. "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13913557",
            "date": "2014-02-26T21:48:02+0000",
            "content": "I tweaked the patch a bit\n\nLooks pretty good, although \"maxTermField\" in DocumentsWriterPerThread looks like a new unused variable ... cruft from a different approach you were going to take?\n\nDo you think this should be committed only to trunk, or trunk & 4x - or is it too much of a runtime behavior change to put on 4x? \n\nCan/should we make throwing an exception dependent on the Version used in the IndexWriterConfig? (it's not clear to me if enough IW context is passed down to DocInverterPerField currently to even access the Version) "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13913564",
            "date": "2014-02-26T21:51:10+0000",
            "content": "I would prefer we just change it in trunk and 4.x, rather than something tricky. "
        },
        {
            "author": "Michael McCandless",
            "id": "comment-13913565",
            "date": "2014-02-26T21:51:15+0000",
            "content": "cruft from a different approach you were going to take?\n\nWoops, yes, nuke it please \n\nDo you think this should be committed only to trunk, or trunk & 4x - or is it too much of a runtime behavior change to put on 4x?\n\nI think a hard break here is fine; I think it's a service to our users if we notify them that they are indexing trash. "
        },
        {
            "author": "Varun Thacker",
            "id": "comment-13916017",
            "date": "2014-02-28T17:08:34+0000",
            "content": "Attached new patch -\n1. Removed unused variable in DWPT\n2. Added Solr Tests  "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13920258",
            "date": "2014-03-05T00:04:40+0000",
            "content": "I would prefer we just change it in trunk and 4.x, rather than something tricky.\n\nWorks for me \u2013 we can note it in the backcompat section\n\nAdded Solr Tests \n\nThanks for writing those tests Varun!\n\nI've tweaked the patch slightly...\n\n\n\trenamed Varun's Solr TestIndexing -> TestExceedMaxTermLength so it's more clear what we're testing\n\tfixed a variable typo in the test (longFielValue -> longFieldValue)\n\tfixed patch so that \"ant precommit\" would pass (String.format was being used w/o a Locale)\n\tremoved a stale nocommit comment i'd put in lucene's TestExceedMaxTermLength that Mike fixed a few patches ago\n\tfixed the jdocs for IndexWriter.addDocument to refer to MAX_TERM_LENGTH (ironically it already incorrectly said that terms which were too long would cause an IllegalArgumentException\n\n\n\nI think this is ready? speak now or i'll commit tomorrow. "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-13921124",
            "date": "2014-03-05T18:05:26+0000",
            "content": "Commit 1574595 from hossman@apache.org in branch 'dev/trunk'\n[ https://svn.apache.org/r1574595 ]\n\nLUCENE-5472: IndexWriter.addDocument will now throw an IllegalArgumentException if a Term to be indexed exceeds IndexWriter.MAX_TERM_LENGTH "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-13921288",
            "date": "2014-03-05T19:37:55+0000",
            "content": "Commit 1574637 from hossman@apache.org in branch 'dev/branches/branch_4x'\n[ https://svn.apache.org/r1574637 ]\n\nLUCENE-5472: IndexWriter.addDocument will now throw an IllegalArgumentException if a Term to be indexed exceeds IndexWriter.MAX_TERM_LENGTH (merge r1574595) "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13921290",
            "date": "2014-03-05T19:38:56+0000",
            "content": "thanks everybody! "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-13982587",
            "date": "2014-04-27T23:25:50+0000",
            "content": "Close issue after release of 4.8.0 "
        }
    ]
}