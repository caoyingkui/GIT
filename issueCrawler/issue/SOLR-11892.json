{
    "id": "SOLR-11892",
    "title": "Avoid unnecessary exceptions in FSDirectory and RAMDirectory",
    "details": {
        "labels": "",
        "priority": "Minor",
        "components": [],
        "type": "Improvement",
        "fix_versions": [],
        "affect_versions": "None",
        "resolution": "Invalid",
        "status": "Closed"
    },
    "description": "In privateDeleteFile, just use deleteIfExists.\n\nin RamDirectory we can declare a static exception and create it once.",
    "attachments": {
        "Screen Shot 2018-01-24 at 9.09.55 PM.png": "https://issues.apache.org/jira/secure/attachment/12907632/Screen%20Shot%202018-01-24%20at%209.09.55%20PM.png",
        "Screen Shot 2018-01-24 at 9.10.47 PM.png": "https://issues.apache.org/jira/secure/attachment/12907633/Screen%20Shot%202018-01-24%20at%209.10.47%20PM.png"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2018-01-24T05:21:45+0000",
            "content": "-1: the exact exception type is important. Sorry, I don't think we should make our directory implementations lenient.\n\nNor should we use such static pre-canned exceptions here. Not the place to try to be cute: There is already a filesystem metadata operation happening:\n\nhttps://gist.github.com/jboner/2841832\n\nAnd this really needs to be a lucene issue, not a solr one. ",
            "author": "Robert Muir",
            "id": "comment-16336933"
        },
        {
            "date": "2018-01-25T00:49:35+0000",
            "content": "Robert Muir\n\nIs the argument you're making that catching an occasional exception is cheaper than testing if a file exists first? I.e. since\u00a0a large majority of the deletes are successful it would be a net loss to test first. Stack traces are not cheap, but the argument would be that it's cheaper than\u00a0adding a\u00a0seek to the file to test existence. Or am I misinterpreting your link?\n\nUh oh. Just looked at the code for FileSystemProvider.deleteIfExists. So if I read this correctly deleteIfExists doesn't really avoid the exception anyway, just conceals it. So changing FSDirectory to use deleteIfExists seems like a net-zero change .vs. catching an exception, do you agree?\n\npublic boolean deleteIfExists(Path path) throws IOException {\n\u00a0 try {\n\u00a0 \u00a0 delete(path);\n\u00a0 \u00a0 return true;\n\u00a0 } catch (NoSuchFileException ignore) {\n\u00a0 \u00a0 return false;\u00a0\n{{\u00a0 }}}\n}\n\n\u00a0\n\nAnother take is that the effort would be better spent understanding why we try to delete files that don't exist in the first place and fix that.\n\nYeah, this should be a Lucene issue, I'll move it over if we decide to take it forward. ",
            "author": "Erick Erickson",
            "id": "comment-16338503"
        },
        {
            "date": "2018-01-25T02:09:39+0000",
            "content": "Exceptions are cheap, deleting files is scary and I am against such \"optimizations\".\n\nI see these issues being opened across the solr project but someone is either horribly confused by their profiler's sampling bias, smoking crack, or both. ",
            "author": "Robert Muir",
            "id": "comment-16338601"
        },
        {
            "date": "2018-01-25T03:36:14+0000",
            "content": "I was not suggesting the code snippet\u00a0as\u00a0a proposal, rather I was making a comment that using deleteIfExists doesn't help at all since it just conceals the same exception from the profiler. So there's no reason to even consider changing the code in privateDelete.\n\nDid you see this next part?\n\n\"Another take is that the effort would be better spent understanding why we try to delete files that don't exist in the first place and fix\u00a0that.\"?\n\nIf \"deleting files is scary\", it seems that trying to delete files that don't exist is also scary and why the attempt is even being made should be investigated. Then we can decide what the proper fix should be, if any.\n\n\u00a0 ",
            "author": "Erick Erickson",
            "id": "comment-16338678"
        },
        {
            "date": "2018-01-25T04:01:08+0000",
            "content": "The leniency there only exists for windows systems / CIFS mounts of windows shares: which may not allow this and require retries. It is explained both in the code comments and the oracle JDK documentation for Files.delete. I don't think there is anything to figure out, except perhaps \"drop windows / CIFS mount support\".\n\nIt is also important to understand what deleteIfExists really does, it simply does nothing but catch an exception and return a boolean: http://hg.openjdk.java.net/jdk/jdk/file/b742e0f9ce80/src/java.base/share/classes/java/nio/file/spi/FileSystemProvider.java#l737\n\nBut sorry, deleting files is nobody's hotspot in lucene, its not the place to add any \"optimizations\". As far as creating exceptions statically, this is 100% bogus and will make debugging impossible. I an completely against it for any lucene code. ",
            "author": "Robert Muir",
            "id": "comment-16338695"
        },
        {
            "date": "2018-01-25T05:46:19+0000",
            "content": "I'm not being clear. Forget all about deleteIfExists, I agree that it doesn't help. Forget about optimizations, I'm over that too.\n\nThe remaining question for me is code correctness. We seem to be trying to delete files that don't exist. That\u00a0raises the possibility\u00a0that somewhere the bookkeeping is off, or there's a race condition or...\u00a0Was a decision made that any such bookkeeping issues (if they in fact exist)\u00a0can safely\u00a0be ignored or are handled appropriately? And/or performance would suffer if underlying issues were addressed?\n\nWe don't see bad indexes or ever-growing numbers of file handles and I'm certain this is not new, nor is it a crisis. I do wonder if we're catching exceptions and driving on, masking\u00a0underlying issues.\n\nAnother way to say it is to ask if, in your view, does the existence of these exceptions raise any concerns about the correctness of the code that's trying to delete files that don't exist and generating them?\n\nI'll attach a couple of screen shots for an indexing\u00a0load test over a one minute time frame showing over 2,600 such exceptions. Unix file system. These are from 6.6.2, but I'm reasonably sure I saw the same things in master, if\u00a0this Jira is\u00a0worth pursuing I can double-check. ",
            "author": "Erick Erickson",
            "id": "comment-16338762"
        },
        {
            "date": "2018-01-29T19:09:56+0000",
            "content": "Few points about Exception cost:\n\n\tIt can not be assumed that all JVM's are all optimized the same, therefore, performance cost should not be ignored. \u00a0General assumptions on cost should not be based on one VM's optimization.\n\tException creation has associated cost, follow the stack on an exception creation :\n\t\n\t\tpublic synchronized Throwable fillInStackTrace() {\n if (stackTrace != null ||\n backtrace != null /* Out of protocol state */ ) \n{\n fillInStackTrace(0);\n stackTrace = UNASSIGNED_STACK;\n }\n return this;\n}\n\t\n\t\n\n\n\nprivate native Throwable fillInStackTrace(int dummy);\n\n\t\n\t\n\t\tIn addition to being synchronized, it has a memory cost, the exception, and all stackelement strings\n\t\n\t\n\tExceptions in the critical path will affect performance, and add to memory pressure.\n\t\n\t\tIn this use case it appears to be logic flow control, and not of the Exception\n\t\n\t\n\n\n\nIn addition to the cpu and memory cost, the frequency of such an exception, the absence of file name map entry is indicative of a race condition, a bug, or a concurrency issue.\n\nThe general rule about exceptions, as they're named, they should be of the exception, and not the norm.\u00a0 ",
            "author": "hamada",
            "id": "comment-16343843"
        },
        {
            "date": "2018-01-29T20:39:07+0000",
            "content": "specifically\u00a0the code of interest where an IOException is thrown \u00a0RAMDirectory\u00a0:\n\n@Override\n public void deleteFile(String name) throws IOException {\n ensureOpen();\n RAMFile file = fileMap.remove(name);\n if (file != null)\n\n{ file.directory = null; sizeInBytes.addAndGet(-file.sizeInBytes); }\n\nelse\n\n{ // FIXME there are no file operations here this method removes fileName entry from a map, it isn't per se deleting a file!\n\nthrow new FileNotFoundException(name); }\n\n} ",
            "author": "hamada",
            "id": "comment-16343976"
        },
        {
            "date": "2018-01-31T07:03:00+0000",
            "content": "I've been digging into this a little more and here's what I'm seeing: The large majority of these are coming from these lines in NRTCachingDirectory.createOutput:\n\ntry {\n\u00a0 in.deleteFile(name);\n{{ } catch (IOException ioe) {}}\n\u00a0 // This is fine: file may not exist\n{{ }}}\n\nThe naive question is \"why wouldn't just opening the file for overwrite work?\" My guess is there's too many edge cases when it comes to different filesystem semantics (e.g. Windows and Unix), plus RAMDirectory issues. Or left over files if someone pulled the plug on the machine with segments created that weren't written yet to the segments_n file. Or......\n\nFor yucks I tried using NIOFSDirectory and it caused almost all of these exceptions to disappear, as did MMapDirectory. Does that make sense from your perspectives?\n\nSo I guess it comes down to whether the logic of deleting the files in NRTCachingDirectory is necessary, there's no explanation in the code for what this guards against and I'm not familiar enough with all the concerns to know off the top of my head. All education welcome.... ",
            "author": "Erick Erickson",
            "id": "comment-16346345"
        },
        {
            "date": "2018-02-01T06:04:30+0000",
            "content": "Moved over to Lucene where it properly belongs. ",
            "author": "Erick Erickson",
            "id": "comment-16348059"
        }
    ]
}