{
    "id": "SOLR-6144",
    "title": "DIH Cache backed with MapDB",
    "details": {
        "affect_versions": "None",
        "status": "Open",
        "fix_versions": [],
        "components": [
            "contrib - DataImportHandler"
        ],
        "type": "New Feature",
        "priority": "Minor",
        "labels": "",
        "resolution": "Unresolved"
    },
    "description": "This is a DIH Cache implementation using Map DB version 1.0.2.  Map DB is a pure Java key-value store that supports both file-based caches and memory-based caches (both on- and off-heap).  See http://www.mapdb.org/.  MapDB is ASL2.0 licensed, so unlike the BDB-JE cache impl (SOLR-2613), this one could potentially be committed.\n\nThis does not perform nearly as well as the BDB-JE cache, but I imagine it is fast enough for a lot of uses.",
    "attachments": {
        "SOLR-6144.patch": "https://issues.apache.org/jira/secure/attachment/12648544/SOLR-6144.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "James Dyer",
            "id": "comment-14019206",
            "date": "2014-06-05T20:37:49+0000",
            "content": "The attached patch requires SOLR-2943 (patch, uncommitted) also. "
        },
        {
            "author": "Ravikanth Gangarapu",
            "id": "comment-14112414",
            "date": "2014-08-27T16:39:04+0000",
            "content": "James Dyer\nhi, I have tried a simpler version of the MapDBCache implementation which is used as a simple replacement for SortedMapBackedCache to store cache on files. I found that if storage mode is file and my SQl query is bringing Clob objects (SQL Server with jtds driver), MapDB will complain about not able to serialize the data on db.commit(). So, I have modified the add() method to go thru record Map and find values that cannot be serialized ( in my case Clob objects) and read the data into a string and put it as value. My solution is not generic, but i think we may need a NonSerializableDataConverter interface and a list of those converter objects on the MapDBcache instance So cache class can handle them properly. Just a suggestion, let me know your feedback, I can contribute.\n\nThanks\nRavi "
        },
        {
            "author": "James Dyer",
            "id": "comment-14118239",
            "date": "2014-09-02T14:36:32+0000",
            "content": "Ravikanth,\n\nFor this ticket, I basically looked at the MapDB quick start guide and tried a rough cache implementation.  I'm hoping for a fast, pure-java alternative to Berkley DB Java Edition, which I use in Production and is very fast.  Unfortunately, this cache was for my use case an order of magnitude slower than the BDB-JE cache (See SOLR-2613).  \n\nIf you can offer improvements to what I have here and especially if you can iron out its inefficiencies, I'd love to have a persistent cache I can actually commit (BDB-JE is incompatibly licensed, so it cannot be committed). Assuming we cannot get MapDB to be fast enough for my use, maybe it would be useful for a lot of other folks?  "
        }
    ]
}