{
    "id": "SOLR-7082",
    "title": "Streaming Aggregation for SolrCloud",
    "details": {
        "components": [
            "SolrCloud"
        ],
        "type": "New Feature",
        "labels": "",
        "fix_versions": [
            "5.1",
            "6.0"
        ],
        "affect_versions": "None",
        "status": "Closed",
        "resolution": "Fixed",
        "priority": "Major"
    },
    "description": "This issue provides a general purpose streaming aggregation framework for SolrCloud. An overview of how it works can be found at this link:\n\nhttp://heliosearch.org/streaming-aggregation-for-solrcloud/\n\nThis functionality allows SolrCloud users to perform operations that we're typically done using map/reduce or a parallel computing platform.\n\nHere is a brief explanation of how the framework works:\n\nThere is a new Solrj io package found in: org.apache.solr.client.solrj.io\n\nKey classes:\n\nTuple: Abstracts a document in a search result as a Map of key/value pairs.\nTupleStream: is the base class for all of the streams. Abstracts search results as a stream of Tuples.\nSolrStream: connects to a single Solr instance. You call the read() method to iterate over the Tuples.\nCloudSolrStream: connects to a SolrCloud collection and merges the results based on the sort param. The merge takes place in CloudSolrStream itself.\nDecorator Streams: wrap other streams to perform operations the streams. Some examples are the UniqueStream, MergeStream and ReducerStream.\n\nGoing parallel with the ParallelStream and  \"Worker Collections\"\n\nThe io package also contains the ParallelStream, which wraps a TupleStream and sends it to N worker nodes. The workers are chosen from a SolrCloud collection. These \"Worker Collections\" don't have to hold any data, they can just be used to execute TupleStreams.\n\nThe StreamHandler\n\nThe Worker nodes have a new RequestHandler called the StreamHandler. The ParallelStream serializes a TupleStream, before it is opened, and sends it to the StreamHandler on the Worker Nodes.\n\nThe StreamHandler on each Worker node deserializes the TupleStream, opens the stream, iterates the tuples and streams them back to the ParallelStream. The ParallelStream performs the final merge of Metrics and can be wrapped by other Streams to handled the final merged TupleStream.\n\nSorting and Partitioning search results (Shuffling)\n\nEach Worker node is shuffled 1/N of the document results. There is a \"partitionKeys\" parameter that can be included with each TupleStream to ensure that Tuples with the same partitionKeys are shuffled to the same Worker. The actual partitioning is done with a filter query using the HashQParserPlugin. The DocSets from the HashQParserPlugin can be cached in the filter cache which provides extremely high performance hash partitioning. \n\nMany of the stream transformations rely on the sort order of the TupleStreams (GroupByStream, MergeJoinStream, UniqueStream, FilterStream etc..). To accommodate this the search results can be sorted by specific keys. The \"/export\" handler can be used to sort entire result sets efficiently.\n\nBy specifying the sort order of the results and the partition keys, documents will be sorted and partitioned inside of the search engine. So when the tuples hit the network they are already sorted, partitioned and headed directly to correct worker node.\n\nExtending The Framework\n\nTo extend the framework you create new TupleStream Decorators, that gather custom metrics or perform custom stream transformations.",
    "attachments": {
        "SOLR-7082.patch": "https://issues.apache.org/jira/secure/attachment/12696836/SOLR-7082.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2015-02-05T19:53:00+0000",
            "author": "Joel Bernstein",
            "content": "The initial patch includes a fully operational parallel streaming framework with tests.\n\nIt's a fairly large patch so I'll be updating this ticket with details about the design and code. ",
            "id": "comment-14307869"
        },
        {
            "date": "2015-02-17T19:43:18+0000",
            "author": "Joel Bernstein",
            "content": "Works with latest updates to Trunk ",
            "id": "comment-14324757"
        },
        {
            "date": "2015-02-23T16:48:03+0000",
            "author": "Otis Gospodnetic",
            "content": "This looks really nice, Joel.  2 questions:\n\n\tthis looks a lot like ES aggregations.  Have you maybe made any comparisons in terms of speed or memory footprint? (ES aggregations love heap)\n\tis this all going to land in Solr or will some of it remain in Heliosearch?\n\n ",
            "id": "comment-14333490"
        },
        {
            "date": "2015-03-01T15:48:10+0000",
            "author": "Joel Bernstein",
            "content": "Hi Otis,\n\nSorry about the slow response, just got back from vacation and still catching up. I'll be writing more about how Streaming aggregation works this week. Here are some thoughts on your questions:\n\n1) This ticket is focused on providing fast streaming Map/Reduce like functionality. Streams can be sorted and partitioned strategically to minimized the amount of memory needed to perform aggregations and transformations. It should be fairly responsive because it pushes most of the work (record selection, sorting, partitioning) into the search the engine. So records go straight from the search engine to the correct worker node to be reduced. These techniques won't be as fast as faceting, but it will support a very wide range of use cases.\n\n2) I aiming to get this into Solr trunk soon with eye towards having this ready to go for Solr 5.1\n\n ",
            "id": "comment-14342293"
        },
        {
            "date": "2015-03-02T03:16:59+0000",
            "author": "Otis Gospodnetic",
            "content": "Thanks Joel.  Re 1) \u2013 but conceptually and functionally speaking, would you say this is more or less the same as ES aggregations? ",
            "id": "comment-14342655"
        },
        {
            "date": "2015-03-02T04:33:47+0000",
            "author": "Joel Bernstein",
            "content": "I believe this is more closely comparable to technologies that shuffle, like Map/Reduce.  ",
            "id": "comment-14342720"
        },
        {
            "date": "2015-03-02T04:36:45+0000",
            "author": "Yonik Seeley",
            "content": "but conceptually and functionally speaking, would you say this is more or less the same as ES aggregations?\n\nI don't think so.  The heliosearch JSON Facet API looks a lot more like ES aggregations?   Streaming aggregations is a more general purpose distributed computation framework.\n ",
            "id": "comment-14342723"
        },
        {
            "date": "2015-03-03T02:30:31+0000",
            "author": "Joel Bernstein",
            "content": "Patch with all tests passing. ",
            "id": "comment-14344350"
        },
        {
            "date": "2015-03-09T21:54:18+0000",
            "author": "Joel Bernstein",
            "content": "Latest work includes more tests, and convenience methods on the Tuple class. Also the HashQParserPlugin doesn't get the hashcode directly from the BytesRef, it converts to CharsRef first using StrField.indexedToReadable. ",
            "id": "comment-14353706"
        },
        {
            "date": "2015-03-09T23:04:43+0000",
            "author": "Joel Bernstein",
            "content": "New patch with precommit passing ",
            "id": "comment-14353829"
        },
        {
            "date": "2015-03-10T01:41:30+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1665391 from Joel Bernstein in branch 'dev/trunk'\n[ https://svn.apache.org/r1665391 ]\n\nSOLR-7082: Streaming Aggregation for SolrCloud ",
            "id": "comment-14354080"
        },
        {
            "date": "2015-03-10T10:41:44+0000",
            "author": "Ramkumar Aiyengar",
            "content": "Haven't looked at the patch in great detail, but looks like the SolrJ side could use a few tests? There's a new package there but with no tests?  ",
            "id": "comment-14354650"
        },
        {
            "date": "2015-03-10T11:33:30+0000",
            "author": "Joel Bernstein",
            "content": "The initial set of tests are here:\nhttps://svn.apache.org/viewvc/lucene/dev/trunk/solr/solrj/src/test/org/apache/solr/client/solrj/io/StreamingTest.java\n\nWe can break these out to smaller files also. ",
            "id": "comment-14354747"
        },
        {
            "date": "2015-03-10T20:51:48+0000",
            "author": "Ramkumar Aiyengar",
            "content": "Missed that, thanks Joel.. ",
            "id": "comment-14355680"
        },
        {
            "date": "2015-03-25T17:17:46+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1669164 from Joel Bernstein in branch 'dev/trunk'\n[ https://svn.apache.org/r1669164 ]\n\nSOLR-7082: Streaming Aggregation for SolrCloud ",
            "id": "comment-14380273"
        },
        {
            "date": "2015-03-25T17:24:37+0000",
            "author": "Joel Bernstein",
            "content": "In the latest commit a few stream implementations are removed to focus on a core set of foundational streams for the initial release.  ",
            "id": "comment-14380288"
        },
        {
            "date": "2015-03-25T19:42:27+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1669212 from Joel Bernstein in branch 'dev/branches/branch_5x'\n[ https://svn.apache.org/r1669212 ]\n\nSOLR-7082 SOLR-7224 SOLR-7225: Streaming Aggregation for SolrCloud ",
            "id": "comment-14380604"
        },
        {
            "date": "2015-03-26T13:40:37+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1669343 from Joel Bernstein in branch 'dev/trunk'\n[ https://svn.apache.org/r1669343 ]\n\nSOLR-7082: update CHANGES.txt ",
            "id": "comment-14381881"
        },
        {
            "date": "2015-03-26T13:42:34+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1669344 from Joel Bernstein in branch 'dev/branches/branch_5x'\n[ https://svn.apache.org/r1669344 ]\n\nSOLR-7082: update CHANGES.txt ",
            "id": "comment-14381884"
        },
        {
            "date": "2015-03-27T12:19:17+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1669554 from Joel Bernstein in branch 'dev/trunk'\n[ https://svn.apache.org/r1669554 ]\n\nSOLR-7082: Editing Javadoc ",
            "id": "comment-14383749"
        },
        {
            "date": "2015-03-27T12:22:03+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1669557 from Joel Bernstein in branch 'dev/branches/branch_5x'\n[ https://svn.apache.org/r1669557 ]\n\nSOLR-7082: Editing Javadoc ",
            "id": "comment-14383752"
        },
        {
            "date": "2015-03-30T18:56:49+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1670176 from Joel Bernstein in branch 'dev/trunk'\n[ https://svn.apache.org/r1670176 ]\n\nSOLR-7082: Syntactic sugar for metric gathering ",
            "id": "comment-14387207"
        },
        {
            "date": "2015-03-30T19:10:35+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1670181 from Joel Bernstein in branch 'dev/branches/branch_5x'\n[ https://svn.apache.org/r1670181 ]\n\nSOLR-7082: Syntactic sugar for metric gathering ",
            "id": "comment-14387237"
        }
    ]
}