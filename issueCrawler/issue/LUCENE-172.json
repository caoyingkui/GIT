{
    "id": "LUCENE-172",
    "title": "[PATCH] Test case for FrenchAnalyzer",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [
            "modules/analysis"
        ],
        "type": "Bug",
        "fix_versions": [],
        "affect_versions": "None",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "Hello,\n\nfollowing is a test case for the French Analyzer to help it get out of the \nsandbox  Looks OK, only has some strange behavior with the minus sign.\nI included a slight modification of the Analyzer to better handle null \nparameters just in case of.\n\n\u2014\n\npackage org.apache.lucene.analysis.fr;\n\n/* ====================================================================\n\n\tThe Apache Software License, Version 1.1\n *\n\tCopyright (c) 2001 The Apache Software Foundation.  All rights\n\treserved.\n *\n\tRedistribution and use in source and binary forms, with or without\n\tmodification, are permitted provided that the following conditions\n\tare met:\n *\n\t1. Redistributions of source code must retain the above copyright\n\tnotice, this list of conditions and the following disclaimer.\n *\n\t2. Redistributions in binary form must reproduce the above copyright\n\tnotice, this list of conditions and the following disclaimer in\n\tthe documentation and/or other materials provided with the\n\tdistribution.\n *\n\t3. The end-user documentation included with the redistribution,\n\tif any, must include the following acknowledgment:\n\t\"This product includes software developed by the\n\tApache Software Foundation (http://www.apache.org/).\"\n\tAlternately, this acknowledgment may appear in the software itself,\n\tif and wherever such third-party acknowledgments normally appear.\n *\n\t4. The names \"Apache\" and \"Apache Software Foundation\" and\n\t\"Apache Lucene\" must not be used to endorse or promote products\n\tderived from this software without prior written permission. For\n\twritten permission, please contact apache@apache.org.\n *\n\t5. Products derived from this software may not be called \"Apache\",\n\t\"Apache Lucene\", nor may \"Apache\" appear in their name, without\n\tprior written permission of the Apache Software Foundation.\n *\n\tTHIS SOFTWARE IS PROVIDED ``AS IS'' AND ANY EXPRESSED OR IMPLIED\n\tWARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES\n\tOF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n\tDISCLAIMED.  IN NO EVENT SHALL THE APACHE SOFTWARE FOUNDATION OR\n\tITS CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n\tSPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n\tLIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF\n\tUSE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND\n\tON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n\tOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT\n\tOF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF\n\tSUCH DAMAGE.\n\t====================================================================\n *\n\tThis software consists of voluntary contributions made by many\n\tindividuals on behalf of the Apache Software Foundation.  For more\n\tinformation on the Apache Software Foundation, please see\n\t<http://www.apache.org/>.\n */\n\n\n\nimport java.io.Reader;\nimport java.io.StringReader;\n\nimport junit.framework.TestCase;\n\nimport org.apache.lucene.analysis.Analyzer;\nimport org.apache.lucene.analysis.Token;\nimport org.apache.lucene.analysis.TokenStream;\n\n/**\n\n\tTest case for FrenchAnalyzer.\n *\n\t@author    Jean-Fran\u00c3\u00a7ois Halleux\n\t@version   $version$\n */\n\n\n\npublic class TestFrenchAnalyzer extends TestCase {\n\n\tpublic void assertAnalyzesTo(Analyzer a, String input, String[] output)\n\t\tthrows Exception {\n\n\t\tTokenStream ts = a.tokenStream(\"dummy\", new StringReader\n(input));\n\n\t\tfor (int i = 0; i < output.length; i++) \n{\n\t\t\tToken t = ts.next();\n\t\t\tassertNotNull(t);\n\t\t\tassertEquals(t.termText(), output[i]);\n\t\t}\n\t\tassertNull(ts.next());\n\t\tts.close();\n\t}\n\n\tpublic void testAnalyzer() throws Exception {\n\t\tFrenchAnalyzer fa = new FrenchAnalyzer();\n\n\t\t// test null reader\n\t\tboolean iaeFlag = false;\n\t\ttry \n{\n\t\t\tTokenStream ts = fa.tokenStream(\"dummy\", null);\n\t\t}\n catch (IllegalArgumentException iae) \n{\n\t\t\tiaeFlag = true;\n\t\t}\n\t\tassertEquals(iaeFlag, true);\n\n\t\t// test null fieldname\n\t\tiaeFlag = true;\n\t\ttry {\n\t\t\tTokenStream ts = fa.tokenStream(null, new StringReader\n(\"dummy\"));\n\t\t} catch (IllegalArgumentException iae) {\t\t\tiaeFlag = true;\t\t}\n\t\tassertEquals(iaeFlag, true);\n\n\t\tassertAnalyzesTo(fa, \"\", new String[] {\n\t\t});\n\n\t\tassertAnalyzesTo(\n\t\t\tfa,\n\t\t\t\"chien chat cheval\",\n\t\t\tnew String[] \n{ \"chien\", \"chat\", \"cheval\" });\n\n\t\tassertAnalyzesTo(\n\t\t\tfa,\n\t\t\t\"chien CHAT CHEVAL\",\n\t\t\tnew String[] { \"chien\", \"chat\", \"cheval\" }\n);\n\n\t\tassertAnalyzesTo(\n\t\t\tfa,\n\t\t\t\"  chien  ,? + = -  CHAT /: > CHEVAL\",\n\t\t\tnew String[] \n{ \"chien\", \"chat\", \"cheval\" });\n\n\t\tassertAnalyzesTo(fa, \"chien++\", new String[] { \"chien\" });\n\n\t\tassertAnalyzesTo(\n\t\t\tfa,\n\t\t\t\"mot \\\"entreguillemet\\\"\",\n\t\t\tnew String[] { \"mot\", \"entreguillemet\" });\n\n\t\t// let's do some french specific tests now\t\n\n\t\t// 1. couldn't resist\n\t\t// I would expect this to stay one term as in French the minus \nsign\n\t\t// is often used for composing words\n\t\tassertAnalyzesTo(\n\t\t\tfa,\n\t\t\t\"Jean-Fran\u00c3\u00a7ois\",\n\t\t\tnew String[] { \"jean\", \"fran\u00c3\u00a7ois\" });\n\n\t\t// 2. stopwords\n\t\tassertAnalyzesTo(\n\t\t\tfa,\n\t\t\t\"le la chien les aux chat du des \u00c3\u00a0 cheval\",\n\t\t\tnew String[] { \"chien\", \"chat\", \"cheval\" }\n);\n\n\t\t// some nouns and adjectives\n\t\tassertAnalyzesTo(\n\t\t\tfa,\n\t\t\t\"lances chismes habitable chiste \u00c3\u00a9l\u00c3\u00a9ments captifs\",\n\t\t\tnew String[] \n{\n\t\t\t\t\"lanc\",\n\t\t\t\t\"chism\",\n\t\t\t\t\"habit\",\n\t\t\t\t\"chist\",\n\t\t\t\t\"\u00c3\u00a9l\u00c3\u00a9ment\",\n\t\t\t\t\"captif\" }\n);\n\n\t\t// some verbs\n\t\tassertAnalyzesTo(\n\t\t\tfa,\n\t\t\t\"finissions souffrirent rugissante\",\n\t\t\tnew String[] \n{ \"fin\", \"souffr\", \"rug\" }\n);\n\n\t\t// some everything else\n\t\t// aujourd'hui stays one term which is OK\n\t\tassertAnalyzesTo(\n\t\t\tfa,\n\t\t\t\"C3PO aujourd'hui oeuf \u00c3\u00af\u00c3\u00a2\u00c3\u00b6\u00c3\u00bb\u00c3\u00a0\u00c3\u00a4 anticonstitutionnellement \nJava++\",\n\t\t\tnew String[] \n{\n\t\t\t\t\"c3po\",\n\t\t\t\t\"aujourd'hui\",\n\t\t\t\t\"oeuf\",\n\t\t\t\t\"\u00c3\u00af\u00c3\u00a2\u00c3\u00b6\u00c3\u00bb\u00c3\u00a0\u00c3\u00a4\",\n\t\t\t\t\"anticonstitutionnel\",\n\t\t\t\t\"jav\" }\n);\n\n\t\t// some more everything else\n\t\t// here 1940-1945 stays as one term, 1940:1945 not ?\n\t\tassertAnalyzesTo(\n\t\t\tfa,\n\t\t\t\"33Bis 1940-1945 1940:1945 (---i+++)*\",\n\t\t\tnew String[] \n{ \"33bis\", \"1940-\n1945\", \"1940\", \"1945\", \"i\" }\n);\n\n\t}\n\n}\n\n\u2014\n\npackage org.apache.lucene.analysis.fr;\n\nimport org.apache.lucene.analysis.Analyzer;\nimport org.apache.lucene.analysis.LowerCaseFilter;\nimport org.apache.lucene.analysis.StopFilter;\nimport org.apache.lucene.analysis.TokenStream;\nimport org.apache.lucene.analysis.standard.StandardFilter;\nimport org.apache.lucene.analysis.standard.StandardTokenizer;\nimport java.io.File;\nimport java.io.Reader;\nimport java.util.Hashtable;\nimport org.apache.lucene.analysis.de.WordlistLoader;\n\n/**\n\n\tAnalyzer for french language. Supports an external list of stopwords (words\nthat\n\twill not be indexed at all) and an external list of exclusions (word that\nwill\n\tnot be stemmed, but indexed).\n\tA default set of stopwords is used unless an other list is specified, the\n\texclusionlist is empty by default.\n *\n\t@author    Patrick Talbot (based on Gerhard Schwarz work for German)\n\t@version   $Id: FrenchAnalyzer.java,v 1.1 2004/01/20 10:07:01 ehatcher Exp $\n */\npublic final class FrenchAnalyzer extends Analyzer {\n\n\n\n\t/**\n\n\tExtended list of typical french stopwords.\n\t */\n\tprivate String[] FRENCH_STOP_WORDS = \n{\n\t\n\t\"a\", \"afin\", \"ai\", \"ainsi\", \"apr\u00c3\u00a8s\", \"attendu\", \"au\", \"aujourd\", \"auquel\n\", \"aussi\",\n\t\n\t\"autre\", \"autres\", \"aux\", \"auxquelles\", \"auxquels\", \"avait\", \"avant\", \"a\nvec\", \"avoir\",\n\t\n\t\"c\", \"car\", \"ce\", \"ceci\", \"cela\", \"celle\", \"celles\", \"celui\", \"cependant\n\", \"certain\",\n\t\n\t\"certaine\", \"certaines\", \"certains\", \"ces\", \"cet\", \"cette\", \"ceux\", \"che\nz\", \"ci\",\n\t\n\t\"combien\", \"comme\", \"comment\", \"concernant\", \"contre\", \"d\", \"dans\", \"de\"\n, \"debout\",\n\t\n\t\"dedans\", \"dehors\", \"del\u00c3\u00a0\", \"depuis\", \"derri\u00c3\u00a8re\", \"des\", \"d\u00c3\u00a9sormais\", \"d\nesquelles\",\n\t\n\t\"desquels\", \"dessous\", \"dessus\", \"devant\", \"devers\", \"devra\", \"divers\", \n\"diverse\",\n\t\n\t\"diverses\", \"doit\", \"donc\", \"dont\", \"du\", \"duquel\", \"durant\", \"d\u00c3\u00a8s\", \"el\nle\", \"elles\",\n\t\n\t\"en\", \"entre\", \"environ\", \"est\", \"et\", \"etc\", \"etre\", \"eu\", \"eux\", \"exce\npt\u00c3\u00a9\", \"hormis\",\n\t\n\t\"hors\", \"h\u00c3\u00a9las\", \"hui\", \"il\", \"ils\", \"j\", \"je\", \"jusqu\", \"jusque\", \"l\", \n\"la\", \"laquelle\",\n\t\n\t\"le\", \"lequel\", \"les\", \"lesquelles\", \"lesquels\", \"leur\", \"leurs\", \"lorsq\nue\", \"lui\", \"l\u00c3\u00a0\",\n\t\n\t\"ma\", \"mais\", \"malgr\u00c3\u00a9\", \"me\", \"merci\", \"mes\", \"mien\", \"mienne\", \"miennes\n\", \"miens\", \"moi\",\n\t\n\t\"moins\", \"mon\", \"moyennant\", \"m\u00c3\u00aame\", \"m\u00c3\u00aames\", \"n\", \"ne\", \"ni\", \"non\", \"n\nos\", \"notre\",\n\t\n\t\"nous\", \"n\u00c3\u00a9anmoins\", \"n\u00c3\u00b4tre\", \"n\u00c3\u00b4tres\", \"on\", \"ont\", \"ou\", \"outre\", \"o\u00c3\u00b9\"\n, \"par\", \"parmi\",\n\t\n\t\"partant\", \"pas\", \"pass\u00c3\u00a9\", \"pendant\", \"plein\", \"plus\", \"plusieurs\", \"pou\nr\", \"pourquoi\",\n\t\n\t\"proche\", \"pr\u00c3\u00a8s\", \"puisque\", \"qu\", \"quand\", \"que\", \"quel\", \"quelle\", \"qu\nelles\", \"quels\",\n\t\n\t\"qui\", \"quoi\", \"quoique\", \"revoici\", \"revoil\u00c3\u00a0\", \"s\", \"sa\", \"sans\", \"sauf\n\", \"se\", \"selon\",\n\t\n\t\"seront\", \"ses\", \"si\", \"sien\", \"sienne\", \"siennes\", \"siens\", \"sinon\", \"s\noi\", \"soit\",\n\t\n\t\"son\", \"sont\", \"sous\", \"suivant\", \"sur\", \"ta\", \"te\", \"tes\", \"tien\", \"tie\nnne\", \"tiennes\",\n\t\n\t\"tiens\", \"toi\", \"ton\", \"tous\", \"tout\", \"toute\", \"toutes\", \"tu\", \"un\", \"u\nne\", \"va\", \"vers\",\n\t\n\t\"voici\", \"voil\u00c3\u00a0\", \"vos\", \"votre\", \"vous\", \"vu\", \"v\u00c3\u00b4tre\", \"v\u00c3\u00b4tres\", \"y\", \n\"\u00c3\u00a0\", \"\u00c3\u00a7a\", \"\u00c3\u00a8s\",\n\t\t\"\u00c3\u00a9t\u00c3\u00a9\", \"\u00c3\u00aatre\", \"\u00c3\u00b4\"\n\t}\n;\n\n\n\n\t/**\n\n\tContains the stopwords used with the StopFilter.\n\t */\n\tprivate Hashtable stoptable = new Hashtable();\n\t/**\n\tContains words that should be indexed but not stemmed.\n\t */\n\tprivate Hashtable excltable = new Hashtable();\n\n\n\n\t/**\n\n\tBuilds an analyzer.\n\t */\n\tpublic FrenchAnalyzer() \n{\n\t\tstoptable = StopFilter.makeStopTable( FRENCH_STOP_WORDS );\n\t}\n\n\n\n\t/**\n\n\tBuilds an analyzer with the given stop words.\n\t */\n\tpublic FrenchAnalyzer( String[] stopwords ) \n{\n\t\tstoptable = StopFilter.makeStopTable( stopwords );\n\t}\n\n\n\n\t/**\n\n\tBuilds an analyzer with the given stop words.\n\t */\n\tpublic FrenchAnalyzer( Hashtable stopwords ) \n{\n\t\tstoptable = stopwords;\n\t}\n\n\n\n\t/**\n\n\tBuilds an analyzer with the given stop words.\n\t */\n\tpublic FrenchAnalyzer( File stopwords ) \n{\n\t\tstoptable = WordlistLoader.getWordtable( stopwords );\n\t}\n\n\n\n\t/**\n\n\tBuilds an exclusionlist from an array of Strings.\n\t */\n\tpublic void setStemExclusionTable( String[] exclusionlist ) \n{\n\t\texcltable = StopFilter.makeStopTable( exclusionlist );\n\t}\n\t/**\n\tBuilds an exclusionlist from a Hashtable.\n\t */\n\tpublic void setStemExclusionTable( Hashtable exclusionlist ) \n{\n\t\texcltable = exclusionlist;\n\t}\n\t/**\n\tBuilds an exclusionlist from the words contained in the given file.\n\t */\n\tpublic void setStemExclusionTable( File exclusionlist ) \n{\n\t\texcltable = WordlistLoader.getWordtable( exclusionlist );\n\t}\n\n\n\n\t/**\n\n\tCreates a TokenStream which tokenizes all the text in the provided\nReader.\n\t *\n\t@return  A TokenStream build from a StandardTokenizer filtered with\n\tStandardFilter, StopFilter, FrenchStemFilter\nand LowerCaseFilter\n\t */\n\tpublic final TokenStream tokenStream( String fieldName, Reader reader ) \n{\n\t\t\n\t\tif (fieldName==null) throw new IllegalArgumentException\n(\"fieldName must not be null\");\n\t\tif (reader==null) throw new IllegalArgumentException(\"reader \nmust not be null\");\n\t\t\n\t\tTokenStream result = new StandardTokenizer( reader );\n\t\tresult = new StandardFilter( result );\n\t\tresult = new StopFilter( result, stoptable );\n\t\tresult = new FrenchStemFilter( result, excltable );\n\t\t// Convert to lowercase after stemming!\n\t\tresult = new LowerCaseFilter( result );\n\t\treturn result;\n\t}\n}",
    "attachments": {
        "ASF.LICENSE.NOT.GRANTED--patch2.txt": "https://issues.apache.org/jira/secure/attachment/12312288/ASF.LICENSE.NOT.GRANTED--patch2.txt",
        "ASF.LICENSE.NOT.GRANTED--TestFrenchAnalyzer.java": "https://issues.apache.org/jira/secure/attachment/12312290/ASF.LICENSE.NOT.GRANTED--TestFrenchAnalyzer.java",
        "ASF.LICENSE.NOT.GRANTED--FrenchAnalyzer.java": "https://issues.apache.org/jira/secure/attachment/12312289/ASF.LICENSE.NOT.GRANTED--FrenchAnalyzer.java"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2004-01-23T04:55:59+0000",
            "content": "thanks for the test!  the test fails for me though.  i have committed the test file and updated \nanalyzer to the sandbox though.  i look forward to a patch that fixes the test case  ",
            "author": "Erik Hatcher",
            "id": "comment-12321489"
        },
        {
            "date": "2004-01-23T16:36:53+0000",
            "content": "Looks like special French characters got transformed to something weird when \nyou copied the source to your local CVS. For me at least, they appear well in \nBugzilla. They are in the 0-255 range. The previous version of FrenchAnalyzer \nin CVS had them right.\n\nJF ",
            "author": "Jean-Fran\u00e7ois Halleux",
            "id": "comment-12321490"
        },
        {
            "date": "2004-01-23T17:24:48+0000",
            "content": "Could you please attach a patch file (cvs diff -u) or the entire file - as an attachment - so nothing \ncan get lost in copy/paste? ",
            "author": "Erik Hatcher",
            "id": "comment-12321491"
        },
        {
            "date": "2004-01-23T18:17:00+0000",
            "content": "Created an attachment (id=10072)\nThis attachement contains a patch to your latest commits. Here the test case runs fine. ",
            "author": "Jean-Fran\u00e7ois Halleux",
            "id": "comment-12321492"
        },
        {
            "date": "2004-01-23T20:15:12+0000",
            "content": "Sorry for my incompetence, but I cannot get the patch files to apply appropriately:\n\npatch -p0 < patch.txt \n(Stripping trailing CRs from patch.)\npatching file java/org/apache/lucene/analysis/fr/FrenchAnalyzer.java\nHunk #1 FAILED at 1.\n1 out of 1 hunk FAILED \u2013 saving rejects to file java/org/apache/lucene/analysis/fr/\nFrenchAnalyzer.java.rej\n(Stripping trailing CRs from patch.)\n\n\nCould you please attach the full files and I will simply replace my local copies and commit them?  \nThanks! ",
            "author": "Erik Hatcher",
            "id": "comment-12321493"
        },
        {
            "date": "2004-01-23T20:20:23+0000",
            "content": "Created an attachment (id=10073)\nthe French Analyzer file ",
            "author": "Jean-Fran\u00e7ois Halleux",
            "id": "comment-12321494"
        },
        {
            "date": "2004-01-23T20:20:58+0000",
            "content": "Created an attachment (id=10074)\nThe test case ",
            "author": "Jean-Fran\u00e7ois Halleux",
            "id": "comment-12321495"
        },
        {
            "date": "2004-01-23T20:50:59+0000",
            "content": "Test still failing for me after applying your latest patch.  The differences seem pretty dramatic - be \nsure to use CVS HEAD.  I've committed what you sent, but I'm getitng this failure:\n\ntest:\n    [junit] Testsuite: org.apache.lucene.analysis.fr.TestFrenchAnalyzer\n    [junit] Tests run: 1, Failures: 1, Errors: 0, Time elapsed: 0.487 sec\n\n    [junit] Testcase: testAnalyzer(org.apache.lucene.analysis.fr.TestFrenchAnalyzer):   FAILED\n    [junit] expected:<...?...> but was:<...?...>\n    [junit] junit.framework.ComparisonFailure: expected:<...?...> but was:<...?...>\n    [junit]     at \norg.apache.lucene.analysis.fr.TestFrenchAnalyzer.assertAnalyzesTo(TestFrenchAnalyzer.java:84)\n    [junit]     at \norg.apache.lucene.analysis.fr.TestFrenchAnalyzer.testAnalyzer(TestFrenchAnalyzer.java:141)\n    [junit]     at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    [junit]     at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n    [junit]     at \nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n ",
            "author": "Erik Hatcher",
            "id": "comment-12321496"
        },
        {
            "date": "2004-01-24T01:08:06+0000",
            "content": "Strange...\n\nJust did a full checkout of lucene and sandbox, run the test and it worked \nproperly. Could there be a problem with the locale? Anybody can try this?\n\nJeff ",
            "author": "Jean-Fran\u00e7ois Halleux",
            "id": "comment-12321497"
        },
        {
            "date": "2004-01-24T01:31:41+0000",
            "content": "well, if it works for you, i'll close this issue.  i'm far from being I18N savvy, so it is likely a locale \nissue on my end.... although surely the test case can be made to pass for me somehow? ",
            "author": "Erik Hatcher",
            "id": "comment-12321498"
        }
    ]
}