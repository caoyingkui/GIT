{
    "id": "LUCENE-7181",
    "title": "JapaneseTokenizer: Validate segmentation of User Dictionary entries on creation",
    "details": {
        "resolution": "Unresolved",
        "affect_versions": "None",
        "components": [],
        "labels": "",
        "fix_versions": [],
        "priority": "Major",
        "status": "Open",
        "type": "Improvement"
    },
    "description": "From the conversation on the dev list\n\nThe user dictionary in the JapaneseTokenizer allows users to customize how a stream is broken into tokens using a specific set of rules provided like: \nAABBBCC -> AA BBB CC\n\nIt does not allow users to change any of the token characters like:\n\n(1) AABBBCC -> DD BBB CC   (this will just tokenize to \"AA\", \"BBB\", \"CC\", seems to only care about positions) \nIt also doesn't let a character be part of more than one token, like:\n\n(2) AABBBCC -> AAB BBB BCC (this will throw an AIOOBE)\n\n..or make the output token bigger than the input text: \n\n(3) AA -> AAA (Also AIOOBE)\n\nCurrently there is no validation for those cases, case 1 doesn't fail but provide unexpected tokens. Cases 2 and 3 fail when the input text is analyzed. We should add validation to the UserDictionary creation.",
    "attachments": {
        "LUCENE-7181.patch": "https://issues.apache.org/jira/secure/attachment/12797208/LUCENE-7181.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "id": "comment-15227461",
            "author": "Tom\u00e1s Fern\u00e1ndez L\u00f6bbe",
            "date": "2016-04-06T00:50:09+0000",
            "content": "This patch may be over simplifying things (not sure if my validation won't break valid use cases), but at least to explain my idea. "
        },
        {
            "id": "comment-15232686",
            "author": "Tom\u00e1s Fern\u00e1ndez L\u00f6bbe",
            "date": "2016-04-08T18:37:32+0000",
            "content": "Christian Moen, any thoughts on the patch? "
        }
    ]
}