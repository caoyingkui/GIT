{
    "id": "LUCENE-6536",
    "title": "Migrate HDFSDirectory from solr to lucene-hadoop",
    "details": {
        "resolution": "Unresolved",
        "affect_versions": "None",
        "components": [],
        "labels": "",
        "fix_versions": [],
        "priority": "Major",
        "status": "Open",
        "type": "Improvement"
    },
    "description": "I am currently working on a search engine that is throughput orientated and works entirely in apache-spark.\n\nAs part of this, I need a directory implementation that can operate on HDFS directly. This got me thinking, can I take the one that was worked on so hard for solr hadoop.\n\nAs such I migrated the HDFS and blockcache directories out to a lucene-hadoop module.\n\nHaving done this work, I am not sure if it is actually a good change, it feels a bit messy, and I dont like how the Metrics class gets extended and abused.\n\nThoughts anyone",
    "attachments": {
        "LUCENE-6536.patch": "https://issues.apache.org/jira/secure/attachment/12738513/LUCENE-6536.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "id": "comment-14578658",
            "author": "Robert Muir",
            "date": "2015-06-09T10:01:04+0000",
            "content": "Questions:\n\n\tWhat will be done to deal with the bugginess of this thing? I see many reports of user corruption issues. By committing it, we take responsibility for this and it becomes \"our problem\". I don't want to see the code committed to lucene just for this reason.\n\tWhat will be done about the performance? I am not really sure the entire technique is viable.\n\n\n\nPersonally, I think if someone wants to do this, a better integration point is to make it a java 7 filesystem provider. That is really how such a filesystem should work anyway.  "
        },
        {
            "id": "comment-14578664",
            "author": "Uwe Schindler",
            "date": "2015-06-09T10:09:33+0000",
            "content": "Personally, I think if someone wants to do this, a better integration point is to make it a java 7 filesystem provider. That is really how such a filesystem should work anyway.\n\nI agree. This is how it should be. Once HDFS provides a Java 7 FileSystemProvider SPI (see, http://docs.oracle.com/javase/7/docs/api/java/nio/file/spi/FileSystemProvider.html), you just need to plug your HDFS JAR file into the classpath, then you would be able to create a standard FSDirectory (NIO, Simple, mmap) using Paths.get(URI) and you are done. No single line of Lucene code needed. I have no idea why Hadoop does not yet provide a FileSystem implementation for Java 7 (maybe because they are still on Java 6).\n\nI would suggest that you talk with the Hadoop people about doing this (including the block cache, which could me implemented as ByteBuffer like MappedByteBuffer off-heap, so it would automatically work with MMapDirectory in Lucene; I don't want to also take over responsibility for the block cache in Lucene). Or you start your own project implementing the FSProvider. "
        },
        {
            "id": "comment-14579210",
            "author": "Greg Bowyer",
            "date": "2015-06-09T16:57:48+0000",
            "content": "Questions:\nWhat will be done to deal with the bugginess of this thing? I see many reports of user corruption issues. By committing it, we take responsibility for this and it becomes \"our problem\". I don't want to see the code committed to lucene just for this reason.\n\nFix its bugs , joking aside is it the directory or the blockcache that is the source of most of the corruptions\n\nWhat will be done about the performance? I am not really sure the entire technique is viable.\nMy usecase is a bit odd, I have many small (2*HDFS block) indexes that get run over map jobs in hadoop. The performance I got last time I did this (with a dirty hack Directory that copied the files in and out of HDFS :S) was pretty good.\n\nIts a throughput orientated usage, I think if you tried to use this to back an online searcher you would have poor performance.\n\nPersonally, I think if someone wants to do this, a better integration point is to make it a java 7 filesystem provider. That is really how such a filesystem should work anyway.\n\nThat is awesome I didnt know such an SPI existed in java. I have found a few people that are trying to make a provider for hadoop.\n\nI also dont have the greatest love for this path, the more test manipulations I did the less and less it felt like a simple feature that should be in lucene. I might try to either strip out the block-cache from this patch, or use a HDFS filesystem SPI in java7. "
        },
        {
            "id": "comment-14579338",
            "author": "Mark Miller",
            "date": "2015-06-09T18:10:16+0000",
            "content": "is it the directory or the blockcache that is the source of most of the corruptions\n\nThere are two issues:\n\n\n\tThe write side of the block cache is buggy and can corrupt indexes - I don't think it provides any value anyway so it should just be cut out - currently it's turned off.\n\tThe hdfs directory doesn't do a classic fsync - to get this kind of behavior you have to write files to hdfs in some really slow mode I believe - it doesn't have an API compatible with how Lucene fsyncs.\n\n\n\nAll and all the block cache performance is good enough for a ton of use cases, but the overall approach and management of it is not great. The Apache Blur project has made a better version that is better for even more uses cases, but it requires Unsafe usage for direct memory access. "
        },
        {
            "id": "comment-14579356",
            "author": "Mark Miller",
            "date": "2015-06-09T18:24:42+0000",
            "content": "I have found a few people that are trying to make a provider for hadoop.\n\nCan you list what you have found?\n\nThis was some discussion / interest here: HADOOP-3518 - Want NIO.2 (JSR 203) file system provider for Hadoop FileSystem\n\nThat leads you to a test impl here: https://github.com/damiencarol/jsr203-hadoop "
        },
        {
            "id": "comment-14579388",
            "author": "Greg Bowyer",
            "date": "2015-06-09T18:46:36+0000",
            "content": "That leads you to a test impl here: https://github.com/damiencarol/jsr203-hadoop\n\nThese are the people that I am talking about. "
        },
        {
            "id": "comment-14579400",
            "author": "Greg Bowyer",
            "date": "2015-06-09T18:56:05+0000",
            "content": "Oh wow the blur store might be exactly what I am looking for. "
        }
    ]
}