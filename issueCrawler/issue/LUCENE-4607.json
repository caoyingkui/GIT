{
    "id": "LUCENE-4607",
    "title": "Add estimateDocCount to DocIdSetIterator",
    "details": {
        "components": [
            "core/search"
        ],
        "fix_versions": [
            "4.3",
            "6.0"
        ],
        "affect_versions": "4.0",
        "priority": "Major",
        "labels": "",
        "type": "Bug",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "this is essentially a spinnoff from LUCENE-4236\nWe currently have no way to make any decsision on how costly a DISI is neither when we apply filters nor when we build conjunctions in BQ. Yet we have most of the information already and can easily expose them via a cost API such that BS and FilteredQuery can apply optimizations on per segment basis.",
    "attachments": {
        "LUCENE-4607.patch": "https://issues.apache.org/jira/secure/attachment/12560185/LUCENE-4607.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2012-12-10T14:55:21+0000",
            "content": "here is a patch that adds #estimateDocCount to DISI. It still has some nocommits mainly related to BitSets and carnality but I this its fine as a start. I removed the TermConjunction specialization and changed the heuristic in FilteredQuery to use the estimated cost. ",
            "author": "Simon Willnauer",
            "id": "comment-13527970"
        },
        {
            "date": "2012-12-10T15:02:06+0000",
            "content": "Nice idea! At least the FilteredQuery code looks fine to me. I agree, the Bits interface and FixedBitSet has a costly cardinality (Bits does not have it at all...), so we should think about that. As far as I see it returns maxDoc as cost. ",
            "author": "Uwe Schindler",
            "id": "comment-13527982"
        },
        {
            "date": "2012-12-10T15:07:17+0000",
            "content": "One thing: estimatedDocCount is long, but docIds in Lucene are still int - this makes no sense, because the current scorer/disi interface can never return anything > Integer.MAX_VALUE, so the estimatedDocCount can never be 64 bits.\n\nWe should maybe rethink in the future to make docIds in Lucene longs, but until this has happened, we should not mix both datatypes in public APIs, this would cause confusion. ",
            "author": "Uwe Schindler",
            "id": "comment-13527986"
        },
        {
            "date": "2012-12-10T15:26:03+0000",
            "content": "When i did the cost estimate patch on LUCENE-4236, i chose a long too. but there it was trying to estimate the number of documents visited,\ne.g. the number of postings.\n\nso the formula for a conjunction would be min(subscorer cost) * #subscorers, and for a disjunction its just the sum of all the subscorer costs, and so on.\n\nI felt like for scoring purposes this is more useful than the number of documents, but thats just my opinion. ",
            "author": "Robert Muir",
            "id": "comment-13527995"
        },
        {
            "date": "2012-12-10T15:48:49+0000",
            "content": "I tend to agree with robert that using longs makes things a lot easier here too. We don't need to deal with int overflows. Maybe we should rename to estimateDocsVisited? ",
            "author": "Simon Willnauer",
            "id": "comment-13528013"
        },
        {
            "date": "2012-12-10T15:51:03+0000",
            "content": "The other idea (just for discussion) would be \"number of i/os\".\n\nSo for example, phrasequery's formula would likely use totalTermFreq rather than docFreq.\nThis would reflect the fact that its much more expensive than a conjunction. ",
            "author": "Robert Muir",
            "id": "comment-13528017"
        },
        {
            "date": "2012-12-10T16:08:25+0000",
            "content": "The other idea (just for discussion) would be \"number of i/os\".\nI like this, yet I think in that case we should go back to estimateCost rather than docId etc. since for a bitset this is way different that for a PhraseScorer. I agree it should be a unit of work that we estimate. ",
            "author": "Simon Willnauer",
            "id": "comment-13528032"
        },
        {
            "date": "2012-12-10T16:51:48+0000",
            "content": "I am fine with any solution. From my perspective as \"API policeman\" the mix of int and long in the same interface is not good. if estimateDocCount() returns long, also advance() must take and return long, docId() must return long, FixedBitSet must take long as size and finally numDocs and maxDoc must be long. ",
            "author": "Uwe Schindler",
            "id": "comment-13528059"
        },
        {
            "date": "2012-12-10T17:01:44+0000",
            "content": "Uwe the current discussion is about not measuring count of documents, but instead i/o operations.\n\nSo advance(), docId(), fixedBitset and so on are totally unrelated to that. ",
            "author": "Robert Muir",
            "id": "comment-13528063"
        },
        {
            "date": "2012-12-10T17:08:50+0000",
            "content": "Uwe the current discussion is about not measuring count of documents, but instead i/o operations.\n\nMan, I just wanted to make clear that the current patch and the current issue summary have this problem. ",
            "author": "Uwe Schindler",
            "id": "comment-13528069"
        },
        {
            "date": "2012-12-10T17:13:47+0000",
            "content": "ok: I agree if its a count of documents, the type should be consistent.\n\nBut as i suggested i dont think a count of documents is that great for how we will use this (picking conjunction leader, filtering heuristics, maybe minimum-should-match disjunction scoring, maybe cleanup exact phrase scorer / add its optimizations to sloppy phrase scorer, maybe more BS versus BS2 heuristics in BooleanWeight, etc etc) ",
            "author": "Robert Muir",
            "id": "comment-13528076"
        },
        {
            "date": "2013-03-14T16:35:48+0000",
            "content": "Patch updated to trunk (as Stefan needs this for LUCENE-4571).\n\nI carefully reviewed all these costs and also integrated it into spans. Though these queries (e.g. nearquery) dont yet use it, they should.\n\nThe only query i changed was to make ConjunctionTermScorer algorithm our ConjunctionScorer, sorting subscorers on cost (which is docFreq in the all terms case). ",
            "author": "Robert Muir",
            "id": "comment-13602402"
        },
        {
            "date": "2013-03-14T17:37:06+0000",
            "content": "+1 ",
            "author": "Michael McCandless",
            "id": "comment-13602475"
        },
        {
            "date": "2013-03-14T18:11:15+0000",
            "content": "Thanks! I will come up with a new prototype impl for LUCENE-4571 soon which will include and build upon this patch. ",
            "author": "Stefan Pohl",
            "id": "comment-13602522"
        },
        {
            "date": "2013-03-14T18:15:11+0000",
            "content": "The patch might be hard to apply due to the svn replace Stefan. I plan on doing final checks on it and committing it today.\n\nReally its silly lucene doesnt have this for our scorers already, since e.g. textbook IR formulas make use of this stuff. \n\nWe can open followup issues to improve the other scorers logic (FilteredQuery, SpanNearQuery, etc). I only did the obvious \nconjunction one so we get the logic of ConjunctionTermScorer across any arbitrary scorers.\n\nJust gimme a few hours, sorry for the delay  ",
            "author": "Robert Muir",
            "id": "comment-13602529"
        },
        {
            "date": "2013-03-14T18:32:00+0000",
            "content": "Thanks Robert, I was thinking about this the other day! Cool that you brought this back to life! +1 to the patch. I think you need to add a CHANGES.TXT entry still.\n\nsimon ",
            "author": "Simon Willnauer",
            "id": "comment-13602550"
        },
        {
            "date": "2013-03-14T18:37:43+0000",
            "content": "I'll put it in when committing...I always wait until then, otherwise its just asking for conflicts if you ever merge up the patch  ",
            "author": "Robert Muir",
            "id": "comment-13602553"
        },
        {
            "date": "2013-03-14T21:04:22+0000",
            "content": "[trunk commit] Robert Muir\nhttp://svn.apache.org/viewvc?view=revision&revision=1456670\n\nLUCENE-4607: add DISI/Spans.cost ",
            "author": "Commit Tag Bot",
            "id": "comment-13602743"
        },
        {
            "date": "2013-03-14T21:26:16+0000",
            "content": "[branch_4x commit] Robert Muir\nhttp://svn.apache.org/viewvc?view=revision&revision=1456686\n\nLUCENE-4607: add DISI/Spans.cost ",
            "author": "Commit Tag Bot",
            "id": "comment-13602780"
        },
        {
            "date": "2013-05-10T10:33:23+0000",
            "content": "Closed after release. ",
            "author": "Uwe Schindler",
            "id": "comment-13653911"
        }
    ]
}