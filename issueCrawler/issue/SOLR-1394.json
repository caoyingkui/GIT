{
    "id": "SOLR-1394",
    "title": "HTML stripper is splitting tokens",
    "details": {
        "affect_versions": "1.4",
        "status": "Closed",
        "fix_versions": [
            "1.4"
        ],
        "components": [
            "Schema and Analysis"
        ],
        "type": "Bug",
        "priority": "Major",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "The Solr HTML stripper is replacing any removed HTML with whitespace. This is to keep offsets correct for highlighting.\n\nHowever, as was already pointed out in SOLR-42, this means that any token containing an HTML entity will be split into several tokens. That makes the HTML stripper completely unreliable for international text (and any text is potentially interantional).\n\nThe current code is actually deficient for BOTH highlighting and indexing, where the previous incarnation (that did not insert spaces) only had problems with highlighting.\n\nThe only workaround is to not use entities at all, which is impossible in some situations and inconvenient in most situations. If the client is required to transform entities before handing it to Solr, it might as well be required to also strip tags, and then the HTML stripper would not be needed at all.\n\nToday, we have a better solution that can be used: offset correction. We can then avoid inserting extra whitespace, but still get correct offsets. The attached patch implements just that.",
    "attachments": {
        "SOLR-1394.patch": "https://issues.apache.org/jira/secure/attachment/12418075/SOLR-1394.patch",
        "hex-entity.patch": "https://issues.apache.org/jira/secure/attachment/12422409/hex-entity.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Anders Melchiorsen",
            "id": "comment-12749153",
            "date": "2009-08-29T14:31:59+0000",
            "content": "Proof-of-concept fixes. I don't expect them to be perfect.\n\nThere is one test that still breaks. I think the test does not make sense with my changes, but I did not remove it.\n\nAlso, the new functionality (offset correction) is not tested. I don't know how to do it. "
        },
        {
            "author": "Anders Melchiorsen",
            "id": "comment-12749193",
            "date": "2009-08-29T22:18:25+0000",
            "content": "Right version of patch file. "
        },
        {
            "author": "Jason Rutherglen",
            "id": "comment-12753911",
            "date": "2009-09-11T00:09:26+0000",
            "content": "I'm also seeing this problem and will try out the patch (after a number of other issues are fixed!) "
        },
        {
            "author": "Jason Rutherglen",
            "id": "comment-12753913",
            "date": "2009-09-11T00:13:28+0000",
            "content": "Here's the exception:\n\nCaused by: java.io.IOException: Mark invalid\n\tat java.io.BufferedReader.reset(BufferedReader.java:485)\n\tat org.apache.solr.analysis.HTMLStripReader.restoreState(HTMLStripReader.java:171)\n\tat org.apache.solr.analysis.HTMLStripReader.read(HTMLStripReader.java:728)\n\tat org.apache.solr.analysis.HTMLStripReader.read(HTMLStripReader.java:742)\n\tat org.apache.lucene.analysis.CharReader.read(CharReader.java:51)\n\tat org.apache.lucene.analysis.standard.StandardTokenizerImpl.zzRefill(StandardTokenizerImpl.java:451)\n\tat org.apache.lucene.analysis.standard.StandardTokenizerImpl.getNextToken(StandardTokenizerImpl.java:637)\n\tat org.apache.lucene.analysis.standard.StandardTokenizer.next(StandardTokenizer.java:198)\n\tat org.apache.lucene.analysis.standard.StandardFilter.next(StandardFilter.java:84)\n\tat org.apache.lucene.analysis.LowerCaseFilter.next(LowerCaseFilter.java:53)\n\tat org.apache.solr.analysis.EnglishPorterFilter.next(EnglishPorterFilterFactory.java:108)\n\tat org.apache.lucene.analysis.StopFilter.next(StopFilter.java:245)\n\tat org.apache.lucene.index.DocInverterPerField.processFields(DocInverterPerField.java:162)\n "
        },
        {
            "author": "Anders Melchiorsen",
            "id": "comment-12754032",
            "date": "2009-09-11T07:33:15+0000",
            "content": "In which situation do you get this exception? "
        },
        {
            "author": "Jason Rutherglen",
            "id": "comment-12754215",
            "date": "2009-09-11T17:02:30+0000",
            "content": "In which situation do you get this exception? \n\nWe need to log the HTML.  I'll post it when we implement the logging. "
        },
        {
            "author": "Anders Melchiorsen",
            "id": "comment-12755421",
            "date": "2009-09-15T08:22:27+0000",
            "content": "Jason, did you get that exception with (and not without) my patch? You said that you had other problems as well, so I just want to make sure that it is a problem with the patch ... "
        },
        {
            "author": "Jason Rutherglen",
            "id": "comment-12755600",
            "date": "2009-09-15T17:40:16+0000",
            "content": "Anders, The error occurs with the existing HTML stripper code in Solr's trunk. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12757676",
            "date": "2009-09-19T16:31:54+0000",
            "content": "What's clear is that the html stripper still has problems - less clear to me is if this patch as it currently exists is better than what's in trunk.... if people think it is, we could commit it quickly for 1.4 "
        },
        {
            "author": "Anders Melchiorsen",
            "id": "comment-12757686",
            "date": "2009-09-19T18:39:05+0000",
            "content": "To me (the author), things are much better with the patch, and I have seen no ill effects. The exception that Jason reported happens without the patch.\n\nMy problem is that I cannot really vouch for the patch, as I have no previous experience with the Solr code. So, it would be really nice if someone with the experience could take fifteen minutes to review the three tiny modifications.\n\nWhen replacing read() with next() in one of the patches, I noted that I was not sure why it worked better. I have later figured out that read() is the external interface, so it should (probably?) not be used internally by the stripper. "
        },
        {
            "author": "Jason Rutherglen",
            "id": "comment-12758519",
            "date": "2009-09-23T00:54:54+0000",
            "content": "Anders, \n\nWe're seeing the error again, we're going to try this patch and\nHTMLStripReader and we'll see what happens. Here's the latest\nstacktrace, which is pretty much the same as the last one:\n\n\nSEVERE: java.io.IOException: Mark invalid\n\tat java.io.BufferedReader.reset(BufferedReader.java:485)\n\tat org.apache.lucene.analysis.CharReader.reset(CharReader.java:63)\n\tat org.apache.solr.analysis.HTMLStripCharFilter.restoreState(HTMLStripCharFilter.java:170)\n\tat org.apache.solr.analysis.HTMLStripCharFilter.read(HTMLStripCharFilter.java:727)\n\tat org.apache.solr.analysis.HTMLStripCharFilter.read(HTMLStripCharFilter.java:741)\n\tat org.apache.lucene.analysis.standard.StandardTokenizerImpl.zzRefill(StandardTokenizerImpl.java:451\n)\n\tat org.apache.lucene.analysis.standard.StandardTokenizerImpl.getNextToken(StandardTokenizerImpl.java\n:637)\n\tat org.apache.lucene.analysis.standard.StandardTokenizer.incrementToken(StandardTokenizer.java:174)\n\tat org.apache.lucene.analysis.standard.StandardFilter.incrementToken(StandardFilter.java:50)\n\tat org.apache.lucene.analysis.LowerCaseFilter.incrementToken(LowerCaseFilter.java:38)\n\tat org.apache.solr.analysis.SnowballPorterFilter.incrementToken(SnowballPorterFilterFactory.java:116\n)\n\tat org.apache.lucene.analysis.TokenStream.next(TokenStream.java:401)\n\tat org.apache.solr.analysis.BufferedTokenStream.read(BufferedTokenStream.java:94)\n\tat org.apache.solr.analysis.BufferedTokenStream.next(BufferedTokenStream.java:80)\n\tat org.apache.lucene.analysis.TokenStream.incrementToken(TokenStream.java:316)\n\tat org.apache.lucene.analysis.StopFilter.incrementToken(StopFilter.java:224)\n\tat org.apache.lucene.index.DocInverterPerField.processFields(DocInverterPerField.java:138)\n\tat org.apache.lucene.index.DocFieldProcessorPerThread.processDocument(DocFieldProcessorPerThread.jav\na:244)\n\tat org.apache.lucene.index.DocumentsWriter.updateDocument(DocumentsWriter.java:772)\n\tat org.apache.lucene.index.DocumentsWriter.updateDocument(DocumentsWriter.java:755)\n\tat org.apache.lucene.index.IndexWriter.updateDocument(IndexWriter.java:2611)\n\tat org.apache.lucene.index.IndexWriter.updateDocument(IndexWriter.java:2583)\n\tat org.apache.solr.update.DirectUpdateHandler2.addDoc(DirectUpdateHandler2.java:241)\n\tat org.apache.solr.update.processor.RunUpdateProcessor.processAdd(RunUpdateProcessorFactory.java:61)\n\tat org.apache.solr.handler.XMLLoader.processUpdate(XMLLoader.java:140)\n\n "
        },
        {
            "author": "Anders Melchiorsen",
            "id": "comment-12764768",
            "date": "2009-10-12T18:00:06+0000",
            "content": "A reworked patch that should be easier to review.\n\nNow also includes a few new tests to show the problems that this patch is fixing. "
        },
        {
            "author": "Anders Melchiorsen",
            "id": "comment-12765490",
            "date": "2009-10-14T09:44:37+0000",
            "content": "Clarifying the description, the original report was just a pasted e-mail. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12766727",
            "date": "2009-10-16T21:58:35+0000",
            "content": "I've been testing this with a bunch of different HTML, and I don't see any places where this is worse, and it prevents splitting of tokens when it shouldn't.\nGiven that the splitting is clearly a bug, and that changes to this filter won't affect the rest of Solr, I plan on committing this shortly.\n\nThings still aren't perfect as far as offsets and highlighting, but this patch makes it no worse.\n\nI modified the solr.xml document to escape the '&'  and then added the strip char filter to the text field.\nThe query was h\u00e9llo OR hello OR unicode\nBefore this patch:  Good <em>unicode</em> support: h\u00e9llo <em>(hell</em>o with an accent over the e)\nAfter this patch: Good <em>unicode</em> support: <em>h\u00e9ll</em>o <em>(hell</em>o with \u00e9 accent over the e) "
        },
        {
            "author": "Anders Melchiorsen",
            "id": "comment-12766735",
            "date": "2009-10-16T22:17:36+0000",
            "content": "Thanks, that sounds great.\n\nThere is an existing off-by-one error in the numWhitespace calculation with hexadecimal numeric entities.\n\nI noticed that while reworking the patch, but did not bother to report it in here because I was annoyed from being ignored. Now you got me in a better mood, so I can fix that error if you like? "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12766738",
            "date": "2009-10-16T22:22:14+0000",
            "content": "Committed.  Thanks Anders! "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12766739",
            "date": "2009-10-16T22:25:12+0000",
            "content": "Now you got me in a better mood, so I can fix that error if you like?\n\nDidn't see your message before the commit - yes, a patch would be great! Could possibly make it into 1.4 still if you're quick  "
        },
        {
            "author": "Anders Melchiorsen",
            "id": "comment-12766744",
            "date": "2009-10-16T22:27:32+0000",
            "content": "I did not even test that this patch compiles, but it should show what I had in mind.\n\nI will not have time to work on this during the weekend. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12766952",
            "date": "2009-10-17T19:56:29+0000",
            "content": "It works!  I added some tests, and committed.  Thanks again! "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12775860",
            "date": "2009-11-10T15:52:14+0000",
            "content": "Bulk close for Solr 1.4 "
        },
        {
            "author": "Cassandra Targett",
            "id": "comment-16623847",
            "date": "2018-09-21T16:29:22+0000",
            "content": "I accidentally assigned this to myself (keyboard shortcuts!). I can't find in the issue history who this used to belong to, but it's probably so old now it doesn't really matter, so I changed it to Unassigned. "
        },
        {
            "author": "Mike Sokolov",
            "id": "comment-16624552",
            "date": "2018-09-22T07:57:24+0000",
            "content": "I'm pretty sure this issue is no longer valid. I don't use this code actively recently, so I can't speak with great authority, but I did look at some related issues, and it seems that quite a while ago LUCENE-3690 made major improvements in handling of entities, so perhaps this can simply be closed as fixed? "
        }
    ]
}