{
    "id": "SOLR-3723",
    "title": "Improve OOTB behavior: English word-splitting should default to autoGeneratePhraseQueries=true",
    "details": {
        "affect_versions": "3.4,                                            3.5,                                            3.6,                                            3.6.1,                                            4.0-ALPHA",
        "status": "Open",
        "fix_versions": [],
        "components": [
            "Schema and Analysis"
        ],
        "type": "Improvement",
        "priority": "Major",
        "labels": "",
        "resolution": "Unresolved"
    },
    "description": "Digging through the Jira and revision history, I discovered that back at the end of May 2011, a change was made to Solr that fairly significantly degrades the OOTB behavior for English Solr queries, namely for word-splitting of terms with embedded punctuation, so that they end up, by default, doing the OR of the sub-terms, rather than doing the obvious phrase query of the sub-terms.\n\nJust a couple of examples:\n\n1. CD-ROM => CD OR ROM rather than \u201cCD ROM\u201d\n\n2. 1,000 => 1 OR 000 rather than \u201c1 000\u201d (when using the WordDelimiterFilter innocently added to text_general or text_en)\n\n3. out-of-the-box => out OR of OR the OR box rather than \u201cout of the box\u201d\n\n4. 3.6 => 3 OR 6 rather than \"3 6\" (when using WordDelimiterFilter innocently added to text_general or text_en)\n\n5. docid-001 => docid OR 001 rather than \"DOCID 001\"\n\nAll of those queries will give surprising and unexpected results.\n\nNote: The hyphen issue is present in StandardTokenizer, even if WDF is not used. Side note: The full behavior of StandardTokenizer should be more fully documented on the Analyzers wiki.\n\nBack to the history of the change, there was a lot of lively discussion on SOLR-2015 - add a config hook for autoGeneratePhraseQueries.\n\nAnd the actual change to default to the behavior described above was SOLR-2519 - improve defaults for text_* field types.\n\n(Consider the entire discussion in those two issues incorporated here for reference. Anyone wishing to participate in discussion on this issue would be well-advised to study those two issues first.)\n\nI gather that the original motivation was for non-European languages, and that even some European languages might search better without auto-phrase generation, but the decision to default English terms to NOT automatically generate phrase queries and to generate OR queries instead is rather surprising and unexpected and outright undesirable, as my examples above show.\n\nI had been aware of the behavior for quite some time, but I had thought it was simply a lingering bug so I paid little attention to it, until I stumbled across this autoGeneratePhraseQueries \"feature\" while looking at the query parser code. I can understand the need to disable automatic phrase queries for SOME languages, but to disable it by default for English seems rather bizarre, as my simple use cases above show.\n\nEven if no action is taken on this Jira, I feel that it is important that there be a wider awareness of the significant and unexpected impact from SOLR-2519, and that what had seemed like buggy behavior was done intentionally.\n\nUnless there has been a change of heart since SOLR-2015/2519, I guess we are stuck with the default TextField behavior, but at least we could improve the example schema in several ways:\n\n1. The English text field types should have autoGeneratePhraseQueries=true. If a user innocently adds a word delimiter to text_en, for example, they need to know that autoGeneratePhraseQueries=true is needed. Better to preempt that confusion and put the attribute in now. In fact, hyphenated terms fail as I have noted above, so the addition is needed even if a WDF is not added.\n\n2. Add commentary about the impact of autoGeneratePhraseQueries=true/false - in terms of use case examples, as above. Specifically note the ones that will break with if the feature is disabled.\n\nAnother, more controversial change will be:\n\n3. Change text_general to autoGeneratePhraseQueries=true so that English will be treated reasonably by default. I suspect that most European languages will be at least \"okay\". A comment will note that this field attribute should be removed or set to false for non-whitespace languages, or that an alternative field type should be used. I suspect that the first thing any non-whitespace language application will want to do is pick the text field type that has analysis that makes the most sense for them, so I see no need to mess up English for no good reason.\n\nMake no mistake, #3 is the primary and only real goal of this OOTB \nimprovement. Maybe \"text_general\" could be kept as is for reference as the purported \"general\" text field type (except that it doesn't work well for English, as shown above), and maybe there should be a \"text_default\" that I would propose should be a literal copy of text_en with commentary to direct users to the other choices for language.\n\nI would note that text_ja already has autoGeneratePhraseQueries=false, so I'm not sure why the default in the TextField code had to be changed to false. Any languages for which automatic phrase query generation is problematic should be attributed similarly. But, now that it is wired into the schema defaults, we may be stuck with it.\n\nI was rather surprised that SOLR-2519 actually changed the default in TextField rather than simply set the attribute as appropriate for the various text field types.\n\nThere are probably also a couple of places in the wikis where the surprising behavior should be noted. There is literally no wiki documentation for this important feature. There are only two references to autoGeneratePhraseQueries, with no discussion of exactly what this feature does or what the downside is if it is disabled.\n\nIn the past, there was no need to document the treatment of embedded word delimiters (well, okay, the poor handling for non-whitespace languages SHOULD have been documented), but now there is no documentation of the degradation of what was a default and implicit feature that a lot of people assume should be automatic.\n\nAnd, I would propose that the 4.0 CHANGES.TXT very clearly highlight the kinds of use cases that unsuspecting users may not realize were BROKEN by the commit of SOLR-2519 that is masked under the innocent phrasing of \"improve defaults for text_* field types\". How many users seriously understood that a query with embedded dashes and commas behave differently as a result of that change?\n\nI am contemplating whether to suggest that the WordDelimiterFilter should also be part of the default text field type. Right now, it is hidden off in text_en_splitting.\n\nI think stemming should also be part of the default English field type. The whole point of the \"example\" schema is to show-off the best of Lucene/Solr.\n\nI'm not quite ready to propose that English be the default language supported by the example schema, but I am 99.999% certain that we should focus it on European, Roman, Latin languages. Non-European languages are indeed important, and should probably have their own schema. text_general was a good idea, but in hindsight it appears to have not been such a great idea in light of the word-splitting problems I have highlighted above.\n\nMaybe I would propose that text_general be left as is, but that we add text_default which is a copy of text_en (which would have WDF and stemming added) and fields use text_default as their type. That way, it would be clear what is going on and users could sensibly see what needs to happen if they wish to switch default languages.\n\nAfter discussion settles, a revised final proposal will be composed. And some specific and non-controversial issues may be split into separate Jira issues.",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "author": "Yonik Seeley",
            "id": "comment-13431808",
            "date": "2012-08-09T13:52:06+0000",
            "content": "Note: The hyphen issue is present in StandardTokenizer, even if WDF is not used.\n\nOuch!  I hadn't realized that.\nI just verified that with our stock setup, a query for F-22 finds anything with an F or with a 22 in the document.  I agree this is bad default behavior. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13431809",
            "date": "2012-08-09T13:54:07+0000",
            "content": "I am strongly -1 against breaking tons of languages for some sketchy \"optimization\" of english.\n\nIf people want to turn on this optimization, they can turn it on for their field just fine. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13431816",
            "date": "2012-08-09T13:59:35+0000",
            "content": "And even worse, a search for something like A-Team, A-Rod will find all documents with an \"a\", which is most of them if any largish text field is searched. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13431817",
            "date": "2012-08-09T14:01:38+0000",
            "content": "I am strongly -1 against breaking tons of languages for some sketchy \"optimization\" of english.\n\nIt's certainly not just for english.\nIt also doesn't seem sketchy at all - it seems to make perfect sense. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13431834",
            "date": "2012-08-09T14:26:33+0000",
            "content": "We can go thru this over and over, but here are my reasons I am against it:\n\n\tthis breaks indexing of many languages completely for a general field. Completely broken.\n  This is the main reason for my veto.\n\tthis screws up ranking for languages like english, because it skews the term importance of\n  these \"generated phrases\" (since their IDF is this multiplication of the IDF of their terms).\n  Generating phrases like this automatically does more harm than good.\n\tthis has bad performance characteristics for real collections which can be a surprise\n  to the user since nobody entered a phrase query, e.g. http://www.hathitrust.org/blogs/large-scale-search/tuning-search-performance\n\tonce turned on, the user has no way to say \"i dont want a phrase query\". However with it off,\n  the user can always tighten their search with single quotes.\n\tits dangerous to apply this to any field that omits positions etc, especially in combination\n  with the above, as it will just throw an exception: and with many analysis chains this is\n  a rareish case anyway, someone might not discover this until production.\n\tkeeping this option at all keeps whitespace tied into the query parser even more, when\n  in fact we should be going the other direction and fixing bugs like LUCENE-2605, so that\n  synonyms, n-grams, shingles, vietnamese, etc actually work at query time.\n\n "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13431861",
            "date": "2012-08-09T14:46:48+0000",
            "content": "this breaks indexing of many languages completely for a general field. Completely broken.\n\nWe don't seem to have a field type that works well for all languages.  Having a type that worked well for english / many western languages would seem to be preferable since that is what all of our documentation, examples on the wiki, etc use.\n\nonce turned on, the user has no way to say \"i dont want a phrase query\". However with it off,\nthe user can always tighten their search with single quotes.\n\nIf we're going into what ways the user can manipulate the query, then the user could always replace their dashes with spaces to avoid joining the terms.\n\nits dangerous to apply this to any field that omits positions etc\n\nImplementation detail.  We could easily handle this.\n\nkeeping this option at all keeps whitespace tied into the query parser even more\n\nI disagree.  I've long advocated that the tokenstream should be able to handle this... i.e. a query of foo A-team bar passed to the tokenstream in one go sould be able to produce foo OR \"a team\" OR bar.  This does not hurt the ability to \"go in the other direction\".\n\nautoGeneratePhraseQueries (which I consider a misleadingly-named parameter) was the default through lucene 3.0.  I continue to disagree with this change that was made.  Unfortunately I didn't realize that the standard tokenizer does some of the same splitting that word delimiter filter does, and so it's more broken than I originally realized. "
        },
        {
            "author": "Jack Krupansky",
            "id": "comment-13431879",
            "date": "2012-08-09T14:56:27+0000",
            "content": "I intend to pore over the StandardTokenizer code to deduce what rules it really uses and to document them. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13431881",
            "date": "2012-08-09T15:00:49+0000",
            "content": "\nWe don't seem to have a field type that works well for all languages. Having a type that worked well for english / many western languages would seem to be preferable since that is what all of our documentation, examples on the wiki, etc use.\n\nI really disagree with this. text_general is going to work for most any language (minus a few exceptions like Thai): or if you have a mix across them.\n\nSure its not going to be optimized to any specific one (e.g. forms unigrams for chinese and japanese, doesn't decompound german, whatever),\nbut its going to work just fine and you will have a reasonable full text search.\n\nI don't think english or western languages should have higher importance than languages such as chinese: especially\nwhen the tradeoff is some sketchy optimization for one language versus breaking full-text search entirely for other languages. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13431888",
            "date": "2012-08-09T15:11:43+0000",
            "content": "I don't think english or western languages should have higher importance than languages such as chinese:\n\nThey already do in all of our examples in all our documentation is in english and the fact that the discussion forums are english.\nThey don't really have higher \"importance\" in the core code of course (skipping the fact that our comments are in english too) - we're only talking about defaults here, not capabilities.\n\nIf someone wants to create a chinese or thai solr example, that's great - they can configure the best fieldtype for that language.\n\nwhen the tradeoff is some sketchy optimization\n\nI don't know why you keep calling it sketchy.  I've provided very specific, and relatively common examples where it's pretty catastrophic.\nSearch for A-team, sort by date.  You get complete garbage (i.e. any document with an \"a\" in it, sorted by date).\n\n\n "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13431895",
            "date": "2012-08-09T15:19:38+0000",
            "content": "\nI've provided very specific, and relatively common examples where it's pretty catastrophic.\n\nI've also provided those same examples where generating phrase queries would break entire languages. \ntext_general is supposed to be for general text.\n\nSo I don't really care what its doing with A-team if chinese doesn't work. "
        },
        {
            "author": "Michael McCandless",
            "id": "comment-13431904",
            "date": "2012-08-09T15:31:29+0000",
            "content": "Jack have you tried the English-specific field types (text_en_*)?  Are there problems with those...?\n\nI think we should not change text_general: it should have OK defaults for all languages.\n\nWe should add other language-specific field types over time (like we have already done for English)... "
        },
        {
            "author": "Jack Krupansky",
            "id": "comment-13431919",
            "date": "2012-08-09T15:48:34+0000",
            "content": "Mike, the English-specific field types that have autoGeneratePhraseQueries=true do in fact work as advertised. But the text_en field type has the problem for hyphens due to the behavior of StandardTokenizer. And, as I noted in the main description, if you innocently add a WDF to text_en or text_general, the problem appears with those field types with embedded dots and commas. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13431930",
            "date": "2012-08-09T15:59:38+0000",
            "content": "Jack have you tried the English-specific field types (text_en_*)? Are there problems with those...?\n\nYep, Jack already pointed out that the problem also exists with text_en.\n\nMore comments on this issue in this email thread:\nhttp://markmail.org/message/n7hllsiistmcrrm4 "
        },
        {
            "author": "Michael McCandless",
            "id": "comment-13431979",
            "date": "2012-08-09T17:06:08+0000",
            "content": "I think apps that want this behaviour should simply use\ntext_en_splitting.  That's why we have that field type.\n\nI don't think we should turn on auto-phrase for text_en (and\ndefinitely not for text_general, breaking entire languages): there are\nserious downsides (as Robert enumerated).\n\nI was curious how ElasticSearch handles text by default, so I indexed\ntext \u5317\u4eac\u533b\u79d1\u5927\u5b66 and then searched for \u5317\u4eac\u5927\u5b66and it does match:\ngood (ie matching text_general).\n\nI also indexed fly-fishing and confirmed fly, fishing and fly-fishing\nall match (like text_general).\n\nYou can of course go and customize your analysis chain in ElasticSearch\n(http://www.elasticsearch.org/guide/reference/index-modules/analysis ), and\nset options like auto_generate_phrase_queries for the query parser:\nhttp://www.elasticsearch.org/guide/reference/query-dsl/query-string-query.html \nif you want to get the same behavior as text_en_splitting. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13432003",
            "date": "2012-08-09T17:24:22+0000",
            "content": "I think apps that want this behaviour should simply use\ntext_en_splitting. That's why we have that field type.\n\nWe could also create a text_en_pureOr (or whatever name fits better) field type that always interpreted a-b as (a OR B) and then apps that want that behavior could use that.\n\nBut we're also talking about what the best default for english (i.e. text_en) in general is.\nThe defaults for \"text\" in general are a different question.  Looking at all of the arguments so far, my judgement is still that for text_en, interpreting a-team as \"a team\" is far preferable to (a OR team)  "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-13432126",
            "date": "2012-08-09T20:35:46+0000",
            "content": "I am strong -1 for changing auto-phrase text_general, but it's fine for pure english (text_en) having it, because this is common usage. "
        },
        {
            "author": "Jack Krupansky",
            "id": "comment-13432128",
            "date": "2012-08-09T20:41:19+0000",
            "content": "Uwe, by \"it's fine for pure english text\" did you mean that text_general's current behavior is fine for English or that you would be supportive of changing text_en as Yonik suggests? "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-13432149",
            "date": "2012-08-09T21:03:00+0000",
            "content": "I edited 2 times and to be sure I will vote to close this completely stupid issue:\n\n-1, I repeat: -1 for having auto-phrases on any language unspecific general field type\n\nBUT:\nI am fine with either auto-phrase or not on \"text_en\" or \"text_de\" "
        },
        {
            "author": "Jack Krupansky",
            "id": "comment-13432173",
            "date": "2012-08-09T21:29:17+0000",
            "content": "My current leaning is a strawman proposal as follows:\n\n1. Leave text_general as is since it has a specific purpose: cross-language generality, even if it does show English in a less than optimum light.\n2. \"Fix\" text_en to have autoGeneratePhraseQueries=true. Maybe the same fix for some other European langages, TBD, as well.\n2a. Add word-splitting (WDF), Porter stemming and a populated stopwords_en.txt to the new text_en type to enhance OOBE to show Lucene/Solr in a better light. Possibly add a commented-out Edge-N-Gram filter as well - maybe even include by default.\n3. Add a new text_default type which curent example schema fields will use instead of text_general. Now the controversial part: text_default will be a copy of the new text_en but with clear comments advising users to switch it to a copy of text_general for non-whitespace languages, and maybe specific types if they are known.\n\nAn alternate proposal for #3 is simply to modify the existing example schema fields to directly reference text_en, also with clear comments directing users to change text_en references to text_general (or other language-specific types) if English is not the preferred language. Personally, I prefer the text_default to emphasize that this is just the default and users are expected to consider whether default is best for them.\n\nThis is by no means a final proposal. More revision is expected. "
        },
        {
            "author": "Jack Krupansky",
            "id": "comment-13432214",
            "date": "2012-08-09T22:05:26+0000",
            "content": "Here is mini-report on my journey into StandardTokenizer land (so far). The \"rules\" for tokens for StandardTokenizer are roughly derived from the character classes/properties defined for Unicode: Unicode Text Segmentation Property Data:\nhttp://www.unicode.org/Public/UNIDATA/auxiliary/WordBreakProperty.txt\n\nActually, ST has a bunch of JFlex rules that determine whether the token is a numeric or alphanumeric token, based on those Unicode properties.\n\nA numeric token is a sequence of numeric characters, as defined by the Unicode \"Number\" property, which covers ASCII 0-9 as well as a lot of oddball Unicode characters, with optional embedded \"numeric punctuation\" (my term), which are characters which have either the \"MidNum\", \"MidNumLet\", or \"ExtendNumLet\" Unicode properties. Besides a lot of oddball Unicode characters, the MidNum characters are ASCII comma and semicolon. Besides a lot of oddball Unicode characters, the MidNumLet characters are ASCII period and apostrophe. The ExtendNumLet characters includes the ASCII underscore.\n\nAn alphanumeric token is a sequence of letters, numeric tokens (yeah, full, complete numeric tokens with embedded numeric punctuation), and \"letter punctuation\", with at least one letter (which doesn't have to be at the beginning of the token). \"Letter punctuation\" are characters with either the \"MidLetter\", \"MidNumLet\", or \"ExtendNumLet\" Unicode properties. MidNumLet, as above, includes period and apostrophe, and ExtendNumLet, as above, includes underscore. Besides a lot of oddball Unicode characters, the MidLetter characters are the ASCII colon and the Middle Dot (hex B7.) That's it. No hyphen! Or Slash that might be used in dates.\n\nIn fact, hyphen does not appear in any of the Unicode \"word break\" character property lists.\n\nAny other punctuation than listed above will result in a word break.\n\nLeading and trailing punctuation is ignored.\n\nComma can occur in alphanumeric tokens, but only between digits.\n\nAnd to be clear, underscore can be used in both numeric and alphanumeric tokens, and to join them.\n\nSo, this is why fly-fishing is split into two words, why dates such as 8/9/2012 are split into three words, but numbers such as 1,00,000.34.56 are preserved as one word. And why a0,1b is a single token by a0,b1 is two tokens. "
        },
        {
            "author": "Steve Rowe",
            "id": "comment-13432223",
            "date": "2012-08-09T22:16:53+0000",
            "content": "Jack, I think what you're looking for is the oddball Word Boundary Rules from UAX#29 Unicode Text Segmentation, referenced in the StandardTokenizer class javadoc "
        },
        {
            "author": "Jack Krupansky",
            "id": "comment-13432244",
            "date": "2012-08-09T22:36:08+0000",
            "content": "Steven, yes, that's how I found the work break properties. "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13505873",
            "date": "2012-11-28T20:31:08+0000",
            "content": "Background discussion...\n\nhttp://mail-archives.apache.org/mod_mbox/lucene-dev/201208.mbox/%3C16F342495A7D49F8819B1611616FCBF4@JackKrupansky%3E\nhttp://mail-archives.apache.org/mod_mbox/lucene-dev/201208.mbox/%3CCAOdYfZXD155fJvFC7Dzriw3A55msnzoOja0H33ioTYkB5-DFXg@mail.gmail.com%3E\nhttp://mail-archives.apache.org/mod_mbox/lucene-dev/201208.mbox/%3Calpine.DEB.2.02.1208082025190.745@frisbee%3E\nhttp://mail-archives.apache.org/mod_mbox/lucene-dev/201208.mbox/%3CCAOdYfZUsmXz-ec5qis0=wgoyCf4Pk2ZRsHn1jbTJESzCmTOsqw@mail.gmail.com%3E\nhttp://mail-archives.apache.org/mod_mbox/lucene-dev/201208.mbox/%3Calpine.DEB.2.02.1208090807280.9170@frisbee%3E\nhttp://mail-archives.apache.org/mod_mbox/lucene-dev/201208.mbox/%3CCAL8PwkYU3-1fXCD8kKiZQWD-wYhJUOA5wXdMwQi-wdUBLjkjUg@mail.gmail.com%3E\nhttp://mail-archives.apache.org/mod_mbox/lucene-dev/201208.mbox/%3CCAB_8Yd8uzs4M-T75Dzz_bsc7_gVOH6V2t=15DJ7dMLihKnSAkg@mail.gmail.com%3E\nhttp://mail-archives.apache.org/mod_mbox/lucene-dev/201208.mbox/%3Calpine.DEB.2.02.1208092008110.12408@frisbee%3E\nhttp://mail-archives.apache.org/mod_mbox/lucene-dev/201208.mbox/%3CCAOdYfZURBuFh0ui8UEgwwjzdqUA0wcVoKYaDsSfSKuOz_q054A@mail.gmail.com%3E\nhttp://mail-archives.apache.org/mod_mbox/lucene-dev/201208.mbox/%3Calpine.DEB.2.02.1208131054000.21076@frisbee%3E\nhttp://mail-archives.apache.org/mod_mbox/lucene-dev/201208.mbox/%3CCAOdYfZV2SGU0h180icmueg51x0xwMBqREdFex7CDdhvGC_2U1g@mail.gmail.com%3E\nhttp://mail-archives.apache.org/mod_mbox/lucene-dev/201208.mbox/%3C6C78E97C707B5B4C8CC61D44F8754586353F66@SUEX10-mbx-03.ad.syr.edu%3E\nhttp://mail-archives.apache.org/mod_mbox/lucene-dev/201208.mbox/%3CCAL8PwkZCzdihHy6t5DMUPPxXd3f88xqQG9YTZxB6pQHneAmUhg@mail.gmail.com%3E\nhttp://mail-archives.apache.org/mod_mbox/lucene-dev/201208.mbox/%3Calpine.DEB.2.02.1208141007080.28699@frisbee%3E\nhttp://mail-archives.apache.org/mod_mbox/lucene-dev/201208.mbox/%3CCAOdYfZX36v1hU25ALxUw8FsJtwO-R9McXzbJxbAL=hPA1xh34g@mail.gmail.com%3E\nhttp://mail-archives.apache.org/mod_mbox/lucene-dev/201208.mbox/%3Calpine.DEB.2.02.1208201208030.18354@frisbee%3E "
        }
    ]
}