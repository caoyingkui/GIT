{
    "id": "SOLR-532",
    "title": "WordDelimiterFilter ignores payloads",
    "details": {
        "affect_versions": "None",
        "status": "Closed",
        "fix_versions": [
            "1.4"
        ],
        "components": [],
        "type": "Bug",
        "priority": "Minor",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "When a WordDelimiterFilter ingests a token stream and creates a new token (newTok) it appears to copy most of the old token attributes, except the payload.  I believe this is a bug.  My solution is for the WordDelimiterFilter to use the Token clone() method to create a carbon copy and then modify the appropriate attributes (offsets and term text).",
    "attachments": {
        "SOLR-532-WordDelimiterFilter.patch": "https://issues.apache.org/jira/secure/attachment/12379277/SOLR-532-WordDelimiterFilter.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Tricia Jenkins",
            "id": "comment-12585162",
            "date": "2008-04-03T16:07:28+0000",
            "content": "Quick fix.  Does this need a unit test to go with it? "
        },
        {
            "author": "Tricia Jenkins",
            "id": "comment-12619994",
            "date": "2008-08-05T18:33:51+0000",
            "content": "LUCENE-1350 contains a survey of Classes that may be effected by Payloads.  This is one of the Classes in Solr proper that may be effected by Payloads. "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12641404",
            "date": "2008-10-21T15:21:24+0000",
            "content": "I consolidated this down to take advantage of Lucene's new clone method:\n\nIndex: src/java/org/apache/solr/analysis/WordDelimiterFilter.java\n===================================================================\n--- src/java/org/apache/solr/analysis/WordDelimiterFilter.java  (revision 706648)\n+++ src/java/org/apache/solr/analysis/WordDelimiterFilter.java  (working copy)\n@@ -236,11 +236,7 @@\n       startOff += start;     \n     }\n \n-    Token newTok = new Token(startOff,\n-            endOff,\n-            orig.type());\n-    newTok.setTermBuffer(orig.termBuffer(), start, (end - start));\n-    return newTok;\n+    return (Token)orig.clone(orig.termBuffer(), start, (end - start), startOff, endOff);\n   }\n\n\nI will likely commit today or tomorrow.  Let me know if this works for you, Tricia.  The tests pass for me. "
        },
        {
            "author": "Tricia Jenkins",
            "id": "comment-12641694",
            "date": "2008-10-22T01:33:14+0000",
            "content": "Thanks Grant.  That's much cleaner using the new clone method.  It works for me after catching up with the new slf4j logging.  Thanks too for committing it! "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12775505",
            "date": "2009-11-10T15:51:42+0000",
            "content": "Bulk close for Solr 1.4 "
        }
    ]
}