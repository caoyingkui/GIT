{
    "id": "LUCENE-6445",
    "title": "Highlighter TokenSources simplification; just one getAnyTokenStream()",
    "details": {
        "resolution": "Fixed",
        "affect_versions": "None",
        "components": [
            "modules/highlighter"
        ],
        "labels": "",
        "fix_versions": [
            "5.2"
        ],
        "priority": "Major",
        "status": "Closed",
        "type": "Improvement"
    },
    "description": "The Highlighter \"TokenSources\" class has quite a few utility methods pertaining to getting a TokenStream from either term vectors or analyzed text.  I think it's too much:\n\n\tsome go to term vectors, some don't.  But if you don't want to go to term vectors, then it's quite easy for the caller to invoke the Analyzer for the field value, and to get that field value.\n\tSome methods return null, some never null; I forget which at a glance.\n\tSome methods read the Document (to get a field value) from the IndexReader, some don't.  Furthermore, it's not an ideal place to get the doc since your app might be using an IndexSearcher with a document cache (e.g. SolrIndexSearcher).\n\tNone of the methods accept a Fields instance from term vectors as a parameter.  Based on how Lucene's term vector format works, this is a performance trap if you don't re-use an instance across fields on the document that you're highlighting.",
    "attachments": {
        "LUCENE-6445_TokenSources_simplification.patch": "https://issues.apache.org/jira/secure/attachment/12728016/LUCENE-6445_TokenSources_simplification.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "id": "comment-14503426",
            "author": "David Smiley",
            "date": "2015-04-20T18:57:34+0000",
            "content": "What I propose is two methods:\n\ngetTokenStream(String field, Fields tvFields, String text, Analyzer analyzer, int maxStartOffset) throws IOException\n\n\nand\n\ngetTermVectorTokenStreamIfPresent(String field,  Fields tvFields, maxStartOffset) throws IOException\n\n\nAll the others can be deprecated in 5x, removed in trunk.  If you supply a maxStartOffset, it should apply to either term vectors or analyzed text \u2013 whichever it gets it from.  See  LUCENE-6423 LimitTokenOffsetFilter.  If the term vector doesn't have offsets then it won't be used.  Ditto for positions... and if the caller knows what it's doing and wants to use TokenStreamFromTermVector with offsets but not positions then it can do so, but not with these convenience methods.  The second method can return null; it's name is suggestive of that.  IOException is never masked in a RuntimeException. "
        },
        {
            "id": "comment-14507956",
            "author": "ASF subversion and git services",
            "date": "2015-04-22T21:35:19+0000",
            "content": "Commit 1675504 from David Smiley in branch 'dev/trunk'\n[ https://svn.apache.org/r1675504 ]\n\nLUCENE-6392 Highlighter: add maxStartOffset (and other memory saving efficiencies) to TokenStreamFromTermVector.\nDelaying TokenSources changes for LUCENE-6445. "
        },
        {
            "id": "comment-14507985",
            "author": "ASF subversion and git services",
            "date": "2015-04-22T21:48:14+0000",
            "content": "Commit 1675505 from David Smiley in branch 'dev/branches/branch_5x'\n[ https://svn.apache.org/r1675505 ]\n\nLUCENE-6392 Highlighter: add maxStartOffset (and other memory saving efficiencies) to TokenStreamFromTermVector.\nDelaying TokenSources changes for LUCENE-6445. "
        },
        {
            "id": "comment-14511673",
            "author": "David Smiley",
            "date": "2015-04-24T20:34:50+0000",
            "content": "Attached patch.\nThe 2nd method name is actually \"getTermVectorTokenStreamOrNull\", and I decided that positions on the term vector needn't be a hard requirement.  \n\nThe patch adds a test for the maxStartOffset behavior. The javadocs for these two methods are quite complete, including a warning about multi-valued fields.  Solr calls one of these now with the maxStartOffset, so it will benefit.  Updating  all the test calls was a bit tedious.\n\nAlso, this highlighter module now depends on analysis-common for the LimitTokenOffsetFilter. "
        },
        {
            "id": "comment-14517070",
            "author": "ASF subversion and git services",
            "date": "2015-04-28T14:11:56+0000",
            "content": "Commit 1676540 from David Smiley in branch 'dev/trunk'\n[ https://svn.apache.org/r1676540 ]\n\nLUCENE-6445: Highlighter TokenSources simplification "
        },
        {
            "id": "comment-14517260",
            "author": "ASF subversion and git services",
            "date": "2015-04-28T15:53:42+0000",
            "content": "Commit 1676571 from David Smiley in branch 'dev/branches/branch_5x'\n[ https://svn.apache.org/r1676571 ]\n\nLUCENE-6445: Highlighter TokenSources simplification "
        },
        {
            "id": "comment-14586810",
            "author": "Anshum Gupta",
            "date": "2015-06-15T21:42:51+0000",
            "content": "Bulk close for 5.2.0. "
        }
    ]
}