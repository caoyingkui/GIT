{
    "id": "SOLR-12290",
    "title": "Do not close any servlet streams and improve our servlet stream closing prevention code for users and devs.",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [],
        "type": "Bug",
        "fix_versions": [
            "7.4",
            "master (8.0)"
        ],
        "affect_versions": "None",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "Original Summary:\n\nWhen you fetch a file for replication we close the request output stream after writing the file which ruins the connection for reuse.\n\nWe can't close response output streams, we need to reuse these connections. If we do close them, clients are hit with connection problems when they try and reuse the connection from their pool.\n\nNew Summary:\n\nAt some point the above was addressed during refactoring. We should remove these neutered closes and review our close shield code.\n\n\nIf you are here to track down why this is done:\n\nConnection reuse requires that we read all streams and do not close them - instead the container itself must manage request and response streams. If we allow them to be closed, not only do we lose some connection reuse, but we can cause spurious client errors that can cause expensive recoveries for no reason. The spec allows us to count on the container to manage streams. It's our job simply to not close them and to always read them fully, from client and server. \n\nJava itself can help with always reading the streams fully up to some small default amount of unread stream slack, but that is very dangerous to count on, so we always manually eat up anything on the streams our normal logic ends up not reading for whatever reason.\n\nWe also cannot call abort without ruining the connection or sendError. These should be options of very last resort (requiring a blood sacrifice) or when shutting down.",
    "attachments": {
        "SOLR-12290_7x.patch": "https://issues.apache.org/jira/secure/attachment/12925480/SOLR-12290_7x.patch",
        "SOLR-12290.patch": "https://issues.apache.org/jira/secure/attachment/12921188/SOLR-12290.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2018-04-29T17:04:44+0000",
            "content": "This is kind of ugly because it happens during recovery - so if lots of updates are coming in, it's possible that you have a legit reason to recover, you start to recover, that ruins connections, updates can fail because of that, recovery is triggered again, updates still coming in ... etc. ",
            "author": "Mark Miller",
            "id": "comment-16458075"
        },
        {
            "date": "2018-04-29T17:55:57+0000",
            "content": "Looks like this may actually have been fixed during some refactoring at some point. I found this in an older code base and saw we still close these streams, but at some point we started shielding the\u00a0response writer close at a higher level. I originally put in those close shields, but had missed shielding the response writing properly. I think when HttpSolrCall came about, this ended up getting shielded.\n\nSo I'll remove these closes and review our shielding and testing. It seems a little error prone right now and I think we can do better. ",
            "author": "Mark Miller",
            "id": "comment-16458106"
        },
        {
            "date": "2018-04-29T18:40:25+0000",
            "content": "Patch attached that cleans this up to be less error prone and remove any closes of the request / response streams whether they were neutered or not. ",
            "author": "Mark Miller",
            "id": "comment-16458112"
        },
        {
            "date": "2018-04-29T20:53:00+0000",
            "content": "New patch. We only assert no closes on callers from lucene and solr packages - for 3rd parties we just shield the close. ",
            "author": "Mark Miller",
            "id": "comment-16458192"
        },
        {
            "date": "2018-04-29T21:27:31+0000",
            "content": "Okay, I think this is final or close to. Gives us much less fragile protection and forces devs to understand the ramifications of the neutered close. ",
            "author": "Mark Miller",
            "id": "comment-16458205"
        },
        {
            "date": "2018-04-29T23:28:48+0000",
            "content": "Last patch, precommit and tests pass. ",
            "author": "Mark Miller",
            "id": "comment-16458237"
        },
        {
            "date": "2018-04-30T03:34:31+0000",
            "content": "Hi Mark. \u00a0In SOLR-11692\u00a0Jeff Miller and I\u00a0took care not to wrap a closeShield in SolrDispatchFilter.doFilter\u00a0when the request continues on thru chain.doFilter \u00a0(line ~367). \u00a0Admittedly there isn't a test for this and I forget precisely why it mattered.\n\nOtherwise overall the patch looks good.\n\n\tJavabinLoader: you can now inline parseAndLoadDocs\n\n ",
            "author": "David Smiley",
            "id": "comment-16458293"
        },
        {
            "date": "2018-04-30T03:55:52+0000",
            "content": "Admittedly there isn't a test for this and I forget precisely why it mattered.\n\nIt's because we can't control closing the outputstream in some 3rd party code. For example Jetty incorrectly does this when you forward.\n\nWe need to shield everywhere, there is no legitimate closing except by the container, so this fixes that issue correctly by only triggering an assert when it's our code and ignoring all non container closes all the time in non test code. ",
            "author": "Mark Miller",
            "id": "comment-16458295"
        },
        {
            "date": "2018-04-30T04:25:50+0000",
            "content": "Jetty incorrectly\n\nTo clarify that, a Jetty servlet does it, not the Jetty container. I guess from that perspective it's not totally incorrect because you could say the servlet simply doesn't support connection reuse well. But connection reuse is very, very important for us and we actually plug that servlet logic into our filter. So we shield that servlet close, that just happens to be a jetty implemented servlet, and we allow only the container itself to close streams. ",
            "author": "Mark Miller",
            "id": "comment-16458299"
        },
        {
            "date": "2018-04-30T05:10:18+0000",
            "content": "JavabinLoader: you can now inline parseAndLoadDocs\n\nInlined.\n\nI'll commit this in the next couple days. It extends test and safety coverage to the entire SolrDispatchFilter for the first time as well as to our Servlets. It also removes the separate test code path, and so testing and protecting no longer have different coverage and everything is tested and protected on one code path.\n\nI've also returned this to a bug. Given SOLR-11692 and some places we never protected (the other servlets) and the fact that different things have been covered at different points of time, this will solve existing spurious cluster recovery issues. ",
            "author": "Mark Miller",
            "id": "comment-16458314"
        },
        {
            "date": "2018-04-30T13:27:27+0000",
            "content": "Sounds good Mark! \u00a0Thanks for the clarifications. \u00a0I didn't know this problem could\u00a0lead to client recovery; ouch! ",
            "author": "David Smiley",
            "id": "comment-16458566"
        },
        {
            "date": "2018-04-30T13:56:39+0000",
            "content": "Yeah, it\u2019s not super obvious, but the problem with closing ourselves is that the we can\u2019t clear any data that might be left on the stream and we also can\u2019t gaurantee some data does t show up from the other side right after an early close. So to ensure connection reuse you cannot close yourself. ",
            "author": "Mark Miller",
            "id": "comment-16458594"
        },
        {
            "date": "2018-04-30T15:47:12+0000",
            "content": "As I've been working on this, I realized that we don't ensure reading full streams when we get files for replication, whether we close the streams early or not.\n\nI filed SOLR-12293. We need to isolate our update connection pool from these other random uses. ",
            "author": "Mark Miller",
            "id": "comment-16458676"
        },
        {
            "date": "2018-05-01T20:54:48+0000",
            "content": "For a long term strategy to improve all of this yet again (of course all the previous HttpClient Http1.1 connection failure work was always a stop gap band aid and as we found out extremely hard to fully nail down), I filed\u00a0SOLR-12297. ",
            "author": "Mark Miller",
            "id": "comment-16460143"
        },
        {
            "date": "2018-05-04T23:02:17+0000",
            "content": "Commit 296201055f24f01e1610f2fb87aba7fa90b9dda1 in lucene-solr's branch refs/heads/master from Mark Miller\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=2962010 ]\n\nSOLR-12290: Do not close any servlet streams and improve our servlet stream closing prevention code for users and devs. ",
            "author": "ASF subversion and git services",
            "id": "comment-16464484"
        },
        {
            "date": "2018-05-06T17:47:50+0000",
            "content": "This commit breaks TestCSVLoader on Windows. It looks like Solr no longer closes any content streams that are passed separately to the servlet stream:\n\n\n   [junit4]   2> NOTE: reproduce with: ant test  -Dtestcase=TestCSVLoader -Dtests.method=testLiteral -Dtests.seed=B40869AE03F63CBC -Dtests.locale=ms -Dtests.timezone=ECT -Dtests.asserts=true -Dtests.file.encoding=UTF-8\n   [junit4] ERROR   0.06s | TestCSVLoader.testLiteral <<<\n   [junit4]    > Throwable #1: java.nio.file.FileSystemException: C:\\Users\\Uwe Schindler\\Projects\\lucene\\trunk-lusolr1\\solr\\build\\solr-core\\test\\J0\\temp\\solr.handler.TestCSVLoader_B40869AE03F63CBC-001\\TestCSVLoader-006\\solr_tmp.csv: Der Prozess kann nicht auf die Datei zugreifen, da sie von einem anderen Prozess verwendet wird.\n   [junit4]    >        at __randomizedtesting.SeedInfo.seed([B40869AE03F63CBC:B2ACAF677D87833E]:0)\n   [junit4]    >        at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)\n   [junit4]    >        at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)\n   [junit4]    >        at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)\n   [junit4]    >        at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)\n   [junit4]    >        at sun.nio.fs.AbstractFileSystemProvider.delete(AbstractFileSystemProvider.java:103)\n   [junit4]    >        at java.nio.file.Files.delete(Files.java:1126)\n   [junit4]    >        at org.apache.solr.handler.TestCSVLoader.tearDown(TestCSVLoader.java:64)\n   [junit4]    >        at java.lang.Thread.run(Thread.java:748)\n\n\n\nI am not sure behind the reasoning of forcefully preventing closing of ServletInputStreams - but IMHO, the better way to handle this is (we had this discussion already a while ago):\n\nWrap the ServletInput/ServletOutput streams with a CloseShieldXxxxStream and only pass this one around. This allows that code anywhere in solr is free to close any streams correctly (which it should), but the ServletStreams are kept open by the shield.\nThe issue we have now is that ContentStreams are not necessarily (like in BlobUploadHandler, CSVHandler) coming from the servlet streams. If it is a file or a uploaded file, then we HAVE to close the stream.\n\nThe reason behind everything here is a bug in Jetty - in contrast to Tomcat and all other servlet containers, it closes the socket after you close the servlet streams. This is a bug - sorry! Jetty should prevent closing the underlying stream stream!\n\nPlease revert the current commit. I can help in solving this correctly - unfortunately I am on travel next week. ",
            "author": "Uwe Schindler",
            "id": "comment-16465235"
        },
        {
            "date": "2018-05-06T17:50:58+0000",
            "content": "I just repeat: We have no a serious file descriptor leak in combination with ContentStreams!!!  ",
            "author": "Uwe Schindler",
            "id": "comment-16465237"
        },
        {
            "date": "2018-05-06T18:02:13+0000",
            "content": "I think I know how to solve this:\n\n\tRevert all stuf that removed close of code that uses ContentStream\n\tIn SolrRequestParsers$HttpRequestContentStream add a CloseShieldInputStream in the getStream() method. This should solve the file leaks caused by no longer closing streams on files...\n\n\n\nThis should make the changes in BlobHandler and CSVLoaderBase obsolete - and code clean again. It's a no-go to not close streams of unknown origin! ",
            "author": "Uwe Schindler",
            "id": "comment-16465240"
        },
        {
            "date": "2018-05-06T18:03:40+0000",
            "content": "I will look into this Uwe. We are still using a CloseShield. Relax, this is only on master and is not a very large change from what we were doing before. ",
            "author": "Mark Miller",
            "id": "comment-16465241"
        },
        {
            "date": "2018-05-06T18:12:06+0000",
            "content": "I have seen. It's fine! I was just really annoyed today while running tests locally. All tests that use ContentStreams with file uploads or files break horribly on windows (which is a sign for file dexcriptor leaks, so I am glad that we run tests on Windows).\n\nAs said before: I'd just revert the code where we consume the ContentStream subclasses (BlobHandler, CSVHandler, maybe DIH,...) and just add another CloseShield in the HttpRequestContentStream. ",
            "author": "Uwe Schindler",
            "id": "comment-16465244"
        },
        {
            "date": "2018-05-06T18:22:05+0000",
            "content": "I think your patch is fine. Really just revert the code that prevents closing of ContentStream.getStream() stuff. That makes half of the patch obsolete! So it looks like you are doing the wrapping AND preventing closing in solr stuff that reads from those ContentStreams? Why do both if the first already solves the issue? ",
            "author": "Uwe Schindler",
            "id": "comment-16465248"
        },
        {
            "date": "2018-05-06T18:28:39+0000",
            "content": "Because we no longer have two separate code paths for tests and normal runs, we have an assert that lets developers know when their closes are no ops so that developers can understand what is actually going on. We don't need a close when it won't actually do anything. We should just close where we need to. In cases like the CSVHandler we need to.\n\nWhether Jetty closed the socket or not, we can't have anyone close these stream because we have to make sure they are fully consumed.\n\nAnyway, it's simple to fix, I'm not going to jam anything in though, I have to run tests and what not. ",
            "author": "Mark Miller",
            "id": "comment-16465249"
        },
        {
            "date": "2018-05-06T18:55:40+0000",
            "content": "It's not only CSV handler. It's all code that consumes ContentStream. It's not only tests. E.g. if you upload a file to DIH or you upload the CSV file via HTTP file upload (and not as part of the stream), you get a file stream.\n\nSo please, just close the stream, costs nothing if its a no-op. It has nothing to do with tests vs. production! In case of a ContentStream, YOU DO NOT KNOW WHAT TYPE OF INPUT STREAM YOU HAVE BEHIND THE ABSTRACT INTERFACE. It can be anything, so it has to be closed. In the case of HttpRequestContentStream it's a no-op, but consuming code does not need to know this. ",
            "author": "Uwe Schindler",
            "id": "comment-16465252"
        },
        {
            "date": "2018-05-06T19:08:27+0000",
            "content": "Whether Jetty closed the socket or not, we can't have anyone close these stream because we have to make sure they are fully consumed.\n\nI agree that's fine as workaround for the \"jetty bug\" (it might be one or now, I don't want to argue about it - I'm not Robert). I can just say: Tomcat fully consumes the stream automatically if a consumer closes it.\n\nMy complaint was only: If we have a perfect stream handling inside SolrDispatchFilter that handles the stream consuming and prevents closing of underlying ServletOutputStream, the code down the line can handle the input like a normal stream. And so goes for ContentStreams, which are an abstract interface. Here I will behave like \"Robert\" and cry for revert if you do not revert the broken code! ",
            "author": "Uwe Schindler",
            "id": "comment-16465254"
        },
        {
            "date": "2018-05-06T19:09:55+0000",
            "content": "As you are not willing to fix this, should I send you the patch based on your current commit? ",
            "author": "Uwe Schindler",
            "id": "comment-16465255"
        },
        {
            "date": "2018-05-06T19:33:59+0000",
            "content": "Commit 5fc725154001c6283315802e1a2193d51d00f9aa in lucene-solr's branch refs/heads/master from markrmiller\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=5fc7251 ]\n\nSOLR-12290: We must close ContentStreams because we don't know the source of the inputstream - use a CloseShield to prevent tripping our close assert in SolrDispatchFilter. ",
            "author": "ASF subversion and git services",
            "id": "comment-16465267"
        },
        {
            "date": "2018-05-06T19:35:18+0000",
            "content": "Oh thanks, that was my patch  ",
            "author": "Uwe Schindler",
            "id": "comment-16465269"
        },
        {
            "date": "2018-05-06T19:36:06+0000",
            "content": "You definitely bring a nasty Lucene vibe into the Solr community sometimes. When did I say I wasn't willing to fix it? I said the fix was easy and I have to run tests. Cool down man. ",
            "author": "Mark Miller",
            "id": "comment-16465271"
        },
        {
            "date": "2018-05-06T19:49:38+0000",
            "content": "Sorry, I am a bit worried today. It's too hot here and it was the yonly day where I fixed a serious security issue caused by me 5 years ago and was really annoyed about tests failing all day.\n\nYou said \"there is no need to close streams if closing is a no-op\". I still argue that this is the wrong way do do it. If stuff like Jetty needs special handling on closing, it should be done top-level. If downstream code gets a stream, it should do try-with-resources.\n\nI am happy with your code in SolrDispatchFilter and the wrapper around the ServletXxxStreams. But I don't think we should make users forcefully remove try-with-resources blocks (and cause a warning in Eclipse), just because some specific implementation of a stream needs special handling. So I'd put all special case only in SolrDispatchFilter and whenever a user gets an input stream/outputstream further down the code it MUST close it. That's just a fact of good programming practise. A method gets a stream does something with it and closes it. Solr (especially in tests) is already full of missing closes, so we should not add more. And because of that I am heavily arguing. It was not against you, I was just bored about the sometimes horrible code quality of solr and its tests and a commit that made the code quality of some parts against all programming standards (streams have to be closed after usage). One reason that I try to avoid fixing bugs in Solr, unless they were caused by me or have something to do with XML handling (because that's one of my beloved parts of code - I love XML).\n\nI can confirm the tests now pass on Windows. So file leaks with uploaded files or other types of content streams are solved. Thanks, but I have a bad feeling now about one more horrible anti-feature of solr. ",
            "author": "Uwe Schindler",
            "id": "comment-16465276"
        },
        {
            "date": "2018-05-06T19:50:16+0000",
            "content": "Oh thanks, that was my patch \n\nYour welcome. If you insist on behaving like Robert, I'm leaving Solr like I left Lucene. There is no reason for this garbage. ",
            "author": "Mark Miller",
            "id": "comment-16465277"
        },
        {
            "date": "2018-05-06T19:54:00+0000",
            "content": "See my comment. But some things have to be said. Introducing bad programming practises, just because of a special case or bug in some component (Jetty) is not a good idea. I stop talking here, all is said. ",
            "author": "Uwe Schindler",
            "id": "comment-16465280"
        },
        {
            "date": "2018-05-07T00:59:41+0000",
            "content": "Last commit to partially revert looks good to me. \u00a0I agree with Uwe's sentiment about standard coding practices \u2013 if you obtain the stream, close the stream. \u00a0I should have thought of this earlier in my review. ",
            "author": "David Smiley",
            "id": "comment-16465331"
        },
        {
            "date": "2018-05-07T01:12:37+0000",
            "content": "This wasn't about coding practices - it's simply about the ContentStream API. It can return a stream from any source and so streams that come from that API must be closed. We are still still not closing servlet streams where we don't have to. In some cases we have because the user of the API can't discern where the stream came from. This wasn't a coding practice issue, it was a bug. ",
            "author": "Mark Miller",
            "id": "comment-16465334"
        },
        {
            "date": "2018-05-07T01:15:20+0000",
            "content": "See my comment. But some things have to be said. Introducing bad programming practises, just because of a special case or bug in some component (Jetty) is not a good idea. I stop talking here, all is said.\n\nWe didn't introduce bad coding practices and your opinion on how Jetty handles this has little to do with it. The original patch didn't handle ContentStream stuff right when working around assert errors. You are supposed to point out bugs. Being an impatient jerk is an unnecessary part of the process. ",
            "author": "Mark Miller",
            "id": "comment-16465335"
        },
        {
            "date": "2018-05-07T01:33:20+0000",
            "content": "I'm not going to backport this to 7x, I've had enough silliness on this issue. If anyone actually understood it, this wouldn't have turned into a bunch of silly statements and threats. ",
            "author": "Mark Miller",
            "id": "comment-16465342"
        },
        {
            "date": "2018-05-07T06:21:15+0000",
            "content": "Hi,\nI can backport this if needed. I'd just like to have a second iteration on it. I am not really happy with the stuff (especially when handling gzip responses). \n\nI understand the issues here, I just wanted to have an easier way to consume the Solr Request where everything is handled in SolrRequestParsers and SolrDispatchFilter. The downstream code should just not need to think about (\"do I need to close or not?). The code should always use try-with-resources and any stuff that was not yet read from the underlying servlet stream should be consumed before SolrDispatchFilter gives control back to the Jetty container. I am out of office this week, so I will for sure look into it next weekend.\n\nWe are still still not closing servlet streams where we don't have to. In some cases we have because the user of the API can't discern where the stream came from. This wasn't a coding practice issue, it was a bug. \u2013 Being an impatient jerk is an unnecessary part of the process.\n\nSorry for being impatient jerk! It was also missing communication. I asked for a revert initially, because the issue was a file handle leak. This was my first comment. It was just a normal request, not even a veto: I was asking for revert so we can have a look a second time. I was not really following this issue last week, because we were moving offices and so on, maybe I should have looked earlier. \n\nI then looked into your patch and was understanding and seeing the issue. I was totally fine with keeping the ServletInputStream open, but the bug in the ContentHandler code looked like bad coding practise, because it removed necessary try-with-resources. I brought that up on the issue, but the reaction was - as far as I understand it - something like: \"no we don't need to close streams so I refuse to add CloseShield\". This was the misunderstanding (you talked about the servlet stream, I talked about ContentStreams). And then I proposed to add a patch. While doing this you committed almost the same code that I hacked together (I reverted about 3 or 4 files and added the CloseShield). The \"This was my patch\" was just a confirmation: All fine! Sorry if you have thought it was sarcastic.\n\nIn some cases I am a bit like Robert, especially if it is around closing stuff and file leaks. I try to write code in a way that the downstream code is forced to always write \"correct code\" (means closing everything with try-with-resources) and we should work around bugs like Jetty's at the source of the problem without touching any other code. IMHO, the asserts in test code are not really needed. Just shield the ServletInputStream from being closed in SolrDispatchFilter and if the downstream code calls close and it is not yet fully consumed, just copy the remaining content to Java's \"/dev/null\" with IOUtils. ",
            "author": "Uwe Schindler",
            "id": "comment-16465479"
        },
        {
            "date": "2018-05-12T04:33:27+0000",
            "content": "Commit 4c09a13afb441bdce1c440263ea61cdb5f10b141 in lucene-solr's branch refs/heads/master from markrmiller\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=4c09a13 ]\n\nSOLR-12290: Update assert messages about closing request / response streams. ",
            "author": "ASF subversion and git services",
            "id": "comment-16472902"
        },
        {
            "date": "2018-05-12T05:15:24+0000",
            "content": "Commit ab58b7f9ba646a294005f1e433e4faee43c7d22b in lucene-solr's branch refs/heads/master from markrmiller\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=ab58b7f ]\n\nSOLR-12290: Update assert messages about closing request / response streams. ",
            "author": "ASF subversion and git services",
            "id": "comment-16472912"
        },
        {
            "date": "2018-05-28T18:42:41+0000",
            "content": "Hi Mark,\n\nIs it okay if we backport this to branch_7x\u00a0 ?\n\nThe motivation being that you mentioned on SOLR-1881 ( https://issues.apache.org/jira/browse/SOLR-11881?focusedCommentId=16458322&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-16458322\u00a0) that this could be one of the underlying reasons for the Jetty exception.\u00a0 ",
            "author": "Varun Thacker",
            "id": "comment-16492883"
        },
        {
            "date": "2018-05-28T22:46:26+0000",
            "content": "Yeah, feel free - the reason I\u2019m not very concerned is that the other issue I did around around the same time that gives updates and only updates their own connection pool should remove any issue this would prob help with.\u00a0 ",
            "author": "Mark Miller",
            "id": "comment-16492948"
        },
        {
            "date": "2018-05-29T00:40:38+0000",
            "content": "Sounds good! Here's a patch which\u00a0squashes all the 4 commits into one. I'll run tests and precommit before pushing this ",
            "author": "Varun Thacker",
            "id": "comment-16492978"
        },
        {
            "date": "2018-05-29T18:10:52+0000",
            "content": "Commit 62de5c099476c958229aafe19c3b266fdfec10eb in lucene-solr's branch refs/heads/branch_7x from Mark Miller\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=62de5c0 ]\n\nSOLR-12290: Do not close any servlet streams and improve our servlet stream closing prevention code for users and devs.\n\n(cherry picked commit 2962010 + 5fc7251 + 4c09a13 + ab58b7f) ",
            "author": "ASF subversion and git services",
            "id": "comment-16493988"
        },
        {
            "date": "2018-05-29T18:22:56+0000",
            "content": "Hi Mark,\n\nI committed it and looks like the author tag was also retained . So the commit technically looks like it's come from you .\n\nIn master , the CHANGES entry is already under 7.4 so nothing to do there.\u00a0 ",
            "author": "Varun Thacker",
            "id": "comment-16494006"
        },
        {
            "date": "2018-06-02T00:04:59+0000",
            "content": "This commit causes incomplete response, see SOLR-12391 ",
            "author": "Jan H\u00f8ydahl",
            "id": "comment-16498738"
        },
        {
            "date": "2018-06-02T05:19:45+0000",
            "content": "Commit 1ff24bbb283a4cbfb9a6babfa702fbd57804a7fd in lucene-solr's branch refs/heads/master from markrmiller\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=1ff24bb ]\n\nSOLR-12290,SOLR-12391: Do not close any servlet streams and improve our servlet stream closing prevention code for users and devs. ",
            "author": "ASF subversion and git services",
            "id": "comment-16498886"
        },
        {
            "date": "2018-06-02T05:23:15+0000",
            "content": "Commit 88400a14716f163715eac82a35be90e6e3718208 in lucene-solr's branch refs/heads/branch_7x from markrmiller\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=88400a1 ]\n\nSOLR-12290,SOLR-12391: Do not close any servlet streams and improve our servlet stream closing prevention code for users and devs. ",
            "author": "ASF subversion and git services",
            "id": "comment-16498892"
        }
    ]
}