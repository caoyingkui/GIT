{
    "id": "LUCENE-2186",
    "title": "First cut at column-stride fields (index values storage)",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [
            "core/index"
        ],
        "type": "New Feature",
        "fix_versions": [
            "4.0-ALPHA",
            "CSF branch"
        ],
        "affect_versions": "None",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "I created an initial basic impl for storing \"index values\" (ie\ncolumn-stride value storage).  This is still a work in progress... but\nthe approach looks compelling.  I'm posting my current status/patch\nhere to get feedback/iterate, etc.\n\nThe code is standalone now, and lives under new package\noal.index.values (plus some util changes, refactorings) \u2013 I have yet\nto integrate into Lucene so eg you can mark that a given Field's value\nshould be stored into the index values, sorting will use these values\ninstead of field cache, etc.\n\nIt handles 3 types of values:\n\n\n\tSix variants of byte[] per doc, all combinations of fixed vs\n    variable length, and stored either \"straight\" (good for eg a\n    \"title\" field), \"deref\" (good when many docs share the same value,\n    but you won't do any sorting) or \"sorted\".\n\n\n\n\n\tIntegers (variable bit precision used as necessary, ie this can\n    store byte/short/int/long, and all precisions in between)\n\n\n\n\n\tFloats (4 or 8 byte precision)\n\n\n\nString fields are stored as the UTF8 byte[].  This patch adds a\nBytesRef, which does the same thing as flex's TermRef (we should merge\nthem).\n\nThis patch also adds basic initial impl of PackedInts (LUCENE-1990);\nwe can swap that out if/when we get a better impl.\n\nThis storage is dense (like field cache), so it's appropriate when the\nfield occurs in all/most docs.  It's just like field cache, except the\nreading API is a get() method invocation, per document.\n\nNext step is to do basic integration with Lucene, and then compare\nsort performance of this vs field cache.\n\nFor the \"sort by String value\" case, I think RAM usage & GC load of\nthis index values API should be much better than field caache, since\nit does not create object per document (instead shares big long[] and\nbyte[] across all docs), and because the values are stored in RAM as\ntheir UTF8 bytes.\n\nThere are abstract Writer/Reader classes.  The current reader impls\nare entirely RAM resident (like field cache), but the API is (I think)\nagnostic, ie, one could make an MMAP impl instead.\n\nI think this is the first baby step towards LUCENE-1231.  Ie, it\ncannot yet update values, and the reading API is fully random-access\nby docID (like field cache), not like a posting list, though I\ndo think we should add an iterator() api (to return flex's DocsEnum)\n\u2013 eg I think this would be a good way to track avg doc/field length\nfor BM25/lnu.ltc scoring.",
    "attachments": {
        "mem.py": "https://issues.apache.org/jira/secure/attachment/12430868/mem.py",
        "LUCENE-2186.patch": "https://issues.apache.org/jira/secure/attachment/12429272/LUCENE-2186.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2010-01-02T18:53:35+0000",
            "content": "Is this patch for flex, as it contains CodecUtils and so on?\n\nIf it is so we should use \"affects version: flex\". ",
            "author": "Uwe Schindler",
            "id": "comment-12795897"
        },
        {
            "date": "2010-01-03T10:37:10+0000",
            "content": "Great to see progress here, Mike!\n\n\nString fields are stored as the UTF8 byte[]. This patch adds a\nBytesRef, which does the same thing as flex's TermRef (we should merge\nthem).\n\nIt looks like ByteRef is very similar to Payload? Could you use that instead \nand extend it with the new String constructor and compare methods? \n\n\nIt handles 3 types of values:\n\nSo it looks like with your approach you want to support certain\n\"primitive\" types out of the box, such as byte[], float, int, String?\nIf someone has custom data types, then they have, similar as with\npayloads today, the byte[] indirection? \n\nThe code I initially wrote for 1231 exposed IndexOutput, so that one\ncan call write*() directly, without having to convert to byte[]\nfirst. I think we will also want to do that for 2125 (store attributes\nin the index). So I'm wondering if this and 2125 should work\nsimilarly? \nThinking out loud: Could we have then attributes with\nserialize/deserialize methods for primitive types, such as float?\nCould we efficiently use such an approach all the way up to\nFieldCache? It would be compelling if you could store an attribute as\nCSF, or in the postinglist, retrieve it from the flex APIs, and also\nfrom the FieldCache. All would be the same API and there would only be\none place that needs to \"know\" about the encoding (the attribute).\n\n\nNext step is to do basic integration with Lucene, and then compare\nsort performance of this vs field cache.\n\nYeah, that's where I got kind of stuck with 1231: We need to figure\nout how the public API should look like, with which a user can add CSF\nvalues to the index and retrieve them. The easiest and fastest way\nwould be to add a dedicated new API. The cleaner one would be to make the whole\nDocument/Field/FieldInfos API more flexible. LUCENE-1597 was a first attempt.\n\n\nThere are abstract Writer/Reader classes. The current reader impls\nare entirely RAM resident (like field cache), but the API is (I think)\nagnostic, ie, one could make an MMAP impl instead.\n\nI think this is the first baby step towards LUCENE-1231. Ie, it\ncannot yet update values, and the reading API is fully random-access\nby docID (like field cache), not like a posting list, though I\ndo think we should add an iterator() api (to return flex's DocsEnum)\n\nHmm, so random-access would obviously be the preferred approach for SSDs, but\nwith conventional disks I think the performance would be poor? In 1231\nI implemented the var-sized CSF with a skip list, similar to a posting\nlist. I think we should add that here too and we can still keep the\nadditional index that stores the pointers? We could have two readers:\none that allows random-access and loads the pointers into RAM (or uses\nMMAP as you mentioned), and a second one that doesn't load anything\ninto RAM, uses the skip lists and only allows iterator-based access?\n\nAbout updating CSF: I hope we can use parallel indexing for that. In\nother words: It should be possible for users to use parallel indexes\nto update certain fields, and Lucene should use the same approach\ninternally to store different \"generations\" of things like norms and CSFs. ",
            "author": "Michael Busch",
            "id": "comment-12795963"
        },
        {
            "date": "2010-01-04T14:53:23+0000",
            "content": "Is this patch for flex, as it contains CodecUtils and so on?\n\nActually it's intended for trunk; I was thinking this should land\nbefore flex (it's a much smaller change, and it's \"isolated\" from\nflex), and so I wrote the CodecUtil/BytesRef basic infrastructure,\nthinking flex would then cutover to them.\n\n\nHmm, so random-access would obviously be the preferred approach for SSDs, but\nwith conventional disks I think the performance would be poor? In 1231\nI implemented the var-sized CSF with a skip list, similar to a posting\nlist. I think we should add that here too and we can still keep the\nadditional index that stores the pointers? We could have two readers:\none that allows random-access and loads the pointers into RAM (or uses\nMMAP as you mentioned), and a second one that doesn't load anything\ninto RAM, uses the skip lists and only allows iterator-based access?\n\nThe intention here is for this (\"index values\") to replace field\ncache, but not aim (initially at least) to do much more.  Ie, it's\n\"meant\" to be a RAM resident (either via explicit slurping-into-RAM or\nvia MMAP).  So the SSD or spinning magnets should not be hit on\nretrieval.\n\nIf we add an iterator API, I think it should be simpler than the\npostings API (ie, no seeking, dense (every doc is visited,\nsequentially) iteration).\n\n\nIt looks like ByteRef is very similar to Payload? Could you use that instead \nand extend it with the new String constructor and compare methods?\n\nGood point!  I agree.  Also, we should use BytesRef when reading the\npayload from TermsEnum.  Actually I think Payload, BytesRef, TermRef\n(in flex) should all eventually be merged; of the three names, I think\nI like BytesRef the best.  With *Enum in flex we can switch to\nBytesRef.  For analysis we should switch PayloadAttribute to BytesRef,\nand deprecate the methods using Payload?  Hmmm... but PayloadAttribute\nis an interface.\n\n\nSo it looks like with your approach you want to support certain\n\"primitive\" types out of the box, such as byte[], float, int, String?\n\nActually, all \"primitive\" types (ie, byte/short/int/long are\n\"included\" under int, as well as arbitrary bit precision \"between\"\nthose primitive types).  Because the API uses a method invocation (eg\nIntSource.get) instead of direct array access, we can \"hide\" how many\nbits are actually used, under the impl.  Same is true for float/double\n(except we can't [easily] do arbitrary bit precision here... just 4 or\n8 bytes).\n\n\nIf someone has custom data types, then they have, similar as with\npayloads today, the byte[] indirection?\n\nRight, byte[] is for String, but also for arbitrary (opaque to Lucene)\nextensibility.  The six anonymous (separate package private classes)\nconcrete impls should give good efficiency to fit the different use\ncases.\n\n\nThe code I initially wrote for 1231 exposed IndexOutput, so that one\ncan call write*() directly, without having to convert to byte[]\nfirst. I think we will also want to do that for 2125 (store attributes\nin the index). So I'm wondering if this and 2125 should work\nsimilarly?\n\nThis is compelling (letting Attrs read/write directly), but, I have\nsome questions:\n\n\n\tHow would the random-access API work?  (Attrs are designed for\n    iteration).  Eg, just providing IndexInput/Output to the Attr\n    isn't quite enough \u2013 the encoding is sometimes context dependent\n    (like frq writes the delta between docIDs, the symbol table needed\n    when reading/writing deref/sorted).  How would I build a random\n    access API on top of that?  captureState-per-doc is too costly.\n    What API would be used to write the shared state, ie, to tell the\n    Attr \"we now are writing the segment, so you need to dump the\n    symbol table\".\n\n\n\n\n\tHow would the packed ints work?  EG say my ints only need 5 bits.\n    (Attrs are sort of designed for one-value-at-once).\n\n\n\n\n\tHow would the \"symbol table\" based encodings (deref, sorted) work?\n    I guess the attr would need to have some state associated with\n    it, and when I first create the attr I need to pass it segment\n    name, Directory, etc, so it opens the right files?\n\n\n\n\n\tI'm thinking we should still directly support native types, ie,\n    Attrs are there for extensibility beyond native types?\n\n\n\n\n\tExposing single attr across a multi reader sounds tricky \u2013\n    LUCENE-2154 (and, we need this for flex, which is worrying me!).\n    But it sounds like you and Uwe are making some progress on that\n    (using some under-the-hood Java reflection magic)... and this\n    doesn't directly affect this issue, assuming we don't expose this\n    API at the MultiReader level.\n\n\n\n\nThinking out loud: Could we have then attributes with\nserialize/deserialize methods for primitive types, such as float?\nCould we efficiently use such an approach all the way up to\nFieldCache? It would be compelling if you could store an attribute as\nCSF, or in the postinglist, retrieve it from the flex APIs, and also\nfrom the FieldCache. All would be the same API and there would only be\none place that needs to \"know\" about the encoding (the attribute).\n\nThis is the grand unification of everything   I like it, but, I\ndon't want that future utopia to stall our progress today... ie I'd\nrather do something simple yet concrete, now, and then work step by\nstep towards that future (\"progress not perfection\").\n\nThat said, if we can get some bite sized step in, today, towards that\nfuture, that'd be good.\n\nEg, the current patch only supports \"dense\" storage, ie it's assumed\nevery document will have a value, because it's aiming to replace field\ncache.  If we wanted to add sparse storage... I think that'd\nrequire/strongly encourage access via a postings-like iteration API,\nwhich I don't see how to take a baby step towards \n\nI do think it would be compelling for an Attr to \"only\" have to expose\nread/write methods, and then the Attr can be stored in CSF or\npostings, but I don't see how to make an efficient random-access API\non top of that.  I think it's in LUCENE-2125 where we should explore\nthis.\n\nNorms and deleted docs should be able to eventually switch to CSF.\n\nIn fact, norms should just be a FloatSource, with default impl being\nthe 1-byte float encoding we use today.  This then gives apps full\nflexibility to plugin their own FloatSource.\n\nFor deleted docs we should probably create a BoolSource.\n\n\nAbout updating CSF: I hope we can use parallel indexing for that. In\nother words: It should be possible for users to use parallel indexes\nto update certain fields, and Lucene should use the same approach\ninternally to store different \"generations\" of things like norms and\nCSFs.\n\nThat sounds great, though, I think we need a more efficient way to\nstore the changes.  Ie, norms rewrites all norms on any change, which\nis costly.  It'd be better to have some sort of delta format, where\nyou sparsely encode docID + new value, and then when loading we merge\nthose on the fly (and, segment merging periodically also merges &\ncommits them).\n\n\nYeah, that's where I got kind of stuck with 1231: We need to figure\nout how the public API should look like, with which a user can add CSF\nvalues to the index and retrieve them. The easiest and fastest way\nwould be to add a dedicated new API. The cleaner one would be to make the whole\nDocument/Field/FieldInfos API more flexible. LUCENE-1597 was a first attempt.\n\nRight, but LUCENE-1597 is another good but far-away-from-landing\ngoal.  I think a dedicated API is fine for the atomic types.  Field\ncache today is a dedicated API...\n\nI guess to sum up my thoughts now (but I'm still mulling...):\n\n\n\tI think the random-access-field-cache-like-API should be separate\n    from the designed-for-iteration-from-a-file postings API.\n\n\n\n\n\tAttrs for extensibilty could be compelling, but I don't see how to\n    build an [efficient] random access API on top of Attrs.  It would\n    be very elegant only having to add a read/write method to your\n    Attr, but, that's not really enough for a full codec.\n\n\n\n\n\tI don't think we should hold up adding direct support for atomic\n    types until/if we can figure out how to add Attrs.  Ie I think we\n    should do this in two steps.  The current patch is [roughly] step\n    1, and I think should be a compelling replacement for field cache.\n    Memory usage and GC cost of string sorting should be much lower\n    than field cache.\n\n\n\nI'm also still mulling on these issues w/ the current patch:\n\n\n\tHow could we use index values to efficiently maintain stats needed\n    for flexible scoring (LUCENE-2187).\n\n\n\n\n\tCurrent patch doesn't handle merging yet.\n\n\n\n\n\tCould norms/deleted docs \"conceivably\" cutover to index values\n    API?\n\n\n\n\n\tWhat \"dedicated API\" for indexing & sorting.\n\n\n\n\n\tRun basic perf tests to see cost of using method instead of direct\n    array.\n\n ",
            "author": "Michael McCandless",
            "id": "comment-12796200"
        },
        {
            "date": "2010-01-16T18:34:30+0000",
            "content": "Attaching my current state \u2013 things are still very very rough, and there are contrib/remote test failures.\n\nThis patch has an initial integration with Lucene, enabling a Field to set how its values should be indexed into CSF... values are merged during indexign, and I created FieldComparators to use them for sorting.\n\nThere are still some outright hacks in there, under nocommits (eg how SegmentInfo.files() computes the CSF files)...\n\nI'm now thinking we should wrap up & land flex, before going much further on this feature... ",
            "author": "Michael McCandless",
            "id": "comment-12801250"
        },
        {
            "date": "2010-01-20T10:10:00+0000",
            "content": "I did a RAM cost estimation of FieldCache vs the approach in this\npatch (attached mem.py).  I took a 5M doc Wikipedia index I have, and\ncomputed how much RAM is used by FieldCache for STORE ONLY\n(.getStrings) and for SORTING (.getStringIndex), vs the patch, on\nthe title field.  I assume all titles are unique:\n\n\nSTORE ONLY\n  32 bit current: 449.0 MB\n  32 bit   patch: 136.0 MB [69.7% smaller]\n  64 bit current: 487.1 MB\n  64 bit   patch: 136.0 MB [72.1% smaller]\n\nSORTING\n  32 bit current: 468.0 MB\n  32 bit   patch: 149.7 MB [68.0% smaller]\n  64 bit current: 506.2 MB\n  64 bit   patch: 149.7 MB [70.4% smaller]\n\n\n\nThis is a sizable RAM savings!  Also, FieldCache creates 2X the\nobjects (because, I think, String creates a separate char[] to hold\nthe characters), whereas with the patch 2 or 3 [shared] arrays are\ncreated, so there's obviously much less GC load too. ",
            "author": "Michael McCandless",
            "id": "comment-12802778"
        },
        {
            "date": "2010-06-29T20:30:40+0000",
            "content": "Attaching current status. I ported mikes patch to current trunk and added some tests here and there.\nCurrent status is: \n\n\tall tests pass\n\tsupports CompoundFile\n\tseveral no-commits still present\n\n\n\nnext steps might be cleaning up most of the no-commits and maybe a first sketch on a Iterator API.\n\nMike do you mind if I take this? ",
            "author": "Simon Willnauer",
            "id": "comment-12883681"
        },
        {
            "date": "2010-06-30T10:15:30+0000",
            "content": "Great \u2013 thanks for pushing this forward Simon!\n\nMike do you mind if I take this?\n\nPlease do! ",
            "author": "Michael McCandless",
            "id": "comment-12883872"
        },
        {
            "date": "2010-08-06T18:18:30+0000",
            "content": "Attaching my current state to start iteration over the code as this patch contains may new things.\n\n\tAll tests are passing\n\thandles merging in a generic way\n\thandles deletes\n\timplements a  dedicated iterator API which operates on the files directly\n\tunifies the Values API like Reader, Writer, Source and ValuesEnum\n\tenables accessing Values via DirectoryReader (no optimized index needed)\n\tadd a proposal to utilize Attributes on a per Field basis\n\n\n\nI'd like to throw this out and get initial feedback as quite a couple of things need to be discussed before we can proceed with this one. There are still a whole lot of nocommits in the code and some of the lower - level changes need review and feedback by people with more experience down there (Mike?  \n\nI'd really appreciate any comments especially on the API as this most important to me right now.\n\nI haven't had time to implement / propose something to use mmap for Source but this would be next on the list.\nIf you have questions please join!!\n\nAgain, this is nothing which is really close to be committable but we are getting closer!\nI would also like to move this to a branch as this seems to grow and a feature branch would be more convenient.  ",
            "author": "Simon Willnauer",
            "id": "comment-12896108"
        },
        {
            "date": "2010-08-06T18:30:48+0000",
            "content": "I'd really appreciate any comments especially on the API as this most important to me right now.\n\nCould you show some examples of the most efficient way to use this API?\ni.e. an example that shows both how to index a document with a CSF, and then how to iterate over all values of a CSF (or get the value for a specific set of documents). ",
            "author": "Yonik Seeley",
            "id": "comment-12896112"
        },
        {
            "date": "2010-08-06T18:59:12+0000",
            "content": "Hey Yonik,\nCould you show some examples of the most efficient way to use this API?\n\nSure! While it's already late over here I am happy to provide you those two examples. This is how you can index CSF with this Attribute approach:\n\n\n \n    RAMDirectory dir = new RAMDirectory();\n    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(Version.LUCENE_40, new SimpleAnalyzer(Version.LUCENE_40)));\n    Document doc = new Document();\n    Fieldable fieldable = new AttributeField(\"myIntField\");\n    ValuesAttribute valuesAttribute = fieldable.attributes().addAttribute(ValuesAttribute.class);\n    valuesAttribute.setType(Values.PACKED_INTS);\n    valuesAttribute.ints().set(100);\n    doc.add(fieldable);    \n    writer.addDocument(doc);\n    writer.close();\n\n\n\nThis is how get the values back via source or the ValuesEnum:\n\n\n    IndexReader reader = IndexReader.open(dir);\n    // this might be integrated into Fields eventually\n    Reader indexValues = reader.getIndexValues(\"myIntField\"); // can get cached version too via reader.getIndexValuesCache();\n    Source load = indexValues.load();\n    long value = load.ints(0);\n    System.out.println(value);\n\n    // or get it from the enum\n    ValuesEnum intEnum = indexValues.getEnum();\n    ValuesAttribute attr = intEnum.getAttribute(ValuesAttribute.class);\n    while(intEnum.nextDoc() != ValuesEnum.NO_MORE_DOCS) {\n      System.out.println(attr.ints().get());\n    }\n\n\n\nI guess this should make it at least easier to get started. I actually expect people saying ValuesEnum looks very much like DocsEnum which is certainly correct. Yet, I didn't integrate ValuesEnum into Fields etc. for simplicity as changes to Fields touches lot of code. Having ValuesEnum being a \"stand-alone\" API makes iterating and development easier and a cut over to DocsEnum would be easy API wise as it already implements DocIdSetIterator. \n\nWith that in mind, the use of ValuesAttribute makes sense too - with a stand-also API this would be obsolet and could be direct part of ValuesEnum.\n\nWhat I don't like about DocsEnum is the BulkReadResult class and its relative being a first class citizen in DocsEnum. With CSF not every DocsEnum iterates over <id,freq>* - but maybe we can move that to an attribute and make a more general abstract class.  The Attributes on those enums don't introduce a real overhead but solve lots of extendability problems though. ",
            "author": "Simon Willnauer",
            "id": "comment-12896122"
        },
        {
            "date": "2010-08-09T13:07:05+0000",
            "content": "Great work Simon!\n\nNow that FieldCache has cut over to shared byte[] blocks, them mem\ngains for CSF when storing byte[] data are mostly gone.\n\nBut, there is still important benefits with CSF:\n\n\n\tThe full image is stored on-disk (= much faster than uninversion\n    (& sometimes sorting) that FieldCache does, on startup)\n\n\n\n\n\tYou can specify all 6 combinations of variable/fixed length X\n    straight/deref/sorted.  FieldCache is either var-length X deref\n    (FieldCache.getTerms) or var-length X sorted\n    (FieldCache.getTermsIndex).\n\n\n\n\n\tIt should be more extensible, ie, you can make your own attrs to\n    store whatever you want.  EG we should be able to use this to\n    store the flex scoring stats (LUCENE-2392).\n\n\n\nThe end-user API is rather cumbersome now (ie, that the user must\ninteract directly w/ attrs).  It seems like we should have a sugar\nlayer on top, eg an IntField(Type) and I can do IntField.set/get.\n\nAlso... maybe we should use Attrs the way NumericField does.  Ie, for\nCSF we'd have a TokenStream (single valued, for now anyway), and then\nattrs could be added to it.  If we can get attr serialization\n(LUCENE-2125) online, then we can refactor all the read/write code in\nthis issue as the default attr serializers?  And, then, indexer would\nhave no special code for CSF in particular.  It just asks attrs to\nserialize themselves...\n\nShouldn't FloatsRef be FloatRef (same for IntsRef)?  It's ref'ing a\nsingle value right? ",
            "author": "Michael McCandless",
            "id": "comment-12896530"
        },
        {
            "date": "2010-08-09T16:50:55+0000",
            "content": "\nIt should be more extensible, ie, you can make your own attrs to\nstore whatever you want. EG we should be able to use this to\nstore the flex scoring stats (LUCENE-2392).\n\nThis is actually the first real use-case together with the norms which is kind of part of LUCENE-2392 anyway\n\n\nThe end-user API is rather cumbersome now (ie, that the user must\ninteract directly w/ attrs). It seems like we should have a sugar\nlayer on top, eg an IntField(Type) and I can do IntField.set/get.\nYeah I guess lots of users would have a rather hard time with that. I remember Grant saying that he tries to explain Document and Fields since every in his trainings and with users in mind this should be done with least amount of changes. Nevertheless this is something which should be fixed outside of this particular issue, LUCENE-2310 would be one I could think of. Guess I need to talk to chrismale on Friday about that.\n\n\n\n\nAlso... maybe we should use Attrs the way NumericField does. Ie, for\nCSF we'd have a TokenStream (single valued, for now anyway), and then\nattrs could be added to it. If we can get attr serialization\n(LUCENE-2125) online, then we can refactor all the read/write code in\nthis issue as the default attr serializers? And, then, indexer would\nhave no special code for CSF in particular. It just asks attrs to\nserialize themselves...\nLUCENE-2125 is something which would be nice to have together with CSF. Yet I don't think it depends on each other but it should use the same or very closely related APIs eventually. LUCENE-2125 has different problems to tackle first I guess - but I am closely following that! I will update that patch to make use of the \n{NumericField}\n - lets call it - work-around to make this patch \"less hairy\". Still hairy but I like the idea of using TokenStream to attach the ValuesAttribute.\n\n\nShouldn't FloatsRef be FloatRef (same for IntsRef)? It's ref'ing a\nsingle value right?\n\nYes and no. I was too lazy to add all the capabilities \n{BytesRef}\n has but I could imagine that this can benefit from being able to hold more values - maybe a entire page when paging is used.  If it only holds a single value we don't need offset and length too. I will leaf it like that for now, can still change it later if it turns out that we don't need this flexibility.\n\nI guess I will move the ValuesEnum down to Fields and FieldsEnum soon. I don't think we should confuse this with an DocsEnum since DocsEnum is so closely related to Terms and has explicit getters for freq() though. DocIdSetIterator seems to be fine for that purpose - while the AttributeSource could be pulled up. ",
            "author": "Simon Willnauer",
            "id": "comment-12896614"
        },
        {
            "date": "2010-09-24T14:42:13+0000",
            "content": "We should get the BytesHash in first to make this patch little simpler. I don't wanna refactor TermsHashPerField in here.  ",
            "author": "Simon Willnauer",
            "id": "comment-12914488"
        },
        {
            "date": "2010-09-24T14:44:09+0000",
            "content": "I would want to move this to a branch for further development. If nobody objects I'm gonna move forward within the next days.\n\nsimon ",
            "author": "Simon Willnauer",
            "id": "comment-12914490"
        },
        {
            "date": "2010-09-24T14:54:18+0000",
            "content": "I would want to move this to a branch for further development. If nobody objects I'm gonna move forward within the next days.\n\n+1\n\nIn my opinion, if its helpful to use a branch for a feature like this, we should not hesitate!\nWith a lot of development on trunk, big patches make it difficult for anyone to get involved.\n\nAdditionally its extremely difficult to iterate, because its hard to see the differences between iterations.\nBut say, with the flexible indexing branch, this history is preserved since it was done in a branch.\nSo I am able to just click 'view merged revisions' in my IDE and see all that history. ",
            "author": "Robert Muir",
            "id": "comment-12914494"
        },
        {
            "date": "2010-10-11T06:29:59+0000",
            "content": "Updates patch to trunk - all tests pass. Since LUCENE-1990 and LUCENE-2662 have been committed some of the improvement / refactorings in this patch became obsolet. I update everything to current trunk and made the Field / Values API somewhat easier to use. I would go a create a branch based on this patch in the next days.\n\nAnybody preferences on the name? I would suggest \"values_branch\" or \"perdoc-payloads\" but it really doesn't matter though. Suggestions? ",
            "author": "Simon Willnauer",
            "id": "comment-12919729"
        },
        {
            "date": "2010-10-11T09:53:25+0000",
            "content": "Updates patch to trunk - all tests pass\n\nPatch is looking good....\n\nThere are still many nocommits but most look like they could become TODOs?\n\nDo you have a high level sense of what's missing before we can commit to trunk?\n\nAnybody preferences on the name? I would suggest \"values_branch\" or \"perdoc-payloads\" but it really doesn't matter though. Suggestions?\n\nHow about docvalues?  You don't need the _branch part since it'll be at http://svn.apache.org.../branches/docvalues. ",
            "author": "Michael McCandless",
            "id": "comment-12919769"
        },
        {
            "date": "2010-10-11T15:18:06+0000",
            "content": "\nThere are still many nocommits but most look like they could become TODOs?\nDo you have a high level sense of what's missing before we can commit to trunk?\n\nYes and No , here is my roadmap for this issue. We have 47 nocommit pending where about the half of it can be TODOs while the other half of it are rather easy task and should be fixed before we go to trunk.\nThese are the major steps I would like to finish until we land this on trunk\n\n\n\tImplement bulk copies for merging where possible. Currently there are still some value types not bulk copied and the ones which are only do if there are no deletes. Yet, the deletes thing I would make a TODO for now - we can still make that more efficient once we are on trunk. If I recall correctly figuring out the next deleted document is still a linear problem (I need to iterate through deletes), right? I guess that would be easier if I could figure out the next one so see if bulks are reasonable - maybe an invalid concern though.\n\n\n\n\n\tExposing the API via Fields / IndexReader. I think we should expose the Iterator API via Fields just like Terms is today. Currently it doesn't feel very natural to get the ValuesEnum via IR.\n\tRethink the Source API - I get the feeling that we don't really need the Source class but could rather use a Random Access Enum like Terms where we can see back and forth depending on how we loaded the fields values. We could actually unify the iterator API and random access which would catch two birds with one stone. internally we simply use the *Refs to set the actual values, default values would no be needed anymore (would save some code / branches internally) and the user would not have to access two different APIs. Additionally we could expose bulk reads just like BulkReadResult in DocsEnum to obtain all values in an array. Maybe if we wanna populate FieldsCache from it. I think we won't have perf. losts due to that since there is not really an overhead compared to the get() call on Source. - Reminds me I need to think about how we use that with sorted values.... If we keep Source we should at least make it implement ValuesEnum so we can use it as enumeration if they are in mem already.\n\n\n\n\n\tTo do merging for byte values correctly we need to figure out how to specify the comparator for each field. I don't have a concrete idea for this but I think this should somehow go into IndexWriterConfig in a per field map. Thougths?\n\n\n\n\nRemaining nocommits could be converted into TODOs - I think we can do so with the following\n\n\n\tEvaluate if we can decide if a Bytes Payload should be stored as straight or as fixed which would make it easier for the user to use the byte variants.\n\tEvaluate if we need String variants or if they can simple be solved with the byte ones\n\tWe should have some king of compatibility notion so that slightly different segments can be merged like fixed vs. var bytes float32 vs. float64.\n\tFor a cleaner transition we should create a sep. SortField that always uses index values.\n\texplore a better way to obtain all dat / idx fiels in SegmentInfo to do segment merges for index values.\n\tBytesValueProcessor should be thread private but I will leave that as a todo since this code might change anyway once realtime lands on trunk though. Not super urgent for now.\n\tFix some exception handling issues especially in MultiSource & MultiValuesEnum\n\tFix the singed / unsigned limitations in Ints implementation\n\tExplore ways to preven Ints impl do two method calls maybe we can expose PackedInts directly somehow\n\n\n\nHow about docvalues? You don't need the _branch part since it'll be at http://svn.apache.org.../branches/docvalues.\nOK ",
            "author": "Simon Willnauer",
            "id": "comment-12919864"
        },
        {
            "date": "2010-10-12T06:20:41+0000",
            "content": "created branch at docvalues and committed the last patch at r1021636. I think the next steps are adding a fix version \"docvalues\" to JIRA and create new issues according to the \"roadmap\" above. Once we are through with the mandatory stuff and documentation we can land this on trunk. Thoughts?\n\nI'm not sure if we should continue on this issue or close it and create a new \"top level\" one and spawn issues from there.\n\nsimon ",
            "author": "Simon Willnauer",
            "id": "comment-12920110"
        },
        {
            "date": "2010-10-12T10:08:11+0000",
            "content": "Implement bulk copies for merging where possible. \n\nI don't think this should block landing on trunk?  (Even in the non-deletes case).\n\nBut, yes, searching for next del doc is a linear op, but a very small constant in front (at least OpenBitSet.nextSetBit, though del docs are currently a BitVector), yet is very much worth it once we get the bulk copying in since presumably big chunks of docs can be bulk copied.\n\nExposing the API via Fields / IndexReader. I think we should expose the Iterator API via Fields just like Terms is today. Currently it doesn't feel very natural to get the ValuesEnum via IR.\n\nAhh that does sound like the right place.\n\nMaybe if we wanna populate FieldsCache from it. \n\nWe should be careful here \u2013 it's best if things consume the docvalues instead of double-copying into the FC. ",
            "author": "Michael McCandless",
            "id": "comment-12920151"
        },
        {
            "date": "2010-11-24T18:29:18+0000",
            "content": "I think this is very close!!\n\n\n\tUsing attr source as the way to specify the docValue is nice in\n    that we get full extensibility, but, it's also heavyweight\n    compared to a dedicated API (ie, .setIntValue, etc.).  So I think\n    this means apps that use doc values really must re-use their Field\n    instances (if they are using doc values) else indexing performance\n    will likely take a good hit.\n\n\n\n\n\tValuesField is nice sugar on top (of the attr)  Can you add some\n    jdocs to ValuesField? EG it's not stored/indexed.  It's OK to have\n    same field name as existing field (hmm... is it)?  Etc.\n\n\n\n\n\tDid you want to make FieldsConsumer.addValuesField abstract?\n\n\n\n\n\tThe javadoc above DocValues.Source is wrong \u2013 Source is not just\n    for ints.\n\n\n\n\n\tYou can change jdocs like \"This feature is experimental and the\n    API is free to change in non-backwards-compatible ways.\" to\n    @lucene.experimental   (eg in Values.java)\n\n\n\n\n\tSo, you're not allowed to change the DocValues type for a field\n    once you've set it the first time... and, also, segments cannot be\n    merged if the same field has different value types.  I'm thinking\n    it's really important now to carry over the same FieldInfos from\n    the last segment when opening the writer (LUCENE-1737)... because\n    hitting that IllegalStateExc during merge is a trap.  This would\n    let us change that IllegalStateExc into an assert (in\n    SegmentMerger) and also turn the assert back on in FieldsConsumer.\n\n\n\n\n\tShould we rename MissingValues to MissingValue? Ie it holds the\n    single value for your type that represents \"missing\"?\n\n\n\n\n\tWe need better names than PagedBytes.fillUsingLengthPrefix,2,3,4\n    heh.\n\n\n\n\n\tIt'd be nice to have a more approachable test case that shows the\n    \"simple\" way to index doc values, ie using ValuesField instead of\n    getting the attr, getting the intsRef, setting it, etc.  I think\n    such an \"example\" should be very compact right?\n\n ",
            "author": "Michael McCandless",
            "id": "comment-12935428"
        },
        {
            "date": "2010-11-25T10:40:36+0000",
            "content": "I think this is very close!!\nHeh, I strongly agree!\n\n\n    Using attr source as the way to specify the docValue is nice in\n    that we get full extensibility, but, it's also heavyweight\n    compared to a dedicated API (ie, .setIntValue, etc.).  So I think\n    this means apps that use doc values really must re-use their Field\n    instances (if they are using doc values) else indexing performance\n    will likely take a good hit.\nWell it is a nice way of extending field but I am not sure if we\nshould keep it since it is heavy weight. We could get rid of\nValuesAttribute for landing on trunk and work on making field\nextendible - which is desperately needed anyway. I was also thinking\nthat the ValuesEnum doesn't need the ValuesAttribute per se. it would\nbe more intuitive to have getter on ValuesEnum too. I just really hate\nthose instanceof checks on fields.\n\n\n   ValuesField is nice sugar on top (of the attr)  Can you add some\n    jdocs to ValuesField? EG it's not stored/indexed.  It's OK to have\n    same field name as existing field (hmm... is it)?  Etc.\nYeah - until here I haven't done much javadoc but that is on top of\nthe list. I will start adding JavaDoc to main classes of the API and\nValuesField is 100% a main class of it.\nBTW. it is ok to have the same name as a existing field.\n\nDid you want to make FieldsConsumer.addValuesField abstract?\nThat is a leftover - I will remove it.\n\nThe javadoc above DocValues.Source is wrong \u2013 Source is not just for ints.\nTrue - see above that class had a different purpose back in the days\nwhere it was a patch \n\n\nYou can change jdocs like \"This feature is experimental and the\nAPI is free to change in non-backwards-compatible ways.\" to\n @lucene.experimental   (eg in Values.java)\n\nyeah - its good to have stuff like that left!!!!!  yay!\n\n So, you're not allowed to change the DocValues type for a field\n once you've set it the first time... and, also, segments cannot be\nmerged if the same field has different value types.  I'm thinking\nit's really important now to carry over the same FieldInfos from\nthe last segment when opening the writer (LUCENE-1737)... because\nhitting that IllegalStateExc during merge is a trap.  This would\nlet us change that IllegalStateExc into an assert (in\nSegmentMerger) and also turn the assert back on in FieldsConsumer.\n\nI think that should not block us from moving forward and landing on trunk ey?\n\n\nShould we rename MissingValues to MissingValue? Ie it holds the single\nvalue for your type that represents \"missing\"?\n\nTrue, I was also thinking to rename some of the classes like\nValues -> DocValueType\nPackedIntsImpl -> Ints\n\n\nWe need better names than PagedBytes.fillUsingLengthPrefix,2,3,4\n\nhehe yeah - lemme change the one I added and lets fix the rest on\ntrunk. I will open an issue once I have a reliable inet connection\nagain.\n\n\n It'd be nice to have a more approachable test case that shows the\n\"simple\" way to index doc values, ie using ValuesField instead of\ngetting the attr, getting the intsRef, setting it, etc.  I think\nsuch an \"example\" should be very compact right?\n\ndone on my checkout!\n\nso on my list there are the following topics until landing:\n\n\n\tmissing testcase for addIndexes and a simple one to show how to use the api\n\tsplit up exiting tests in smaller tests - they test too much and\nthey are hard to understand\n\tAdd JavaDoc to main classes like DocValues, Source, ValuesEnum, ValuesField\n\tDocument the different types\n\tConsistent class naming - see above\n\tenable ram usage tracking for all DocValuesProducer to support\nflush by RAM usage\n\n\n\nThat seems very very close to me. Lets see how much I get done on my\nflight to boston  ",
            "author": "Simon Willnauer",
            "id": "comment-12935713"
        },
        {
            "date": "2010-11-26T11:20:34+0000",
            "content": "BTW. it is ok to have the same name as a existing field.\n\nIt is, usually... but we should add a test to assert this is still the\ncase for other field + ValuesField?\n\n\nI'm thinking it's really important now to carry over the same FieldInfos from the last segment when opening the writer (LUCENE-1737)... because hitting that IllegalStateExc during merge is a trap.\n\nI think that should not block us from moving forward and landing on trunk ey?\n\nIt makes me mighty nervous though... I'll try to get that issue done\nsoon.\n\n\nWell it is a nice way of extending field but I am not sure if we\nshould keep it since it is heavy weight. \n\nThe ValuesAttr for ValuesField is actually really heavyweight.  Not\nonly must it fire up an AttrSource, but then ValuesAttrImpl itself has\na field for each type.  Worse, for the type you do actually use, it's\nthen another object eg FloatsRef, which in turn holds\narray/offset/len, a new length 1 array, etc.\n\nMaybe we shouldn't use attrs here?  And instead somehow let\nValuesField store a single value as it's own private member?\n\nFloatsRef, LongsRef are missing the ASL header.  Maybe it's time to\nrun RAT  ",
            "author": "Michael McCandless",
            "id": "comment-12935977"
        },
        {
            "date": "2010-11-26T12:35:10+0000",
            "content": "\nIt is, usually... but we should add a test to assert this is still the\ncase for other field + ValuesField?\n\nI already implemented a simple testcase that shows that this works as an example (I will commit that soon though) but I think we need to add another test that ensures that this works with all types of DocValues though. Yet, I work on making the test more \"atomic\" and test only a single thing anyway so i will add that too.\n\nIt makes me mighty nervous though... I'll try to get that issue done soon.\nWell until then I just go on and get the remaining stuff done here.\n\n\nMaybe we shouldn't use attrs here? And instead somehow let ValuesField store a single value as it's own private member?\nI more and more think we can nuke ValuesAttribute completely since its other purpose on ValuesEnum is somewhat obsolete too. It is actually a leftover from earlier days where I was experimenting with using DocEnum to serve CSF too. There it would have made sense though but now we can provide a dedicated API. It still bugs me that Field is so hard to extend. We really need to fix that soon!\n\nI think what we should do is extend AbstractField and simply use a long/double/BytesRef and force folks to add another field instance if they want to have it indexed and stored.\nMaybe it's time to run RAT\n+1 \n ",
            "author": "Simon Willnauer",
            "id": "comment-12935994"
        },
        {
            "date": "2010-11-27T23:07:07+0000",
            "content": "Is there any test cases that cover the new FieldComparators that use the doc values?\n\nI think a good test case would be to sort w/ FieldCache and then again w/ doc values and verify they match... ",
            "author": "Michael McCandless",
            "id": "comment-12964464"
        },
        {
            "date": "2010-11-30T14:48:39+0000",
            "content": "Is there any test cases that cover the new FieldComparators that use the doc values?\nnot yet, I added it to my internal roadmap to land on trunk. I just committed my latest changes including a simple testcase to show how to use the API and used bytes tracking. \n\nhere is a list of what is missing:\n\n\n  /*\n   * TODO:\n   * Roadmap to land on trunk\n   *   - Cut over to a direct API on ValuesEnum vs. ValuesAttribute \n   *   - Add documentation for:\n   *      - Source and ValuesEnum\n   *      - DocValues\n   *      - ValuesField\n   *      - ValuesAttribute\n   *      - Values\n   *   - Add @lucene.experimental to all necessary classes\n   *   - Try to make ValuesField more lightweight -> AttributeSource\n   *   - add test for unoptimized case with deletes\n   *   - add a test for addIndexes\n   *   - split up existing testcases and give them meaningfull names\n   *   - use consistent naming throughout DocValues\n   *     - Values -> DocValueType\n   *     - PackedIntsImpl -> Ints\n   *   - run RAT\n   *   - add tests for FieldComparator FloatIndexValuesComparator vs. FloatValuesComparator etc.\n   */\n\n\n\nonce I am through with it I will create a new issue and create the final patch so we can iterate over it if needed.\n\nsimon ",
            "author": "Simon Willnauer",
            "id": "comment-12965242"
        },
        {
            "date": "2010-12-06T19:47:25+0000",
            "content": "Whew... this interface is more expansive than I thought it would be (but I guess it's really many issues rolled into one... like sorting, caching, etc).\nSo it seems like DocValuesEnum is the traditional lowest level \"read the index\", and Source is a cached version of that?\n\nA higher level question I have is why we're not reusing the FieldCache for caching/sorting? ",
            "author": "Yonik Seeley",
            "id": "comment-12968381"
        },
        {
            "date": "2010-12-06T21:21:12+0000",
            "content": "Whew... this interface is more expansive than I thought it would be (but I guess it's really many issues rolled into one... like sorting, caching, etc).\nsorry about that \n\nSo it seems like DocValuesEnum is the traditional lowest level \"read the index\", and Source is a cached version of that?\nNot quiet DocValuesEnum is an iterator based access to the DocValues which does not load everything to memory while Source is a entirely Ram-Resident offering random access to values similar to field cache. Yet, you can also obtain a DocValuesEnum from a Source since its already in memory. \n\nA higher level question I have is why we're not reusing the FieldCache for caching/sorting?\nYou mean as a replacement for Source? - For caching what we did in here is to leave it to the user to do the caching or cache based on Source instance how would that relate to FieldCache in your opinion? ",
            "author": "Simon Willnauer",
            "id": "comment-12968416"
        },
        {
            "date": "2011-01-09T19:29:41+0000",
            "content": "Out of curiosity, re: LUCENE-2312, are we planning on putting CSF into Lucene 4.x?  What's left to be done? ",
            "author": "Jason Rutherglen",
            "id": "comment-12979395"
        },
        {
            "date": "2011-01-09T20:47:18+0000",
            "content": "Out of curiosity, re: LUCENE-2312, are we planning on putting CSF into Lucene 4.x? What's left to be done?\nwe are very close - to land on trunk there is about an evening of work left. JDoc is missing here and there plus some tests for FieldComparators - thats it! ",
            "author": "Simon Willnauer",
            "id": "comment-12979404"
        },
        {
            "date": "2011-01-09T21:12:48+0000",
            "content": "we are very close - to land on trunk there is about an evening of work left. JDoc is missing here and there plus some tests for FieldComparators - thats it!\n\nNice!  Once it's in I'll try to get started on the RT field cache/doc values, which can likely be implemented and tested somewhat independent of the RT inverted index. ",
            "author": "Jason Rutherglen",
            "id": "comment-12979407"
        },
        {
            "date": "2011-04-08T21:57:14+0000",
            "content": "I'm wondering if there is a limitation on whether or not we can randomly access the doc values from the underlying Directory implementation, rather than need to load all the values directly into the main heap space.  This seems doable, and if so let me know if I can provide a patch. ",
            "author": "Jason Rutherglen",
            "id": "comment-13017679"
        },
        {
            "date": "2011-04-09T09:13:58+0000",
            "content": "I'm wondering if there is a limitation on whether or not we can randomly access the doc values from the underlying Directory implementation, rather than need to load all the values directly into the main heap space. This seems doable, and if so let me know if I can provide a patch.\n\nthe current implementation to access docValues not loaded into memory uses DocIdSetIterator as its parent interface so it works only in one direction currently. changing this to a random access \"seekable\" API should be not too hard. \nLook at http://svn.apache.org/repos/asf/lucene/dev/branches/docvalues/lucene/src/java/org/apache/lucene/index/values/DocValuesEnum.java\n\nsimon\n ",
            "author": "Simon Willnauer",
            "id": "comment-13017822"
        },
        {
            "date": "2011-04-09T14:58:38+0000",
            "content": "changing this to a random access \"seekable\" API should be not too hard\n\nI think we can offer the option of MMap'ing the field caches, which I think will help alleviate OOMs? ",
            "author": "Jason Rutherglen",
            "id": "comment-13017886"
        },
        {
            "date": "2011-04-26T02:49:25+0000",
            "content": "What's the current status on this?  ",
            "author": "Lance Norskog",
            "id": "comment-13025033"
        },
        {
            "date": "2011-04-26T08:29:22+0000",
            "content": "What's the current status on this?\nI am currently focusing on RT and DWPT to be landed on trunk. Once this is done I can merge DocValues and finish the last remaining limitations. Its pretty close there are a couple of issues like javadoc (not complete but close), Codec integration is somewhat flaky and needs some new api. Feature wise its complete.\n ",
            "author": "Simon Willnauer",
            "id": "comment-13025130"
        },
        {
            "date": "2011-06-09T10:49:31+0000",
            "content": "currently landing on LUCENE-3108 ",
            "author": "Simon Willnauer",
            "id": "comment-13046460"
        }
    ]
}