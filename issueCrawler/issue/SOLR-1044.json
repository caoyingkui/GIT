{
    "id": "SOLR-1044",
    "title": "Use Hadoop RPC for inter Solr communication",
    "details": {
        "affect_versions": "None",
        "status": "Resolved",
        "fix_versions": [],
        "components": [
            "search"
        ],
        "type": "New Feature",
        "priority": "Major",
        "labels": "",
        "resolution": "Won't Fix"
    },
    "description": "Solr uses http for distributed search . We can make it a whole lot faster if we use an RPC mechanism which is more lightweight/efficient. \nHadoop RPC looks like a good candidate for this.  \n\nThe implementation should just have one protocol. It should follow the Solr's idiom of making remote calls . A uri + params +[optional stream(s)] . The response can be a stream of bytes.\n\nTo make this work we must make the SolrServer implementation pluggable in distributed search. Users should be able to choose between the current CommonshttpSolrServer, or a HadoopRpcSolrServer .",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "author": "Yonik Seeley",
            "id": "comment-12678105",
            "date": "2009-03-02T20:49:01+0000",
            "content": "Is our use of HTTP really a bottleneck?\n\nMy feeling has been that if we go to a call mechanism, it should be based on something more standard that will have many off the shelf bindings - perl, python, php, C, etc.\n\nOn the plus side of hadoop RPC, it could handle multiple requests per socket.  That can also be a potential weakness though I think... a slow reader or writer for one request/response hangs up all the others. "
        },
        {
            "author": "Ken Krugler",
            "id": "comment-12678108",
            "date": "2009-03-02T21:04:30+0000",
            "content": "I agree with both of Yonik's points:\n\n\n\tWe'd first want to measure real-world performance before deciding that using something other than HTTP was important.\n\tUsing something other than HTTP has related costs that should be considered.\n\n\n\nAt Krugle we used Hadoop RPC to handle remote searchers. In general it worked well, but we did run into the problem similar to what Yonik voiced as a potential concern - occasionally a remote searcher would hang, and when that happened the socket would essentially become a zombie. Under very heavy load testing this wound up eventually causing the entire system to lock up.\n\nThough we heard that there were subsequent changes to the Hadoop RPC that fixed a number of similar bugs. Not sure about any details, though, and we never re-ran tests with the latest Hadoop (at that time, which was about a year ago).\n\nIf there are performance issues, I would be curious if using a long-lasting connection via keep-alive significantly reduces the overhead. I know that Jetty (for example) has a very efficient implementation of the Comet web app model, where you don't wind up needing a gazillion threads to handle many requests/second. "
        },
        {
            "author": "Eks Dev",
            "id": "comment-12678121",
            "date": "2009-03-02T21:35:51+0000",
            "content": "I do not know much about Solr needs there, but we are using one of prehistoric versions of hadoop RPC (no NIO version)  as everything else proved to eat far to much time (in 800+ rq/sec environment every millisecond counts). Creating new Sockets is not working there as OSs start having problems to keep up with this rate (especially with java , slower Socket release due to gc() latency).  \n\n\nWe are anyhow contemplating to give etch (or thrift) a try. Etch looks like really good peace of work, with great flexibility. Someone tried it?  "
        },
        {
            "author": "Noble Paul",
            "id": "comment-12678242",
            "date": "2009-03-03T05:36:27+0000",
            "content": "Is our use of HTTP really a bottleneck? \nwe are limited by the servlet engine's ability to serve requests . I guess it would easily peak out at 600-800 req/sec .Whereas a NIO based system can serve far more with lower latency (http://www.jboss.org/netty/performance.html). If we have a request served out of cache (no lucene search involved) the only overhead will be that of the HTTP . Then there is the overhead of servlet engine itself . Moreover HTTP is not a very efficient for large volume small sized requests\n\nMy feeling has been that if we go to a call mechanism, it should be based on something more standard that will have many off the shelf bindings - perl, python, php, C, etc.\n\nI agree. Hadoop looked like a simple RPC mechanism . But we can choose any (Thrift, Etch, Grizzly etc). We can rely on these for the transport alone. The payload will have to be our own say xml/json/javabin etc . None of them yet support a flexible format\n\nThat can also be a potential weakness though I think... a slow reader or writer for one request/response hangs up all the others.\n\nThe requests on the server are served by multiple handlers (each one is a thread). One request will not block another if there are enough handlers/threads  "
        },
        {
            "author": "Noble Paul",
            "id": "comment-12678585",
            "date": "2009-03-04T04:56:33+0000",
            "content": "do not know much about Solr needs there, but we are using one of prehistoric versions of hadoop RPC (no NIO version)\n\ndisclaimer : I am not a hadoop user . have you used the NIO version ? how is the perf?\n "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12678587",
            "date": "2009-03-04T05:26:25+0000",
            "content": "We're using persistent HTTP connections, so socket creation overhead should not be much of an issue.\nAs far as NIO - servlet containers often have NIO connectors (I guess so idle persistent connections don't take up a thread to listen on them).  That handles the receive-side.  On the sender-side, NIO shouldn't matter... all of our clients need a thread to keep the request context anyway - we really have no way of using NIO there.\n\nThere could be an issue surrounding the number of TCP connections in a large cluster (that's an orthogonal issue to NIO), but modern OSs seem to handle high numbers of connections efficiently.... do switches?  Or perhaps the real limit has to do with exhausting port numbers (65536)? "
        },
        {
            "author": "Noble Paul",
            "id": "comment-12678597",
            "date": "2009-03-04T05:51:48+0000",
            "content": "We're using persistent HTTP connections, so socket creation overhead should not be much of an issue.\n\nAn HTTP connection can be re-used only after the request-response is complete. meanwhile, If there is another request to be fired to the same server from the same client  , a new connection will have to be created. So the no:of connections we create will be quite high if we have a large no:of nodes in distributed search . \n\nI haven't yet seen a HTTP server serving more than around 1200 req/sec (apache HTTPD). A call based server can serve 4k-5k messages easily. (I am yet to test hadoop RPC) . The proliferation of a large no: of frameworks around that is a testimony to the superiority of that approach. "
        },
        {
            "author": "Walter Underwood",
            "id": "comment-12678601",
            "date": "2009-03-04T06:03:40+0000",
            "content": "During the Oscars, the HTTP cache in front of our Solr farm had a 90% hit rate. I think a 10X reduction in server load is a testimony to the superiority of the HTTP approach. "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12678605",
            "date": "2009-03-04T06:14:04+0000",
            "content": "During the Oscars, the HTTP cache in front of our Solr farm had a 90% hit rate. I think a 10X reduction in server load is a testimony to the superiority of the HTTP approach.\n\nNobody is replacing HTTP with RPC \n\nHTTP is great but on a distributed solr deployment, it can be a bottleneck, I guess. I think if we do find RPC giving a better throughput than HTTP, the distributed search part is the right place to start using it. We do not need to move to non-HTTP communication (at least not now). "
        },
        {
            "author": "Noble Paul",
            "id": "comment-12678712",
            "date": "2009-03-04T12:22:23+0000",
            "content": "Hadoop RPC looks bad in my initial studies for a  packet size of 2048 bytes. tests run with 5 client threads , over 20 secs\n\n\n\nhadoop RPC: 3036 req/sec . average latency 1.6ms\ntomcat:  82012 4100/s average latency 1.ms\n\n\nthis may not be an apple to apple comparison. Here tomcat uses 5 connections internally and hadoop RPC uses only one. But , this is a more realistic one because we have no framework around hadoop rpc which can cache and reuse connections like httpclient\n "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12678987",
            "date": "2009-03-04T23:28:00+0000",
            "content": "An HTTP connection can be re-used only after the request-response is complete. meanwhile, If there is another request to be fired to the same server from the same client , a new connection will have to be created.\n\nBut the system quickly reaches steady state, right?  That new connection will be persistent and hang around for a while to be reused again when needed.\n\nFor a high-fanout distributed search, a more important part might actually be message parsing (independent of transport used).  I think we've done a decent job with the binary protocol for both CPU and network bandwidth... the actual requests themselves (hitting the lucene index, doing faceting and highlighting, retrieving stored fields) should hopefully be the bottleneck. "
        },
        {
            "author": "Noble Paul",
            "id": "comment-12679061",
            "date": "2009-03-05T03:49:44+0000",
            "content": "But the system quickly reaches steady state, right? That new connection will be persistent and hang around for a while to be reused again when needed.\nthe system reaches a steady state where the no:of connections would be slightly greater than the maximum no:of parallel requests. whereas a system using a message based RPC will still have only a single connection between 2 Solrs. \n\nFor a high-fanout distributed search, a more important part might actually be message parsing (independent of transport used)\n\nAs Solr move towards other applications such as mapreduce/mahout where the operations do not involve disk IO and where the payload is small there can be a problem.\n\nMy tests with hadoop RPC showed it outperforming tomcat when I used a small payload (5 bytes) "
        },
        {
            "author": "Mike Klaas",
            "id": "comment-12679466",
            "date": "2009-03-06T02:06:24+0000",
            "content": " I haven't yet seen a HTTP server serving more than around 1200 req/sec (apache HTTPD). A call based server can serve 4k-5k  messages  easily. (I am yet to test hadoop RPC) . The proliferation of a large no: of frameworks around that is a testimony to the superiority of that approach. \n{/quote}\n\nup to 50,000 req/sec, with keepalive: http://www.litespeedtech.com/web-server-performance-comparison-litespeed-2.0-vs.html "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13604372",
            "date": "2013-03-16T19:02:42+0000",
            "content": "SPRING_CLEANING_2013 we can reopen if necessary.  "
        }
    ]
}