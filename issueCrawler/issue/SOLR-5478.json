{
    "id": "SOLR-5478",
    "title": "Optimization: Fetch all \"fl\" values from docValues instead of stored values if possible/equivalent",
    "details": {
        "affect_versions": "4.5",
        "status": "Closed",
        "fix_versions": [
            "4.9",
            "6.0"
        ],
        "components": [
            "Response Writers"
        ],
        "type": "Improvement",
        "priority": "Major",
        "labels": "",
        "resolution": "Duplicate"
    },
    "description": "When the \"fl\" field list mentions a list of fields that all have docValues, and they are equivalent to the stored version (not true for multiValued field due to ordering), then we can fetch the values more efficiently from docValues than from stored values.  If this can't be done, might as well fetch them all from stored values when they have both (this is what happens today).\n\nFormer title: Speed-up distributed search with high rows param or deep paging by transforming docId's to uniqueKey via memory docValues\n\nOriginally the scope of this was just for the uniqueKey but now it's broader.",
    "attachments": {
        "SOLR-5478 smiley fl.fieldCacheFields.patch": "https://issues.apache.org/jira/secure/attachment/12622863/SOLR-5478%20smiley%20fl.fieldCacheFields.patch",
        "SOLR-5478.patch": "https://issues.apache.org/jira/secure/attachment/12616547/SOLR-5478.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Manuel Lenormand",
            "id": "comment-13827998",
            "date": "2013-11-20T19:11:44+0000",
            "content": "Following this mailing list thread - http://lucene.472066.n3.nabble.com/distributed-search-is-significantly-slower-than-direct-search-td4098191.html#a4101713\nI upload a patch for testing performance.\nThe idea is during the top document search (first stage) we read the uniquekey from docValues, and doc fields are not loaded (not normally nor lazily). During the second stage we do not access the stored fields in case the user requested uniquekey only "
        },
        {
            "author": "Manuel Lenormand",
            "id": "comment-13831369",
            "date": "2013-11-25T11:19:37+0000",
            "content": "Here are the patches, still preliminary in order to test the idea for this usage.\n\nFirst one is the patch for BinaryResponseWriter, the way it could be if the concept works.\nFor testing I'd recommand using the second patch which is a class that extends BinaryResponseWriter and is simply used by adding its reference to the solrconfig.xml. You can straightly use the jar with the following:\n\nadd this to the schema:\n<field name=\"id\" type=\"string_onmemory\" indexed=\"true\" stored=\"true\" required=\"true\" docValues=\"true\"/>\n\nand according to this field this fieldtype\n<fieldType name=\"string_onmemory\" class=\"solr.StrField\" docValuesFormat=\"Memory\"/> \n\nAnd this to the solrconfig.xml\n<queryResponseWriter name=\"javabin\" class=\"test.solr.DocValuesBinaryResponseWriter\"/>\n\nYou have two options that can be tested. These are the parameters required to the query:\n1. accelerateSearch=true - orders the distributed search (phase I) to seek for docValues and should have no effects on the results returned.\n2. accelerateIdSearch=true - orders the distributedsearch and id seek (phase I + II) to seek for docValues. This way the search would return uniqueKeys only.\n\nAssuming you have 10 shards on your instance and requesting rows=1000 (start=0 and hits per shard>1000), accelerateSearch would avoid 10*1000 id reads and lazy doc loading from the stored. accelerateIdSearch would avoid another total of 1000 id and lazy doc loading from the stored.\n\nFeel free adding any oppinion about the idea and implementation \n\n\nHope this rocks,\nManuel "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-13831435",
            "date": "2013-11-25T13:08:28+0000",
            "content": "Thanks Manuel. Can you please generate a patch file against trunk (or whichever version you use in production) which has all the changes (instead of multiple source files)?\n\nSee http://wiki.apache.org/solr/HowToContribute "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13831458",
            "date": "2013-11-25T13:32:53+0000",
            "content": "\nsearcher.getAtomicReader().getSortedDocValues(uniqueKey);\n\nThis is a performance killer. SlowWrapper must not be used here! "
        },
        {
            "author": "Manuel Lenormand",
            "id": "comment-13831501",
            "date": "2013-11-25T14:31:50+0000",
            "content": "I will save the searcher.getAtomicReader().getSortedDocValues(uniqueKey) as a member in the index searcher so I don't have to recreate it everytime.\n\nAfter I'm done I'll repatch "
        },
        {
            "author": "Manuel Lenormand",
            "id": "comment-13836495",
            "date": "2013-12-02T13:15:15+0000",
            "content": "repatched it, waiting for comments "
        },
        {
            "author": "Manuel Lenormand",
            "id": "comment-13867688",
            "date": "2014-01-10T10:42:15+0000",
            "content": "new patch:\n\nI redesigned it without making any changes to indexSearcher.\n\nImplemented by:\n1. A userCache (\"uniqueKeyCache\") that stores the the whole index's DocValues (by a SlowWrapper AtomicReader). Its' get method returns the unique key for every docId.\n2. An event listener (\"cacheWarmerListener\") that renews this cache as the [docId,uniqueKey] mapping might change every commit.\n3. A change in BinaryResponseWriter that accepts a query param (accelerateSearch) to request the uniqueKey from the cache instead of fetching it from the stored value. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13867821",
            "date": "2014-01-10T14:17:10+0000",
            "content": "\nI will save the searcher.getAtomicReader().getSortedDocValues(uniqueKey) as a member in the index searcher so I don't have to recreate it everytime.\n\nYou missed the point, its unnecessary to use SlowCompositeWrapper (getAtomicReader) here. You don't need a top-level docvalues, and you dont need a complicated cache or any of that either.\n\nYou just need to use docvalues per-segment. I really recommend starting simple here with just that. "
        },
        {
            "author": "Manuel Lenormand",
            "id": "comment-13867869",
            "date": "2014-01-10T14:59:29+0000",
            "content": "The problem is that the searcher that I get in the BinaryResponseWriter exposes the atomic reader as SlowCompositeWrapper.\n\nThe new patch involves in creating the SlowCompositeWrapper (shard level) only once per commit, and as these docValues are saved on disk there is no duplication.\n\nhow do you suggest accessing the per-segment docValues reader? Where would the docId-->UniqueKey convesation be done? "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13867876",
            "date": "2014-01-10T15:08:17+0000",
            "content": "This is how i do it. I can give you a patch with my code if you want as well. But its not perfect:\n\n\tideally this logic really would not be in a response writer at all, thats messy.\n\tcurrently only works for string fields. really if the id is numeric, we should use the NumericDocValues, etc.\n\tin fact the whole thing is a hack: really solr should use the internal lucene docid for distributed search.\n\n\n\n\n            Set<String> fnames = returnFields.getLuceneFieldNames();\n            context.iterator = ids.iterator();\n\n            final boolean onlyID = fnames != null && (fnames.equals(idOnly) || fnames.equals(idAndScore));\n            if (onlyID) {\n                // optimized case: only the ids are needed.\n                List<AtomicReaderContext> leaves = searcher.getIndexReader().leaves();\n                BytesRef ref = new BytesRef();\n                for (int i = 0; i < sz; i++) {\n                    int id = context.iterator.nextDoc();\n                    int subIndex = ReaderUtil.subIndex(id, leaves);\n                    AtomicReaderContext ctx = leaves.get(subIndex);\n                    ctx.reader().getSortedDocValues(uniqueKeyField).get(id - ctx.docBase, ref);\n                    Document doc = new Document();\n                    doc.add(new StringField(uniqueKeyField, ref.utf8ToString(), Field.Store.YES));\n                    SolrDocument sdoc = getDoc(doc);\n                    if (transformer != null) {\n                        transformer.transform(sdoc, id);\n                    }\n                    codec.writeSolrDocument(sdoc);\n                }\n            } else {\n\n "
        },
        {
            "author": "dennis",
            "id": "comment-13868433",
            "date": "2014-01-10T22:53:36+0000",
            "content": "Hi folks! \nFirst phase returns topN docs and uses stored id fields, not docValues even they are present? Am i right? Or I misunderstood something? I'm using Solr 4.6.0. Due to https://issues.apache.org/jira/browse/SOLR-3855 description everything must be fine, but seems it still uses stored fields for distributed search. Will be grateful for any help. Thanks. "
        },
        {
            "author": "Manuel Lenormand",
            "id": "comment-13869934",
            "date": "2014-01-13T20:28:47+0000",
            "content": "Denis - yes, the topN doc ids are read from the stored fields. It happens in the BinaryResponseWriter.\n\nRobert - you suggest returning the uniqueKey in the SolrQueryResponse? what stage do think of doing it? what about letting the frontend work with docId, while being aware of the shard provenance? why after working on solr-3855 didn't you implement the uniquekey read from docValues? "
        },
        {
            "author": "David Smiley",
            "id": "comment-13870151",
            "date": "2014-01-14T00:05:37+0000",
            "content": "Go fig; I implemented this issue for someone a few months ago.  I got permission to open-source it but haven't had the time to see the issue through to completion; it touched a bunch of things.  It's also more general beyond the uniqueKey; if all fields desired in \"fl\" are available in DocValues, then only DocValues are used \u2013 no stored field lookup.  I should post it.  I didn't have to muck with the response writer either, if I recall. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13870193",
            "date": "2014-01-14T00:46:58+0000",
            "content": "Thats undesirable: as it makes for N worst case seeks per document instead of 1. For this issue, we should keep it simple IMO. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13870205",
            "date": "2014-01-14T00:54:25+0000",
            "content": "It's also more general beyond the uniqueKey; if all fields desired in \"fl\" are available in DocValues, then only DocValues are used\n\n+1, sounds right. "
        },
        {
            "author": "David Smiley",
            "id": "comment-13870749",
            "date": "2014-01-14T14:12:50+0000",
            "content": "(Disclaimer; this patch isn't tested and in particular aside from porting it to trunk from v4.2 just now, I didn't try it out)\n\nThe essentials of this patch is a modification in 3 places \u2013 SolrReturnFields is the start.  Here, it detects that the only fields asked for are fields that are in a whitelist of FieldCache'able fields.  It defaults to just the uniqueKey field.  If this occurs, then a flag is set (\"skipDocOptimization\") and a \"DocTransformer\" is added for each such field that is able to fetch the field value from the FieldCache viewed as a ValueSource.  Then, annoyingly this code is in 2 places but in both BinaryResponseWriter and in TextResponseWriter there's logic that fetches the lucene document. I modified it to see if the skipDocOptimization flag is set and if so then to skip fetching the Document.  The transformers will run and add the id field and any others you might configure.\n\nI'd appreciate a look from others and recommendations on how to test it. "
        },
        {
            "author": "David Smiley",
            "id": "comment-13870751",
            "date": "2014-01-14T14:14:37+0000",
            "content": "Nevermind what I said about not being tested; I took the time to write a test apparently  "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-13971088",
            "date": "2014-04-16T12:57:07+0000",
            "content": "Move issue to Solr 4.9. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-14260255",
            "date": "2014-12-29T17:40:42+0000",
            "content": "As per Shalin Shekhar Mangar's comment on SOLR-6888 this is all probably taken care of by SOLR-6810.  "
        },
        {
            "author": "David Smiley",
            "id": "comment-14260271",
            "date": "2014-12-29T17:57:51+0000",
            "content": "SOLR-6810 addresses just the document ID, but seemingly not other fields that are in doc-Values.  Any way... I should dust off this patch after SOLR-6810 gets committed to see how that impacts things. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-14260283",
            "date": "2014-12-29T18:11:17+0000",
            "content": "bq:  addresses just the document ID, but seemingly not other fields that are in doc-Values\n\nI think I saw a comment (from Yonik?) asking that very question, so perhaps it'll \"just happen\".\nI confess though, that I'm not going to take the time to digest this right now...\n\nI was going to look a bit more thoroughly at this patch (I just glanced at the diff file), but now\nI'll let that go until after SOLR-6810. One question I had but didn't pursue about this patch \nwas whether docValues fields were returned on the second pass or not.\n\nThat said, I'll wait for all the dust to settle re: SOLR-6810 too. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-14260358",
            "date": "2014-12-29T19:40:40+0000",
            "content": "The general case of not using stored fields at all when other options exist is related to SOLR-5968 "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-14260418",
            "date": "2014-12-29T20:31:23+0000",
            "content": "Yonik Seeley OK, you made me look again....\n\nOriginally I was thinking that the second pass would require we get the stored rather than the indexed value, but since DVs are restricted to string and numerics and thus unanalyzed in any way, I was hypothesizing problems that didn't exist. Gotta wrap my head around that, perhaps it'll stick now.\n\nSo never mind..... I also see a lot of discussion about what stored should really mean in SOLR-3855 relative to DV fields, so I guess the topic's been pretty well hashed out. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-15205705",
            "date": "2016-03-22T03:25:35+0000",
            "content": "Yonik Seeley Shalin Shekhar Mangar David Smiley Now that SOLR-8220 is committed, is this still something we should be keeping open? "
        },
        {
            "author": "David Smiley",
            "id": "comment-15206379",
            "date": "2016-03-22T13:45:30+0000",
            "content": "Definitely keep this open; these issues are somewhat related but aren't the same thing.  If we can get to the point that Solr will automatically know to return the uniqueKey field via docValues (assuming docValues are enabled for it) when it's the only field you ask for, then we can call this issue done.  That specific optimization for just asking for the ID is key because any distributed search is going to do this in its first phase to find the top-X docs.  Of course, it'd be nice if it could do this in a broader set of cases too. "
        },
        {
            "author": "David Smiley",
            "id": "comment-16036951",
            "date": "2017-06-05T13:45:21+0000",
            "content": "Perhaps this issue can be closed now if the ID field can be marked as not stored but have docValues \u2013 thus a user can simply configure this.  I'm not sure if this is expressly tested?  I could be mistaken but I thought Solr had some expectation somewhere that the uniqueKey be stored, even though nowadays we have a docValues substitute.\n\nSeparate issues would be:\n\n\tconfiguring docValues=true stored=false for the uniqueKey in our default schemas\n\tif all \"fl\" fields requested have docValues and if there is no loss in functionality (no multi-valued fields) then don't use stored-values at all.  My patch on this issue does this; but it's perhaps broader in scope than handling just the uniqueKey in the title of this issue.  Shrug; or maybe adjust this issue scope to be broader and keep it open?\n\n "
        },
        {
            "author": "Varun Thacker",
            "id": "comment-16037208",
            "date": "2017-06-05T16:57:40+0000",
            "content": "Hi David,\n\nconfiguring docValues=true stored=false for the uniqueKey in our default schemas\n\nI created SOLR-10816 to track this. \n\nif all \"fl\" fields requested have docValues and if there is no loss in functionality (no multi-valued fields) then don't use stored-values at all. My patch on this issue does this; but it's perhaps broader in scope than handling just the uniqueKey in the title of this issue. Shrug; or maybe adjust this issue scope to be broader and keep it open?\n\n+1 renaming the Jira subject and linking SOLR-8344?  "
        },
        {
            "author": "Cao Manh Dat",
            "id": "comment-16171004",
            "date": "2017-09-19T02:11:52+0000",
            "content": "Hi David Smiley Varun Thacker, I think commit on SOLR-8344 solved this issue as well then this issue can be closed. In case we want to change the optimization algorithm, we can open another ticket with a detailed proposal about the changing.  "
        }
    ]
}