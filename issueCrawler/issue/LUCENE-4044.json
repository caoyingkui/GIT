{
    "id": "LUCENE-4044",
    "title": "Add NamedSPILoader support to TokenizerFactory, TokenFilterFactory and CharFilterFactory",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [
            "modules/analysis"
        ],
        "type": "Sub-task",
        "fix_versions": [
            "4.0-BETA",
            "6.0"
        ],
        "affect_versions": "None",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "In LUCENE-2510 I want to move all the analysis factories out of Solr and into the directories with what they create.  This is going to hamper Solr's existing strategy for supporting solr.* package names, where it replaces solr with various pre-defined package names.  One way to tackle this is to use NamedSPILoader so we simply look up StandardTokenizerFactory for example, and find it wherever it is, as long as it is defined as a service.  This is similar to how we support Codecs currently.\n\nAs noted by Robert in LUCENE-2510, this would also have the benefit of meaning configurations could be less verbose, would aid in fully decoupling the analysis module from Solr, and make the analysis factories easier to interact with.",
    "attachments": {
        "LUCENE-4044-4x-stripped.patch": "https://issues.apache.org/jira/secure/attachment/12537864/LUCENE-4044-4x-stripped.patch",
        "LUCENE-4044.patch": "https://issues.apache.org/jira/secure/attachment/12537635/LUCENE-4044.patch",
        "LUCENE-4044-4x.patch": "https://issues.apache.org/jira/secure/attachment/12537863/LUCENE-4044-4x.patch",
        "LUCENE-4044-stripped.patch": "https://issues.apache.org/jira/secure/attachment/12537819/LUCENE-4044-stripped.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2012-05-09T02:26:45+0000",
            "content": "This is going to hamper Solr's existing strategy for supporting solr.* package names\n\nWhy is that?  Why can't solr.WhitespaceTokenizerFactory also check the package that you're planning on moving WhitespaceTokenizerFactory to? ",
            "author": "Yonik Seeley",
            "id": "comment-13271017"
        },
        {
            "date": "2012-05-09T02:28:08+0000",
            "content": "There will be alot of different packages, I assumed that cycling through them all would be undesirable. ",
            "author": "Chris Male",
            "id": "comment-13271020"
        },
        {
            "date": "2012-05-09T02:35:31+0000",
            "content": "With that said, I'm open to suggestions since I dont think this is going to do what I want it to do. ",
            "author": "Chris Male",
            "id": "comment-13271024"
        },
        {
            "date": "2012-05-09T04:00:11+0000",
            "content": "Hmm it seems that this process only supports singletons, which isn't much use to us. ",
            "author": "Chris Male",
            "id": "comment-13271055"
        },
        {
            "date": "2012-05-09T06:47:16+0000",
            "content": "why is it a problem? You just put the .class instance instead. ",
            "author": "Robert Muir",
            "id": "comment-13271159"
        },
        {
            "date": "2012-05-09T09:08:44+0000",
            "content": "I'm not really sure how to do that, since the service has to implement NamedSPILoader.NamedSPI. ",
            "author": "Chris Male",
            "id": "comment-13271228"
        },
        {
            "date": "2012-07-11T23:03:42+0000",
            "content": "bulk cleanup of 4.0-ALPHA / 4.0 Jira versioning. all bulk edited issues have hoss20120711-bulk-40-change in a comment ",
            "author": "Hoss Man",
            "id": "comment-13412284"
        },
        {
            "date": "2012-07-24T01:16:07+0000",
            "content": "I was wondering what happened to this issue, then i realized Chris was waiting on me to explain...\n\nhere's a proof of concept patch (won't get by the generics policeman or anything, just showing that it works). ",
            "author": "Robert Muir",
            "id": "comment-13421080"
        },
        {
            "date": "2012-07-24T01:29:58+0000",
            "content": "Chris: I'm gonna scratch out a branch here and see if we can flesh this out.\n\nAt least I think we should give it a try as it would be pretty much a win for everyone\nto simplify this syntax and make these analysis modules real plugins (I'm frustrated with\nthings like SOLR-3623 / the hassle people have to go thru to use some of the lucene analyzers)\n\nI expect Uwe to be horrified by what I did, but I'm hoping he will be willing to help it,\nand there is still a ton of work to get everything integrated  ",
            "author": "Robert Muir",
            "id": "comment-13421085"
        },
        {
            "date": "2012-07-24T01:54:34+0000",
            "content": "it would be pretty much a win for everyone to simplify this syntax and make these analysis modules real plugins (I'm frustrated with things like SOLR-3623 / the hassle people have to go thru to use some of the lucene analyzers)\n\nJust to clarify: i believe you're saying that this would simplify things for end users because it would mean one less jar people need to load in (ie: bundle the FooTokenizerFactory in the same jar as the FooTokenizer so no need to a special solr contrib containing just the factory) ... correct?\n\nAnd in theory it would simplify things for developers because if we can remove things like contrib/solr/analysis-extras then things like SOLR-3664 are problematic in fewer situations.\n\nBut (unless i'm missing something) nothing in this approach would actually eliminate the requirement that Solr users configure <lib ... /> directives to load these external jars (and any third party dependencies) to get the factories+impls+third-party-deps ... correct? ",
            "author": "Hoss Man",
            "id": "comment-13421095"
        },
        {
            "date": "2012-07-24T02:00:32+0000",
            "content": "\nJust to clarify: i believe you're saying that this would simplify things for end users because it would mean one less jar people need to load in (ie: bundle the FooTokenizerFactory in the same jar as the FooTokenizer so no need to a special solr contrib containing just the factory) ... correct?\n\nYes.\n\n\nAnd in theory it would simplify things for developers because if we can remove things like contrib/solr/analysis-extras then things like SOLR-3664 are problematic in fewer situations.\n\nYes.\n\n\nBut (unless i'm missing something) nothing in this approach would actually eliminate the requirement that Solr users configure <lib ... /> directives to load these external jars (and any third party dependencies) to get the factories+impls+third-party-deps ... correct?\n\nThere is no magic. they have to put things in their classpath.\n\nBut the other major improvement i suggested was syntax too. Of course we must still support FQDN and also the solr.XXX:\n\n\n<charFilter class=\"solr.HtmlStripCharFilterFactory\"/>\n<tokenizer class=\"solr.StandardTokenizerFactory\"/>\n<filter class=\"solr.LowerCaseFilterFactory\"/>\n<filter class=\"solr.PorterStemFilterFactory\"/>\n\n\n\nBut I think we should fix the examples and support (as the \"new\" syntax):\n\n\n<charFilter name=\"htmlstrip\"/>\n<tokenizer name=\"standard\"/>\n<filter name=\"lowercase\"/>\n<filter name=\"porterstem\"/>\n\n\n ",
            "author": "Robert Muir",
            "id": "comment-13421103"
        },
        {
            "date": "2012-07-24T02:17:27+0000",
            "content": "There is no magic. they have to put things in their classpath.\n\nJust checking ... sometimes you and Uwe bust out stuff that is indistinguishable from magic.\n\nBut I think we should fix the examples and support (as the \"new\" syntax)\n\nHmmm... yeah i'm -0 on that part ... i mainly just worry that it would be confusing for users if some places in the config (charfilter, tokneizer, tokenfilter, analyzer) supported these short names, but other places (fieldtype, requesthandler, serachcomponent, etc...) didn't and required a FQN ClassName or solr.ClassName\n\n\u2014\n\nFWIW: The other issue to consider here is how the packaging of these \"uber-module-jars\" will work in Solr binary pacakges ... right now it's the solr contribs that provide the factories that ensure the lucene modules they depend on make it into the final tgx/zip files ... if lucene modules start providing the factories themselves, we'll need some build.xml shenanigans to copy those module jars into the solr package dirs. ",
            "author": "Hoss Man",
            "id": "comment-13421112"
        },
        {
            "date": "2012-07-24T02:20:44+0000",
            "content": "\nHmmm... yeah i'm -0 on that part ... i mainly just worry that it would be confusing for users if some places in the config (charfilter, tokneizer, tokenfilter, analyzer) supported these short names, but other places (fieldtype, requesthandler, serachcomponent, etc...) didn't and required a FQN ClassName or solr.ClassName\n\nWell solr can keep its verbose syntax then: I'll leave it alone. Ill just support backwards (class=solr.xxx) via the SPI.\n\n\nFWIW: The other issue to consider here is how the packaging of these \"uber-module-jars\" will work in Solr binary pacakges ... right now it's the solr contribs that provide the factories that ensure the lucene modules they depend on make it into the final tgx/zip files ... if lucene modules start providing the factories themselves, we'll need some build.xml shenanigans to copy those module jars into the solr package dirs.\n\nIts not anything we arent dealing with already. We already have shenanigans copying that stuff over. its just less jars. ",
            "author": "Robert Muir",
            "id": "comment-13421114"
        },
        {
            "date": "2012-07-24T03:06:07+0000",
            "content": "Chris: I'm gonna scratch out a branch here and see if we can flesh this out.\n\nThanks for coming back to this Robert!  I was just thinking about returning to this issue.\n\n\nAt least I think we should give it a try as it would be pretty much a win for everyone\nto simplify this syntax and make these analysis modules real plugins (I'm frustrated with\nthings like SOLR-3623 / the hassle people have to go thru to use some of the lucene analyzers)\n\nAbsolutely.  I'm a huge fan of the simplified syntax.  Every consumer of Lucene, Solr or not, would benefit from being able to easily retrieve these Factories.\n\nLooking over the patch I see what you meant and I really like it.  I wonder whether we should integrate newInstance into NamedSPILoader and add getName() to the Factorys?  The getName impl can then do the classname clipping like currently done in the patch. ",
            "author": "Chris Male",
            "id": "comment-13421138"
        },
        {
            "date": "2012-07-24T03:10:51+0000",
            "content": "Chris: working on it \n\nmy first goal: get compile and tests working again.\n\nNext: i would like TestAllFactoriesWorkViaSPI (we should be able to do that)\nAnd also: TestAllAnalysisComponentsHaveFactories (we can use TestRandomChains-like sweeping to find them)\n\nThis would prevent anything from being out of sync. ",
            "author": "Robert Muir",
            "id": "comment-13421139"
        },
        {
            "date": "2012-07-24T03:12:56+0000",
            "content": "Haha sweet!\n\n\nNext: i would like TestAllFactoriesWorkViaSPI (we should be able to do that)\nAnd also: TestAllAnalysisComponentsHaveFactories (we can use TestRandomChains-like sweeping to find them)\nThis would prevent anything from being out of sync.\n\nHuge +1 to that. ",
            "author": "Chris Male",
            "id": "comment-13421141"
        },
        {
            "date": "2012-07-24T03:49:29+0000",
            "content": "\nAbsolutely. I'm a huge fan of the simplified syntax.\n\nI think so too, but since some of this is contentious, lets just leave it for a future issue.\n\nBasically we can use the SPI to implement backwards compat, but in the future we can imagine more:\n\n\tremove .java Analyzer files from lucene and replace with some declarative specification that uses the factories (e.g. json or whatever)\n\tfix TestRandomChains or whatever to use SPI to find available tokenstreams, fix it to be a real integration test too.\n\tallowing users to pick from available implementations in analysis gui to prototype up a chain and see what it looks like\n\tsimplified syntax as mentioned above\n\n\n\nThose were just my ideas. we can just leave these for future issues.\n\nOn this issue we can make the pluggability simple, improve testing, make sure backwards is done right, and get it all past the generics policeman  ",
            "author": "Robert Muir",
            "id": "comment-13421151"
        },
        {
            "date": "2012-07-24T04:04:37+0000",
            "content": "I think so too, but since some of this is contentious, lets just leave it for a future issue.\n\nYeah fair enough.\n\nremove .java Analyzer files from lucene and replace with some declarative specification that uses the factories (e.g. json or whatever)\n\nThis will be a great day. ",
            "author": "Chris Male",
            "id": "comment-13421157"
        },
        {
            "date": "2012-07-24T05:03:31+0000",
            "content": "\nI think so too, but since some of this is contentious, lets just leave it for a future issue.\n\nYeah fair enough.\n\nI wasn't objecting to supporting the shortenend syntax, i'm just worried that using it in the examples might confuse people when the same shortened syntax doesn't work in other places.\n\nIts not anything we arent dealing with already. We already have shenanigans copying that stuff over. its just less jars.\n\nit's something we're dealing with already, but the way we are dealing with it will probably need to change in some cases...\n\nright now (some) lucene-module jars get copied over into solr binary artifacts is because there are solr contribs that provide the factories and have build.xml files that copy the jars - if (some) solr contribs go away because the factories are included directly lucene module, then the solr contrib build.xml files will go away, and then we need new/differnet ways to ensure those lucene module jars get copied into solr binary packages ... correct? ",
            "author": "Hoss Man",
            "id": "comment-13421178"
        },
        {
            "date": "2012-07-24T05:09:52+0000",
            "content": "\nright now (some) lucene-module jars get copied over into solr binary artifacts is because there are solr contribs that provide the factories and have build.xml files that copy the jars - if (some) solr contribs go away because the factories are included directly lucene module, then the solr contrib build.xml files will go away, and then we need new/differnet ways to ensure those lucene module jars get copied into solr binary packages ... correct?\n\nI can't make that contrib go away with this issue. It has a solr fieldtype as well for ICU.\n\nBecause of that, for this issue we can just keep the status quo and not remove any contribs.\nThen there is nothing to deal with here  ",
            "author": "Robert Muir",
            "id": "comment-13421181"
        },
        {
            "date": "2012-07-24T10:35:23+0000",
            "content": "I was testing my Solr integration code and ran into needing to move MockTokenizerFactory (which is in solr/test-framework}.  Moving it to lucene/test-framework alongside MockTokenizer doesn't seem to be an option since test-framework doesn't depend on the analysis module.  Moving it into the analysis module main src doesn't seem to be an option either since test-framework is a test scoped dependency.  It would be possible to put it into the analysis module test code but then it's not distributed like it is in test-framework.  Any ideas? ",
            "author": "Chris Male",
            "id": "comment-13421316"
        },
        {
            "date": "2012-07-24T12:28:57+0000",
            "content": "Then the integration code has a problem? \n\nMockTokenizerFactory should work as is: its in the org.apache.solr package. ",
            "author": "Robert Muir",
            "id": "comment-13421353"
        },
        {
            "date": "2012-07-24T12:34:34+0000",
            "content": "Hm, the problem is that MockTokenizerFactory isn't accessible via SPI.  Should I add a META-INF TokenizerFactory SPI file in Solr? or are you suggesting we should use the existing behaviour when a Factory can be found traditionally, and only use SPI when it can't. ",
            "author": "Chris Male",
            "id": "comment-13421356"
        },
        {
            "date": "2012-07-24T12:38:11+0000",
            "content": "Chris male: you have it all backwards.\n\n\nor are you suggesting we should use the existing behaviour when a Factory can be found traditionally, and only use SPI when it can't.\n\nTry the SPI first... but then fall back totally on today's behavior. It MUST be this way or its a backwards break. I myself have made 3rd party analyzer projects and i put them in this package name on purpose so people could use the solr.XXX  ",
            "author": "Robert Muir",
            "id": "comment-13421359"
        },
        {
            "date": "2012-07-24T12:44:37+0000",
            "content": "There is one problem with the SPI approach:\nSPI loads one instance per factory. The SPI loader returns only this instance. If you then set init paramters on it, you modify the only available singleton.\n\nEDIT: You fixed that in the specail SPI loader \n\nA second problem I see is the fact that on SPI init all factories are instantiated, but there is no way around that without another \"Provider\" interface inbetween. In all cases it is important that the factory does not initialize the class it creates, otherwise things like Kumoroji slow down. I hate the fact that SPILoader automatically instantiates the factory, but there is with Java 6 no way around, unless we write an own parser for META-INF files. Which would be a good option maybe. ",
            "author": "Uwe Schindler",
            "id": "comment-13421362"
        },
        {
            "date": "2012-07-24T12:51:26+0000",
            "content": "\nA second problem I see is the fact that on SPI init all factories are instantiated, but there is no way around that without another \"Provider\" interface inbetween. In all cases it is important that the factory does not initialize the class it creates, otherwise things like Kumoroji slow down. I hate the fact that SPILoader automatically instantiates the factory, but there is with Java 6 no way around, unless we write an own parser for META-INF files. Which would be a good option maybe.\n\nThis should only be a problem if Factories have heavy logic during construction, right?  Most don't do anything until their init() method is called. ",
            "author": "Chris Male",
            "id": "comment-13421366"
        },
        {
            "date": "2012-07-24T13:02:23+0000",
            "content": "This seems like a big enough change that it should be targeted toward trunk and not 4x at this point. ",
            "author": "Yonik Seeley",
            "id": "comment-13421379"
        },
        {
            "date": "2012-07-24T13:07:57+0000",
            "content": "\nThis seems like a big enough change that it should be targeted toward trunk and not 4x at this point.\n\nWhy? I Just started experimenting with this last night: you havent even given the issue time to be completed.\n\nI did my development in a branch to make it transparent: but its not mandatory to do that.\n\nI think its fine for this issue to be targeted at 4.x, in fact I think we are very close.\n\nIts no backwards break to the index format. ",
            "author": "Robert Muir",
            "id": "comment-13421382"
        },
        {
            "date": "2012-07-24T13:12:04+0000",
            "content": "Try the SPI first... but then fall back totally on today's behavior. It MUST be this way or its a backwards break. I myself have made 3rd party analyzer projects and i put them in this package name on purpose so people could use the solr.XXX \n\nCan we include this into the SPILoader itsself? So when it finds a name which looks like a full class name (but does not exist in the service list) it tries to Class.forName.asSubClass(clazz) it and instantiate it in newInstance(). The replacement of solr. to something else should be maybe done in Solr as name-preprocessing. Maybe that's too much magic, just an idea. ",
            "author": "Uwe Schindler",
            "id": "comment-13421385"
        },
        {
            "date": "2012-07-24T13:16:16+0000",
            "content": "Can we include this into the SPILoader itsself? So when it finds a name which looks like a full class name (but does not exist in the service list) it tries to Class.forName.asSubClass(clazz) it and instantiate it in newInstance(). The replacement of solr. to something else should be maybe done in Solr as name-preprocessing. Maybe that's too much magic, just an idea.\n\nI'm experimenting with code that kind of does that.  It does some pre-processing of the name before passing it of to the SPI Loader, but then it just falls back to existing behavior for simplicity (all inside the Solr side of the code). ",
            "author": "Chris Male",
            "id": "comment-13421387"
        },
        {
            "date": "2012-07-24T13:43:37+0000",
            "content": "Why?\n\nAside from other back compat risks, there are performance concerns.\nhttp://colabti.org/irclogger/irclogger_log/lucene-dev?date=2012-07-24 ",
            "author": "Yonik Seeley",
            "id": "comment-13421408"
        },
        {
            "date": "2012-07-24T13:52:47+0000",
            "content": "Like I said: I'm not even done yet. The issue just got started.\n\nI'm targeting 4.x: because I want the analysis modules to be successful in 4.0 ",
            "author": "Robert Muir",
            "id": "comment-13421421"
        },
        {
            "date": "2012-07-24T13:59:00+0000",
            "content": "I fully agree with Robert, we're working through the issues. ",
            "author": "Chris Male",
            "id": "comment-13421425"
        },
        {
            "date": "2012-07-25T02:51:25+0000",
            "content": "I did a review of the latest code and things are looking really good.  What's still pending? ",
            "author": "Chris Male",
            "id": "comment-13421960"
        },
        {
            "date": "2012-07-25T02:53:11+0000",
            "content": "Yeah Uwe really went to town and rewrote everything (as I hoped!)\n\nI've just been adding more tests myself to shake anything out.\n\nI think this is ready to go in. ",
            "author": "Robert Muir",
            "id": "comment-13421961"
        },
        {
            "date": "2012-07-25T03:16:51+0000",
            "content": "Yeah thanks for adding the great test coverage and improving the Factories.\n\nI'm +1 for this going in. ",
            "author": "Chris Male",
            "id": "comment-13421969"
        },
        {
            "date": "2012-07-25T06:04:55+0000",
            "content": "From my opinion, this is ready to go in! Real cool new tests.\n\nThe only thing I want to add is an ANT task (e.g., using ASM like the other one), that creates the META-INF/services files automatically. We can then do the same in core for codecs or postings. It just collects all .class files from a FileSet that extends a specfic class and adds them to a services file. But that has time, currently all factories must be added manually, but this can go in!\n\n+1 to let this go in ASAP, as it outdates very fast (the many moves will make merging fast and changes to trunk's factories may get lost! ",
            "author": "Uwe Schindler",
            "id": "comment-13422025"
        },
        {
            "date": "2012-07-25T06:11:49+0000",
            "content": "\nThe only thing I want to add is an ANT task (e.g., using ASM like the other one), that creates the META-INF/services files automatically. We can then do the same in core for codecs or postings. It just collects all .class files from a FileSet that extends a specfic class and adds them to a services file. But that has time, currently all factories must be added manually, but this can go in!\n\nI agree this would be nice, for safety in the meantime I added TestAllAnalyzersHaveFactories, which checks that both we have a factory for every Tokenizer/TokenFilter/CharFilter and that the SPI is configured correctly (since it uses forName to validate this) and fails if we don't.\n\nIts not a perfect solution but just to prevent stupid mistakes. ",
            "author": "Robert Muir",
            "id": "comment-13422027"
        },
        {
            "date": "2012-07-25T06:28:25+0000",
            "content": "For the provider-auto-config I found https://code.google.com/p/spi/, which is a javac annotation processor. Instead of adding the factories, we have to add a @ProviderFor(TokenizerFactor.class) on the implementation class (instead of adding it to the crazy file in resources folder). javac then automatically writes the META-INF file to the compiler output. As this annotation processor is an SPI by itsself and can be added to ANT's javac task as additional classpath (to find the tool), it will do this while compiling without any further configuration. For Eclipse you have to add annotation processing, but this can be enabled in ant eclipse.\n\nThe cool thing is, that we dont need to make crazy Eclipse classpaths, because the META-INF/services folder in resources can be nuked and no file collisions can happen.\n\nI am still digging to have it fully automatic, but this approach is used by many projects. ",
            "author": "Uwe Schindler",
            "id": "comment-13422032"
        },
        {
            "date": "2012-07-25T07:08:53+0000",
            "content": "Shall we merge and then address automation? ",
            "author": "Chris Male",
            "id": "comment-13422049"
        },
        {
            "date": "2012-07-25T08:05:29+0000",
            "content": "As I said, I will open separate issue!\n\n+1 to merge forward to branch and then reintegrate + commit! And merge back to 4.x (also asap, otherwise we might get out of sync, too because changes in factory classes in 4.x might get lost, too)\n\nI will now merge the branch up to trunk, reintegrate can come afterwards. ",
            "author": "Uwe Schindler",
            "id": "comment-13422074"
        },
        {
            "date": "2012-07-25T09:25:33+0000",
            "content": "Here the monster patch for merging against trunk (caused by lot of SVN moves). I will try to get a simplier one which shows actual changes in non-moved classes only (explude additions/removals). ",
            "author": "Uwe Schindler",
            "id": "comment-13422112"
        },
        {
            "date": "2012-07-25T09:31:55+0000",
            "content": "Short patch with no additions/deletions - just showing changes in already existing files. As you see changes in Solr and Lucene are minimal. Unfortunately it does not show all changes in the Lucene SPI utils (SPIClassIterator,...) ",
            "author": "Uwe Schindler",
            "id": "comment-13422118"
        },
        {
            "date": "2012-07-25T09:35:20+0000",
            "content": "Thanks Uwe, patches look good, +1 to committing ",
            "author": "Chris Male",
            "id": "comment-13422121"
        },
        {
            "date": "2012-07-25T11:32:46+0000",
            "content": "One thing for later cleanup (I just add these points here to add further subtasks to parent issues once this is committed): Solr/contrib/analysis-extras is now almost obsolete and feels like just a JAR file duplicator - it only contains a standalone lib/ folder and one single class ICUCollationKeyField.java. We should nuke that and maybe find a good solution for the CollationKeyField (copy to core?, use Reflection, so it only works with ICU when available,...).\n\nWith the current approach you can simply copy the JAR files from the advanced analyzers in Lucene to your solr/lib plugin folder and they are available (depending on solrconfig.xml, of course). That's the most cool thing on the whole issue! No need to ship them with distribution, maybe add a downloader script to Solr that fetches the required JARS from maven/ivy and install them in you Solr instance's lib folder. ",
            "author": "Uwe Schindler",
            "id": "comment-13422164"
        },
        {
            "date": "2012-07-25T13:27:04+0000",
            "content": "I will commit this to trunk and then we backport soon, because this gets outdated very fast. ",
            "author": "Uwe Schindler",
            "id": "comment-13422243"
        },
        {
            "date": "2012-07-25T13:55:10+0000",
            "content": "Committed trunk revision: 1365586\n\nI will remove branch now and start to backport. ",
            "author": "Uwe Schindler",
            "id": "comment-13422273"
        },
        {
            "date": "2012-07-25T17:36:56+0000",
            "content": "Patches for 4.x (like trunk, one complete, one diffs only). It was a little bit of work, as some factories were different and created conflicts on removal. I also had to move factories for old deprecated analysis components including some utility methods. Thanks Robert for help!\n\nSome additional changes:\n\n\tArabicLetterTokenizerFactory\n\tCJKTokenizerFactory\n\tChineseFilterFactory\n\tPatternReplaceCharFilterFactory\n\tFSTSynonym's backwards layer\n\t...\n\n\n\nI will commit this now. ",
            "author": "Uwe Schindler",
            "id": "comment-13422443"
        },
        {
            "date": "2012-07-25T17:42:45+0000",
            "content": "Committed 4.x revision: 1365673 ",
            "author": "Uwe Schindler",
            "id": "comment-13422449"
        }
    ]
}