{
    "id": "LUCENE-8527",
    "title": "Upgrade JFlex to 1.7.0",
    "details": {
        "components": [
            "general/build",
            "modules/analysis"
        ],
        "status": "Open",
        "resolution": "Unresolved",
        "fix_versions": [],
        "affect_versions": "None",
        "labels": "",
        "priority": "Minor",
        "type": "Improvement"
    },
    "description": "JFlex 1.7.0, supporting Unicode 9.0, was released recently: http://jflex.de/changelog.html#jflex-1.7.0.  We should upgrade.",
    "attachments": {
        "LUCENE-8527.patch": "https://issues.apache.org/jira/secure/attachment/12951158/LUCENE-8527.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "id": "comment-16713295",
            "author": "Uwe Schindler",
            "content": "+1 ",
            "date": "2018-12-07T21:23:17+0000"
        },
        {
            "id": "comment-16713437",
            "author": "Steve Rowe",
            "content": "Robert Muir mentioned on LUCENE-8125 that StandardTokenizer should give Emoji sequences the <EMOJI> token type - see the logic in the icu module's BreakIteratorWrapper.\n\nJFlex 1.7.0 supports Unicode 9.0, which, if I'm interpreting the discussion at http://www.unicode.org/L2/L2016/16315r-handling-seg-emoji.pdf properly, does not (fully) include Emoji sequence support (though customized rules that would do that properly in Unicode 9.0 are listed in that doc).\n\nShould we include the (post-9.0) customized rules for Unicode 9.0? ",
            "date": "2018-12-08T00:22:07+0000"
        },
        {
            "id": "comment-16713510",
            "author": "Robert Muir",
            "content": "It would be really nice. I don't think the tricky part is really segmentation at all (as far as finding breaks) but instead the problem of assigning the proper \"label\" to the token (tag it as a emoji type). \n\nSo the stuff in the ICU tokenizer uses some properties to tag the \"stuff between breaks\" as emoji token type versus something else. I looked at latest jflex, it seems it would need those props? And its a little tricky, e.g. ordinary ascii digit 7 is [:Emoji:] in unicode. So thats why the isEmoji there is a bit crazy. ",
            "date": "2018-12-08T03:47:55+0000"
        },
        {
            "id": "comment-16714302",
            "author": "Steve Rowe",
            "content": "Patch, passes most Lucene/Solr tests (see below), including the test built with Unicode 9.0's word break test data: WordBreakTestUnicode_9_0_0.\nSo the stuff in the ICU tokenizer uses some properties to tag the \"stuff between breaks\" as emoji token type versus something else. I looked at latest jflex, it seems it would need those props?\nYes, JFlex 1.7.0 doesn't have the Emoji props it needs to properly tokenize and type as emoji, since these props' definitions are not included with release-specific data. For Lucene's use it should be possible to script pulling in Unicode data to augment the scanner specs, which would allow proper emoji tokenization/typing to work. (I've made a note to add these properties to future JFlex releases.)\n\nFailing tests with the patch:\n\nant test -Dtestcase=TestStandardAnalyzer -Dtests.method=testRandomHugeStringsGraphAfter -Dtests.seed=B33609C22A50A253 -Dtests.slow=true -Dtests.badapples=true -Dtests.locale=es-VE -Dtests.timezone=Africa/Blantyre -Dtests.asserts=true -Dtests.file.encoding=UTF-8\n\nant test -Dtestcase=TestStandardAnalyzer -Dtests.method=testRandomHugeStrings -Dtests.seed=DA01A0705C379738 -Dtests.slow=true -Dtests.badapples=true -Dtests.locale=ru-RU -Dtests.timezone=Europe/Sarajevo -Dtests.asserts=true -Dtests.file.encoding=ISO-8859-1\n\nIn both ^^ of these cases, BaseTokenStreamTestCase.checkAnalysisConsistency() fails with unexpected tokenization after randomly choosing to use a spoon-feed reader wrapper: MockReaderWrapper. If I disable the wrapping with those seeds, the tests pass. I'll work on making a simplified test case demonstrating the problem; I'm not sure what's going wrong. ",
            "date": "2018-12-10T05:15:46+0000"
        },
        {
            "id": "comment-16714304",
            "author": "Steve Rowe",
            "content": "FYI the patch does not include generated files, since that would make it much larger. \u00a0Run ant jflex\u00a0in lucene/core and lucene/analysis/common to do the generation. ",
            "date": "2018-12-10T05:19:39+0000"
        }
    ]
}