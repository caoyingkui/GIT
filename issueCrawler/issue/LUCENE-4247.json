{
    "id": "LUCENE-4247",
    "title": "QueryParser doesn't call Analyzer",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [
            "core/queryparser"
        ],
        "type": "Bug",
        "fix_versions": [],
        "affect_versions": "3.6",
        "resolution": "Invalid",
        "status": "Resolved"
    },
    "description": "I'm trying to escape czech characters thorough the ASCIIFoldingFilter this works fine in indexing since I can retrieve the non-diacritic version of the content I indexed. But trying to retrieve with diacritics returns always 0 results\n\nIn debug mode I can clearly see that the Analyzer wasn't called (in addition to that I've put a breakpoint in my analyser to check if it is not called later, and it never passes in)\n\n\nsearchText = \"p\u0159\u00edLI\u0161*\";\n\t\tAnalyzer analyzer = (Analyzer) factory.getBean(\"analyzer\");\n\t\tQuery q = new QueryParser((Version) factory.getBean(\"version\"), DestinationPlaceProperties.NAME, analyzer).parse(searchText);\n\n\nThe query q has these values in debug:\nprefix\tTerm  (id=90)\t\n\tfield\t\"name\" (id=100)\t\n\ttext\t\"p\u0159\u00edli\u0161\" (id=101)\t\n\n\u2014 more details ----\nq\tPrefixQuery  (id=65)\t\n\tboost\t1.0\t\n\tnumberOfTerms\t0\t\n\tprefix\tTerm  (id=90)\t\n\trewriteMethod\tMultiTermQuery$2  (id=92)\t\n---------------------\n\nMy analyser is quite simple: I put its code just for reference\n\npublic class DestinationAnalyser extends Analyzer {\n\n\t/**\n\n\t\t */\n\tprivate final Version\tluceneVersion;\n\n\n\n\tpublic DestinationAnalyser(Version lucene_version) \n{\n\t\tsuper();\n\t\tthis.luceneVersion = lucene_version;\n\t}\n\n\t/*\n\n\t(non-Javadoc)\n\t\n\t@see org.apache.lucene.analysis.Analyzer#tokenStream(java.lang.String,\n\tjava.io.Reader)\n\t */\n\t@Override\n\tpublic TokenStream tokenStream(String fieldName, Reader reader) \n{\n\t\tTokenStream result = new StandardTokenizer(luceneVersion, reader);\n\t\tresult = new StandardFilter(luceneVersion, result);\n\t\tresult = new LowerCaseFilter(luceneVersion, result);\n\t\tresult = new ASCIIFoldingFilter(result);\n\t\treturn result;\n\t}\n}\n\n\n\n\n--------- WORKAROUND ---------\nTo avoid the problem, I'm actually using this method to transform the search text \n\t/**\n\n\tUses \n{@link ASCIIFoldingFilter}\n to transform diacritical text to its ascii\n\tcounterpart\n\t\n\t@param text\n\tto transform\n\t@return ascii text\n\t */\n\tpublic static String foldToASCII(String text) \n{\n\t\tint length = text.length();\n\t\tchar[] toReturn = new char[length];\n\t\tASCIIFoldingFilter.foldToASCII(text.toCharArray(), 0, toReturn, 0, length);\n\t\treturn new String(toReturn);\n\t}",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "date": "2012-07-23T17:34:36+0000",
            "content": "This is not a bug, because you are using a wildcard query which cannot use the analyzer (because the analyzer would destroy the wildcards). Without the \"*\" at the end this query would be parsed as you expect.\n\nPlease ask such questions on the java-user@lucene.apache.org mailing list first, people there will help you with such things. ",
            "author": "Uwe Schindler",
            "id": "comment-13420804"
        },
        {
            "date": "2012-07-23T17:59:09+0000",
            "content": "Just to add some background information:\nFor the Solr Queryparser (see SOLR-2921) there is a new marker \"MultiTermAware\" in Solr. The Solr QueryParser can handle that, but lack of an IndexSchema, Lucene's cannot, so it does not analyze all MultiTermQueries like WildCard, Prefix, Fuzzy, or TermRangeQueries.\nMaybe we port over the whole analysis factory infrastructure to Lucene, then this might be fixed, but that is not possible at the moment with what's available in Lucene. ",
            "author": "Uwe Schindler",
            "id": "comment-13420826"
        }
    ]
}