{
    "id": "LUCENE-7274",
    "title": "Add LogisticRegressionDocumentClassifier",
    "details": {
        "resolution": "Won't Fix",
        "affect_versions": "None",
        "components": [
            "modules/classification"
        ],
        "labels": "",
        "fix_versions": [],
        "priority": "Major",
        "status": "Resolved",
        "type": "Improvement"
    },
    "description": "Add LogisticRegressionDocumentClassifier for Lucene.",
    "attachments": {
        "LUCENE-7274.patch": "https://issues.apache.org/jira/secure/attachment/12802587/LUCENE-7274.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "id": "comment-15273579",
            "author": "Cao Manh Dat",
            "date": "2016-05-06T03:18:15+0000",
            "content": "Initial patch that support classify doc based on input weights and fields. "
        },
        {
            "id": "comment-15669850",
            "author": "Tommaso Teofili",
            "date": "2016-11-16T08:47:44+0000",
            "content": "Hi Cao Manh Dat, thanks for your patch.\nA couple of comments:\n\n\tI think it'd be good if we could make it a LogisticRegressionClassifier and then extend it into a LogisticRegressionDocumentClassifier (like for KNearestNeighbourClassifier.\n\tIIUTC this implementation assumes each feature is stored in a separate field and the weights to be computed externally as a double[] , can this work for example with Solr's capabilities to store AI models ?\n\tregarding the labels, wouldn't it be better to declare the classifier as a Classifier<Boolean>\u00a0(it's a binary classifier in the end)?\n\tthe changes to NumericDocValues, FloatDocValues and DoubleDocValues break some lucene/core tests as it seems your patched NumericDocValues always returns a Long while FloatDV and DoubleDV convert such a Long value to an Integer and then back to a Float / Double using Float.intBitsToFloat / Double.intBitsToDouble, can you clarify if / why that is needed ?\n\n "
        },
        {
            "id": "comment-15834076",
            "author": "Tommaso Teofili",
            "date": "2017-01-23T08:48:42+0000",
            "content": "Cao Manh Dat would you have time to have a look into the above points ? "
        },
        {
            "id": "comment-15834091",
            "author": "Cao Manh Dat",
            "date": "2017-01-23T09:04:27+0000",
            "content": "Tommaso Teofili Sure, I will take a look at above points, soon! "
        },
        {
            "id": "comment-15849629",
            "author": "Cao Manh Dat",
            "date": "2017-02-02T08:11:47+0000",
            "content": "Tommaso Teofili After review the patch, I'm afraid that we should close this issue as won't fix.\n\nBecause all classifiers in classification module are lazy learning methods and relied on Lucene to quickly classify documents. They don't have any pre-trained model. Logistic Regression in other way is eager learning method, so It need a pre-trained model to classify documents. But the patch did not provide an api to train a logistic regression model, so it will be hard for users to use LogisticRegressionDocumentClassifier.\n\nBTW SOLR-8492 and SOLR-9252 provide an api for training a model. The trained model will be stored as a document in Lucene index. So it will make Lucene depend on how Solr construct that model, but I don't think it will be a good idea. \n\nSo I think we can close this issue and create another issue like \"an unify api for eager learning method in classification module\" "
        },
        {
            "id": "comment-15849959",
            "author": "Tommaso Teofili",
            "date": "2017-02-02T14:20:50+0000",
            "content": "+1 thanks Cao Manh Dat. "
        }
    ]
}