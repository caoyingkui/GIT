{
    "id": "SOLR-12405",
    "title": "Add a quality of service type filter for request load management and request throttling.",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [],
        "type": "New Feature",
        "fix_versions": [],
        "affect_versions": "None",
        "resolution": "Unresolved",
        "status": "Open"
    },
    "description": "Trying to manage resource usage just with thread / connection pool limits is a losing strategy ( especially without using Continuations and making scalability vs performance tradeoffs) if you cannot manage requests.\n\nA QOSFilter type servlet filter with give us some base functionality we want:\n\nAbility to limit number of concurrent requests.\n\nAbility to queue requests without holding a thread per request.\n\nAbility to drop requests over a certain queue size.\n\nAbility to prioritize requests on the queue.",
    "attachments": {
        "SOLR-12405.patch": "https://issues.apache.org/jira/secure/attachment/12925874/SOLR-12405.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2018-05-26T10:14:16+0000",
            "content": "Some ideas:\n\nCoordinate settings using ZooKeeper?\n\ntlog replay could efficiently throttle requests while replaying buffered documents.\n\nInternal requests could get a higher priority.\n\nThe natural throttling that some want with pool limits can be done in a more efficient way and with a single more understandable config (number of concurrent requests allowed). ",
            "author": "Mark Miller",
            "id": "comment-16491600"
        },
        {
            "date": "2018-05-26T10:21:18+0000",
            "content": "We could start simply, but I thought it might be nice to get to the point that limits could be changed based on\u00a0changing\u00a0metrics. If a replica is super overloaded, we can start queuing up more requests, or even dropping them. Perhaps this could be complementary to\u00a0a Jira that I don't think was finished that lets a replica go inactive when too much load is seen. ",
            "author": "Mark Miller",
            "id": "comment-16491602"
        },
        {
            "date": "2018-05-26T10:40:13+0000",
            "content": "Internal requests could get a higher priority.\n\nActually we probably only want to queue and maintain a max of external requests and always let internal requests though. ",
            "author": "Mark Miller",
            "id": "comment-16491611"
        },
        {
            "date": "2018-05-26T17:48:54+0000",
            "content": "I started playing with this in my HTTP/2 branch: https://github.com/markrmiller/lucene-solr/blob/http2/solr/core/src/java/org/apache/solr/servlet/SolrQoSFilter.java\n\nIn terms of keeping resources under control, pretty effective. ",
            "author": "Mark Miller",
            "id": "comment-16491758"
        },
        {
            "date": "2018-05-27T01:47:35+0000",
            "content": "This is pretty sweet - a much more effective way of limiting resource usage than pool sizes and timeouts on queue waits.\n\nWithout using a an async model like continuations, any thread/connection pool limits end up being fairly nasty in our architecture, and distrib deadlock will be looking to bite you out of the blue when you cluster or traffic or feature use changes.\n\nAsync models are great for possibly scaling to more requests handled concurrently than your system can have threads, but under more forgiving traffic, the current model is going to be more efficient. Async models also push you towards a somewhat awkward request handling model. I think it would be interesting to offer it on our update and search paths if we can do it without too much craziness, but with something like full text search, I'm not even sure how much of a scalability win it could really be.\n\nSo that means we want to continue offering our current efficient model, but we can't reasonably limit OS resources in a nice way. We can limit external requests efficiently though, which is a great way to control a lot of resource usage at a single, easy to reason point.\n\nAdjusting the max concurrent external requests based on system load and throttling for updatelog request recovery are what I'd like to look at next with this. ",
            "author": "Mark Miller",
            "id": "comment-16491874"
        },
        {
            "date": "2018-05-31T07:22:15+0000",
            "content": "WIP patch , which copies over https://github.com/markrmiller/lucene-solr/blob/http2/solr/core/src/java/org/apache/solr/servlet/SolrQoSFilter.java\u00a0and marks all HttpShardHandler requests as internal.\u00a0 ",
            "author": "Varun Thacker",
            "id": "comment-16496212"
        },
        {
            "date": "2018-06-02T21:06:58+0000",
            "content": "Just to experiment a little to understand how this works better. So I changed the qos filter to be\n\n@Override\npublic void init(FilterConfig filterConfig) {\n  super.init(filterConfig);\n  _origMaxRequests = 0;\n  super.setMaxRequests(_origMaxRequests);\n  super.setSuspendMs(60000);\n  super.setWaitMs(50);\n}\n\n@Override\npublic void doFilter(ServletRequest request, ServletResponse response, FilterChain chain)\n    throws IOException, ServletException {\n  HttpServletRequest req = (HttpServletRequest) request;\n  String source = req.getHeader(QoSParams.REQUEST_SOURCE);\n  if (req.getServletPath() != null && req.getServletPath().contains(\"/update\")) {\n    log.info(\"Blocking update\");\n    super.doFilter(req, response, chain);\n  } else {\n    chain.doFilter(req, response);\n  }\n}\n\nNever does an update get processed as expected. At the 1 minute mark the client would get back a 503\u00a0\n\n[master] ~/apache-work/lucene-solr/solr$ time curl http://127.0.0.1:8983/solr/techproducts/update?commit=true -H 'Content-type:application/json' -d '\n\n[\n\n{\"id\" : \"1\"}\n\n]'\n\n<html>\n\n<head>\n\n<meta http-equiv=\"Content-Type\" content=\"text/html;charset=utf-8\"/>\n\n<title>Error 503 Service Unavailable</title>\n\n</head>\n\n<body><h2>HTTP ERROR 503</h2>\n\n<p>Problem accessing /solr/techproducts/update. Reason:\n\n<pre>\u00a0 \u00a0 Service Unavailable</pre></p>\n\n</body>\n\n</html>\n\n\nreal\t1m0.130s\n\nuser\t0m0.007s\n\nsys\t0m0.007s\n\n\u00a0 ",
            "author": "Varun Thacker",
            "id": "comment-16499187"
        },
        {
            "date": "2018-08-16T20:39:57+0000",
            "content": "Here's an interesting article for reference :\u00a0https://engineering.linkedin.com/blog/2018/05/making-linkedin-s-organic-feed-handle-peak-traffic ",
            "author": "Varun Thacker",
            "id": "comment-16583038"
        }
    ]
}