{
    "id": "LUCENE-7778",
    "title": "Remove synchronized from high-contention methods on RAMFile",
    "details": {
        "labels": "",
        "priority": "Minor",
        "resolution": "Unresolved",
        "affect_versions": "None",
        "status": "Open",
        "type": "Improvement",
        "components": [
            "core/store"
        ],
        "fix_versions": []
    },
    "description": "When benchmarking RAMDirectory access via multiple threads the methods RAMFile::numBuffers and RAMFile::getBuffer show up blocking threads fairly frequently\n\nBy removing the synchronized keyword from these methods our internal benchmarks show a 2x performance increase under concurrent load.\n\nI don't think removing synchronized from these methods is a problem as they are read-only and write access to these fields is not synchronized.  LUCENE-2779 also implies that some ofthe locking on RAMDirectory is not necessary",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "id": "comment-15964589",
            "date": "2017-04-11T16:12:20+0000",
            "content": "RAMDirectory is not designed to be fast, only to make testing easier. Maybe you should switch to MMapDirectory? You could still have all the index content in memory by using an index directory on a tmpfs mount or by telling MMapDirectory to load the content of the files into memory with MMapDirectory.setPreload(true). ",
            "author": "Adrien Grand"
        },
        {
            "id": "comment-15964590",
            "date": "2017-04-11T16:12:23+0000",
            "content": "GitHub user spmason opened a pull request:\n\n    https://github.com/apache/lucene-solr/pull/183\n\n    LUCENE-7778 Removed synchronized from RAMFile methods\n\n    These methods don't seem to benefit from locking - the methods that mutate the underlying fields aren't synchronized themselves, for example\n\n    Removing these methods gives me a 2x throughput increase under concurrent load on internal benchmarks\n\nYou can merge this pull request into a Git repository by running:\n\n    $ git pull https://github.com/spmason/lucene-solr-1 ram-directory-remove-synchronized\n\nAlternatively you can review and apply these changes as the patch at:\n\n    https://github.com/apache/lucene-solr/pull/183.patch\n\nTo close this pull request, make a commit to your master/trunk branch\nwith (at least) the following in the commit message:\n\n    This closes #183\n\n\ncommit 2439b917a33b91892e326ce4467cace46ad9ded5\nAuthor: Steve Mason <stevem@brandwatch.com>\nDate:   2017-04-11T11:08:38Z\n\n    LUCENE-7778 Removed synchronized from RAMFile methods\n\n    These methods don't seem to benefit from locking - the methods that mutate the underlying fields aren't synchronized themselves, for example\n\n ",
            "author": "ASF GitHub Bot"
        },
        {
            "id": "comment-15964602",
            "date": "2017-04-11T16:27:46+0000",
            "content": "I actually simplified the description a bit because we're using Luwak, which utilises a RAMDirectory under the hood. I'll take a look at the performance of the MMapDirectory though and see if it makes a reasonable solution\n\nThough if it can be agreed that synchronised on those method is pointless, then the patch I've submitted should still be good regardless of my motivations behind submitting it? ",
            "author": "Steve Mason"
        },
        {
            "id": "comment-15965678",
            "date": "2017-04-12T11:24:15+0000",
            "content": "Thanks for suggesting MMapDirectory with MMapDirectory.setPreload(true).  I've tried this out with a locally patched version of Luwak and performance suffers massively - it's at least 20% slower than RAMDirectory in its current form and 80% slower than RAMDirectory with my changes applied.\n\nFrom looking at stacks to see what it's doing it seems to be mostly spending a lot of time writing to disk or doing direct memory access.  As Luwak is all about on-the-fly matching of documents to queries, writing to disk or going outside of the JVM seems redundant because we only need the index for less than a second before we're on to matching the next set of documents.\n\nIt seems that RAMDirectory fits this use-case pretty well - it's accurate and performs decently (better after these changes).  We aren't using it for massive in-memory indexes (I'm using batches from 10 to 200 documents) and the lifetime of them is very short so GC issues aren't a concern.\n\nI've noticed that my assertion in the description that RAMFile doesn't lock during writes is wrong - addBuffer has a `synchronized(this)` block in it.  Before I change my patch to use a more complicated ReadWriteLock arrangement are there any further objections to fixing this issue? ",
            "author": "Steve Mason"
        },
        {
            "id": "comment-15972823",
            "date": "2017-04-18T14:45:12+0000",
            "content": "The fact that MMapDirectory performs worse than RAMDirectory is a bit counter-intuitive to me, what does your workload look like? Your last comment suggests that you run queries on tiny indexes that contain 10 to 200 documents, is it correct? This looks like a use-case that MemoryIndex has been designed for? ",
            "author": "Adrien Grand"
        },
        {
            "id": "comment-15972932",
            "date": "2017-04-18T15:39:55+0000",
            "content": "Yes we're using small temporary indexes to do on-the-fly matching of documents to queries (not vice-versa which is the regular Lucene use-case).\n\nLuwak actually uses a MemoryIndex internally if you give it a batch of one document. If you have a number of documents to search it switches to a RAMDirectory. With the batch sizes we're using Luwak / RAMDirectory performance surpasses MemoryIndex by a factor of 2-3.\n\nMemoryIndex performance appears to be constant - one query checked against one page will always take roughly X milliseconds. If you have Y queries and Z pages then the time taken to search will be roughly X * Y * Z milliseconds.  With RAMDirectory the performance doesn't scale linearly given the number of documents in the index like this.  It might take 10 milliseconds to search an index of 10 documents, but it'll take 20 milliseconds to search an index of 100 documents (I'm making up the numbers here, but that's the effect we're observing).\n\nWhen using MMapDirectory it seems that the cost of I/O starts to come into play - with both RAMDirectory and MemoryIndex the time to index the document doesn't show up as being a factor really (this contention was observed when reading from a RAMDirectory).  With MMap it's a big factor (there also seems to be some more contention / blocking / thread joining going on, which looks pretty hairy) ",
            "author": "Steve Mason"
        },
        {
            "id": "comment-16013958",
            "date": "2017-05-17T12:48:20+0000",
            "content": "Github user spmason closed the pull request at:\n\n    https://github.com/apache/lucene-solr/pull/183 ",
            "author": "ASF GitHub Bot"
        }
    ]
}