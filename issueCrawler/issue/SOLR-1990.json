{
    "id": "SOLR-1990",
    "title": "blockUntilFinished() is called in StreamingUpdateSolrServer more often then it should",
    "details": {
        "affect_versions": "1.4.1",
        "status": "Open",
        "fix_versions": [],
        "components": [
            "clients - java"
        ],
        "type": "Bug",
        "priority": "Major",
        "labels": "",
        "resolution": "Unresolved"
    },
    "description": "in the StreamingUpdateSolrServer .request() it identifies a commit/optimize request by having no document...\n\n\n    // this happens for commit...\n    if( req.getDocuments()==null || req.getDocuments().isEmpty() ) {\n      blockUntilFinished();\n\n\n\n...but there are other situations where an UpdateRequest will nave no documents (delete, updates using stream.url or stream.file, etc...)",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "author": "Mark Miller",
            "id": "comment-12886371",
            "date": "2010-07-08T16:53:10+0000",
            "content": "Nice catch - is this causing you a particular problem?\n\nLooks like if you submit a delete in a long line of adds, rather than putting the delete into the request queue, it's going to block and wait for all the previous doc adds to finish, then process the delete, then continue processing docs.\n\nCould always check for a delete query or delete id(s), but I wonder if there is a better way to just check if the request is a commit or optimize rather than checking everything else. "
        },
        {
            "author": "ofer fort",
            "id": "comment-12886389",
            "date": "2010-07-08T17:50:17+0000",
            "content": "I am not sure, still investigating.\nAt a specific moment i had two threads trying to delete two documents, and a\nfew others that were adding documents.\nThe ones deleting were both parking(waiting on the lock), so my big concern\nis that it's actually a deadlock, but still not sure\n\ntwo thread with:\n  \"IndexWorker0\" prio=5 tid=267 WAITING\n    at sun.misc.Unsafe.park(Native Method)\n    at java.util.concurrent.locks.LockSupport.park(LockSupport.java:158)\n    at\njava.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:747)\n    at\njava.util.concurrent.locks.AbstractQueuedSynchronizer.acquireQueued(AbstractQueuedSynchronizer.java:778)\n    at\njava.util.concurrent.locks.AbstractQueuedSynchronizer.acquire(AbstractQueuedSynchronizer.java:1114)\n    at\njava.util.concurrent.locks.ReentrantLock$NonfairSync.lock(ReentrantLock.java:186)\n    at java.util.concurrent.locks.ReentrantLock.lock(ReentrantLock.java:262)\n    at\norg.apache.solr.client.solrj.impl.StreamingUpdateSolrServer.blockUntilFinished(StreamingUpdateSolrServer.java:232)\n    at\norg.apache.solr.client.solrj.impl.StreamingUpdateSolrServer.request(StreamingUpdateSolrServer.java:181)\n    at\norg.apache.solr.client.solrj.request.AbstractUpdateRequest.process(AbstractUpdateRequest.java:105)\n    at\norg.apache.solr.client.solrj.SolrServer.deleteById(SolrServer.java:102)\n\n\na few threads with:\n  \"pool-1-thread-158\" prio=5 tid=1288 RUNNABLE\n    at java.net.SocketInputStream.socketRead0(Native Method)\n    at java.net.SocketInputStream.read(SocketInputStream.java:129)\n    at java.io.BufferedInputStream.fill(BufferedInputStream.java:218)\n    at java.io.BufferedInputStream.read(BufferedInputStream.java:237)\n    at\norg.apache.commons.httpclient.HttpParser.readRawLine(HttpParser.java:78)\n    at\norg.apache.commons.httpclient.HttpParser.readLine(HttpParser.java:106)\n    at\norg.apache.commons.httpclient.HttpConnection.readLine(HttpConnection.java:1116)\n    at\norg.apache.commons.httpclient.MultiThreadedHttpConnectionManager$HttpConnectionAdapter.readLine(MultiThreadedHttpConnectionManager.java:1413)\n    at\norg.apache.commons.httpclient.HttpMethodBase.readStatusLine(HttpMethodBase.java:1973)\n    at\norg.apache.commons.httpclient.HttpMethodBase.readResponse(HttpMethodBase.java:1735)\n    at\norg.apache.commons.httpclient.HttpMethodBase.execute(HttpMethodBase.java:1098)\n    at\norg.apache.commons.httpclient.HttpMethodDirector.executeWithRetry(HttpMethodDirector.java:398)\n    at\norg.apache.commons.httpclient.HttpMethodDirector.executeMethod(HttpMethodDirector.java:171)\n    at\norg.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:397)\n    at\norg.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:323)\n    at\norg.apache.solr.client.solrj.impl.StreamingUpdateSolrServer$Runner.run(StreamingUpdateSolrServer.java:137)\n\n\n\n "
        },
        {
            "author": "ofer fort",
            "id": "comment-12886398",
            "date": "2010-07-08T18:17:00+0000",
            "content": "reading the thread dump again, it seems i have only one thread deleting and\na lot of adding ones.\nthe one deleting is just waiting...\n\n "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12886404",
            "date": "2010-07-08T18:46:44+0000",
            "content": "Is this behavior by design?\n\nIf you do an add followed by a delete of the same document, one would normally expect that the document would be deleted.  Without ordering things, you can't really guarantee that though.\n\nOf course the same problem exists if you add multiple documents with the same id - you don't know which will end up winning by being last. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-12886409",
            "date": "2010-07-08T18:50:21+0000",
            "content": "reading the thread dump again, it seems i have only one thread deleting and a lot of adding ones. the one deleting is just waiting...\n\nRight - the delete thread will wait until all the other threads are done adding.\n\nIs this behavior by design?\n\nI doubt it - looks like an oversight - don't see why the delete should not just go in the queue like doc adds. "
        },
        {
            "author": "ofer fort",
            "id": "comment-12886422",
            "date": "2010-07-08T19:24:27+0000",
            "content": "Each document has it's own id.\nThe deleted document is not one of the added ones. It was added a while ago\nand if my application realizes it is not relevant anymore, it will delete\nit.\n\n\n\u05d1-08/07/2010, \u05d1\u05e9\u05e2\u05d4 21:47, \"Yonik Seeley (JIRA)\" <jira@apache.org> \u05db\u05ea\u05d1/\u05d4:\n\n\n   [\nhttps://issues.apache.org/jira/browse/SOLR-1990?page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel&focusedCommentId=12886404#action_12886404]\n\nYonik Seeley commented on SOLR-1990:\n------------------------------------\n\nIs this behavior by design?\n\nIf you do an add followed by a delete of the same document, one would\nnormally expect that the document would be deleted.  Without ordering\nthings, you can't really guarantee that though.\n\nOf course the same problem exists if you add multiple documents with the\nsame id - you don't know which will end up winning by being last.\n\nblockUntilFinished() is called in StreamingUpdateSolrServer when deleing by\nid\n\n------------------------------------------------------------------------------\n\n\n               Key: SOLR-1990\n\n               URL: https://issues.apache.org/jira/browse/SOLR-1990\n\n           Project: Solr\n\n        Issue Type: Bug\n\n        Components: clients - java\n\n  Affects Versions: 1.4.1\n\n          Reporter: ofer fort\n\n Original Estimate: 24h\n\nRemaining Estimate: 24h\n\n\nin the StreamingUpdateSolrServer .request() it identifies a commit/optimize\nrequest by having no document, but also the delete doesn't have a docuemnt.\n\n   // this happens for commit...\n\n   if( req.getDocuments()==null || req.getDocuments().isEmpty() ) {\n\n     blockUntilFinished();\n\n\n\u2013 \nThis message is automatically generated by JIRA.\n-\nYou can reply to this email to add a comment to the issue online. "
        },
        {
            "author": "Hoss Man",
            "id": "comment-12899128",
            "date": "2010-08-16T22:08:56+0000",
            "content": "updating summary/description to note that the issue goes beyond just deletes by query.\n\nanother example noted on the user list is when doing index updates using stream.url or stream.file \u2013 these are update requests that do not include any documents, and even if it is considered intentional that \"deletes\" block until the queue is empty, these updates certainly shouldn't. "
        },
        {
            "author": "Hoss Man",
            "id": "comment-12899130",
            "date": "2010-08-16T22:12:40+0000",
            "content": "Note: the entire premise of the code in question, that updates w/o documents should \"blockUntilFinished\" because \"this happens for commit\" makes no sense to me.\n\nIn the Runnable where requests that do make it into the queue are processed, there is code that explicitly checks for requests which include the \"commit\" or \"optimize\" params and those are processed as part of the stream \u2013 w/o blocking.\n\nSo why should a \"commit\" by itself block, but an update doc that includes an \"optimize\" not block? "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-12899739",
            "date": "2010-08-18T05:45:59+0000",
            "content": "IIRC, the big picture intention is that <commit/> with the StreamingUpdateSolrServer should behave the same as <commit/> with the other (non-streaming) implementations.  People using the implementation should not need to know to blockUntilFinished() for commit to work properly.  \n\nIt seem the check should be:\n\nif( req.getAction() != null ) {\n   blockUntilFinished();\n}\n\n\n\nThough it may be good to try and avoid the two map lookups for every request:\n\npublic ACTION getAction() {\n    if (params==null) return null;\n    if (params.getBool(UpdateParams.COMMIT, false)) return ACTION.COMMIT;\n    if (params.getBool(UpdateParams.OPTIMIZE, false)) return ACTION.OPTIMIZE;\n    return null;\n}\n\n\n\n "
        }
    ]
}