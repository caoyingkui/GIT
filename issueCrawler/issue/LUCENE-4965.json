{
    "id": "LUCENE-4965",
    "title": "Add dynamic numeric range faceting",
    "details": {
        "components": [
            "modules/facet"
        ],
        "fix_versions": [
            "4.4",
            "6.0"
        ],
        "affect_versions": "None",
        "priority": "Major",
        "labels": "",
        "type": "Improvement",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "The facet module today requires the app to compute the hierarchy\nat index time, eg a timestamp field might use a year/month/day\nhierarchy.\n\nWhile this gives great performance, since it minimizes the search-time\ncomputation, sometimes it's unfortunately useful/necessary to do things entirely at\nsearch time, like Solr does.\n\nE.g. I'm playing with a prototype Lucene search for Jira issues\nand I'd like to add a drill down+sideways for \"Updated in past day,\n2 days, week, month\" etc.  But because time is constantly advancing,\ndoing this at index time is a not easy ...",
    "attachments": {
        "LUCENE-4965.patch": "https://issues.apache.org/jira/secure/attachment/12580848/LUCENE-4965.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2013-04-27T21:23:16+0000",
            "content": "Patch, just a start but the test passes  It uses a NumericDV field\nand just does the obvious approach (load value for each hit and find\nranges that value falls within).  Once LUCENE-4964 is in I'll test the\nintegration with DrillDown/SidewaysQuery... ",
            "author": "Michael McCandless",
            "id": "comment-13643801"
        },
        {
            "date": "2013-04-28T05:47:46+0000",
            "content": "Looks great! Few comments:\n\n\n\tI think the Accumulator should not take FSP, just the ndv field, for various reasons:\n\t\n\t\tIt will eliminate the need for the checks about the validity of FSP\n\t\tWhen I read the test, it seemed awkward to me that you need to create a FSP and CountingFR, since 'field' is not a facet at all...\n\t\n\t\n\n\n\n\n\tIf you change FacetsAccumulator to not initialize a FacetArrays, you can safely pass null for taxonomy and FacetArrays\n\n\n\n\n\tI think the only reason you override getAggregator is because FacetsCollector.create() calls it to determine if doc scores are needed?\n\t\n\t\tMaybe we can have FacetsAccumulator.requiresDocScore() \u2013 the default will call getAggregator().requireDocScore() and you will just return false? Then FC will use the accumulator to determine that.\n\t\n\t\n\n\n\n\n\tRegarding the \"nocommit int/float/double too\", I think this class should be called DynamicLongRangeAccumulator since it can only handle longs. To handle int/float/double, you will need to override accumulate() entirely to pull a different DV and find the range.\n\t\n\t\tIf you make this class abstract, you can have a utility method which converts the ranges to FacetResultNodes.\n\t\n\t\n\n\n\n\n\tif (r.count > 0) \u2013 I think that's wrong? We should return all requested ranges, some may be with count=0. Just like we return in normal faceted search a FacetResult per FacetRequest.\n\n\n\n\n\tInstead of addLongRange, can the ctor take an IndexReader and LongRange...? The ranges need to be final (there's no sense adding a new range after accumulate), and also, I think that the start/endInclusive logic may not be that simple when you come to handle a FloatRange.\n\n ",
            "author": "Shai Erera",
            "id": "comment-13643912"
        },
        {
            "date": "2013-04-28T14:25:16+0000",
            "content": "New patch incorporating Shai's feedback ... ",
            "author": "Michael McCandless",
            "id": "comment-13644028"
        },
        {
            "date": "2013-04-28T14:30:39+0000",
            "content": "Woops, trying again ... ",
            "author": "Michael McCandless",
            "id": "comment-13644029"
        },
        {
            "date": "2013-04-28T14:52:27+0000",
            "content": "Thanks Mike. Looks good! Few more comments:\n\n\n\tThe nocommit on default aggregator \u2013 I think you can override and throw Unsupported?\n\n\n\n\n\t+1 to move to o.a.l.facet.dynamic, or oal.facet.range.\n\n\n\n\n\tDynamicRange:\n\t\n\t\tthanks for introducing accept(), but I don't think the way it's implemented can support other impls, such as float/double.\n\t\tPerhapd instead DynamicRange should be abstract, with impls for LongRange, IntRange, FloatRange and DoubleRange, which can then implement accept properly.\n\t\t\n\t\t\tIt won't have min/max, but can keep label.\n\t\t\n\t\t\n\t\tAlso, that will allow you to add type-safety to DynamicRangeFacetRequest. I.e. now someone can pass int and float ranges in the same request, which makes no sense. But if you make it 'typed', one would need to specify the type at construction, and cannot make mistakes.\n\t\t\n\t\t\tDRFR would then be defined with <T extends DynamicRange> and its ctor would take T....\n\t\t\n\t\t\n\t\n\t\n\n\n\n\n\tI think it's ok if the request is called DynamicRange without numerics because someone can write a DynamicRange impl not on numeric fields. He'll then need to also write an accumulator though, but as for the request, it's still about DynamicRange implementations ... in short, I'm +0 if it stays like that or renamed .\n\n ",
            "author": "Shai Erera",
            "id": "comment-13644032"
        },
        {
            "date": "2013-04-28T15:14:21+0000",
            "content": "Patch, just moving things under oal.facet.range.\n\nI'm ... not sure how to do the generics to support float/double/int/long, without just making separate Accumulator (eg Int/Float/Double/LongRangeAccumulator), since I need to use native types for each case.  \n\nAlso, I think ideally (maybe not on the first commit), we should use an interval tree to find overlapping ranges for each value ... so somehow we'd need to build this from all of the provided ranges up front. ",
            "author": "Michael McCandless",
            "id": "comment-13644036"
        },
        {
            "date": "2013-04-28T17:35:07+0000",
            "content": "New patch, breaking out separate .newLong/Float/DoubleRange. ",
            "author": "Michael McCandless",
            "id": "comment-13644067"
        },
        {
            "date": "2013-04-28T19:30:41+0000",
            "content": "Comments:\n\n\n\tRange is not really extendable (private ctor) \u2013 is that intentional? I guess there's not much point extending it ...\n\n\n\n\n\tAny reason why not take primitive values and let the user define e.g Long.MAX_VALUE as an unlimited upper bound? I'm not a big fan of auto-boxing, and passing null is as good to me as passing MAX_VAL. User has to make a decision anyway, so might as well be explicit about it.\n\n\n\n\n\tAccumulate() iterates at the outer loop on matchingDocs, and inner loop on ranges. I remember while writing FacetsAccumulator that luceneutil was happier with the other way (matchingDocs inner). Maybe test?\n\n\n\n\n\tShouldn't if (ranges.ranges.accept(v)) break if there's a match?\n\t\n\t\tWhile at it, maybe RangeSet should sort the ranges by their minimum value? Not sure if asymptotically this will matter...\n\t\n\t\n\n\n\n\n\tI don't think it matters much, but maybe allocate new ArrayList<FacetResultNode>() with ranges.ranges.length?\n\n\n\nI think this we're almost ready! ",
            "author": "Shai Erera",
            "id": "comment-13644101"
        },
        {
            "date": "2013-04-28T22:21:41+0000",
            "content": "Range is not really extendable (private ctor) \u2013 is that intentional? I guess there's not much point extending it ...\n\nI suppose if an app had some custom encoding (into the long value in NumericDVField) then it would need a custom impl?  I'll make it protected...\n\nAny reason why not take primitive values and let the user define e.g Long.MAX_VALUE as an unlimited upper bound? \n\nI was trying to mimic NumericRangeQuery, but I agree: let's just take primitives.\n\nAccumulate() iterates at the outer loop on matchingDocs, and inner loop on ranges. I remember while writing FacetsAccumulator that luceneutil was happier with the other way (matchingDocs inner). Maybe test?\n\nAhhh right I forgot about that   I'll just switch it to inner loop on matchingDocs... I'm not quite set up to perf test this yet \n\nShouldn't if (ranges.ranges.accept(v)) break if there's a match\n\nI think not?  Ie overlapping ranges should be allowed?  For Jira search I'd like to have \"Past day\", \"Past 2 days\", etc.\n\nWhile at it, maybe RangeSet should sort the ranges by their minimum value? Not sure if asymptotically this will matter...\n\nI think we need to use an interval tree here (I put a TODO) ... it's a little tricky to do that since each Range has its own private min/max ... but I think we can do this in a followon issue. ",
            "author": "Michael McCandless",
            "id": "comment-13644156"
        },
        {
            "date": "2013-04-28T22:23:06+0000",
            "content": "Patch w/ last round of fixes... ",
            "author": "Michael McCandless",
            "id": "comment-13644157"
        },
        {
            "date": "2013-04-29T05:34:01+0000",
            "content": "Ie overlapping ranges should be allowed?\n\nAhh, you're right.\n\nit's a little tricky to do that since each Range has its own private min/max\n\nMaybe Range can implement Comparable, and you build the tree using it, like we build PQ? In practice though, I wonder how much more efficient a tree would be vs simply sorting and iterating until a range is bigger than value? We're talking probably very few ranges no?\n\nBTW, I think Range would need to implement Comparable as well as compareTo(long) since a value may not fall into the first (sorted order) range (e.g. range.accept() returns false), but you'll need to continue looking until range.compareTo(long) > 0 (i.e. range.minValue > value).\n\nAlso, maybe instead of FRN we should return a RangeFRN which contains the range? That way, someone can extract the min/max values of the range without parsing the label by casting to the range added? Hmm, but then you'll need to make the range impls public, but maybe that's not bad? Instead of Range.newLongRange, someone will just do new LongRange()?\n\nI see you decided not to go with generics? In that case, maybe document that you are expected to pass the same Range type? Although, why not make RangeFacetRequest generic and prevent this pitfall? ",
            "author": "Shai Erera",
            "id": "comment-13644279"
        },
        {
            "date": "2013-04-29T10:30:08+0000",
            "content": "New patch, adds generics to make sure the Range instances are the same class, and switches to simple ctors instead of .newXXXRange.\n\nI also added RangeFRN ... I only use it for the \"sub nodes\" and not the root node.\n\nI don't think we should try to do the sorting here ... I think that's too simplistic ... we should do an interval tree (but on a new issue).\n\nEg the simplistic sorting approach can easily fail to speed things up if, say, most of my values are > max(range.max) (this will be the case with the Jira search) and you had sorted \"smallest to biggest\". ",
            "author": "Michael McCandless",
            "id": "comment-13644402"
        },
        {
            "date": "2013-04-29T11:03:51+0000",
            "content": "I agree we should optimize separately (and preferably after you have luceneutil set up so we can measure how important it really is).\n\nThanks for adding generics.\n\n+1 to commit! ",
            "author": "Shai Erera",
            "id": "comment-13644419"
        },
        {
            "date": "2013-04-29T21:33:38+0000",
            "content": "New patch, breaking out Long/Float/DoubleRange as standalone sources, adding Test/RangeFacetsExample, and adding randomized tests in TestRangeAccumulator ... ",
            "author": "Michael McCandless",
            "id": "comment-13644900"
        },
        {
            "date": "2013-04-30T08:04:24+0000",
            "content": "Awesome! And thanks for adding the examples!\n\nIn TestRangeAccumulator:\n\n\tYou don't use LongRange.accept (for expected counts) b/c that's what you test right? maybe just drop a one liner?\n\tAlso, does the test really need to run atLeast(100) iters? I would think one iteration is enough, if we let Jenkins periodic builds do the iters for us (plus, someone can run with -Dtests.iters or -Dtests.dups)\n\tThese apply to all 4 random test methods.\n\n\n\nIn RangeAccumulator:\n\n\tI think you can remove \"nocommit add to example\"?\n\tThere are some leftover commented out lines (members and ctor)\n\n\n\nIn the example:\n\n\tnew Date().getTime() can be just System.currentTimeMillis()?\n\tAlso, do we really need to index 1000 documents to demo? I ask because it's harder to debug 1000 docs \n\n\n\nI'm +1 to commit, no need to upload a new patch from my side. ",
            "author": "Shai Erera",
            "id": "comment-13645375"
        },
        {
            "date": "2013-04-30T10:56:50+0000",
            "content": "\nYou don't use LongRange.accept (for expected counts) b/c that's what you test right? maybe just drop a one liner?\n\nRight, I'll add a comment.\n\nAlso, does the test really need to run atLeast(100) iters? I would think one iteration is enough, if we let Jenkins periodic builds do the iters for us (plus, someone can run with -Dtests.iters or -Dtests.dups)\n\nWell it's an efficiency question I guess (how many jenkins iters will\nit take to find a bug) ... I have beasted it and it's passing for me\n  I'll drop it to 10 ... the test is plenty fast.\n\nI think you can remove \"nocommit add to example\"?\nThere are some leftover commented out lines (members and ctor)\n\nWoops, fixed!\n\n\nIn the example:\nnew Date().getTime() can be just System.currentTimeMillis()?\nAlso, do we really need to index 1000 documents to demo? I ask because it's harder to debug 1000 docs \n\nGood, I'll switch to currentTimeMillis, and drop it to 100 docs.\n\nThanks Shai. ",
            "author": "Michael McCandless",
            "id": "comment-13645459"
        },
        {
            "date": "2013-04-30T11:02:19+0000",
            "content": "Great thanks. +1! ",
            "author": "Shai Erera",
            "id": "comment-13645462"
        },
        {
            "date": "2013-04-30T11:17:34+0000",
            "content": "[branch_4x commit] mikemccand\nhttp://svn.apache.org/viewvc?view=revision&revision=1477560\n\nLUCENE-4965: add dynamic numeric range faceting ",
            "author": "Commit Tag Bot",
            "id": "comment-13645474"
        },
        {
            "date": "2013-04-30T11:20:15+0000",
            "content": "[trunk commit] mikemccand\nhttp://svn.apache.org/viewvc?view=revision&revision=1477562\n\nLUCENE-4965: add dynamic numeric range faceting ",
            "author": "Commit Tag Bot",
            "id": "comment-13645476"
        },
        {
            "date": "2013-04-30T11:20:29+0000",
            "content": "[trunk commit] mikemccand\nhttp://svn.apache.org/viewvc?view=revision&revision=1477563\n\nLUCENE-4965: add dynamic numeric range faceting ",
            "author": "Commit Tag Bot",
            "id": "comment-13645477"
        },
        {
            "date": "2013-04-30T11:21:46+0000",
            "content": "[branch_4x commit] mikemccand\nhttp://svn.apache.org/viewvc?view=revision&revision=1477564\n\nLUCENE-4965: add dynamic numeric range faceting ",
            "author": "Commit Tag Bot",
            "id": "comment-13645478"
        },
        {
            "date": "2013-04-30T11:22:10+0000",
            "content": "Thanks Shai! ",
            "author": "Michael McCandless",
            "id": "comment-13645479"
        },
        {
            "date": "2013-07-23T18:37:00+0000",
            "content": "Bulk close resolved 4.4 issues ",
            "author": "Steve Rowe",
            "id": "comment-13716715"
        },
        {
            "date": "2013-10-19T16:18:55+0000",
            "content": "Commit 1533782 from Robert Muir in branch 'dev/branches/lucene4956'\n[ https://svn.apache.org/r1533782 ]\n\nLUCENE-4965: don't expose this as a large hashmap with thousands of arrays ",
            "author": "ASF subversion and git services",
            "id": "comment-13799938"
        },
        {
            "date": "2013-11-19T22:49:26+0000",
            "content": "Is this code easily portable to Solr 3.6? ",
            "author": "Pradeep",
            "id": "comment-13827050"
        },
        {
            "date": "2013-11-20T14:46:38+0000",
            "content": "This facet method isn't available via Solr, yet, unfortunately.  Though, in theory porting it to Solr would not be that hard, since it does not rely on the taxonomy index.\n\nThat said, Solr does have its own range faceting ( http://wiki.apache.org/solr/SimpleFacetParameters#Facet_by_Range ) but it effectively requires multiple passes through the result set (I think?), so for something like range distance faceting (< 1 mile, < 2 miles, < 5 miles, ...), where the cost to compute the value for each doc is highish, the multiple passes through the result set is costly. ",
            "author": "Michael McCandless",
            "id": "comment-13827716"
        }
    ]
}