{
    "id": "SOLR-6306",
    "title": "Problem using Solr 4.9 index with 4.10 build (merge failures with DocValues?)",
    "details": {
        "affect_versions": "4.10",
        "status": "Closed",
        "fix_versions": [],
        "components": [],
        "type": "Bug",
        "priority": "Major",
        "labels": "",
        "resolution": "Invalid"
    },
    "description": "I have a SolrCloud cluster that has been running 4.9, I tried a 4.10 build as a test and our indexing slowed to a crawl. I noticed the number of segments (typically under 25) was up to 75 and climbing. In the logs it seems like merges were failing with the following.\n\nHappy to provide any other info as needed.\n\n\n15:06:24.624 [qtp1728790703-1634] ERROR o.a.solr.servlet.SolrDispatchFilter - null:java.io.IOException: background merge hit exception: _9n6s(4.9):C14802716/827586:delGen=97 _9nbh(4.9):C2903594/263527:delGen=100 _9no8(4.9):C2190621/20968:delGen=58 _9nak(4.9):C712244/78919:delGen=100 _9nfr(4.9):C686466/84576:delGen=97 \n_9ngy(4.9):C679031/90147:delGen=96 _9ncx(4.9):C641773/81866:delGen=99 _9nht(4.9):C415750/68337:delGen=94 _9mvj(4.9):C338961/39283:delGen=110 _9nje(4.9):C215123/41594:delGen=87 _9nmn(4.9):C156084/40673:delGen=69 _9nsk(4.9):C60958/7357:delGen=21 _9nka(4.9):C69625/22375:delGen=83 _9nrl(4.9):C27522/4326:delGen=31 _9nqr(4.\n9):C27216/7540:delGen=39 _9nqm(4.9):C24252/5597:delGen=40 _9nto(4.9):C10324/1882:delGen=10 _9ntx(4.9):C9581/1218:delGen=8 _9nts(4.9):C9731/1619:delGen=9 _9nv1(4.10):C3425 _9ntz(4.9):C1437/919:delGen=8 _9nu7(4.10):C1130/697:delGen=5 _9nuw(4.10):C611/218:delGen=2 _9nun(4.10):C625/308:delGen=3 _9nug(4.10):C828/489:delGen\n=4 into _9nv2 [maxNumSegments=1]\n        at org.apache.lucene.index.IndexWriter.forceMerge(IndexWriter.java:1865)\n        at org.apache.lucene.index.IndexWriter.forceMerge(IndexWriter.java:1801)\n        at org.apache.solr.update.DirectUpdateHandler2.commit(DirectUpdateHandler2.java:563)\n        at org.apache.solr.update.processor.RunUpdateProcessor.processCommit(RunUpdateProcessorFactory.java:95)\n        at org.apache.solr.update.processor.UpdateRequestProcessor.processCommit(UpdateRequestProcessor.java:64)\n        at org.apache.solr.update.processor.DistributedUpdateProcessor.doLocalCommit(DistributedUpdateProcessor.java:1648)\n        at org.apache.solr.update.processor.DistributedUpdateProcessor.processCommit(DistributedUpdateProcessor.java:1625)\n        at org.apache.solr.handler.RequestHandlerUtils.handleCommit(RequestHandlerUtils.java:69)\n        at org.apache.solr.handler.ContentStreamHandlerBase.handleRequestBody(ContentStreamHandlerBase.java:68)\n        at org.apache.solr.handler.RequestHandlerBase.handleRequest(RequestHandlerBase.java:135)\n        at org.apache.solr.core.SolrCore.execute(SolrCore.java:1963)\n        at org.apache.solr.servlet.SolrDispatchFilter.execute(SolrDispatchFilter.java:777)\n        at org.apache.solr.servlet.SolrDispatchFilter.doFilter(SolrDispatchFilter.java:418)\n        at org.apache.solr.servlet.SolrDispatchFilter.doFilter(SolrDispatchFilter.java:207)\n        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1419)\n        at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:455)\n        at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:137)\n        at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:557)\n        at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:231)\n        at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1075)\n        at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:384)\n        at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:193)\n        at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1009)\n        at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:135)\n        at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:255)\n        at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:154)\n        at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:116)\n        at org.eclipse.jetty.server.Server.handle(Server.java:368)\n        at org.eclipse.jetty.server.AbstractHttpConnection.handleRequest(AbstractHttpConnection.java:489)\n        at org.eclipse.jetty.server.BlockingHttpConnection.handleRequest(BlockingHttpConnection.java:53)\n        at org.eclipse.jetty.server.AbstractHttpConnection.content(AbstractHttpConnection.java:953)\n        at org.eclipse.jetty.server.AbstractHttpConnection$RequestHandler.content(AbstractHttpConnection.java:1014)\n        at org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:861)\n        at org.eclipse.jetty.http.HttpParser.parseAvailable(HttpParser.java:240)\n        at org.eclipse.jetty.server.BlockingHttpConnection.handle(BlockingHttpConnection.java:72)\n        at org.eclipse.jetty.server.bio.SocketConnector$ConnectorEndPoint.run(SocketConnector.java:264)\n        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:608)\n        at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:543)\n        at java.lang.Thread.run(Thread.java:744)\nCaused by: java.lang.IndexOutOfBoundsException\n        at java.nio.Buffer.checkIndex(Buffer.java:546)\n        at java.nio.DirectByteBuffer.getInt(DirectByteBuffer.java:681)\n        at org.apache.lucene.store.ByteBufferIndexInput$SingleBufferImpl.readInt(ByteBufferIndexInput.java:480)\n        at org.apache.lucene.util.packed.DirectReader$DirectPackedReader20.get(DirectReader.java:184)\n        at org.apache.lucene.codecs.lucene49.Lucene49DocValuesProducer$1.get(Lucene49DocValuesProducer.java:351)\n        at org.apache.lucene.codecs.lucene49.Lucene49DocValuesProducer$8.nextOrd(Lucene49DocValuesProducer.java:616)\n        at org.apache.lucene.codecs.DocValuesConsumer.mergeSortedSetField(DocValuesConsumer.java:599)\n        at org.apache.lucene.index.SegmentMerger.mergeDocValues(SegmentMerger.java:213)\n        at org.apache.lucene.index.SegmentMerger.merge(SegmentMerger.java:122)\n        at org.apache.lucene.index.IndexWriter.mergeMiddle(IndexWriter.java:4217)\n        at org.apache.lucene.index.IndexWriter.merge(IndexWriter.java:3812)\n        at org.apache.lucene.index.ConcurrentMergeScheduler.doMerge(ConcurrentMergeScheduler.java:405)\n        at org.apache.lucene.index.ConcurrentMergeScheduler$MergeThread.run(ConcurrentMergeScheduler.java:482)",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "author": "Robert Muir",
            "id": "comment-14081676",
            "date": "2014-07-31T23:30:12+0000",
            "content": "Can you run checkindex? Ideally supply -ea\nThis will help narrow it down. Also, if data is not sensitive, can you supply the index. I will debug the situation. In that case. Otherwise i am happy to debug it here. "
        },
        {
            "author": "Brett Hoerner",
            "id": "comment-14082380",
            "date": "2014-08-01T15:54:50+0000",
            "content": "The index isn't very small, 3.1GB here: https://s3.amazonaws.com/massrel-pub/index.tar\n\ncheckindex output: https://s3.amazonaws.com/massrel-pub/checkindex.txt "
        },
        {
            "author": "Robert Muir",
            "id": "comment-14082394",
            "date": "2014-08-01T16:05:56+0000",
            "content": "Brett, thank you very much. \n\nIt seems the segments are already corrupt (and some have source=flush so they came directly from indexwriter), so i don't think its a merging bug, something way more wrong has happened. Moreover, the checksums pass, so its not like your disk went bad or something like that.\n\nOne thing that concerns me, is the java version is \"1.8.0\". \n\nBut I will download your index for now and play and try to figure it out. "
        },
        {
            "author": "Brett Hoerner",
            "id": "comment-14082414",
            "date": "2014-08-01T16:15:26+0000",
            "content": "I just want to note that this happened on two different collections (same SolrCloud cluster) on different machines. In both cases I had existing shards from 4.9 and I tried to index into them after running 4.10. Our data is sharded by time and \"rolls forward\" and new shards created after 4.10 that don't have any pre-4.10 data are doing fine.\n\nI believe I can repo this by taking any of my old 4.9 shards and indexing a lot of data into them under 4.10... let me know if you need anything from me. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-14082425",
            "date": "2014-08-01T16:22:07+0000",
            "content": "Brett, all the problematic segments have this:\n\nlucene.version=4.9-SNAPSHOT Unversioned directory - brett - 2014-06-16 13:17:20\n\nIt looks like these were created with an unreleased version of 4.9? The index format is not finalized until the final release, so that would explain why 4.10 cannot read it: we can only support backwards compatibility for release versions.\n\nIf you can tell me what SVN revision you used to create that snapshot, I can tell you with 100% confidence, but this looks like the issue. "
        },
        {
            "author": "Brett Hoerner",
            "id": "comment-14082447",
            "date": "2014-08-01T16:32:33+0000",
            "content": "Robert, I was afraid of that, but it's reasonable. \n\nI'm not sure on exact svn rev, but it was built with branch_4x as of that day (6-16), which to me means something must have \"fixed\" the issue in here (6-16 up to 4.9 release, from git):\n\n\n* 36c54b1 - (tag: lucene_solr_4_9_0) tag 4.9 Robert Muir (5 weeks ago)\n* bfcb37f - SOLR-6182: correctly cast managedData as a List<Object> when loading stored RestManager data; solution verified with manual testing only as the unit tests use in-memory storage so will need to re-work the backing store to test this behavior in the unit test; backport to 4.9 branch Timothy Potter (6 weeks a\n* c733b8e - LUCENE-5767: remove bogus cast (in this case can exceed Integer.MAX_VALUE, and the underlying delta reader takes long anyway) Robert Muir (6 weeks ago)\n* f7c3fd8 - fix off-by-one in checkBufferSize, it must be >= 8 Robert Muir (6 weeks ago)\n* fb7c50f - svn:eol-style Robert Muir (6 weeks ago)\n* 22fb394 - LUCENE-5777: fix double escaping of dash in hunspell conditions Robert Muir (6 weeks ago)\n* f19581a - LUCENE-5773: Fix ram usage estimation on PositiveIntOutputs. Adrien Grand (6 weeks ago)\n* c88eb15 - SOLR-6161: Walk the entire cause chain looking for an Error shalin Shekhar Mangar (6 weeks ago)\n* 1143ff5 - LUCENE-5773: Test SegmentReader.ramBytesUsed. Adrien Grand (6 weeks ago)\n* 7d625d2 - SOLR-6128: Removed deprecated analysis factories and fieldTypes from the example schema.xml (merge r1603644 via r1603649) Chris M. Hostetter (6 weeks ago)\n* fc53ee8 - SOLR-6064: Return DebugComponent track output as JSON object Alan Woodward (6 weeks ago)\n* 71fae50 - SOLR-6125: Allow SolrIndexWriter to close without waiting for merges Alan Woodward (6 weeks ago)\n* f2b8c78 - LUCENE-5775: Deprecate JaspellLookup; fix its ramBytesUsed to not StackOverflow Michael McCandless (6 weeks ago)\n* 5894d26 - LUCENE-5772: implement getSortedNumericDocValues in SortingAtomicReader Shai Erera (6 weeks ago)\n* 2d0042b - SOLR-6160: bugfix when facet query or range with group facets and distributed David Wayne Smiley (6 weeks ago)\n* dfedf04 - SOLR-6164: Copy Fields Schema additions are not distributed to other nodes (merged trunk r1603300 and r1603301) Steven Rowe (6 weeks ago)\n* 2d811ac - SOLR-6175: Merged test fixes from branch_4x shalin Shekhar Mangar (6 weeks ago)\n* 8c6fc93 - LUCENE-5761: upgrade note for solr (merge r1603227) Chris M. Hostetter (6 weeks ago)\n* 3bee1c3 - branch for 4.9 Robert Muir (6 weeks ago)\n* 8d9a5f5 - SOLR-6129: DateFormatTransformer doesn't resolve dateTimeFormat shalin Shekhar Mangar (6 weeks ago)\n* aff7dc9 - SOLR-6175: DebugComponent throws NPE on shard exceptions when using shards.tolerant shalin Shekhar Mangar (6 weeks ago)\n* 973ed13 - LUCENE-5769: SingletonSortedSetDocValues now supports random access ordinals Robert Muir (7 weeks ago)\n* 2fa15c3 - Remove javadoc @see tag. I can't manage to make it work with precommit. Adrien Grand (7 weeks ago)\n* 95c697a - LUCENE-5768: hunspell condition checks with character classes were buggy Robert Muir (7 weeks ago)\n* 3acb593 - LUCENE-5767: OrdinalMap optimizations. Adrien Grand (7 weeks ago)\n* 059a7b5 - SOLR-6015: Backport fixes from trunk to branch_4x. Timothy Potter (7 weeks ago)\n* de203d5 - LUCENE-5765: Add tests to OrdinalMap.ramBytesUsed. Adrien Grand (7 weeks ago)\n* 5fc0871 - LUCENE-5764: Add tests to DocIdSet.ramBytesUsed. Adrien Grand (7 weeks ago)\n* 9e0e17e - LUCENE-5759: Add PackedInts.unsignedBitsRequired. Adrien Grand (7 weeks ago)\n* 51924f0 - LUCENE-5761: Remove DiskDocValuesFormat Robert Muir (7 weeks ago)\n* 171ae5a - SOLR-6151: Intermittent TestReplicationHandlerBackup failures. Dawid Weiss (7 weeks ago)\n* 9ad403f - LUCENE-5762: Disable old codecs as much as possible Robert Muir (7 weeks ago)\n\n "
        },
        {
            "author": "Robert Muir",
            "id": "comment-14082481",
            "date": "2014-08-01T16:48:44+0000",
            "content": "Well it just means the format changed, several times during development. Sometimes its just little changes like LUCENE-5750.\n\nIn general once we have an official release, the format for that version is \"frozen\" and then we add backwards compatibility indexes and test for it. But anything in between releases probably cannot be upgraded. "
        },
        {
            "author": "Brett Hoerner",
            "id": "comment-14082484",
            "date": "2014-08-01T16:51:00+0000",
            "content": "Makes sense, thanks for your help! "
        }
    ]
}