{
    "id": "SOLR-81",
    "title": "Add Query Spellchecker functionality",
    "details": {
        "affect_versions": "None",
        "status": "Closed",
        "fix_versions": [
            "1.2"
        ],
        "components": [
            "search"
        ],
        "type": "New Feature",
        "priority": "Minor",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "Use the simple approach of n-gramming outside of Solr and indexing n-gram documents.  For example:\n\n<doc>\n<field name=\"word\">lettuce</field>\n<field name=\"start3\">let</field>\n<field name=\"gram3\">let ett ttu tuc uce</field>\n<field name=\"end3\">uce</field>\n<field name=\"start4\">lett</field>\n<field name=\"gram4\">lett ettu ttuc tuce</field>\n<field name=\"end4\">tuce</field>\n</doc>\n\nSee:\nhttp://www.mail-archive.com/solr-user@lucene.apache.org/msg01254.html\nJava clients: SOLR-20 (add delete commit optimize), SOLR-30 (search)",
    "attachments": {
        "SOLR-81-ngram-schema.patch": "https://issues.apache.org/jira/secure/attachment/12350361/SOLR-81-ngram-schema.patch",
        "SOLR-81-spellchecker.patch": "https://issues.apache.org/jira/secure/attachment/12352485/SOLR-81-spellchecker.patch",
        "hoss.spell.patch": "https://issues.apache.org/jira/secure/attachment/12354135/hoss.spell.patch",
        "SOLR-81-ngram.patch": "https://issues.apache.org/jira/secure/attachment/12347713/SOLR-81-ngram.patch",
        "SOLR-81-edgengram-ngram.patch": "https://issues.apache.org/jira/secure/attachment/12350288/SOLR-81-edgengram-ngram.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Og\u00fcn Bilge",
            "id": "comment-12457871",
            "date": "2006-12-12T20:37:55+0000",
            "content": "I have created a NGramFilter for generating those gram fields based on the \"word\" field\nIt is configurable with the schema.xml file simply by generating fieldtypes and using the \ncopyField directive. \nThe generated documents can be used with the Lucene spellchecker extension to fetch a \nsuggest word.\nUnfortunately i have made this extension during my working hours and so i can't apply the \nasf license on it, but if you have question please ask. "
        },
        {
            "author": "Otis Gospodnetic",
            "id": "comment-12458052",
            "date": "2006-12-13T08:51:49+0000",
            "content": "Something like this, then?\n\n    <fieldtype name=\"queryString\" class=\"solr.TextField\" positionIncrementGap=\"1\">\n      <analyzer>\n       <tokenizer class=\"solr.NGramTokenizerFactory\"/>  <!-- Or maybe just make an NGramAnalyzer? -->\n      <filter class=\"solr.LowerCaseFilterFactory\"/>\n      </analyzer>\n    </fieldtype>\n\nPlus:\n\n<copyField source=\"word\" dest=\"word_start1\"/>\n<copyField source=\"word\" dest=\"word_end1\"/>\n<copyField source=\"word\" dest=\"word_start2\"/>\n<copyField source=\"word\" dest=\"word_end2\"/>\n<copyField source=\"word\" dest=\"word_start3\"/>\n<copyField source=\"word\" dest=\"word_end3\"/>\n<copyField source=\"word\" dest=\"word_gram1\"/>\n<copyField source=\"word\" dest=\"word_gram2\"/>\n<copyField source=\"word\" dest=\"word_gram3\"/>\n<copyField source=\"word\" dest=\"word_gram4\"/> \n\nI'd probably also want to give those word_start* n-grams some boost, though I don't see how to do that in schema.xml yet. "
        },
        {
            "author": "Og\u00fcn Bilge",
            "id": "comment-12458072",
            "date": "2006-12-13T10:48:28+0000",
            "content": "Yes exactly as you described. \nThe Fieldnames for the gram fields have to be like this to make it work with SpellChecker: \n\n<copyField source=\"word\" dest=\"start1\"/>\n<copyField source=\"word\" dest=\"end1\"/>\n<copyField source=\"word\" dest=\"start2\"/>\n<copyField source=\"word\" dest=\"end2\"/>\n<copyField source=\"word\" dest=\"start3\"/>\n<copyField source=\"word\" dest=\"end3\"/>\n<copyField source=\"word\" dest=\"start4\"/>\n<copyField source=\"word\" dest=\"end4\"/>\n<copyField source=\"word\" dest=\"gram1\"/>\n<copyField source=\"word\" dest=\"gram2\"/>\n<copyField source=\"word\" dest=\"gram3\"/>\n<copyField source=\"word\" dest=\"gram4\"/> \n\nA NGramAnalyzer is enough, i used a WhiteSpacetokenizer as Tokenizer, some other filters and finally  the \nNGramAnaylzer\n\nUnfortunately the SpellChecker implementation has a beta state imho. It is not possible to set your own boost factors \nfor the start or end grams. In the current release it is set to start-gram factor 2 , end-gram factor 1\n "
        },
        {
            "author": "Otis Gospodnetic",
            "id": "comment-12460331",
            "date": "2006-12-21T19:52:33+0000",
            "content": "Og\u00fcn - yes, that Spellchecker class in Lucene's contrib/spellchecker has 1.0f defined as the boost for the last n-gram.  I'm not even sure if that's needed.  I talked to Bob Carpenter (alias-i.com) about it recently, and he said boosting the end ngram doesn't make sense, if I remember correctly.  I'm inclined to go remove that from the source completely.  Thoughts?\n\nI'm unsure about how to integrate the Lucene spellchecker code into Solr, though.  There is no \"n-gram tokenizer\" per se in the spellchecker extension, so I can't really point NGramFilter config in Solr's schema.xml to anything in that spellchecker library.... I can write my own n-gram Filter, that's not a problem, but you said you made use of the Lucene spellchecker code, and I can't see how to do that.\n\nDid you simply create your own NGramFilter that creates the same ngrams as Spellchecker.java, and then used the Spellchecker.suggest(String word) method only for fetching/getting alternative spelling suggestions? "
        },
        {
            "author": "Erik Hatcher",
            "id": "comment-12460397",
            "date": "2006-12-22T07:34:59+0000",
            "content": "The way the spell checker works is to have a separate spell checking index.  This could be integrated into Solr with a custom cache that builds the dictionary index into a RAMDirectory.  I've done this in Collex for AJAX suggestions.  Will it scale?  I'm not sure, but I suspect for many Solr installations it'd fit into RAM just fine.  Tie in a custom request handler (and underlying Util class like highlighting, etc) and you're all set!   \n\nWhat have I overlooked or oversimplified? "
        },
        {
            "author": "Otis Gospodnetic",
            "id": "comment-12460402",
            "date": "2006-12-22T07:49:53+0000",
            "content": "Yeah, I've used the Lucene-based spellchecker before, I just never had to hook it up with Solr.  At this point I'm not interested in the fancy stuff (cache, RAMDir...), I just want to figure out how to configure it via schema.xml... "
        },
        {
            "author": "Otis Gospodnetic",
            "id": "comment-12460405",
            "date": "2006-12-22T08:10:33+0000",
            "content": "This patch contains 3 new classes for org.apache.solr.analysis:\n1. NGramTokenizerFactory\n2. NGramTokenizer\n3. NGramTokenizerTest (all tests pass)\n+ 1 modified class:\n4. BaseTokenizerFactory\n\nI think the above can be configured in schema.xml as follows:\n\n    <fieldtype name=\"gram1\" class=\"solr.TextField\">\n      <analyzer>\n        <tokenizer class=\"solr.WhitespaceTokenizerFactory\"/>\n        <tokenizer class=\"solr.NGramTokenizerFactory\" minGram=\"1\" maxGram=\"1\"/>\n        <filter class=\"solr.LowerCaseFilterFactory\"/>\n      </analyzer>\n    </fieldtype>\n    <fieldtype name=\"gram2\" class=\"solr.TextField\">\n      <analyzer>\n        <tokenizer class=\"solr.WhitespaceTokenizerFactory\"/>\n        <tokenizer class=\"solr.NGramTokenizerFactory\" minGram=\"2\" maxGram=\"2\"/>\n        <filter class=\"solr.LowerCaseFilterFactory\"/>\n      </analyzer>\n    </fieldtype>\n    <fieldtype name=\"gram3\" class=\"solr.TextField\">\n      <analyzer>\n        <tokenizer class=\"solr.WhitespaceTokenizerFactory\"/>\n        <tokenizer class=\"solr.NGramTokenizerFactory\" minGram=\"3\" maxGram=\"3\"/>\n        <filter class=\"solr.LowerCaseFilterFactory\"/>\n      </analyzer>\n    </fieldtype>\n\nAnd I believe the following fields would have to be defined (to match the fields in Spellchecker.java):\n\n<field name=\"word\" type=\"string\" indexed=\"true\" stored=\"true\" multiValued=\"false\"/>\n<field name=\"start1\" type=\"string\" indexed=\"true\" stored=\"true\" multiValued=\"false\"/>  **\n<field name=\"end1\" type=\"string\" indexed=\"true\" stored=\"true\" multiValued=\"false\"/> **\n<field name=\"start2\" type=\"string\" indexed=\"true\" stored=\"true\" multiValued=\"false\"/> **\n<field name=\"end2\" type=\"string\" indexed=\"true\" stored=\"true\" multiValued=\"false\"/> **\n<field name=\"start3\" type=\"string\" indexed=\"true\" stored=\"true\" multiValued=\"false\"/> **\n<field name=\"end3\" type=\"string\" indexed=\"true\" stored=\"true\" multiValued=\"false\"/> **\n<field name=\"start4\" type=\"string\" indexed=\"true\" stored=\"true\" multiValued=\"false\"/> **\n<field name=\"end4\" type=\"string\" indexed=\"true\" stored=\"true\" multiValued=\"false\"/> **\n<field name=\"gram1\" type=\"gram1\" indexed=\"true\" stored=\"true\" multiValued=\"false\"/>\n<field name=\"gram2\" type=\"gram2\" indexed=\"true\" stored=\"true\" multiValued=\"false\"/>\n<field name=\"gram3\" type=\"gram3\" indexed=\"true\" stored=\"true\" multiValued=\"false\"/>\n<field name=\"gram4\" type=\"gram4\" indexed=\"true\" stored=\"true\" multiValued=\"false\"/>\n\nc.f. http://wiki.apache.org/jakarta-lucene/SpellChecker\nI am not sure how to configure the fields marked with  ** above.\nMaybe I don't even need startN/endN fields.  I am not sure how endN fields would be useful.  The startN are probably useful because those can get an extra boost.\n\nI think the above config (except for ** fields, which I don't know how to handle) will do the following.\nIf the input (query string) is \"pork\", my ngrammer may generate the following uni- and bi-gram tokens:\n\n  p o r k po or rk\n\nAnd this is how I think they will get mapped to fields and indexed:\nword: pork\ngram1: p o r k\ngram2: po or rk\nstart1: p **\nstart2: po **\nend1 rk **\nend2: rk **\n\nAgain, not sure how to achieve **.\n\nI haven't actually tried this.  I am only modifying my local example/solr/conf/schema.xml for now, and I haven't actually indexed anything with the above config.\n\nThoughts/comments? "
        },
        {
            "author": "Adam Hiatt",
            "id": "comment-12470011",
            "date": "2007-02-04T01:15:38+0000",
            "content": "This new patch provides a superset of the functionality of Otis's orginal patch. Specifically it includes edge n-gram tokenizers based on Otis's lucene analyzer contrib. I modified this tokenizer to output edge n-grams in a range of sizes (ie you can tokenizer a range of 1-2 on the string \"abc\" resulting in \"a\", \"ab\").  This patch also fixes a bug in the n-gram factory and provides some code cleanup. \n\nFor clarity's sake this patch suplants 'SOLR-81-ngram.patch'  "
        },
        {
            "author": "Otis Gospodnetic",
            "id": "comment-12470295",
            "date": "2007-02-05T18:03:55+0000",
            "content": "Adam,\n\nI took a look at your patch.  It looks like you brought over (copied) various n-gram tokenizer classes and their unit tests that I put in Lucene's contrib/analyzers/.... .  Did you do this on purpose?  I intentionally put those n-gram tokenizers under Lucene's contrib, as they are generic and not Solr-specific.  Thus, the only classes my patch has are classes that are Solr-specific:\n\nsrc/java/org/apache/solr/analysis/EdgeNGramTokenizerFactory.java\nsrc/java/org/apache/solr/analysis/NGramTokenizerFactory.java\nsrc/java/org/apache/solr/analysis/BaseTokenizerFactory.java\n\nAnd instead of copying the source classes from Lucene's contrib/analyzers/.... it adds the new jar built from those sources:\nlib/lucene-analyzers-2.1-dev.jar\n\nPlus:\nlib/lucene-spellchecker-2.1-dev.jar\nexample/solr/conf/schema.xml\n\nI have some locally modified code for this issue, that was not a part of the first patch.  I wanted to attach the updated patch assuming you didn't really want those few generic tokenizer classes copied from Lucene over to Solr, but because changes are now in two places, so to speak, let's do this to unify our work:\n\nCould you please:\n\n\topen a new LUCENE issue or just reopen the one where I originally attached this code and post your patch to the Lucene tokenizers there.\n\tprepare a new patch for this issue and make sure it only contains Solr-specific classes (see above), plus those 2 Jars.\n\n\n\nI'll upload my patch for schema.xml, so you can see my config (your patch didn't have this), and make sure your changes to the code are in sync with that.\n\nFinally, are you making use of this code somehow already?\nOne thing that is completely missing from this patch is the RequestHandler that knows how to take the input (a query string), and get suggestions for alternative spellings via a SpellChecker instance.  I have some NGramRequestHandler code locally, but the code is unfinished. "
        },
        {
            "author": "Otis Gospodnetic",
            "id": "comment-12470297",
            "date": "2007-02-05T18:07:58+0000",
            "content": "schema.xml changes:\n\n\tto make use of NGramTokenizerFactory and EdgeNGramTokenizerFactory\n\tto define some <field>s and some <copyField>s to be used with Lucene SpellChecker.\n\n "
        },
        {
            "author": "Otis Gospodnetic",
            "id": "comment-12473813",
            "date": "2007-02-16T20:05:57+0000",
            "content": "Adam:\nPlease look at LUCENE-759.  That incorporates your patch, fixes a bug I found in it, and introduces a new bug, so we are not too bored with bug-free code.  Any idea how to extract that last n-gram when using Side.BACK? "
        },
        {
            "author": "Adam Hiatt",
            "id": "comment-12473848",
            "date": "2007-02-16T23:06:07+0000",
            "content": "What was the bug? I couldn't tell from the Lucene issue description.\n\n\n "
        },
        {
            "author": "Otis Gospodnetic",
            "id": "comment-12474734",
            "date": "2007-02-21T15:40:38+0000",
            "content": "Here is a new patch that should include everything:\n\n\tNew SpellCheckerRequestHandler\n\tUpdated solrconfig.xml that defines the above handler and maps it to /spellechecker\n\tNew NGramTokenizerFactory\n\tNew EdgeNGramTokenizerFactory (includes Adam's changes)\n\tModified BaseTokenizerFactory (used by the above 2 factories)\n\tUpdated schema.xml that configures the above 2 factories to tokenize the input words into n-grams as required by the Lucene contrib SpellChecker (see http://wiki.apache.org/jakarta-lucene/SpellChecker for examples of n-grams used by the SpellChecker)\n\n "
        },
        {
            "author": "Otis Gospodnetic",
            "id": "comment-12475416",
            "date": "2007-02-23T17:49:47+0000",
            "content": "\n\tFixed SpellCheckerRequestHandler (needed that init method)\n\tFixed SpellCheckerRequestHandler name in solrconfig.xml\n\tRemoved unused field types, fields, and copy fields from schema.xml\n\n\n\nThe indexing part has a bug (will bring it to solr-user in a moment). "
        },
        {
            "author": "Otis Gospodnetic",
            "id": "comment-12477392",
            "date": "2007-03-02T18:08:00+0000",
            "content": "I think this is the final version - tested it, and it works.\nI'd like to commit this next week, so please have a look if you have time.\n\nThis is what's in the patch:\n\nA      lib/lucene-spellchecker-2.2-dev.jar\nA      lib/lucene-analyzers-2.2-dev.jar\nA      src/java/org/apache/solr/analysis/NGramTokenFilterFactory.java\nM      src/java/org/apache/solr/analysis/BaseTokenFilterFactory.java\nA      src/java/org/apache/solr/analysis/EdgeNGramTokenFilterFactory.java\nA      src/java/org/apache/solr/request/SpellCheckerRequestHandler.java\nC      example/solr/conf/schema.xml\nM      example/solr/conf/solrconfig.xml\n\nI think you can ignore that \"C\" \u2013 there is no conflict in the file, actually. "
        },
        {
            "author": "Adam Hiatt",
            "id": "comment-12477542",
            "date": "2007-03-02T23:08:48+0000",
            "content": "This patch was developed off of Otis's previous patch. It fixes a numSuggestion bug + adds an accuracy argument for the spellchecker + adds a commit handler for updating the spell correction index. It removes the n-gram generation from the spell correction index generation because that isn't actually needed to build the index (SpellChecker does that for you). "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12477547",
            "date": "2007-03-02T23:26:09+0000",
            "content": "Is spelling check normally going to be integrated into the \"main\" index, or will it normally be a separate index?\nIf the latter, does it make more sense for some of this (the field definitions & handler) to be in contrib instead of core?\n\nAny other way to avoid \"cluttering\" the current schema.xml?\n\nIf spelling check is to be a core feature (that one can turn on for any field in any index), it seems like it needs to be easier to configure.  Having the user define all the ngram fields, fieldTypes, and copyField statements doesn't seem ideal.\n\nIf, however, this is more of a \"configuration\" of solr used for spell-checking, it might make more sense for contrib. "
        },
        {
            "author": "Adam Hiatt",
            "id": "comment-12477568",
            "date": "2007-03-03T00:38:21+0000",
            "content": "> Is spelling check normally going to be integrated into the \"main\" index, or will it normally be a separate index?\nAH: It is a separate index.\n\n> If the latter, does it make more sense for some of this (the field definitions & handler) to be in contrib instead of core? \nAH: That would be fine by me. However, it should be noted that it can be turned on for any field.\n\n> Any other way to avoid \"cluttering\" the current schema.xml?\n> If spelling check is to be a core feature (that one can turn on for any field in any index), it seems like it needs to be easier to configure. Having the user \n> define all the ngram fields, fieldTypes, and copyField statements doesn't seem ideal. \nAH: I think there is some confusion over Otis's version and mine. I was never able to get Otis's version (single index using ngram types + copyfields) working fully so I went with the pure SpellChecker implementation that doesn't require any of that (no schema.xml additions) It just needs for the user to use a custom request handler to query for spelling corrections (Otis wrote the original) and a custom commit handler (based on CommitRequestHandler) to rebuild the spell checker index.\n\nFor the record the version I commited is: https://issues.apache.org/jira/secure/attachment/12352485/SOLR-81-spellchecker.patch "
        },
        {
            "author": "Adam Hiatt",
            "id": "comment-12477569",
            "date": "2007-03-03T00:38:23+0000",
            "content": "> Is spelling check normally going to be integrated into the \"main\" index, or will it normally be a separate index?\nAH: It is a separate index.\n\n> If the latter, does it make more sense for some of this (the field definitions & handler) to be in contrib instead of core? \nAH: That would be fine by me. However, it should be noted that it can be turned on for any field.\n\n> Any other way to avoid \"cluttering\" the current schema.xml?\n> If spelling check is to be a core feature (that one can turn on for any field in any index), it seems like it needs to be easier to configure. Having the user \n> define all the ngram fields, fieldTypes, and copyField statements doesn't seem ideal. \nAH: I think there is some confusion over Otis's version and mine. I was never able to get Otis's version (single index using ngram types + copyfields) working fully so I went with the pure SpellChecker implementation that doesn't require any of that (no schema.xml additions) It just needs for the user to use a custom request handler to query for spelling corrections (Otis wrote the original) and a custom commit handler (based on CommitRequestHandler) to rebuild the spell checker index.\n\nFor the record the version I commited is: https://issues.apache.org/jira/secure/attachment/12352485/SOLR-81-spellchecker.patch "
        },
        {
            "author": "Otis Gospodnetic",
            "id": "comment-12478277",
            "date": "2007-03-06T06:27:22+0000",
            "content": "Adam:\n\nI can merge our patches to produce a unified one.\n\nNOTE:\nThe SpellCheckerCommitRequestHandler assumes that:\n  a) one wants to populate the spellchecker index with data from another Lucene index.\n  b) the Lucene index to be used for populating is available on the same box where the spellchecker service is running.\n\nI think both a) and b) are good - let those who want this functionality have it.\nHowever, some may not be able to live with these assumptions (e.g. one may want to have a server dedicated to spellchecker service, and may not want to push the source Lucene index to the spellchecker box.)  For those people, the approach that includes schema.xml modifications will be required, unless I'm missing something.  Am I?\n\nAlso, I think this is a mistake:\n\naccuracy = p.getFloat(\"accuracy\", DEFAULT_NUM_SUGGESTIONS);\n\nYou probably wanted DEFAULT_ACCURACY there, but that doesn't exist yet, so I'll fix that. "
        },
        {
            "author": "Adam Hiatt",
            "id": "comment-12478301",
            "date": "2007-03-06T08:00:32+0000",
            "content": "Good call on the DEFAULT_ACCURACY constant. BTW it should probably be .5.\n\nAs for:\n> The SpellCheckerCommitRequestHandler assumes that:\n>  a) one wants to populate the spellchecker index with data from another Lucene index.\n>  b) the Lucene index to be used for populating is available on the same box where the spellchecker service is running. \n\nThis does not necessarily have to be true (well a. sort of has to be true). The way I've been testing this is to make my primary index  an index of search terms + related metadata. The SpellChecker simply creates a separate index for the pieces it needs to do its work. In essence this is a standalone spellchecker. However, as you note, this same setup allows for the primary index to be any field. Can you see a downside to this approach? "
        },
        {
            "author": "Adam Hiatt",
            "id": "comment-12478302",
            "date": "2007-03-06T08:01:21+0000",
            "content": "BTW updated patch added. "
        },
        {
            "author": "Hoss Man",
            "id": "comment-12478893",
            "date": "2007-03-07T21:02:07+0000",
            "content": "looking over both Otis's patches and Adam's patches for hte first time i find myself really confused.\n\nAs previously discussed in email, there are two completley different appraoches that could be taken to achieve \"spell correction\" using Solr:\n\n1) Use something like the Lucene SpellChecker contrib to make suggestions basedon the data in the main solr index (defined by the solr schema) ... adding hooks to Solr to keep the SpellChecker system aware of changes to the main index, and hooks to allow requesthandlers to return suggestions with each query\n\n2) use the main solr index (defined by the schema) to store the dictionary of words, turning the entire solr instance into one giant SpellChecker.  In this case there would be a recomended schema.xml for users who want to setup a SpellChecker Solr instance and possible a custom RequestHandler htat assumes you are using this schema.\n\n\nThese two patches both seem to be dealing with case#1, but they have hints of approach#2 ... for example i don't entirely understand why they include the NGram tokenfilter factories, since they don't seem to need the fields of the solr index to be tokenized in any special way (since the lucene SpellChecker controls the format of it's dictionary).   It's also not clear do me what the purpose of the SpellCheckerRequestHandler is ... if the main index is storing \"real\" user records, then wouldn't a helper method that existing request handlers (like dismax and standard) can optionally call to get the SpellChecker data be more useful? "
        },
        {
            "author": "Adam Hiatt",
            "id": "comment-12478900",
            "date": "2007-03-07T21:24:40+0000",
            "content": "In essence, point 1) is true. However, the way I have been using the SpellChecker index allows for the user to have a standalone spell checker as well as piggy-backing it off a primary index. \n\nPoint 2) prevents the second use case I mentioned and also limits what can be done with the SpellChecker. \n\nWRT the issue of the NGram/EdgeNGram tokenizers: These should probably be split out into a separate patch/issue as they are not critical to the implementation. \n\nI like the idea of providing the SpellChecker index access functionality as a contrib that can be accessed from any RequestHandler, but it is useful to have a separate RequestHandler that can just provide spell checking functionality alone. "
        },
        {
            "author": "Hoss Man",
            "id": "comment-12479670",
            "date": "2007-03-09T18:12:50+0000",
            "content": "Okay, assuming what we are talking about is a adding the existing Lucene SpellChecker as a hook into a Solr instance, where the dictionary may be built externally, or it may be built based on the main source index, here's my comments based on the most recent patch (from Adam ... as i recall it already incorperates most of Otis's stuff)\n\n\n1) we should definitely move the *NGramTokenizerFactories into a seperate issues since they don't come into play here.\n\n2) when configuring where the SpellChecker Directory lives, we should probably support three options:  a path relative dataDir (so the regular replication scripts can copy a SpellChecker index from a master to slave right along with the main index), an absolute path, or a RAMDirectory\n\n3) it seems like the functionality present in SpellCheckerRequestHandler and SpellCheckerCommitRequestHandler should all be in one request handler (where special query time input triggers the rebuild).  that way no redundent configuration is required.  There should also be an option for \"reloading\" the SpellChecker instance from disk (ie: reopening it's IndexReader) without rebuilding \u2013 which would be useful for people who are (re)buidling the SpellChecker index external from Solr and need a way to tell Solr to start using the new one\n\nA key use case i'm imagining is that a master could have a postCommit listener configured to ping \"qt=spell&rebuild=true\" after each commit, while a slave could have \"qt=spell&rebuild=true\" to pick up the changed SpellCheck index.\n\n4) i'ts not really safe to trust this...\n\n+        IndexReader indexReader = req.getSearcher().getReader();\n+        Dictionary dictionary = new LuceneDictionary(indexReader, termSourceField);\n\n...the source field might be encoded in some way.  We really need a subclass of LuceneDictionary that knows about the IndexSchema/FieldType of termSourceField to extract the Readable value from the indexed terms (either that or we go ahead and feed SpellChecker the raw terms, and then at query time run the users (mispelled) input through the query time analyzer for termSourceField before passing it to spellChecker.suggestSimilar\n\n5) we definitely shouldn't have a \"private static SpellChecker\" it should be possible to have multiple SpellChecker instance (from different dictionaries) just by registerig multiple instances of the handler .. at first glance this seems like it might make adding SpellChecking funtionality to the other requesthandlers hard .. except that they can call core.getRequestHandler(name) ... so we can still add code to other request handlers so that they can be configured to ask for a SpellCheckerRequestHandler by name, and delegate some spell checking functionality to it.\n\n6) as far as configuring things like spellcheckerIndexDir and termSourceField, there's no reason to do that in the \"invariants\" list .. that's really for things that the code allows to be query time params, but the person configuring Solr doesn't want query clients to be able to specify it.  seperate init params can be used and accessed directly from the init method (just like XSLTResponseWriter)...\n\n+    <requestHandler name=\"spellchecker\" class=\"solr.SpellCheckerRequestHandler\">\n+        <!-- default values for query parameters -->\n+        <lst name=\"defaults\">\n+            <str name=\"echoParams\">explicit</str>\n+            <int name=\"suggestionCount\">1</int>\n+            <float name=\"accuracy\">0.5</float>\n+        </lst>\n+\n+        <!-- main init params for handler -->\n+        <str name=\"spellcheckerIndexDir\">/tmp/spellchecker</str>\n+        <str name=\"termSourceField\">word</str>\n+    </requestHandler>\n+\n\n7) adding a special field to the example schema (and example docs) to demonstrate building the SpellChecker index is a bit confusing ... we should just build the dictionary off of an existing field that contains data (like \"name\" or \"text\") to demonstrate the common use case.\n "
        },
        {
            "author": "Otis Gospodnetic",
            "id": "comment-12480409",
            "date": "2007-03-13T14:33:13+0000",
            "content": "Adam:\nHave you started making the changes that Hoss proposed here?  Please let me know (today, if you can).  If you have not started, I'll make the changes.  If you've started, I'll hold off.\n\nHoss & Adam:\n\n1) out with tokenizer factories - right, they are no longer needed.\n\n2) I'll stick to the absolute path for now, get that in SVN, and then we can add support for other things... unless you show me an example of how easy it is to support other paths/locations\n\n3) merging the handlers sounds ok:\n  to get suggestions: ...?qt=spellchecker&cmd=suggest \n  to completely rebuild: ...?qt=spellchecker&cmd=rebuild\nOK?\nThe use-case here is to rebuild the index every once in a while, not on every change of the main index.\n\n4) I'll leave that for later, as I don't completely understand you there.\n\n5) ok, no static SpellChecker\n\n6) ok, sounds like we just need remove the wrapping <lst name=\"invariants\"> element\n\n7) I actually liked having a separate example doc for demonstrating just the spellchecker functionality \u2013 you don't have to know about those other documents/fields/values.  But if both Adam and Hoss think differently, we should go with the majority's opinion. "
        },
        {
            "author": "Otis Gospodnetic",
            "id": "comment-12480618",
            "date": "2007-03-14T01:20:44+0000",
            "content": "Here is a new version of the patch:\n\n\n\tNo token filters, no schema.xml changes, no invariant properties used\n\tOnly 1 SpellCheckerRequestHandler that either returns spelling suggestions or rebuilds the spellchecker index is cmd=rebuild is specified\n\tSpellChecker instance is no longer static\n\tkept spellchecker.xml example doc\n\tstill using absolute path for index dir\n\n\n\nI'm still recovering from a +13h timezone change, so please shout if I missed anything.  I'd like to commit this by the end of the week, so please help me finalize this.\n\nAdam: if you are doing any work on this, please email or comment here, so we don't duplicate the effort.\n "
        },
        {
            "author": "Hoss Man",
            "id": "comment-12480660",
            "date": "2007-03-14T05:43:05+0000",
            "content": "Otis: haven't had a chance to look at your newest patch yet, but just to clarify my comment#4... In the last patch i looked at, LuceneDictionary could be used to build the dictionary based on a field name from the index \u2013 but this will only work for simple String or TextFields.\n\nTheoretically, someone could write a ROT132FieldType that munges up the field values stored in it, if you were to try and build a SpellChecker index from this field, nothing good would come of it just using LUceneDIctionary (because of hte way it uses hte raw TermEnum) .. but since we have the IndexSchema, we can get the FieldType for the field name we want to use, and then the \"indexedToReadable\" method on each indexed term will tell you the \"plain text\" version.\n\nit's a minor thing, but it's a good thing to take into account.\n\nAlternately, we can just document that it doesn't make sense to use any field type except \"StrField\" (even TextField doens't really make sense since we can't anticipate what hte Analyzer might have done) "
        },
        {
            "author": "Otis Gospodnetic",
            "id": "comment-12481738",
            "date": "2007-03-16T19:29:35+0000",
            "content": "This is in SVN now, but I'm going to leave this open for another week, in case Hoss, Adam, or anyone else finds any issues. "
        },
        {
            "author": "Otis Gospodnetic",
            "id": "comment-12481759",
            "date": "2007-03-16T20:53:45+0000",
            "content": "There is a useless (I think) static IndexReader in there:\n    private static IndexReader reader = null;\n\nIf we set this to some real IndexReader, we can get the SpellChecker to act as follows (from its coffeedocs):\n\n....\n\n\t@param ir the indexReader of the user index (can be null see field param)\n\t@param field String the field of the user index: if field is not null, the suggested\n\twords are restricted to the words present in this field.\n\t@param morePopular boolean return only the suggest words that are more frequent than the searched word\n\t(only if restricted mode = (indexReader!=null and field!=null)\n....\n  public String[] suggestSimilar(String word, int numSug, IndexReader ir,\n      String field, boolean morePopular) throws IOException {\n\n\n\nSo, should we do this on init:\n  reader = req.getSearcher().getReader();\n?\nOr maybe add a new param to solrconfig.xml's declaration of the SpellCheckerRequestHandler that turns this on/off?\n\nThoughts? "
        },
        {
            "author": "Hoss Man",
            "id": "comment-12483790",
            "date": "2007-03-23T23:34:47+0000",
            "content": "\npatch makes a few changes, if there are no objections i'll try to commit this on monday....\n\n\n\tfixed NPE if no q param (when using cmd)\n\tfixed schema.xml to know about \"words\" field in spellchecker.xml\n\tcmd=rebuild needs to be disabled if termSourceField is null\n\tadded \"cmd=reopen\" for people maintaining the spell index externally.\n\tadded support for ramDir based spell index.\n\tcan't do relative path to dataDir, because we can't getdataDir,\n   because SolrCore isn't done initializing yet.\n\tadded more explanation to solrconfig.xml about meaning of params,\n   and changed the default values to work for anyone (using ramdir)\n\tI punted on the issue of field type encoding by making it clear in\n   the solrconfig.xml comments that termSourceField needs to use a simple\n   field type\n\n\n\nRemaining issues...\n\n\n\tshould we add a firstSearcher or newSearcher hook to rebuild in\n   the example solrconfig.xml ?\n\ti don't have an optinion about passing an IndexReader to\n   suggestSimilar, if we want to do that it shouldn't be a static reader,\n   it should come from the current request ... in the meantime i changed\n   the name of the current one to \"nullReader\" so it's clear what it is.\n\tthe indenting is currently a hodgepodge of 2spaces vs 4 spaces ...\n   i'll fix after commiting (trying to keep the patch easy to read for now)\n\n "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-12483795",
            "date": "2007-03-23T23:41:47+0000",
            "content": ">  * can't do relative path to dataDir, because we can't getdataDir,\n>    because SolrCore isn't done initializing yet.\n\nwith SOLR-182, SolrCore gets initialized first - so we could use relative paths during handler initialization. "
        },
        {
            "author": "Otis Gospodnetic",
            "id": "comment-12483804",
            "date": "2007-03-24T04:28:29+0000",
            "content": "I haven't applied this and tried it, but I looked at the patch, and like the changes.  The only issues I could stop are 3 typos that we can clean up later. "
        },
        {
            "author": "Otis Gospodnetic",
            "id": "comment-12483805",
            "date": "2007-03-24T04:34:19+0000",
            "content": "Hoss, another poooooossibly interesting and useful addition:\n\nMake use of public RAMDirectory(Directory dir) and allow one to specify that even though the spellchecker index exists in FS, use it only to pull it into a RAMDir-based index.  Might not be a huge win because most spellchecker indices are probably pretty small and easily fit in RAM already, even when they are FSDir-based, but I thought I'd mention it anyway.\n\n "
        },
        {
            "author": "Hoss Man",
            "id": "comment-12484232",
            "date": "2007-03-26T21:17:47+0000",
            "content": "I've committed my last patch with a few changes:\n\n1) support for directories relative dataDir since SOLR-182 was committed - used this in example solrconfig.xml\n2) cleaned up some Typos (thanks for reminding me Otis)\n3) whitespace reformatted (separate commit so diffs are easier to follow)\n\nI think things are in a pretty good generally usable state now ... Otis; how do you feel about resolving? (possibly opening new enhancement Jira issues for some of the other things discussed, like the reader idea, and loading copying the FSDirectory into a RAMDirectory?) "
        },
        {
            "author": "Otis Gospodnetic",
            "id": "comment-12484261",
            "date": "2007-03-26T23:33:16+0000",
            "content": "Thanks Hoss, finito! "
        },
        {
            "author": "Thomas Peuss",
            "id": "comment-12511989",
            "date": "2007-07-12T07:02:37+0000",
            "content": "Hello Otis!\n\nWhat happened to the TokenFilters included in the patch? They are in the patch but in trunk I don't see them.\n\nCU\nThomas "
        },
        {
            "author": "Hoss Man",
            "id": "comment-12512290",
            "date": "2007-07-12T22:29:01+0000",
            "content": "the various NGram tokenizers and token filters were promoted out of this issue into a LUCENE issue and subsequently committed into a contrib. "
        },
        {
            "author": "Hoss Man",
            "id": "comment-12589324",
            "date": "2008-04-15T23:44:45+0000",
            "content": "This bug was modified as part of a bulk update using the criteria...\n\n\n\tMarked (\"Resolved\" or \"Closed\") and \"Fixed\"\n\tHad no \"Fix Version\" versions\n\tWas listed in the CHANGES.txt for 1.2\n\n\n\nThe Fix Version for all 39 issues found was set to 1.2, email notification\nwas suppressed to prevent excessive email.\n\nFor a list of all the issues modified, search jira comments for this\n(hopefully) unique string: 20080415hossman2 "
        }
    ]
}