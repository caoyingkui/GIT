{
    "id": "SOLR-6326",
    "title": "ExternalFileFieldReloader and commits",
    "details": {
        "affect_versions": "None",
        "status": "Open",
        "fix_versions": [],
        "components": [],
        "type": "Bug",
        "priority": "Major",
        "labels": "",
        "resolution": "Unresolved"
    },
    "description": "When there are multiple 'external file field' files available, Solr will reload the last one (lexicographically) with a commit, but only if changes were made to the index. Otherwise, it skips the reload and logs: \"No uncommitted changes. Skipping IW.commit.\" \nIndexWriter.hasUncommittedChanges() returns false, but new external files should be reloaded with commits.",
    "attachments": {
        "SOLR-6326.patch": "https://issues.apache.org/jira/secure/attachment/12674552/SOLR-6326.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Ramana",
            "id": "comment-14129648",
            "date": "2014-09-11T05:26:07+0000",
            "content": "Hi,\nI am trying to replicate the issue. I have configure below in schema.xml\n\nIn the \"solrconfig.xml\",  I added below listeners.\n\n <listener event=\"newSearcher\" class=\"org.apache.solr.schema.ExternalFileFieldReloader\"/>\n <listener event=\"firstSearcher\" class=\"org.apache.solr.schema.ExternalFileFieldReloader\"/>\n\n<fieldType name=\"testFieldlType\" keyField=\"id\" defVal=\"0\" stored=\"false\" indexed=\"false\" class=\"solr.ExternalFileField\" valType=\"pfloat\"/>\n<field name=\"testField\"  type=\"testFieldlType\" />\n\nIn my SOLR data directory, I created a file \"external_testField\"\n\nAfter server start up, I am able to see the values using below URL:\n\n http://localhost:8983/solr/select?q=\n{!func}\ntestField&fl=id,score\n\nBut, when i changed the values.while the server is up and when refreshed the above URL..I am not able to see updated values.\n\nI tried adding below request handler and invoked reload cache with URL http://localhost:8983/solr/reloadCache\n\n<requestHandler name=\"/reloadCache\" class=\"org.apache.solr.search.function.FileFloatSource$ReloadCacheRequestHandler\" />\n\nI have also tried commit with below:\n  http://localhost:8983/solr/update?commit=true\n\nStill, I am not able to see the updated values. Please let me know how to reload the values when the server is up.\n\nThanks,\nRamana. "
        },
        {
            "author": "Ramana",
            "id": "comment-14134144",
            "date": "2014-09-15T17:15:39+0000",
            "content": "My previous issue is resolved. Now i am able to reload the external file field changes.\n\nBasically i have 3 fields defined in my schema.xml with extrenal file field type like below:\n\n<fieldType name=\"testFieldlType\" keyField=\"id\" defVal=\"0\" stored=\"true\" indexed=\"true\" class=\"solr.ExternalFileField\" valType=\"pfloat\"/>\n\n\t<field name=\"testField\"  type=\"testFieldlType\" />\n\t<field name=\"testField1\"  type=\"testFieldlType\" />\n\t<field name=\"testField2\"  type=\"testFieldlType\" />\n\nI created one file for each field in the data directory. When modified all the external files when the server is up, I am able to see all the changes by following below steps:\n\n1) http://localhost:8983/solr/reloadCache\n\n2) http://localhost:8983/solr/select?q=*&fl=id,score,field(testField)\n\n\nPeter,\nCould you please give an example here about the problem.That will help me understand the issue better.\n\nThanks,\nRamana.\n\n\n "
        },
        {
            "author": "Peter Keegan",
            "id": "comment-14134170",
            "date": "2014-09-15T17:33:44+0000",
            "content": "Hi Ramana,\n\nThe use case is:\n\n1. A SolrJ client updates the main index (and replicas) and issues a distributed commit at regular intervals.\n2. Another component updates the external files at other intervals.\n\nUsually, the commits from (1) result in a new searcher which triggers the org.apache.solr.schema.ExternalFileFieldReloader, but only if there were changes to the main index.\n\nUsing ReloadCacheRequestHandler in (2) above would result in the loss of index/replica synchronization provided by the distributed commit in (1), and reloading the core is slow and overkill.\n\nThanks,\nPeter "
        },
        {
            "author": "Steve Rowe",
            "id": "comment-14136215",
            "date": "2014-09-16T21:04:29+0000",
            "content": "Maybe a new event type \u201cpreCommit\u201d could be introduced, which gets fired in DirectUpdateHandler2.commit() before anything else happens?  Then binding the ExternalFileFieldReloader to this event via a <listener> in the <updateHandler> section should do the trick. "
        },
        {
            "author": "Steve Rowe",
            "id": "comment-14136293",
            "date": "2014-09-16T21:41:09+0000",
            "content": "Actually, looking at DirectUpdateHandler2.commit(), \"postCommit\" listeners are called regardless of whether a commit was actually performed, so a new \"preCommit\" event type isn't necessary.  ExternalFileFieldReloader could override AbstractSolrEventListener.postCommit() and handle reloading there.\n\nThere is no support currently for registering \"postSoftCommit\" event listeners in the solrconfig.xml <updateHandler> section, so I think that'd have to be added, along with ExternalFileFieldReloader overriding AbstractSolrEventListener.postSoftCommit(), to provide the same functionality as the current \"newSearcher\" listener.  The \"firstListener\" callback would still be necessary, since no (soft) commit will have happened on startup. "
        },
        {
            "author": "Peter Keegan",
            "id": "comment-14162386",
            "date": "2014-10-07T19:39:14+0000",
            "content": "After revisiting this issue again, I noticed that the EFF reload was occuring in Solr 4.6 on a newSearcher listener, but not in 4.9, because of this change to SolrCore.openNewSearcher:\n\n        if (newReader == null) { // the underlying index has not changed at all\n\n          if (realtime) \n{\n            // if this is a request for a realtime searcher, just return the same searcher\n            newestSearcher.incref();\n            return newestSearcher;\n\n          }\n else if (newestSearcher.get().isCachingEnabled() && newestSearcher.get().getSchema() == getLatestSchema()) \n{\n            // absolutely nothing has changed, can use the same searcher\n            // but log a message about it to minimize confusion\n\n            newestSearcher.incref();\n            log.info(\"SolrIndexSearcher has not changed - not re-opening: \" + newestSearcher.get().getName());\n            return newestSearcher;\n\n          }\n // ELSE: open a new searcher against the old reader...\n          currentReader.incRef();\n          newReader = currentReader;\n        }\n\nSo maybe this needs to be modified to check to see if there are any new EFF files to load?\n "
        },
        {
            "author": "Mikhail Khludnev",
            "id": "comment-14162422",
            "date": "2014-10-07T19:53:22+0000",
            "content": "shouldn't it fail any test? "
        },
        {
            "author": "Peter Keegan",
            "id": "comment-14162720",
            "date": "2014-10-07T22:44:23+0000",
            "content": "Sorry, I'm missing your question. Could you add more words around 'shouldn't it fail any test'? "
        },
        {
            "author": "Mikhail Khludnev",
            "id": "comment-14163278",
            "date": "2014-10-08T09:50:18+0000",
            "content": "I mean, you reveal some issue in the code. I wonder is there a test which fails due to it. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-14163404",
            "date": "2014-10-08T12:05:40+0000",
            "content": "This is caused by SOLR-5783, which went into 4.8\nI still don't know the genesis of that issue though (i.e. if it's even important... were people calling commit often when nothing had changed?) "
        },
        {
            "author": "Peter Keegan",
            "id": "comment-14165890",
            "date": "2014-10-09T22:30:29+0000",
            "content": "Hoss's issue in SOLR-5783 seems reasonable to me. In a sharded index, a 'deleteByQuery' that only affects one shard in a collection should not necessitate the creation of a new searcher in the other unaffected shards.\n\nI will submit a patch for review on Monday. My proposed solution is to add a check in SolrCore.openNewSearcher to see if there are any new 'versioned' EFF files available for any of the ExternalFileFieldReloader event listeners, based on the existing logic in VersionedFile.getLatestFile. If true, a new searcher is opened.\n\n "
        },
        {
            "author": "Peter Keegan",
            "id": "comment-14169694",
            "date": "2014-10-13T18:23:59+0000",
            "content": "Patch attached "
        },
        {
            "author": "Mikhail Khludnev",
            "id": "comment-14170612",
            "date": "2014-10-14T07:11:20+0000",
            "content": "Peter Keegan patch seems effective, though isn't accomplished by test.\n\nI feel like it's reversing dependency: core facility (IndexSearcher) is aware about the secondary one (EFF). I'd prefer EFF kicks IS. Why do you prefer commit for EFF reload, but not eff-reload handler?   "
        },
        {
            "author": "Peter Keegan",
            "id": "comment-14170853",
            "date": "2014-10-14T12:25:18+0000",
            "content": "The preference for commit driven reloads is based on the use case I described to Ramana earlier, in particular the synchronization provided by distributed commits. "
        },
        {
            "author": "Mikhail Khludnev",
            "id": "comment-14171015",
            "date": "2014-10-14T14:48:09+0000",
            "content": "Peter Keegan I'm sorry for annoying offtop, but:\n\nUsing ReloadCacheRequestHandler in (2) above would result in the loss of index/replica synchronization provided by the distributed commit in (1), and reloading the core is slow and overkill.\n\nperhaps it's useless workaround but..\nyou can emulate proper distributed commit, by getting all cluster nodes via https://cwiki.apache.org/confluence/display/solr/Collections+API#CollectionsAPI-api18 and hitting all ReloadCacheRequestHandlers. It flushes all  entries from FileFloatSource.floatCache. \n\nnote: ReloadCacheRequestHandlers doesn't reload core, but commit, however, giving that commit is lazy, it can lead to eg stale entries in queryResultCache. \n\none more offtop: SOLR-5944 seems like a great and necessary replacement for EFF hack. though I didn't look on it deeply.  "
        },
        {
            "author": "Peter Keegan",
            "id": "comment-14171207",
            "date": "2014-10-14T16:49:41+0000",
            "content": "Mikhail Khludnev : not annoying at all, I think your questions and comments are helpful.\n\nI'm doing the indexing and commits with CloudSolrServer. The commit will block until all replicas have successfully committed. After the commit, I could then hit the ReloadCacheRequestHandlers, but wouldn't that open a new searcher twice (assuming the commit resulted in a new searcher, too)? \n\nReplacing EFF with DocValues does seem to be a much better way to handle rapid field changes. It does seem risky, though, but I'll definitely look into it - thanks. "
        },
        {
            "author": "Mikhail Khludnev",
            "id": "comment-14171233",
            "date": "2014-10-14T17:17:52+0000",
            "content": "After the commit, I could then hit the ReloadCacheRequestHandlers, \n\n\n\tI'd rather suggest just hit the ReloadCacheRequestHandlers only at all nodes one by one or in parallel. ReloadCacheRequestHandlers calls commit() underneath.\n\n\n\nbut wouldn't that open a new searcher twice (assuming the commit resulted in a new searcher, too)? \n\n\n\teven if you do both, it could, but we know SOLR-5783 prevents it.\n\n "
        }
    ]
}