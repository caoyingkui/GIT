{
    "id": "SOLR-4449",
    "title": "Enable backup requests for the internal solr load balancer",
    "details": {
        "affect_versions": "None",
        "status": "Open",
        "fix_versions": [],
        "components": [
            "SolrCloud"
        ],
        "type": "New Feature",
        "priority": "Minor",
        "labels": "",
        "resolution": "Unresolved"
    },
    "description": "Add the ability to configure the built-in solr load balancer such that it submits a backup request to the next server in the list if the initial request takes too long. Employing such an algorithm could improve the latency of the 9xth percentile albeit at the expense of increasing overall load due to additional requests.",
    "attachments": {
        "solr-back-request-lb-plugin.jar": "https://issues.apache.org/jira/secure/attachment/12599170/solr-back-request-lb-plugin.jar",
        "patch-4449.txt": "https://issues.apache.org/jira/secure/attachment/12570739/patch-4449.txt",
        "SOLR-4449.patch": "https://issues.apache.org/jira/secure/attachment/12569281/SOLR-4449.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "philip hoy",
            "id": "comment-13577693",
            "date": "2013-02-13T16:40:05+0000",
            "content": "The patch implements backup requests only for the methods used by the HttpShardHandler not for Solrj client type use. \n\nThe load balancer may be configured using something like the following:\n\n \n<shardHandlerFactory class=\"HttpBackupRequestShardHandlerFactory\"> \n\t<int name=\"backupRequestDelay\">1000</int> \n\t<int name=\"maximumConcurrentRequests\">2</int> \n        <!-- all the HttpShardHandlerFactory args are available too. -->\n</shardHandlerFactory>\n\n "
        },
        {
            "author": "philip hoy",
            "id": "comment-13580713",
            "date": "2013-02-18T17:05:35+0000",
            "content": "Here is some information supporting the idea of using backup requests to improve latency. Below are links for a slide deck from Google and some interesting blog posts:\n\n\thttp://research.google.com/people/jeff/latency.html\n\thttp://highscalability.com/blog/2012/6/18/google-on-latency-tolerant-systems-making-a-predictable-whol.html\n\thttp://www.bailis.org/blog/doing-redundant-work-to-speed-up-distributed-queries/\n\n\n\nAlso for reference here is some further discussion on the issue from solr-user mailing list:\n\n\thttp://mail-archives.apache.org/mod_mbox/lucene-solr-user/201302.mbox/%3C81E9A7879C550B42A767F0B86B2B815929EFB1D4@ex4.corp.w3data.com%3E\n\n "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13580714",
            "date": "2013-02-18T17:09:41+0000",
            "content": "Cool, I'll add this issue to my list in case someone else doesn't get to it. "
        },
        {
            "author": "Markus Jelsma",
            "id": "comment-13580779",
            "date": "2013-02-18T19:00:17+0000",
            "content": "Hi Philip - can you show some 99th percentile measurements of a cluster receiving a decent amount of concurrent requests? With and without your patch? "
        },
        {
            "author": "Raintung Li",
            "id": "comment-13582029",
            "date": "2013-02-20T08:26:17+0000",
            "content": "Hi Philip, I have one suggestion that don't open new thread in BackupRequestLBHttpSolrServer that will increase threads double special in the search function.\nSearch receive request thread will wait the response from multiple shards, this thread can submit the second request to shards of overtime.\nFor example:\nOne search request:\n3 shards, \nthe first request: Need 1+3*2 = 7 threads to handle , \nthe second request: Bad case(3 shards all need resend again) 10 threads\n\nChange to \nthe first request: Need 1+3=4  threads to handle\nthe second request: Bad case 7 threads\n\nLook solr use simple random to do LB. \nhttps://blog.heroku.com/archives/2013/2/16/routing_performance_update/ \nThis blog attacked the random strategy was terrible.\n\n "
        },
        {
            "author": "philip hoy",
            "id": "comment-13582304",
            "date": "2013-02-20T16:36:15+0000",
            "content": "Hi Raintung, I don't think there will be that many threads created, although it depends somewhat on how the injected ThreadPoolExecuter and HttpClient are configured. \n\nFor the good case, where the first shard responds within the delay period, there is I think one thread for the orchestration code and one to send and receive the request.\n\nFor the bad case, where there are three shards all responding slowly and where the maximumConcurrentRequests is set to 3 or higher then it will again use one thread for the the orchestration code but this time there will be three threads used to send and receive responses for the three requests.\n "
        },
        {
            "author": "Raintung Li",
            "id": "comment-13582805",
            "date": "2013-02-21T02:04:46+0000",
            "content": "Hi Philip, although all threads are in the ThreadPool that don't create the new thread, it still occupy the thread in the threads pool.\nFor one search request, you will use double threads than before in the first request(Normal case).  If it is coming 100 request, that means 300 threads will be used additional for 3 shards.\n\nIf wait the response and send the second request in the HttpShardHandler.submit method, it will reduce the unnecessary threads cost. "
        },
        {
            "author": "philip hoy",
            "id": "comment-13583054",
            "date": "2013-02-21T09:45:40+0000",
            "content": "Raintung, Agreed the strategy does use more threads, but that is unavoidable I believe because work needs to be done concurrently. The two concurrent tasks are firstly to await completed requests and optionally create new requests if the request takes too long and secondly to send the request and accept the response. If a request is made in the main thread then of course it will block that thread so can't react if a request it sent previously in another thread responds.\n\nIn the case where 100 requests are sent, if all is well then in will use 200 threads, if there are issues then no doubt servers will be zombied so it is unlikely to cycle through all 3 shards for all 100 requests.  "
        },
        {
            "author": "Raintung Li",
            "id": "comment-13585565",
            "date": "2013-02-25T01:54:53+0000",
            "content": "Let me describe it clear to make the same page.\n\nNormal case:\nClient send 1 request for search, the Servlet will have handle request thread that we call it is request main thread.\nThen main thread will start 3 threads to send the request to 3 shards, because this collection has 3 shards.\nMain thread block to wait the full 3 threads(shards) response.  \nResult:\nWe need 4 threads in the normal case that don't send the second request.\n\nYour case:\nClient send 1 request search .....\nThen main thread will start 6 threads to send the request to 3 shards......\nMain thread block to wait the 3 threads response, the other 3 threads are stared in the LB\nResult:\nWe need 7 threads in the normal case that don't send the second request.\n\n\nMy case:\nClient send 1 request for search, ....\nThen this thread will .....\nChange: Main thread wait the 3 threads response in the fixed time. Which shard is overtime, main thread submit the second request.\nResult:\nWe need 4 threads in the normal case that don't send the second request.\n\n\n "
        },
        {
            "author": "Raintung Li",
            "id": "comment-13585682",
            "date": "2013-02-25T07:24:31+0000",
            "content": "It is only the sample my idea, doesn't test. "
        },
        {
            "author": "philip hoy",
            "id": "comment-13585772",
            "date": "2013-02-25T10:16:30+0000",
            "content": "Hi Raintang, My apologies I think I have been sloppy in my language and that may have misled you. When I referred to shards in my comments previously, really I meant replicas. This jira covers how the replicas are load balanced not how the shard/slice requests are managed. I would think that should be dealt with in a separate issue.  "
        },
        {
            "author": "philip hoy",
            "id": "comment-13590572",
            "date": "2013-03-01T14:39:02+0000",
            "content": "added logging to the load balancer and fixed a bug. "
        },
        {
            "author": "philip hoy",
            "id": "comment-13591681",
            "date": "2013-03-03T08:33:32+0000",
            "content": "Seems like the ExecutorCompletionService<T>.poll(time) method is costly. Need to figure out a way of delaying the backup requests using a different mechanism. "
        },
        {
            "author": "philip hoy",
            "id": "comment-13743729",
            "date": "2013-08-19T11:14:15+0000",
            "content": "A bounded ArrayBlockingQueue backed Executor performs better than the default completion queue.  "
        },
        {
            "author": "philip hoy",
            "id": "comment-13745966",
            "date": "2013-08-21T11:46:35+0000",
            "content": "Now SOLR-4448 is committed the backup request load balancer is pluggable, attached is a java7 plugin built against lucene solr 4.4.0.  "
        },
        {
            "author": "Isaac Hebsh",
            "id": "comment-13747639",
            "date": "2013-08-22T16:30:54+0000",
            "content": "philip hoy, can you provide an example for solrconfig.xml, with this plugin? "
        },
        {
            "author": "Isaac Hebsh",
            "id": "comment-13747646",
            "date": "2013-08-22T16:41:11+0000",
            "content": "And, as i asked in the duplicated issue SOLR-5092, the code contains a comment that says it's important to \"use the same replica for all phases of a distributed request.\"\n\nI don't think it's important, because it might happen even without this plugin, if one replica goes down between two phases of the request.\n\nDo you have any thoughts/conclusions about this? "
        },
        {
            "author": "philip hoy",
            "id": "comment-13759148",
            "date": "2013-09-05T15:10:14+0000",
            "content": "Isaac Hebsh, to test, just drop the attached jar into the shared lib folder and add the shardHandlerFactory configuration to the requestHandler node in the solrconfig.xml:\n\n \n<requestHandler default=\"true\" name=\"standard\" class=\"solr.SearchHandler\">\n  <shardHandlerFactory class=\"HttpBackupRequestShardHandlerFactory\">\n    <int name=\"backupRequestDelay\">1500</int>\n    <int name=\"maximumConcurrentRequests\">2</int>\n  </shardHandlerFactory>\n</requestHandler>\n\n \n\nI too have no idea why the HttpShardHandler contains that comment. However for the sake of caching, hitting the same replica could be beneficial i guess. "
        },
        {
            "author": "Otis Gospodnetic",
            "id": "comment-13847128",
            "date": "2013-12-13T03:51:21+0000",
            "content": "Nice one, philip hoy!\n\nHi Philip - can you show some 99th percentile measurements of a cluster receiving a decent amount of concurrent requests? With and without your patch?\n\n+1 for this - I'd love to see the same.\n\nAlso, another idea:\nI'm assuming this patch always sends an extra request right away.  How about sending just 1 request first and then firing the 2nd one only if the 1st one hasn't returned after N milliseconds?  This way the price of an extra request will be paid only sometimes.  Using N=-1 or N=0 could mean \"send both right away\". "
        },
        {
            "author": "philip hoy",
            "id": "comment-13847375",
            "date": "2013-12-13T10:42:50+0000",
            "content": "Otis, it does work in the way that you have suggested, any backup requests are only sent after a configurable backupRequestDelay millis which could of course be 0. The number of concurrent requests is limited by maximumConcurrentRequests.\n\nAlso i have recently implemented inflight request counting and added that to the backup request load balancer. Now the load balancer will pick the server that is currently handling the fewest requests. \n\nCurrently the backup request load balancer is running live in our production environment alongside a standard solr load balancer, i have configured a socket timeout of 30 secs and a retry after 15 secs, also worth noting is we have only two replicas of the data. Here are some numbers from yesterday:\n\n\n\n\nSeconds\n  Count(standard)\n Count(with backups)   \n\n\n0.0\t        \n279635\t\t    \n281384 \n\n\n5.0\t        \n3141\t    \t    \n2668 \n\n\n10.0 \t\n585\t\t            \n421\n\n\n15.0 \t\n176\t\t            \n209\n\n\n20.0 \t\n145\t\t            \n54 \n\n\n25.0 \t\n147\t\t            \n42 \n\n\n30.0 \t\n137\t\t            \n79 \n\n\n35.0 \t\n22\t\t            \n14 \n\n\n40.0 \t\n30\t\t            \n11 \n\n\n45.0 \t\n20\t\t            \n37\n\n\n50.0 \t\n17\t\t            \n5 \n\n\n55.0 \t\n7\t\t            \n0\n\n\n60.0 \t\n213\t\t            \n68\n\n\n\n\n\nAs you can see the numbers do look a little better with backups however i think with more replicas of the data one could be more aggressive with the retry time without the risk of flooding all the  servers in which case the improvement would be more marked.  "
        },
        {
            "author": "Jeff Wartes",
            "id": "comment-14901555",
            "date": "2015-09-21T22:41:15+0000",
            "content": "I pulled this patch out into a freestanding jar and ported it to Solr 5.3. \n\nI tried to pull in all the things that had changed since they were copied from the parent class in 4.4, and added per-request backup time support. \nSadly, there were still a few places where package-protected restrictions got in the way, (Rsp.server and LBHttpSolrClient.doRequest in particular) so even as a separate jar, this must be loaded by the same classloader as LBHttpSolrClient, not via solr's lib inclusion mechanism.\n\nAfter this long, it feels unlikely this feature will get merged, but if there's any interest in that it should still be pretty simple to just copy the files back into the solr source tree, I didn't change any paths or package names, and I'd be happy to upload another patch file.\n\nMy version can be found here:\nhttps://github.com/whitepages/SOLR-4449\n\nFor those who were wondering about the effect of this stuff, in one test today I cut my median query response time in half, at a cost of about 15% more cluster-wide cpu, simply by using this and setting the backupRequestDelay to half my observed ParNew GC pause. The next logical step would be performance-aware backup request settings, like \"issue a backup request when you exceed your 95th percentile latency for a given requestHandler or queryPerformanceClass\".\n\nMy thanks to philip hoy for authoring this. "
        },
        {
            "author": "Jeff Wartes",
            "id": "comment-14947724",
            "date": "2015-10-07T22:39:12+0000",
            "content": "I've added performance tracking to this, so that you can request a backup request at (say) the 95th percentile latency for a given performance class of query.\n\nI'm likely going to continue on this path, but this adds a dependency on metrics-core, so I've dropped a tag (5.3_port_complete) just prior to those changes. Anyone interested in merging something like this may prefer to work from that. "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-14947756",
            "date": "2015-10-07T22:55:59+0000",
            "content": "this adds a dependency on metrics-core\n\nThe core Solr module (where SolrCloud code lives) already contains a dependency on metrics-core from codahale.  That dependency is currently version 3.0.1.  The dependency was originally added for SOLR-1972.  Is that the metrics-core that you're talking about, or is there a different one? "
        },
        {
            "author": "Jeff Wartes",
            "id": "comment-14949141",
            "date": "2015-10-08T18:47:34+0000",
            "content": "Ah, great. Yeah, same thing. I knew it had been discussed in SOLR-4735, but since that hadn't been merged, I didn't even bother checking if it already existed.\n\nThanks for the reference. After reading through the comment history in SOLR-1972, it seems like I should look closely at that integration and see if I can leverage anything existing there. "
        },
        {
            "author": "Markus Jelsma",
            "id": "comment-15013406",
            "date": "2015-11-19T11:48:43+0000",
            "content": "Hi Jeff, these are nice additions to the shardHandler. Anyone here able to review and get this in Solr? "
        },
        {
            "author": "philip hoy",
            "id": "comment-15013549",
            "date": "2015-11-19T13:36:51+0000",
            "content": "And if there is anything i can do to help i would be more than happy. "
        },
        {
            "author": "Jeff Wartes",
            "id": "comment-15053665",
            "date": "2015-12-11T22:07:49+0000",
            "content": "I looked around a bit, and unless I'm missing something, it looks like solr-core doesn't really use metrics-core. At the end of SOLR-1972, the necessary classes were just copy/pasted into the solr codeline. It sounds like this was mostly due to being nervous after encountering some problems in the metrics-core version at the time, and an aversion to a global registry approach. \n\nUnfortunately, this means that although requesthandlers have statistics, they cannot be attached to a metrics Reporter, and instead you have to develop something to interrogate JMX or some such. \n\nSolr does include metrics-core 3.0.1, but there's only a few places it actually gets used, and only in contrib modules.\n\nI didn't have the negative experience with metrics-core. In fact, my experiences with 3.1.2 over the last year and a half has been universally positive. So when I added backup-percentile support to this issue I relied heavily on the global SharedMetricsRegistry and the assumption that the library was threadsafe in general. My scattershot code reviews of the metrics library have generally enforced my opinion that this is ok, and I'm using my version of this issue in production now. Initializing a well-known-named shared registry with an attached reporter in jetty.xml has yielded all kinds of great performance data.\n\nThis might be a useful point of information if anyone gets back to SOLR-4735. I'll mention here if I do encounter any metrics-core related issues in the future. "
        },
        {
            "author": "Jeff Wartes",
            "id": "comment-15053711",
            "date": "2015-12-11T22:42:16+0000",
            "content": "For what it's worth, if I were a solr committer, I probably wouldn't just merge this issue as-is. BackupRequestLBHttpSolrClient still has a certain amount of copy/paste code from the parent LBHttpSolrClient class that'd become extra long-term maintenance load. (As it will be every time I update this issue for a new solr version)\n\nInstead, I'd do something like:\n1. Pull the asynchronous ExecutorCompletionService-based query approach into the LBHttpSolrClient itself. This would be interesting and useful functionality in it's own right. \n2. Add the concept of a shardTimeout. (Distinct from timeAllowed)\n3. Add extendable support for how to handle a shardTimeout. If a strategy ends up making a request to another server in the list, that request must be submitted to the same ExecutorCompletionService so that in all cases, LBHttpSolrClient would return the first response among the submitted requests. \n4. The backup-request functionality could still then be a class extending LBHttpSolrClient, but the only real code there would be defining the shardTimeout for a given request, and how to handle a shardTimeout if there was one.\n\nI'd probably audit the access restrictions in LBHttpSolrClient while I was at it though, since solrconfig.xml provides such an easy way to use alternate implementations of that class. A lot of the existing code in BackupRequestLBHttpSolrClient is only necessary due to not having sufficient access to the parent class. (isTimeExceeded/getTimeAllowedInNanos seem generally useful to have, for example, and I'm not sure why doRequest is protected) "
        },
        {
            "author": "Phil Hoy",
            "id": "comment-15595349",
            "date": "2016-10-21T15:04:43+0000",
            "content": "I no longer work at Findmypast. Thank you. "
        }
    ]
}