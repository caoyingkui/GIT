{
    "id": "SOLR-9825",
    "title": "Solr should not return HTTP 400 for some cases",
    "details": {
        "components": [],
        "type": "Bug",
        "labels": "",
        "fix_versions": [],
        "affect_versions": "5.3.2",
        "status": "Open",
        "resolution": "Unresolved",
        "priority": "Major"
    },
    "description": "For some cases, when solr handling requests, it should not always return http 400.  We met several cases, here is the recent two:\n\nCase 1:  When adding a doc, if there is runtime error happens, even it's a solr internal issue, it returns http 400 to confuse the client. Actually the request is good, while IndexWriter is closed. \n\nThe exception stack is:\n2016-11-22 21:23:32.858 ERROR (qtp2011912080-83) [c:collection12 s:shard1 r:core_node1 x:collection12_shard1_replica1] o.a.s.c.SolrCore org.apache.solr.common.SolrException: Exception writing document id Q049dXMxYjMtbWFpbDg4L089bGxuX3VzMQ==20824042!8918AB024CF638F685257DDC00074D78 to the index; possible analysis error.\n\tat org.apache.solr.update.DirectUpdateHandler2.addDoc(DirectUpdateHandler2.java:167)\n\tat org.apache.solr.update.processor.RunUpdateProcessor.processAdd(RunUpdateProcessorFactory.java:69)\n\tat org.apache.solr.update.processor.UpdateRequestProcessor.processAdd(UpdateRequestProcessor.java:51)\n\tat org.apache.solr.update.processor.DistributedUpdateProcessor.doLocalAdd(DistributedUpdateProcessor.java:955)\n\tat org.apache.solr.update.processor.DistributedUpdateProcessor.versionAdd(DistributedUpdateProcessor.java:1110)\n\tat org.apache.solr.update.processor.DistributedUpdateProcessor.processAdd(DistributedUpdateProcessor.java:706)\n\tat org.apache.solr.update.processor.UpdateRequestProcessor.processAdd(UpdateRequestProcessor.java:51)\n\tat org.apache.solr.update.processor.LanguageIdentifierUpdateProcessor.processAdd(LanguageIdentifierUpdateProcessor.java:207)\n\tat org.apache.solr.update.processor.UpdateRequestProcessor.processAdd(UpdateRequestProcessor.java:51)\n\tat org.apache.solr.update.processor.CloneFieldUpdateProcessorFactory$1.processAdd(CloneFieldUpdateProcessorFactory.java:231)\n\tat org.apache.solr.handler.loader.JsonLoader$SingleThreadedJsonLoader.processUpdate(JsonLoader.java:143)\n\tat org.apache.solr.handler.loader.JsonLoader$SingleThreadedJsonLoader.load(JsonLoader.java:113)\n\tat org.apache.solr.handler.loader.JsonLoader.load(JsonLoader.java:76)\n\tat org.apache.solr.handler.UpdateRequestHandler$1.load(UpdateRequestHandler.java:98)\n\tat org.apache.solr.handler.ContentStreamHandlerBase.handleRequestBody(ContentStreamHandlerBase.java:74)\n\tat org.apache.solr.handler.RequestHandlerBase.handleRequest(RequestHandlerBase.java:143)\n\tat org.apache.solr.core.SolrCore.execute(SolrCore.java:2068)\n\tat org.apache.solr.servlet.HttpSolrCall.execute(HttpSolrCall.java:672)\n\tat org.apache.solr.servlet.HttpSolrCall.call(HttpSolrCall.java:463)\n\tat org.apache.solr.servlet.SolrDispatchFilter.doFilter(SolrDispatchFilter.java:235)\n\tat org.apache.solr.servlet.SolrDispatchFilter.doFilter(SolrDispatchFilter.java:199)\n\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1652)\n\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:585)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)\n\tat org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:577)\n\tat org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:223)\n\tat org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1127)\n\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:515)\n\tat org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)\n\tat org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1061)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n\tat org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:215)\n\tat org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:110)\n\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97)\n\tat org.eclipse.jetty.server.Server.handle(Server.java:499)\n\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:310)\n\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:257)\n\tat org.eclipse.jetty.io.AbstractConnection$2.run(AbstractConnection.java:540)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:635)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:555)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: org.apache.lucene.store.AlreadyClosedException: this IndexWriter is closed\n\tat org.apache.lucene.index.IndexWriter.ensureOpen(IndexWriter.java:719)\n\tat org.apache.lucene.index.IndexWriter.ensureOpen(IndexWriter.java:733)\n\tat org.apache.lucene.index.IndexWriter.updateDocument(IndexWriter.java:1471)\n\tat org.apache.solr.update.DirectUpdateHandler2.addDoc0(DirectUpdateHandler2.java:239)\n\tat org.apache.solr.update.DirectUpdateHandler2.addDoc(DirectUpdateHandler2.java:163)\n\t... 40 more\nCaused by: java.nio.channels.ClosedByInterruptException\n\tat java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:202)\n\tat sun.nio.ch.FileChannelImpl.size(FileChannelImpl.java:315)\n\tat org.apache.lucene.store.NativeFSLockFactory$NativeFSLock.ensureValid(NativeFSLockFactory.java:170)\n\tat org.apache.lucene.store.LockValidatingDirectoryWrapper.createOutput(LockValidatingDirectoryWrapper.java:43)\n\tat org.apache.lucene.store.TrackingDirectoryWrapper.createOutput(TrackingDirectoryWrapper.java:43)\n\tat org.apache.lucene.codecs.blocktree.BlockTreeTermsWriter.<init>(BlockTreeTermsWriter.java:328)\n\tat org.apache.lucene.codecs.blocktree.BlockTreeTermsWriter.<init>(BlockTreeTermsWriter.java:280)\n\tat org.apache.lucene.codecs.lucene50.Lucene50PostingsFormat.fieldsConsumer(Lucene50PostingsFormat.java:428)\n\tat org.apache.lucene.codecs.perfield.PerFieldPostingsFormat$FieldsWriter.write(PerFieldPostingsFormat.java:196)\n\tat org.apache.lucene.index.FreqProxTermsWriter.flush(FreqProxTermsWriter.java:107)\n\tat org.apache.lucene.index.DefaultIndexingChain.flush(DefaultIndexingChain.java:112)\n\tat org.apache.lucene.index.DocumentsWriterPerThread.flush(DocumentsWriterPerThread.java:422)\n\tat org.apache.lucene.index.DocumentsWriter.doFlush(DocumentsWriter.java:503)\n\tat org.apache.lucene.index.DocumentsWriter.flushAllThreads(DocumentsWriter.java:615)\n\tat org.apache.lucene.index.IndexWriter.getReader(IndexWriter.java:423)\n\tat org.apache.lucene.index.StandardDirectoryReader.doOpenIfChanged(StandardDirectoryReader.java:273)\n\tat org.apache.lucene.index.DirectoryReader.openIfChanged(DirectoryReader.java:203)\n\tat org.apache.solr.core.SolrCore.openNewSearcher(SolrCore.java:1581)\n\tat org.apache.solr.core.SolrCore.getSearcher(SolrCore.java:1773)\n\tat org.apache.solr.update.DirectUpdateHandler2.commit(DirectUpdateHandler2.java:609)\n\tat org.apache.solr.update.CommitTracker.run(CommitTracker.java:216)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\t... 1 more\n\n\nThe code is:\n  public int addDoc(AddUpdateCommand cmd) throws IOException {\n    try \n{\n      return addDoc0(cmd);\n    }\n catch (SolrException e) \n{\n      throw e;\n    }\n catch (RuntimeException t) \n{\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Exception writing document id %s to the index; possible analysis error.\",\n          cmd.getPrintableId()), t);\n    }\n  }\n\nCase 2: For solrcloud, when ZK session has issues or core node fails to register itself to zk, it's actually an internal issue or IO issue. 503/500/404 are all acceptable, but 400 is not, as it will make client confuse. \n\ncode: \n  public static DocCollection getCollectionLive(ZkStateReader zkStateReader,\n      String coll) {\n    String collectionPath = getCollectionPath(coll);\n    try \n{\n      Stat stat = new Stat();\n      byte[] data = zkStateReader.getZkClient().getData(collectionPath, null, stat, true);\n      ClusterState state = ClusterState.load(stat.getVersion(), data,\n          Collections.<String> emptySet(), collectionPath);\n      ClusterState.CollectionRef collectionRef = state.getCollectionStates().get(coll);\n      return collectionRef == null ? null : collectionRef.get();\n    }\n catch (KeeperException.NoNodeException e) \n{\n      log.warn(\"No node available : \" + collectionPath, e);\n      return null;\n    }\n catch (KeeperException e) \n{\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          \"Could not load collection from ZK:\" + coll, e);\n    }\n catch (InterruptedException e) \n{\n      Thread.currentThread().interrupt();\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          \"Could not load collection from ZK:\" + coll, e);\n    }\n  }",
    "attachments": {},
    "issue_links": {},
    "comments": []
}