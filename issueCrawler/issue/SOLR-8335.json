{
    "id": "SOLR-8335",
    "title": "HdfsLockFactory does not allow core to come up after a node was killed",
    "details": {
        "components": [],
        "type": "Bug",
        "labels": "",
        "fix_versions": [],
        "affect_versions": "5.0,                                            5.1,                                            5.2,                                            5.2.1,                                            5.3,                                            5.3.1",
        "status": "Reopened",
        "resolution": "Unresolved",
        "priority": "Major"
    },
    "description": "When using HdfsLockFactory if a node gets killed instead of a graceful shutdown the write.lock file remains in HDFS . The next time you start the node the core doesn't load up because of LockObtainFailedException .\n\nI was able to reproduce this in all 5.x versions of Solr . The problem wasn't there when I tested it in 4.10.4\n\nSteps to reproduce this on 5.x\n\n1. Create directory in HDFS : bin/hdfs dfs -mkdir /solr\n2. Start Solr: bin/solr start -Dsolr.directoryFactory=HdfsDirectoryFactory -Dsolr.lock.type=hdfs -Dsolr.data.dir=hdfs://localhost:9000/solr -Dsolr.updatelog=hdfs://localhost:9000/solr\n3. Create core: ./bin/solr create -c test -n data_driven\n4. Kill solr\n5. The lock file is there in HDFS and is called write.lock\n6. Start Solr again and you get a stack trace like this:\n\n\n2015-11-23 13:28:04.287 ERROR (coreLoadExecutor-6-thread-1) [   x:test] o.a.s.c.CoreContainer Error creating core [test]: Index locked for write for core 'test'. Solr now longer supports forceful unlocking via 'unlockOnStartup'. Please verify locks manually!\norg.apache.solr.common.SolrException: Index locked for write for core 'test'. Solr now longer supports forceful unlocking via 'unlockOnStartup'. Please verify locks manually!\n        at org.apache.solr.core.SolrCore.<init>(SolrCore.java:820)\n        at org.apache.solr.core.SolrCore.<init>(SolrCore.java:659)\n        at org.apache.solr.core.CoreContainer.create(CoreContainer.java:723)\n        at org.apache.solr.core.CoreContainer$1.call(CoreContainer.java:443)\n        at org.apache.solr.core.CoreContainer$1.call(CoreContainer.java:434)\n        at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n        at org.apache.solr.common.util.ExecutorUtil$MDCAwareThreadPoolExecutor$1.run(ExecutorUtil.java:210)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n        at java.lang.Thread.run(Thread.java:745)\nCaused by: org.apache.lucene.store.LockObtainFailedException: Index locked for write for core 'test'. Solr now longer supports forceful unlocking via 'unlockOnStartup'. Please verify locks manually!\n        at org.apache.solr.core.SolrCore.initIndex(SolrCore.java:528)\n        at org.apache.solr.core.SolrCore.<init>(SolrCore.java:761)\n        ... 9 more\n2015-11-23 13:28:04.289 ERROR (coreContainerWorkExecutor-2-thread-1) [   ] o.a.s.c.CoreContainer Error waiting for SolrCore to be created\njava.util.concurrent.ExecutionException: org.apache.solr.common.SolrException: Unable to create core [test]\n        at java.util.concurrent.FutureTask.report(FutureTask.java:122)\n        at java.util.concurrent.FutureTask.get(FutureTask.java:192)\n        at org.apache.solr.core.CoreContainer$2.run(CoreContainer.java:472)\n        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n        at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n        at org.apache.solr.common.util.ExecutorUtil$MDCAwareThreadPoolExecutor$1.run(ExecutorUtil.java:210)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n        at java.lang.Thread.run(Thread.java:745)\nCaused by: org.apache.solr.common.SolrException: Unable to create core [test]\n        at org.apache.solr.core.CoreContainer.create(CoreContainer.java:737)\n        at org.apache.solr.core.CoreContainer$1.call(CoreContainer.java:443)\n        at org.apache.solr.core.CoreContainer$1.call(CoreContainer.java:434)\n        ... 5 more\nCaused by: org.apache.solr.common.SolrException: Index locked for write for core 'test'. Solr now longer supports forceful unlocking via 'unlockOnStartup'. Please verify locks manually!\n        at org.apache.solr.core.SolrCore.<init>(SolrCore.java:820)\n        at org.apache.solr.core.SolrCore.<init>(SolrCore.java:659)\n        at org.apache.solr.core.CoreContainer.create(CoreContainer.java:723)\n        ... 7 more\nCaused by: org.apache.lucene.store.LockObtainFailedException: Index locked for write for core 'test'. Solr now longer supports forceful unlocking via 'unlockOnStartup'. Please verify locks manually!\n        at org.apache.solr.core.SolrCore.initIndex(SolrCore.java:528)\n        at org.apache.solr.core.SolrCore.<init>(SolrCore.java:761)\n        ... 9 more\n\n\n\n\nIn 4.10.4 I saw these two differences\n\n1. The lock file name was different . It's something like : /solr/index/HdfsDirectory@46ad6bd3 lockFactory=org.apache.solr.store.hdfs.HdfsLockFactory@4b44b5f6-write.lock\n2. When the node is started again after it was killed , it loaded up the core just fine but there were two lock files in hdfs now . 4b44b5f6-write.lock is the latest one\n\n\n/solr/index/HdfsDirectory@46ad6bd3 lockFactory=org.apache.solr.store.hdfs.HdfsLockFactory@4b44b5f6-write.lock\n/solr/index/HdfsDirectory@52959724 lockFactory=org.apache.solr.store.hdfs.HdfsLockFactory@9d59d3f-write.lock",
    "attachments": {
        "SOLR-8335.patch": "https://issues.apache.org/jira/secure/attachment/12887113/SOLR-8335.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2015-11-24T12:16:19+0000",
            "author": "Mark Miller",
            "content": "Not really a bug, same as with simple local simple fs locks. You have to use a native lock factory to avoid this. For HDFS, we have an issue to look at trying to use ZK in an alternate factory, though it's not an easy issue.  ",
            "id": "comment-15024364"
        },
        {
            "date": "2015-11-24T12:34:52+0000",
            "author": "Varun Thacker",
            "content": "Interesting. Do you know why it worked in 4.10.4 ? \n\nAlso since you are saying this is a known limitation, should we not get rid of 'unlockOnStartup' in SOLR-6737 ? I know Lucene has removed it but does it make sense  for Solr to keep it and do something with the parameter?\n\nFor example, if a user is on HDFS and uses autoAddReplicas . If a process gets killed then unless someone manually removed the lock autoAddReplicas will fail right?\n\nYou mention on SOLR-6737 that its a really bad idea to have unlockOnStartup . Thats true especially after the read only replicas feature comes in I guess. But for current users , it's either they manually remove the lock files or use no lock factory at all ? ",
            "id": "comment-15024421"
        },
        {
            "date": "2015-11-24T14:46:26+0000",
            "author": "Mark Miller",
            "content": "Would not have worked any better on 4.10 - a file in Hdfs won't just go away because of a crash. Unlock on startup is no real solution - that's saying, make the lock factory not really lock, even more dangerous on a shared fs where more than one Solr instance can easily point at an index. \n\nManual removal is the best option without a different lock factory available.  ",
            "id": "comment-15024615"
        },
        {
            "date": "2015-11-25T05:12:57+0000",
            "author": "Varun Thacker",
            "content": "Hi Mark,\n\na file in Hdfs won't just go away because of a crash.\n\nSure it won't go away. But the one difference which I am seeing in 4.10 is the naming of the lock and that a new named lock gets created every time you start solr after killing it abruptly ( kill -9 in my test )\n\nSteps I followed on 4.10.4 \n\n1. Start Solr using java -jar start.jar -Dsolr.directoryFactory=HdfsDirectoryFactory -Dsolr.lock.type=hdfs -Dsolr.data.dir=hdfs://localhost:9000/solr410 -Dsolr.updatelog=hdfs://localhost:9000/solr410\n\n2. Output from hdfs\n\nFound 2 items\n-rw-r--r--   3 varun supergroup          0 2015-11-25 10:28 /solr410/index/HdfsDirectory@52959724 lockFactory=org.apache.solr.store.hdfs.HdfsLockFactory@9d59d3f-write.lock\n-rwxr-xr-x   1 varun supergroup         53 2015-11-25 10:28 /solr410/index/segments_1\n\n\n\n3. Kill Solr and start again\n\n4. Output from hdfs\n\nFound 3 items\n-rw-r--r--   3 varun supergroup          0 2015-11-25 10:29 /solr410/index/HdfsDirectory@46ad6bd3 lockFactory=org.apache.solr.store.hdfs.HdfsLockFactory@4b44b5f6-write.lock\n-rw-r--r--   3 varun supergroup          0 2015-11-25 10:28 /solr410/index/HdfsDirectory@52959724 lockFactory=org.apache.solr.store.hdfs.HdfsLockFactory@9d59d3f-write.lock\n-rwxr-xr-x   1 varun supergroup         53 2015-11-25 10:28 /solr410/index/segments_1\n\n\n\nEvery time I repeat the kill + start a new lock file gets created . Hence it works on 4.10.4 but never worked in 5.x since the lock file in 5.x is called write.lock which made me believe it was a bug in 5.x\n\nAm I doing anything differently in the tests here? ",
            "id": "comment-15026212"
        },
        {
            "date": "2015-11-25T15:47:43+0000",
            "author": "Mark Miller",
            "content": "Ah, ok.  I'd have to look closer.  ",
            "id": "comment-15026955"
        },
        {
            "date": "2015-11-25T16:19:32+0000",
            "author": "Uwe Schindler",
            "content": "This was just broken behaviour in 4.x. The lock file should not have a prefix, because this would have no effect at all. Every Solr node would produce a new lock file name so locking would have no effect \n\nI was expecting that you had the 4.x deprecated setting to forcefully remove the lock file on startup, which is no longer supported in 5.x. You have to delete the file on your own. ",
            "id": "comment-15027024"
        },
        {
            "date": "2015-11-25T16:36:13+0000",
            "author": "Uwe Schindler",
            "content": "SOLR-6737 is already solved since 5.3. ",
            "id": "comment-15027073"
        },
        {
            "date": "2015-11-25T18:09:32+0000",
            "author": "Varun Thacker",
            "content": "Every Solr node would produce a new lock file name so locking would have no effect\n\nThat explains it \n\nI am marking this ticket as 'Won't Fix' then. ",
            "id": "comment-15027303"
        },
        {
            "date": "2015-11-25T18:11:54+0000",
            "author": "Varun Thacker",
            "content": "The current behaviour is expected and one has to manually remove the lock file if the JVM stops abruptly . SOLR-8169 aims to solve that problem for HDFS users by exploring the option of the lock being in ZooKeeper. ",
            "id": "comment-15027306"
        },
        {
            "date": "2016-03-19T05:12:47+0000",
            "author": "lvchuanwen",
            "content": "hi ,\nOn solr 4.10.3,I have occasionally encountered this problem, when the Solr has just started, why there will be a lock already exist? Is bug\uff1fWas it a bug\uff1f\nDirectory.java\n  @Override\n  public String toString() {\n    return getClass().getSimpleName() + '@' + Integer.toHexString(hashCode()) + \" lockFactory=\" + getLockFactory();\n  }\n\n\nLOG as follow\uff1a\n\n\n2016-03-16 15:51:31,327 INFO org.apache.solr.servlet.SolrHadoopAuthenticationFilter: Connecting to ZooKeeper without authentication\n2016-03-16 15:51:31,434 INFO org.apache.curator.framework.imps.CuratorFrameworkImpl: Starting\n2016-03-16 15:51:31,445 INFO org.apache.zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.5-test5.4.2--1, built on 05/19/2015 23:53 GMT\n2016-03-16 15:51:31,445 INFO org.apache.zookeeper.ZooKeeper: Client environment:host.name=Impala03\n2016-03-16 15:51:31,445 INFO org.apache.zookeeper.ZooKeeper: Client environment:java.version=1.7.0_55\n2016-03-16 15:51:31,445 INFO org.apache.zookeeper.ZooKeeper: Client environment:java.vendor=Oracle Corporation\n2016-03-16 15:51:31,445 INFO org.apache.zookeeper.ZooKeeper: Client environment:java.home=/usr/java/jdk/jre\n2016-03-16 15:51:31,445 INFO org.apache.zookeeper.ZooKeeper: Client environment:java.class.path=/home/mr/tomcat/bin/bootstrap.jar\n2016-03-16 15:51:31,445 INFO org.apache.zookeeper.ZooKeeper: Client environment:java.library.path=/home/hdfs/hdfs/lib/native/Linux-amd64-64/\n2016-03-16 15:51:31,445 INFO org.apache.zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/var/lib/solr/\n2016-03-16 15:51:31,445 INFO org.apache.zookeeper.ZooKeeper: Client environment:java.compiler=<NA>\n2016-03-16 15:51:31,446 INFO org.apache.zookeeper.ZooKeeper: Client environment:os.name=Linux\n2016-03-16 15:51:31,446 INFO org.apache.zookeeper.ZooKeeper: Client environment:os.arch=amd64\n2016-03-16 15:51:31,446 INFO org.apache.zookeeper.ZooKeeper: Client environment:os.version=3.0.13-0.27-default\n2016-03-16 15:51:31,446 INFO org.apache.zookeeper.ZooKeeper: Client environment:user.name=mr\n2016-03-16 15:51:31,446 INFO org.apache.zookeeper.ZooKeeper: Client environment:user.home=/home/mr\n2016-03-16 15:51:31,446 INFO org.apache.zookeeper.ZooKeeper: Client environment:user.dir=/home/mr/solr/bin\n2016-03-16 15:51:31,447 INFO org.apache.zookeeper.ZooKeeper: Initiating client connection, connectString=Impala04:2181,Impala02:2181,Impala03:2181 sessionTimeout=60000 watcher=org.apache.curator.ConnectionState@2590f83a\n2016-03-16 15:51:31,472 INFO org.apache.zookeeper.ClientCnxn: Opening socket connection to server Impala03/10.233.85.238:2181. Will not attempt to authenticate using SASL (unknown error)\n2016-03-16 15:51:31,483 INFO org.apache.zookeeper.ClientCnxn: Socket connection established, initiating session, client: /10.233.85.238:42992, server: Impala03/10.233.85.238:2181\n2016-03-16 15:51:31,492 INFO org.apache.zookeeper.ClientCnxn: Session establishment complete on server Impala03/10.233.85.238:2181, sessionid = 0x35379cb0b604e1f, negotiated timeout = 60000\n2016-03-16 15:51:31,499 INFO org.apache.curator.framework.state.ConnectionStateManager: State change: CONNECTED\n2016-03-16 15:51:32,533 INFO org.apache.hadoop.security.authentication.util.ZKSignerSecretProvider: The secret znode already exists, retrieving data\n2016-03-16 15:51:33,392 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens\n2016-03-16 15:51:33,420 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)\n2016-03-16 15:51:33,536 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens\n2016-03-16 15:51:33,570 INFO org.apache.solr.servlet.SolrDispatchFilter: SolrDispatchFilter.init()\n2016-03-16 15:51:33,588 INFO org.apache.solr.core.SolrResourceLoader: No /solr/home in JNDI\n2016-03-16 15:51:33,588 INFO org.apache.solr.core.SolrResourceLoader: using system property solr.solr.home: /var/lib/solr/\n2016-03-16 15:51:33,588 INFO org.apache.solr.core.SolrResourceLoader: new SolrResourceLoader for directory: '/var/lib/solr/'\n2016-03-16 15:51:33,767 INFO org.apache.solr.servlet.SolrDispatchFilter: Trying to read solr.xml from Impala04:2181,Impala02:2181,Impala03:2181/solr\n2016-03-16 15:51:33,781 INFO org.apache.solr.common.cloud.SolrZkClient: Using default ZkCredentialsProvider\n2016-03-16 15:51:33,786 INFO org.apache.zookeeper.ZooKeeper: Initiating client connection, connectString=Impala04:2181,Impala02:2181,Impala03:2181/solr sessionTimeout=30000 watcher=org.apache.solr.common.cloud.ConnectionManager@5943d900\n2016-03-16 15:51:33,787 INFO org.apache.solr.common.cloud.ConnectionManager: Waiting for client to connect to ZooKeeper\n2016-03-16 15:51:33,787 INFO org.apache.zookeeper.ClientCnxn: Opening socket connection to server Impala03/10.233.85.238:2181. Will not attempt to authenticate using SASL (unknown error)\n2016-03-16 15:51:33,788 INFO org.apache.zookeeper.ClientCnxn: Socket connection established, initiating session, client: /10.233.85.238:42993, server: Impala03/10.233.85.238:2181\n2016-03-16 15:51:33,790 INFO org.apache.zookeeper.ClientCnxn: Session establishment complete on server Impala03/10.233.85.238:2181, sessionid = 0x35379cb0b604e20, negotiated timeout = 30000\n2016-03-16 15:51:33,790 INFO org.apache.solr.common.cloud.ConnectionManager: Watcher org.apache.solr.common.cloud.ConnectionManager@5943d900 name:ZooKeeperConnection Watcher:Impala04:2181,Impala02:2181,Impala03:2181/solr got event WatchedEvent state:SyncConnected type:None path:null path:null type:None\n2016-03-16 15:51:33,790 INFO org.apache.solr.common.cloud.ConnectionManager: Client is connected to ZooKeeper\n2016-03-16 15:51:33,790 INFO org.apache.solr.common.cloud.SolrZkClient: Using default ZkACLProvider\n2016-03-16 15:51:33,878 INFO org.apache.solr.core.CoresLocator: Config-defined core root directory: /var/lib/solr\n2016-03-16 15:51:33,880 INFO org.apache.zookeeper.ZooKeeper: Session: 0x35379cb0b604e20 closed\n2016-03-16 15:51:33,880 INFO org.apache.zookeeper.ClientCnxn: EventThread shut down\n2016-03-16 15:51:33,887 INFO org.apache.solr.core.CoreContainer: New CoreContainer 1881284549\n2016-03-16 15:51:33,887 INFO org.apache.solr.core.CoreContainer: Loading cores into CoreContainer [instanceDir=/var/lib/solr/]\n2016-03-16 15:51:33,887 INFO org.apache.solr.core.CoreContainer: Begin register HeartBeat\n2016-03-16 15:51:33,905 INFO org.apache.solr.handler.component.HttpShardHandlerFactory: Setting socketTimeout to: 0\n2016-03-16 15:51:33,906 INFO org.apache.solr.handler.component.HttpShardHandlerFactory: Setting urlScheme to: null\n2016-03-16 15:51:33,906 INFO org.apache.solr.handler.component.HttpShardHandlerFactory: Setting connTimeout to: 0\n2016-03-16 15:51:33,906 INFO org.apache.solr.handler.component.HttpShardHandlerFactory: Setting maxConnectionsPerHost to: 20\n2016-03-16 15:51:33,906 INFO org.apache.solr.handler.component.HttpShardHandlerFactory: Setting corePoolSize to: 0\n2016-03-16 15:51:33,906 INFO org.apache.solr.handler.component.HttpShardHandlerFactory: Setting maximumPoolSize to: 2147483647\n2016-03-16 15:51:33,906 INFO org.apache.solr.handler.component.HttpShardHandlerFactory: Setting maxThreadIdleTime to: 5\n2016-03-16 15:51:33,906 INFO org.apache.solr.handler.component.HttpShardHandlerFactory: Setting sizeOfQueue to: -1\n2016-03-16 15:51:33,906 INFO org.apache.solr.handler.component.HttpShardHandlerFactory: Setting fairnessPolicy to: false\n2016-03-16 15:51:33,906 INFO org.apache.solr.handler.component.HttpShardHandlerFactory: Setting useRetries to: false\n2016-03-16 15:51:34,022 INFO org.apache.solr.logging.LogWatcher: SLF4J impl is org.slf4j.impl.Log4jLoggerFactory\n2016-03-16 15:51:34,022 INFO org.apache.solr.logging.LogWatcher: Registering Log Listener [Log4j (org.slf4j.impl.Log4jLoggerFactory)]\n2016-03-16 15:51:34,023 INFO org.apache.solr.core.CoreContainer: Host Name: Impala03\n2016-03-16 15:51:34,024 INFO org.apache.solr.core.ZkContainer: Zookeeper client=Impala04:2181,Impala02:2181,Impala03:2181/solr\n2016-03-16 15:51:34,031 INFO org.apache.solr.cloud.ZkController: zkHost includes chroot\n2016-03-16 15:51:34,032 INFO org.apache.solr.common.cloud.SolrZkClient: Using default ZkCredentialsProvider\n2016-03-16 15:51:34,032 INFO org.apache.zookeeper.ZooKeeper: Initiating client connection, connectString=Impala04:2181,Impala02:2181,Impala03:2181 sessionTimeout=60000 watcher=org.apache.solr.common.cloud.ConnectionManager@23c93725\n2016-03-16 15:51:34,032 INFO org.apache.solr.common.cloud.ConnectionManager: Waiting for client to connect to ZooKeeper\n2016-03-16 15:51:34,033 INFO org.apache.zookeeper.ClientCnxn: Opening socket connection to server Impala02/10.233.85.237:2181. Will not attempt to authenticate using SASL (unknown error)\n2016-03-16 15:51:34,034 INFO org.apache.zookeeper.ClientCnxn: Socket connection established, initiating session, client: /10.233.85.238:45311, server: Impala02/10.233.85.237:2181\n2016-03-16 15:51:34,035 INFO org.apache.zookeeper.ClientCnxn: Session establishment complete on server Impala02/10.233.85.237:2181, sessionid = 0x25379cb085d4f3b, negotiated timeout = 60000\n2016-03-16 15:51:34,036 INFO org.apache.solr.common.cloud.ConnectionManager: Watcher org.apache.solr.common.cloud.ConnectionManager@23c93725 name:ZooKeeperConnection Watcher:Impala04:2181,Impala02:2181,Impala03:2181 got event WatchedEvent state:SyncConnected type:None path:null path:null type:None\n2016-03-16 15:51:34,036 INFO org.apache.solr.common.cloud.ConnectionManager: Client is connected to ZooKeeper\n2016-03-16 15:51:34,036 INFO org.apache.solr.common.cloud.SolrZkClient: Using default ZkACLProvider\n2016-03-16 15:51:34,038 INFO org.apache.zookeeper.ZooKeeper: Session: 0x25379cb085d4f3b closed\n2016-03-16 15:51:34,039 INFO org.apache.zookeeper.ClientCnxn: EventThread shut down\n2016-03-16 15:51:34,041 INFO org.apache.zookeeper.ZooKeeper: Initiating client connection, connectString=Impala04:2181,Impala02:2181,Impala03:2181/solr sessionTimeout=30000 watcher=org.apache.solr.common.cloud.ConnectionManager@3ef17aa1\n2016-03-16 15:51:34,041 INFO org.apache.solr.common.cloud.ConnectionManager: Waiting for client to connect to ZooKeeper\n2016-03-16 15:51:34,042 INFO org.apache.zookeeper.ClientCnxn: Opening socket connection to server Impala04/10.233.85.239:2181. Will not attempt to authenticate using SASL (unknown error)\n2016-03-16 15:51:34,042 INFO org.apache.zookeeper.ClientCnxn: Socket connection established, initiating session, client: /10.233.85.238:30675, server: Impala04/10.233.85.239:2181\n2016-03-16 15:51:34,045 INFO org.apache.zookeeper.ClientCnxn: Session establishment complete on server Impala04/10.233.85.239:2181, sessionid = 0x15379cb082a4e11, negotiated timeout = 30000\n2016-03-16 15:51:34,045 INFO org.apache.solr.common.cloud.ConnectionManager: Watcher org.apache.solr.common.cloud.ConnectionManager@3ef17aa1 name:ZooKeeperConnection Watcher:Impala04:2181,Impala02:2181,Impala03:2181/solr got event WatchedEvent state:SyncConnected type:None path:null path:null type:None\n2016-03-16 15:51:34,045 INFO org.apache.solr.common.cloud.ConnectionManager: Client is connected to ZooKeeper\n2016-03-16 15:51:34,076 INFO org.apache.solr.common.cloud.ZkStateReader: Updating cluster state from ZooKeeper... \n2016-03-16 15:51:34,114 INFO org.apache.solr.common.cloud.ZkStateReader: A cluster state change: WatchedEvent state:SyncConnected type:NodeDataChanged path:/clusterstate.json, has occurred - updating... (live nodes size: 3)\n2016-03-16 15:51:36,102 INFO org.apache.solr.cloud.ZkController: Register node as live in ZooKeeper:/live_nodes/Impala03:8983_solr\n2016-03-16 15:51:36,107 INFO org.apache.solr.common.cloud.SolrZkClient: makePath: /live_nodes/Impala03:8983_solr\n2016-03-16 15:51:36,113 INFO org.apache.solr.cloud.Overseer: Overseer (id=null) closing\n2016-03-16 15:51:36,139 INFO org.apache.solr.core.CoresLocator: Looking for core definitions underneath /var/lib/solr\n2016-03-16 15:51:36,150 INFO org.apache.solr.core.CoresLocator: Found core TESTX_shard2_replica1 in /var/lib/solr/TESTX_shard2_replica1/\n2016-03-16 15:51:36,151 INFO org.apache.solr.core.CoresLocator: Found 1 core definitions\n2016-03-16 15:51:36,157 INFO org.apache.solr.cloud.ZkController: publishing core=TESTX_shard2_replica1 state=down collection=TESTX\n2016-03-16 15:51:36,157 INFO org.apache.solr.cloud.ZkController: numShards not found on descriptor - reading it from system property\n2016-03-16 15:51:36,161 INFO org.apache.solr.cloud.ZkController: waiting to find shard id in clusterstate for TESTX_shard2_replica1\n2016-03-16 15:51:36,161 INFO org.apache.solr.cloud.ZkController: Check for collection zkNode:TESTX\n2016-03-16 15:51:36,162 INFO org.apache.solr.cloud.ZkController: Collection zkNode exists\n2016-03-16 15:51:36,162 INFO org.apache.solr.common.cloud.ZkStateReader: Load collection config from:/collections/TESTX\n2016-03-16 15:51:36,164 INFO org.apache.solr.common.cloud.ZkStateReader: path=/collections/TESTX configName=TESTX specified config exists in ZooKeeper\n2016-03-16 15:51:36,164 INFO org.apache.solr.core.SolrResourceLoader: new SolrResourceLoader for directory: '/var/lib/solr/TESTX_shard2_replica1/'\n2016-03-16 15:51:36,172 INFO org.apache.solr.common.cloud.ZkStateReader: A cluster state change: WatchedEvent state:SyncConnected type:NodeDataChanged path:/clusterstate.json, has occurred - updating... (live nodes size: 4)\n2016-03-16 15:51:36,242 INFO org.apache.solr.core.SolrConfig: Adding specified lib dirs to ClassLoader\n2016-03-16 15:51:36,243 WARN org.apache.solr.core.SolrResourceLoader: Can't find (or read) directory to add to classloader: ../../../contrib/extraction/lib (resolved as: /var/lib/solr/TESTX_shard2_replica1/../../../contrib/extraction/lib).\n2016-03-16 15:51:36,243 WARN org.apache.solr.core.SolrResourceLoader: Can't find (or read) directory to add to classloader: ../../../dist/ (resolved as: /var/lib/solr/TESTX_shard2_replica1/../../../dist).\n2016-03-16 15:51:36,243 WARN org.apache.solr.core.SolrResourceLoader: Can't find (or read) directory to add to classloader: ../../../contrib/clustering/lib/ (resolved as: /var/lib/solr/TESTX_shard2_replica1/../../../contrib/clustering/lib).\n2016-03-16 15:51:36,243 WARN org.apache.solr.core.SolrResourceLoader: Can't find (or read) directory to add to classloader: ../../../dist/ (resolved as: /var/lib/solr/TESTX_shard2_replica1/../../../dist).\n2016-03-16 15:51:36,243 WARN org.apache.solr.core.SolrResourceLoader: Can't find (or read) directory to add to classloader: ../../../contrib/langid/lib/ (resolved as: /var/lib/solr/TESTX_shard2_replica1/../../../contrib/langid/lib).\n2016-03-16 15:51:36,243 WARN org.apache.solr.core.SolrResourceLoader: Can't find (or read) directory to add to classloader: ../../../dist/ (resolved as: /var/lib/solr/TESTX_shard2_replica1/../../../dist).\n2016-03-16 15:51:36,243 WARN org.apache.solr.core.SolrResourceLoader: Can't find (or read) directory to add to classloader: ../../../contrib/velocity/lib (resolved as: /var/lib/solr/TESTX_shard2_replica1/../../../contrib/velocity/lib).\n2016-03-16 15:51:36,243 WARN org.apache.solr.core.SolrResourceLoader: Can't find (or read) directory to add to classloader: ../../../dist/ (resolved as: /var/lib/solr/TESTX_shard2_replica1/../../../dist).\n2016-03-16 15:51:36,374 INFO org.apache.solr.update.SolrIndexConfig: IndexWriter infoStream solr logging is enabled\n2016-03-16 15:51:36,382 INFO org.apache.solr.core.SolrConfig: Using Lucene MatchVersion: 4.10.3\n2016-03-16 15:51:36,493 INFO org.apache.solr.core.Config: Loaded SolrConfig: solrconfig.xml\n2016-03-16 15:51:36,505 INFO org.apache.solr.schema.IndexSchema: Reading Solr Schema from /configs/TESTX/managed-schema\n2016-03-16 15:51:36,571 INFO org.apache.solr.schema.IndexSchema: [TESTX_shard2_replica1] Schema name=example-schemaless\n2016-03-16 15:51:36,711 WARN org.apache.solr.core.SolrResourceLoader: Solr loaded a deprecated plugin/analysis class [solr.DateField]. Please consult documentation how to replace it accordingly.\n2016-03-16 15:51:36,716 WARN org.apache.solr.core.SolrResourceLoader: Solr loaded a deprecated plugin/analysis class [solr.DoubleField]. Please consult documentation how to replace it accordingly.\n2016-03-16 15:51:36,721 WARN org.apache.solr.core.SolrResourceLoader: Solr loaded a deprecated plugin/analysis class [solr.FloatField]. Please consult documentation how to replace it accordingly.\n2016-03-16 15:51:36,731 WARN org.apache.solr.core.SolrResourceLoader: Solr loaded a deprecated plugin/analysis class [solr.IntField]. Please consult documentation how to replace it accordingly.\n2016-03-16 15:51:36,735 WARN org.apache.solr.core.SolrResourceLoader: Solr loaded a deprecated plugin/analysis class [solr.LongField]. Please consult documentation how to replace it accordingly.\n2016-03-16 15:51:37,022 WARN org.apache.solr.core.SolrResourceLoader: Solr loaded a deprecated plugin/analysis class [solr.ThaiWordFilterFactory]. Please consult documentation how to replace it accordingly.\n2016-03-16 15:51:37,085 INFO org.apache.solr.schema.IndexSchema: unique key field: id\n2016-03-16 15:51:37,087 INFO org.apache.solr.schema.FileExchangeRateProvider: Reloading exchange rates from file currency.xml\n2016-03-16 15:51:37,096 INFO org.apache.solr.schema.FileExchangeRateProvider: Reloading exchange rates from file currency.xml\n2016-03-16 15:51:37,370 INFO org.apache.solr.core.CoreContainer: Creating SolrCore 'TESTX_shard2_replica1' using configuration from collection TESTX\n2016-03-16 15:51:37,400 INFO org.apache.solr.core.SolrCore: org.apache.solr.core.HdfsDirectoryFactory\n2016-03-16 15:51:37,410 INFO org.apache.solr.core.HdfsDirectoryFactory: solr.hdfs.home=hdfs://LV//solr\n2016-03-16 15:51:37,410 INFO org.apache.solr.core.HdfsDirectoryFactory: Solr Kerberos Authentication disabled\n2016-03-16 15:51:37,410 INFO org.apache.solr.core.SolrCore: [TESTX_shard2_replica1] Opening new SolrCore at /var/lib/solr/TESTX_shard2_replica1/, dataDir=hdfs://LV//solr/TESTX/core_node1/data/\n2016-03-16 15:51:37,412 INFO org.apache.solr.core.JmxMonitoredMap: JMX monitoring is enabled. Adding Solr mbeans to JMX Server: com.sun.jmx.mbeanserver.JmxMBeanServer@2cae38bd\n2016-03-16 15:51:37,444 INFO org.apache.solr.core.SolrCore: [TESTX_shard2_replica1] Added SolrEventListener for newSearcher: org.apache.solr.core.QuerySenderListener{queries=[]}\n2016-03-16 15:51:37,444 INFO org.apache.solr.core.SolrCore: [TESTX_shard2_replica1] Added SolrEventListener for firstSearcher: org.apache.solr.core.QuerySenderListener{queries=[]}\n2016-03-16 15:51:37,455 INFO org.apache.solr.core.HdfsDirectoryFactory: creating directory factory for path hdfs://LV//solr/TESTX/core_node1/data\n2016-03-16 15:51:38,259 INFO org.apache.solr.core.CachingDirectoryFactory: return new directory for hdfs://LV//solr/TESTX/core_node1/data\n2016-03-16 15:51:38,262 INFO org.apache.solr.core.SolrCore: New index directory detected: old=null new=hdfs://LV//solr/TESTX/core_node1/data/index/\n2016-03-16 15:51:38,297 INFO org.apache.solr.core.HdfsDirectoryFactory: creating directory factory for path hdfs://LV//solr/TESTX/core_node1/data/index\n2016-03-16 15:51:38,327 INFO org.apache.solr.core.HdfsDirectoryFactory: Number of slabs of block cache [1] with direct memory allocation set to [true]\n2016-03-16 15:51:38,327 INFO org.apache.solr.core.HdfsDirectoryFactory: Block cache target memory usage, slab size of [134217728] will allocate [1] slabs and use ~[134217728] bytes\n2016-03-16 15:51:38,327 INFO org.apache.solr.core.HdfsDirectoryFactory: Creating new global HDFS BlockCache\n2016-03-16 15:51:38,381 INFO org.apache.solr.store.blockcache.BlockDirectory: Block cache on write is disabled\n2016-03-16 15:51:38,381 INFO org.apache.solr.core.CachingDirectoryFactory: return new directory for hdfs://LV//solr/TESTX/core_node1/data/index\n2016-03-16 15:51:38,395 ERROR org.apache.solr.core.SolrCore: [TESTX_shard2_replica1] Solr index directory 'hdfs://LV//solr/TESTX/core_node1/data/index/' is locked.  Throwing exception\n2016-03-16 15:51:38,395 INFO org.apache.solr.core.SolrCore: [TESTX_shard2_replica1]  CLOSING SolrCore org.apache.solr.core.SolrCore@cadc90b\n2016-03-16 15:51:38,395 INFO org.apache.solr.update.SolrCoreState: Closing SolrCoreState\n2016-03-16 15:51:38,395 INFO org.apache.solr.update.DefaultSolrCoreState: SolrCoreState ref count has reached 0 - closing IndexWriter\n2016-03-16 15:51:38,395 INFO org.apache.solr.core.SolrCore: [TESTX_shard2_replica1] Closing main searcher on request.\n2016-03-16 15:51:38,398 INFO org.apache.solr.core.CachingDirectoryFactory: Closing HdfsDirectoryFactory - 2 directories currently being tracked\n2016-03-16 15:51:38,398 INFO org.apache.solr.core.CachingDirectoryFactory: looking to close hdfs://LV//solr/TESTX/core_node1/data [CachedDir<<refCount=0;path=hdfs://LV//solr/TESTX/core_node1/data;done=false>>]\n2016-03-16 15:51:38,398 INFO org.apache.solr.core.CachingDirectoryFactory: Closing directory: hdfs://LV//solr/TESTX/core_node1/data\n2016-03-16 15:51:38,398 INFO org.apache.solr.store.hdfs.HdfsDirectory: Closing hdfs directory hdfs://LV/solr/TESTX/core_node1/data\n2016-03-16 15:51:38,398 INFO org.apache.solr.core.CachingDirectoryFactory: looking to close hdfs://LV//solr/TESTX/core_node1/data/index [CachedDir<<refCount=0;path=hdfs://LV//solr/TESTX/core_node1/data/index;done=false>>]\n2016-03-16 15:51:38,398 INFO org.apache.solr.core.CachingDirectoryFactory: Closing directory: hdfs://LV//solr/TESTX/core_node1/data/index\n2016-03-16 15:51:38,519 INFO org.apache.solr.store.hdfs.HdfsDirectory: Closing hdfs directory hdfs://LV/solr/TESTX/core_node1/data/index\n2016-03-16 15:51:38,622 ERROR org.apache.solr.core.CoreContainer: Error creating core [TESTX_shard2_replica1]: Index locked for write for core TESTX_shard2_replica1\norg.apache.solr.common.SolrException: Index locked for write for core TESTX_shard2_replica1\n\tat org.apache.solr.core.SolrCore.<init>(SolrCore.java:884)\n\tat org.apache.solr.core.SolrCore.<init>(SolrCore.java:657)\n\tat org.apache.solr.core.CoreContainer.create(CoreContainer.java:496)\n\tat org.apache.solr.core.CoreContainer$1.call(CoreContainer.java:260)\n\tat org.apache.solr.core.CoreContainer$1.call(CoreContainer.java:254)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: org.apache.lucene.store.LockObtainFailedException: Index locked for write for core TESTX_shard2_replica1\n\tat org.apache.solr.core.SolrCore.initIndex(SolrCore.java:519)\n\tat org.apache.solr.core.SolrCore.<init>(SolrCore.java:788)\n\t... 8 more\n2016-03-16 15:51:38,627 INFO org.apache.solr.servlet.SolrDispatchFilter: user.dir=/home/mr/solr/bin\n2016-03-16 15:51:38,627 INFO org.apache.solr.servlet.SolrDispatchFilter: SolrDispatchFilter.init() done\n\n\n ",
            "id": "comment-15202567"
        },
        {
            "date": "2016-04-21T16:00:57+0000",
            "author": "Mark Miller",
            "content": "SOLR-8169 aims to solve that problem for HDFS users by exploring the option of the lock being in ZooKeeper.\n\nI wonder if we should ditch the lock entirely for hdfs and count on 'write once' and hfds file write leases for protection. I think it's hard to get the behavior we want with an hdfs or zk based lock impl. ",
            "id": "comment-15252104"
        },
        {
            "date": "2016-07-26T19:15:36+0000",
            "author": "Hrishikesh Gadre",
            "content": "Mark Miller Varun Thacker I wonder if we can utilize deleteOnExit functionality in HDFS.\n\nhttps://hadoop.apache.org/docs/r2.6.1/api/org/apache/hadoop/fs/FileSystem.html#deleteOnExit(org.apache.hadoop.fs.Path) ",
            "id": "comment-15394366"
        },
        {
            "date": "2016-11-08T03:22:48+0000",
            "author": "hu xiaodong",
            "content": "In solr cloud mode ,can I use solr.lock.type=none instead of  solr.lock.type=hdfs? ",
            "id": "comment-15646335"
        },
        {
            "date": "2016-11-08T15:54:57+0000",
            "author": "Erick Erickson",
            "content": "When asking usage questions you'll get more people seeing the question and (probably) far faster response if you ask questions like this on the user's list. We try to reserve JIRAs for discussing code issues. See the \"mailing lists\" section here: http://lucene.apache.org/solr/resources.html\n ",
            "id": "comment-15647930"
        },
        {
            "date": "2017-09-07T13:38:24+0000",
            "author": "Mihaly Toth",
            "content": "As I see this was given up to be fixed, but I believe this is doable and is actually needed for a proper auto add replica functionality. The implementation is based on giving the lock a timeout, after which it can be taken over (deleted). It is also guarded against concurrent takeovers.\n\nI have not yet created a pull request, because I am not sure how to handle the situation when the lock is lost. Shall we eventually unload the core that opened the SolrIndexWriter? If I introduce a lock lost callback for every obtain the change spreads through the code quite widely.\n\nHere is what I have done so far:\nhttps://github.com/mihalytoth/lucene-solr/tree/master_hdfs_lock\n\nWhat about reopening (and then fixing) this Jira? ",
            "id": "comment-16156960"
        },
        {
            "date": "2017-09-14T14:40:40+0000",
            "author": "Mihaly Toth",
            "content": "Attaching the proposal. 2 further notes beside my comments above:\n\n\tIf lock is lost (taken over by newly started node while this node was unable to update it) LockValidatingDirectoryWrapper already solves potential problems by calling HdfsLock.ensureValid() function\n\tThis is an alternative to zookeeper based locking. This lock is available exactly under the same conditions as the file to be written.\n\n\n\nThe changes are also available under my clone's branch ",
            "id": "comment-16166380"
        },
        {
            "date": "2018-09-21T18:35:41+0000",
            "author": "Yonik Seeley",
            "content": "OK, so for this attached patch, it looks like keeping the lock requires touching it periodically (like a lease).\nI'm not enough of an expert on HDFS intricacies to know if this is the best approach, but this patch has gone a year w/ no feedback.  Anyone have anything to add around if this is the right approach or not?\n\n It's probably best not to introduce new dependencies (hamcrest) along with a patch unless they are really necessary though. ",
            "id": "comment-16624023"
        },
        {
            "date": "2018-09-27T09:26:21+0000",
            "author": "Mano Kovacs",
            "content": "If Mihaly Toth does not mind, I will take on the remaining work regarding this patch. I rebased the patch and opened a PR. I will remove the hamcrest dependency too. ",
            "id": "comment-16630042"
        },
        {
            "date": "2018-09-27T10:57:47+0000",
            "author": "Mihaly Toth",
            "content": "Thanks, Mano Kovacs. Sure, please take it over. ",
            "id": "comment-16630198"
        },
        {
            "date": "2018-09-28T10:59:58+0000",
            "author": "Mano Kovacs",
            "content": "I removed hamcrest from the patch. If I could get a review, that would be greatly appreciated: https://github.com/apache/lucene-solr/pull/459 ",
            "id": "comment-16631699"
        },
        {
            "date": "2018-10-16T06:53:56+0000",
            "author": "Mano Kovacs",
            "content": "Review would be greatly appreciated!\nhttps://github.com/apache/lucene-solr/pull/471 ",
            "id": "comment-16651234"
        },
        {
            "date": "2018-10-25T09:14:21+0000",
            "author": "Mano Kovacs",
            "content": "Varun Thacker, Mark Miller, could you help me reviewing this jira? Thank you in advance. ",
            "id": "comment-16663474"
        }
    ]
}