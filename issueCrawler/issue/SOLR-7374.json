{
    "id": "SOLR-7374",
    "title": "Backup/Restore should provide a param for specifying the directory implementation it should use",
    "details": {
        "components": [],
        "type": "Bug",
        "labels": "",
        "fix_versions": [
            "6.2"
        ],
        "affect_versions": "None",
        "status": "Closed",
        "resolution": "Fixed",
        "priority": "Major"
    },
    "description": "Currently when we create a backup we use SimpleFSDirectory to write the backup indexes. Similarly during a restore we open the index using FSDirectory.open . \n\nWe should provide a param called directoryImpl or type which will be used to specify the Directory implementation to backup the index. \nLikewise during a restore you would need to specify the directory impl which was used during backup so that the index can be opened correctly.\n\nThis param will address the problem that currently if a user is running Solr on HDFS there is no way to use the backup/restore functionality as the directory is hardcoded.\n\nWith this one could be running Solr on a local FS but backup the index on HDFS etc.",
    "attachments": {
        "SOLR-7374.patch": "https://issues.apache.org/jira/secure/attachment/12803571/SOLR-7374.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2015-04-13T20:20:41+0000",
            "author": "Jan H\u00f8ydahl",
            "content": "Looking forward to a collection backup command, we can imagine a cluster wide set of Directory configurations, such as an S3Directory configured with API keys etc. So should be letting each core/shard backup/restore command be able to write/read the backup directly to/from such cluster-wide locations. One way could be to support protocol and config in the location attribute, e.g. s3:/backups/collection1/shard1. Would make it super simple for Overseer to kick off a bunch of backup jobs across a cluster and let each shard write directly to correct target instead of intermediate local stoage. No idea of how to configure cluster-wide Directory configs though. ",
            "id": "comment-14493005"
        },
        {
            "date": "2016-03-22T23:25:53+0000",
            "author": "Hrishikesh Gadre",
            "content": "Varun Thacker are you still working on this? If not, I would like to take a crack at it... ",
            "id": "comment-15207510"
        },
        {
            "date": "2016-03-24T22:50:26+0000",
            "author": "Varun Thacker",
            "content": "Hi Hrishikesh,\n\nPlease feel free to work on it. I've not got time to even look back at this issue unfortunately.\n\nI'll be glad to review if you work on a patch though ",
            "id": "comment-15211093"
        },
        {
            "date": "2016-03-24T23:49:52+0000",
            "author": "Hrishikesh Gadre",
            "content": "Varun Thacker Sure. I think at the high-level we can expose API to configure Directory configurations for storing snapshots (e.g. local filesystem, HDFS, S3 etc.). As part of the implementation, we can store this config to ZK. Once this mechanism in place, we can pass appropriate directory configuration during the backup command execution. Does this make sense?\n\nCC  David Smiley (who is also interested in SOLR-5750) ",
            "id": "comment-15211148"
        },
        {
            "date": "2016-04-06T18:53:49+0000",
            "author": "David Smiley",
            "content": "+1 to a specifying protocol/impl as a prefix.  Presumably there would need to then be a way to register them and look them up. ",
            "id": "comment-15228886"
        },
        {
            "date": "2016-05-12T04:35:36+0000",
            "author": "Hrishikesh Gadre",
            "content": "Please find the patch attached. It includes following\n\n\n\tA backup repository interface and concrete implementations for local file-system and HDFS\n\tAbility to configure repositories via solr.xml\n\tRefactored the \"core\" level backup/restore to use this repository interface\n\tUnit test for HDFS integration.\n\n ",
            "id": "comment-15281198"
        },
        {
            "date": "2016-05-13T00:23:20+0000",
            "author": "Hrishikesh Gadre",
            "content": "Updated patch (includes couple of bug fixes). ",
            "id": "comment-15282280"
        },
        {
            "date": "2016-05-19T22:29:17+0000",
            "author": "Tom\u00e1s Fern\u00e1ndez L\u00f6bbe",
            "content": "I came to this issue following the discussion in SOLR-9055. I really like this patch. It should also allow future improvements (like making the backups incremental) and since it's really low level most of the logic is in the SnapShooter can be shared no matter what storage system is used. \n\nSmall comment. There seems to be a bug in BackupRepositoryFactory\nBackupRepositoryFactory.java\nif (isDefault && (this.defaultBackupRepoPlugin != null)) {\n    if (this.defaultBackupRepoPlugin != null) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"More than one backup repository is configured as default\");\n    }\n    this.defaultBackupRepoPlugin = backupRepoPlugins[i];\n}\n\n\nSome improvements to TestSolrXml could catch this?\nI'd also add some more logging to this class, like logging.info(\"Adding BackupRepositoryFactory foo\");. Configuration is pretty open to mistakes that are difficult to track. ",
            "id": "comment-15292265"
        },
        {
            "date": "2016-05-20T02:11:15+0000",
            "author": "Hrishikesh Gadre",
            "content": "Tom\u00e1s Fern\u00e1ndez L\u00f6bbe Thanks for the review. Let me submit an updated patch with your comments. ",
            "id": "comment-15292559"
        },
        {
            "date": "2016-05-23T01:52:34+0000",
            "author": "Hrishikesh Gadre",
            "content": "Here is an updated patch which addresses the review comments from Tom\u00e1s Fern\u00e1ndez L\u00f6bbe  ",
            "id": "comment-15295832"
        },
        {
            "date": "2016-05-26T17:23:19+0000",
            "author": "Mark Miller",
            "content": "Where are we at here? I'd really like to get this in so that SOLR-9055 can also be wrapped up. What do you think @varunthacker1989  ",
            "id": "comment-15302519"
        },
        {
            "date": "2016-05-31T16:05:08+0000",
            "author": "Hrishikesh Gadre",
            "content": "Varun Thacker could you please review the patch? ",
            "id": "comment-15307998"
        },
        {
            "date": "2016-06-02T17:48:25+0000",
            "author": "Mark Miller",
            "content": "I'm going to steal this issue  ",
            "id": "comment-15312753"
        },
        {
            "date": "2016-06-06T17:42:29+0000",
            "author": "Mark Miller",
            "content": "I'm try to pinpoint if this has destabilized TestReplicationHandlerBackup or if it was before. Otherwise this is looking pretty good, just want to do a little manual testing. Anything else would be nitpicky mostly, but perhaps more comments coming. ",
            "id": "comment-15316839"
        },
        {
            "date": "2016-06-09T22:15:17+0000",
            "author": "Hrishikesh Gadre",
            "content": "Mark Miller Let me know if you need anything from my side. If you could post the test params (for failure), I can take a look. ",
            "id": "comment-15323481"
        },
        {
            "date": "2016-06-10T18:39:29+0000",
            "author": "Hrishikesh Gadre",
            "content": "Mark Miller Please find the updated patch which resolves the TestReplicationHandlerBackup failure. ",
            "id": "comment-15325052"
        },
        {
            "date": "2016-06-14T11:22:44+0000",
            "author": "Mark Miller",
            "content": "Thanks, I'm pretty much ready with this.\n\nOne comment: Shouldn't we make BackupRepository an abstract class rather than interface? We can only add default methods in Java 8, but branch6x is still Java 7 right? Backcompat will be easier with abstract for now I think. ",
            "id": "comment-15329338"
        },
        {
            "date": "2016-06-14T13:41:02+0000",
            "author": "Mark Miller",
            "content": "Just found the follow fail. Does not seem to be repeatable by seed, must be timing or something.\n\n   [junit4] ERROR   0.72s J4  | TestReplicationHandlerBackup.doTestBackup <<<\n   [junit4]    > Throwable #1: java.util.NoSuchElementException\n   [junit4]    > \tat __randomizedtesting.SeedInfo.seed([2234E0A12F864773:63BFC0C40838B43C]:0)\n   [junit4]    > \tat sun.nio.fs.UnixDirectoryStream$UnixDirectoryIterator.next(UnixDirectoryStream.java:215)\n   [junit4]    > \tat sun.nio.fs.UnixDirectoryStream$UnixDirectoryIterator.next(UnixDirectoryStream.java:132)\n   [junit4]    > \tat org.apache.solr.handler.TestReplicationHandlerBackup.doTestBackup(TestReplicationHandlerBackup.java:174)\n   [junit4]    > \tat java.lang.Thread.run(Thread.java:745)\n   [junit4]   2> 563888 INFO  (SUITE-TestReplicationHandlerBackup-seed#[2234E0A12F864773]-worker) [    ] o.a.s.SolrTestCaseJ4 ###deleteCore\n\n   NOTE: reproduce with: ant test  -Dtestcase=TestReplicationHandlerBackup -Dtests.method=doTestBackup -Dtests.seed=2234E0A12F864773 -Dtests.slow=true -Dtests.locale=sk -Dtests.timezone=Asia/Calcutta -Dtests.asserts=true -Dtests.file.encoding=US-ASCII ",
            "id": "comment-15329512"
        },
        {
            "date": "2016-06-14T14:06:52+0000",
            "author": "David Smiley",
            "content": "One comment: Shouldn't we make BackupRepository an abstract class rather than interface? We can only add default methods in Java 8, but branch6x is still Java 7 right?\n\nNo; we're all Java 8 now \u2013 master & 6x.  You must be thinking of 5x which was Java 7. ",
            "id": "comment-15329554"
        },
        {
            "date": "2016-06-14T15:35:17+0000",
            "author": "Mark Miller",
            "content": "Looks like for the test fail we may just have to check the backup status and wait in a spot we are not. ",
            "id": "comment-15329679"
        },
        {
            "date": "2016-06-14T15:51:33+0000",
            "author": "Hrishikesh Gadre",
            "content": "Looking into this... ",
            "id": "comment-15329707"
        },
        {
            "date": "2016-06-15T15:07:39+0000",
            "author": "Varun Thacker",
            "content": "Hi Hrishikesh,\n\nPatch is looking good! \n\nHere are my main two concerns \n\nI think we need to deal with the \"location\" param better. Before this patch we used to read location as a query param . If the query param is empty then we read it from the cluster property. \nWith this patch we are adding the ability to specify \"location\" in the solr.xml file but it will never be used? CollectionsHandler will bail out early today .\n\n\n        String location = req.getParams().get(\"location\");\n        if (location == null) {\n          location = h.coreContainer.getZkController().getZkStateReader().getClusterProperty(\"location\", (String) null);\n        }\n        if (location == null) {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"'location' is not specified as a query parameter or set as a cluster property\");\n        }\n\n\n\nOne approach would be to deprecate the usage of cluster prop and look at query param followed by solr.xml ? Looking at three places seems messy . \n\nrepo is the key used to specify the implementation. In Solr xml the tag is called repository . Should we just use repository throughout?\n\nSmall changes:\n\n\tJavadocs for BackupRepository - s/index/indexes\n\tI think we should follow the if (condition) spacing convention ? Some of the places don't have spaceIn and some do.\n\tIn BackupRepositoryFactory : In these two log log lines can we mention the name as well - LOG.info(\"Default configuration for backup repository is with configuration params {}\", defaultBackupRepoPlugin); and LOG.info(\"Added backup repository with configuration params {}\", backupRepoPlugins[i]);\n\tCan we reuse the \"location\" string with (BackupRepository.DEFAULT_LOCATION_PROPERTY) on line 871/925 of CoreAdminOperation? Let's fix it in CollectionsHandler and OverseerCollectionMessageHandler as well?\n\tIn RestoreCore do we need to deprecate the old RestoreCore ctor ? Any reason why we can't remove it directly?\n\n ",
            "id": "comment-15331892"
        },
        {
            "date": "2016-06-15T15:12:57+0000",
            "author": "Mark Miller",
            "content": "I have the following changes already in my local copy:\n\n\n\tfixed formatting\n\tuse BackupRepository.DEFAULT_LOCATION_PROPERTY\n\n\n\nLet me take a look at the location param in solr.xml issue. ",
            "id": "comment-15331898"
        },
        {
            "date": "2016-06-15T15:59:29+0000",
            "author": "Mark Miller",
            "content": "\"location\" in the solr.xml \n\nThe baseLocation in the test solr.xml files just looks like dev cruft to me. ",
            "id": "comment-15331958"
        },
        {
            "date": "2016-06-15T16:22:22+0000",
            "author": "Mark Miller",
            "content": "New patch. ",
            "id": "comment-15332011"
        },
        {
            "date": "2016-06-15T16:29:39+0000",
            "author": "Mark Miller",
            "content": "deprecate the usage of cluster prop and look at query param followed by solr.xml \n\nIt is a bit odd to have some config in solr.xml and then default location as a cluster prop, but much nicer to be able to easily change the default location on the fly. solr.xml is a pain to change and requires a restart. ",
            "id": "comment-15332029"
        },
        {
            "date": "2016-06-15T18:41:20+0000",
            "author": "Hrishikesh Gadre",
            "content": "Varun Thacker Mark Miller Thanks for the comments!\n\nI think we need to deal with the \"location\" param better. Before this patch we used to read location as a query param . If the query param is empty then we read it from the cluster property. \n\nWith this patch we are adding the ability to specify \"location\" in the solr.xml file but it will never be used? CollectionsHandler will bail out early today .\n\nThis is a partial patch handling ONLY core level changes. The collection level changes are being captured in the patch for SOLR-9055. I did this to keep the patch relatively short and easier to review. In the patch for SOLR-9055 - I have changed the CollectionsHandler implementation to read default location from solr.xml (instead of cluster property). Since this core level operation is \"internal\" - technically we don't have to handle the case for missing \"location\" param in this patch (i.e. we can keep the original behavior). I think I made this change to simplify unit testing.\n\nOne approach would be to deprecate the usage of cluster prop and look at query param followed by solr.xml ? Looking at three places seems messy .\n[Mark] It is a bit odd to have some config in solr.xml and then default location as a cluster prop, but much nicer to be able to easily change the default location on the fly. solr.xml is a pain to change and requires a restart.\n\nI agree that cluster property approach is more convenient as compared to solr.xml. But since we allow users to configure multiple repositories in solr.xml, we can not really use the current cluster property as is. This is because user may want to specify different location for different file-systems (or repositories). Hence at minimum we need one cluster property per repository configuration (e.g. name could be <repository-name>-location). But based on my understanding CLUSTERPROP API implementation requires fixed (or well-known) property names,\n\nhttps://github.com/apache/lucene-solr/blob/651499c82df482b493b0ed166c2ab7196af0a794/solr/solrj/src/java/org/apache/solr/common/cloud/ClusterProperties.java#L90\n\nWe may have to relax this restriction for this work. On the other hand, specifying default location in solr.xml is not so bad since user can always specify a location parameter to avoid restarting the Solr cluster. Thoughts?\n\nCan we reuse the \"location\" string with (BackupRepository.DEFAULT_LOCATION_PROPERTY) on line 871/925 of CoreAdminOperation? Let's fix it in CollectionsHandler and OverseerCollectionMessageHandler as well?\n\nLet me fix the CoreAdminOperation in this patch. I will defer the collection level changes to SOLR-9055.\n\nIn RestoreCore do we need to deprecate the old RestoreCore ctor ? Any reason why we can't remove it directly?\n\nThe deprecated constructor is used by the ReplicationHandler. The new constructor expects the BackupRepository reference which can be obtained only via CoreContainer. I couldn't find a way to get hold of CoreContainer in ReplicationHandler. Hence I didn't remove this constructor.\n\nrepo is the key used to specify the implementation. In Solr xml the tag is called repository . Should we just use repository throughout?\n\nSure that make sense. Let me fix this.\n\n ",
            "id": "comment-15332291"
        },
        {
            "date": "2016-06-15T20:03:46+0000",
            "author": "Hrishikesh Gadre",
            "content": "Mark Miller Here is an updated patch.\n\n\n\tFixed trailing white-spaces\n\tRemoved unused and deprecated constructor from RestoreCore\n\tRenamed constant referring to \"location\" property in BackupRepository interface.\n\n\n\nAll the other review comments were already incorporated in your earlier patch. ",
            "id": "comment-15332447"
        },
        {
            "date": "2016-06-16T10:33:50+0000",
            "author": "Varun Thacker",
            "content": "Hi Hrishikesh,\n\nThanks for the updated patch! Looks good\n\nWhile reviewing it I didn't understand one thing -\n\nIn ReplicationHandler#restore why are we always using LocalFileSystemRepository and not reading any repository param? \nCurrently to backup/restore in standalone mode we use the replication handler ( https://cwiki.apache.org/confluence/display/solr/Making+and+Restoring+Backups+of+SolrCores ) . I think we should read the repository param and initialize accordingly.\n\nThe backup/restore operation that is in CoreAdminOperation was added as part of SOLR-5750 for the Overseer to be able to call backup/restore on individual cores.\n\n\nI don't think this set of comments is entirely true. The first version of backup which had been there for ages allowed an empty location param and resorted to the cores data directory. It had nothing to do with shared file systems . The back compat part is true though.\n\n\n    // Note - This logic is only applicable to the usecase where a shared file-system is exposed via\n    // local file-system interface (primarily for backwards compatibility). For other use-cases, users\n    // will be required to specify \"location\" where the backup should be stored.\n\n\n\nLastly you mentioned this in a previous comment \nThis is a partial patch handling ONLY core level changes. The collection level changes are being captured in the patch for SOLR-9055. \n\nHowever TestHdfsBackupRestore  added in this patch is a solr cloud test . What other work is left for supporting collection level changes? \nI only briefly looked at SOLR-9055 and couldn't tell why we need ShardRequestProcessor  etc. \nI would think the only work required would be in CollectionsHandler to deal with \"location\" , in OverseerCollectionMessageHandler the part where we read/write the meta information and ZK configs? ",
            "id": "comment-15333537"
        },
        {
            "date": "2016-06-16T11:29:02+0000",
            "author": "Varun Thacker",
            "content": "Also i found ZkStateReader#BACKUP_LOCATION constant. We should merge those two constants I guess ",
            "id": "comment-15333604"
        },
        {
            "date": "2016-06-16T17:21:24+0000",
            "author": "Hrishikesh Gadre",
            "content": "Varun Thacker Thanks for the comments.\n\nIn ReplicationHandler#restore why are we always using LocalFileSystemRepository and not reading any repository param? \n\nThe reason is that ReplicationHandler is not configured with the CoreContainer (which is required to fetch the repository configuration). Also building two parallel implementations for the same functionality doesn't quite make sense. Can we instead make the Core level Backup/Restore APIs public (i.e. not limited to Solrcloud)? This allows users to keep using ReplicationHandler in case of local file-system but if they need to integrate with other file-systems they can move to these core level APIs. If feasible, we can even deprecate (and remove) backup/restore APIs from ReplicationHandler in future.\n\nHowever TestHdfsBackupRestore added in this patch is a solr cloud test . What other work is left for supporting collection level changes? \n\nI had to implement this test as a \"cloud\" test so as to enable testing these core level operations (since these operations are enabled only in the cloud mode). The collection-level changes include,\n\n\tBackup/restore collection metadata\n\tCheck the version compatibility during restore\n\tStrategy interface to define \"how\" backup operation is performed (e.g. copying the index files vs. a file-system snapshot etc.)\n\n\n\nI only briefly looked at SOLR-9055 and couldn't tell why we need ShardRequestProcessor etc. \n\nThe main reason is to implement a index backup strategy. Also in general processing shard requests is such a common functionality that embedding it in the OverseerCollectionMessageHandler doesn't quite seem right (from modularity perspective).\n\nAlso i found ZkStateReader#BACKUP_LOCATION constant. We should merge those two constants I guess\n\nMake sense. Let me do that.\n ",
            "id": "comment-15334207"
        },
        {
            "date": "2016-06-16T17:33:14+0000",
            "author": "Varun Thacker",
            "content": "Also building two parallel implementations for the same functionality doesn't quite make sense.\n\nIndeed . It's far from ideal right now. We document the core level backup/restore via the replication handler as thats where it was supported . \n\nWith SOLR-5750 a hook to Core Admin to leverage it . It was simply for convenience and not meant to be made public. Maybe we should fix it leverage the ReplicationHandler instead . Or we could deprecate the usage via Replication Handler as it's more of a core admin operation anyways.\n\nBut I think let's keep that to a separate Jira/discussion? For the scope of this Jira can we just support it in ReplicationHandler as well ? ",
            "id": "comment-15334233"
        },
        {
            "date": "2016-06-16T23:10:09+0000",
            "author": "Hrishikesh Gadre",
            "content": "For the scope of this Jira can we just support it in ReplicationHandler as well ?\n\nSure I am working on this. It looks like we may not be able to provide identical behavior w.r.t. core level backup/restore API. \nSpecifically when user does not specify \"location\" parameter, the existing ReplicationHandler implementation uses a directory relative to the \"data\" directory. e.g.\nhttps://github.com/apache/lucene-solr/blob/a4455a4b14f2bf947db1136f9d5fc7d0d88d32ef/solr/core/src/java/org/apache/solr/handler/ReplicationHandler.java#L419\nhttps://github.com/apache/lucene-solr/blob/a4455a4b14f2bf947db1136f9d5fc7d0d88d32ef/solr/core/src/java/org/apache/solr/handler/SnapShooter.java#L67\n\nWhile this logic is OK on a local file-system, it would not work if user is using a different file-system for backup/restore. e.g. consider a case when a user configures HDFS repository without a default location (and using local file-system for storing index files). \n\nNote - when only a single repository is configured, we use it as a \"default\".  Now consider a case when a user invokes backup/restore without specifying \"location\" and \"repository\" parameters, we don't want to use the \"data\" directory as the location since it may not be valid on HDFS. So I am adding a constraint that if \"repository\" parameter is specified then location must be specified either via \"location\" parameter OR via a repository configuration in solr.xml\n\nWhen \"repository\" parameter is not specified, we default to \"LocalFileSystem\" instead of configured default repository in solr.xml. This is to handle the use-case mentioned above. It also helps to maintain the backwards compatibility with the existing API behavior. \n\nOn the other hand the Core level BACKUP API always fetches the \"default\" repository configuration from solr.xml and require that location be specified either via \"location\" parameter OR via a repository configuration. I hope this small difference in API behavior should be OK (since we should aim to retire one of the APIs). ",
            "id": "comment-15334905"
        },
        {
            "date": "2016-06-16T23:41:44+0000",
            "author": "Hrishikesh Gadre",
            "content": "For the scope of this Jira can we just support it in ReplicationHandler as well ?\n\nIt looks like we are also creating a snapshot as part of post commit/optimize operation. Not sure which repository should we use for this? Would this require adding another config param to ReplicationHandler?\n\nhttps://github.com/apache/lucene-solr/blob/a4455a4b14f2bf947db1136f9d5fc7d0d88d32ef/solr/core/src/java/org/apache/solr/handler/ReplicationHandler.java#L1324\n\n ",
            "id": "comment-15334985"
        },
        {
            "date": "2016-06-17T16:36:27+0000",
            "author": "Hrishikesh Gadre",
            "content": "Varun Thacker OK I think I have addressed all the review comments. Could you please take a look? ",
            "id": "comment-15336417"
        },
        {
            "date": "2016-06-20T11:57:44+0000",
            "author": "Varun Thacker",
            "content": "Changes look good!\n\nIt looks like we are also creating a snapshot as part of post commit/optimize operation. Not sure which repository should we use for this? Would this require adding another config param to ReplicationHandler?\n\nLet's stick to the current model of reading from the solr.xml file and defaulting to local if its not defined ? ",
            "id": "comment-15339387"
        },
        {
            "date": "2016-06-20T15:22:23+0000",
            "author": "Mark Miller",
            "content": "Varun Thacker, do you want to take this back for the commit now that you're back from vacation?  ",
            "id": "comment-15339700"
        },
        {
            "date": "2016-06-20T17:27:28+0000",
            "author": "Hrishikesh Gadre",
            "content": "Varun Thacker\n\nLet's stick to the current model of reading from the solr.xml file and defaulting to local if its not defined ?\n\nI am not sure if you realize the problem here. This is the code snippet that I am wondering about,\nhttps://github.com/apache/lucene-solr/blob/a4455a4b14f2bf947db1136f9d5fc7d0d88d32ef/solr/core/src/java/org/apache/solr/handler/ReplicationHandler.java#L1324\n\nThis particular code is invoked as a callback (and not directly as part of handling a user request). \nhttps://github.com/apache/lucene-solr/blob/a4455a4b14f2bf947db1136f9d5fc7d0d88d32ef/solr/core/src/java/org/apache/solr/handler/ReplicationHandler.java#L1182\n\nSo in case there are multiple repositories configured, we need a way to configure which repository to use. In case of backup/restore API - this configuration parameter was passed by the user. I wonder if we need to add a config param in the ReplicationHandler ? \n\n\n ",
            "id": "comment-15339971"
        },
        {
            "date": "2016-06-20T17:49:25+0000",
            "author": "Varun Thacker",
            "content": "Hi Hrishikesh,\n\nSo in case there are multiple repositories configured, we need a way to configure which repository to use\n\nAlternatively how do you feel about forcing a default repository if multiple repos are configured? Currently if there is just 1 we make that default but when there are multiple repositories we don't necessarily need to provide a default.\n\nMark - Sure I can assign it to myself. I'd like your opinion and Hrishikesh's opinion on this comment though  -\n\n\nI had to implement this test as a \"cloud\" test so as to enable testing these core level operations (since these operations are enabled only in the cloud mode). The collection-level changes include,\n- Backup/restore collection metadata\n- Check the version compatibility during restore\n- Strategy interface to define \"how\" backup operation is performed (e.g. copying the index files vs. a file-system snapshot etc.)\n\n\n\nI feel the first point should be part of this Jira . We can then say this patch effectively solves makes the repository interface work for both standalone and cloud.\n\nPoints 2/3 seem more like better guarantee checks and more options and aren't cloud related. We could tackle that in SOLR-9055 ",
            "id": "comment-15340021"
        },
        {
            "date": "2016-06-20T21:28:55+0000",
            "author": "Hrishikesh Gadre",
            "content": "Varun Thacker\n\nAlternatively how do you feel about forcing a default repository if multiple repos are configured? Currently if there is just 1 we make that default but when there are multiple repositories we don't necessarily need to provide a default.\n\nYes we can force the user to have a default repository if multiple repos are configured. But it seems to me that the code under consideration is added as part of SOLR-561 (i.e. Solr replication). Do we need to incorporate these changes in the replication work-flow? My gut feeling is that we shouldn't make any changes to this code as part of this JIRA.\n\nI feel the first point should be part of this Jira . We can then say this patch effectively solves makes the repository interface work for both standalone and cloud.\n\nBased on JIRA description, I thought the requirement for this JIRA is to support core level backup/restore. But I am OK with repurposing this JIRA to cover Solr cloud as well. Its just that the patch will grow in size  I generally prefer to keep patch short which makes it easier to review and test. But if you are OK with larger patch, I can resubmit it. Let me know.\n ",
            "id": "comment-15340439"
        },
        {
            "date": "2016-06-21T05:48:41+0000",
            "author": "Varun Thacker",
            "content": "Do we need to incorporate these changes in the replication work-flow?\n\nI think having a mandatory default repository and using that for this workflow should be enough right? ",
            "id": "comment-15341157"
        },
        {
            "date": "2016-06-21T07:11:03+0000",
            "author": "Mark Miller",
            "content": "I don't see a problem with breaking off the full cloud work into another JIRA. Let's just relate them and then we can wrap this up and have a fresh canavas to discuss what has not already been reviewed.\n\nWhich repo the replication handler should use seems a bit tricky. I don't like any of the current options that much. Still thinking about that a bit. \n ",
            "id": "comment-15341266"
        },
        {
            "date": "2016-06-21T07:25:05+0000",
            "author": "Mark Miller",
            "content": "So I think we do want it configurable in ReplicationHandler config, but if it's not config'd, perhaps we could default to the first repo defined? And local if no repos are defined? Forcing a default for this seems annoying, same as forcing config.  ",
            "id": "comment-15341289"
        },
        {
            "date": "2016-06-21T14:11:31+0000",
            "author": "Varun Thacker",
            "content": "FYI I created SOLR-9239 for discussing the two approaches that we have for core level backup/restore ",
            "id": "comment-15341836"
        },
        {
            "date": "2016-06-21T14:22:35+0000",
            "author": "Varun Thacker",
            "content": "Regarding the cloud level changes required, I agree with you'll - lets just then do it in another Jira as long as it's not SOLR-9055 as those have other enhancements  . I guess I got thrown off by this comment previously.\n\nThe collection level changes are being captured in the patch for SOLR-9055 ",
            "id": "comment-15341858"
        },
        {
            "date": "2016-06-21T16:26:26+0000",
            "author": "Hrishikesh Gadre",
            "content": "Mark Miller\n\nSo I think we do want it configurable in ReplicationHandler config, but if it's not config'd, perhaps we could default to the first repo defined? And local if no repos are defined? Forcing a default for this seems annoying, same as forcing config.\n\nPersonally I think that the code under consideration is quite unrelated to backup/restore functionality. It was added as part of SOLR-561 to implement replication. So my suggestion is to not consider it as part of this JIRA. We can file a separate JIRA for tracking. The backup/restore API in ReplicationHandler already accept repository parameter in my latest patch. ",
            "id": "comment-15342101"
        },
        {
            "date": "2016-06-21T16:37:36+0000",
            "author": "Mark Miller",
            "content": "I have no strong preference on whether that needs to use a Repository here or not, but Varun Thacker has not seemed very amenable to ignoring it yet. ",
            "id": "comment-15342117"
        },
        {
            "date": "2016-06-21T17:22:53+0000",
            "author": "Varun Thacker",
            "content": "Yeah we can tackle that in another Jira . Whether we enforce a default repository or not , it could warrant a param in the replication handler and hence could be tackled separately.\n\n\nFor the patch , One thing I'd like to address would be - In TestHdfsBackupRestore make runCoreAdminCommand use the Replication handler instead since thats the current documented way of running core backups/restore. ",
            "id": "comment-15342235"
        },
        {
            "date": "2016-06-21T22:01:44+0000",
            "author": "Hrishikesh Gadre",
            "content": "Varun Thacker Please find the latest patch.\n\nFor the patch , One thing I'd like to address would be - In TestHdfsBackupRestore make runCoreAdminCommand use the Replication handler instead since thats the current documented way of running core backups/restore.\n\nInstead of replacing the usage of core admin API with replication handler, I just added another test which uses replication handler. This way we can test both the APIs.\n\nMark Miller I made a small change in HdfsDirectory class to define a constant for the buffer size. This way we can use the same value for both HdfsDirectory as well as HdfsBackupRepository. ",
            "id": "comment-15342842"
        },
        {
            "date": "2016-06-22T00:01:25+0000",
            "author": "Hrishikesh Gadre",
            "content": "Varun Thacker I have filed SOLR-9242 to track the work required to enable this feature at the collection level backup/restore. ",
            "id": "comment-15343072"
        },
        {
            "date": "2016-06-22T13:13:24+0000",
            "author": "Varun Thacker",
            "content": "Hi Hrishikesh ,\n\nI took your latest patch and made a few minor changes. I'll list them out as accurately as I can ( I closed the window where I was noted down the changes while making them )\n\n1. In BackupRepository removed some modifiers that were not needed.\n2. Created BackupRestoreUtils for some of the tests to reuse the classes. Methods like indexDocs and {{verifyDocs]} were moved there and made to reuse in our all backup/restore tests\n3. Made some modifications to the CHANGES entry\n4. Merged the replication handler and core admin handler test in TestHdfsBackupRestoreCore to one. We test it randomly \n\nI've run the test suite once and it passes along with precommit. Let me know if this looks good . I plan to go over it one more time tomorrow morning and commit it otherwise ",
            "id": "comment-15344284"
        },
        {
            "date": "2016-06-22T17:01:34+0000",
            "author": "Hrishikesh Gadre",
            "content": "Varun Thacker Thanks for the review. I think the changes look good. I have one question though.\n\n4. Merged the replication handler and core admin handler test in TestHdfsBackupRestoreCore to one. We test it randomly\n\nWouldn't it be better to test both ways every time? I see that this pattern is used extensively in other tests too. My main concern is that the probability of one of the test not being executed in multiple iterations is > 0.  If someone makes any subsequent changes to this code, this unit test doesn't provide a strong assurance that these changes are correct since one of the tests may not have been executed at all. So developers end up diagnosing and fixing such issues after committing the code (which could have been done before the first commit itself). \n\nI do think that random tests are very useful to test the Solr cloud behavior (e.g. chaos monkey tests). But in this case, I am not sure if we need randomness. Any thoughts? ",
            "id": "comment-15344745"
        },
        {
            "date": "2016-06-22T17:21:54+0000",
            "author": "Hrishikesh Gadre",
            "content": "Varun Thacker Oh BTW let's not hold up the patch for this. This is more of a question than a review comment  ",
            "id": "comment-15344773"
        },
        {
            "date": "2016-06-22T18:03:58+0000",
            "author": "Mark Miller",
            "content": "So developers end up diagnosing and fixing such issues after committing the code\n\nThis is a common issue, and usually it comes down to what the developers judge at commit. There is so much random testing going on, if we did it all in one run, the test run would take forever. At the same time, you want common paths to be fairly well tested every run.\n\nAt the end of the day, I generally do it based on how painful it is in extra test time vs how core the functionality being tested is.\n\nIf you are writing or changing tests, you generally run them many times before committing (at least you probably should in many cases - there is a beasting target and scripts to help with this), and you will find most things. The many Jenkins machines that are running tests all the time will find them otherwise, and that is okay too.\n\nWe have a fairly lax commit then review policy and following up with a fix or two based on jenkins random fails is common.\n\nI'll leave this one for you and Varun to figure out, just giving some context. ",
            "id": "comment-15344893"
        },
        {
            "date": "2016-06-23T17:17:16+0000",
            "author": "Hrishikesh Gadre",
            "content": "Mark Miller Thanks for the insight. Varun Thacker I am ok with the current test configuration. Let me know if anything is needed from my side. ",
            "id": "comment-15346787"
        },
        {
            "date": "2016-06-23T17:22:03+0000",
            "author": "Varun Thacker",
            "content": "I've got precommit to pass. Running the test suite one more time and then committing it.\n\nI pondered marking BackupRepository as experimental in case we need iron it out , but decided against it . \n\nDo you plan on tackling SOLR-9242 as well? ",
            "id": "comment-15346795"
        },
        {
            "date": "2016-06-23T17:28:12+0000",
            "author": "Hrishikesh Gadre",
            "content": "Varun Thacker \n\nDo you plan on tackling SOLR-9242 as well?\n\nYup. I already have a patch ready for submission. Just waiting for this patch to get committed to trunk. ",
            "id": "comment-15346820"
        },
        {
            "date": "2016-06-23T18:19:47+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 07be2c42ba24fea7c4e84836aa4c3f8d059f71d6 in lucene-solr's branch refs/heads/master from Varun Thacker\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=07be2c4 ]\n\nSOLR-7374: Core level backup/restore now supports specifying a directory implementation ",
            "id": "comment-15346907"
        },
        {
            "date": "2016-06-24T12:40:45+0000",
            "author": "Varun Thacker",
            "content": "I was looking at http://jenkins.thetaphi.de/job/Lucene-Solr-master-Solaris/668/ , and it doesn't seem related to this jira from what I understood. It's been failing for quite a while also unfortunately. ",
            "id": "comment-15348204"
        },
        {
            "date": "2016-06-27T06:39:08+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 36183cad87dfc3fc8f0a1e0b0c210e8bd14a4ce0 in lucene-solr's branch refs/heads/master from Varun Thacker\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=36183ca ]\n\nSOLR-7374: Fixing test failures like build #3366. Index a minimum of 1 doc ",
            "id": "comment-15350478"
        },
        {
            "date": "2016-06-27T06:39:56+0000",
            "author": "ASF subversion and git services",
            "content": "Commit eb071436331595cc453cd9c7d9c82d3269bb5e40 in lucene-solr's branch refs/heads/branch_6x from Varun Thacker\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=eb07143 ]\n\nSOLR-7374: Fixing test failures like build #3366. Index a minimum of 1 doc ",
            "id": "comment-15350479"
        },
        {
            "date": "2016-06-27T06:41:31+0000",
            "author": "Varun Thacker",
            "content": "Thanks Hrishikesh and Mark!  ",
            "id": "comment-15350482"
        },
        {
            "date": "2016-08-26T14:00:34+0000",
            "author": "Michael McCandless",
            "content": "Bulk close resolved issues after 6.2.0 release. ",
            "id": "comment-15439045"
        }
    ]
}