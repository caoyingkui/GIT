{
    "id": "SOLR-9258",
    "title": "Optimizing, storing and deploying AI models with Streaming Expressions",
    "details": {
        "components": [],
        "type": "New Feature",
        "labels": "",
        "fix_versions": [
            "6.3"
        ],
        "affect_versions": "None",
        "status": "Closed",
        "resolution": "Implemented",
        "priority": "Major"
    },
    "description": "This ticket describes a framework for optimizing, storing and deploying AI models within the Streaming Expression framework.\n\nOptimizing\nCao Manh Dat, has contributed SOLR-9252 which provides Streaming Expressions for both feature selection and optimization of a logistic regression text classifier. SOLR-9252 also provides a great working example of optimization of a machine learning model using an in-place parallel iterative algorithm.\n\nStoring\n\nBoth features and optimized models can be stored in SolrCloud collections using the update expression. Using Cao Manh Dat's example in SOLR-9252, the pseudo code for storing features would be:\n\n\nupdate(featuresCollection, \n       featuresSelection(collection1, \n                            id=\"myFeatures\", \n                            q=\"*:*\",  \n                            field=\"tv_text\", \n                            outcome=\"out_i\", \n                            positiveLabel=1, \n                            numTerms=100))\n\n  \n\nThe id field can be added to the featureSelection expression so that features can be later retrieved from the collection it's stored in.\n\nDeploying\n\nWith the introduction of the topic() expression, SolrCloud can be treated as a distributed message queue. This messaging capability can  be used to deploy models and process data through the models.\n\nTo implement this approach a classify() function can be created that uses a topic() function to return both the model and the data to be classified:\n\nThe pseudo code looks like this:\n\n\nclassify(topic(models, q=\"modelID\", fl=\"features, weights\"),\n         topic(emails, q=\"*:*\", fl=\"id, body\", rows=\"500\", version=\"3232323\"))\n\n\n\n\nIn the example above the classify() function uses the topic() function to retrieve the model. Each time there is an update to the model in the index, the topic() expression will automatically read the new model.\n\nThe topic function() is also used to pull in the data set that is being classified. Notice the version parameter. This will be added to the topic function to support pulling results from a specific version number (jira ticket to follow).\n\nWith this approach both the model and the data to process through the model are treated as messages in a message queue.\n\nThe daemon function can be used to send the classify function to Solr where it will be run in the background. The pseudo code looks like this:\n\n\ndaemon(...,\n         update(classifiedEmails, \n                 classify(topic(models, q=\"modelID\", fl=\"features, weights\"),\n                          topic(emails, q=\"*:*\", fl=\"id, fl, body\", rows=\"500\", version=\"3232323\"))))\n\n\n\nIn this scenario the daemon will run the classify function repeatedly in the background. With each run the topic() functions will re-pull the model if the model has been updated. It will also pull a new set of emails to be classified. The classified emails can be stored in another SolrCloud collection using the update() function.\n\nUsing this approach emails can be classified in batches. The daemon can continue to run even after all all the emails have been classified. New emails added to the emails collections will then be automatically classified when they enter the index.\n\nClassification can be done in parallel once SOLR-9240 is completed. This will allow topic() results to be partitioned across worker nodes so they can be processed in parallel. The pseudo code for this is:\n\n\nparallel(workerCollection, worker=\"20\", ...,\n         daemon(...,\n                   update(classifiedEmails, \n                           classify(topic(models, q=\"modelID\", fl=\"features, weights\", partitionKeys=\"none\"),\n                                    topic(emails, q=\"*:*\", fl=\"id, fl, body\", rows=\"500\", version=\"3232323\", partitionKeys=\"id\")))))\n\n\n\nThe code above sends a daemon to 20 workers, which will each classify a partition of records pulled by the topic() function.\n\nAI based alerting\n\nIf the version parameter is not supplied to the topic stream it will stream only new content from the topic, rather then starting from an older version number.\n\nIn this scenario the topic function behaves like an alert. Pseudo code for alerts look like this:\n\n\ndaemon(...,\n         alert(..., \n             classify(topic(models, q=\"modelID\", fl=\"features, weights\"),\n                      topic(emails, q=\"*:*\", fl=\"id, fl, body\", rows=\"500\"))))\n\n\n\nIn the example above an alert() function wraps the classify() function and takes actions based on the classification of documents. Developers can build there own alert functions using the Streaming API and plug them in to provide custom actions.",
    "attachments": {
        "ModelCache.java": "https://issues.apache.org/jira/secure/attachment/12828510/ModelCache.java",
        "SOLR-9258.patch": "https://issues.apache.org/jira/secure/attachment/12827155/SOLR-9258.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2016-09-06T09:25:43+0000",
            "author": "Cao Manh Dat",
            "content": "A patch that add classify stream to Solr\n\nclassify(\n  topic(checkpointCollection, uknownCollection, q=\"*:*\", fl=\"text_s, id\", qt=\"/export\", sort=\"id asc\", id=\"1000000\", initialCheckpoint=\"0\"),\n  topic(checkpointCollection, modelCollection, q=\"name_s:model\", fl=\"iteration_i, name_s, terms_ss, idfs_ds, weights_ds, field_s\", sort=\"iteration_i asc\", include=\"true\", id=\"2000000\"),\n  outcome=\"out_d\",\n  field=\"text_s\",\n  fieldType=\"whitetok\"\n)\n\n\nParameters of classify stream include :\n\n\tfirst sub-stream fetch documents that needed to classify,\n\tthe second sub-stream fetch the lastest model\n\toutcome specify the outcome field name that classify stream will decorate on documents\n\tfield : text field that classify stream will apply the model on\n\tfieldType : Classify stream will use this fieldType to analyze text to correspond vector\n\n\n\nThis patch also include a minor change to TopicStream (a new include parameter). \n\nsolrParams.add(\"fq\", \"{!frange cost=100 incl=\"+Boolean.toString(includeCheckpoint)+\" l=\"+checkpoint+\"}_version_\");\n\n\nIt will help classify stream to re-fetch the last model (if collection doesn't have newer model) ",
            "id": "comment-15466943"
        },
        {
            "date": "2016-09-06T09:28:02+0000",
            "author": "Cao Manh Dat",
            "content": "Re-upload the patch ",
            "id": "comment-15466952"
        },
        {
            "date": "2016-09-13T14:49:24+0000",
            "author": "Joel Bernstein",
            "content": "Thanks for working on this!  I'll start reviewing this patch today.\n\nLet's create a new ticket for the classify expression and link it to this ticket. There will be a number of approaches for deploying models, which we can build in separate tickets and link to this one. ",
            "id": "comment-15487408"
        },
        {
            "date": "2016-09-13T16:54:44+0000",
            "author": "Joel Bernstein",
            "content": "Ok, first question.\n\nWhy is the ClassifyStream an inner class of the StreamHandler? ",
            "id": "comment-15487739"
        },
        {
            "date": "2016-09-13T17:30:05+0000",
            "author": "Joel Bernstein",
            "content": "Aside from the inner class issue the ClassifyStream is looking very good.\n\nOne thing we should talk about is the model streaming. I think it makes sense to pull the model in the Classify.open() method. I think it also makes sense to have a specific ModelStream implementation that has this behavior:\n\n1) Checks a local cache of the models to see if the model is in memory. The cache can be a simple LRUCache.\n2) If the model is already in the cache, attempt to pull the model with a TopicStream. If nothing comes back, the model hasn't been changed so use the cached version. If the model does come back, use the new model and update the cache.\n3) If the model is not already in the cache, pull the model using a CloudSolrStream and update the cache.\n\nThe topic checkpoints can be kept in the same solr cloud collection as the models. So the syntax would be:\n\nmodel(collection, modelID)\n\n\n\n\n ",
            "id": "comment-15487842"
        },
        {
            "date": "2016-09-14T18:51:01+0000",
            "author": "Joel Bernstein",
            "content": "Attaching ModelCache.java for review. This should be a very efficient cache for models. It checks for Models at intervals using a TopicStream. If no changes have occurred to the model it uses the cached version. ",
            "id": "comment-15491184"
        },
        {
            "date": "2016-09-15T02:14:09+0000",
            "author": "Joel Bernstein",
            "content": "The more I look at the ModelCache the less I like it. My main concern is the synchronization which could become a bottleneck.\n\nLooking into other caching approaches... ",
            "id": "comment-15492086"
        },
        {
            "date": "2016-09-15T03:28:08+0000",
            "author": "Joel Bernstein",
            "content": "New version of the ModelCache that doesn't synchronize on code with blocking io. This is looking much better. ",
            "id": "comment-15492183"
        },
        {
            "date": "2016-09-15T05:23:54+0000",
            "author": "Cao Manh Dat",
            "content": "We cant put ClassifyStream inside sorlj.io, because solrj module is not dependent on solr-core or lucene-core, so we cant access Analyzer or SolrCore from ClassifyStream. \nI also cant find any package inside solr-core that appropriate for this class. So I make ClassifyStream as an inner class of the StreamHandler? (Hint a welcome  ) ",
            "id": "comment-15492424"
        },
        {
            "date": "2016-09-15T11:46:36+0000",
            "author": "Joel Bernstein",
            "content": "Ah I see the problem now.\n\nOk, it sounds like any Stream that uses analyzers will be tied to Solr core. This is OK, because the main use case is to run the expressions through StreamHandler.\n\nMaybe we need a new package in Solr core for streams that rely on Solr core classes. I'll put some thought into this.\n\nI'll keep working with the patch. ",
            "id": "comment-15493086"
        },
        {
            "date": "2016-09-20T01:16:05+0000",
            "author": "Joel Bernstein",
            "content": "New patch which adds the ModelCache, ModelStream and breaks out the ClassifyStream into it's own class. The test case has been adjusted slightly to accommodate the new classes.\n\nThe core algorithms though are the same as the original patch\n\nI haven't actually run this code yet so this is just for review.\n\n ",
            "id": "comment-15505226"
        },
        {
            "date": "2016-09-20T14:05:02+0000",
            "author": "Cao Manh Dat",
            "content": "+1 The patch look great. ",
            "id": "comment-15506635"
        },
        {
            "date": "2016-09-21T18:23:54+0000",
            "author": "Joel Bernstein",
            "content": "New patch with passing StreamExpressionTest for the Classify function. Also exercises the model function,\n\nI'll add some code to test the model caching behavior shortly. ",
            "id": "comment-15510758"
        },
        {
            "date": "2016-09-21T19:31:14+0000",
            "author": "Joel Bernstein",
            "content": "New patch which adds the cacheMillis param to the model() expression ",
            "id": "comment-15510921"
        },
        {
            "date": "2016-09-29T18:58:36+0000",
            "author": "Joel Bernstein",
            "content": "New patch with a parallel classification test and some parameter clarification ",
            "id": "comment-15533708"
        },
        {
            "date": "2016-09-29T22:54:32+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 9cd6437d4b21dd6d9c16688eedb5af012ea67e86 in lucene-solr's branch refs/heads/master from Joel Bernstein\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=9cd6437 ]\n\nSOLR-9258: Optimizing, storing and deploying AI models with Streaming Expressions ",
            "id": "comment-15534333"
        },
        {
            "date": "2016-09-29T22:54:34+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 8f00bcb1a0d88a6898e3ae6b8749610b2bd47d3c in lucene-solr's branch refs/heads/master from Joel Bernstein\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=8f00bcb ]\n\nSOLR-9258: Fix precommit ",
            "id": "comment-15534334"
        },
        {
            "date": "2016-09-30T00:02:59+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 568b54687a938ed0f6cd8b29100eda2c0b547975 in lucene-solr's branch refs/heads/branch_6x from Joel Bernstein\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=568b546 ]\n\nSOLR-9258: Fix precommit ",
            "id": "comment-15534473"
        },
        {
            "date": "2016-09-30T01:02:50+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 787d905edcf813f2e02155aabcc0c1dd25509b21 in lucene-solr's branch refs/heads/master from Joel Bernstein\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=787d905 ]\n\nSOLR-9258: Update CHANGES.txt ",
            "id": "comment-15534643"
        },
        {
            "date": "2016-09-30T01:04:13+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 5adb8f1bd5905f6749e57b7e27d467a4f36c56b2 in lucene-solr's branch refs/heads/branch_6x from Joel Bernstein\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=5adb8f1 ]\n\nSOLR-9258: Update CHANGES.txt ",
            "id": "comment-15534646"
        },
        {
            "date": "2016-09-30T01:05:46+0000",
            "author": "Cao Manh Dat",
            "content": "Thanks Joel Bernstein for your hard work on this ticket. ",
            "id": "comment-15534649"
        },
        {
            "date": "2016-09-30T01:07:48+0000",
            "author": "Joel Bernstein",
            "content": "Cao Manh Dat, thanks for all your work on this great ticket! ",
            "id": "comment-15534654"
        },
        {
            "date": "2016-11-09T08:38:08+0000",
            "author": "Shalin Shekhar Mangar",
            "content": "Closing after 6.3.0 release. ",
            "id": "comment-15650266"
        }
    ]
}