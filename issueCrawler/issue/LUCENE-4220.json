{
    "id": "LUCENE-4220",
    "title": "Replace benchmarks crazy HTML parser by a nekohtml 10-liner",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [
            "modules/benchmark"
        ],
        "type": "Improvement",
        "fix_versions": [
            "4.0-BETA",
            "6.0"
        ],
        "affect_versions": "4.0-ALPHA",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "Benchmark contains a javacc-based HTML parser which of course violates all specs, is huge and error prone.\n\nI can replace it by a NEKOHTML based one (approx 10 - 20 lines of code). NEKOHTML is an extension for XERCES (that we already use to read wikipedia), that produces SAX-events or DOM tree out of a HTML file usingg standard XML APIS. We could also use TIKA, but I refuse to download the Internet to get TIKA running for just parsing a HTML file.",
    "attachments": {
        "LUCENE-4220.patch": "https://issues.apache.org/jira/secure/attachment/12536557/LUCENE-4220.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2012-07-15T15:08:34+0000",
            "content": "Path using NekoHTML.\n\nThe patch currently has a workaround for the Turkish Locale bug, because NekoHTML uses toLowerCase/toUpperCase without locale to \"normalize\" element and attribute names (see http://blog.thetaphi.de/2012/07/default-locales-default-charsets-and.html). I opened NekoHTML bug: https://sourceforge.net/tracker/?func=detail&aid=3544334&group_id=195122&atid=952178\n\nThe patch mimics most of the behaviour of the old JavaCC based parser (but it does not lowercase META element values, which is bogus. Keys are lowercased - with Locale).\n\nI copied the old parser's test to the feeds package and added some additional tests for turkish and some other types of invalid HTML like plain text or missing elements. ",
            "author": "Uwe Schindler",
            "id": "comment-13414656"
        },
        {
            "date": "2012-07-15T15:56:30+0000",
            "content": "Small improvements to make parser more universal useable (allows InputSource), perf improvements on element matching. ",
            "author": "Uwe Schindler",
            "id": "comment-13414683"
        },
        {
            "date": "2012-07-15T16:23:33+0000",
            "content": "patch removes 8,600 lines of code \n\n+1! ",
            "author": "Robert Muir",
            "id": "comment-13414692"
        },
        {
            "date": "2012-07-15T17:27:42+0000",
            "content": "The original patch had a bug (which was caused by my misunderstanding and missing test data).\n\nOther changes:\n\n\tthe new Parser now correctly implements TrecParser interface and also cleans up the whole HTMLParser interface.\n\tremoved useless InterruptedException from method signatures (was only there because of the crazy old parser)\n\tFixed NPE in parsing date from <meta.../> elements\n\n\n\nIt would be good if someone (e.g. Doron Cohen, who wrote the original parser or anybody else who has a license) could temporarily provide the Gov2 TREC collection to me, so that I can check that all is working as expected. The test data is horrible small.\n\nNevertheless, I will commit the current state soon to trunk and 4.x. ",
            "author": "Uwe Schindler",
            "id": "comment-13414712"
        },
        {
            "date": "2012-07-15T17:38:36+0000",
            "content": "Committed trunk revision: 1361741\nCommitted 4.x revision: 1361743 ",
            "author": "Uwe Schindler",
            "id": "comment-13414716"
        }
    ]
}