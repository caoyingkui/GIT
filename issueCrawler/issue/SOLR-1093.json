{
    "id": "SOLR-1093",
    "title": "A RequestHandler to run multiple queries in a batch",
    "details": {
        "affect_versions": "None",
        "status": "Resolved",
        "fix_versions": [],
        "components": [
            "search"
        ],
        "type": "New Feature",
        "priority": "Major",
        "labels": "",
        "resolution": "Won't Fix"
    },
    "description": "It is a common requirement that a single page requires to fire multiple queries .In cases where these queries are independent of each other. If there is a handler which can take in multiple queries , run them in paralll and send the response as one big chunk it would be useful\nLet us say the handler is  MultiRequestHandler\n\n<requestHandler name=\"/multi\" class=\"solr.MultiRequestHandler\"/>\n\n\n\n\nQuery Syntax\n\nThe request must specify the no:of queries as count=n\n\nEach request parameter must be prefixed with a number which denotes the query index.optionally ,it may can also specify the handler name.\n\nexample\n\n/multi?count=2&1.handler=/select&1.q=a:b&2.handler=/select&2.q=a:c\n\n\n\ndefault handler can be '/select' so the equivalent can be\n\n \n/multi?count=2&1.q=a:b&2.q=a:c\n\n\n\nThe response\nThe response will be a List<NamedList> where each NamedList will be a response to a query.",
    "attachments": {
        "SOLR-1093-1.1.patch": "https://issues.apache.org/jira/secure/attachment/12809888/SOLR-1093-1.1.patch",
        "SOLR-1093.patch": "https://issues.apache.org/jira/secure/attachment/12541215/SOLR-1093.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Grant Ingersoll",
            "id": "comment-12793666",
            "date": "2009-12-22T16:42:34+0000",
            "content": "Might also be useful if it handled \"fallback queries\" too. "
        },
        {
            "author": "Noble Paul",
            "id": "comment-12793683",
            "date": "2009-12-22T17:27:02+0000",
            "content": "fallback queries? "
        },
        {
            "author": "Lance Norskog",
            "id": "comment-12793847",
            "date": "2009-12-23T00:17:29+0000",
            "content": "When the query servers are saturated, or when doing data mining, doing multiple simultaneous queries just makes things worse. If you go with this design, please add an option to do things serially.\n\nThe most general solution is to add a scripting request handler. You give any code you want as the script. This allows, for example, a follow-up query based on previous results.\n "
        },
        {
            "author": "Noble Paul",
            "id": "comment-12793953",
            "date": "2009-12-23T07:06:12+0000",
            "content": "a scripting request handler is beyond the scope of this issue. \n "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-12803356",
            "date": "2010-01-21T16:48:36+0000",
            "content": "Parallel execution of multiple queries is just one use case in a family of many others, and I agree with Lance's post in the list that it would be better to make an extensible component.\n\nOther similar use cases often requested: multi source federation, factor in ad service, select sources based on query analysis, select sources based on results, non-solr sources, result modification based on content in result, query abstraction layer/templating\n\nThe common goal is to make an abstraction layer on top of search sources which can handle search-close functionality and thus not need implement this in all the front-ends. Other products which try to fill this role are: FAST Unity, Comperio Front, Sesat (sesat.no)\n\nPerhaps the /multi req.handler could be the start of such a framework, where the first plugin to implement is the parallel queries use-case.\n\nTo be able to handle a high count for \"n\" without hitting HTTP GET limitaions, and get a cleaner syntax for complex cases, the handler could accept the request as a POST. Pseudo post content, could be JSON or custom:\n<steps>\n  <branch type=\"list\">\n    <src name=\"web\">qt=dismax&q=$q&rows=10&facet=true&facet.fl=mimetype</src>\n    <src name=\"google\">q=$q</src>\n    <src name=\"yp\">q=category:$q^10 OR company:$q&rows=3</src>\n    <src name=\"wp\">q=$q&rows=3</src>\n    <src name=\"ads\">q=$q</src>\n  </multi>\n</steps>\n\nThe result list would then consist of five entries named web, yp, google, wp and ads.\nEach \"branch\" and \"src\" would be pre-defined in config, specifying the implementing class and any defaults. indeed, the whole POST could be pre-configured, only needing to supply a &steps= param to identify which \"template\" to choose, using $variables for q etc.\nThe class implmenting \"steps\" simply calls each sub step in sequence, passing the request and response objects. This provides a simple framework for future extensions, pre- or post-processing.\nThe class implementing \"branch\" of type \"list\" would spawn all sub queries as threads and include each source result in a list.\nAnother implementation type of \"branch\" could merge (federate) results instead of stacking them.\nThe class implementing a \"src\" would be a thin wrapper which simply dispatches the query to the Search RequestHandler. Other implementations of \"src\" could be wrappers for external engines like Google or ad servers.\n\nMy intention is not to suggest a huge component, but consider if a smart interface design could enable very powerful  extension possibility which will be useful in almost all portal type applications. "
        },
        {
            "author": "Hoss Man",
            "id": "comment-12872602",
            "date": "2010-05-27T22:08:37+0000",
            "content": "Bulk updating 240 Solr issues to set the Fix Version to \"next\" per the process outlined in this email...\n\nhttp://mail-archives.apache.org/mod_mbox/lucene-dev/201005.mbox/%3Calpine.DEB.1.10.1005251052040.24672@radix.cryptio.net%3E\n\nSelection criteria was \"Unresolved\" with a Fix Version of 1.5, 1.6, 3.1, or 4.0.  email notifications were suppressed.\n\nA unique token for finding these 240 issues in the future: hossversioncleanup20100527 "
        },
        {
            "author": "syed abdul kather",
            "id": "comment-13040255",
            "date": "2011-05-27T14:27:52+0000",
            "content": "Please  add this feauture "
        },
        {
            "author": "Simon Willnauer",
            "id": "comment-13040349",
            "date": "2011-05-27T17:37:24+0000",
            "content": "We got lots of votes on this issue, seems like we should take some action here! I will assign it and make sure it will be resolved rather sooner than later.\n\nPlease add this feauture\n\nto get expectations right, we are working on releasing 3.2 soon and this one should not block it. I will work towards 3.3 here "
        },
        {
            "author": "Martijn van Groningen",
            "id": "comment-13041710",
            "date": "2011-05-31T17:56:16+0000",
            "content": "Currently with grouping one might be able to achieve something similar. Queries are not executed in parallel, but it is something you can already use in Solr 4.0.\n\nJust specify group.query parameter multiple times. E.g.\ngroup=true&group.query=brand:sumsung&group.query=category:phones "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13043832",
            "date": "2011-06-03T16:47:17+0000",
            "content": "Bulk move 3.2 -> 3.3 "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13106450",
            "date": "2011-09-16T14:51:09+0000",
            "content": "3.4 -> 3.5 "
        },
        {
            "author": "Santthosh",
            "id": "comment-13113782",
            "date": "2011-09-23T21:31:30+0000",
            "content": "Yup, I am also looking for something like this... "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-13193086",
            "date": "2012-01-25T15:05:16+0000",
            "content": "Anyone who wants to work on this? "
        },
        {
            "author": "Mikhail Khludnev",
            "id": "comment-13193750",
            "date": "2012-01-26T10:49:09+0000",
            "content": "1. is there a way to dispatch separate queries by the webcontainer threads?\n2. otherwise it requires separate thread pool. It makes operations support more complicated and less predictable. I suppose that webcontainer admin wisely configures number of threads and jvm heap size. Then you surprisingly blows up no:of threads that can lead to failures. \n\nand even item 1. is possible there is a chance to saturate web container thread pool by multiqueries, which will be blocked by \"sub-queries\". And saturated thread pool blocks \"sub-queries\" from progress. \n\nI propose implement this feature at the client side - in SolrJ. It also allows evenly distribute load on a cluster via http://wiki.apache.org/solr/LBHttpSolrServer underneath, instead of explode single node by such multi-query. "
        },
        {
            "author": "Noble Paul",
            "id": "comment-13193890",
            "date": "2012-01-26T15:14:37+0000",
            "content": "If you use distributed search, solr  uses its own thread pool.\n\nif you implement it in client side  java clients can benefit "
        },
        {
            "author": "LI Geng",
            "id": "comment-13219099",
            "date": "2012-02-29T11:12:14+0000",
            "content": "What's the current state of this issue? I'm interested in co-working on it. "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13412111",
            "date": "2012-07-11T22:26:02+0000",
            "content": "bulk fixing the version info for 4.0-ALPHA and 4.0 all affected issues have \"hoss20120711-bulk-40-change\" in comment "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13429740",
            "date": "2012-08-07T03:42:36+0000",
            "content": "rmuir20120906-bulk-40-change "
        },
        {
            "author": "Karthick Duraisamy Soundararaj",
            "id": "comment-13435940",
            "date": "2012-08-16T12:58:04+0000",
            "content": "I have created a new class MultiSearchHandler which is an extension of SearchHandler. It takes all the parameters that a SearchHandler can take and parses them into sub queries(LocalSolrQueryRequests). It then executes each of these sub queries serially using the SearchHandler. It doesnt enforce IndexSearcher consistency amongnst multiple queries within the same request (This doesnt harm us and is infact good for our usecase).\n\nUsage \n    To pass a parameter an individual query, it should be prefixed with the query number\n           Eg. 1.q=\u201dquery1\u201d&2.q=\u201dquery2\u201d\u2026.\n\n    To pass a parameter to all queries, the prefix shouldn\u2019t be specified\n           Eg. count=2&query=\u201dcommon_query\u201d&1.mm=3&2.mm=2\u2026.\n\nNew query parameters specific to MultiSearchHandler\n    In addition to all the parameters that a SearchHandler can accept, the following query parameters can be passed to the MultiSearchHandler\n\n    Query parameter that can be used both as common & specific  to each individual query\n           threshold     - The minimum number of matches(numFound) for a query.    Default value is -1 .    \n\n    Query parameter common to all the sub queries\n           count                -   Count of the queries in the url . This parameter is mandatory\n           skiponfailure - Boolean parameter that specifies whether or not to include the results of queries  whose numFound is less than threshold. This parameter is optional.\n           stoponpass   -  Boolean parameter that specifies whether or not to stop executing if the query if first subquery has result count greater than the threshold. This parameter is optional.\n "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13457482",
            "date": "2012-09-17T23:45:18+0000",
            "content": "I'm removing the fixVersion=4.0 since this feature request doesn't seem like it should hold up the (hopefully eminent) 4.0 release. "
        },
        {
            "author": "B Karunakar Reddy",
            "id": "comment-13531387",
            "date": "2012-12-13T19:45:00+0000",
            "content": "Hi every. can anyone tel for which version we have to apply this patch?i am using currently Solr3.4 .  "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13531858",
            "date": "2012-12-14T00:38:15+0000",
            "content": "well, the patch is from August, so it was probably made against the (then current) 4.x branch. I'd start against a current 4x branch, but wouldn't be surprised if it didn't apply cleanly.\n\nIt'd be cool if you can update it to apply cleanly against the current 4.x trunk...\n "
        },
        {
            "author": "Karthick Duraisamy Soundararaj",
            "id": "comment-13531897",
            "date": "2012-12-14T01:32:31+0000",
            "content": "B Karunakar Reddy This patch was for the then trunk code. I was able to apply the patch to 4.0 when I tested it last week. "
        },
        {
            "author": "J Mohamed Zahoor",
            "id": "comment-13571244",
            "date": "2013-02-05T11:41:20+0000",
            "content": "Integration with solrj will be a nice addition "
        },
        {
            "author": "Ariel Lieberman",
            "id": "comment-13604404",
            "date": "2013-03-16T19:49:03+0000",
            "content": "I've applied it to 4.2 and it works like a charm "
        },
        {
            "author": "David Smiley",
            "id": "comment-13620283",
            "date": "2013-04-02T21:16:55+0000",
            "content": "-1  If this issue is strictly about a feature in which a batch of queries are fully known at the time of submission, then I don't think this should be accepted for inclusion in Solr; sorry.  Simply submit them in parallel.\n\nInstead, I am highly in favor of a scripting request handler in which a script runs that submits the searches to Solr (in-VM) and can react to the results of one request before making another that is formulated dynamically, and can assemble the response data, potentially reducing both the latency and data that would move over the wire if this feature didn't exist.  And if you really were bent on submitting a batch of queries that are returned in a batch, then you could implement that with the script. "
        },
        {
            "author": "Gordon Mohr",
            "id": "comment-13648441",
            "date": "2013-05-03T14:20:57+0000",
            "content": "I have a possibly-related desired use-case: I'd like to issue M multiple queries, get the top N results for each query, and for each result across all queries, get its score for each of the queries. (And of course I'd prefer to do this in one parallel index pass, rather than M serial passes.)  "
        },
        {
            "author": "jefferyyuan",
            "id": "comment-13659915",
            "date": "2013-05-16T20:12:47+0000",
            "content": "Just found one small issue in the code.\nIf we put several fq for one query, only one will be used, for example: 1.fq=datatype:4&1.fq=filetype:pdf.\n\nTo fix this, just need change code below:\norg.apache.solr.handler.component.MultiSearchHandler.initRequestParams(SolrQueryRequest, Vector<SimpleOrderedMap<Object>>, SimpleOrderedMap<Object>)\n+        int startPos = paramName.indexOf('.') + 1;\n+        localRequestParams.elementAt(queryId - 1).add(\n+            paramName.substring(startPos), reqParams.get(paramName));\n\n\nShould be changed to:\nint startPos = paramName.indexOf('.') + 1;\n\nString[] paramsValues = reqParams.getParams(paramName);\nif(paramsValues!=null)\n{\n  for(String value: paramsValues)\n  {\n\tlocalRequestParams.elementAt(queryId - 1).add(\n\t\tparamName.substring(startPos),value);\n  } "
        },
        {
            "author": "Thomas Scheffler",
            "id": "comment-13699300",
            "date": "2013-07-03T18:38:33+0000",
            "content": "As said by David Smiley in his comment\n\nI am highly in favor of a scripting request handler in which a script runs that submits the searches to Solr (in-VM) and can react to the results of one request before making another that is formulated dynamically, and can assemble the response data, potentially reducing both the latency and data that would move over the wire if this feature didn't exist.\n\nI have a use-case that currently requires for every search I do two more searches that depend on the result of the first search. Doing this on client side requires also two more network roundtrips and the overhead of preparing the searches. An efficient way to specify a script (external file or cdata section) could optimize the time for doing this and may even allow better caching.\n\nOriginally I came across this issue to combine the two later request into one. A scriptable RequestHandler would even save this request by moving some simple logic to SOLR. "
        },
        {
            "author": "Noble Paul",
            "id": "comment-13699756",
            "date": "2013-07-04T04:27:24+0000",
            "content": "I'm in favor of a scripting request handler. Why don't we open a separate issue and track of there?  "
        },
        {
            "author": "David Smiley",
            "id": "comment-13700043",
            "date": "2013-07-04T12:42:25+0000",
            "content": "I opened it: SOLR-5005 "
        },
        {
            "author": "Shaun A Elliott",
            "id": "comment-14582632",
            "date": "2015-06-11T22:39:53+0000",
            "content": "Could this be done with SolrCloud? "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-14582669",
            "date": "2015-06-11T23:13:56+0000",
            "content": "Don't see how that relates at all, they seem like completely different beasts. "
        },
        {
            "author": "Noble Paul",
            "id": "comment-14582952",
            "date": "2015-06-12T05:18:51+0000",
            "content": "The JS request handler SOLR-7576 would support stuff like\n\n$.query({q:\"a:b\"}).pipe(\"results1\");\n$.query({q:\"a:c\"}).pipe(\"results2\");\n$.query({q:\"x:y\"}).pipe(\"results2\");\n\n\n\nThis means you would get a response with  3 results. for three different queries in results1 , results2, results3 keys respectively\nThis would be the extremely simplistic usecase . The advantage is it can do some intermediate processing and construct other queries\n\nShaun A Elliott SOLR-7576 works \"only\" in SolrCloud . probably we can extend it "
        },
        {
            "author": "Shaun A Elliott",
            "id": "comment-14582974",
            "date": "2015-06-12T05:35:17+0000",
            "content": "Erik Eriksson, check out Solr Cloud streaming expressions. In particular, the merge function. It accepts 2 StreamExpression which basically is 2 search queries. While I don't think Streaming Expressions fulfills this request, I think it could be something to start with.\n\nNoble Paul SOLR-7576 does not look like it is associated with a particular version, so I'm confused what you mean. Do you mean the patch in the task works only with SolrCloud? "
        },
        {
            "author": "Gordon Mohr",
            "id": "comment-14583037",
            "date": "2015-06-12T06:35:37+0000",
            "content": "This issue may mean different things to different people. The facility I'd most like to see would be able to (a) satisfy multiple queries in one scan over an index/shard (that is: optimizing IO/memory passes moreso than just request roundtrips); and (b) score all top results for any query against all queries.\n\nEssentially, my interest is in supporting a search session which develops over time, of queries Q1, Q2, ..., Qm. But when Qm is issued, as long as a full-scan is happening to collect Qm's results, I'd like to find out how all the prior top-n results score for Qm, and how the new n results for Qm score for each of the [Q1...Q(m-1)] queries. Perhaps there's already a way to do this, either via grouping or `explainOther` resubmitting all prior Q1...Q(m-1) hits back as a (potentially very large) second query-by-document ID... but I haven't found a good approach, and it seems that a single-request/single-scan M(queries) x N(collectors) approach would be natural and maximally efficient.\n\nPerhaps that's a different enough need to spawn a separate issue? "
        },
        {
            "author": "Noble Paul",
            "id": "comment-14583051",
            "date": "2015-06-12T06:47:06+0000",
            "content": "that is better suited in a new issue.  "
        },
        {
            "author": "Fellipe Castro",
            "id": "comment-15310892",
            "date": "2016-06-01T18:59:00+0000",
            "content": "I tried to apply this patch to the most recent version of solr, found at\n\nhttps://github.com/apache/lucene-solr\n\nby using the following command\n\nwget https://issues.apache.org/jira/secure/attachment/12541215/SOLR-1093.patch -O - | patch -p0 --dry-run\n\nand I'm getting this failure output:\n\nFile solr/CHANGES.txt is read-only; trying to patch anyway\nchecking file solr/CHANGES.txt\nHunk #1 succeeded at 8110 (offset 7962 lines).\nchecking file solr/core/src/java/org/apache/solr/handler/component/MultiSearchHandler.java\nFile solr/core/src/java/org/apache/solr/handler/component/SearchHandler.java is read-only; trying to patch anyway\nchecking file solr/core/src/java/org/apache/solr/handler/component/SearchHandler.java\nHunk #1 FAILED at 158.\n1 out of 1 hunk FAILED\n\nAny ideas on how to solve this?\n\nIs that the correct way to patch on solr? "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-15311062",
            "date": "2016-06-01T20:36:32+0000",
            "content": "There is almost no chance that  a patch created 3+ years ago will apply to a recent version of Solr. The best you'll be able to do would be to get the code from when the patch was fresh, try to understand it and then figure out what equivalent possibilities are in the new code.\n\nFirst I'd ask on the user's list if there's a decent alternative that's come up in the last three years. "
        },
        {
            "author": "Pedro Rosanes",
            "id": "comment-15327797",
            "date": "2016-06-13T17:28:56+0000",
            "content": "If multi queries were sent, the resulting json would be invalid, since it'd have two or more \"response\" keys.\nIn this patch, each response has an identifier of the corresponding query.\nEg.: \n\n{ \"1.response\" : ..., \"2.response\" : ... }\n\n\nAnd you should use \n\n<requestHandler name=\"/multi\" class=\"solr.MultiSearchHandler\"/>\n\n. "
        }
    ]
}