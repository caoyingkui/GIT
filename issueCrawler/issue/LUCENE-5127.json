{
    "id": "LUCENE-5127",
    "title": "FixedGapTermsIndex should use monotonic compression",
    "details": {
        "components": [],
        "fix_versions": [
            "5.0",
            "6.0"
        ],
        "affect_versions": "None",
        "priority": "Major",
        "labels": "",
        "type": "Improvement",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "for the addresses in the big in-memory byte[] and disk blocks, we could save a good deal of RAM here.\n\nI think this codec just never got upgraded when we added these new packed improvements, but it might be interesting to try to use for the terms data of sorted/sortedset DV implementations.\n\npatch works, but has nocommits and currently ignores the divisor. The annoying problem there being that we have the shared interface with \"get(int)\" for PackedInts.Mutable/Reader, but no equivalent base class for monotonics get(long)... \n\nStill its enough that we could benchmark/compare for now.",
    "attachments": {
        "LUCENE-5127.patch": "https://issues.apache.org/jira/secure/attachment/12593317/LUCENE-5127.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2013-07-22T12:45:11+0000",
            "content": "+1\n\nI think we should just nuke the divisor? ",
            "author": "Michael McCandless",
            "id": "comment-13715169"
        },
        {
            "date": "2013-07-22T15:39:43+0000",
            "content": "Maybe, though we could also add a minimal get(long) interface to blockpacked/monotonicblockpacked/appending/monotonicappending.\n\nA few notes:\n\n\tCurrent patch changes both the disk offsets (termsDictOffsets) and the offsets into the in-ram terms data (termOffsets)\n\tWith the current patch as-is, we could remove the interval*2B #terms limitation, as long addressing is used everywhere.\n\tCurrent patch saves RAM, savings increase as termsindex/termsdict gets larger. With 10M:\n\n\n\nCheckout\nTIB\nTII\n\n\nTrunk\n519329144\n19300603\n\n\nPatch\n519329144\n14149524\n\n\n\n\n\tCurrent patch slows down seek-heavy queries a bit:\n\n                    Task   QPS trunk      StdDev   QPS patch      StdDev                Pct diff\n                PKLookup       86.02      (2.9%)       76.17      (2.4%)  -11.4% ( -16% -   -6%)\n                 Respell       39.76      (3.0%)       36.58      (2.5%)   -8.0% ( -13% -   -2%)\n                  Fuzzy2       35.49      (4.1%)       32.88      (2.6%)   -7.3% ( -13% -    0%)\n                  Fuzzy1       31.49      (4.1%)       29.18      (2.6%)   -7.3% ( -13% -    0%)\n\n\n\ttermOffsets are read twice per seek / binary search iteration:\n\n      final long offset = fieldIndex.termOffsets.get(idx);\n      final int length = (int) (fieldIndex.termOffsets.get(1+idx) - offset);\n\n\n\ttermsDictOffsets are only read once... and this is really just an unfortunate consequence of TermsIndexReaderBase's API... ideally they would lazy-decode this until you really needed it, like BlockTree.\n\n\n\nSo I see a few things we could do:\n\n\tgo forward with current patch (maybe add the divisor stuff via a simple get() interface). clean up int->long everywhere. I'm not sure if these perf diffs matter for the use cases where someone needs an ord-enabled terms index?\n\thybrid patch, where termOffsets stay \"absolute\" but termDictOffsets use monotonicpacked. This would still save some space, but restore the seek-heavy perf. But then we wouldnt be able to cleanup int->long and so on.\n\tdo nothing, maybe \"fork\" the logic of this thing so it can be used in DV. For how DV is used, it'd be the right tradeoff so its no issue there.\n\n ",
            "author": "Robert Muir",
            "id": "comment-13715302"
        },
        {
            "date": "2013-07-25T15:49:21+0000",
            "content": "I made some progress... \n\nFinally clean up divisor and interval, which are only confusing to users since they have done nothing in the default codec for so long: and in 5.x we dont have to read any preflex indexes.\n\nthis makes interval a codec parameter for fixedgap and so on (like blocktree's min/max). this is cleaner and more flexible anyway, because it means e.g. if you use one of these codecs you can specify it per-field in the usual ways rather than globally for the whole index.\n\nthe fieldcache-like divisor is gone. As far as the special -1 value, i didnt yet clean this up, but i see two directions. The best IMO is to nuke the mergeReader shit from ReadersAndLiveDocs completely. Otherwise we keep it and codecs can do special shit based on IOContext, but in all cases we dont need a special param.\n\ntests are passing (at least once). More cleanups are needed to some of the codec impls, and some of the special case tests for corner-case bugs in the past (e.g. TII0+empty field name) should really be moved to fix-gap specific unit tests. ",
            "author": "Robert Muir",
            "id": "comment-13719719"
        },
        {
            "date": "2013-07-25T16:00:31+0000",
            "content": "Commit 1507035 from Robert Muir in branch 'dev/branches/lucene5127'\n[ https://svn.apache.org/r1507035 ]\n\nLUCENE-5127: create branch ",
            "author": "ASF subversion and git services",
            "id": "comment-13719728"
        },
        {
            "date": "2013-07-25T16:01:07+0000",
            "content": "Commit 1507036 from Robert Muir in branch 'dev/branches/lucene5127'\n[ https://svn.apache.org/r1507036 ]\n\nLUCENE-5127: dump current state ",
            "author": "ASF subversion and git services",
            "id": "comment-13719729"
        },
        {
            "date": "2013-07-25T16:03:11+0000",
            "content": "Commit 1507041 from Robert Muir in branch 'dev/branches/lucene5127'\n[ https://svn.apache.org/r1507041 ]\n\nLUCENE-5127: randomize codec parameter ",
            "author": "ASF subversion and git services",
            "id": "comment-13719732"
        },
        {
            "date": "2013-07-25T16:32:09+0000",
            "content": "Commit 1507054 from Robert Muir in branch 'dev/branches/lucene5127'\n[ https://svn.apache.org/r1507054 ]\n\nLUCENE-5127: fix solr tests ",
            "author": "ASF subversion and git services",
            "id": "comment-13719752"
        },
        {
            "date": "2013-07-25T17:01:21+0000",
            "content": "This cleanup is awesome, thanks Rob!\n\nI think we should just nuke the special -1 \"don't load terms index\" value? ",
            "author": "Michael McCandless",
            "id": "comment-13719775"
        },
        {
            "date": "2013-07-25T17:21:06+0000",
            "content": "Commit 1507067 from Robert Muir in branch 'dev/branches/lucene5127'\n[ https://svn.apache.org/r1507067 ]\n\nLUCENE-5127: nuke mergeReader ",
            "author": "ASF subversion and git services",
            "id": "comment-13719793"
        },
        {
            "date": "2013-07-25T17:28:09+0000",
            "content": "Commit 1507070 from Robert Muir in branch 'dev/branches/lucene5127'\n[ https://svn.apache.org/r1507070 ]\n\nLUCENE-5127: simplify seek-within-block ",
            "author": "ASF subversion and git services",
            "id": "comment-13719798"
        },
        {
            "date": "2013-07-25T17:46:32+0000",
            "content": "Commit 1507075 from Robert Muir in branch 'dev/branches/lucene5127'\n[ https://svn.apache.org/r1507075 ]\n\nLUCENE-5127: explicit var gap testing part 1 ",
            "author": "ASF subversion and git services",
            "id": "comment-13719826"
        },
        {
            "date": "2013-07-25T17:56:51+0000",
            "content": "Commit 1507078 from Robert Muir in branch 'dev/branches/lucene5127'\n[ https://svn.apache.org/r1507078 ]\n\nLUCENE-5127: explicit var gap testing part 2 ",
            "author": "ASF subversion and git services",
            "id": "comment-13719836"
        },
        {
            "date": "2013-07-25T18:22:00+0000",
            "content": "Commit 1507083 from Robert Muir in branch 'dev/branches/lucene5127'\n[ https://svn.apache.org/r1507083 ]\n\nLUCENE-5127: simplify vargap ",
            "author": "ASF subversion and git services",
            "id": "comment-13719873"
        },
        {
            "date": "2013-07-25T18:40:03+0000",
            "content": "Commit 1507086 from Robert Muir in branch 'dev/branches/lucene5127'\n[ https://svn.apache.org/r1507086 ]\n\nLUCENE-5127: simplify fixedgap ",
            "author": "ASF subversion and git services",
            "id": "comment-13719892"
        },
        {
            "date": "2013-07-25T18:40:45+0000",
            "content": "Commit 1507087 from Robert Muir in branch 'dev/branches/lucene5127'\n[ https://svn.apache.org/r1507087 ]\n\nLUCENE-5127: fix indent ",
            "author": "ASF subversion and git services",
            "id": "comment-13719894"
        },
        {
            "date": "2013-07-25T19:24:44+0000",
            "content": "Commit 1507097 from Michael McCandless in branch 'dev/branches/lucene5127'\n[ https://svn.apache.org/r1507097 ]\n\nLUCENE-5127: add tests ",
            "author": "ASF subversion and git services",
            "id": "comment-13719932"
        },
        {
            "date": "2013-07-25T20:25:10+0000",
            "content": "Commit 1507111 from Robert Muir in branch 'dev/branches/lucene5127'\n[ https://svn.apache.org/r1507111 ]\n\nLUCENE-5127: clear nocommits ",
            "author": "ASF subversion and git services",
            "id": "comment-13720005"
        },
        {
            "date": "2013-07-25T20:41:10+0000",
            "content": "Commit 1507116 from Robert Muir in branch 'dev/branches/lucene5127'\n[ https://svn.apache.org/r1507116 ]\n\nLUCENE-5127: fix TestLucene40PF and clean up some more outdated stuff ",
            "author": "ASF subversion and git services",
            "id": "comment-13720024"
        },
        {
            "date": "2013-07-25T20:42:50+0000",
            "content": "Commit 1507118 from Michael McCandless in branch 'dev/branches/lucene5127'\n[ https://svn.apache.org/r1507118 ]\n\nLUCENE-5127: fix false fail when terms dict is a ghostbuster ",
            "author": "ASF subversion and git services",
            "id": "comment-13720027"
        },
        {
            "date": "2013-07-25T20:52:35+0000",
            "content": "Commit 1507120 from Robert Muir in branch 'dev/branches/lucene5127'\n[ https://svn.apache.org/r1507120 ]\n\nLUCENE-5127: clean up error msgs ",
            "author": "ASF subversion and git services",
            "id": "comment-13720044"
        },
        {
            "date": "2013-07-26T02:21:36+0000",
            "content": "Commit 1507179 from Robert Muir in branch 'dev/branches/lucene5127'\n[ https://svn.apache.org/r1507179 ]\n\nLUCENE-5127: use less ram when writing the terms index ",
            "author": "ASF subversion and git services",
            "id": "comment-13720357"
        },
        {
            "date": "2013-07-26T03:05:20+0000",
            "content": "Patch for trunk, i think its ready. ",
            "author": "Robert Muir",
            "id": "comment-13720365"
        },
        {
            "date": "2013-07-26T14:24:10+0000",
            "content": "+1, patch looks great.  Thanks Rob! ",
            "author": "Michael McCandless",
            "id": "comment-13720828"
        },
        {
            "date": "2013-07-26T14:57:37+0000",
            "content": "This is a very nice cleanup! In FixedGapTermsIndexWriter, I think we could improve the buffering of offsets and addresses by directly buffering into a MonotonicBlockPackedWriter over a RamOutputStream, and then copy the raw content of the RamOutputStream to the IndexOutput? This would avoid an extra encoding/decoding step. ",
            "author": "Adrien Grand",
            "id": "comment-13720856"
        },
        {
            "date": "2013-07-26T15:39:22+0000",
            "content": "Good idea! I initially thought of the growableoutput, but i didnt want all the resizing. I think a RamOutputStream can work well. ",
            "author": "Robert Muir",
            "id": "comment-13720892"
        },
        {
            "date": "2013-07-29T17:02:19+0000",
            "content": "patch with RAMOutputStream approach (so we don't compress/uncompress/recompress) ",
            "author": "Robert Muir",
            "id": "comment-13722639"
        },
        {
            "date": "2013-07-29T17:13:46+0000",
            "content": "+1 ",
            "author": "Adrien Grand",
            "id": "comment-13722649"
        },
        {
            "date": "2013-07-29T17:34:54+0000",
            "content": "Commit 1508147 from Robert Muir in branch 'dev/trunk'\n[ https://svn.apache.org/r1508147 ]\n\nLUCENE-5127: FixedGapTermsIndex should use monotonic compression ",
            "author": "ASF subversion and git services",
            "id": "comment-13722697"
        },
        {
            "date": "2013-07-29T17:48:15+0000",
            "content": "resolving for trunk only. I think the situation is already confusing in 4.x and backporting seems risky... ",
            "author": "Robert Muir",
            "id": "comment-13722719"
        },
        {
            "date": "2015-02-23T05:02:29+0000",
            "content": "Bulk close after 5.0 release. ",
            "author": "Anshum Gupta",
            "id": "comment-14332893"
        }
    ]
}