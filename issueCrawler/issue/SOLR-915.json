{
    "id": "SOLR-915",
    "title": "SolrCore;close()  - scope to exploit parallelism among the number of closeHooks",
    "details": {
        "affect_versions": "None",
        "status": "Closed",
        "fix_versions": [
            "1.4"
        ],
        "components": [
            "search"
        ],
        "type": "Improvement",
        "priority": "Minor",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "In SolrCore: close() - all the way towards the end of the function - there seems to be a sequential list of close method invocation. \n\n    if( closeHooks != null ) {\n       for( CloseHook hook : closeHooks ) \n{\n         hook.close( this );\n      }\n    }\n\nI believe this has scope to be parallelized ( actually the entire sequence of close operations , updateHandler,close() etc.) - by means of launching them in separate threads from an ExecutorService , for a much faster shutdown as the process definitely does not need to be sequential. \n\nThis becomes all the more important in the multi-core context when we might want to shutdown and restart a SolrCore altogether.",
    "attachments": {
        "SOLR-915.patch": "https://issues.apache.org/jira/secure/attachment/12396124/SOLR-915.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Karthik K",
            "id": "comment-12656428",
            "date": "2008-12-14T18:14:57+0000",
            "content": "multi-core , as in multi-core processors specifically , where this process can complete much faster than what is currently now. We are running a 4-core box ( pretty expensive !! ) and would like to utilize the cpu cycles as much as possible.  "
        },
        {
            "author": "Noble Paul",
            "id": "comment-12656437",
            "date": "2008-12-14T18:40:53+0000",
            "content": "before exploring the possiblity of parallelizing some code can we explain the problem statement?\n\nIn the entire codebase there are very few instances of closeHook usages. So the problem is not as grave as you point out it to be\n\nare we trying to solve an imaginary problem? \n\n\n\n "
        },
        {
            "author": "Karthik K",
            "id": "comment-12656470",
            "date": "2008-12-14T21:43:00+0000",
            "content": "The problem statement (hardly is imaginary ), is for a faster shutdown and reinitialization of the SolrCore.  Hence the need to parallelize the code.  It is not just about closeHook , but also the other sequence of steps performed at close. All of them can have a better performance gain by parallelizing the code. Again , adding some well-abstracted code, should make things more maintainable.  "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-12656482",
            "date": "2008-12-14T22:17:16+0000",
            "content": "Faster startup and shutdown sounds great. \n\nHave you run tests to see if this gets faster when run in parallel?  I imagine you are talking about many cores before this would make any difference. "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12656535",
            "date": "2008-12-15T03:36:52+0000",
            "content": "Kay, I guess all we are trying to avoid is the XY problem.\n\nWe just want to make sure that we are solving the right problem. Do you mind telling us about your use-case on solr-user because the solution you have adopted is not something the code was written for. Perhaps there are alternate ways of achieving the goals? There are lots of people on these lists who have done some very heavy lifting with Solr and might be able to offer suggestions. "
        },
        {
            "author": "Karthik K",
            "id": "comment-12656679",
            "date": "2008-12-15T18:13:16+0000",
            "content": "Yes-  We are having a system with multiple cores , for different (Lucene) indexes in memory .  Also - we have a much less-frequent writer and high-frequency multiple readers for the same directory. \n\nThe tests that I have run uses threadpools ( FixedPools for now). We also a couple of custom handlers , that are SolrCoreAware , that adds closehooks ( addCloseHook() in SolrCore ) through the inform method.  The closehooks do some io heavylifting - which I believe has scope to be exploited.  Solr, as much as being a server, also serves the purpose of an API , for custom request handlers to be extended. So - my concern here is that the close() for a single SolrCore instance also takes significant importance, even though it is all about unwinding resource acquisition. \n\nps: I am not a big fan of running multiple SolrCore on a single app server since architecturally (also from the point of deploying it ) - it is not intuitive / scalable. But until we move towards separating out - this is something we need to live with.  "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-12656696",
            "date": "2008-12-15T18:54:53+0000",
            "content": "I see \u2013 so this becomes important when you have many cores and the code in hook.close( this ) takes a while.\n\nBehavior wise, we should make sure that core.close() does not return until all the closeHooks are finished.\n\nCan you submit a patch with your fix? "
        },
        {
            "author": "Karthik K",
            "id": "comment-12656702",
            "date": "2008-12-15T19:17:28+0000",
            "content": "I agree on the behavior (may be using a CountdownLatch). Let me submit the patch soon for the same.  "
        },
        {
            "author": "Karthik K",
            "id": "comment-12656744",
            "date": "2008-12-15T20:45:11+0000",
            "content": "1. New class- SolrExecutor, providing an abstraction of the Executor framework for all threads across the SolrSystem. \n\n2. SolrCore: \n\n. List<closeHooks> changed to Collection<CloseHook> as the order does not matter when they are launched in independent threads. \n\n\n3. More comments added to CloseHook explaining the context of the same.  "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-12656752",
            "date": "2008-12-15T21:06:28+0000",
            "content": "Overall looks reasonable...\n\nBut I'm weary of adding static classes (we just spent so much time getting rid of them!)\n\nRather then adding a static SolrExecutor class, perhaps we could add a \"getExecutor()\" method to to CoreContainer?  This would allow it to be modified if necessary.  It would also allow it to be loaded lazily so it does not affect the memory footprint (not sure that is a big deal or not) "
        },
        {
            "author": "Karthik K",
            "id": "comment-12656756",
            "date": "2008-12-15T21:11:57+0000",
            "content": "Sure - That is fine with me. \n\nMy objective is to have a static method somewhere that returns an Executor , that could be used to launch various threads. Also - at the same time - keeping the abstraction of Executor creation away from the user so that it could be tweaked depending on the startup memory constraints. \n "
        },
        {
            "author": "Karthik K",
            "id": "comment-12656757",
            "date": "2008-12-15T21:19:35+0000",
            "content": "1) Removed SolrExecutor. \n\n2) Added Executor to CoreContainer .  "
        },
        {
            "author": "Karthik K",
            "id": "comment-12656759",
            "date": "2008-12-15T21:26:46+0000",
            "content": "Just thought about the case in which the closeHook can thrown unchecked Exceptions.  As such with current implementation - close() would hang - (because the latch counter would not have decremented). \n\nRevised code would be bound in a try block as below - while giving the guarantee that close() definitely does complete even if there is an erroneous closeHook attached to the service. \n\n       solrExecutor.execute(new Runnable() {\n          public void run() {\n            try \n{ \n              hook.close(SolrCore.this);\n            }\n finally \n{ \n              latch.countDown();\n            }\n          } \n\nThe question is - do we want this ?  "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-12656764",
            "date": "2008-12-15T21:45:39+0000",
            "content": "How do you feel about this version?\n\nRather then make a public static function on CoreContainer \u2013 it has a package protected member.\n\n-------\n\nLooking over this again, I don't see how this helps the problem of having lots of cores.  If I follow correctly, this just helps if you have lots of long running shutdown hooks.\n\nIf you call core1.close(), core2.close() sequentially it will still block for one to finish before core2...\n\nDo we we really want the parallel part in CoreContainer.shutdown()? "
        },
        {
            "author": "Karthik K",
            "id": "comment-12656771",
            "date": "2008-12-15T21:58:10+0000",
            "content": "The version that I had initially was to just launch the threads for closeHooks ( excluding the CountDownLatch , so SolrCore::close() returns after invoking all the hooks ). \n\nAs far as the behavior of SolrCore::close() \n1) do we want  the guarantee that the closehooks are called for the same in separate threads and eventually execute, or \n2) do we also want the guarantee that the closehooks have completed as well. \n\n\nAs far as the Executor is concerned - the motivation is that , other potential new threads / existing threads ( I could see 4 instances of new Thread() { }.start() in the code ) can use a common executor so that the executor handles the cleanup / reuse of thread from the thread pools. While the thread pool policy might vary - it would be useful to have as minimum executors as possible to be re-used in other cases as well.  "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-12656777",
            "date": "2008-12-15T22:25:25+0000",
            "content": "Can we back up a bit...  what problem exactly are you having?\n\nWe need to see if there is a good minimal-impact solution with back compatibility.  In the end, we want the existing behavior to work as it does now: you close a core and all the closeHooks are executed.\n\nWhere is the blocking you are hitting?  Are  you calling CoreContainer.shutdown()?  are you calling the close() function programatically or via the webapp?  \n\n--------\n\nAs for new Thread() vs using a ThreadPool \u2013 can we open that as a new issue/discussion.  It seems to make sense, but I have not thought about the consequences too much.  If we are adding a container wide ThreadPool it would be good to do that explicitly rather then as a side effect of an edge case (slow shutdown hooks) "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12656876",
            "date": "2008-12-16T04:11:41+0000",
            "content": "Another issue with calling close hooks in parallel is thread safety and race conditions which could cause double closes or null pointer exceptions, etc. "
        },
        {
            "author": "Karthik K",
            "id": "comment-12657081",
            "date": "2008-12-16T17:37:29+0000",
            "content": "\n\n\n Another issue with calling close hooks in parallel is thread safety and race conditions which could cause double closes or null pointer exceptions, etc.\n\n\n\n\n\nIdeally the close hooks should all be independent of each other without any order among them. When we register multiple handlers (through <requesthandler> in solrconfig.xml ) - they might register their own closehooks as necessary. In that case - the order becomes totally irrelevant ( so the member of CloseHooks is better defined as a Collection , rather than a List, irrespective of if we have parallelism or not ).  Maintaining the same order as the order of definition in solrconfig.xml is not very intuitive since it is possible for people to move around content in the .xml file. \n\nIf they were going to totally parallel - then there is not much scope for race conditions since they do not share any object ( closeHook.close() has no objects ) and it merely serves as a notification to a hook . \n\ndoubleCloses, are not possible since there seems to be an AtomicInteger right at the beginning of close() which executes only if the counter is set to 0 . \n\nI did not understand the part about NPE , though.  "
        },
        {
            "author": "Karthik K",
            "id": "comment-12657083",
            "date": "2008-12-16T17:41:35+0000",
            "content": "\n\n\n As for new Thread() vs using a ThreadPool - can we open that as a new issue/discussion. It seems to make sense, but I have not thought about the consequences too much. If we are adding a container wide ThreadPool it would be good to do that explicitly rather then as a side effect of an edge case (slow shutdown hooks)\n\n\n\n\n\n\nI have opened https://issues.apache.org/jira/browse/SOLR-922 for a web-app wide ThreadPool design , which I agree - is independent of this issue. Started a http://mail-archives.apache.org/mod_mbox/lucene-solr-user/200812.mbox/%3C4947DE46.6030909@gmail.com%3E in the mailing list ( solr-user ) about the problem.  "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-12657087",
            "date": "2008-12-16T17:44:59+0000",
            "content": "I don't see any issue with Collection vs List.\n\nHowever I still don't see how making closeHook execution parallel helps your problem.  close() still returns when the core and all its hooks have closed.\n\nPerhaps you just want to add a single closeHook that starts up a Thead for your long running operations?   "
        },
        {
            "author": "Karthik K",
            "id": "comment-12657091",
            "date": "2008-12-16T17:51:51+0000",
            "content": "\n\n\n  I don't see any issue with Collection vs List.\n\n\n\n\n\nList, by default implies ordering and Collection does not. Making it a collection is more intuitive since there is really not a specific order ( at least intuitively) that could be obvious to the programmer . Since - there could be multiple plugins registering themselves as SolrCoreAware and adding closeHooks , Hence a Collection intuitively reflects what the underlying use case is. \n\n\n\n\n Perhaps you just want to add a single closeHook that starts up a Thead for your long running operations?\n\n\n\n\n\nSure - I could. But I believe by nature of being a closeHook - it should not interfere with the actual close process , but act as a plugin to the process that is guaranteed to be notified when the process happens.  "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-12657092",
            "date": "2008-12-16T18:10:06+0000",
            "content": "sorry, i should have said, \"I have no objection to changing List -> Collection\"\n\nSo this issue is really about changing the semantics of closeHook \u2013 you are suggesting changing the meaning so that it is just a notification, not code inserted in the shutdown cycle.\n\nTo me, the existing logic makes the most sense \u2013 the close hook is called when the core shuts down; after core.close() returns you know that all the hooks have been called.  In the case where you want to fire a long running process, the close hook can start its own thread.   \n\nThe existing process makes both options possible, the way you are proposing forces everyone to run the hook asynchronously (even existing code that assumes it won't be).\n\nI am -1 on a change like that... "
        },
        {
            "author": "Karthik K",
            "id": "comment-12657097",
            "date": "2008-12-16T18:27:41+0000",
            "content": "Ok - then let me submit a revised patch with List change to Collection and some javadoc added to CloseHook explaining why it needs to be short-lived.  "
        },
        {
            "author": "Karthik K",
            "id": "comment-12657099",
            "date": "2008-12-16T18:34:59+0000",
            "content": "1) Add comment to CloseHook.close() \n\n2) SolrCore.closeHooks ( change it from a List to a Collection interface. ) "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-12657120",
            "date": "2008-12-16T19:13:58+0000",
            "content": "check: rev 727122\n\nthanks Kay "
        },
        {
            "author": "Karthik K",
            "id": "comment-12657130",
            "date": "2008-12-16T19:33:54+0000",
            "content": "Thanks Ryan for helping with the fix.  "
        }
    ]
}