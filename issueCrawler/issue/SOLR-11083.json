{
    "id": "SOLR-11083",
    "title": "MoveReplica API can lose replicas for shared file systems on overseer restart if source node is live",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [
            "hdfs",
            "SolrCloud"
        ],
        "type": "Bug",
        "fix_versions": [
            "7.6",
            "master (8.0)"
        ],
        "affect_versions": "None",
        "resolution": "Unresolved",
        "status": "Open"
    },
    "description": "MoveReplica unloads the old replica and creates a new one for shared file systems. But if the overseer restarts between the two operations then the old replica is lost. It is upto the user to detect the failure (using request status API) and retry.",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "date": "2017-07-14T08:37:12+0000",
            "content": "The same problem does not apply for non-shared filesystems because for them, MoveReplica first creates a new replica and then tries to delete the old core. So even if overseer fails in between, the cluster just ends up with an extra replica. ",
            "author": "Shalin Shekhar Mangar",
            "id": "comment-16087036"
        },
        {
            "date": "2017-07-14T08:41:19+0000",
            "content": "Noble Paul suggested that if we build a core admin API to unload a replica temporarily i.e. for the next N minutes, then MoveReplica can use that API first and then add a new replica. Once the N minutes elapse, the old replica will be loaded again and will discover that it has been replaced and promptly unload itself. If the overseer fails then a new replica won't exist and the old replica will come back online.\n\nI won't have time to work on this but wanted to write a potential solution here in case someone else is interested. ",
            "author": "Shalin Shekhar Mangar",
            "id": "comment-16087041"
        },
        {
            "date": "2017-07-14T09:05:47+0000",
            "content": "The same command should also be able to extend the down-time by repeatedly invoking the command\n\nSo MOVEREPLICA for shared FS could be built with the following  steps\n\n\n\tinvoke TMPUNLOAD on the source replica with timeout=60secs\n\tcreate a new replica with the same coreNodeName and coreName in target node\n\tkeep tracking the target node and see if it comes up within say 50 secs\n\tif it's still not up, extend the lease by invoking the TMPUNLOAD command with timeout=60 seconds\n\trepeat until the target replica comes up or a timeout of say 300 secs\n\tif target replica comes up successfully , UNLOAD the source replica\n\n ",
            "author": "Noble Paul",
            "id": "comment-16087063"
        }
    ]
}