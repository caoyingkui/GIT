{
    "id": "SOLR-9027",
    "title": "Add GraphTermsQuery to limit traversal on high frequency nodes",
    "details": {
        "components": [],
        "type": "New Feature",
        "labels": "",
        "fix_versions": [
            "6.1"
        ],
        "affect_versions": "None",
        "status": "Resolved",
        "resolution": "Implemented",
        "priority": "Minor"
    },
    "description": "The gatherNodes() Streaming Expression is currently using a basic disjunction query to perform the traversals. This ticket is to create a specific GraphTermsQuery for performing the traversals. \n\nThe GraphTermsQuery will be based off of the TermsQuery, but will also include an option for a docFreq cutoff. Terms that are above the docFreq cutoff will not be included in the query. This will help users do a more precise and efficient traversal.",
    "attachments": {
        "SOLR-9027.patch": "https://issues.apache.org/jira/secure/attachment/12800241/SOLR-9027.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2016-04-22T16:16:14+0000",
            "author": "Joel Bernstein",
            "content": "Basic implementation. Tests still needed.\n\nIt doesn't do anything fancy to build up the matching docs. The main thing that it adds is the maxDocFreq param which is the threshold for discarding query terms.\n\nThis essentially creates an on-the-fly stop list for high frequency nodes that appear during a graph traversal. ",
            "id": "comment-15254155"
        },
        {
            "date": "2016-04-22T19:17:20+0000",
            "author": "Joel Bernstein",
            "content": "Simple test cases that shows the maxDocFreq param working. I'll expand on these and do some manual testing for performance. ",
            "id": "comment-15254496"
        },
        {
            "date": "2016-04-22T20:21:58+0000",
            "author": "Joel Bernstein",
            "content": "Actually more tests have shown that I'm not collecting the docFreq properly. I'll need to take the exact same approach as the CommonTermsQuery in doing this. More work to do here. ",
            "id": "comment-15254579"
        },
        {
            "date": "2016-04-25T16:31:04+0000",
            "author": "Joel Bernstein",
            "content": "New patch that gathers the TermContexts in the rewrite method.  ",
            "id": "comment-15256548"
        },
        {
            "date": "2016-04-25T19:59:25+0000",
            "author": "Joel Bernstein",
            "content": "Filled in the test cases a little bit more. ",
            "id": "comment-15256935"
        },
        {
            "date": "2016-04-26T20:30:33+0000",
            "author": "ASF subversion and git services",
            "content": "Commit d66f5515e648bdf52f3ea36ae76af72742a95336 in lucene-solr's branch refs/heads/master from jbernste\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=d66f551 ]\n\nSOLR-9027: Add GraphTermsQuery to limit traversal on high frequency nodes ",
            "id": "comment-15258857"
        },
        {
            "date": "2016-04-27T04:52:11+0000",
            "author": "David Smiley",
            "content": "I took a peek at what you committed out of curiosity.\n\n\twhy wrap each BytesRef in a Term when in the end you just need the BytesRef?  Or maybe I'm mistaken.\n\tequals and hashcode is on id yet you initialize that to new Object().  Firstly; why not have equals/hashcode actually work?  Secondly, if for some reason it should be this way, then you can do away with id and do equals on instance equality of the query instance \u2013 you don't need id.\n\tQuery fields should be 'final' to emphasize immutability.\n\tI think it's very suspicious that GraphTermsQuery holds List<TermContext>; I think the Query object should not hold state pertaining to the actual index as it could cause issues with caching.  Maybe you could do the construction of this in createWeight and hold it on the Weight?\n\tcollectTermContext: assuming just one field is actually supported, this could avoid looking up a Terms for each query terms since it'd always be the same.\n\tin no place do I see you sort the incoming terms.  It's faster to seek sequentially and not randomly.\n\n ",
            "id": "comment-15259548"
        },
        {
            "date": "2016-04-27T12:38:35+0000",
            "author": "Joel Bernstein",
            "content": "why wrap each BytesRef in a Term when in the end you just need the BytesRef? Or maybe I'm mistaken.\n\nI haven't really optimized things yet. I'll take a look at optimizing this.\n\nequals and hashcode is on id yet you initialize that to new Object(). Firstly; why not have equals/hashcode actually work? Secondly, if for some reason it should be this way, then you can do away with id and do equals on instance equality of the query instance \u2013 you don't need id.\n\nIt's designed to only be equal on identity so it doesn't cache. The main reason for this is that graph traversals are typically one time jobs so I wanted to avoid the overhead of hashcode and equals on large term lists.There may be a better approach to the identity equality, so I'll review your suggestion.\n\nI think it's very suspicious that GraphTermsQuery holds List<TermContext>; I think the Query object should not hold state pertaining to the actual index as it could cause issues with caching. Maybe you could do the construction of this in createWeight and hold it on the Weight?\n\nThis sounds like a good idea.\n\nin no place do I see you sort the incoming terms. It's faster to seek sequentially and not randomly.\n\nIt appeared that the TermsQuery was sorting terms to account for different fields. But the GraphTermsQuery is always on one field. Since it's always doing a seekExact, I was assuming that it would always have to seek from the top of the terms enum anyway, because it can't make assumptions on the order of the terms. In this case it would seem sorting would just add overhead. But I could be wrong about this.\n ",
            "id": "comment-15260053"
        },
        {
            "date": "2016-04-27T12:47:00+0000",
            "author": "David Smiley",
            "content": "Some TermsEnum impls, including the default one, are optimized for the case of seeking forward from the current position.  At least it was the last I checked. ",
            "id": "comment-15260065"
        },
        {
            "date": "2016-04-27T13:09:24+0000",
            "author": "Joel Bernstein",
            "content": "Ok, I didn't realize that. So they must start from where they left off and wrap-around? If thats the case then sorting will definitely be faster. I'll add the sort. ",
            "id": "comment-15260103"
        },
        {
            "date": "2016-04-27T13:37:28+0000",
            "author": "Joel Bernstein",
            "content": "David Smiley, I was looking at the TermContext issue that you brought up. As long as the TermContext is not part of the Cache key, it should be ok to hang onto it in the query. I put a comment into rewrite about this. So I think we're safe the way it's being used. Also rewrite seems like a nice place to gather the TermContexts. But if you feel strongly that the Query should not hold any index state I can still move this code to createWeight. ",
            "id": "comment-15260154"
        },
        {
            "date": "2016-04-27T13:37:46+0000",
            "author": "Joel Bernstein",
            "content": "Also thanks for reviewing! ",
            "id": "comment-15260155"
        },
        {
            "date": "2016-04-27T13:44:29+0000",
            "author": "David Smiley",
            "content": "Because this query is intentionally non-cacheable (unlike just about all other Query's) I think it's okay to get away with putting the TermContexts on the Query.  I wouldn't do it out of principle unless there was no other reasonable way, but that's me.  Maybe the fact that it's not cached could be made more explicit to others reading the code.  Might you implement ExtendedQuery to to have getCache return true to make this more guaranteed?\n\nAlso thanks for reviewing!\n\nno prob.  sorry for not providing input before you committed. ",
            "id": "comment-15260169"
        },
        {
            "date": "2016-04-27T14:17:44+0000",
            "author": "Joel Bernstein",
            "content": "Ok, I'll do one more round of work on this in master before back porting to 6x and I'll try to roll-in all your suggestions. ",
            "id": "comment-15260228"
        },
        {
            "date": "2016-04-27T21:49:47+0000",
            "author": "Kevin Watters",
            "content": "Nice stuff Joel!  Just a thought, it might be nice to also provide a \"maxDocFreq\"  on the GraphTermsQuery...  relatively easy to add now, and it would allow graph traversal that ignore sparse edges...  \n\nEither way, this is very cool,  It seems like this would be a natural enhancement for the GraphQuery when it builds the frontier. ",
            "id": "comment-15261007"
        },
        {
            "date": "2016-04-28T00:44:13+0000",
            "author": "Joel Bernstein",
            "content": "Thanks!\n\nThe GraphTermsQuery has a maxDocFreq param, did you mean a minDocFreq? ",
            "id": "comment-15261308"
        },
        {
            "date": "2016-04-28T00:47:56+0000",
            "author": "Kevin Watters",
            "content": "Yes, sorry for the typo, minDocFreq   avoid sparse edges .. could be a useful use case.. (especially in a distributed use case) ",
            "id": "comment-15261311"
        },
        {
            "date": "2016-04-28T02:07:04+0000",
            "author": "Joel Bernstein",
            "content": "Sure, this would be easy to add. I was having a hard time thinking of the use cases though. Are there scenarios where nodes with low document frequencies are better to skip? ",
            "id": "comment-15261400"
        },
        {
            "date": "2016-04-28T02:13:41+0000",
            "author": "Kevin Watters",
            "content": "no specific use case.. but if doc frequency is 0 for a given term in a \"node/from\" field,  there's not much point in traversing it,or querying for it in the first place.   I'm not sure if that's even possible, but you might have edges that point to a document that doesn't exist, in such a case, it's an easy optimization to avoid that traversal.   (similar to the leafNodesOnly parameter on the GraphQuery.) ",
            "id": "comment-15261408"
        },
        {
            "date": "2016-04-28T15:54:01+0000",
            "author": "Joel Bernstein",
            "content": "David Smiley, I've been working on the changes you proposed. I dug into how the TermContext is being used elsewhere in Lucene. What I found was that the TermQuery is holding onto the TermContext and seems to be relying on wrapper queries to manage it properly. This is marked as an expert usage. The CommonTermsQuery uses this constructor. So it does appear that holding onto the TermContext is OK, as long as it's handled properly. So I'll review just to make sure the TermContexts are always regenerated when the query is run and continue to hold onto it within the query. ",
            "id": "comment-15262381"
        },
        {
            "date": "2016-04-28T17:28:39+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 2c66d4b04619e5ac3ddf6984aacd833a62c33a29 in lucene-solr's branch refs/heads/master from jbernste\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=2c66d4b ]\n\nSOLR-9027: GraphTermsQuery optimizations and more explicit handling of non-caching behavior ",
            "id": "comment-15262580"
        },
        {
            "date": "2016-04-28T19:50:16+0000",
            "author": "David Smiley",
            "content": "I dug into how the TermContext is being used elsewhere in Lucene. What I found was that the TermQuery is holding onto the TermContext and seems to be relying on wrapper queries to manage it properly. This is marked as an expert usage. The CommonTermsQuery uses this constructor. So it does appear that holding onto the TermContext is OK, as long as it's handled properly.\n\nOkay.  AFAICT, the only reason TermQuery.perReaderTermState exists is because some callers just so happen to already have the TermContext, so this saves getting it later.  In the case of GraphTermsQuery the QParser does not and has no reason to get the TermContext in advance. ",
            "id": "comment-15262823"
        },
        {
            "date": "2016-04-28T19:58:57+0000",
            "author": "Joel Bernstein",
            "content": "Good point, I may take one more pass at refactoring before back porting.  ",
            "id": "comment-15262856"
        },
        {
            "date": "2016-04-29T14:07:07+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 58ad591a643e4c48a51d2ca9039b4889a789dbde in lucene-solr's branch refs/heads/master from jbernste\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=58ad591 ]\n\nSOLR-9027: Collect the TermContexts in createWeight ",
            "id": "comment-15264092"
        },
        {
            "date": "2016-04-29T14:09:32+0000",
            "author": "Joel Bernstein",
            "content": "Ok, I moved the TermContext collection into createWeight, so no more hanging onto the TermContexts in the Query object.\n\nThanks David Smiley, for the suggestions! I plan to do some more manual testing at scale and then backport to 6x. ",
            "id": "comment-15264097"
        },
        {
            "date": "2016-04-29T14:16:40+0000",
            "author": "David Smiley",
            "content": "Nice Joel Bernstein.\n\nBTW about collectTermContext, to be more clear on what I said earlier, which may have been overlooked \u2013 we're calling fields.terms(term.field()) on every single term given.  But they will all be the same as this is used for just one field.  Even if we wanted to support multiple fields, this terms variable could be declared outside the loop and then only re-fetch if the current field for this loop iteration is different than that of the previous.  Granted I don't know if a lot of terms is normal or the rare case for GraphTermsQuery but I suspect a lot.  This is another reason for the sort I advocated for. ",
            "id": "comment-15264109"
        },
        {
            "date": "2016-04-29T14:32:14+0000",
            "author": "Joel Bernstein",
            "content": "Yep, I see this. I'll make this change as well. ",
            "id": "comment-15264124"
        },
        {
            "date": "2016-04-29T14:53:52+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 3d3c3fb5fc2db39f433c5f449d0bee81ef89a189 in lucene-solr's branch refs/heads/master from jbernste\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=3d3c3fb ]\n\nSOLR-9027: Pull the TermsEnum once for each segment ",
            "id": "comment-15264151"
        },
        {
            "date": "2016-05-02T13:29:41+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 06f9bd2bf9805309801824b5c97294a7d1d231ab in lucene-solr's branch refs/heads/branch_6x from jbernste\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=06f9bd2 ]\n\nSOLR-9027: Add GraphTermsQuery to limit traversal on high frequency nodes ",
            "id": "comment-15266608"
        },
        {
            "date": "2016-05-02T13:29:44+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 86f371cbc68f233697f9be8df93b707daf3826b4 in lucene-solr's branch refs/heads/branch_6x from jbernste\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=86f371c ]\n\nSOLR-9027: GraphTermsQuery optimizations and more explicit handling of non-caching behavior ",
            "id": "comment-15266610"
        },
        {
            "date": "2016-05-02T13:29:45+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 3cc4125a8a04fb71be71b1eb1222a860d3d646e4 in lucene-solr's branch refs/heads/branch_6x from jbernste\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=3cc4125 ]\n\nSOLR-9027: Collect the TermContexts in createWeight ",
            "id": "comment-15266611"
        },
        {
            "date": "2016-05-02T13:29:47+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 32f7d045d628ea29b358a1c1420f89f7e66865bf in lucene-solr's branch refs/heads/branch_6x from jbernste\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=32f7d04 ]\n\nSOLR-9027: Pull the TermsEnum once for each segment ",
            "id": "comment-15266612"
        },
        {
            "date": "2016-05-02T15:31:04+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 62a28dd0c7dc8f41e43d5c37e28c968556b8e9d2 in lucene-solr's branch refs/heads/master from jbernste\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=62a28dd ]\n\nSOLR-8986, SOLR-8925, SOLR-9027: Update CHANGES.txt ",
            "id": "comment-15266798"
        },
        {
            "date": "2016-05-02T16:08:06+0000",
            "author": "ASF subversion and git services",
            "content": "Commit df72df1c58a5884774d003eec2f71c27a4737896 in lucene-solr's branch refs/heads/branch_6x from jbernste\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=df72df1 ]\n\nSOLR-8986, SOLR-8925, SOLR-9027: Update CHANGES.txt\n\nConflicts:\n\tsolr/CHANGES.txt ",
            "id": "comment-15266890"
        },
        {
            "date": "2016-06-27T13:13:39+0000",
            "author": "Steve Rowe",
            "content": "Reproducing NPE on TestGraphTermsQParserPlugin.testQueries(): SOLR-9254  ",
            "id": "comment-15350963"
        }
    ]
}