{
    "id": "LUCENE-4343",
    "title": "Clear up more Tokenizer.setReader/TokenStream.reset issues",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [
            "modules/analysis"
        ],
        "type": "Task",
        "fix_versions": [
            "4.0",
            "6.0"
        ],
        "affect_versions": "None",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "spinoff from user-list thread.\n\nI think the rename helps, but the javadocs still have problems: they seem to only describe a totally wacky case (CachingTokenFilter) and not the normal case.\n\nIdeally setReader would be final I think, but there are a few crazy tokenstreams to fix before I could make that work. Would also need something hackish so MockTokenizer's state machine is still functional.\n\nBut i worked on fixing up the mess in our various tokenstreams, which is easy for the most part.\n\nAs part of this I found it was really useful in flushing out test bugs (ones that dont use MockTokenizer, which they really should), if we can do some best-effort exceptions when the consumer is broken and it costs nothing.\n\nFor example:\n\n-  private int offset = 0, bufferIndex = 0, dataLen = 0, finalOffset = 0;\n+  // note: bufferIndex is -1 here to best-effort AIOOBE consumers that don't call reset()\n+  private int offset = 0, bufferIndex = -1, dataLen = 0, finalOffset = 0;\n\n\n\nI think this is worth exploring more... this was really effective at finding broken tests etc. We should see if we can be more thorough/ideally throw better exceptions when consumers are broken and its free.",
    "attachments": {
        "LUCENE-4343.patch": "https://issues.apache.org/jira/secure/attachment/12543013/LUCENE-4343.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2012-08-30T00:25:44+0000",
            "content": "Here's a first stab. ",
            "author": "Robert Muir",
            "id": "comment-13444565"
        },
        {
            "date": "2012-08-30T11:42:29+0000",
            "content": "+1\n\nWe had a lot of tokenizers abusing setReader for stuff they should be doing in reset!\n\nIt would be really nice to make setReader final but that sounds like a challenge... ",
            "author": "Michael McCandless",
            "id": "comment-13444887"
        },
        {
            "date": "2012-08-30T12:19:37+0000",
            "content": "I think we can still make it final: we just have 2 or 3 bad apples to figure out  ",
            "author": "Robert Muir",
            "id": "comment-13444906"
        },
        {
            "date": "2012-08-30T12:24:38+0000",
            "content": "+1 to the improvements and pursuing making it final. ",
            "author": "Chris Male",
            "id": "comment-13444908"
        },
        {
            "date": "2012-08-30T15:09:25+0000",
            "content": "updated patch:\n\n\tMockTokenizer's state machine works via an assert-only testpoint.\n\tfixed PatternTokenizer to not consume in its ctor \n\n\n\ntwo more tokenstreams in solr to fix and we are good: PreAnalyzedField and TrieTokenizerFactory. ",
            "author": "Robert Muir",
            "id": "comment-13444998"
        },
        {
            "date": "2012-08-30T15:40:40+0000",
            "content": "Updated patch: with setReader as final  ",
            "author": "Robert Muir",
            "id": "comment-13445031"
        },
        {
            "date": "2012-08-30T16:05:51+0000",
            "content": "Updated patch: with setReader as final\n\nYay!  Patch looks great.  +1 ",
            "author": "Michael McCandless",
            "id": "comment-13445053"
        },
        {
            "date": "2012-08-30T16:08:14+0000",
            "content": "Just a tiny update to make PreAnalyzedTokenizer more correct. ",
            "author": "Robert Muir",
            "id": "comment-13445057"
        },
        {
            "date": "2013-05-10T10:34:00+0000",
            "content": "Closed after release. ",
            "author": "Uwe Schindler",
            "id": "comment-13654094"
        }
    ]
}