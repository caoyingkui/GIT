{
    "id": "SOLR-6319",
    "title": "consider increasing over-request amount when sorting by index with mincount > 1",
    "details": {
        "affect_versions": "None",
        "status": "Open",
        "fix_versions": [],
        "components": [],
        "type": "Improvement",
        "priority": "Minor",
        "labels": "",
        "resolution": "Unresolved"
    },
    "description": "Discovered this while working on SOLR-2894.  the logic for distributed faceting ignores over requesting (beyond the user specified facet.limit) if the facet.sort is index order \u2013 but the rationale for doing this falls apart if the user has specified a facet.mincount > 1",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "author": "Hoss Man",
            "id": "comment-14085353",
            "date": "2014-08-04T21:44:28+0000",
            "content": "\nConsider the following sample data...\n\n1.csv\nfoo_t\na b c d e f g h\na\na\na\na\na\na\na\na\na\nb\nb\nb\nb\nb\nb\nb\nb\nb\ng\ng\ng\ng\n\n\n\n2.csv\nfoo_t\na b c d e f g h\nb\nf\nf\nf\nf\nf\nf\nf\nf\nf\ng\ng\ng\ng\ng\ng\ng\ng\ng\ng\ng\nh\nh\nh\nh\nh\nh\nh\nh\nh\nh\nh\nh\n\n\n\n\nIf you index this data in a single node solr setup, the following queries produce the results you expect...\n\n\n$ curl \"http://localhost:8983/solr/update?rowidOffset=100&rowid=id&commit=true\" -H 'Content-type:application/csv; charset=utf-8' --data-binary @1.csv\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<response>\n<lst name=\"responseHeader\"><int name=\"status\">0</int><int name=\"QTime\">522</int></lst>\n</response>\n$ curl \"http://localhost:8983/solr/update?rowidOffset=200&rowid=id&commit=true\" -H 'Content-type:application/csv; charset=utf-8' --data-binary @2.csv\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<response>\n<lst name=\"responseHeader\"><int name=\"status\">0</int><int name=\"QTime\">435</int></lst>\n</response>\n$ curl -sS 'http://localhost:8983/solr/select?q=*:*&rows=0&facet=true&facet.field=foo_t&facet.sort=index&omitHeader=true&wt=json&indent=true'\n{\n  \"response\":{\"numFound\":57,\"start\":0,\"docs\":[]\n  },\n  \"facet_counts\":{\n    \"facet_queries\":{},\n    \"facet_fields\":{\n      \"foo_t\":[\n        \"a\",11,\n        \"b\",12,\n        \"c\",2,\n        \"d\",2,\n        \"e\",2,\n        \"f\",11,\n        \"g\",17,\n        \"h\",14]},\n    \"facet_dates\":{},\n    \"facet_ranges\":{},\n    \"facet_intervals\":{}}}\n$ curl -sS 'http://localhost:8983/solr/select?q=*:*&rows=0&facet=true&facet.field=foo_t&facet.limit=1&facet.mincount=13&facet.sort=index&omitHeader=true&wt=json&indent=true'\n{\n  \"response\":{\"numFound\":57,\"start\":0,\"docs\":[]\n  },\n  \"facet_counts\":{\n    \"facet_queries\":{},\n    \"facet_fields\":{\n      \"foo_t\":[\n        \"g\",17]},\n    \"facet_dates\":{},\n    \"facet_ranges\":{},\n    \"facet_intervals\":{}}}\n\n\n\n\nBut in a simple 2 node distributed setup...\n\n\n$ curl \"http://localhost:8881/solr/update?rowidOffset=100&rowid=id&commit=true\" -H 'Content-type:application/csv; charset=utf-8' --data-binary @1.csv\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<response>\n<lst name=\"responseHeader\"><int name=\"status\">0</int><int name=\"QTime\">483</int></lst>\n</response>\n$ curl \"http://localhost:8882/solr/update?rowidOffset=200&rowid=id&commit=true\" -H 'Content-type:application/csv; charset=utf-8' --data-binary @2.csv\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<response>\n<lst name=\"responseHeader\"><int name=\"status\">0</int><int name=\"QTime\">456</int></lst>\n</response>\n$ curl -sS 'http://localhost:8881/solr/select?q=*:*&rows=0&facet=true&facet.field=foo_t&facet.sort=index&omitHeader=true&wt=json&indent=true&shards=localhost:8881/solr,localhost:8882/solr'\n{\n  \"response\":{\"numFound\":57,\"start\":0,\"maxScore\":1.0,\"docs\":[]\n  },\n  \"facet_counts\":{\n    \"facet_queries\":{},\n    \"facet_fields\":{\n      \"foo_t\":[\n        \"a\",11,\n        \"b\",12,\n        \"c\",2,\n        \"d\",2,\n        \"e\",2,\n        \"f\",11,\n        \"g\",17,\n        \"h\",14]},\n    \"facet_dates\":{},\n    \"facet_ranges\":{},\n    \"facet_intervals\":{}}}\n$ curl -sS 'http://localhost:8881/solr/select?q=*:*&rows=0&facet=true&facet.field=foo_t&facet.limit=1&facet.mincount=13&facet.sort=index&omitHeader=true&wt=json&indent=true&shards=localhost:8881/solr,localhost:8882/solr'\n{\n  \"response\":{\"numFound\":57,\"start\":0,\"maxScore\":1.0,\"docs\":[]\n  },\n  \"facet_counts\":{\n    \"facet_queries\":{},\n    \"facet_fields\":{\n      \"foo_t\":[]},\n    \"facet_dates\":{},\n    \"facet_ranges\":{},\n    \"facet_intervals\":{}}}\n\n\n\n\nBottom Line: we should be overrequesting when facet.sort=index is combined with facet.mincount > 0\n "
        },
        {
            "author": "Hoss Man",
            "id": "comment-14085355",
            "date": "2014-08-04T21:45:14+0000",
            "content": "I suspect some refactoring being done in SOLR-2894 will fix this automatically, but i wanted to file it as a distinct issue so we know the bug has existed in past releases and is being fixed. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-14085406",
            "date": "2014-08-04T22:20:20+0000",
            "content": "It's not clear to me if you've hit something new, or something that has already been considered/documented.\n\nHere's the current comments for reference:\n\n            // we're sorting by index order.\n            // if minCount==0, we should always be able to get accurate results w/o over-requesting or refining\n            // if minCount==1, we should be able to get accurate results w/o over-requesting, but we'll need to refine\n            // if minCount==n (>1), we can set the initialMincount to minCount/nShards, rounded up.\n            // For example, we know that if minCount=10 and we have 3 shards, then at least one shard must have a count of 4 for the term\n            // For the minCount>1 case, we can generate too short of a list (miss terms at the end of the list) unless limit==-1\n            // For example: each shard could produce a list of top 10, but some of those could fail to make it into the combined list (i.e.\n            //   we needed to go beyond the top 10 to generate the top 10 combined).  Overrequesting can help a little here, but not as\n            //   much as when sorting by count.\n\n\n\nIt's been years since I wrote that, but IIRC the thinking was that over requesting when sorting by index was probably not worth it.  It's a judgement call, and shouldn't be categorized as a bug (if I'm understanding this issue correctly).  "
        },
        {
            "author": "Hoss Man",
            "id": "comment-14085441",
            "date": "2014-08-04T22:54:23+0000",
            "content": "It's been years since I wrote that, but IIRC the thinking was that over requesting when sorting by index was probably not worth it. It's a judgement call, and shouldn't be categorized as a bug (if I'm understanding this issue correctly). \n\nI don't know how it could be considered \"not a bug\" ... did you look at the steps to reproduce that i posted?\n\nit's trivial to generate queries where facet.mincount>1 combined with small facet.limit counts won't produce results even when results exist.\n\nthe comment \"Overrequesting can help a little here, but not as much as when sorting by count.\" seems like an understatement. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-14085508",
            "date": "2014-08-04T23:41:50+0000",
            "content": "It would also be trivial to produce examples where over-requesting by any given amount would also fail to produce correct results.  Over-requesting does not fix the problem, it's simply a trade-off... increased cost for decreased chance of incorrect results.  It was initial my judgement that over-requesting was worth it for sorting by count, but probably not worth it for sorting by index.  Even in that case, the degree that we over-request by was a guess.  If you have a different intuition about the best amount of over-requesting, I'm all ears.\n "
        },
        {
            "author": "Hoss Man",
            "id": "comment-14085546",
            "date": "2014-08-05T00:15:48+0000",
            "content": "Let's put it this way...\n\n\n\tthe comment that you quoted explicitly says \"Overrequesting can help a little here, but not as much as when sorting by count\" but then does no overrequesting at all \u2013 which looks like a bug to me, and is at best a disconnect between the comment and the code:\n\t\n\t\tif overrequesting can help, then why wasn't it done, or at have add an option to do it?\n\t\tso what if it doesn't help as much as with sorting by count if it still helps? If there was any overrequesting here (even if it had just been a smaller amount then when sort=count) then the comment would match the code, and i would have assumed it was intentional.\n\t\n\t\n\ti can not find any tests of distributed field faceting that combines \"sort=index + mincount>1 + limit>0\" which suggests to me that the code (if not the comment) wasn't thought through completely. (this was based on some creative greping - if i missed an assert i'm happy to be corrected here)\n\tSOLR-2894 introduces new request params to allow users fine grained control over the amount of overrequest involved if they so choose (facet.overrequest.ratio & facet.overrequest.count) with default values that match the current behavior of the code when facet.sort=count (limit * 1.5 + 10)\n\ti plan to change the existing facet.field logic such that the default behavior for \"sort=index + mincount>1 + limit>0\" will overrequest by default, and respects those params (and their defaults) to decide how much over requesting if an expert user doesn't explicitly set them.\n\tif you (still) don't like me calling this a bug then feel free to edit the jira and call it WTF you want.  There aren't enough hours in the day for me to care about arguing that nit \u2013  what i care about is making the code behavior better by default, and having a record in jira moving forward of when the behavior changed.\n\n "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-14085557",
            "date": "2014-08-05T00:23:53+0000",
            "content": "if you (still) don't like me calling this a bug then feel free to edit the jira and call it WTF you want. \n\nDone.\nI do feel the distinction is important since adding more over-request still won't fix the bug if it is categorized as such. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-14085580",
            "date": "2014-08-05T00:42:02+0000",
            "content": "the comment that you quoted explicitly says \"Overrequesting can help a little here, but not as much as when sorting by count\" but then does no overrequesting at all\n\nActually, a type of over-requesting is already built-in.\n\nSay you have 10 shards and request the top 20.\nIf the stars align, one can get correct results by requesting 2 items per shard.  There is obviously a high percentage chance of errors (but it depends on the data).  As one requests more data per shard, the error chance decreases.  I'm not sure there's anything magic about \"20\", except for the fact that if all results are on one shard then we are still OK.  In the general case of data being randomized across shards though, there doesn't seem to be anything special about \"20\".  So we request a total of 200 and select the top 20... there's your built-in over-request.\n\nAnd even if there were not a built-in over-request, just because \"it can help a little here\" says nothing about whether it's worth the cost or not.\n\nLooking at your example, I might be convinced of an over-request of the form of \"+10\" or something to handle the very low limit cases, but I don't think we should apply a multiplier by default, as is done with sort-by-count.\n\nAnyway, if you are still asserting that lack of over-requesting is a bug... please post a patch that attempts to fix things via over-requesting only, and then I'll show you an example that still breaks  "
        }
    ]
}