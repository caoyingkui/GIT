{
    "id": "LUCENE-1644",
    "title": "Enable MultiTermQuery's constant score mode to also use BooleanQuery under the hood",
    "details": {
        "labels": "",
        "priority": "Minor",
        "components": [
            "core/search"
        ],
        "type": "Improvement",
        "fix_versions": [
            "2.9"
        ],
        "affect_versions": "None",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "When MultiTermQuery is used (via one of its subclasses, eg\nWildcardQuery, PrefixQuery, FuzzyQuery, etc.), you can ask it to use\n\"constant score mode\", which pre-builds a filter and then wraps that\nfilter as a ConstantScoreQuery.\n\nIf you don't set that, it instead builds a [potentially massive]\nBooleanQuery with one SHOULD clause per term.\n\nThere are some limitations of this approach:\n\n\n\tThe scores returned by the BooleanQuery are often quite\n    meaningless to the app, so, one should be able to use a\n    BooleanQuery yet get constant scores back.  (Though I vaguely\n    remember at least one example someone raised where the scores were\n    useful...).\n\n\n\n\n\tThe resulting BooleanQuery can easily have too many clauses,\n    throwing an extremely confusing exception to newish users.\n\n\n\n\n\tIt'd be better to have the freedom to pick \"build filter up front\"\n    vs \"build massive BooleanQuery\", when constant scoring is enabled,\n    because they have different performance tradeoffs.\n\n\n\n\n\tIn constant score mode, an OpenBitSet is always used, yet for\n    sparse bit sets this does not give good performance.\n\n\n\nI think we could address these issues by giving BooleanQuery a\nconstant score mode, then empower MultiTermQuery (when in constant\nscore mode) to pick & choose whether to use BooleanQuery vs up-front\nfilter, and finally empower MultiTermQuery to pick the best (sparse vs\ndense) bit set impl.",
    "attachments": {
        "LUCENE-1644.patch": "https://issues.apache.org/jira/secure/attachment/12414025/LUCENE-1644.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2009-06-11T02:21:29+0000",
            "content": "I'm inclined to think we push to 3.0? ",
            "author": "Mark Miller",
            "id": "comment-12718279"
        },
        {
            "date": "2009-06-11T12:29:56+0000",
            "content": "I agree... moving out. ",
            "author": "Michael McCandless",
            "id": "comment-12718424"
        },
        {
            "date": "2009-07-20T18:27:24+0000",
            "content": "I'd really like to get this one in for 2.9.  The API is still\nmalleable because the constant-score rewrite mode of MultiTermQuery\nhasn't been released yet.\n\nAttached patch, that adds a MultiTermQuery.RewriteMethod parameter,\nwith current values FILTER, SCORING_BOOLEAN_QUERY and\nCONSTANT_BOOLEAN_QUERY.  This replaces the\nsetConstantScoreRewrite(boolean) method.\n\nI also added javadocs noting that the two remaining multi-term queries\nthat have not yet switched over to FILTER rewrite method\n(WildcardQuery and PrefixQuery) will switch over in 3.0.  (LUCENE-1557\nis already open to make that switch.) ",
            "author": "Michael McCandless",
            "id": "comment-12733310"
        },
        {
            "date": "2009-07-21T02:43:16+0000",
            "content": "Mike, one question: couldn't you consider FILTER versus CONSTANT_BOOLEAN_QUERY an implementation detail? could lucene pick / switch over to the best one?\n\nI guess in my opinion, there was nothing wrong with the setConstantScoreRewrite() from an API perspective, but behind the scenes maybe lucene could be a bit smarter about how it actually accomplishes that? ",
            "author": "Robert Muir",
            "id": "comment-12733445"
        },
        {
            "date": "2009-07-21T03:31:14+0000",
            "content": "Thats originally what I thought this issue was - the correct method would be chosen under the covers using a heuristic. Progress not perfection deal? ",
            "author": "Mark Miller",
            "id": "comment-12733458"
        },
        {
            "date": "2009-07-21T10:08:17+0000",
            "content": "couldn't you consider FILTER versus CONSTANT_BOOLEAN_QUERY an implementation detail? could lucene pick / switch over to the best one?\n\nYeah I struggled with this.  I completely agree it's an impl detail \u2013 the user should just have to say \"I want constant scoring\" and Lucene finds the most performant way to achieve it.\n\nBut then I realized it's not obvious when one impl should be chosen over another.  Often FILTER is faster than CONSTANT_BOOLEAN_QUERY, but at some point once the index becomes large enough the underlying O(maxDoc) cost (w/ small constant in front) of FILTER will dominate, or if the number of terms/docs that match is small then CONSTANT_BOOLEAN_QUERY will win, etc.  If number of terms exceeds BooleanQuery's maxClauseCount, you must use FILTER.\n\nAnd my intuitions weren't right (I had thought NumericRangeQuery, since in general it doesn't produce too many terms, would perform well with BOOLEAN_QUERY, but from Uwe's numbers that's not the case; though we should re-test now that, with this patch, no CPU is spent on scoring).\n\nSo, I was uncomfortable trying to make Lucene too smart under the hood, at least for this first go at it.\n\nMaybe we could add an AUTO option, that would make try to decide what's best?  This way if we mess up its smarts, the user can still fallback and force one method over another.\n\n(Though, since the maxClauseCount is so clearly a dead-end, maybe even in CONSTANT_BOOLEAN_QUERY mode we should forcefully fallback to FILTER on hitting too many terms). ",
            "author": "Michael McCandless",
            "id": "comment-12733563"
        },
        {
            "date": "2009-07-21T10:31:48+0000",
            "content": "Mike, I see your point, I believe two things are involved, but I could be wrong on this!\n\nIn the tests I have run, for \"uncached\" queries that match only a few docs, query is faster.\nFILTER is faster if things are cached or if the query matches many documents, even for a huge index.\n\nI don't think this disagrees with Uwe's numbers really, I just think the OS cache etc plays a big part, at least thats what I thought I was seeing on my end... ",
            "author": "Robert Muir",
            "id": "comment-12733578"
        },
        {
            "date": "2009-07-21T10:51:03+0000",
            "content": "Your results seem to agree w/ Uwe's (once things are \"hot\" then FILTER is even faster, even on a rather large index).  Uwe's results were on a 5M doc index.  How large is your index?\n\nOK so how about I add an CONSTANT_AUTO mode that tries to pick?  I can add [expert] setters that you can use to set the cutoffs.  Then in the javadocs, strongly encourage CONSTANT_AUTO, and state that in 3.0 it'll be the default? ",
            "author": "Michael McCandless",
            "id": "comment-12733582"
        },
        {
            "date": "2009-07-21T11:19:29+0000",
            "content": "Mike: > 100M docs. it does not fit in os cache \n\nI really should rerun tests since its been quite some time.\n\nWhat do you think about CONSTANT_AUTO doing your maxClauseCount trick? ",
            "author": "Robert Muir",
            "id": "comment-12733593"
        },
        {
            "date": "2009-07-21T11:34:40+0000",
            "content": "Mike: > 100M docs. it does not fit in os cache\n\nHeh   OK.\n\nWhat do you think about CONSTANT_AUTO doing your maxClauseCount trick?\n\nI'm thinking there'd be a cutoff on the number of terms.  EG maybe it defaults to 25 .  So, if more than 25 terms are encountered, we'll use FILTER; else we use BOOLEAN_QUERY.  And, then, at all times I'd cutover to FILTER if that threshold exceeds the maxClauseCount. ",
            "author": "Michael McCandless",
            "id": "comment-12733598"
        },
        {
            "date": "2009-07-21T14:21:29+0000",
            "content": "Maybe, we simply go back to the boolean (constant scoring or not), and then add this term count cutoff to control when a filter is used vs BooleanQuery? ",
            "author": "Michael McCandless",
            "id": "comment-12733637"
        },
        {
            "date": "2009-07-21T16:07:45+0000",
            "content": "Mike, I am afraid that might hurt some people's performance.\nI'm a bit concerned my index/queries are maybe abnormal and don't want to break the general case.\n\nI'm not too familiar with trie [what it would do with a really general range query], but a simpler example would be no stopwords, wildcard query of \"th?\" (matching \"the\")\nmaybe it only matches one term, but that term is very common / dense bitset and probably \"hot\".\n\nIn this case the filter would be better, even though its 1 term. ",
            "author": "Robert Muir",
            "id": "comment-12733676"
        },
        {
            "date": "2009-07-21T18:19:39+0000",
            "content": "In this case the filter would be better, even though its 1 term.\n\nYou're right.  So... maybe we could also take the net doc count into account?  Loading the TermInfo shouldn't be costly, since it's loaded anyway when the query/filter runs (and, it's cached).  We'd then sum it up as we're checking, and if it crosses the threshold (default maybe 10% of maxDoc()?) we'd cut out to FILTER?\n\nThough, if we go this route, we should probably do it under a new CONSTANT_AUTO method (instead of falling back to the clean single boolean constantScoreRewrite), ie, it's getting a little too smart to just always do w/ no way to fallback and force it to just rewrite one way or another.\n\nOr we can punt on any smarts altogether for now (this being the \"eve\" of 2.9) and simply start with the three explicit rewrite methods. ",
            "author": "Michael McCandless",
            "id": "comment-12733769"
        },
        {
            "date": "2009-07-21T18:43:49+0000",
            "content": "Mike, that heuristic sounds really promising to me.\n\nat the same time, starting to think your .setMultiTermRewriteMethod really is the right way to go (regardless of whether it immediately has AUTO)...\n\nthe thing i never really liked about .setConstantScoreRewrite is that its kinda misleading, since it really does more than just toggle scoring... ",
            "author": "Robert Muir",
            "id": "comment-12733775"
        },
        {
            "date": "2009-07-21T18:55:01+0000",
            "content": "Or we can punt on any smarts altogether for now (this being the \"eve\" of 2.9) and simply start with the three explicit rewrite methods.\n\n+1 - unless you just want to pump it out, we want to make the current change anyway I think, so lets leave it at that and add an auto later.\n\nWe should get 2.9 out sooner rather than later I think. ",
            "author": "Mark Miller",
            "id": "comment-12733781"
        },
        {
            "date": "2009-07-21T19:08:24+0000",
            "content": "Mike, sorry to flip back and forth on this since last night. \n\nThe patch you have here does make things less confusing and I think that after talking things thru, the \"big boolean option\" with heuristics might actually make things more confusing, even if its seems convenient at first.\n\nin the future the AUTO would be a good feature I think, best of both worlds. ",
            "author": "Robert Muir",
            "id": "comment-12733786"
        },
        {
            "date": "2009-07-21T21:22:42+0000",
            "content": "Attached rough patch \u2013 javadocs are missing/not\nupdated, need to add new tests, need to fix QueryParser.jj, etc., but\nall tests pass.\n\nHere's what I did:\n\n\n\tChanged the MTQ.RewriteMethod class from a simple Parameter to its\n    own abstract base class w/ a single method, rewrite, which\n    MultiTermQuery.rewrite delegates to.\n\n\n\n\n\tSwitched over CONSTANT_SCORE_FILTER_REWRITE,\n    SCORING_BOOLEAN_QUERY_REWRITE and\n    CONSTANT_SCORE_BOOLEAN_QUERY_REWRITE.  These classes are private\n    (they have no configuration), and I created final static singleton\n    instances for them.\n\n\n\n\n\tCreated ConstantScoreAutoRewrite (and the default\n    CONSTANT_SCORE_AUTO_REWRITE instance) that you can configure based\n    on term count & doc count, as to when it cuts over to\n    CONSTANT_SCORE_FILTER_REWRITE.\n\n\n\nThis approach also has the benefit of allowing customization entirely,\nif needed, of the \"rewrite strategy\", if none of the 4 choices work\nfor you.\n ",
            "author": "Michael McCandless",
            "id": "comment-12733836"
        },
        {
            "date": "2009-07-22T10:37:07+0000",
            "content": "Sorry that I came back too late to this issue, I am in holidays at the moment.\n\nIn my opinion, the Parameter instead of boolean is a good idea. The latest patch is also a good idea, I only hve some small problems with it:\n\n\tWhy did you make so many internal things public? The additional ctor to MultiTermQueryrapperFilter should be package-private or protected (the class is not abstract, but should be used like abstract, so it ,must have only protected ctors). Only the public instances TermRangeFilter should have public ctors.\n\tgetFilter()/getEnum should stay protected.\n\tI do not like the wired caching of Terms. A more cleaner API would be a new class CachingFilteredTermEnum, that can turn on caching for e.g. the first 20 terms and then reset. In this case, the API would stay clear and the filter code does not need to be changed at all (it just harvests the TermEnum, if it is cached or not). I would propose something like: new CachingFilteredTermEnum(originalEnum), use it normally, then termEnum.reset() to consume again and termEnum.purgeCache() if caching no longer needed and to be switched off (after the first 25 terms or so). The problem with MultiTermQueryWrapper filter is, that the filter is normally stateless (no reader or termenum). So normally the method getDocIdSet() should get the termenum or wrapper in addition to the indexreader. This is not very good (it took me some time, to understand, what you are doing).\n\n ",
            "author": "Uwe Schindler",
            "id": "comment-12734067"
        },
        {
            "date": "2009-07-22T10:48:06+0000",
            "content": "The biggest problem is, that this caching gets completely wired with multi-segment indexes:\nThe rewriting is done on the top-level reader. In this case the boolean query would be built and the terms cached. If there are too many terms, it creates a filter instance with the cached terms.\nThe rewritten query is then executed against all sub-readers using the cached terms and a fixed term enum. Normally this would create a docidset for the current index reader, the rewrite did it for the top-level index reader -> the wron doc ids are returned and so on. So you cannot reuse the collected terms from the rewrite operation in the getDocIdSet calls.\n\nSo please turn of this caching at all! As noted before, the important thing is, that the returned filter by rewrite is stateless and should not know anythis about index readers. The idex reader is passed in getDocIdSet any is different for non-optimized indexes.\n\nYou have seen no tests fail, because all RangeQuery tests use optimized indexes. ",
            "author": "Uwe Schindler",
            "id": "comment-12734070"
        },
        {
            "date": "2009-07-22T12:41:26+0000",
            "content": "The biggest problem is, that this caching gets completely wired with multi-segment indexes\n\nRight, I caught this as well (there is one test that fails when I forcefully swap in constant-boolean-query as the constant score method), and I'm now turning off the caching.\n\nI've fixed it locally \u2013 will post a new rev soon. ",
            "author": "Michael McCandless",
            "id": "comment-12734096"
        },
        {
            "date": "2009-07-22T16:47:31+0000",
            "content": "Attached patch: fixed some bugs in the last rev, updated test cases,\njavadocs, CHANGES.  I also optimized MultiTermQueryWrapperFilter to\nuse the bulk-read API from termDocs.\n\nI confirmed all tests pass if I temporarily switch\nCONSTANT_SCORE_FILTER_REWRITE to CONSTANT_SCORE_AUTO_REWRITE_DEFAULT.\n\nI changed QueryParser to use CONSTANT_SCORE_AUTO for rewrite (it was\npreviously CONSTANT_FILTER).\n\nI still need to run some perf tests to get a rough sense of decent\ndefaults for CONSTANT_SCORE_AUTO cutover thresholds.\n\ngetFilter()/getEnum should stay protected.\n\nOK I made getEnum protected again.\n\nI had tentatively made it public so that one could create their own\n[external] rewrite methods.  But I think (if we leave it protected),\none could still make an inner/nested class that can access getEnum().\n\nDo we even need getFilter()?  I removed it in the patch. ",
            "author": "Michael McCandless",
            "id": "comment-12734188"
        },
        {
            "date": "2009-07-22T20:36:16+0000",
            "content": "Hi Mike,\n\npatch looks good. I was a little bit confused about the high term number cut off, but it is using Math.max to limit it to the current BooleanQuery max clause count.\n\nSome small things:\n\nOK I made getEnum protected again.\n\n...but only in MultiTermQuery itsself. Everywhere else (even in the backwards compatibility override test [JustCompile] it is public). And the same should be for the incNumberOfTerms (also protected). I think the rewrite method is internal to MultiTermQuery and always implemented ina subclass of MTQ as inner class.\n\nAlso the current singletons are not really singletons, because queries that are unserialized will contain instances that are not the \"singleton\" instances  - and will therefore fail to produce correct hashcode/equals tests. The problem behind: The singletons are serializable but do not return itsself in readResolve() (not implemented). All singletons that are serializable must implement readResolve and return the singleton instance (see Parameter base class or the parser singletons in FieldCache).\n\nThe instance in the default Auto RewriteMethod is still modifiable. Is this correct? So one could modify the defaults by setting properties in this instance. Is this correct? ",
            "author": "Uwe Schindler",
            "id": "comment-12734301"
        },
        {
            "date": "2009-07-23T00:36:28+0000",
            "content": "I was a little bit confused about the high term number cut off,\n\nSorry I still need to do some perf testing to pick an appropriate\ndefault here.\n\nEverywhere else (even in the backwards compatibility override test [JustCompile] it is public).  And the same should be for the incNumberOfTerms (also protected).\n\nWoops \u2013 I'll fix.  Thanks for catching even though you're on\n\"vacation\" \n\nAlso the current singletons are not really singletons, because queries that are unserialized will contain instances that are not the \"singleton\" instances\n\nSigh.  I'll do what FieldCache's parser singletons do.\n\nThe instance in the default Auto RewriteMethod is still modifiable. Is this correct?\n\nI was thinking this was OK, ie, you could set the default cutoffs for\nanything that used the AUTO_DEFAULT.  But it is static (global), so\nthat's not great.  I guess I'll make it an anonymous subclass of\nConstantScoreAutoRewrite that disallows changes. ",
            "author": "Michael McCandless",
            "id": "comment-12734411"
        },
        {
            "date": "2009-07-23T00:46:03+0000",
            "content": "New patch attached w/ above fixes plus some javadoc fixes.  It has\nsome nocommits which I'll clean up before committing. ",
            "author": "Michael McCandless",
            "id": "comment-12734413"
        },
        {
            "date": "2009-07-23T11:39:59+0000",
            "content": "New patch attached.  I think it's ready to commit!\n\nI ran a series of simple tests, using a 20.0 million doc Wikipedia\nindex. I tested w/ PrefixQuery, using different prefixes to tickle the\ndifferent number of matching terms vs matching docs.\n\nI first pursued the \"matches many terms but few docs\" case, and found\nat around 350 terms the filter method becomes faster.\n\nThen, I fixed the number of terms at 350 (modified PrefixQuery to\npretend the enum stopped there) and tested different number of \"doc\nvisit counts\" (sum of docFreq of each term) and found ~ 0.1% (1/1000)\nof the maxDoc() was the cutover.\n\nI also switched NumericRange* to use CONSTANT_SCORE_AUTO by default. ",
            "author": "Michael McCandless",
            "id": "comment-12734561"
        },
        {
            "date": "2009-07-23T12:01:16+0000",
            "content": "Looks good, Mike.\n\nI think NumericRangeQuery should also be swiched to auto mode, you are right. My perf test was a little bit unfair, because it used a 5 Mio index with random integers. The queries were also random and the sum of docs/index size was about 1/3 (because of the random query). So most quries hit abou one third of all docs. In this case, always the filter is faster. For very small ranges with few terms, it may be really good to use \n\nA good thing would also be to set the mode to filter automatically, if precisionStep >6 for longs (valSize=64) and precStep > 8 for ints (valSize=32), because here the number of terms is often too big.\n\nOne bug in ConstantScoreRangeQuery: You set the default to AUTO, the method to prevent changing this is wrong:\n\n   /** Changes of mode are not supported by this class (fixed to constant score rewrite mode) */\n-  public void setConstantScoreRewrite(boolean constantScoreRewrite) {\n-    if (!constantScoreRewrite)\n-      throw new UnsupportedOperationException(\"Use TermRangeQuery instead to enable boolean query rewrite.\");\n+  public void setRewriteMethod(RewriteMethod method) {\n+    if (method != CONSTANT_SCORE_FILTER_REWRITE) {\n+      throw new UnsupportedOperationException(\"Use TermRangeQuery instead to change the rewrite method.\");\n+    }\n   }\n\n\nI would change this to simply always throw UOE on any change in ConstantScoreRangeQuery. ",
            "author": "Uwe Schindler",
            "id": "comment-12734570"
        },
        {
            "date": "2009-07-23T12:03:30+0000",
            "content": "Another question: Maybe it would be good to change the FieldCache to also use the buffered TermDocs variant in the Uninverter code?\nHas done anybody perf tests here. It would be easy to change this. ",
            "author": "Uwe Schindler",
            "id": "comment-12734571"
        },
        {
            "date": "2009-07-23T12:47:34+0000",
            "content": "I would change this to simply always throw UOE on any change in ConstantScoreRangeQuery.\n\nOK will do.\n\nA good thing would also be to set the mode to filter automatically, if precisionStep >6 for longs (valSize=64) and precStep > 8 for ints (valSize=32), because here the number of terms is often too big.\n\nWill do.\n\nHmm \u2013 my last patch hit this test failure, after I had switched to CONSTANT_SCORE_AUTO for NumericRangeQuery:\n\n    [junit] NOTE: random seed of testcase 'testRandomTrieAndClassicRangeQuery_NoTrie' was: -2919237198484373178\n    [junit] ------------- ---------------- ---------------\n    [junit] Testcase: testRandomTrieAndClassicRangeQuery_NoTrie(org.apache.lucene.search.TestNumericRangeQuery32):\tFAILED\n    [junit] Total number of terms should be equal for unlimited precStep expected:<668552> but was:<668584>\n    [junit] junit.framework.AssertionFailedError: Total number of terms should be equal for unlimited precStep expected:<668552> but was:<668584>\n    [junit] \tat org.apache.lucene.search.TestNumericRangeQuery32.testRandomTrieAndClassicRangeQuery(TestNumericRangeQuery32.java:266)\n    [junit] \tat org.apache.lucene.search.TestNumericRangeQuery32.testRandomTrieAndClassicRangeQuery_NoTrie(TestNumericRangeQuery32.java:287)\n    [junit] \tat org.apache.lucene.util.LuceneTestCase.runTest(LuceneTestCase.java:88)\n    [junit] \n\n\nI haven't dug into it yet... ",
            "author": "Michael McCandless",
            "id": "comment-12734583"
        },
        {
            "date": "2009-07-23T13:15:17+0000",
            "content": "Hmm - my last patch hit this test failure, after I had switched to CONSTANT_SCORE_AUTO for NumericRangeQuery:\n\nHeh \u2013 so I tried to repeat the failure, and couldn't.  The I remembered that nice random seed that was printed out, so I went to the test and wired that seed and BOOM the failure happened.  Thank you Hoss \n\nI found the failure \u2013 I was just failing to incr the term count in the \"auto uses BooleanQuery\" case.  New patch soon... ",
            "author": "Michael McCandless",
            "id": "comment-12734590"
        },
        {
            "date": "2009-07-23T13:17:47+0000",
            "content": "New patch.  I'll commit in a day or two, though I'll wait first for LUCENE-1693 to go in (it'll conflict on QueryParser.jj/java). ",
            "author": "Michael McCandless",
            "id": "comment-12734591"
        },
        {
            "date": "2009-07-23T13:24:33+0000",
            "content": "You were faster. The problem was the missing update of term count. I first thought, that you maybe counting the terms two times (one time at the beginning and then again in the filter, if the auto mode switches). But you are now only updating the term count at the end when you build the boolean query.\n\nBy the way: How about initializing the ArrayList not with the default size, but maybe termCount cutoff/2 or something like that? ",
            "author": "Uwe Schindler",
            "id": "comment-12734592"
        },
        {
            "date": "2009-07-23T14:32:28+0000",
            "content": "How about initializing the ArrayList not with the default size, but maybe termCount cutoff/2 or something like that?\n\nThat makes me a bit nervous, eg if someone sets these limits to something immense? ",
            "author": "Michael McCandless",
            "id": "comment-12734603"
        },
        {
            "date": "2009-07-25T00:03:58+0000",
            "content": "Thanks Uwe! ",
            "author": "Michael McCandless",
            "id": "comment-12735211"
        }
    ]
}