{
    "id": "SOLR-7030",
    "title": "replicas goes in recovery mode right after update",
    "details": {
        "components": [
            "SolrCloud"
        ],
        "type": "Bug",
        "labels": "",
        "fix_versions": [],
        "affect_versions": "4.10.1",
        "status": "Closed",
        "resolution": "Invalid",
        "priority": "Major"
    },
    "description": "We have a cluster of solr cloud server with 10 shards and 4 replicas in each shard in our stress environment.  In our prod environment we will have 10 shards and 15 replicas in each shard.  Our current commit settings are as follows\n\n        <autoSoftCommit>\n            <maxDocs>500000</maxDocs>\n            <maxTime>180000</maxTime>\n        </autoSoftCommit>\n\n        <autoCommit>\n            <maxDocs>2000000</maxDocs>\n            <maxTime>180000</maxTime>\n            <openSearcher>false</openSearcher>\n        </autoCommit>\n\nWe indexed roughly 90 Million docs. We have two different ways to index documents \na)\tFull indexing. It takes 4 hours to index 90 Million docs and the rate of docs coming to the searcher is around 6000 per second\nb)\tIncremental indexing. It takes an hour to indexed delta changes. Roughly there are 3 million changes and rate of docs coming to the searchers is 2500 per second \n\nWe have two collections search1 and search2. When we do full indexing , we do it in search2 collection while search1 is serving live traffic. After it finishes we swap the collection using aliases so that the search2 collection serves live traffic while search1 becomes available for next full indexing run. \nWhen we do incremental indexing we do it in the search1 collection which is serving live traffic.\n\nAll our searchers have 12 GB of RAM available and have quad core  Intel(R) Xeon(R) CPU X5570  @ 2.93GHz\nWe have observed the following issue when we trigger indexing . \nIn about 10 minutes after we trigger indexing on 14 parallel hosts, the replicas goes in to recovery mode. This happens to all the shards . In about 20 minutes more and more replicas start going into recovery mode. After about half an hour all replicas except the leader are in recovery mode. We cannot throttle the indexing load as that will increase our overall indexing time. So to overcome this issue, we remove all the replicas before we trigger the indexing and then add them back after the indexing finishes.\n\nWe observe the same behavior of replicas going into recovery when we do incremental indexing. We cannot remove replicas during our incremental indexing because it is also serving live traffic. We tried to throttle our indexing speed , however the cluster still goes into recovery .\n\nIf we leave the cluster as it , when the indexing finishes , it eventually recovers after a while. As it is serving live traffic we cannot have these replicas go into recovery mode because it degrades the search performance also , our tests have shown. \n\nWe have tried different commit settings like below\na)\tNo auto soft commit, no auto hard commit and a commit triggered at the end of indexing\nb)\tNo auto soft commit, yes auto hard commit and a commit in the end of indexing\nc)\tYes auto soft commit , no auto hard commit \nd)\tYes auto soft commit , yes auto hard commit \ne)\tDifferent frequency setting for commits for above\nUnfortunately all the above yields the same behavior . The replicas still goes  in recovery\nWe have increased the zookeeper timeout from 30 seconds to 5 minutes and the problem persists. \nIs there any setting that would fix this issue ?",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "date": "2015-01-25T17:43:04+0000",
            "author": "Shawn Heisey",
            "content": "This should have been brought up on the mailing list, or possibly IRC, not the bug tracker.\n\nhttps://wiki.apache.org/solr/IRCChannels\nhttp://lucene.apache.org/solr/resources.html#community\n\nBased on the indexing rates you have mentioned, I'm fairly sure that the maxTime value you have for autoCommit and autoSoftCommit is what will be used \u2013 you'll never reach half a million or two million new documents in three minutes.  Since this means they effectively have the same config, the recommendation would be to remove autoSoftCommit and just add openSearcher=true to autoCommit.  If you want to use both, they should have different configs so that they aren't happening at the same time.\n\nWe really need to move discussion to the mailing list, but there are some initial questions:\n\nIs that 12GB of RAM the total amount of RAM on each server?  If so, how much of that 12GB is dedicated to the Java heap and other programs on the system, and what is the total size of all Solr indexes on each machine?\n\nI will close this issue, if discussion does turn up a bug, then we can re-open. ",
            "id": "comment-14291194"
        },
        {
            "date": "2015-01-25T21:13:42+0000",
            "author": "Vijay Sekhri",
            "content": "Thank you Shawn. I have posted my question to both IRC and mailing list.\nFYI \nAll our searchers have 12 GB of RAM available and have quad core Intel(R) Xeon(R) CPU X5570 @ 2.93GHz. There is only one java process running i.e jboss and solr in it . All 12 GB is available as heap for the java process.  We have observed that the heap memory of the java process average around 8 - 10 GB from the admin console. All searchers have final index size of 9 GB. So in total there are 9X10 (shards) =  90GB worth of index files (after the indexing finishes).\n\nPlease also NOTE that we have tried 15 minute soft commit setting and 30 minutes hard commit settings. Same time settings for both, 30 minute soft commit and an hour hard commit setting already. The only option we have not tried is the auto commit with open searcher true. We will give that a try also. We have even tried no commit what so ever option. We observed the tlogs growing huge as that was expected , however the replicas still after a while goes in recovery. \nMy suspicion is that solr cloud is unable to keep up with the updates at the rate we are sending while it is trying to be consistent with all the replicas. ",
            "id": "comment-14291273"
        },
        {
            "date": "2015-01-26T00:11:46+0000",
            "author": "Vijay Sekhri",
            "content": "I am sorry I had wrong information posted. I posted our DEV env configuration by mistake.\nAfter double checking our stress and Prod Beta env where we have found the original issue, I found all the searchers have around 50 GB of RAM available and two instances of JVM running (2 different ports). Both instances have 12 GB allocated. The rest 26 GB is available for the OS. 1st  instance on a host has search1 collection (live collection) and the 2nd instance on the same host  has search2 collection (for full indexing ). ",
            "id": "comment-14291316"
        }
    ]
}