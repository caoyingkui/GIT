{
    "id": "SOLR-6591",
    "title": "Cluster state updates can be lost on exception in main queue loop",
    "details": {
        "components": [
            "SolrCloud"
        ],
        "type": "Bug",
        "labels": "",
        "fix_versions": [
            "5.0",
            "6.0"
        ],
        "affect_versions": "6.0",
        "status": "Closed",
        "resolution": "Fixed",
        "priority": "Major"
    },
    "description": "I found this bug while going through the failure on jenkins:\nhttps://builds.apache.org/job/Lucene-Solr-NightlyTests-trunk/648/\n\n\n2 tests failed.\nREGRESSION:  org.apache.solr.cloud.CollectionsAPIDistributedZkTest.testDistribSearch\n\nError Message:\nError CREATEing SolrCore 'halfcollection_shard1_replica1': Unable to create core [halfcollection_shard1_replica1] Caused by: Could not get shard id for core: halfcollection_shard1_replica1\n\nStack Trace:\norg.apache.solr.client.solrj.impl.HttpSolrServer$RemoteSolrException: Error CREATEing SolrCore 'halfcollection_shard1_replica1': Unable to create core [halfcollection_shard1_replica1] Caused by: Could not get shard id for core: halfcollection_shard1_replica1\n        at org.apache.solr.client.solrj.impl.HttpSolrServer.executeMethod(HttpSolrServer.java:570)\n        at org.apache.solr.client.solrj.impl.HttpSolrServer.request(HttpSolrServer.java:215)\n        at org.apache.solr.client.solrj.impl.HttpSolrServer.request(HttpSolrServer.java:211)\n        at org.apache.solr.cloud.CollectionsAPIDistributedZkTest.testErrorHandling(CollectionsAPIDistributedZkTest.java:583)\n        at org.apache.solr.cloud.CollectionsAPIDistributedZkTest.doTest(CollectionsAPIDistributedZkTest.java:205)\n        at org.apache.solr.BaseDistributedSearchTestCase.testDistribSearch(BaseDistributedSearchTestCase.java:869)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:606)\n        at com.carrotsearch.randomizedtesting.RandomizedRunner.invoke(RandomizedRunner.java:1618)",
    "attachments": {
        "SOLR-6591-constructStateFix.patch": "https://issues.apache.org/jira/secure/attachment/12677293/SOLR-6591-constructStateFix.patch",
        "SOLR-6591-no-mixed-batches.patch": "https://issues.apache.org/jira/secure/attachment/12677388/SOLR-6591-no-mixed-batches.patch",
        "SOLR-6591-ignore-no-collection-path.patch": "https://issues.apache.org/jira/secure/attachment/12678963/SOLR-6591-ignore-no-collection-path.patch",
        "SOLR-6591.patch": "https://issues.apache.org/jira/secure/attachment/12677107/SOLR-6591.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2014-10-06T10:16:21+0000",
            "author": "Shalin Shekhar Mangar",
            "content": "What happens here is:\n\n\tThe Stress Collection Creation thread in that test is trying to create collections (which have stateFormat=2)\n\tThe overseer gets a \"state\" message from a new core created using core admin API. This should implicitly create a new collection:\n\n   [junit4]   2> 561673 T45931 oasc.Overseer$ClusterStateUpdater.updateState Update state numShards=1 message={\n   [junit4]   2>          \"collection\":\"halfcollectionblocker\",\n   [junit4]   2>          \"base_url\":\"http://127.0.0.1:42021\",\n   [junit4]   2>          \"state\":\"down\",\n   [junit4]   2>          \"numShards\":\"1\",\n   [junit4]   2>          \"node_name\":\"127.0.0.1:42021_\",\n   [junit4]   2>          \"roles\":null,\n   [junit4]   2>          \"shard\":null,\n   [junit4]   2>          \"operation\":\"state\",\n   [junit4]   2>          \"core\":\"halfcollection_shard1_replica1\"}\n   [junit4]   2> 561674 T45931 oasc.Overseer$ClusterStateUpdater.createCollection Create collection halfcollectionblocker with shards [shard1]\n   [junit4]   2> 561674 T45931 oasc.Overseer$ClusterStateUpdater.createCollection state version halfcollectionblocker 1\n   [junit4]   2> 561679 T45931 oasc.Overseer$ClusterStateUpdater.updateState Assigning new node to shard shard=shard1\n\n\n\tRight after the above message, the overseer gets a message to create 'awholynewstresscollection_collection4_1' (I'm assuming through a \"state\" message). This fails with the following message:\n\n   [junit4]   2> 561682 T45931 oasc.Overseer$ClusterStateUpdater.run ERROR Exception in Overseer main queue loop org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /collections/awholynewstresscollection_collection4_1/state.json\n   [junit4]   2>        at org.apache.zookeeper.KeeperException.create(KeeperException.java:111)\n   [junit4]   2>        at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)\n   [junit4]   2>        at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:783)\n   [junit4]   2>        at org.apache.solr.common.cloud.SolrZkClient$9.execute(SolrZkClient.java:382)\n   [junit4]   2>        at org.apache.solr.common.cloud.SolrZkClient$9.execute(SolrZkClient.java:379)\n   [junit4]   2>        at org.apache.solr.common.cloud.ZkCmdExecutor.retryOperation(ZkCmdExecutor.java:61)\n   [junit4]   2>        at org.apache.solr.common.cloud.SolrZkClient.create(SolrZkClient.java:379)\n   [junit4]   2>        at org.apache.solr.cloud.Overseer$ClusterStateUpdater.updateZkStates(Overseer.java:358)\n   [junit4]   2>        at org.apache.solr.cloud.Overseer$ClusterStateUpdater.run(Overseer.java:311)\n   [junit4]   2>        at java.lang.Thread.run(Thread.java:745)\n   [junit4]   2>\n\n\n\tThis exception causes the \"state\" messaged executed for 'halfcollectionblocker' collection to be lost. The message is still present in the work queue but because the overseer is healthy, it will continue to execute the main queue.\n\n   [junit4]   2> 881993 T46259 oasc.ZkController.waitForShardId waiting to find shard id in clusterstate for halfcollection_shard1_replica1\n   [junit4]   2> 1202711 T46259 oasc.CoreContainer.create ERROR Error creating core [halfcollection_shard1_replica1]: Could not get shard id for core: halfcollection_shard1_replica1 org.apache.solr.common.SolrException: Could not get shard id for core: halfcollection_shard1_replica1\n   [junit4]   2>        at org.apache.solr.cloud.ZkController.waitForShardId(ZkController.java:1425)\n   [junit4]   2>        at org.apache.solr.cloud.ZkController.doGetShardIdAndNodeNameProcess(ZkController.java:1371)\n   [junit4]   2>        at org.apache.solr.cloud.ZkController.preRegister(ZkController.java:1513)\n   [junit4]   2>        at org.apache.solr.core.CoreContainer.create(CoreContainer.java:504)\n   [junit4]   2>        at org.apache.solr.core.CoreContainer.create(CoreContainer.java:484)\n   [junit4]   2>        at org.apache.solr.handler.admin.CoreAdminHandler.handleCreateAction(CoreAdminHandler.java:575)\n\n\n\n ",
            "id": "comment-14160156"
        },
        {
            "date": "2014-10-06T10:16:56+0000",
            "author": "Shalin Shekhar Mangar",
            "content": "This bug affects trunk and branch_5x only. It was introduced after SOLR-5473 and does not affect any released version of Solr. ",
            "id": "comment-14160157"
        },
        {
            "date": "2014-10-06T17:42:36+0000",
            "author": "Noble Paul",
            "content": "Shalin Shekhar Mangar this would not happen when the collection is created through the collection API? ",
            "id": "comment-14160563"
        },
        {
            "date": "2014-10-06T18:24:58+0000",
            "author": "Shalin Shekhar Mangar",
            "content": "Noble Paul - I don't think this is affected by how a collection is created. The gist of the issue is that any exception thrown in updateZkStates for state version > 1 can cause updates for the main cluster state to be lost. ",
            "id": "comment-14160627"
        },
        {
            "date": "2014-10-16T08:13:59+0000",
            "author": "Shalin Shekhar Mangar",
            "content": "So there are two separate bugs at play here:\n\n\n\tDue to an exception in persisting a collection with state format > 1. main cluster state events can be lost\n\tA rapid create+delete loop for collections with state format > 1 causes the above exception to happen. This is because the updateZkState method assumes that the collection exists and it tries to write to /collections/collection_name/state.json directly without verifying whether the /collections/collection_name zk node exists\n\n ",
            "id": "comment-14173521"
        },
        {
            "date": "2014-10-25T14:49:52+0000",
            "author": "Shalin Shekhar Mangar",
            "content": "I found a related (same?) bug while investigating #2 above. The overseer loop can sometimes use stale cluster state for collections with stateFormat > 1. This happens because ZkStateReader.removeZKWatch removes collection from the 'watchedCollections' set but doesn't remove the cached state in the watchedCollectionStates map. So when the replica of a collection is unloaded, the watch is also removed but the cached state still exists. If the overseer happens to be on the same node which had hosted the replica then it will continue reading the old state causing replica information or leader information to be lost.\n\nI've added a test which reproduces the problem (it hangs for a long time on getLeaderRetry before failing to create the collection). The patch fixes the problem by removing collection from watchedCollectionStates in ZkStateReader.removeZKWatch. ",
            "id": "comment-14184114"
        },
        {
            "date": "2014-10-25T19:20:30+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1634243 from shalin@apache.org in branch 'dev/trunk'\n[ https://svn.apache.org/r1634243 ]\n\nSOLR-6591: Overseer can use stale cluster state and lose updates for collections with stateFormat > 1 ",
            "id": "comment-14184228"
        },
        {
            "date": "2014-10-25T19:30:47+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1634246 from shalin@apache.org in branch 'dev/branches/branch_5x'\n[ https://svn.apache.org/r1634246 ]\n\nSOLR-6591: Overseer can use stale cluster state and lose updates for collections with stateFormat > 1 ",
            "id": "comment-14184230"
        },
        {
            "date": "2014-10-27T13:15:44+0000",
            "author": "Shalin Shekhar Mangar",
            "content": "The overseer can still use stale cached cluster state because ZkStateReader.updateClusterState returns cached state for watched collections. Here is a patch which fixes that by reading collection state live during ZkStateReader.updateClusterState and setting it into the watchedCollectionStates map. ",
            "id": "comment-14185118"
        },
        {
            "date": "2014-10-27T14:51:10+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1634554 from shalin@apache.org in branch 'dev/trunk'\n[ https://svn.apache.org/r1634554 ]\n\nSOLR-6591: ZkStateReader.updateClusterState should refresh cluster state for watched collections ",
            "id": "comment-14185205"
        },
        {
            "date": "2014-10-27T14:53:34+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1634555 from shalin@apache.org in branch 'dev/branches/branch_5x'\n[ https://svn.apache.org/r1634555 ]\n\nSOLR-6591: ZkStateReader.updateClusterState should refresh cluster state for watched collections ",
            "id": "comment-14185207"
        },
        {
            "date": "2014-10-27T19:54:55+0000",
            "author": "Shalin Shekhar Mangar",
            "content": "Right now main cluster states are batched together and updates to collections with stateFormat > 1 are not batched (I'll create another issue for that). However updates to both can be mixed together e.g. if overseer gets 5 messages for main cluster state and then 1 for stateFormat > 1 then the resulting updates are written to ZK together. This is error prone and we shouldn't batch updates for different stateFormats together.\n\nThis patch tracks the last stateFormat for which message was processed and breaks out of the loop if a different one is encountered. ",
            "id": "comment-14185704"
        },
        {
            "date": "2014-10-27T20:56:42+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1634684 from shalin@apache.org in branch 'dev/trunk'\n[ https://svn.apache.org/r1634684 ]\n\nSOLR-6591: Do not batch updates for different stateFormats together ",
            "id": "comment-14185798"
        },
        {
            "date": "2014-10-27T20:57:07+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1634685 from shalin@apache.org in branch 'dev/branches/branch_5x'\n[ https://svn.apache.org/r1634685 ]\n\nSOLR-6591: Do not batch updates for different stateFormats together ",
            "id": "comment-14185800"
        },
        {
            "date": "2014-11-03T16:53:17+0000",
            "author": "Shalin Shekhar Mangar",
            "content": "\nA rapid create+delete loop for collections with state format > 1 causes the above exception to happen. This is because the updateZkState method assumes that the collection exists and it tries to write to /collections/collection_name/state.json directly without verifying whether the /collections/collection_name zk node exists\n\nThis patch ignores state messages which are trying to create new collections when the parent zk path doesn't exist. I've added the following comment in the code to explain the situation:\n\n                 // if the /collections/collection_name path doesn't exist then it means that\n                  // 1) the user invoked a DELETE collection API and the OverseerCollectionProcessor has deleted\n                  // this zk path.\n                  // 2) these are most likely old \"state\" messages which are only being processed now because\n                  // if they were new \"state\" messages then in legacy mode, a new collection would have been \n                  // created with stateFormat = 1 (which is the default state format)\n                  // 3) these can't be new \"state\" messages created for a new collection because\n                  // otherwise the OverseerCollectionProcessor would have already created this path\n                  // as part of the create collection API call \u2013 which is the only way in which a collection\n                  // with stateFormat > 1 can possibly be created\n ",
            "id": "comment-14194721"
        },
        {
            "date": "2014-11-03T17:15:37+0000",
            "author": "Shalin Shekhar Mangar",
            "content": "With the right patch (SOLR-6591-ignore-no-collection-path.patch) this time. ",
            "id": "comment-14194744"
        },
        {
            "date": "2014-11-03T17:30:05+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1636400 from shalin@apache.org in branch 'dev/trunk'\n[ https://svn.apache.org/r1636400 ]\n\nSOLR-6591: Ignore overseer operations for collections with stateFormat > 1 if the parent ZK path doesn't exist ",
            "id": "comment-14194756"
        },
        {
            "date": "2014-11-03T17:31:27+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1636401 from shalin@apache.org in branch 'dev/branches/branch_5x'\n[ https://svn.apache.org/r1636401 ]\n\nSOLR-6591: Ignore overseer operations for collections with stateFormat > 1 if the parent ZK path doesn't exist ",
            "id": "comment-14194760"
        },
        {
            "date": "2015-02-23T05:02:14+0000",
            "author": "Anshum Gupta",
            "content": "Bulk close after 5.0 release. ",
            "id": "comment-14332846"
        }
    ]
}