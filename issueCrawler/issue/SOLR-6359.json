{
    "id": "SOLR-6359",
    "title": "Allow customization of the number of records and logs kept by UpdateLog",
    "details": {
        "affect_versions": "None",
        "status": "Closed",
        "fix_versions": [
            "5.1",
            "6.0"
        ],
        "components": [],
        "type": "Improvement",
        "priority": "Minor",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "Currently UpdateLog hardcodes the number of logs and records it keeps, and the hardcoded numbers (100 records, 10 logs) can be quite low (esp. the records) in an heavily indexing setup, leading to full recovery even if Solr was just stopped and restarted.\n\nThese values should be customizable (even if only present as expert options).",
    "attachments": {
        "SOLR-6359.patch": "https://issues.apache.org/jira/secure/attachment/12702473/SOLR-6359.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "ASF GitHub Bot",
            "id": "comment-14091959",
            "date": "2014-08-10T01:13:38+0000",
            "content": "GitHub user andyetitmoves opened a pull request:\n\n    https://github.com/apache/lucene-solr/pull/83\n\n    Customize number of logs and records to keep with UpdateLog\n\n    Patch for SOLR-6359\n\nYou can merge this pull request into a Git repository by running:\n\n    $ git pull https://github.com/bloomberg/lucene-solr trunk-customize-ulog-keep\n\nAlternatively you can review and apply these changes as the patch at:\n\n    https://github.com/apache/lucene-solr/pull/83.patch\n\nTo close this pull request, make a commit to your master/trunk branch\nwith (at least) the following in the commit message:\n\n    This closes #83\n\n\ncommit 66d8ced68fb30624ad32b47bab07c7766d8c7e64\nAuthor: Ramkumar Aiyengar <andyetitmoves@gmail.com>\nDate:   2014-08-10T01:07:28Z\n\n    Customize number of logs and records to keep with UpdateLog\n\n "
        },
        {
            "author": "Ramkumar Aiyengar",
            "id": "comment-14091961",
            "date": "2014-08-10T01:21:03+0000",
            "content": "I haven't currently added these options to the example configs in case they were too obscure, but could add them.. "
        },
        {
            "author": "Forest Soup",
            "id": "comment-14246505",
            "date": "2014-12-15T09:45:55+0000",
            "content": "Is the patch only available for Solr 5.0? For Solr 4.7, can we apply the patch? Thanks! "
        },
        {
            "author": "Ramkumar Aiyengar",
            "id": "comment-14246569",
            "date": "2014-12-15T11:14:04+0000",
            "content": "You might have to resolve conflicts but yeah, nothing in there should be specific to 5.0.. "
        },
        {
            "author": "Forest Soup",
            "id": "comment-14246609",
            "date": "2014-12-15T12:31:01+0000",
            "content": "When could we get the official build with that patch in 4.x or 5.0? "
        },
        {
            "author": "Forest Soup",
            "id": "comment-14246618",
            "date": "2014-12-15T12:55:35+0000",
            "content": "The \"numRecordsToKeep\" and \"maxNumLogsToKeep\" values should be in the <updateLog>.like below.\n    <!-- Enables a transaction log, used for real-time get, durability, and\n         and solr cloud replica recovery.  The log can grow as big as\n         uncommitted changes to the index, so use of a hard autoCommit\n         is recommended (see below).\n         \"dir\" - the target directory for transaction logs, defaults to the\n                solr data directory.  -->\n    <updateLog>\n      <str name=\"dir\">${solr.ulog.dir:}</str>\n      <int name=\"numRecordsToKeep\">10000</int>\n      <int name=\"maxNumLogsToKeep\">100</int>\n    </updateLog> "
        },
        {
            "author": "Forest Soup",
            "id": "comment-14249827",
            "date": "2014-12-17T13:11:47+0000",
            "content": "I applied the patch for SOLR-6359 on 4.7 and did some test. Set below config:\n<updateLog>\n<str name=\"dir\">${solr.ulog.dir:}</str>\n<int name=\"numRecordsToKeep\">10000</int>\n<int name=\"maxNumLogsToKeep\">100</int>\n</updateLog> "
        },
        {
            "author": "Forest Soup",
            "id": "comment-14263763",
            "date": "2015-01-04T06:04:12+0000",
            "content": "it works but with some pre-condition: the 20% newest existing transaction log of the core to be recovered must be newer than the 20% oldest existing transaction log of the good core. "
        },
        {
            "author": "Forest Soup",
            "id": "comment-14263764",
            "date": "2015-01-04T06:05:40+0000",
            "content": "A full snapshot recovery does not clean the tlog of the core being recovered. "
        },
        {
            "author": "Forest Soup",
            "id": "comment-14263807",
            "date": "2015-01-04T09:10:34+0000",
            "content": "The snapshot recovery does not clear tlog of the core being recovered. Is it an issue? "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-14263834",
            "date": "2015-01-04T11:06:49+0000",
            "content": "The snapshot recovery does not clear tlog of the core being recovered. Is it an issue?\n\nNo, that's fine. The last two transaction log references are always kept around in case a peer sync is needed again. "
        },
        {
            "author": "Forest Soup",
            "id": "comment-14264277",
            "date": "2015-01-05T07:24:59+0000",
            "content": "Thanks. But will there be this case?  \nAfter a snapshot recovery of core A is done, the tlog is still out-of-date without any new records from recovery, and it's not cleared. And if the just recovered core(core A) taking the leader role, and another core(core C) is trying to recover from it. As A's tlog contains the old entries without newest ones, will the core C do a peersync only with the old records, but missing the newest ones?\n\nAnd I think the snapshot recovery is because there are too much difference between the 2 cores, so the tlog gap are also too much. So the out-of-date tlog is no longer needed for peersync.\n\nOur testing shows the snapshot recovery does not clean tlog with below steps:\n1, Core A and core B are 2 replicas of a shard.\n2, Core A down, and core B took leader role. And it takes some updates and record them to its tlog.\n3, After A up, it will do recovery from B, and if the difference are too much, A will do snapshot pull recovery. And during the snapshot pull recovery, there is no other update comes in. After the snapshot pull recovery, the tlog of A is not updated, it still does NOT contain any most recent from B. \nAnd the tlog are still out-of-date, although the index of A is already updated.\n4, Core A down again, and core B still remain the leader role, and it takes some other updates and recore them to its tlog.\n5, After A up again, it will do recovery from B. But it found its tlog is still too old. So it will do a snapshot recovery again, which is not necessary.\n\nDo you agree? Thanks! "
        },
        {
            "author": "Ramkumar Aiyengar",
            "id": "comment-14346958",
            "date": "2015-03-04T14:36:21+0000",
            "content": "Taking over this one as well. Mark/Shalin, see attached patch and let me know if this looks good.. "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14351535",
            "date": "2015-03-07T11:43:10+0000",
            "content": "Commit 1664825 from andyetitmoves@apache.org in branch 'dev/trunk'\n[ https://svn.apache.org/r1664825 ]\n\nSOLR-6359: Allow customization of the number of records and logs kept by UpdateLog "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14351536",
            "date": "2015-03-07T11:45:42+0000",
            "content": "Commit 1664826 from andyetitmoves@apache.org in branch 'dev/branches/branch_5x'\n[ https://svn.apache.org/r1664826 ]\n\nSOLR-6359: Allow customization of the number of records and logs kept by UpdateLog "
        },
        {
            "author": "ASF GitHub Bot",
            "id": "comment-14381563",
            "date": "2015-03-26T08:31:36+0000",
            "content": "Github user andyetitmoves closed the pull request at:\n\n    https://github.com/apache/lucene-solr/pull/83 "
        },
        {
            "author": "Forest Soup",
            "id": "comment-14381798",
            "date": "2015-03-26T12:34:06+0000",
            "content": "We have a SolrCloud with 5 solr servers of Solr 4.7.0. There are one collection with 80 shards(2 replicas per shard) on those 5 servers. And we made a patch by merge the code of this fix to 4.7.0 stream. And after applied the patch to our servers with the config changing uploaded to ZooKeeper, we did a restart on one of the 5 solr server, we met some issues on that server.  Below is the details -  \nThe solrconfig.xml we changed:\n<updateLog>\n<str name=\"dir\">$\n{solr.ulog.dir:}\n</str>\n<int name=\"numRecordsToKeep\">10000</int>\n<int name=\"maxNumLogsToKeep\">100</int>\n</updateLog>\n\nAfter we restarted one solr server without other 4 servers are running, we met below exceptions in the restarted one:\nERROR - 2015-03-16 20:48:48.214; org.apache.solr.common.SolrException; org.apache.solr.common.SolrException: Exception writing document id Q049bGx0bWFpbDIxL089bGxwX3VzMQ==41703656!B68BF5EC5A4A650D85257E0A00724A3B to the index; possible analysis error.\n\tat org.apache.solr.update.DirectUpdateHandler2.addDoc(DirectUpdateHandler2.java:164)\n\tat org.apache.solr.update.processor.RunUpdateProcessor.processAdd(RunUpdateProcessorFactory.java:69)\n\tat org.apache.solr.update.processor.UpdateRequestProcessor.processAdd(UpdateRequestProcessor.java:51)\n\tat org.apache.solr.update.processor.DistributedUpdateProcessor.doLocalAdd(DistributedUpdateProcessor.java:703)\n\tat org.apache.solr.update.processor.DistributedUpdateProcessor.versionAdd(DistributedUpdateProcessor.java:857)\n\tat org.apache.solr.update.processor.DistributedUpdateProcessor.processAdd(DistributedUpdateProcessor.java:556)\n\tat org.apache.solr.handler.loader.JavabinLoader$1.update(JavabinLoader.java:96)\n\tat org.apache.solr.client.solrj.request.JavaBinUpdateRequestCodec$1.readOuterMostDocIterator(JavaBinUpdateRequestCodec.java:166)\n\tat org.apache.solr.client.solrj.request.JavaBinUpdateRequestCodec$1.readIterator(JavaBinUpdateRequestCodec.java:136)\n\tat org.apache.solr.common.util.JavaBinCodec.readVal(JavaBinCodec.java:225)\n\tat org.apache.solr.client.solrj.request.JavaBinUpdateRequestCodec$1.readNamedList(JavaBinUpdateRequestCodec.java:121)\n\tat org.apache.solr.common.util.JavaBinCodec.readVal(JavaBinCodec.java:190)\n\tat org.apache.solr.common.util.JavaBinCodec.unmarshal(JavaBinCodec.java:116)\n\tat org.apache.solr.client.solrj.request.JavaBinUpdateRequestCodec.unmarshal(JavaBinUpdateRequestCodec.java:173)\n\tat org.apache.solr.handler.loader.JavabinLoader.parseAndLoadDocs(JavabinLoader.java:106)\n\tat org.apache.solr.handler.loader.JavabinLoader.load(JavabinLoader.java:58)\n\tat org.apache.solr.handler.UpdateRequestHandler$1.load(UpdateRequestHandler.java:92)\n\tat org.apache.solr.handler.ContentStreamHandlerBase.handleRequestBody(ContentStreamHandlerBase.java:74)\n\tat org.apache.solr.handler.RequestHandlerBase.handleRequest(RequestHandlerBase.java:135)\n\tat org.apache.solr.core.SolrCore.execute(SolrCore.java:1916)\n\tat org.apache.solr.servlet.SolrDispatchFilter.execute(SolrDispatchFilter.java:780)\n\tat org.apache.solr.servlet.SolrDispatchFilter.doFilter(SolrDispatchFilter.java:427)\n\tat org.apache.solr.servlet.SolrDispatchFilter.doFilter(SolrDispatchFilter.java:217)\n\tat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)\n\tat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)\n\tat org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:220)\n\tat org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:122)\n\tat org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:171)\n\tat org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:102)\n\tat org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:116)\n\tat org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:408)\n\tat org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1040)\n\tat org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:607)\n\tat org.apache.tomcat.util.net.JIoEndpoint$SocketProcessor.run(JIoEndpoint.java:314)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1156)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:626)\n\tat org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)\n\tat java.lang.Thread.run(Thread.java:804)\nCaused by: org.apache.lucene.store.AlreadyClosedException: this IndexWriter is closed\n\tat org.apache.lucene.index.IndexWriter.ensureOpen(IndexWriter.java:645)\n\tat org.apache.lucene.index.IndexWriter.ensureOpen(IndexWriter.java:659)\n\tat org.apache.lucene.index.IndexWriter.updateDocument(IndexWriter.java:1525)\n\tat org.apache.solr.update.DirectUpdateHandler2.addDoc0(DirectUpdateHandler2.java:236)\n\tat org.apache.solr.update.DirectUpdateHandler2.addDoc(DirectUpdateHandler2.java:160)\n\t... 37 more\n\nIt looks like https://issues.apache.org/jira/browse/SOLR-4605, but I guess it's not the case..\n\nIs it due to txn log reply of the old log entries? Could you please help to explain the root cause of it and how to avoid it?\n\nDoing a rolling restart cannot solve the issue. So we have to do a full outage that stop all 5 solr servers, then start one, wait all cores become \"active\", then start another one. \n\nDo you have any better idea to get quick resolution of those failure? \n\nThanks! "
        },
        {
            "author": "Timothy Potter",
            "id": "comment-14495366",
            "date": "2015-04-15T00:30:49+0000",
            "content": "Bulk close after 5.1 release "
        },
        {
            "author": "David Smiley",
            "id": "comment-15210469",
            "date": "2016-03-24T16:08:42+0000",
            "content": "Maybe I misunderstand the impacts of these configuration options, but why even have a maxNumLogsToKeep?  i.e. why isn't it effectively unlimited?  I don't care how many internal log files the updateLog would like to do its implementation-detail business, so long as I can specify that it has docs added within the last X minutes, and maybe a minimum number of docs.  Sounds reasonable?  Because X minutes allows me to specify a server restart worth of time.  That 'X' minutes is basically the hard auto commit interval, since that's what truncates the current log to a new file.  Ramkumar Aiyengar in your \"heavy indexing setup\" couldn't you have just set the auto commit window large enough to your liking?  \n\nThe current \"numRecordsToKeep\" (defaulting to 100) doesn't say if it's a min or max; it seems to be implemented as a soft maximum \u2013 the oldest log files will be removed to stay under, but we'll always have at least one log file, however big or small it may be.  In my scenario where I basically don't care how many records it actually is (I care about time), I think I can basically ignore this (leave at 100). "
        },
        {
            "author": "Ramkumar Aiyengar",
            "id": "comment-15213679",
            "date": "2016-03-28T00:06:30+0000",
            "content": "Yeah, you are right that you get better control by tweaking one vs the other. With num logs, you can get an approximation to amount of time for which you keep logs (ie number of commits).. I agree that's not exact, and it would be good to have the time itself as a config option.\n.\nThe other option is to leave the num logs at unlimited, and tweak the number of records, which probably helps to protect against going berserk with log sizes if your indexing rates vary wildly. We do this in our setups, ie leave the number of files unlimited, while set the records to keep.. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-15214361",
            "date": "2016-03-28T15:49:57+0000",
            "content": "Maybe I misunderstand the impacts of these configuration options, but why even have a maxNumLogsToKeep? i.e. why isn't it effectively unlimited?\n\nThe reason for having a different number internally has to do with current implementation details and practical system limits.  Each log file is kept open, hence the edge case where someone does add,commit,add,commit over and over will run the system out of file descriptors if num records to keep is high. "
        }
    ]
}