{
    "id": "SOLR-3085",
    "title": "New edismax param mm.autoRelax to aid in fixing the dismax/edismax stopwords mm issue",
    "details": {
        "affect_versions": "None",
        "status": "Resolved",
        "fix_versions": [
            "6.0"
        ],
        "components": [
            "query parsers"
        ],
        "type": "Bug",
        "priority": "Major",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "As discussed here http://search-lucene.com/m/Wr7iz1a95jx and here http://search-lucene.com/m/Yne042qEyCq1 and here http://search-lucene.com/m/RfAp82nSsla DisMax has an issue with stopwords if not all fields used in QF have exactly same stopword lists.\n\nTypical solution is to not use stopwords or harmonize stopword lists across all fields in your QF, or relax the MM to a lower percentag. Sometimes these are not acceptable workarounds, and we should find a better solution.",
    "attachments": {
        "SOLR-3085.patch": "https://issues.apache.org/jira/secure/attachment/12619427/SOLR-3085.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-13197854",
            "date": "2012-02-01T14:22:45+0000",
            "content": "In this thread http://search-lucene.com/m/Tzktd1a95jx James Dyer suggests:\nI do wonder...what if (e)dismax had a flag you could set that would tell it that if any analyzers removed a term, then that term would become optional for any fields for which it remained?  I'm not sure what the development effort would perhaps it would be a nice way to circumvent this problem in a future release...\n\nI like the suggestion. Would this be possible?\n\nTake as example this parsed query (q=the contract&qf=alltags title_en&mm=100%defType=edismax)\n\n+((DisjunctionMaxQuery((alltags:the)~0.01) DisjunctionMaxQuery((title_en:contract | alltags:contract)~0.01))~2)\n\n\n\nThe field \"alltags\" does not use stopwords, but \"title_en\" does. So we get a required DisMax Query for alltags:the which does not match any docs. Is it possible in the (e)DisMax code to detect this and make the first DisMax query optional? "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13198104",
            "date": "2012-02-01T20:08:37+0000",
            "content": "So we get a required DisMax Query for alltags:the which does not match any docs. \n\nI think you are missreading that output...\n\n\n+( ( DisjunctionMaxQuery((alltags:the)~0.01) \n     DisjunctionMaxQuery((title_en:contract | alltags:contract)~0.01)\n   )~2\n )\n\n\n\nThe \"DisjunctionMaxQuery((alltags:the)~0.01)\" clause is not required in that query.  it is one of two SHOULD clauses in a boolean query, and becomes subject to the same \"mm\" rule.  both clauses in that BooleanQuery are already SHOULD clauses, so i don't know what it would mean to make then more \"optional\".\n "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-13198347",
            "date": "2012-02-02T00:04:12+0000",
            "content": "You're right that technically it's not marked as required, but in the context of this \"feature\" we're discussing, the reason why people get 0 hits is that mm=100%, counted from all (SHOULD) clauses. And that means effectively that alltags:the is required.\n\nWhat James suggested, and what most people tricked by this \"feature\" expects, is that if \"the\" is a stopword for one of the qf fields, it becomes optional in some way.\n\nSo how can we get that end result? First we need a way to safely detect that we're in this scenario, perhaps by inspecting whether each DisMax clause contains a field query for every field listed in QF. If one or more is missing, we can assume that the query term is a stopword in one or more of the fields. Then, one way may be to subtract the MM count accordingly, so that in our case above, when we detect that the DisMax clause for \"the\" does not contain \"title_en\", we do mm=mm-1 which will give us an MM of 1 instead of 2 and we'll get hits. This is probably the easiest solution.\n\nAnother way would be to keep mm as is, and move the affected clause out of the BooleanQuery and add it as a BoostQuery instead?\n\nThis behavior should be parameter driven, e.g. &mm.sw=false reading \"Minimum should match does not require Stop Words\" "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13198361",
            "date": "2012-02-02T00:18:56+0000",
            "content": "Then, one way may be to subtract the MM count accordingly, so that in our case above, when we detect that the DisMax clause for \"the\" does not contain \"title_en\", we do mm=mm-1 which will give us an MM of 1 instead of 2 and we'll get hits. This is probably the easiest solution.\n\nthat wouldn't make any sense ... in your example that would result in the query matching every doc containing \"alltags:the\" (or \"title_en:contract\", or \"alltags:contract\") which hardly seems like what the user is likely to expect if they used mm=100% (with or w/o a \"mm.sw=false\" param)\n\nAnother way would be to keep mm as is, and move the affected clause out of the BooleanQuery and add it as a BoostQuery instead?\n\nsomething like that might work .. but i haven't thought it through very hard ... i have a nagging feeling that there are non-stopword cases that would be indistinguishable (to the parser) from this type of stopword case, and thus would also trigger this logic undesirably, but i can't articulate what they might be off the top of my head. "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-13199147",
            "date": "2012-02-02T19:42:22+0000",
            "content": "i have a nagging feeling that there are non-stopword cases that would be indistinguishable (to the parser) from this type of stopword case, and thus would also trigger this logic undesirably, but i can't articulate what they might be off the top of my head.\n\nA potential difficult one is this multi language example: &qf=title_no title_en tags. Each of these fields may have their separate stopwords list, say title_no has a stopword \"men\" (norwegian for but) and title_en has stopword \"the\". Then we query q=the men. The user expectation would be that it would return ENGLISH docs matching \"men\", since \"the\" is an english stopword.\n\nToday we'd get:\n\n+((DisjunctionMaxQuery((title_no:the | tags:the)~0.01) DisjunctionMaxQuery((title_en:men | tags:men)~0.01))~2)\n\n\n\nIn this case with mm=100% we'd likely get 0 hits, given that \"the\" is not common in either of title_no or tags. However, the parser cannot know whether the user's real information need is \"the\" or \"men\" - since both are stopwords for different fields.\n\nNow, all DisMax clauses in this example have had at least one stopword pruned, so using the \"mm decrement\" strategy would change mm from 2 to 0 which would turn this into an OR query - and of course return results. This is a compromise, so a better option in this special case would probably be to use eDismax's \"smart\" conditional stopword removal [1], but that requires change of fieldType.\n\nThe \"convert to boost query\" approach would only work when we have at least one clause without stop words, since we cannot query ONLY with bq. Say two of my four query terms q=the best cheap holiday are stop words, and mm=100%. So we remove the two stop clauses from the BooleanQuery and reduce mm accordingly from 4 (100%) to 2, and add the two stop clauses as BQs. This approach would also work for mm<100% cases, since we only count mm clauses from the non-stop clauses.\n\n\n[1] For the special case of all clauses being stop clauses, eDisMax's existing \"smart\" conditional stopword handling could perhaps be another solution? For those unfamiliar with it, you can specify &stopwords=true (which is the default) and eDismax will remove stopwords for you instead of letting Analysis do it. It requires that you don't have StopFilterFactory in your Analysis. Now, if ALL query terms are stopwords, disMax will not remove them, to support queries like \"Who is the who?\". (Q: How does edismax pick up which stopword dicationary(ies) to use?). It's of no use to those removing stop-words in their \"index\" analysis though. "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-13228351",
            "date": "2012-03-13T12:17:27+0000",
            "content": "How about we add a new fieldType to exampel schema.xml text_general_smartstopwords and in it document how to use eDisMax to conditionally remove stopwords on query side only? "
        },
        {
            "author": "Bill Bell",
            "id": "comment-13228990",
            "date": "2012-03-14T05:36:48+0000",
            "content": "We also found another loophole. If we send [* TO *] to edismax we also can bring down the server.\n\nSome chars are not being escaped before being sent to SOLR.  Eg I can send queries like this to SOLR by searching on ([* TO *] OR [* TO *] OR [* TO *]) in the search box - it took 72 seconds to return:\n\nwebapp=/solr path=/select params=\n{d=160.9344&start=0&q=([*+TO+*]+OR+[*+TO+*]+OR+[*+TO+*])&pt=40.7146,-74.0071&qt=providersearchdist&wt=json&qq=city_state_lower:\"new+york,+ny\"&rows=20}\n hits=276442 status=0 QTime=72458 "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-13229083",
            "date": "2012-03-14T08:58:12+0000",
            "content": "@Bill, since this is a bit off topic, I moved your \"loophole\" to SOLR-3243. It is certainly something that is dangerous and I cannot see a single usecase for allowing an un-fielded range! Good catch. "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13237079",
            "date": "2012-03-23T20:31:42+0000",
            "content": "Bulk changing fixVersion 3.6 to 4.0 for any open issues that are unassigned and have not been updated since March 19.\n\nEmail spam suppressed for this bulk edit; search for hoss20120323nofix36 to identify all issues edited "
        },
        {
            "author": "Jonathan Rochkind",
            "id": "comment-13251828",
            "date": "2012-04-11T18:41:37+0000",
            "content": "Hoss says: i have a nagging feeling that there are non-stopword cases that would be indistinguishable (to the parser) from this type of stopword case, and thus would also trigger this logic undesirably, but i can't articulate what they might be off the top of my head.\n\nIndeed there are, pretty much anything where analysis differs between two fields in a way that can effect number of tokens produced. Punctuation stripping can sometimes do this, and I ran into such a case in my real world use.  More info http://bibwild.wordpress.com/2011/06/15/more-dismax-gotchas-varying-field-analysis-and-mm/ \n\nThis is a difficult problem to fix in the general case, at one point I think there was a solr listserv discussion where I tried to brainstorm general case solutions, but they were all shot down by people who knew more about Solr than me.  I can't find the archive of that discussion now though.  "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-13251915",
            "date": "2012-04-11T20:53:55+0000",
            "content": "Good article, Jonathan. I agree that it may be very hard to completely fix this 100%, but an option to at least avoid the most common frustrations around this would be welcome, even if it is only fixing the symptoms. I.e. having a configuration parameter relaxMmHack=true which relaxes mm if one of the fields yields fewer tokens than the others would be fixing the felt effect of the problem for many peo, simply by adding a param. "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13412139",
            "date": "2012-07-11T22:26:07+0000",
            "content": "bulk fixing the version info for 4.0-ALPHA and 4.0 all affected issues have \"hoss20120711-bulk-40-change\" in comment "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13429788",
            "date": "2012-08-07T03:43:03+0000",
            "content": "rmuir20120906-bulk-40-change "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13451082",
            "date": "2012-09-07T22:32:19+0000",
            "content": "removing fixVersion=4.0 since there is no evidence that anyone is currently working on this issue.  (this can certainly be revisited if volunteers step forward)\n "
        },
        {
            "author": "Markus Jelsma",
            "id": "comment-13558652",
            "date": "2013-01-21T09:35:55+0000",
            "content": "Any progress with this one? Any smart ideas to share? "
        },
        {
            "author": "Naomi Dushay",
            "id": "comment-13677709",
            "date": "2013-06-07T00:50:23+0000",
            "content": "We avoided this by adding stopwords to our string fields (and simultaneously dealing with whitespace around punctuation marks).  It's dumb, but it worked fine in dismax.  We no longer use stopwords in general.\n\n<!-- single token with punctuation terms removed so dismax doesn't look for punctuation terms in these fields -->\n<!-- On client side, Lucene query parser breaks things up by whitespace before field analysis for dismax -->\n<!-- so punctuation terms (& :  are stopwords to allow results from other fields when these chars are surrounded by spaces in query -->\n<fieldType name=\"string_punct_stop\" class=\"solr.TextField\" omitNorms=\"true\">\n   <analyzer type=\"index\">\n     <tokenizer class=\"solr.KeywordTokenizerFactory\" />\n     <filter class=\"solr.ICUNormalizer2FilterFactory\" name=\"nfkc\" mode=\"compose\" />\n   </analyzer>\n   <analyzer type=\"query\">\n     <tokenizer class=\"solr.KeywordTokenizerFactory\" />\n     <filter class=\"solr.ICUNormalizer2FilterFactory\" name=\"nfkc\" mode=\"compose\" />\n     <!-- removing punctuation for Lucene query parser issues -->\n     <filter class=\"solr.StopFilterFactory\" ignoreCase=\"true\" words=\"stopwords_punctuation.txt\" enablePositionIncrements=\"true\" />\n   </analyzer>\n</fieldType> "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-13851634",
            "date": "2013-12-18T12:21:28+0000",
            "content": "This issue is still with us... How do people feel about a super-simple fix through a new optional param:\n\nmm.autoRelax=true|false : Automatically relax number of MUST clauses when tokens are removed from some fields but not all\n\nIt would count number of fields remaining for each clause and then adjust MM accordingly. I can attempt a patch. "
        },
        {
            "author": "Markus Jelsma",
            "id": "comment-13851645",
            "date": "2013-12-18T12:33:23+0000",
            "content": "I think that would be certainly better than the current situation. But there may be another issue; if you don't remove stopwords at all, like we do, there is a problem with mm and stop words too. For example: q=train from amsterdam to rotterdam&mm=2<-1 5<80%; ideally you would not want documents with only terms `from`, `to` and another non-stop word to match. In this case we would need mm to apply only on non-stop words but also need a query time stopwordfilter that doesn't remove them but marks them as stop words. "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-13851667",
            "date": "2013-12-18T12:55:33+0000",
            "content": "ideally you would not want documents with only terms `from`, `to` and another non-stop word to match. In this case we would need mm to apply only on non-stop words but also need a query time stopwordfilter that doesn't remove them but marks them as stop words.\n\nWhat exactly would \"marks them as stop words\" mean if they are not to be removed? "
        },
        {
            "author": "Markus Jelsma",
            "id": "comment-13851670",
            "date": "2013-12-18T12:58:41+0000",
            "content": "As in not removed, we would still want to be able to query for stop words, but have mm only apply to non-stop words. "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-13852247",
            "date": "2013-12-18T22:38:56+0000",
            "content": "This patch is a first shot at a new param mm.autoRelax\n\nWhen set as &mm.autoRelax=true on the request, it will adjust minShouldMatch to at most require the number of clauses with the max number of disjuncts.\n\nHave tested manually for some common cases, and it seems to work as expected, i.e. if you had a query q=A horse in a stable that gave problems due to mm=100% => minShouldMatch=5, applying autoRelax will adjust it to 2. Need to add some JUnit tests. "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-13853875",
            "date": "2013-12-20T11:20:49+0000",
            "content": "New patch\n\n\n\tAdds tests\n\tNow also works with the old dismax\n\tNo longer breaks mm for non-dismax boolean clauses\n\n "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-13853912",
            "date": "2013-12-20T12:25:59+0000",
            "content": "Last patch had a bad import. This one now passes ant precommit. "
        },
        {
            "author": "Markus Jelsma",
            "id": "comment-13853922",
            "date": "2013-12-20T12:37:53+0000",
            "content": "Hi Jan - the SolrCore.java modification shouldnt be in the patch. Anyway, it looks like this fix does what it advertises. The problem i reported above, perhaps another issue, is still real. Environments without stopwords still have a problem with mm. Consider your q=A horse in a stable. With mm=2 we get all kinds of documents, usually all documents in the corpus (in and a). Ideally this or another parameter would only require horse and stable.\n\nedit, you already remove the import. "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-13853940",
            "date": "2013-12-20T13:04:30+0000",
            "content": "Environments without stopwords still have a problem with mm. Consider your q=A horse in a stable. With mm=2 we get all kinds of documents, usually all documents in the corpus (in and a). Ideally this or another parameter would only require horse and stable.\n\nThe mm.autoRelax param is designed to tackle one of the most common situation where your qf includes a bunch of \"text\" fields with stopword removal plus one or more \"string\" fields like \"id\" or \"tags\" etc. Take the example of qf=title body tags where title and body removes stopwords but tags does not. This would translate to something like\n\n\n(DMQ(tags:a) DMQ(title:horse |\u00a0body:horse |\u00a0tags:horse) DMQ(tags:in) DMQ(tags:a) DMQ(title:stable |\u00a0body:stable | tags:stable))~5\n\n\n\nVery often in these cases the \"tags\" field does not contain free-text, so tags:a, tags:in would not match, and we always get 0 hits \u2013 thus mm=2 would help here.\n\nBut for cases where you query multiple english analyzed text fields with different stopword lists, relaxation of mm is not the cure. The cure is rather to add the same stopword handling to all those text fieldTypes.\n\nClearly mm.autoRelax is not a complete solution for all mm issues. For other cases we may need other cures. One idea I thought of the other day is a param mergeStopwords=true, which modifies the analysis chain for each field in qf to include all StopFilters on the \"query\" analysis of each field. I.e. if my field A has stopwords=\"a.txt\" and field B has stopwords=\"b.txt\", then edismax would add those two stopword filters in a row for both fields, much the same way that edismax removes the StopFilter when doing smart stopword handling. "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-13862324",
            "date": "2014-01-04T14:57:15+0000",
            "content": "As it seems there is no silver bullet for all kind of mm problems, I suggest to chop up the elephant, starting with mm.autoRelax as the first tool. And then try to tackle other needs later. Thoughts? "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-13946395",
            "date": "2014-03-25T11:30:46+0000",
            "content": "This keeps getting up on the users list. Any objections to adding params mm.autoRelax and mergeStopwords to start with, perhaps as experimental and then if they prove useful, promote them as permanent edismax citizens? "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-13971219",
            "date": "2014-04-16T12:57:29+0000",
            "content": "Move issue to Solr 4.9. "
        },
        {
            "author": "Markus Jelsma",
            "id": "comment-14089239",
            "date": "2014-08-07T14:04:59+0000",
            "content": "Yes, i think this should be added and possibly as experimental. The patch works for some cases although it is indeed not a silver bullet. Merging stop word lists might prove useful! "
        },
        {
            "author": "David Smiley",
            "id": "comment-14173329",
            "date": "2014-10-16T04:09:03+0000",
            "content": "I like the \"convert to boost query\" approach.  I independently arrived at that solution, though I haven't put it into practice.  The all-stop-words case (e.g. \"who is the who\" or \"to be or not to be\") could be special-cased to not convert these clauses to boost queries.  Granted it seems unlikely in this example you'd find anything since the 'qf' field you point to that is analyzed differently (e.g. string field) would need all of them.  But if you configure stop words then this is expected behavior \u2013 it's the conscious trade-off you make by filtering them.  Another possibility is OR'ing in the query as a phrase, giving an opportunity for common-grams/shingling to find matches. "
        },
        {
            "author": "Simon Endele",
            "id": "comment-14642843",
            "date": "2015-07-27T15:13:01+0000",
            "content": "We're currently experiencing the same issue with query terms that only contain non-alphanumerical characters, which are removed by the StandardTokenizer or WordDelimiterFilter, e.g. \"miles & more\".\nWill this case also be addressed by mm.autoRelax? "
        },
        {
            "author": "David Smiley",
            "id": "comment-14643428",
            "date": "2015-07-27T21:25:45+0000",
            "content": "Simon Endele Yes it would.  So would the solution of converting these clauses to boost queries, which I did some months ago as part of a custom client-specific query parser, and it works fine.  \n\nOne reason I like converting these clauses to boost queries is that from a Lucene internals/performance perspective, we separate out the clauses we know aren't a must-match into the boost, which is in a SHOULD position, and is thus secondary since the docs in the boost can be skipped past for docs that don't stand a chance.  I believe this is faster than one BooleanQuery with a smaller min-should-match.  \n\nJan's patch for mm.autoRelax looks good to me.  I suggest another name however, one involving \"stopwords\".  Perhaps \"mm.discountStopwords\". "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-14651234",
            "date": "2015-08-02T22:28:43+0000",
            "content": "Attaching new patch which applied to current trunk.\n\nI keep the param name mm.autoRelax since it will relax mm not only at \"uneven\" stopword removal but for all kind of analysis which ends up with different number of clauses between fields. This is easier to explain in documentation too. "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14651235",
            "date": "2015-08-02T22:31:21+0000",
            "content": "Commit 1693833 from janhoy@apache.org in branch 'dev/trunk'\n[ https://svn.apache.org/r1693833 ]\n\nSOLR-3085: New edismax param mm.autoRelax which helps in certain cases of the stopwords/zero-hits issue "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-14651244",
            "date": "2015-08-02T22:41:17+0000",
            "content": "Due to popular demand, I committed the mm.autoRelax logic to trunk only, for people to play with. After some broader exposure there we can consider porting to 5.x.\n\nThe mergeStopwords idea is spun off into SOLR-7862. "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-14651245",
            "date": "2015-08-02T22:42:47+0000",
            "content": "Resolving as fixed. Please re-open if back-porting to 5.x "
        }
    ]
}