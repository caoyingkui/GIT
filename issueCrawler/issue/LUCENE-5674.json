{
    "id": "LUCENE-5674",
    "title": "A new token filter: SubSequence",
    "details": {
        "type": "Improvement",
        "priority": "Minor",
        "labels": "",
        "resolution": "Unresolved",
        "components": [
            "core/other"
        ],
        "affect_versions": "None",
        "status": "Open",
        "fix_versions": []
    },
    "description": "A new configurable token filter which, given a token breaks it into sub-parts and outputs consecutive sub-sequences of those sub-parts.\n\nUseful for, for example, using during indexing to generate variations on domain names, so that \"www.google.com\" can be found by searching for \"google.com\", or \"www.google.com\".\n\nParameters:\n\nsepRegexp: A regular expression used split incoming tokens into sub-parts.\nglue: A string used to concatenate sub-parts together when creating sub-sequences.\nminLen: Minimum length (in sub-parts) of output sub-sequences\nmaxLen: Maximum length (in sub-parts) of output sub-sequences (0 for unlimited; negative numbers for token length in sub-parts minus specified length)\nanchor: Anchor.START to output only prefixes, or Anchor.END to output only suffixes, or Anchor.NONE to output any sub-sequence\nwithOriginal: whether to output also the original token\n\nEDIT: now includes tests for filter and for factory.",
    "attachments": {
        "subseqfilter.patch": "https://issues.apache.org/jira/secure/attachment/12646852/subseqfilter.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "id": "comment-14001043",
            "author": "Nitzan Shaked",
            "content": "Updated patch, including tests ",
            "date": "2014-05-18T09:28:37+0000"
        },
        {
            "id": "comment-14001046",
            "author": "Ahmet Arslan",
            "content": "anchorStr.toUpperCase()\ndoes this pass ant precommit ? ",
            "date": "2014-05-18T09:47:23+0000"
        },
        {
            "id": "comment-14001084",
            "author": "Nitzan Shaked",
            "content": "It did not. Added the obvious Locale.ROOT parameter. New patch (attaching in just a second) includes:\n\n1. Fix for .toUpperCase() as mentioned above\n2. Fix for other another ant precommit issue: rouge tabs\n3. A fix for the RandomChains test (did not allow SubSeqFilter.Anchor as a parameter type)\n4. Passes all tests\n5. Passes ant precommit, with the (possible?) exception of \"documentation-lint\", which I could not test ",
            "date": "2014-05-18T13:48:15+0000"
        },
        {
            "id": "comment-14001085",
            "author": "Nitzan Shaked",
            "content": "Fixes for ant precommit ",
            "date": "2014-05-18T13:48:56+0000"
        },
        {
            "id": "comment-14008340",
            "author": "Nitzan Shaked",
            "content": "Any word on this? ",
            "date": "2014-05-25T13:30:08+0000"
        },
        {
            "id": "comment-14008474",
            "author": "Ahmet Arslan",
            "content": "I see that somehow your patch contains old versions of itself. It is hard to read. Can you create a patch that created against trunk? It would be nice to have a documentation describing functionality of this filter. And why we cannot achieve it with existing analysis components.  ",
            "date": "2014-05-25T23:05:55+0000"
        },
        {
            "id": "comment-14008475",
            "author": "Ahmet Arslan",
            "content": "What happens when this filter instantiated with a minLen greater than maxLen? ",
            "date": "2014-05-25T23:11:15+0000"
        },
        {
            "id": "comment-14008476",
            "author": "Otis Gospodnetic",
            "content": "Didn't look at this, but I remember needing/writing something like this 10+ years ago.... but I think back then I wanted to have output be something like: com, com.google, com.google.www - i.e. tokenized, but reversed order. ",
            "date": "2014-05-25T23:16:25+0000"
        },
        {
            "id": "comment-14008566",
            "author": "Nitzan Shaked",
            "content": "Ahmet:\n\n1) I'll attach a \"squashed\" version of the patch, without history, hopefully that'll be easier to read.\n2) I don't know how to \"prove\" that something can't be done using existing analysis components, but after spending quite some time on this, and after asking on S.O., I am fairly convinced that it indeed cannot be done using existing components.\n3) Instantiating with minLen>maxLen is ok, since maxLen can be negative (-2 to count 2 sub-tokens from the end, for example). It might also happen that minLen may be greater than some tokens' lengths. In those cases there will simply be no output for the given token. I'll add a check that when both minLen and maxLen are positive, then minLen <= maxLen.\n\nOtis: while I'm adding this last check, I'll also add the \"reverse\" option, I can see why that might be useful. ",
            "date": "2014-05-26T04:26:34+0000"
        },
        {
            "id": "comment-14008624",
            "author": "Nitzan Shaked",
            "content": "Latest patch, all commits squashed into one ",
            "date": "2014-05-26T07:02:08+0000"
        },
        {
            "id": "comment-14008625",
            "author": "Nitzan Shaked",
            "content": "Ahmet, Otis: latest patch I just added contains everything mentioned above: check for minLen > maxLen (if maxLen > 0), a squahsed patch as per Ahmet's request, and a \"reverse\" feature (obviously with added tests). ",
            "date": "2014-05-26T07:03:01+0000"
        },
        {
            "id": "comment-14008656",
            "author": "Ahmet Arslan",
            "content": "In one place; old header used ? \n\n Copyright 2005 The Apache Software Foundation\n ",
            "date": "2014-05-26T08:10:29+0000"
        },
        {
            "id": "comment-14008838",
            "author": "Koji Sekiguchi",
            "content": "\nDidn't look at this, but I remember needing/writing something like this 10+ years ago.... but I think back then I wanted to have output be something like: com, com.google, com.google.www - i.e. tokenized, but reversed order.\n\nPathHierarchyTokenizer can tokenize something like that. ",
            "date": "2014-05-26T13:39:42+0000"
        },
        {
            "id": "comment-14008844",
            "author": "Nitzan Shaked",
            "content": "Copied verbatim from files in the same dir. Where is the 'new' header, I'll\nreplace.\n\nWhile we're at it: anything else?\n ",
            "date": "2014-05-26T13:46:02+0000"
        },
        {
            "id": "comment-14008874",
            "author": "Nitzan Shaked",
            "content": "Koji: it can't do what I'm trying to do. Have you looked at my description?\n ",
            "date": "2014-05-26T14:20:03+0000"
        },
        {
            "id": "comment-14009140",
            "author": "Koji Sekiguchi",
            "content": "Koji: it can't do what I'm trying to do. Have you looked at my description?\n\nPlease ignore my comment Nitzan as it was just for what Otis described, and PathHierarchyTokenizer is a Tokenizer, not TokenFilter.  ",
            "date": "2014-05-26T23:29:24+0000"
        },
        {
            "id": "comment-14009475",
            "author": "Nitzan Shaked",
            "content": "Updated patch, contains \"new format header\" for the one place that used the \"old format header\" ",
            "date": "2014-05-27T07:55:47+0000"
        },
        {
            "id": "comment-14014931",
            "author": "Nitzan Shaked",
            "content": "So what's up with this? ",
            "date": "2014-06-01T08:02:28+0000"
        }
    ]
}