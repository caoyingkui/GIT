{
    "id": "SOLR-3619",
    "title": "Rename 'example' dir to 'server' and pull examples into an 'examples' directory",
    "details": {
        "affect_versions": "None",
        "status": "Closed",
        "fix_versions": [
            "5.0",
            "6.0"
        ],
        "components": [],
        "type": "Improvement",
        "priority": "Major",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "",
    "attachments": {
        "solrconfig.xml": "https://issues.apache.org/jira/secure/attachment/12660215/solrconfig.xml",
        "managed-schema": "https://issues.apache.org/jira/secure/attachment/12660214/managed-schema",
        "SOLR-3619.patch": "https://issues.apache.org/jira/secure/attachment/12536465/SOLR-3619.patch",
        "server-name-layout.png": "https://issues.apache.org/jira/secure/attachment/12536464/server-name-layout.png"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Mark Miller",
            "id": "comment-13413715",
            "date": "2012-07-13T13:24:42+0000",
            "content": "From SOLR-3259 "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13413806",
            "date": "2012-07-13T15:13:35+0000",
            "content": "So I guess as I look at things, this would be my first instinct:\n\nRename example to server.\n\nMake a new root level folder called examples -> put the other solrhome examples there (an example with 2 cores if we still want it, the DIH example)\n\nMove exampledocs under examples as well?\n\nGiving:\n\ncontrib\ndist\ndocs\nexamples\n solrhomes (or?)\n exampledocs\nserver\n\n\n\nThat clearly separates the example stuff out and makes it easily findable - then you are left with a server that looks more like what it is - our default setup that people build off rather than merely an example. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13414081",
            "date": "2012-07-13T21:44:59+0000",
            "content": "This what my proposed layout would look. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13414084",
            "date": "2012-07-13T21:46:51+0000",
            "content": "first cut patch "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13414085",
            "date": "2012-07-13T21:47:44+0000",
            "content": "obviously will use svn moves though despite patch "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13414086",
            "date": "2012-07-13T21:48:17+0000",
            "content": "Work with these kinds of moves gets out dated quickly...any feedback? "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13414105",
            "date": "2012-07-13T22:18:42+0000",
            "content": "We really need that per version doc - the biggest pain of point of this has got to be the wiki. "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-13414142",
            "date": "2012-07-13T23:21:04+0000",
            "content": "The name \"server\" is good in that it indicate that there's actually an appserver inside.\n\nBut it feels wrong to include one example config in \"server\" and leave the others by themselves. After all, the nature of a search engine is that every user needs their own custom schema, so anything we provide OOTB will per definition be an example. We should not fool people into thinking that there is a \"default\" or \"generic\" schema - we simply provide a starting point. So to make it even easier for beginners to explore all of Solr including DIH and extracting-handler etc, let's have simply one examples/solrhome with all the examples we wish to expose (and maintain!). It will give them more prime-time, we can get rid of the old \"multicore\" etc.\n\nSeen together with the start-scripts issue, I say we should have a top-level solr/bin with all the scripts, including zkcli, and a feed-example script. Here's my take on new structure:\n\n\n\u251c\u2500\u2500 bin\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 feed-example.sh\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 start-server.sh\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 stop-server.sh\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 zkcli.bat\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 zkcli.sh\n\u251c\u2500\u2500 contrib\n\u251c\u2500\u2500 dist\n\u251c\u2500\u2500 docs\n\u251c\u2500\u2500 examples\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 exampledocs\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 docs\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 products\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 solrhome\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 DIH-db\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 DIH-rss\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 docs\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 products\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 solr.xml\n\u2514\u2500\u2500 server\n    \u251c\u2500\u2500 solr.home (file)\n    \u2514\u2500\u2500 webapps\n\n\n\nWith this setup, the products core would be today's \"collection1\", and docs would be a handful of PDFs and HTMLs for use with solr-cell and/or DIH files example. Today's \"collection1\" is not very well tuned for PDF/HTML kind of docs, so it may be better with a dedicated schema for such docs.\n\nThe one-liner for starting and feeding examples could then be something like:\n\ncd solr/bin; ./start-server.sh; ./feed-example.sh all\n\n\n\nBut if the example configs are not below server/ anymore, the old cd server; java -jar start.jar will not work anymore. Soft-linking a \"solr\" folder to ../examples/solrhome wouldn't work for Windows, so a nice solution could be to in addition to looking for a ./solr folder for our SOLR_HOME, we look for a ./solr.home file with one line poining to SOLR_HOME. Separating binaries and data this way is also a preferred way for many, and it makes the whole concept of SOLR_HOME more clear to people - today some are confused about solr/example/solr being SOLR_HOME. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13414169",
            "date": "2012-07-13T23:58:46+0000",
            "content": "so anything we provide OOTB will per definition be an example.\n\nI think thats exactly why this issue came up in the linked to issue - we are renaming it from example because we are recognizing people use it as the default to built on. It's essentially out of the box Solr - even though we have called it example, that how it effectively has worked out. Benchmarkers use it as Solr when comparing to other search engines, users start from it and tweak to the config they want. It defacto is out of the box Solr with all it's default glory. Perhaps you want to trim your config options from our defaults - perhaps you want to add or take away from the schema. That's fine - but it's not like you are examining our example and then building your own install. It's much more like you are tweaking the out of the box config.\n\nI think calling it an example is a real turn off. People want to download new software and get going without headaches. Seeing all this example stuff out of the box makes things look difficult too even get started. What other software works this way? All these issues are why I initially avoided Solr back in the early days. It seemed like to much of a pain to get going. The trick it to make it seem easy to get going. Then you dive in and figure out what you need to tweak as you go. That's what people end up doing anyway, except they get to be a little confused first. PHP/.Net or any non java guys looking to run Solr get to go, \"webapps? wars? java -jar start.jar? examples and no application? yikes  Damn Unix hackers!\"\n\nThe others solrhomes are truly examples and have always been second class citizens as far as additions and scope.\n\nI was pro dropping the multicore example, but its very minimal and it's nice to have an example of configuring more than one core. I could take it or leave it - it's more palatable to me in the examples dir though.\n\nI'm good with the bin folder for start/stop scripts (ive got another issue open for that). I don't mind root level or under /server\n\nI'm really pro having the default solr home under server though - away from the other less practically useful examples (eg you probably want to merge the idea of them with a lot of the config from the default solrhome).\n\nOther opinions on that? "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13414326",
            "date": "2012-07-14T09:38:53+0000",
            "content": "I think calling it an example is a real turn off.\n\n+1 - we've been getting dinged vs the competition on the perception that it takes a lot to get solr up and running.\nIf your first instruction is to go edit some XML file... you've already lost some people.\n\nThe others solrhomes are truly examples and have always been second class citizens as far as additions and scope.\n\n+1 - multiple solr homes under the server directory is confusing\n\nI'm really pro having the default solr home under server though\n\nMe too - In general I think server should be as stand-alone as possible (i.e. you should be able to copy it to somewhere else and still have it work) and have all relevant config.  The \"contrib\" is a bit of a sore spot there of course...\n\nWe should probably have a \"bin\" directory under server as I imagine scripts may proliferate beyond start/stop, and we don't want too much clutter in the server root.\n\nI could get behind Jan's idea of separating all the binary stuff from the solr home... but from a practical perspective I don't know how much work it would take to implement that.  Anything writable like logs would need to be changed to go under the solr home.  Instead of a solr.home file, I think the CWD could be checked for a solr.xml file, and optionally if that didn't exist, use the stock one in ../solrhome or something.  It would also be nice to create a new solr home via a command (i.e. cd to an empty directory and start solr with a --new flag that puts everything in place for a new server).  But this all sounds like a good bit of work...\n\nToday's \"collection1\" is not very well tuned for PDF/HTML kind of docs\n\nI haven't tried it in a while... can we improve it w/o getting in the way of people who don't use solr-cell? "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-13414531",
            "date": "2012-07-14T22:45:09+0000",
            "content": "we are renaming it from example because we are recognizing people use it as the default to built on. \nAnd that's all fine - people need to start somewhere. But if they think that adding a few <field>s to schema.xml is all Solr has to offer they'll build crappy search apps - I've seen many of these out there. So in calling it example (or template or skeleton or whaterver) gives people a hint that it's not anything that they should expect to be sufficient for their need without some more tuning (Solr is not GSA..)\n\n\nToday's \"collection1\" is not very well tuned for PDF/HTML kind of docs\nI haven't tried it in a while... can we improve it w/o getting in the way of people who don't use solr-cell?\nWhen Solr is compared to various other search engines, what they tend to test is web/filesystem crawling. So I really think that if we should include ONE main \"example\" config, it should be geared towards HTML/PDF/DOC indexing, either from crawling or pushing stuff from filesystem. That would mean that you have a title, a teaser, body, URL/path and various metadata. There has been some discussion on the list about improving user experience for such type of input.\n\nSure, it is harder (much harder) to get excellent results from unstructured text than from some nice synthetic structured xml docs, so it would take some work to let Solr shine in those comparisons. One needed piece could be an improved post.jar (or an feeder wrapper script) which can recursively traverse folders and push files matching certain file types, with the correct MIME and unique ID. That would let people quickly index, say, their home folder, and then view the results in Solritas. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13414534",
            "date": "2012-07-14T23:10:33+0000",
            "content": "So in calling it example (or template or skeleton or whaterver) gives people a hint that it's not anything that they should expect to be sufficient for their need without some more tuning (Solr is not GSA..)\n\nI think that is exactly what you want to avoid - the feeling that you cannot get anywhere without tuning. You should have a relatively good experience without tuning when you first start - that's how people like software to work - really easy to get into, and then really easy to tune as you need. That comes down to documentation.\n\nI really don't think it helps to try and club someone up front and say, no, you must figure it out all up front. That is when someone looks for something easier. Everything should work the best it can without tuning. Then good documentation and crazy customizability work in your favor. Lots of people don't clean up all the stuff in schema.xml and make their own. They add a few fields. The remove a few things. Some pare it down to just what they need. If initial building and testing you do works with the example schema and few or no tweaks, great! You can pare it down later when you have learned more over time.\n\nI think that's how most people try and come at things anyhow - try and get the existing stuff up and improve and tweak as they learn more. We should make that easier and more intuitive. There is no reason Solr should not be as good as GSA out of the box (though Solr not having crawlers makes that an odd comparison). Easy out of the box and super configurable/tunable is way better than hard out of the box and super configurable/tunable.\n\nI also think you can do way more with Solr out of the box than you might think! Either using dynamic field defs or adding just a field or three. Have you ever seen Hossmans out of the box talks? They are fantastic. I think enough is configured right out of the box that there are a variety of paths you can take to really quick cool setups.\n\nFor people that can get away with just a few teaks to what we ship, should we really be trying to send the message that you really need to treat all these huge xml files as an example, and actually, you need to figure out how to create new ones for your use case?\n\nI think that rather than trying to put the burden on the user right away (don't think this is gonna be easy buster!), we should be making the initial experience liquid smooth and as hassle free as possible and maintain all of the options and configurability so that as they learn Solr they are able to take it in whatever direction they need. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13414544",
            "date": "2012-07-14T23:33:44+0000",
            "content": "Since I think there is at least general agreement on the overall change, I'd like to commit soon - this involves a lot of changes over a fair number of files, and many moves. It's a nightmare to keep up to date over time. I'd like to commit what I currently have and then make changes from there. "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-13414555",
            "date": "2012-07-14T23:53:50+0000",
            "content": "Sure it would be nice to be GSAish. Everything with nice GUIs, point it to your content and things just work with great relevancy. Point it on your employee LDAP and you get a super person finder. Point it at your webshop and you sell more...\n\nBut it's all about use cases. When I worked @ FAST, we created some 5 different blueprint templates as starting point depending on whether it was a web crawl, e-commerce, yellow-page, intranet etc. One size does not fit all. For our Solr example we have chosen to demonstrate a simple product search, and that is exactly what it is (even if it's a rather non-impressive one). If newbies try to shuffle in some office docs of their own, chances are they won't have a clue of how to get that done, but if they should happen to get them in, then they won't show up in /browse without tweaking, facets will be wrong etc.\n\nI think that rather than trying to put the burden on the user right away (don't think this is gonna be easy buster!)...\nGetting started with our example(s) should be dead simple, also tweaking to do very similar use cases. But we mislead our users by pretending that one size is meant to fit all. Let's make the entry threshold really low - no argue about that - but for one or more chosen use cases, and then point them in the right direction on how to incrementally tweak things to become a great\u2122 search. "
        },
        {
            "author": "Jack Krupansky",
            "id": "comment-13414562",
            "date": "2012-07-15T02:12:46+0000",
            "content": "Now I am confused. The summary seems deceptively simple and the lack of a description and the multi-direction discussion to date leads me to believe that is the still the case (people trying to extend whatever the original motivation was), but looking at the patch, I am not sure what is really going on here. If the goal is simply \"improve OOBE for Solr\", great. But I am not sure how merely renaming a directory accomplishes that. Personally, I think the current Solr tutorial is reasonably straightforward. I do wish it was better integrated with the SolrCell tutorial and elsewhere I have proposed a modest change to the schema to help with that, but this issue doesn't seem directed down that path either, I think.\n\nIn short, could somebody summarize what is really going on here? Or at least fill in the description. \n\nMaybe there was an IRC discussion that I missed out on. If so, A summary of that discussion would help a lot.\n\nFrom what I know so far, I would prefer to keep the current \"example\" approach since we have tons of email messages that tell people how to resolve issues relative to the example.\n\nGranted, a single one-size-doesn't-quite-fit-all example has its limitations, but let's not toss out the baby with the bath water. I mean I would love to see more comprehensive examples, but I'd like to understand them first.\n\nIf there are specific issues that are to be addressed, lets see those issues listed in a description first.\n "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13414612",
            "date": "2012-07-15T11:51:39+0000",
            "content": "One size does not fit all. \nThats fine - one size can fit a lot though! And the initial size is very important to people first trying Solr out! This is an important person to the project! New users. 5 blueprints are fine! They certainly are not necessary in tons of cases! We should have a great out of the box experience and provide examples and uses cases up the whazoo on top of that. Your talking about pleasing one segment of the users - some of the more advanced ones. \n\nI'm talking about pleasing more segments. The advanced guys don't lose out, and new advanced and noob guys like it more. I don't even believe the direction your promoting pleases the advanced users. They want it easy too. I've been listening to a lot of developers - and these days I hear more and more - they are looking for software that is easy to get started with. Not software that feels \"enterprise\". Many of these people are doing things where the search engine is not the primary system - they want it to just work to the best that it can. Everyone I know (including me) really disliked FAST and the like. Devs are not looking for software that looks like it has a high hurdle to get started. Know why MongoDB is so ridiculously popular right now? It has many rival techs you can choose instead. \n\nIf newbies try to shuffle in some office docs of their own, chances are they won't have a clue of how to get that done \nI don't believe that at all. Good examples and doc and intro tutorials are how people learn to get started - it's easy to explain how to use the built in dynamic fields! It's easy to explain you might want to take a moment and add a couple fields! It's a lie to say you should think of the whole conf dir as an example and you should not consider using it in production. Why not? People do it with just some tweaks all the time - I've seen the configs. And we can make it even better. Jumbo shops will still want to hire consultants to tune things for harder problems - but Johnny blogger will also be able to get get up and hopping in 3 seconds. Drupal is a huge user base of Solr. Users that don't want to pay for hosted Solr should be able to setup and use Solr with ease! Ruby and Drupal users generally just take all the example config and then just plop a custom schema.xml in. That's it - and that's fine. That is how easy it should be. Later, if they find they are scaling and have some issues, they can start to peak into solrconfig.xml. They should not feel that they better go tackle right away or else there will be trouble! You should not have to tell the army of devs that use Solr for minor side projects and the like that OutOfTheBoxSolr will not work for you. All these guys accessing Solr from wordpress plugins, from ruby and php and perl, from Drupal - they should be able to run Solr with ease IMO. And it should end up working for the advanced guys as well. I think people like to be able to string up systems quickly and easily - and then go back and tune. Not the other way around. And I think it's silly to try and prod them into doing the other way around. You really don't have to customize any of your config until you need to. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13414617",
            "date": "2012-07-15T12:02:40+0000",
            "content": "I just resolved a couple conflicts to get this back to trunk. My nightmare scenario is someone changing a file under a dir I have moved and I have to redo it all \n\nIf any other committers have comments or objections to the 'general' moves specified in this issue, please speak up shortly. Otherwise, I'm going to commit the current state of things and then continue discussing and modifying the details.\n "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-13414814",
            "date": "2012-07-16T00:31:18+0000",
            "content": "Ruby and Drupal users generally just take all the example config and then just plop a custom schema.xml in.\n\nExactly - a custom config, sometimes the whole \"conf\" folder including synonyms etc. Note that for standard systems like Drupal, Wordpress, Escenic, Magento etc, someone already did the work of creating a custom config. Even the most simple of these systems saw a need to tweak, adding custom fieldTypes, perhaps a default requesthandler etc.\n\nAll these guys accessing Solr from wordpress plugins, from ruby and php and perl, from Drupal - they should be able to run Solr with ease IMO.\n\nYes, and this is what this jira is about - easier to get started and understand Solr's folder layout. And for this purpose I'm +1 renaming example to \"server\" and moving the other examples out of Jetty's folder. But to be really general purpose OOTB (work well for indexing blog posts, web pages or PDF docs), we should continue work on SOLR-3439 and SOLR-3442 as well.\n\nJust another comment about naming. If we stick with multiple independent SOLR_HOMES in examples instead of one big multicore, I think examples/solrhome should be named examples/solrhomes - else it is just too intuitive to try try -Dsolr.solr.home=examples/solrhome. Perhaps better to make each example more self contained including a README, a content folder for example content and a solrhome folder with the config:\n\n\u251c\u2500\u2500 examples\n\u2502   \u251c\u2500\u2500 DIH\n\u2502   \u2502   \u251c\u2500\u2500 content\n\u2502   \u2502   \u251c\u2500\u2500 solrhome\n\u2502   \u2502   \u2514\u2500\u2500 README.TXT\n\u2502   \u2514\u2500\u2500 multicore\n\u2502       \u251c\u2500\u2500 content\n\u2502       \u251c\u2500\u2500 solrhome\n\u2502       |   \u251c\u2500\u2500 core1\n\u2502       |   \u2514\u2500\u2500 core2\n\u2502       \u2514\u2500\u2500 README.TXT\n\n\n\nThat would be more intuitive to startup:\n\nInstead of \njava -Dsolr.solr.home=../examples/solrhome/multicore -jar start.jar\nwe get\njava -Dsolr.solr.home=../examples/multicore/solrhome -jar start.jar\n\n "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13415128",
            "date": "2012-07-16T13:56:03+0000",
            "content": "Exactly - a custom config, sometimes the whole \"conf\" folder including synonyms etc\n\nNo - a custom schema file - they generally take solrconfig.xml out of the box along with the other config files. And with the right schema and features to start they would not have to even replace this one file.\n\n\nEven the most simple of these systems saw a need to tweak, adding custom fieldTypes, perhaps a default requesthandler etc.\n\nThats not true - like I said - dynamic fields out of the box can build many apps! Especially when you are doing things from something like ruby where you have easy control of the field names! The out of the box request handlers are fine as well. You can go a long way - if you need to tweak later, you tweak. That's a far cry from everything you start with is an example.\n\nOthers with pre typed json don't want to have to redefine types...all that should work out of the box. I've got json, I've got strings, I've got ints, I want to plug them into a db and have simple search. That should be effortless. If I want to improve edge cases later, than I expand effort.\n\nA custom tweak or two is how all real systems work anyway - you get something good out of the box and then you tweak the settings. You don't tell users, oh actually, you have to replace ALL of the settings and config. It's just an absurd stance - only engineers would design a system like this.\n\nNow that we are also becoming a viable NoSQL option, I think the whole example thing is just stupid and a long term huge negative for Solr. It's also a lie, because almost every user install I've seen does not work this way. But so be it.\n\nMy checkout is already out of date, and I'm out of energy trying to argue my way into making Solr a reasonable OOTB experience. "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-13415767",
            "date": "2012-07-16T23:05:04+0000",
            "content": "Mark. I agree that for simple DB like searches you can do almost everything using example schema with dynamic fields. And if you don't care about building a great search experience, you can also do anything with the example schema - just throw some data at it, query and hey I get results!!  In the >100 enterprise search customer deployments I have done, there has always been business requirements involved calling for adjusting the schema. Often for simple things like indexing an Author field which should be searchable analyzed with phonetics and also should be a facet.\n\nI'd love for us to make Solr more and more light weight in terms of configuration. Letting things just work the way you'd expect. Perhaps we one day can offer users to use Solr in schema-less mode if they wish to - in the sense that you can mix and match pre-defined fieldTypes with ad-hoc ones. And that Solr figures out the optimal cache and warming settings automagically etc. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13415854",
            "date": "2012-07-17T02:58:55+0000",
            "content": "100 enterprise search customer\n\nLike I said - that is one segment of the Solr user base - and as a Solr consultant, I'm sure it's one you are well aware of - we serve many other user segments. Many of those segments are doing simple db searches! Many will start prototyping with simple db searches! Many startups and companies are doing things with simple searches! Mabye the simple stuff will be all they need. Or perhaps they will adjust some settings and change some fields when they feel comfortable and try and make the next thing work. This is how the developers I know develop software? Even the guys you are talking about - those enterprise developers - they like software that's easy too get started with as well.\n\nYou hit the nail on the head - this stuff feels like \"enterprise\". And that's too bad - practically, luckily you can do a lot without going through all the crap you claim that you need to go through - so if people do dive in, they realize all this example stuff we have around is half non sense and they just use the configs as starting settings. It's a scary jump you have to make though. I looked and didn't jump once. New users certainly don't plan out a schema on day two of playing with Solr. But they should be able to prototype simple solutions on day 1 of playing with Solr! We do a disservice to confuse them \"for their own good\" so that they sit and contemplate on the high levels of search before they even dare start prototyping a system. Enterprise software indeed \n\nI'll be working against that vision pretty hard. I have a pretty much the opposite vision. Only in enterprise software do you endeavor to be so difficult to get started at the expense of the developer \"for their own good\".\n\nIt's not our job to force developers to make \"wonderful\" search experiences - it's our job to give them the tools and user experience that gets out of their way and allows them a lot of power. If we do that, they will figure out the \"wonderful\" search experience part - not because we said they have to edit xml files before they even start thinking about starting a real solr install - but because we gave them a nice dev friendly system with a lot of power, and developers know how to do the rest. The ones that don't - your not going to teach them anything anyway.\n\nI know as a search consultant it can be attractive to say \"search is hard!\" - but we should be saying \"search is easy to get started with!\" - because it is (though it should be much easier than we currently make it look).\n "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13416150",
            "date": "2012-07-17T12:45:45+0000",
            "content": "\"This is for your own good.\" That's what they told the tomcat before his operation.\n\nIt seems to me that this discussion has strayed, it started out discussing renaming the example directory. Is it fair to say that there's agreement there and the rest can be tackled later? And Mark can check his changes in and not have to continue reconciling these changes?\n\nWe can't protect the user from themselves. If they are satisfied with \"crappy search apps\", well it must be good enough for their needs; it's not our place to second-guess them. Nor force them to jump hurdles in order to do get their job done.\n\n+1, frankly, for Mark to do whatever he thinks best here. He's doing the work after all. "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-13418825",
            "date": "2012-07-20T00:16:41+0000",
            "content": "Mark, after all these words far from the original issue  let me wrap up using bullets\n\n\n\tThere are many levels of Solr users. You're mainly focused on the simplest structured-data ones; I the full-text \"enterprisy\" ones. Fair enough.\n\tThe current example config serves the simple users/apps pretty well OOTB - I agree on that\n\tThe example config, if not enough for enterprise use-cases, serves well for first days rapid prototyping\n\tNoone should be told that \"Solr is hard, don't expect to get anything done before X Y and Z\". If you feel the word \"example\" implies this, feel free to improve on the terminology\n\tWe should strive to make Solr as zero-config as possible. Pretending it already is today does not help.\n\n\n\nGo ahead Mark, progress is made one step at a time, this JIRA is one such step "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13429796",
            "date": "2012-08-07T03:43:07+0000",
            "content": "rmuir20120906-bulk-40-change "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13438032",
            "date": "2012-08-20T17:53:31+0000",
            "content": "I started reading through this, and then got bogged down, and didn't have the energy to keep going.\n\nSo i'm just going to point out the suggestion i made a while back in SOLR-3259 but never got any feedback on...\n\nhttps://issues.apache.org/jira/browse/SOLR-3259?focusedCommentId=13234012&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13234012\n\nIn summary...\n\n\n\trename example to server\n\tmake .../solr/collection1 a super generic kitchen-sink set of configs\n\t\n\t\tinclude every imaginable field type and  dynamicField, and a super generic set of explicit fields\n\t\tthis would be the recomended starting point for all new users\n\t\tthis collection would work out of the box when running \"java -jar start.jar\"\n\t\tthis collection would come with no sample data\n\t\n\t\n\tmake a bunch of .../solr/example-collections/* directories\n\t\n\t\tie: minimal tech-products, books, super-heroes, rss, etc...\n\t\teach of these collections would have scaled down configs, tailored to the example use case, showing off just the fields/features that matter for the use case\n\t\teach of these collections would either have an ./exampledocs directory, or a DIH config for fetching some sample data\n\t\tthese collections would not be enabled by default or even mentioned in the solr.xml, but the wiki pages and tutorials that wanted to refer to them could list the CoreAdmin CREATE url to start using them\n\t\n\t\n\n\n\n...that way people who want to get started quickly with the \"recomended server setup\" can just copy the \"server\" directory, and delete everything under \"example-collections\".  people can also look customize their solr/collection1 configs either by pruning, or by drawing inspiration from the special case example stuff in the examples.\n\nThe basic migration would be something like...\n\n\nmkdir solr/example/solr/example-collections\nsvn cp solr/example/solr/collection1 solr/example/solr/example-collections/tech-products\nsvn cp solr/example/solr/collection1 solr/example/solr/example-collections/books\n# :TODO: edit solr/example/solr/example-collections/tech-products to prune it down\n# :TODO: edit solr/example/solr/collection1 to remove anything too product-ish specific\n# :TODO: edit solr/example/solr/example-collections/books to remove anything to product-ish specific and make fields more 'book' specific\nmkdir solr/example/solr/example-collections/books/exampledocs\nmkdir solr/example/solr/example-collections/tech-products/exampledocs\nsvn mv solr/example/exampledocs/books.* solr/example/solr/example-collections/books/exampledocs\nsvn mv solr/example/exampledocs/*.xml solr/example/solr/example-collections/tech-products/exampledocs\nsvn mv solr/example/exampledocs/* solr/example\nsvn mv solr/example/example-DIH/solr/rss solr/example/solr/example-collections/dih-rss-crawling\nsvn mv solr/example/example-DIH/solr/db solr/example/solr/example-collections/dih-db-crawling\nsvn mv solr/example/example-DIH/solr/mail solr/example/solr/example-collections/dih-mail-crawling\nsvn mv solr/example/example-DIH/solr/mail solr/example/solr/example-collections/dih-tika-crawling\nsvn rm solr/example/multicore # no longer needed, everything else is already a multicore example\n# :TODO: add a solr/example/solr/example-collections/minimal\n# :TODO: update example tests to CREATE every example-collection and index some data.\nsvn mv example server # since that's what people seen to want\n\n\n "
        },
        {
            "author": "David Smiley",
            "id": "comment-13440958",
            "date": "2012-08-24T05:08:20+0000",
            "content": "+1 Hoss.  The main points I like here that I've been hoping for are:\n\n\tThe rename of \"example\" to \"server\"\n\tIntegrating or at least organizing the various configurations.\n\tAn even better new project template.\n\n "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13456397",
            "date": "2012-09-15T12:49:26+0000",
            "content": "Unassigned issues -> 4.1 "
        },
        {
            "author": "Steve Rowe",
            "id": "comment-13717208",
            "date": "2013-07-23T18:47:29+0000",
            "content": "Bulk move 4.4 issues to 4.5 and 5.0 "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-13970976",
            "date": "2014-04-16T12:56:47+0000",
            "content": "Move issue to Solr 4.9. "
        },
        {
            "author": "Timothy Potter",
            "id": "comment-14064938",
            "date": "2014-07-17T14:00:37+0000",
            "content": "Resurrecting interest in this as I'd like to get this done in the near term. Main question is whether this will only be for Solr 5 or should be backported to 4.x? "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-14064953",
            "date": "2014-07-17T14:17:35+0000",
            "content": "Good luck getting consensus   I sort of lost interest when it looked like some of the proposals would have made things more complex (or at least as complex) as what we have now. "
        },
        {
            "author": "Timothy Potter",
            "id": "comment-14065174",
            "date": "2014-07-17T17:29:28+0000",
            "content": "A fair point Yonik  We need to come together on this quickly as I hear often how unintuitive the Solr directory layout is compared to other open source search engines based on Lucene. \n\nWhat about leaving example untouched and introducing a new server directory? That would make backporting easier and satisfy the bulk of the concerns of new users looking at Solr's directory structure. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-14065222",
            "date": "2014-07-17T17:49:55+0000",
            "content": "I think we should make this change in 4x and 5x. No reason we should have to wait for 5x to get a sensible modern directory layout.\n\nWhat about leaving example untouched and introducing a new server directory? \n\nAs long as we pull jetty and what not out into the server directory. We can improve on the sprawling example dir later. I would hate to see another set of configs introduced though.\n\n\n "
        },
        {
            "author": "Alexandre Rafalovitch",
            "id": "comment-14065877",
            "date": "2014-07-18T01:39:01+0000",
            "content": "Just to be \"fair and balanced\", ES does not come with any examples at all. Or JavaDoc. Or Admin console. Or sample documents. Not that shipping PDF sample documents would help anyway, because it also does not come with Tika (which is a separate plugin). Nor does it ship tutorial, only the guide on the website. \n\nBut it is easy to get started as the download is only 22Mb and they can index their first document by the time Solr's 154Mb is downloaded and unpacked. This differential becomes more and more important as not everybody has a FIOS.\n\nBut, let's return  to user perception and the directory structure to improve such.\n\nIdeally, one would write a tutorial first that show cases most important Solr features. Then, we would adjust the structure of the directories to make that tutorial a reality. In my eyes, this would mean moving collection1 example into a new kitchen_sink directory and creating a new one that skips all the defaults and non-immediately affective declarations (e.g. warmers) and has a highest impact for smallest number of lines configuration. Which would probably include schema auto-detect, skip the /browse handle and maybe keep only one non-English type (e.g. German to show case accent folding, token-splitting, etc).\n\nJust as ideally, somebody would sponsor/build a web-based config generation wizard. I have an initial design document, which I am happy to share. But the basic idea is the same as http://www.initializr.com/ : hit a bunch of check-boxes get a fully-configured collection config showcasing user's specific needs. Possibly with 'with comments/without comments' button or some such. This would give flexibility of having a bunch of blueprints (as mentioned in past comments) but without them contributing to the bulk of the downloaded Solr distribution. "
        },
        {
            "author": "Timothy Potter",
            "id": "comment-14066878",
            "date": "2014-07-18T21:08:38+0000",
            "content": "Alexandre - you raise some great points ... I'm ingesting not ignoring (and detained on another short project through today) hope to get back to this on Monday. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-14067625",
            "date": "2014-07-19T18:32:10+0000",
            "content": "Just to be \"fair and balanced\", ES does not come with any examples at all. \n\nTo me, this issue is not about being more like ES. It's about being like most database systems out there. Examples are good, calling your out of the box experience an example is not good. \n\nThere are lot's of low hanging ease of use issues we can address, but I still think the best way for this issue to move forward is to do what it says in the title and fight other battles in other issues.\n\nRename 'example' dir to 'server' and pull examples into an 'examples' directory\n\nLet's ship with a server dir where out of the box Solr lives. Let's move the example stuff mostly out of that.\n\nWe can work on other things in other issues. Like not having this silly default collection1 and exactly how many examples we should have and how they should be laid out. Let's just get a server directory going without duplicating stuff from example. We don't want to drop examples, we want to have a simple and generic out of the box experience and offer easy to use examples somewhere to the side. "
        },
        {
            "author": "Alexandre Rafalovitch",
            "id": "comment-14067756",
            "date": "2014-07-20T01:33:24+0000",
            "content": "+1 on splitting the issue if that gets something in here done. \n\nJust to clarify though, when a server is started, it still needs to point at something, right? To keep the \"download, unzip, run\" experience.\n\nThat's going to be some collection1? What that's going to be? A new basic example? Or still the original one just with different path and invocation command line? "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-14067757",
            "date": "2014-07-20T01:42:00+0000",
            "content": "Just to clarify though, when a server is started, it still needs to point at something, right? To keep the \"download, unzip, run\" experience.\n\nYeah, it feels like one should still be able to start the server and then index a document (as they can do now) without any other mandatory steps. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-14067779",
            "date": "2014-07-20T03:07:42+0000",
            "content": "I don't think so. Having this 'collection1' is just odd. You want to rename it right away.\n\nI think the issue is, it just has to be a single command to get a collection1 named what you want. And it should be easy to get a sensible starting schema or go \"schemaless\". A flag change at most.\n\nSo you have:\n\n\n\tdownload\n\trun\n\tcreate mycollection\n\tindex a doc\n\n\n\nMaking it so that any real system first has to delete collection1 and acting against the normal for systems like this doesn't seem worth it.\n\ncreate mycollection just has to be about that simple, and then they know how to create mycollection2.\n\nHaving a default collection1 is just a band aid for the amount of work we put you through to create a collection. It's pretty undesirable other than that. "
        },
        {
            "author": "Alexandre Rafalovitch",
            "id": "comment-14067787",
            "date": "2014-07-20T03:55:42+0000",
            "content": "Ok, so what does this mean on the practical level: *create mycollection*. Especially for people who are still trying Solr as opposed to doing production setup (two different distributions?).\n\nThe way ES handles it now is by basically baking in the templates and defaults into the core jars. So, the first time you issue a URL against non-existing collection, it's created and inherits all the defaults (ids, endpoints, default types (including multilngual), etc).\n\nSolr requires everything explicitly. And you cannot expect people to create a schema.xml and solrconfig.xml from scratch to get their first collection to work. So, *something* has to pre-exist. And that something should be easy to run as step 3 (worst case 4). \n\nIf it's not a pre-built collection, then we need some sort of wizard to create the directory structure. How do you see that? Maybe with global configsets or something similar? I would love that, but I am not sure that starting to talk about the wizards in this JIRA is any smarter than rebuilding the whole set of examples. "
        },
        {
            "author": "Alexandre Rafalovitch",
            "id": "comment-14067791",
            "date": "2014-07-20T04:08:24+0000",
            "content": "Rereading the comment. Did you mean the following sequence of steps?\n1) Download\n2) Unzip\n3) Start server\n4) Visit Admin UI\n5) Create new collection (using one of provided configsets, which is basically renamed examples)\n6) Index?\n\nThat could work. And a good differentiation from ES, as we ship AdminUI in the box (theirs is separate and is free for development only). \n\nWe'd need UI support for configsets (and I don't actually know how extensive they are), but that's probably a good idea anyway. On the other hand, asking users to create a directory in a right location, copy schema and solrconfig files there (from where?) and then do AdminUI (or command line) call to create collection - is NOT going to work.  "
        },
        {
            "author": "Mark Miller",
            "id": "comment-14067794",
            "date": "2014-07-20T04:11:53+0000",
            "content": "It would be just like it is now. People don't start from scratch, they pull the so called example config and build from that. You should be able to say, create me a collection and get that at a minimum. Except it should be better - schema guessing option, dynamic field option, production schema option, etc. Less example, and more practical. It's all common sense, and it's basically how things have worked anyway, it's just that automating it and simplifying it hasn't happened yet. When I was at Lucid we did a lot of this with config 'templates' for their enterprise search product. You can get a default starting template, a built in template, a user supplied template. Probably lot's of ways to hide the current exposed complexity and not sacrifice power or control. We should discuss all this in other issues though. This issue won't remove collection1. "
        },
        {
            "author": "Alexandre Rafalovitch",
            "id": "comment-14067797",
            "date": "2014-07-20T04:23:04+0000",
            "content": "I do not disagree with a single thing you say there. All I am asking is to clarify/visualize the exact user experience at the end of this JIRA before you start moving things around. Step by step UX, not generalizing \"create a collection\" bit. I think it is important not to diminish the usability we already have and I am happy for the actual improvements to be in discussed separately. \n\nI am assuming, of course, we are still talking about releasing this specific improvement as part of Solr 4.X and not just as a small part of the big 5.0 overhaul. "
        },
        {
            "author": "Upayavira",
            "id": "comment-14067875",
            "date": "2014-07-20T10:12:13+0000",
            "content": "As someone who teaches people how to use Solr, I think the contents of this ticket is very useful and necessary.\n\nAs someone who likes automation, I find it a little scary. Changing the directory structure as substantially as is proposed in a minor release to me kinda gives the wrong message.\n\nMy preference would be to accept that version numbers are cheap, this is incompatible, so release it soon in 5.0. Folks will then expect some back incompatibility, so all is good. "
        },
        {
            "author": "Timothy Potter",
            "id": "comment-14067932",
            "date": "2014-07-20T13:49:59+0000",
            "content": "I don't think so. Having this 'collection1' is just odd. You want to rename it right away.\n\n+1 ... Let's not forget how weird collection1 makes starting up Solr in cloud mode the first time with the \"-Dbootstrap_confdir=./solr/collection1/conf -Dcollection.configName=myconf\" stuff (plus you never use those flags again when adding new collections to a cluster). I think having to create a collection when getting started with the proposed server directory is quite natural, just like you have to do when starting out with a database like mysql. "
        },
        {
            "author": "Jack Krupansky",
            "id": "comment-14067950",
            "date": "2014-07-20T14:51:21+0000",
            "content": "a database like MySQL\n\nBut Solr isn't a database! (Nor is Elasticsearch.)\n\nI think part of the issue here is that there are two distinct use cases: single core and multi-core, or single collection and multiple collection. Solr is perfectly usable in single-core/collection mode - the user need not concern themselves with naming a collection. In that case, the fact that there is this extra level of abstraction called a \"collection\" and it is named \"collection1\" is a bit of an annoyance and distraction, so the less annoying the better. Forcing the user to come up with a name and perform an extract step of naming that default collection adds no significant value for the single-core-collection use case, or the onboarding or introduction of new users to Solr as \"a simple but powerful search platform.\"\n\nSure, once the user has decided that they indeed have the multi-core/collection use case, THEN they will want to name their cores/collections with \"real\" names. Sure, by all means make support for this use case as clean and convenient as possible.\n\nWhy not simply give the user a choice, up front, and let them decide for themselves what use case they want? Whether that is a separate download or a separate startup command or a separate start directory seems like more of a detail than an architectural choice for de-supporting one useful use case.\n\nI would say leave the current \"example\" where it is, as it is, and have a separate, clean download for \"multi-collection server\" mode. I'm sure people deploying SolrCloud clusters in the cloud would appreciate the latter, without any burden of example and tutorial fluff.\n\nAnd maybe the use case distinction is simply SolrCloud vs. traditional Solr. And then for the new (5.0) SolrCloud server mode, we can have a little script for \"quick demo mode\" that is more like the current example/collection1 setup - or a separate example/introduction/tutorial download from the raw server download.\n\nIn short, don't sacrifice the current simplicity, but do pursue the 5.0 server mode.\n\nMaybe if progress were made on the 5.0 Solr \"server\", some of these details would just fall out or at least be more obvious and non-controversial.\n\nAs it is, this is feeling a lot more like \"rearranging deck chairs on the Titanic\" than helping Solr to leapfrog to a whole new level in either \"server-ness\" or \"ease-of-use-ness.\"\n\nBTW, has any thought been given to including a packaging of the 5.0 Solr server as a \"Windows service\"? That might also help to clarify some of this packaging stuff.\n\n "
        },
        {
            "author": "Mark Miller",
            "id": "comment-14067951",
            "date": "2014-07-20T14:56:01+0000",
            "content": "Single core must die. And so must this bad \"core\" name.\n\nSolr and ES are databases. We just happen to have a lot better search.\n\nWhen you have a system that allows multiple collections, you make it easy to create one and have the user do it upfront so they know how. You never pretend that there is this universal collection unless you want to delete it and go into \"multi collection\" mode.\n\nThat's just silly. This has all been done before, it's not rocket science  "
        },
        {
            "author": "Mark Miller",
            "id": "comment-14067952",
            "date": "2014-07-20T14:58:36+0000",
            "content": "I do not disagree with a single thing you say there... Step by step UX, not generalizing \"create a collection\" bit....\n\nLike I said, this issue is not about removing the default collection1. That really has no bearing on this issue. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-14067954",
            "date": "2014-07-20T15:01:44+0000",
            "content": "\nMy preference would be to accept that version numbers are cheap, this is incompatible, so release it soon in 5.0. Folks will then expect some back incompatibility, so all is good.\n\nSolr should be developed by \"doing what is right\". Once we have that, you can decide where that needs to happen - the next 4x release, the 5x release, with a back compat layer, whatever. Coming at it back compat \"oh my\" first is why we never move. Let's decide how things should be and focus on our energy on making it happen, not why it cannot happen. "
        },
        {
            "author": "Alexandre Rafalovitch",
            "id": "comment-14068103",
            "date": "2014-07-21T01:44:45+0000",
            "content": "Ok, everybody is right  But we are talking in abstract. \n\nBack in August (2012!) on this issue, Hoss made a concrete proposal. Directory layout and all. Maybe it would be good to repeat that exercise and drop the discussion down to the lower level. Then, we can see whether it is ok for 4.x line or stays in 5.x line. I, for one, have a single main concern. I am trying to understand what will be the new first command for a new user instead of \"java -jar start.jar\". I have no further comments for this issue until I can see that low-level element. \n\nI do have lots of comments and ideas on general UX/experience improvement but it can wait for a personal project, another JIRA or an evening huddle at the conference. "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-14068403",
            "date": "2014-07-21T11:04:32+0000",
            "content": "Yeah, it feels like one should still be able to start the server and then index a document (as they can do now) without any other mandatory steps.\n\n+1\n\nAgree, single core dies, collection1 dies.  Everything should just work out of the box!  The first 5 minute experience should be all about the user and their data and very little to do about solr configs, schemas, etc.  Same for pretty much the whole first day.  By the end of the first week, a new user should have a thorough understanding of what they need to do to get to production.  \"Easy to start, easy to finish\".   "
        },
        {
            "author": "Mark Miller",
            "id": "comment-14068591",
            "date": "2014-07-21T14:56:53+0000",
            "content": "Maybe it would be good to repeat that exercise and drop the discussion down to the lower level. \n\nNo, please no! Let's just talk about a server directory. Let's not screw this issue by trying to do more than that. Been there. That can come later.\n\nI am trying to understand what will be the new first command for a new user instead of \"java -jar start.jar\".\n\nNo!  This issue doesn't change that.\n\nIf we let this issue get bogged down with all that shit, it's dead just like last time and just like in other issues.\n\nRename 'example' dir to 'server' and pull examples into an 'examples' directory\n\nThis doesn't require crazy new layouts! This doesn't require removing collection1! This doesn't require a new way to start Solr! Let's focus on this first. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-14068711",
            "date": "2014-07-21T16:15:51+0000",
            "content": "I do have lots of comments and ideas on general UX/experience improvement but it can wait for a personal project, another JIRA or an evening huddle at the conference.\n\nStart filing JIRAs and linking them as related to this  We have a lot to do. The problem is, every issue can be contentious depending on who gets involved. \n\nI think to start, we will have to go very step at a time. Like here: let's see what we have to do to get a sever folder while making as few other changes as possible. Even if it can only go into 5x. We can figure out how to do that with minimal disruption I think. And that gives a toe hold to start pushing from.\n\nIn the meantime, let's discuss all these other ideas in related issues. We should discuss them, it's just dangerous to keep weighing this issue down with that discussion - that type of thing can put an issue on ice. \n\nSome JIRA's are already out there, like adding start scripts, and I think removing collection1, etc.  "
        },
        {
            "author": "Mark Miller",
            "id": "comment-14070636",
            "date": "2014-07-22T18:24:52+0000",
            "content": "So one idea, along the lines of what Tim first proposed is to do something like:\n\nleave example as it is for now\nadd the server dir and put the start scripts in it and set them up to work with example for now\n\nNot very contentious, but gets us a start on pimping out a server folder? "
        },
        {
            "author": "Timothy Potter",
            "id": "comment-14070700",
            "date": "2014-07-22T18:57:12+0000",
            "content": "+1 I blocked off all day tomorrow to focus on this issue so look for a patch (using the scripts from SOLR-3617) later in the day tomorrow. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-14077633",
            "date": "2014-07-29T11:41:08+0000",
            "content": "Any progress on that Tim? "
        },
        {
            "author": "Timothy Potter",
            "id": "comment-14078331",
            "date": "2014-07-29T20:50:27+0000",
            "content": "Here is a patch that introduces a server directory.\n\nFirst, note that many of the files that were in the example will be svn mv'd to preserve history when I do the commit, but I've included them as \"adds\" using svn diff --show-copies-as-adds so that you can actually try out this patch if you're so inclined.\n\nThe new directory structure of packaged Solr will be:\n\n\n<tip>\n|__bin (see SOLR-3617 for scripts)\n     |__solr (for *nix)\n     |__solr.cmd (for Windows)\n|__contrib\n|__dist\n|__docs\n|__example\n     |__example-DIH\n     |__example-schemaless\n     |__exampledocs\n     |__multicore\n     |__solr\n|__licenses\n|__server\n     |__contexts\n     |__etc\n     |__lib\n     |__logs\n     |__resources\n     |__scripts\n     |__solr\n     |__solr-webapp\n     |__start.jar\n     |__webapps\n\n\n\n\nI left the examples untouched as much as made sense; basically the example directory just contains solr home directories for our existing examples. In other words, example now contains examples and server contains scripts, binaries, and resources needed to run Solr as a server or any of the examples.\n\nI've run ant precommit (with clean-jars and jar-checksums) and ant package and the build changes seem to work. There's probably still some clean-up needed for the README.txt files but I took a stab and updating those as well.\n\nThe biggest thing we now need to decide is what a default config looks like?\n\nOnce you start Solr with the new scripts and server directory, there is no core or collection created (ie. no more collection1). So if a user wants to create a new core, they need some config to point at. \n\nI vote for a minimal solrconfig.xml and managed-schema; basically I would strip out all non-essential elements from the solrconfig.xml from the schema-less example for Solr's default config.\n\nAlso, to be clear, a user can launch any of the examples if they are so inclined using:\n\nbin/solr -e <EXAMPLE> (see SOLR-3617)\n\nfor instance\n\nbin/solr -e dih\n\nwill launch Solr from the server directory with solr.solr.home set to example/example-DIH/solr\n\nI'm asking if we want to include a minimal solrconfig.xml / schema.xml configuration that new users can use to setup their own index? If so, where should that live? I think server/solr/default_conf makes sense but am not married to that path. Perhaps we could use XSL transform to strip out non-essentials from the solrconfig.xml in example-schemaless? "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-14078990",
            "date": "2014-07-30T06:49:49+0000",
            "content": "Woohoo! Go Tim! "
        },
        {
            "author": "Mark Miller",
            "id": "comment-14079335",
            "date": "2014-07-30T14:55:57+0000",
            "content": "Heh, you went full hog.\n\n+1 from me, that's all stuff I want. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-14079345",
            "date": "2014-07-30T15:01:38+0000",
            "content": "I'm asking if we want to include a minimal solrconfig.xml / schema.xml configuration that new users can use to setup their own index?\n\nYes, we must if we are going to remove the default core / collection. It must be very simple to create one then. I think you should not even have to specify config in which case you get the default.\n\nI vote for a minimal solrconfig.xml and managed-schema; basically I would strip out all non-essential elements from the solrconfig.xml from the schema-less example for Solr's default config.\n\nIdeally, that is what I want as well. You either start solr with std minimal config (perhaps the schema just has dynamic fields defined) or in schemaless. Either one should be just as easy. Some stuff should probably be commented out to make it easy to enable, but a lot could go in a kitchen sink example or doc.\n\nIf so, where should that live?\n\nNo strong preference. "
        },
        {
            "author": "Timothy Potter",
            "id": "comment-14079430",
            "date": "2014-07-30T16:12:42+0000",
            "content": "Thanks for the feedback! I'm wondering if we should rename example -> examples as well? In addition, that solr directory under example (aka the kitchen sink example) sticks out to me like a sore thumb ... thinking it should have a better name. See any issues with a few additional renames as part of this change?\n\nI'll provide the default_conf directory in this ticket and add an easy way to create a core (for standalone) or collection (for cloud) using the bin/solr script. We might need some UI changes to the Core Admin page to use this default_conf by default when creating a new core (I'll open a different ticket for that).\n "
        },
        {
            "author": "Mark Miller",
            "id": "comment-14079446",
            "date": "2014-07-30T16:20:45+0000",
            "content": "See any issues with a few additional renames as part of this change?\n\nI don't, but at this point, with these changes, this is all 5x I think. My feeling is, as painful as it might be in some cases, we need to make things as right as possible for 5x though. So in my opinion, everything is fair game to get things right, renames included. Depends on who chimes in when though.\n\nI was thinking of a more limited server folder that would also work with 4x. But IMO, you have gone with what really needs to be done, which is along the lines of what I have pushed for for a long time, and that kind of effort and work needs to be absorbed when it shows up. \"Those that do, decide\", because otherwise the \"doing\" goes to /dev/null  So I'm +1 on \"let's make 5x like it should be\".\n\nthinking it should have a better name. \n\nYup. "
        },
        {
            "author": "Timothy Potter",
            "id": "comment-14079486",
            "date": "2014-07-30T16:42:01+0000",
            "content": "because otherwise the \"doing\" goes to /dev/null \n\nNo doubt! Your original patch on this was an immense amount of work sent into /dev/null  I'm happy to scale back some of these changes if it helps get it into 4x. What jumps out as being incompatible with 4x here? Heck, we can ship a script that creates symbolic links to do:\n\nln -s server/start.jar example/start.jar\n\netc\n\nOn the other hand, this will create some headaches back-porting from trunk to 4x but for the most part, it shouldn't be too bad since there aren't any code-level changes.\n\nLastly, I definitely want to get the scripts in place for 4x as those don't introduce back compat issues and I'd like to see those get some use sooner than later. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-14079547",
            "date": "2014-07-30T17:13:07+0000",
            "content": "Because of upgrade difficulties and the degree of changes for a point release, I would guess 4x would get a lot of pushback. I wouldn't really be against it myself.\n\nOn the other hand, I don't think 5x is that far out in the scheme of things. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-14079551",
            "date": "2014-07-30T17:14:29+0000",
            "content": "On the other hand, this will create some headaches back-porting from trunk to 4x\n\nYeah, that was most of the pain I was referring to with \"My feeling is, as painful as it might be in some cases\".\n "
        },
        {
            "author": "Timothy Potter",
            "id": "comment-14088029",
            "date": "2014-08-06T18:51:14+0000",
            "content": "Just an update on where things sit with this one. I've committed bin/solr scripts (SOLR-3617) that will work with this new layout (and the legacy example layout). \n\nNext patch will include a new default_conf directory cooked up in server/solr/default_conf. It's a minimized solrconfig.xml with managed-schema and field-guessing enabled.\n\nHaving a default conf directory raises the question of how to use it during core creation? This is mainly for non-cloud mode since in cloud mode, you have to upload a config directory to ZooKeeper before creating cores and we have tools for that.\n\nWe can either\n\n\thave the bin/solr script implement a \"new_core\" command bin/solr new_core -n foo that creates the instance directory and cp -r's the default_conf to instanceDir/conf for the user and then just hits the Core API's CREATE endpoint, or\n\tadd the ability to create a core using the default configuration to the CoreAdminHandler, i.e. the core creation logic uses some logic added to the SolrResourceLoader to find the default config when solrconfig.xml is not found\n\n\n\nOf the two approaches, I'm favoring the first because it's more like the cloud experience (tooling puts the config in the right place), esp. since the Core Admin API isn't usable for creating new cores without doing some work upfront on the command-line (i.e. user has to go create the instanceDir first anyway).\n\nThe first approach also avoids the Solr code doing something subtle behind the scenes that the user is not aware of; for instance if the user fat-fingered the name of their conf directory (e.g. their instance dir contains cnf instead of conf) or something silly like that, building logic into the CoreAdminHandler to use default config would skip their config and use the default one vs. throwing an error about not finding their conf. However I have a way of talking myself into things that require less work  "
        },
        {
            "author": "Steve Rowe",
            "id": "comment-14088038",
            "date": "2014-08-06T18:56:47+0000",
            "content": "Tim, in standalone mode, a third option would be to use the named configsets functionality, right?: SOLR-4478 "
        },
        {
            "author": "Mark Miller",
            "id": "comment-14088054",
            "date": "2014-08-06T19:03:04+0000",
            "content": "Next patch will include a new default_conf directory cooked up in server/solr/default_conf. It's a minimized solrconfig.xml with managed-schema and field-guessing enabled.\n\nI'm not sure I'm sold on that as the default. Perhaps - with some big red documentation warnings. I think at a minimum though, it needs to be as easy as a command line switch to change between the two defaults. I think the non managed-schema and non field-guessing default should probably just have dynamic fields as a start. Field guessing has too many downsides to bring it to the front without a sensible production default as well. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-14088062",
            "date": "2014-08-06T19:05:15+0000",
            "content": "We can either\n\nShouldn't the core create command just create the instance dir and move the config into place when it sees the user did not specify any config? "
        },
        {
            "author": "Mark Miller",
            "id": "comment-14088066",
            "date": "2014-08-06T19:06:27+0000",
            "content": "I'm favoring the first because it's more like the cloud experience (tooling puts the config in the right place), \n\nI want to hide that as well. This is a negative currently. It should be optional IMO. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-14088077",
            "date": "2014-08-06T19:15:33+0000",
            "content": "Tim, in standalone mode, a third option would be to use the named configsets functionality, right?\n\n+1, this feels like the right way.  This should also sort of mirror cloud-mode given that config sets were supposed to mirror cloud-mode, right?\n "
        },
        {
            "author": "Mark Miller",
            "id": "comment-14088091",
            "date": "2014-08-06T19:21:41+0000",
            "content": "Yeah, it should be done with named config sets.\n\nThe key then, for both modes, is allowing the use of template/default config sets without uploading them or setting them up first. "
        },
        {
            "author": "David Smiley",
            "id": "comment-14088093",
            "date": "2014-08-06T19:21:48+0000",
            "content": "Tim, in standalone mode, a third option would be to use the named configsets functionality, right?\n\nDefinitely; right?  It's pretty useful.\n\nI think the non managed-schema and non field-guessing default should probably just have dynamic fields as a start. Field guessing has too many downsides to bring it to the front without a sensible production default as well.\n\n+1 I can't stand field guessing; lets not encourage users "
        },
        {
            "author": "Timothy Potter",
            "id": "comment-14088106",
            "date": "2014-08-06T19:31:21+0000",
            "content": "+1 on the named configsets approach (working on that now)\n\nI'm not sure I'm sold on that as the default ... without a sensible production default as well.\n\nI guess I was optimizing for a quick and easy getting started experience. Solr doesn't have a getting to production problem, it's the getting started path that's way too complicated, esp. for a new user population that knows they need search  and just wants to kick the tires on Solr for a few minutes / hours.  There's something very powerful about being able to: 1) start solr, 2) send in a few JSON docs, 3) query for your data.\n\nOf course we all know that adding some data and firing off a few queries is a long way from production, but if we lose the user in the first 5 minutes, getting to production is no longer relevant. So I think we need a low-barrier to entry configset for this user population and if we want to have another more structured configset, that's great too. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-14088119",
            "date": "2014-08-06T19:43:54+0000",
            "content": "Solr doesn't have a getting to production problem\n\nIt will if you make the default field guessing and make a production default hard by leaving it out.\n\nbut if we lose the user in the first 5 minutes,\n\nThat is why we need both modes and it need to be just as easy to choose either.\n\nI'm -1 on making a sensible default hard and a prototyping default easy. They both need to be just as easy, a good production start can't be eclipsed. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-14088141",
            "date": "2014-08-06T19:57:19+0000",
            "content": "I guess I was optimizing for a quick and easy getting started experience. Solr doesn't have a getting to production problem,\n\n+1\n\nI'm -1 on making a sensible default hard and a prototyping default easy. They both need to be just as easy,\n[...] \nThat is why we need both modes and it need to be just as easy to choose either.\n\nHaving modes (esp called production vs prototyping) ups the perceived complexity again and makes the prototyping mode feel cheap somehow (i.e. it's just for show).\n\nSchemaless can sometimes be desired in production (an internal cloud type scenario where new collections are being created often by new users).  For those who want to lock down their schema, it should be easily doable/changeable via an API.  Same goes for the managed schema. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-14088151",
            "date": "2014-08-06T20:02:41+0000",
            "content": "Having modes (esp called production vs prototyping)\n\nThey are not actually modes, they are just different starting config. The complexity is already well beyond that. One can certainly be a \"specify\" nothing default. I'd still vote for production 'config' for that. The other should be as easy as a param to choose.\n\nSchemaless can sometimes be desired in production\n\nYes, in some very specific cases, so it doesn't really affect this discussion. It's mostly not desired, especially with the misguided idea that it's \"friendly\", because its more 'insidious' in production than friendly unless you understand what you are getting into well.\n "
        },
        {
            "author": "Mark Miller",
            "id": "comment-14088159",
            "date": "2014-08-06T20:06:56+0000",
            "content": "production vs prototyping\n\nThe names would probably be more like 'default' and 'schemaless'. Documentation should warn heavily about schemaless in production. "
        },
        {
            "author": "Timothy Potter",
            "id": "comment-14088173",
            "date": "2014-08-06T20:12:55+0000",
            "content": "non field-guessing default should probably just have dynamic fields as a start\n\nWhen I look at the managed-schema from the schemaless example (which is what I based the default on), it has all the popular Solr field types and dynamic fields defined. I've attached it here for your review - let me know if you want to add/remove anything.\n\nI'm not trying to be obtuse or argumentative, but can you elaborate on how enabling an optional feature makes it hard to go to production? If I don't want field guessing, then my docs coming need to be well-formed to the schema that is defined.\n\nDisabling field guessing requires one line change (to comment out the add-unknown-fields-to-the-schema in the update chain) and I don't think we've ever advocated going to production without the user doing a thorough review of their solrconfig.xml.\n\nMy default solrconfig.xml is attached too, please review as I was pretty aggressive with my removals.\n\nAt this point, it sounds like we're in agreement that there should be a getting started configset and another one that doesn't have field guessing enabled. Any other features that you think are important to be enabled /disabled. These configsets need names? Thinking data-driven-schema (Hoss' term) and default?? "
        },
        {
            "author": "Mark Miller",
            "id": "comment-14088184",
            "date": "2014-08-06T20:18:24+0000",
            "content": "how enabling an optional feature makes it hard to go to production?\n\nRight now you basically start with how we recommend you go to production. From what I understand, your proposal means everything just works as \"schemaless\" and you would have to dig to figure out how to get out of this mode. Find some other config files to plug in, figure out what to edit in your config files, I don't know. By enabling this optional feature, you are making the non optional part more difficult to get to and likely just out of mind entirely.\n\nFor those who want to lock down their schema, it should be easily doable/changeable via an API. \n\nIf I though that was easier that it seems to me, I might be willing to go further down that thought path.\n\nChris Hostetter (Unused), any chance I can ask for your opinion on this issue?\n "
        },
        {
            "author": "Mark Miller",
            "id": "comment-14088195",
            "date": "2014-08-06T20:26:56+0000",
            "content": "Has anyone started in managed schema mode and used the rest api to lock down a real schema and compared that to building the schema in an xml file? Is it pretty nice or is it a fork in the eye? Is it easy to bootstrap the managed schema stuff with a hand built schema.xml? "
        },
        {
            "author": "Cassandra Targett",
            "id": "comment-14088235",
            "date": "2014-08-06T20:58:28+0000",
            "content": "Has anyone started in managed schema mode and used the rest api to lock down a real schema and compared that to building the schema in an xml file? \n\nI did it recently and didn't think it was bad at all. I was trying to index some web access_logs with logstash into a SolrCloud instance and wanted to avoid ZK tools to edit the files, so I put it in managed schema mode and used the REST API to make fields & copyFields. The hardest part was really figuring out the fields that logstash was outputting to the documents, which took some trial & error. The API calls themselves were easy (for me). \n\nThe biggest plus for me was that I didn't need to bother with ZK tools while in SolrCloud mode to make some simple edits. How anyone uses those tools is really beyond me - I have a huge hazy gap in my brain whenever I try to use them and I fail miserably. \n\nHowever, the Schema API is still a work-in-progress; I could do the basics of what I needed for my little project, but I couldn't delete fields, create new fieldTypes or change the analysis for any fieldType. If I had started with schemaless and then wanted to lock down my fields later, I don't know that I would have had the tools with the REST API, and I'm not sure how I would edit it manually if we're not supposed to edit the schema by hand when it's in managed mode. And then I'd have to contend with ZK.\n\nIs it easy to bootstrap the managed schema stuff with a hand built schema.xml?\nI didn't do it as part of the project I just described, but I have done it before - made edits to schema.xml and then switched to using Managed Schema. It was as expected - a new file named 'managed-schema' was created that had my changes already in it and then I could use the REST API. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-14088240",
            "date": "2014-08-06T20:59:05+0000",
            "content": "I'm not trying to be obtuse or argumentative,\n\nArgue all you want by the way. That's how this stuff generally gets hashed out - people make arguments, stuff falls out of it, others weigh in on ideas. At some point, more and more consensus generally falls out. The only problem with arguing is if no one ends up being willing to compromise or change their opinion on anything regardless of the arguments or efforts to compromise. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-14088253",
            "date": "2014-08-06T21:05:40+0000",
            "content": "I did it recently and didn't think it was bad at all. \n\nThanks for the input Cassandra!\n\n\nThe biggest plus for me was that I didn't need to bother with ZK tools while in SolrCloud mode to make some simple edits. How anyone uses those tools is really beyond me - I have a huge hazy gap in my brain whenever I try to use them and I fail miserably.\n\nThat's still a huge issue with SolrCloud, but extends to solrconfig.xml as well. We have an extra script that helps deal with that for Cloudera Search, but it's still no fun.\n\nHowever, the Schema API is still a work-in-progress; \n\nOkay, so sounds like that is the largest limiting part of this right now?\n\nGregory Chanan, you did a lot with the managed schema mode recently. What do you think about it becoming the primary Solr 'mode' in it's current state? "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-14088264",
            "date": "2014-08-06T21:11:37+0000",
            "content": "Another point about \"managed schema\"... although it tells you not to, you can hand-edit it just fine, and the syntax is the same.\nYou just don't want to edit it while solr is running since the change won't take affect and your changes would also be overwritten by the next operation to go through the API.  Longer term, I think schema and managed schema should be synonymous, but I lost that argument in the short term  "
        },
        {
            "author": "Hoss Man",
            "id": "comment-14088287",
            "date": "2014-08-06T21:26:20+0000",
            "content": "FWIW: I've been deliberately avoiding reading/commenting on most of the issues like this one for hte past few months, because i've come to realize I've got far too much vested history to have any real idea what choices for things like this best serve the \"new user experience\" with solr.\n\nBut since miller called me out explicitly and asked for an opinion, i'll give one \u2013 but please don't take any of this this as a vote for/against any other specific, concrete, ideas other people have proposed \u2013 because i still haven't read most of the comments in this issue since whenever my last comment was. \n\nThe main gist i get of the current discussion is about \"default\" behavior and schema management \u2013 so here is the pie-in-the-sky opinion of what i personally think would make a lot of sense in the long run...\n\n\n\tYou start solr up the first time, you have 0 collections.\n\tthere are many sample configsets that come with solr, ready to be specified by name when you create your first collection\n\t\n\t\tnone of the configsets are named \"default\" or \"collection1\" - there is no such thing as a \"default\" config set, just like there is no such thing as a \"default\" collection\n\t\teach of the sample config sets has a README file explaining why it's interesting\n\t\teach of the sample config sets has a file/directory of sample data, or a DIH config file that knows how to index some external data\n\t\tthe configsets should all be as small as they can possible be, while still clearly showcasing the thing that they showcase\n\t\n\t\n\n\n\n\n\ta paired down version of the current \"collection1\" configs would be called \"sample_techproductdata_configs\"\n\t\n\t\tanything in the current configs not directly related to the tech product example docs would be ripped out\n\t\teverything would be tweaked to showcase the best possible configs we could imagine for the specific sample data usecase (ie: request handler defualts, spell check configs, velocity UI templates, etc...)\n\t\tthe first thing in the tutorial would be creating a \"tech_products\" collection using this configset, and indexing it's sample data.\n\t\tthe tutorial would then use the \"tech_products\" collection to demo some of the features currently covered in the tutorial (basic search, schema concepts, faceting, highlighting, etc...)\n\t\n\t\n\tanother config called \"sample_bookdata_configs\" would also be much a much smaller subset of the current \"collection1\" configs\n\t\n\t\tit would be paired with books.json & books.csv, have nothing in it unrelated to books, etc...\n\t\twe probably wouldn't need to mention this config set in the tutorial, but having it available as another example of a purpose created set of configs for users to compare/contrast with the \"sample_techproductdata_configs\" would be useful.\n\t\n\t\n\n\n\n\n\tthere would be a configset named \"basic_configs\"\n\t\n\t\tthis would have the managed-schema enabled (so the REST API could be used to manipulate the schema) .. as more REST APIs are added moving forward, they would also be enabled in this config set.\n\t\tthis would not have the \"schemaless\" update processors\n\t\t\n\t\t\t? or maybe the update processors are there, but in a non-default chain ?\n\t\t\n\t\t\n\t\tthey key goal here being the most basic configs someone could start with, and add to, w/o any confusion about what might be cruft they can delete\n\t\tthe second major section of the tutorial would have the user create two collections using this configset, and then use those two collections to showcase the Schema REST APIs to create the same field with different properties, and then show how the two collections behavior differently with the same sample data indexed into them.\n\t\n\t\n\n\n\n\n\tthere would be a configset named \"data_driven_schema_configs\"\n\t\n\t\tthis would have all of the \"schemaless\" bells and whistles enabled\n\t\tthe tutorial would have the user create a collection using this config to show off these features, etc...\n\t\n\t\n\n\n\n\n\tthere would be many other config sets available, to show off various features of solr, int isolated specific example configs where they are easier to digest then the current kitchen sink of pain that we have today.\n\t\n\t\tevery configset would have some JUnit tests to verify that they work, and that they can load their sample data (even if we aren't testing \"curl\", we can test with contentStream and the file path, mock DIH datasources, etc...)\n\t\n\t\n\n\n\n\n\tthe world would be full of sunshine and rainbows and free candy.\n\n "
        },
        {
            "author": "Gregory Chanan",
            "id": "comment-14088402",
            "date": "2014-08-06T22:40:38+0000",
            "content": "Gregory Chanan, you did a lot with the managed schema mode recently. What do you think about it becoming the primary Solr 'mode' in it's current state?\n\nInteresting question.  I don't have a philosophical objection to it, like I would with schemaless.  My main concerns are:\n\n\tI think SOLR-6249 would definitely need to be addressed, it's too non-intuitive to use programatically at this point\n\tCassandra gave a good overview of the other limitations of the API.  Those are less serious than SOLR-6249, because instead of something breaking, you might just get stuck.  I'd have some concern that the usual workflow would be: try managed schema -> get stuck -> write the schema manually.  This is a worse experience IMO than just telling users to write the schema manually.\n\n\n\nSo I think I'd pass on making it the \"default\" for now. "
        },
        {
            "author": "Timothy Potter",
            "id": "comment-14089854",
            "date": "2014-08-07T21:06:45+0000",
            "content": "Thanks Gregory and Hoss for contributing--I feel like a concrete plan is starting to form!\n\nYou start solr up the first time, you have 0 collections.\n\n+1\n\nCan we agree to start with 2 configsets (based on Hoss' plan above) and then work on converting the other examples iteratively?\n\n1) data_driven_schema_configs: field guessing and managed-schema\n\n2) basic_configs: schema.xml (not managed) and no field guessing ... this basically seems like the collection1 config we have today. So it seems like we should just do: svn mv example/solr/collection1/conf and have server/solr/configsets/basic_configs/conf\n\nI also plan to enhance the start script (SOLR-3617) to have a command (new_core or new_collection) that takes configset name as a parameter. The experience would then be:\n\n\nbin/solr start\nbin/solr new_core -name gettingstarted -config data_driven_schema_configs\n\n\n\nor\n\n\nbin/solr start\nbin/solr new_core -name prod_index -config basic_configs\n\n\n\nPlease let me know if there are anymore reservations about this approach as I'm working on an updated patch based on this plan. "
        },
        {
            "author": "Hoss Man",
            "id": "comment-14089886",
            "date": "2014-08-07T21:38:04+0000",
            "content": "Can we agree to start with 2 configsets (based on Hoss' plan above) and then work on converting the other examples iteratively?\n\nIt sounds like you'd need a minimum of 3 to start with:\n\n\tdata_driven_schema_configs (new, based on example-schemaless's solrconfig.xml, but no starting schema.xml )\n\tbasic_configs (new, as bare bones as we can get w/ the rest APIs enabled)\n\tsample_techproducts_configs (exact copy of the current collection1 configs\n\n\n\nreasoning: basic_configs & data_driven_schema_configs should start out (and stay!) tiny and clean, and demonstrate how simple starting configs can be \u2013 the key distinction between them simply being that one let's you just throw data at, and the other you have to use the REST API to explicit create fields.  That way it's more obvious (then it is today) how you can do things programtically even if you don't want auto-generated fields ... it's not an \"all or nothing\" world of schemaless vs manual editing of schema.xml.  But basic_configs is still super small and clean and tiny and easy to see how you can disable the REST API if you don't want it.  But then, in addition to those two, you still have the big beefy sample_techproducts_configs that can be used in the tutorial to shows off the kitchen sink of features.\n\nSo right from the start, you have something to make the \"schemaless\" fan boys happy, and you have something a bit more locked down but still welcoming for the REST zealots, and then you still have the reliable old standby that's easy to understand for people who like editing config files and/or are trying to follow along an article they're reading that was written 4 years ago.\n\nThen, as you say, we can iterate on adding more configsets by gradually teasing out (and pairing down) things from sample_techproducts_configs and bringing back things from example-DIH.\n\nSo it seems like we should just do: svn mv example/solr/collection1/conf and have server/solr/configsets/basic_configs/conf\n\nI can not, in good conscious, allow you to rename the current collection1 configs \"basic\" ... i know where you live Tim, don't make me come after you. "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-14089943",
            "date": "2014-08-07T22:20:32+0000",
            "content": "Can we agree to start with 2 configsets (based on Hoss' plan above) and then work on converting the other examples iteratively\n\nI don't think getting started should require any knowledge of configsets, etc.  You've already lost me as a new dev (I've seen this so many times in the past 2 years).  Getting started is all about my data and my queries.  I should only have to know enough to start indexing.  Than, as I peel back the layer, I can dig in deeper.\n\n\n\tbin/start\n\tcreate new collection (Managed schema, field guessing)\n\tThrow my JSON, CSV, PDFs, etc. at it and it does a reasonable first pass at it such that I can start iterating on how this all works.\n\n "
        },
        {
            "author": "Mark Miller",
            "id": "comment-14090019",
            "date": "2014-08-07T23:23:43+0000",
            "content": "To me, which of the 2 config sets is the 'default' is less important than that choosing either as a starting point is as simple as a param change or addition of a param, eg default is schemaless, alternative is -configset fixedschema or whatever.\n\nAt least until managed and field guessing are fully done (see above outstanding issues). I think it's fairly telling that even our simple example data choked on schemaless and we had to change the data to get it to work.\n\nI believe in loose to start and lock it down as you progress, and I'm okay with bringing managed and field guessing front and center as it has improved, but I think the current default config style needs to be just as readily available until 5x or until managed and schemaless are less \"work in progress\" and fully developed and smooth. It sounds like that is not super far off but that we are not there yet for 4x.\n\nEven then, I don't know that I agree field guessing is a good default. If the majority want it, so be it, but the experience needs should be complete before we axe or attic the more complete and documented 'production recommend' configs we effectively default to now.\n\nA middle ground compromise might be defaulting to managed schema and just making it simple to add a param to turn on field guessing. Or off field guessing if the argument goes that way. It seems that managed schema should be finished before we default to it though, no? Things like not being able to change the analysis or delete without stopping the service seem like fairly important parts to finish. "
        },
        {
            "author": "Jack Krupansky",
            "id": "comment-14090765",
            "date": "2014-08-08T13:45:30+0000",
            "content": "I do hope that people use Elasticsearch as a high priority criteria for whether standing up a tutorial or production instance of Solr is easy enough. I mean, I still hear plenty of chatter that \"Solr is too hard.\" Granted, a lot of that is just perception, but the final result of this issue should be that Solr has two SHORT web pages for those two use cases that clearly show that Solr is \"just as easy to stand up as Elasticsearch.\"\n\nElasticsearch says \"Installation is a snap.\" Solr needs to be able to do the same.\n "
        },
        {
            "author": "Timothy Potter",
            "id": "comment-14090810",
            "date": "2014-08-08T14:39:26+0000",
            "content": "allow you to rename the current collection1 configs \"basic\" \n\nlol your description of what basic is clears things up for me \n\nIt seems that managed schema should be finished before we default to it though, no?\n\nCorrect! Rowe and I are digging into this over the next couple of weeks. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-14090894",
            "date": "2014-08-08T15:50:20+0000",
            "content": "Correct! Rowe and I are digging into this over the next couple of weeks.\n\nOkay, well if managed schema is made ready for prime time, I agree that we should move to it as part of this issue. "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-14091912",
            "date": "2014-08-09T21:38:49+0000",
            "content": "I skimmed the existing discussion, didn't read it closely.  I expect I will be restating many things that have already been said:\n\nI can see the value of a \"schemaless\" mode for a brand-new user or when initially developing a schema, but when it comes to production, the chances of an incorrect guess are just too high, and fixing things after an incorrect guess is likely to require a reindex.  On the IRC channel, users are not shy about letting you know just how much they hate reindexing ... especially if they were not previously aware of what reindexing actually means.  That doesn't really go away when the schema is explicit, but it would not be as likely.\n\nThe managed schema mode has a lot of promise, but there are holes in its functionality.  Once those holes are patched so that editing the actual schema.xml file is never required, it will be awesome.  I can envision a section of the admin UI where fieldTypes, fields, and other schema settings can be constructed or edited easily.  If a change requires a reindex, the UI can notify the user.\n\nI assume that Cassandra's complaints about the ZK tools refers mostly to zkcli.  If so, I agree ... it is  difficult to use, clunky, and intimidating ... but using it produces the best results.  Relying on bootstrap system properties causes a lot of problems for new users when they try to move to production.  I'd like to see an extensive admin UI interface for uploading, changing, cloning, and deleting config sets.\n\nBecause of the security concerns that Redhat raised with the \"edit the config files\" UI we used to have, zookeeper config modifying functionality must be disabled by default, with some way of enabling it that requires administrative access to the operating system.  That might be the presence of a specifically-named file in the solr home, which you can create or delete to enable/disable the functionality without restarting Solr.  My initial thought was an option in solr.xml, but because solr.xml itself can be located in zookeeper, that would create a chicken/egg problem.\n\nI just had an interesting idea.  In order for config editing to turn on, we could require a two-part procedure.  First you go to a specific section of the admin UI where you enter an edit mode expiration time.  When that is submitted, it gives you a filename, most likely containing a hash, like edit-5fb65b8bfe33f603b7a427284cc6e48a.  Until the expire time for that hash is reached, the presence of that file in the solr home will allow config editing.  We could put a limit on the expiry time of 1-4 hours.\n\nIn general, I like what Hoss has proposed.  If any specific objections arise as we get closer to implementation and release, I expect I'll be able to raise them then. "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-14092073",
            "date": "2014-08-10T12:06:19+0000",
            "content": "I can see the value of a \"schemaless\" mode for a brand-new user or when initially developing a schema, but when it comes to production, the chances of an incorrect guess are just too high,\n\nThere are actually some use cases for it in production, as Yonik mentioned, but in reality, I don't think anyone here is proposing that the majority of users go into production in data-driven schema mode.\n\nand fixing things after an incorrect guess is likely to require a reindex. On the IRC channel, users are not shy about letting you know just how much they hate reindexing ... especially if they were not previously aware of what reindexing actually means. That doesn't really go away when the schema is explicit, but it would not be as likely.\n\nWe aren't talking about re-indexing production.  We are talking about rapid iteration of data modeling.  Those who truly need data-driven (and there are those people out there) will already know the caveats and those who don't should be guided away from it as they progress by documentation.  I like to break this whole process down into what I consistently see as the selection process most devs go through when selecting technology (search or otherwise):  \n\n\tBoss or you or someone else says: hey we need to solve this problem.  I think X and possibly Y will work.\n\tBoss: You've got one (maybe two) week(s) to make a recommendation\n\tYou then spend that time doing the following for X and Y:\n\t\n\t\t5 minute to 1 hour test/tutorial (anything that doesn't pass that gets tossed)\n\t\t1 day test (can I get my data in and ask the questions I need of it?)\n\t\tSpend the rest of the time scaling it up and exploring and peeling back the layers of the onion (how do I scale? how would I do this in production?  what bumps are in my way?)\n\t\n\t\n\tMake a recommendation\n\tGo for it \u2013 This step is when they start to lock things down.\n\n\n\nThe thing is, Solr is incredibly awesome at the end stages of this game (i.e. getting to production).  It is way more solid and way more tested, as can be seen time and time again, but if we don't solve the ease of use stuff, than it doesn't matter, b/c it isn't being selected to be used in the first place.  If you think about it, easy to get started, easy to get finished is a killer combination.  Solr is easy to get finished already, but it still has a fairly steep learning curve for people who aren't search experts (which is what has changed the most recently: more people are looking at Solr as a NoSQL store and less at it as a search engine). \n\nI'd like to see an extensive admin UI interface for uploading, changing, cloning, and deleting config sets.\n\nPerhaps for experts, but again, I doubt most users should need to do these things.  Not saying I'm against it, but I think we should minimize any mention of this stuff until later.\n\nzookeeper config modifying functionality must be disabled by default, with some way of enabling it that requires administrative access to the operating system.\n\nI believe there are other APIs that are being worked on that will make editing the config something one does programmatically, which means it can also be secured.  IMO, the current XML config files, etc., should be an implementation detail, not an API, as they are now.\n\nI just had an interesting idea. In order for config editing to turn on, we could require a two-part procedure. First you go to a specific section of the admin UI where you enter an edit mode expiration time. When that is submitted, it gives you a filename, most likely containing a hash, like edit-5fb65b8bfe33f603b7a427284cc6e48a. Until the expire time for that hash is reached, the presence of that file in the solr home will allow config editing. We could put a limit on the expiry time of 1-4 hours.\n\nAgain, perhaps this is an expert thing and labeled accordingly, but I don't think new users should have to do this.  If we can't make this stuff simpler, then we shouldn't do it at all.  "
        },
        {
            "author": "Alexandre Rafalovitch",
            "id": "comment-14092077",
            "date": "2014-08-10T12:30:20+0000",
            "content": "+1 on schemaless mode being pitched specifically as development/fast-prototyping time. The last couple of prototypes I did, I started from universal dynamic field enabled and then added fields one-by-one as I knew what to do with them. Schemaless would give me the same except it would also be a bit smarter about int fields, etc.\n\nAlso, while ElasticSearch website talks mostly about schemaless mode, all the \"going to production\" third-party guides I have seen stress quite strongly that locked-down schema should be used for real production.\n\nThis could also be reinforced by adding a tutorial that starts from schemaless and then - explicitly - talks about moving to explicit schema. And, of course, the comments in the config file, as appropriate. "
        },
        {
            "author": "Timothy Potter",
            "id": "comment-14162562",
            "date": "2014-10-07T21:24:52+0000",
            "content": "Have resumed working on this and am close to being ready to commit to trunk. I do think this should be included in branch_5x as well. "
        },
        {
            "author": "Timothy Potter",
            "id": "comment-14169895",
            "date": "2014-10-13T20:29:59+0000",
            "content": "Interesting discussion related to this ticket on the #solr IRC channel today. In a nutshell, we're thinking the bin/solr scripts would default to starting the Solr server in cloud-mode and the next step after a new user starts the server they can do: bin/solr create_collection -name foo -shards 4 -replicas 2 -configset schemaless (as an example) ... this would be for 5.x. If a user doesn't want cloud mode, then the user can start a standalone server but will be on their own for creating cores using the core admin api or the Web UI.\n\nWe also discussed starting ZooKeeper in a separate process instead of embedded but that can be tackled by another ticket.\n\nHere's a record of that discussion:\n\n[11:28am] timpotter: Hi - so as part of SOLR-3619, I\u2019d like to add a command to the bin/solr scripts to create a new core or collection (depending on which mode Solr is running in cloud or standalone). I think it over complicates things to have two commands (create_core AND create_collection) so my first thought was to have some overloaded command like create_index but that introduces yet another term in our nomenclature that will only confuse new users even more \u2026 chatting with Hoss and Steve about this they suggested just using create_collection and if Solr is running in standalone mode, the Collections API just does the right thing and creates the core (vs. erroring out). Anyone have any thoughts about this?\n[11:28am] timpotter: the idea here is that you\u2019d fire up solr using bin/solr start and then either A) go to the Web UI or  can just create a new collection right there on the command-line\n[11:28am] timpotter: (emoticon unintentional, should be B.\n[11:30am] erikhatcher: timpotter: maybe it could default (or vice versa) to falling back to creating a core in standalone mode, and have a command-line switch that just errors after the collection creation fails (-force-solrcloud-mode ?)\n[11:32am] timpotter: erikhatcher: It could do that \u2026 I think Hoss\u2019 point is that the Collections API should just work in standalone mode but maybe that\u2019s opening a big can of worms \u2026\n[11:32am] anshum: I\u2019d say it\u2019d be better to error out and only support collection creation in cloud mode\u2026 creating a core under the hood when running in standalone mode would confuse users as none of the other \u2018Collection\u2019 API calls would work though the collection creation would succeed\n[11:38am] timpotter: anshum - that\u2019s good point \u2026 so how to tell users to create a core in standalone mode \u2026 most important in my mind is easy to get started\n[11:39am] anshum: we should default to solrcloud mode.. i.e. a zk comes up behind the scenes\u2026, have defaults\u2026  and bring things up\n[11:39am] anshum: leave the core creation to advanced users only\n[11:39am] anshum: we really wouldn\u2019t want someone who\u2019s getting started to know about \u2018cores\u2019 .. but that\u2019s my thought..\n[11:40am] timpotter: correct - which is why I liked create_collection but there\u2019s no requirement to start Solr in cloud mode\n[11:40am] timpotter: so if I start in standalone mode, what do I do next?\n[11:43am] anshum: timpotter: that\u2019s the thing. cloud = zk enabled. If the start scripts starts solr with embedded zk by default, there\u2019s no standalone mode. If by standalone mode you mean 1 node, that could still be a solrcloud setup with 1 node, embedded zk..\n[11:45am] sarowe: anshum: i don't think we should ever use embedded zk, it's a bad practice\n[11:45am] hoss: anshum: i would go even farther: no embedded zk, the start script with --example launches a distinct zk process .... but i think ultimatley tim is worried baout incrimental progress\n[11:45am] timpotter: anshum - yes the script can do that (ie. make cloud mode the default)\n[11:46am] anshum: sarowe/hoss: sure\u2026 that\u2019s even better.. I don\u2019t think the user needs to familiarize with standalone vs cloud .. and I\u2019m always +1 on non-embedded zk..\n[11:46am] timpotter: is that what we want to do in 5.x? ie. download -> start solr (in cloud mode) -> create_collection? If so, that\u2019s doable\n[11:47am] anshum: timpotter: I would like that.\n[11:48am] sarowe: timpotter: but that leaves your original question unanswered: what to do in (non-default) standalone mode?  should create_collection create a core?\n[11:48am] timpotter: sarowe - sounds like just error out and the user is left to their own devices (curl to core API or Web UI)\n[11:49am] anshum: sarowe: there is no standalone mode (non-cloud)\u2026 is what I\u2019m saying\u2026 start script starts solrcloud in 5x ?\n[11:49am] timpotter: which seems fine if non-cloud mode is not the default anymore\n[11:49am] timpotter: anshum - correct - but people still do master/slave all the time so there has to be a way to not do cloud\n[11:50am] sarowe: timpotter: I haven't looked for it, but does bin/solr support master/slave now?\n[11:50am] anshum: in that case, have a create core command, explicit, advanced usage\u2026\n[11:51am] anshum: even I\u2019m not sure about bin/solr doing the master/slave now.. timpotter ?\n[11:51am] timpotter: no, script doesn\u2019t do anything specific for master slave as that\u2019s all solrconfig.xml settings\n[11:52am] timpotter: but the scripts do allow you to start Solr without specfiying a ZooKeeper connection string \u2026 to summarize, sounds like the bin/solr scripts are pretty much for the default behavior and if you want to stray from that, you\u2019re on your own\n[11:53am] anshum: timpotter: I may be missing something here\u2026 but is the script supposed to help people getting started or help people with ops..?\n[11:53am] timpotter: both\n[11:54am] anshum: timpotter/sarowe/hoss: so for ops, we might add \u2018create core\u2019, default is create collection, which only runs in cloud mode\u2026 trying to create a collection in non-cloud mode would lead to an error\n[11:55am] anshum: specially as the user would have explicitly studied and specified that he \u2018wants\u2019 to run in non-cloud mode\u2026 he would also know about core admin commands and the difference between create collection and create core\n[11:55am] anshum: i.e. for the purpose of ops\n[11:56am] timpotter: I should clarify - bin/solr does basic ops (start, stop, restart, healthcheck, info) as well as launching specific examples \u2026 I don\u2019t intend for it to become a tool to do all ops \u2026 was just thinking the create_collection command would be a nice simple addition for getting started (since we\u2019re not booting up Solr with a collection1 already created)\n[11:59am] anshum: timpotter: right, so someone who\u2019s getting started (who wants to use create_collection) would have used the defaults. For anyone else, we should/could just error out\n[11:59am] timpotter: that makes sense\n "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-14169986",
            "date": "2014-10-13T21:10:31+0000",
            "content": "chatting with Hoss and Steve about this they suggested just using create_collection and if Solr is running in standalone mode, the Collections API just does the right thing and creates the core (vs. erroring out). Anyone have any thoughts about this?\n\nThat seems reasonable.\n\ncreating a core under the hood when running in standalone mode would confuse users as none of the other \u2018Collection\u2019 API calls would work though the collection creation would succeed\n\nThat's why all of the applicable APIs should be made to work.\nThe other path is to either scale down better by using embedded ZK, or by emulating ZK using the filesystem.\n\nI have reservations about launching external ZK processes by default... it feels like it could really complicate the new user experience.  (so many gotchas in there... another moving part, what happens if ZK comes up but solr doesn't, killing Solr is no longer so simple, getting rid of unwanted state is no longer simple, etc).\n "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-14170066",
            "date": "2014-10-13T21:54:45+0000",
            "content": "I am resistant (but not completely opposed) to always running in cloud mode, even for a simple single-server install.  This is my position regardless of whether ZK is embedded or external.  I realize that it is probably where Solr is headed and that I shouldn't fight it, but I already see a lot of confusion from users who want to edit their config on disk and restart, just like they do for any other program they might download and use.\n\nFor that simple single-server install, an embedded ZK makes a lot of sense, but we do need to have documentation that guides a user towards a fully external 3 node ensemble once they get beyond a proof of concept.  I also think we should recommend a ZK chroot, but that may be a discussion much further down the road.\n\nIt's a good idea to have a single \"create collection\" command, whether the actual thing that will be created is a collection or a core.  A prominent FAQ item (or perhaps an entire dedicated wiki page) needs to discuss the finer points of our terminology \u2013 collection, shard, replica, core ... but I think the user needs to be initially directed to always think about a \"collection\" ... understanding the makeup below that is important, but shouldn't muddy the user's first contact with Solr.\n\nHas anyone given any thought to deprecating the CoreAdmin API and extending the Collections API to handle everything it currently does, by using a parameter to tell it that the operation is at the core level? "
        },
        {
            "author": "Timothy Potter",
            "id": "comment-14182323",
            "date": "2014-10-24T02:21:10+0000",
            "content": "Here's an updated patch that I think is very close to being committable. Here are the key changes in this patch:\n\n1) Directory structure:\n\n\n<tip>\n|__bin\n     |__solr (for *nix)\n     |__solr.cmd (for Windows)\n|__contrib\n|__dist\n|__docs\n|__example\n     |__example-DIH\n     |__exampledocs\n|__licenses\n|__server\n     |__contexts\n     |__etc\n     |__lib\n     |__logs\n     |__resources\n     |__scripts\n     |__solr\n          |__configsets\n               |__basic_configs\n               |__data_driven_schema_configs\n               |__sample_techproducts_configs\n     |__solr-webapp\n     |__start.jar\n     |__webapps\n\n\n\nThe important part here is that I've moved some of the configurations from under the example directory to be configsets under server/solr/configsets. Specifically, example/example-schemaless/solr/collection1/conf becomes server/solr/configsets/data_driven_schema_configs/conf and example/solr/collection1/conf becomes server/solr/configsets/sample_techproducts_configs/conf (I used Hoss' suggested names)\n\n2) When you start Solr using (bin/solr start), the server starts up with server/solr as the solr.solr.home and no collections / cores are created. A nice next step might be to bin/solr create_core if in standalone server mode or bin/solr create_collection if in SolrCloud mode. I know we talked about making cloud-mode the default start mode, which we can handle in another ticket. For now, to get started, you can do:\n\n\nbin/solr start\nbin/solr create_core -n test\n\n\n\nor\n\n\nbin/solr start -cloud\nbin/solr create_collection -n test\n\n\n\n3) To run the examples, you can still use the bin/solr script, such as:\n\nbin/solr -e schemaless will boot up Solr in standalone mode and then create a new core named schemaless using the data_driven_schema_configs configset.\n\nbin/solr -e techproducts will boot up Solr and then create a new core named techproducts using the sample_techproducts_configs configset and then calls post.jar to index example/exampledocs/*.xml\n\n4) I took a stab and what the basic_configs should include but am not beholden to what I have there now. I definitely would like some other eyes on this. I know Alexandre Rafalovitch has done a lot of nice work in this area, so please take a close look at server/solr/configsets/basic_configs.\n\n5) I left the dih example alone because it is more involved than just a configset. Also, it seemed like we didn't need multicore anymore, so I deleted that.\n\nOverall, I think this is a more intuitive layout and much of the ease-of-use comes from the bin/solr script doing most of the work for the user. Please give this a good look and help me get it committed soon. "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14191330",
            "date": "2014-10-31T04:30:53+0000",
            "content": "Commit 1635666 from Timothy Potter in branch 'dev/trunk'\n[ https://svn.apache.org/r1635666 ]\n\nSOLR-3619: Rename 'example' dir to 'server' "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14192191",
            "date": "2014-10-31T18:18:19+0000",
            "content": "Commit 1635833 from Timothy Potter in branch 'dev/trunk'\n[ https://svn.apache.org/r1635833 ]\n\nSOLR-3619: Fix IDEA project settings after move to server. "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14192866",
            "date": "2014-11-01T01:22:03+0000",
            "content": "Commit 1635887 from Timothy Potter in branch 'dev/trunk'\n[ https://svn.apache.org/r1635887 ]\n\nSOLR-3619: get the smoke tester working with the bin/solr script and server directory "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14193235",
            "date": "2014-11-01T15:21:34+0000",
            "content": "Commit 1635969 from Timothy Potter in branch 'dev/branches/branch_5x'\n[ https://svn.apache.org/r1635969 ]\n\nSOLR-3619: backport to 5x "
        },
        {
            "author": "Anshum Gupta",
            "id": "comment-14195562",
            "date": "2014-11-04T01:59:26+0000",
            "content": "I'm thinking if it would make more sense to just get rid of 'example' directory. i.e. move it's contents to another directory with a more fitting name?\nIf not that, at least rename 'ant example'  to 'ant server' ? "
        },
        {
            "author": "Steve Rowe",
            "id": "comment-14200420",
            "date": "2014-11-06T16:39:31+0000",
            "content": "See SOLR-6708 - problems using bin/solr in the smoke tester run under Jenkins "
        },
        {
            "author": "Alexandre Rafalovitch",
            "id": "comment-14218940",
            "date": "2014-11-20T03:17:53+0000",
            "content": "I am testing the new example layout and it just hit me that I never quite thought through the configsets for this scenario.\n\nSpecifically, if we create a schemaless example now and post a document to it, the baseline configuration (in configset) is forever changed even if we then remove the created collection directory. So, we no longer have a gold master.\n\nFor some reason, I thought we will create a new collection from that config set, but that every collection will be a clone of the configuration in the configset and the original will never be changed. Instead, it is a configuration by reference, which is shared between all collections using it.\n\nSo, it feels that now the cost of experimentation is actually higher then when people copied an example directory. Did I miss a part of discussion where this tradeoff was decided to be a good thing? "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-14218946",
            "date": "2014-11-20T03:24:31+0000",
            "content": "Instead, it is a configuration by reference, which is shared between all collections using it.\n\nThis is exactly how configurations in zookeeper function.  As I understand it, configsets are basically a duplication of what Zookeeper brings to SolrCloud.\n\nUsing configsets in conjunction with schemaless mode (or even a config where the schema API is active) seems like it might not be a good idea.  I'm not sure what to do about it, though. "
        },
        {
            "author": "Alexandre Rafalovitch",
            "id": "comment-14218971",
            "date": "2014-11-20T04:02:04+0000",
            "content": "Example creation fails in foreground mode. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-14219419",
            "date": "2014-11-20T14:28:00+0000",
            "content": "This is exactly how configurations in zookeeper function. \n\nNot exactly - no collections start in ZooKeeper and so you do essentially start with a gold master.\n\nI think Alexandre is right. They should act as gold masters and get copied into place - much like you would upload a clean config set to zookeeper.\n "
        },
        {
            "author": "Alexandre Rafalovitch",
            "id": "comment-14219428",
            "date": "2014-11-20T14:37:47+0000",
            "content": "Using configsets in conjunction with schemaless mode (or even a config where the schema API is active) seems like it might not be a good idea.\n\nThis actually raises another question. If I have, for example, REST-controlled stop-list and have multiple collections share the configset in non-cloud mode, would other collections even know that the set was updated?\n\nI'm not sure what to do about it, though.\n\nCould we fix that by adding a clone parameter to CREATE call, if the current behavior has to stay? "
        },
        {
            "author": "Timothy Potter",
            "id": "comment-14219492",
            "date": "2014-11-20T15:35:34+0000",
            "content": "Re-opening to address Alexandre and Mark's feedback around configsets. "
        },
        {
            "author": "Alexandre Rafalovitch",
            "id": "comment-14220272",
            "date": "2014-11-21T00:07:58+0000",
            "content": "Since we reopened: The other thing I am finding super-confusing is how the name in the -e parameter does not match the config set, nor does it match the names in the leftover example directory. Especially with the current non-gold-master issue.\n\nWould it make sense to have things somehow consistent? \n\nAlso, in the examples directory, example-DIH can be used with -e dih flag. But the multicore is not, right? Is there a reason for inconsistency? \n\nI feel that a beginner user would treat every inconsistency as meaningful and/or confusing.\n "
        },
        {
            "author": "Alexandre Rafalovitch",
            "id": "comment-14220335",
            "date": "2014-11-21T00:59:39+0000",
            "content": "Sorry, for spamming this JIRA, but I think I just hit an even bigger immutable master issue. We have different examples stepping on each others' feet.\n\nSpecifically, the examples techproducts and schemaless both create the actual Solr collections inside the server/solr directory. So, if you run both, it will create two more collections there.\n\nThen, if you run cloud example, it will clone this augmented server directory and use that as a base of node1 and node2 (created, strangely enough, in the current directory).\n\nSo, when you actually try to access the Admin UI, it auto-discovers and tries to load those extra collections as well and fails as configName is - I am guessing - is relative to unexpected location and does not get resolved. \n\n\n    techproducts: org.apache.solr.common.cloud.ZooKeeperException:org.apache.solr.common.cloud.ZooKeeperException: Could not find configName for collection techproducts found:null\n    schemaless: org.apache.solr.common.cloud.ZooKeeperException:org.apache.solr.common.cloud.ZooKeeperException: Could not find configName for collection schemaless found:null \n\nWould it make sense to:\n\n\tMake configsets not changeable by cloning the configuration\n\tMake all generated examples showing up in solr/example directory as that's where the other examples are anyway\n\tMake switch question order in the cloud example to ask for collection name first and use that as a root directory name under the solr/example with nodes inside of that\n\n\n\nI am also not sure that cloud example is restartable once it is shutdown. But that's probably a different issue. "
        },
        {
            "author": "Timothy Potter",
            "id": "comment-14220482",
            "date": "2014-11-21T03:44:55+0000",
            "content": "Thanks for digging in Alexandre Rafalovitch ... your feedback is much appreciated.\n\nAgreed on the create_core cloning the configset, e.g. if I do: bin/solr create_core -n foo -c basic_configs, then the create_core action will:\n\nmkdir server/solr/foo\ncp -r server/solr/configsets/basic_configs/conf server/solr/foo/conf\n\n\n\nAs for the names of the configsets and the examples, I used the names Hoss suggested in his comment above for the configsets but heard rumblings at Rev that others didn't like the long names  It's easy to change the names at this point, so what do we want them to be called? I'm cool with whatever people think are short but descriptive enough.\n\nmulticore - ugh! I intended on just getting rid of it, but there are unit tests that rely on that directory. It should be removed under a separate ticket (SOLR-6773); I don't think it should be an example anymore but if we don't get rid of it, then I can add it back as an example in the bin/solr script as the consistency will be confusing and that's exactly what we don't want.\n\nAs for the bin/solr -e cloud example being affected by artifacts from running other examples, I think we can just have the script clean-up unrecognized directories after cloning, i.e.\n\n\ncp -r server node1\nrm -r node1/solr/<unrecognized_dir>\ncp -r node1 node2\n\n\n\nThis is just an example, so putting the node1 directory into the expected state after cloning seems reasonable, albeit a bit of a maintenance issue if the list of expected dirs changes, but that happens very infrequently.\n\nLastly, you can restart the cloud example, but you have to just use the bin/solr options directly. For instance, if you launched bin/solr -e cloud -noprompt (2 nodes on the default ports), you could stop and restart using:\n\n\nbin/solr stop -all\nbin/solr restart -c -p 8983 -d node1\nbin/solr restart -c -p 7574 -d node2 -z localhost:9983\n\n\n\nThe example prints out these commands as it runs to help the user make the link between what the example is doing and the command-line options supported by the script. "
        },
        {
            "author": "Alexandre Rafalovitch",
            "id": "comment-14221801",
            "date": "2014-11-22T04:19:22+0000",
            "content": "Is there a specific reason the collections are created in the server directory? I read the discussion before, but don't remember anything jumping out. The delete extra stuff strategy feels quite fragile to me.  "
        },
        {
            "author": "Alexandre Rafalovitch",
            "id": "comment-14222189",
            "date": "2014-11-22T21:35:17+0000",
            "content": "Couple of small issues around start/stop:\n-e <example>  Name of the example to run; available examples:\nThis does not actually run the example as such. This would imply the command can be redone and reruns the same example. It is more \"Install an example\", \"bootstrap an example\" or some such.\n\n\nbin/solr stop -p\nERROR: Expected port number but found  instead!\nI assume it is saying \" \"(space) in there but it is certainly not clear. Could be nice at this point to list the known port numbers instead. After all, we know they are in the file in the bin directory, otherwise we could not stop the solr. "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14226980",
            "date": "2014-11-26T23:12:14+0000",
            "content": "Commit 1641961 from Timothy Potter in branch 'dev/trunk'\n[ https://svn.apache.org/r1641961 ]\n\nSOLR-3619: clone configsets when starting examples or creating cores instead of using configsets directly; selectively clone the server directory when creating node1 for the cloud example; fix script error reporting "
        },
        {
            "author": "Timothy Potter",
            "id": "comment-14226995",
            "date": "2014-11-26T23:34:06+0000",
            "content": "I've addressed most of Alexandre Rafalovitch's concerns in the latest commit. However, I didn't create the example cores in a solr home under example (as suggested) because what happens if the user does the following?\n\n\nbin/solr -e schemaless\nbin/solr create_core -n my_core\n\n\n\nNow my_core lives under example/solr/my_core vs. server/solr/my_core, which is exactly where we were before this ticket - setting up the user to create non-example stuff under examples! In other words, we can't assume the user isn't going to create their own cores after starting up an example so it doesn't make sense to me to create things under a different solr home (other than the default server/solr). Moreover, once we start using a different solr home, then the user would have to know to restart the server with the -s parameter, i.e. bin/solr restart -s example/solr.\n\nNext, if you re-run an example, such as:\n\n\nbin/solr -e techproducts\nbin/solr stop -all\nbin/solr -e techproducts\n\n\n\nThen the script does the correct thing (fires up Solr, tries to re-create the existing core (which fails), and then re-indexes the docs but that's harmless IMO).\n\nAlso, I went with the selective cloning of the server directory when running the cloud example. Agreed it's a bit of a maintenance headache, but Solr needs a default solr.solr.home set in order to initialize, so at some point, there may be cores in the server/solr directory. In other words, if the user does:\n\n\nbin/solr start -p 8983\nbin/solr create_core -n foo\nbin/solr stop -p 8983\nbin/solr -e cloud\n\n\n\nThen the foo instanceDir is in server/solr and we don't want to pull that over when creating node1. At least now with the latest changes, it's safe to run the -e cloud example after doing other things that affect the server/solr directory.\n\nIn short, I think we should only take this immutable master concept so far, but at some point, there's either going to be a dirty solr home directory some where OR the user is going to have to be burdened with passing the correct -s param, which is bad for getting started. "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14226998",
            "date": "2014-11-26T23:37:37+0000",
            "content": "Commit 1641965 from Timothy Potter in branch 'dev/branches/branch_5x'\n[ https://svn.apache.org/r1641965 ]\n\nSOLR-3619: clone configsets when starting examples or creating cores instead of using configsets directly; selectively clone the server directory when creating node1 for the cloud example; fix script error reporting "
        },
        {
            "author": "Alexandre Rafalovitch",
            "id": "comment-14227012",
            "date": "2014-11-26T23:51:28+0000",
            "content": "Why can't we have \n\n/server\n/logs\n/homes (whatever name, if not examples)\n/homes/default\n/homes/cloud\n/exampledocs\n\nThen, the /server is immutable, can be copied around and so on. And the users do not have to grep the file system to look for where the files changed.\n\nThe problem is not when the user creates something (though you bet they will freak out over the error message). The problem is when they come back the next day and something goes wrong. And they have to figure out what happened behind the scenes. Or when they want to delete the examples they created all over the place and want to start a fresh setup of their own. \n\nAt the moment, if they create schemaless and techproducts, they go together in a very deep directory under server. If they create cloud example, we get two directory copies (with logs, not just those examples I complained about) in a random (current directory) location. \n\nAnother way to look at it is what do I need to delete to get back to the original setup. At the moment, it's something in /bin (pid files), something - not everything - in some deep directories (/server/solr/X,Y,Z), something else in another deep directory (/server/logs) and something in whatever location I was in when I run cloud example. Even I just delete the whole setup and just untar the build archive. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-14227207",
            "date": "2014-11-27T03:17:05+0000",
            "content": "The last commit broke the build. MinimalSchemaTest fails. "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14227211",
            "date": "2014-11-27T03:23:07+0000",
            "content": "Commit 1642017 from Timothy Potter in branch 'dev/trunk'\n[ https://svn.apache.org/r1642017 ]\n\nSOLR-3619: Fix NPE during unit tests "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14227230",
            "date": "2014-11-27T03:52:44+0000",
            "content": "Commit 1642020 from Timothy Potter in branch 'dev/branches/branch_5x'\n[ https://svn.apache.org/r1642020 ]\n\nSOLR-3619: Fix NPE during unit tests "
        },
        {
            "author": "Timothy Potter",
            "id": "comment-14233066",
            "date": "2014-12-03T14:46:51+0000",
            "content": "I think moving solr.solr.home to another location is out of scope for this ticket. I re-opened it to address cloning configset directories when creating cores, which is resolved now. Any future changes to Solr's out-of-box directory structure can be addressed in another improvement ticket.  "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-14269733",
            "date": "2015-01-08T17:44:40+0000",
            "content": "First off, love the new stuff!\n\nComing a little late to the party, but just now finally checking this out.  So, I built the distro, copied it to a new directory and unpacked it.\n\nI then went to the README which is the first thing I do for any \"new\" software (as I suspect most devs do) and here's what I see:\n\n\nThis will launch a Solr server in the background of your shell, bound\nto port 8983. After starting Solr, you can create a new core for indexing\nyour data by doing:\n\n  bin/solr create_core -n <name>\n\nand then a few lines later:\n\n\nAfter starting Solr in cloud mode, you can create a new collection for indexing\nyour data by doing:\n\n  bin/solr create_collection -n <name>\n\nYou've already lost me (well, not me, literally, but noobs, I'm sure).  What the heck is the diff between a collection and a core and why should I care so early on?  Why should I have to know that distinction at this stage of the game?  I get that it relates to the Collections API and cloud mode, but I'm a new user and that distinction, in my estimation, is at least a day or two away (and hopefully is resolved at some point and becomes a non-issue) at which time it can be explained via the Docs in the ref guide.\n\nJust my 2 cents.   "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-14269740",
            "date": "2015-01-08T17:50:01+0000",
            "content": "My pref would be:\n\nbin/solr create <name> and we handle the cloud logic under the scenes. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-14269745",
            "date": "2015-01-08T17:51:36+0000",
            "content": "OK, just saw Grant's comment and that sparked....\n\nIMO we shouldn't talk about cores at all, or at least mark them all as \"expert\" and put them in a relatively obscure place. I've seen a lot of confusion on the lists and on site about the relationship between cores/collections/shards/replicas/whatever..... "
        },
        {
            "author": "David Smiley",
            "id": "comment-14269763",
            "date": "2015-01-08T17:58:02+0000",
            "content": "IMO we shouldn't talk about cores at all, or at least mark them all as \"expert\" and put them in a relatively obscure place. I've seen a lot of confusion on the lists and on site about the relationship between cores/collections/shards/replicas/whatever.....\n\nThat point resonates well with me too.  It may be difficult to not talk about \"cores\" but we should try and avoid it I guess.  It may be easier to not talk about it in SolrCloud mode... but then not everyone is using SolrCloud. "
        },
        {
            "author": "Hoss Man",
            "id": "comment-14269780",
            "date": "2015-01-08T18:08:27+0000",
            "content": "tim already spun this idea off into it's own issue \u2013 please discuss there so as not to comvolute and make this one any longer then it already is. "
        },
        {
            "author": "Anshum Gupta",
            "id": "comment-14332756",
            "date": "2015-02-23T05:01:44+0000",
            "content": "Bulk close after 5.0 release. "
        }
    ]
}