{
    "id": "LUCENE-5218",
    "title": "background merge hit exception && Caused by: java.lang.ArrayIndexOutOfBoundsException",
    "details": {
        "components": [
            "core/index"
        ],
        "fix_versions": [
            "4.5",
            "6.0"
        ],
        "affect_versions": "4.4",
        "priority": "Major",
        "labels": "",
        "type": "Bug",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "forceMerge(80)\n==============================\nCaused by: java.io.IOException: background merge hit exception: _3h(4.4):c79921/2994 _3vs(4.4):c38658 _eq(4.4):c38586 _h1(4.4):c37370 _16k(4.4):c36591 _j4(4.4):c34316 _dx(4.4):c30550 _3m6(4.4):c30058 _dl(4.4):c28440 _d8(4.4):c19599 _dy(4.4):c1500/75 _h2(4.4):c1500 into _3vt [maxNumSegments=80]\n\tat org.apache.lucene.index.IndexWriter.forceMerge(IndexWriter.java:1714)\n\tat org.apache.lucene.index.IndexWriter.forceMerge(IndexWriter.java:1650)\n\tat com.xxx.yyy.engine.lucene.LuceneEngine.flushAndReopen(LuceneEngine.java:1295)\n\t... 4 more\nCaused by: java.lang.ArrayIndexOutOfBoundsException: 2\n\tat org.apache.lucene.util.PagedBytes$Reader.fillSlice(PagedBytes.java:92)\n\tat org.apache.lucene.codecs.lucene42.Lucene42DocValuesProducer$6.get(Lucene42DocValuesProducer.java:267)\n\tat org.apache.lucene.codecs.DocValuesConsumer$2$1.setNext(DocValuesConsumer.java:239)\n\tat org.apache.lucene.codecs.DocValuesConsumer$2$1.hasNext(DocValuesConsumer.java:201)\n\tat org.apache.lucene.codecs.lucene42.Lucene42DocValuesConsumer.addBinaryField(Lucene42DocValuesConsumer.java:218)\n\tat org.apache.lucene.codecs.perfield.PerFieldDocValuesFormat$FieldsWriter.addBinaryField(PerFieldDocValuesFormat.java:110)\n\tat org.apache.lucene.codecs.DocValuesConsumer.mergeBinaryField(DocValuesConsumer.java:186)\n\tat org.apache.lucene.index.SegmentMerger.mergeDocValues(SegmentMerger.java:171)\n\tat org.apache.lucene.index.SegmentMerger.merge(SegmentMerger.java:108)\n\tat org.apache.lucene.index.IndexWriter.mergeMiddle(IndexWriter.java:3772)\n\tat org.apache.lucene.index.IndexWriter.merge(IndexWriter.java:3376)\n\tat org.apache.lucene.index.ConcurrentMergeScheduler.doMerge(ConcurrentMergeScheduler.java:405)\n\tat org.apache.lucene.index.ConcurrentMergeScheduler$MergeThread.run(ConcurrentMergeScheduler.java:482)\n\n===============",
    "attachments": {
        "LUCENE-5218.patch": "https://issues.apache.org/jira/secure/attachment/12605084/LUCENE-5218.patch",
        "lucene44-LUCENE-5218.zip": "https://issues.apache.org/jira/secure/attachment/12604772/lucene44-LUCENE-5218.zip"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2013-09-16T06:22:36+0000",
            "content": "PagedBytes.java#fillSlice\nmaybe wrong start??\n\n\n \npublic void fillSlice(BytesRef b, long start, int length) {\n      assert length >= 0: \"length=\" + length;\n      assert length <= blockSize+1;\n      final int index = (int) (start >> blockBits);\n      final int offset = (int) (start & blockMask);\n      b.length = length;\n      if (blockSize - offset >= length) {\n        // Within block\n        b.bytes = blocks[index];\n        b.offset = offset;\n      } else {\n        // Split\n        b.bytes = new byte[length];\n        b.offset = 0;\n        System.arraycopy(blocks[index], offset, b.bytes, 0, blockSize-offset);\n        System.arraycopy(blocks[1+index], 0, b.bytes, blockSize-offset, length-(blockSize-offset));\n      }\n    }\n\n\n  ",
            "author": "Littlestar",
            "id": "comment-13768098"
        },
        {
            "date": "2013-09-16T11:44:45+0000",
            "content": "Which JVM are you using? ",
            "author": "Michael McCandless",
            "id": "comment-13768253"
        },
        {
            "date": "2013-09-16T13:59:23+0000",
            "content": "java version \"1.7.0_25\"\nI also build jdk 7u40 with openjdk-7u40-fcs-src-b43-26_aug_2013.zip\ntwo jdks has same problem. ",
            "author": "Littlestar",
            "id": "comment-13768322"
        },
        {
            "date": "2013-09-16T14:21:16+0000",
            "content": "my app continue insert records, may be 10-10000 records per seconds.\nlucene index with a lots of small segments, so I call forceMerge(80) before each call. ",
            "author": "Littlestar",
            "id": "comment-13768344"
        },
        {
            "date": "2013-09-16T14:56:43+0000",
            "content": "Don't use 7u40: there is apparently a JVM bug that can cause index corruption like this (LUCENE-5212).\n\nBut 7u25 should be safe.  If you use only 7u25, and start from a new index, you can reproduce this exception?  Can you run CheckIndex on the resulting index and post the output? ",
            "author": "Michael McCandless",
            "id": "comment-13768380"
        },
        {
            "date": "2013-09-17T08:35:42+0000",
            "content": "jvm args:\n-Xss256k -XX:+UnlockExperimentalVMOptions -XX:+UseG1GC -XX:MaxGCPauseMillis=200 -XX:GCPauseIntervalMillis=1000 -XX:NewRatio=2 -XX:SurvivorRatio=1 \nmaybe UseG1GC has bug? ",
            "author": "Littlestar",
            "id": "comment-13769327"
        },
        {
            "date": "2013-09-17T12:05:33+0000",
            "content": "Can you reproduce this, starting from a clean index?  If so, try to narrow it down, e.g. try not passing any of those extra JVM args and see if it still repros?\n\nIt's also quite possible it's a real bug somewhere in how binary DV fields are written/read!  So if you can boil it down to a smallish test case then we can better narrow it down. ",
            "author": "Michael McCandless",
            "id": "comment-13769460"
        },
        {
            "date": "2013-09-24T07:15:15+0000",
            "content": "I can't narrow it down from an empty index.\nbut I backup the failed index (5G).\n\nI run core\\src\\java\\org\\apache\\lucene\\index\\CheckIndex.java\nmaybe one segment failed.\n\n44 of 54: name=_d8 docCount=19599\n    codec=hybaseStd42x\n    compound=true\n    numFiles=3\n    size (MB)=9.559\n    diagnostics = \n{timestamp=1379167874407, mergeFactor=22, os.version=2.6.32-358.el6.x86_64, os=Linux, lucene.version=4.4.0 1504776 - sarowe - 2013-07-19 02:49:47, source=merge, os.arch=amd64, mergeMaxNumSegments=1, java.version=1.7.0_25, java.vendor=Oracle Corporation}\n    no deletions\n    test: open reader.........OK\n    test: fields..............OK [29 fields]\n    test: field norms.........OK [4 fields]\n    test: terms, freq, prox...OK [289268 terms; 3096641 terms/docs pairs; 689694 tokens]\n    test: stored fields.......OK [408046 total field count; avg 20.82 fields per doc]\n    test: term vectors........OK [0 total vector count; avg 0 term/freq vector fields per doc]\n    test: docvalues...........ERROR [2]\njava.lang.ArrayIndexOutOfBoundsException: 2\n\tat org.apache.lucene.util.PagedBytes$Reader.fillSlice(PagedBytes.java:92)\n\tat org.apache.lucene.codecs.lucene42.Lucene42DocValuesProducer$6.get(Lucene42DocValuesProducer.java:267)\n\tat org.apache.lucene.index.CheckIndex.checkBinaryDocValues(CheckIndex.java:1316)\n\tat org.apache.lucene.index.CheckIndex.checkDocValues(CheckIndex.java:1420)\n\tat org.apache.lucene.index.CheckIndex.testDocValues(CheckIndex.java:1291)\n\tat org.apache.lucene.index.CheckIndex.checkIndex(CheckIndex.java:615)\n\tat org.apache.lucene.index.CheckIndex.main(CheckIndex.java:1854)\nFAILED\n    WARNING: fixIndex() would remove reference to this segment; full exception:\njava.lang.RuntimeException: DocValues test failed\n\tat org.apache.lucene.index.CheckIndex.checkIndex(CheckIndex.java:628)\n\tat org.apache.lucene.index.CheckIndex.main(CheckIndex.java:1854)\n\n  45 of 54: name=_3xn docCount=215407 ",
            "author": "Littlestar",
            "id": "comment-13776059"
        },
        {
            "date": "2013-09-24T07:21:03+0000",
            "content": "org.apache.lucene.index.CheckIndex -segment _d8 /tmp/backup/indexdir\nfailed agian.\n\nhow to narrow it down, thanks.\nI can reduced index files, mininal files, contain _d8, CheckIndex failed with above errors.\nCan I upload the following index files? (32M)\n\n \nsegments_54d\n*.si\n_d8.cfe\n_d8.cfs\n\n  ",
            "author": "Littlestar",
            "id": "comment-13776068"
        },
        {
            "date": "2013-09-24T10:46:27+0000",
            "content": "I attached testindex and testcode.\nSome files in test_fail_index was deleted except segment \"_d8\". (full indexSize is 5G(54 segments), only segment \"_d8\" needed for testcase)\n\njava -cp ./bin;./lib/lucene-core-4.4.0.jar;./lib/lucene-codecs-4.4.0.jar org.apache.lucene.index.CheckIndex -segment _d8 ./test_fail_index\n\nThanks. ",
            "author": "Littlestar",
            "id": "comment-13776189"
        },
        {
            "date": "2013-09-25T14:57:33+0000",
            "content": "\npublic void fillSlice(BytesRef b, long start, int length) {\n      assert length >= 0: \"length=\" + length;\n      assert length <= blockSize+1;\n      final int index = (int) (start >> blockBits);\n      final int offset = (int) (start & blockMask);\n      b.length = length;\n      if (blockSize - offset >= length) {\n        // Within block\n        b.bytes = blocks[index];  //here is java.lang.ArrayIndexOutOfBoundsException\n        b.offset = offset;\n      } else {\n        // Split\n        b.bytes = new byte[length];\n        b.offset = 0;\n        System.arraycopy(blocks[index], offset, b.bytes, 0, blockSize-offset);\n        System.arraycopy(blocks[1+index], 0, b.bytes, blockSize-offset, length-(blockSize-offset));\n      }\n    }\n\n\n\nI debug into above code.\nwhen java.lang.ArrayIndexOutOfBoundsException occurs:\nb=[], start=131072,lenth=0\nindex=2, offset=0, blockSize=65536, blockBits=16, blockMask=65535, blocks.length=2\n\nmy patch:\n\n public void fillSlice(BytesRef b, long start, int length) {\n      assert length >= 0: \"length=\" + length;\n      assert length <= blockSize+1: \"length=\" + length;\n      final int index = (int) (start >> blockBits);\n      final int offset = (int) (start & blockMask);\n      b.length = length;\n      \n      +if (index >= blocks.length) {\n      +   // Outside block\n      +   b.bytes = EMPTY_BYTES;\n      +   b.offset = b.length = 0;\n      +} else if (blockSize - offset >= length) {\n        // Within block\n        b.bytes = blocks[index];\n        b.offset = offset;\n      } else {\n        // Split\n        b.bytes = new byte[length];\n        b.offset = 0;\n        System.arraycopy(blocks[index], offset, b.bytes, 0, blockSize-offset);\n        System.arraycopy(blocks[1+index], 0, b.bytes, blockSize-offset, length-(blockSize-offset));\n      }\n    }\n\n\n ",
            "author": "Littlestar",
            "id": "comment-13777584"
        },
        {
            "date": "2013-09-25T15:45:54+0000",
            "content": "Hmm are you adding length=0 binary doc values?  It sounds like this could be a bug in that case, when the start aligns with the block boundary. ",
            "author": "Michael McCandless",
            "id": "comment-13777637"
        },
        {
            "date": "2013-09-25T15:59:59+0000",
            "content": "mybe binary doc length=0.\nmyapp convert string to byte[], adding to binaryDocvalues.\n\nabove patch works for me. ",
            "author": "Littlestar",
            "id": "comment-13777672"
        },
        {
            "date": "2013-09-25T19:16:28+0000",
            "content": "Thanks Littlestar, I'm able to reproduce this with a small test case ... I'll add a patch shortly. ",
            "author": "Michael McCandless",
            "id": "comment-13777956"
        },
        {
            "date": "2013-09-25T19:22:08+0000",
            "content": "Patch w/ test and fix; I fixed it slightly differently, just returning immediately when length == 0. ",
            "author": "Michael McCandless",
            "id": "comment-13777968"
        },
        {
            "date": "2013-09-26T02:14:31+0000",
            "content": "patch tested OK.\nplease submit to trunk/trunk4x/trunk45, thanks.\n\nChecking only these segments: _d8:\n  44 of 54: name=_d8 docCount=19599\n    codec=hybaseStd42x\n    compound=true\n    numFiles=3\n    size (MB)=9.559\n    diagnostics = \n{timestamp=1379167874407, mergeFactor=22, os.version=2.6.32-358.el6.x86_64, os=Linux, lucene.version=4.4.0 1504776 - sarowe - 2013-07-19 02:49:47, source=merge, os.arch=amd64, mergeMaxNumSegments=1, java.version=1.7.0_25, java.vendor=Oracle Corporation}\n    no deletions\n    test: open reader.........OK\n    test: fields..............OK [29 fields]\n    test: field norms.........OK [4 fields]\n    test: terms, freq, prox...OK [289268 terms; 3096641 terms/docs pairs; 689694 tokens]\n    test: stored fields.......OK [408046 total field count; avg 20.82 fields per doc]\n    test: term vectors........OK [0 total vector count; avg 0 term/freq vector fields per doc]\n    test: docvalues...........OK [0 total doc count; 13 docvalues fields]\n\nNo problems were detected with this index. ",
            "author": "Littlestar",
            "id": "comment-13778368"
        },
        {
            "date": "2013-09-26T14:57:55+0000",
            "content": "Commit 1526529 from Michael McCandless in branch 'dev/branches/branch_4x'\n[ https://svn.apache.org/r1526529 ]\n\nLUCENE-5218: fix exception when trying to read a 0-byte BinaryDocValues field ",
            "author": "ASF subversion and git services",
            "id": "comment-13778847"
        },
        {
            "date": "2013-09-26T14:59:52+0000",
            "content": "Commit 1526538 from Michael McCandless in branch 'dev/trunk'\n[ https://svn.apache.org/r1526538 ]\n\nLUCENE-5218: fix exception when trying to read a 0-byte BinaryDocValues field ",
            "author": "ASF subversion and git services",
            "id": "comment-13778849"
        },
        {
            "date": "2013-09-26T15:05:27+0000",
            "content": "Commit 1526546 from Michael McCandless in branch 'dev/branches/lucene_solr_4_5'\n[ https://svn.apache.org/r1526546 ]\n\nLUCENE-5218: fix exception when trying to read a 0-byte BinaryDocValues field ",
            "author": "ASF subversion and git services",
            "id": "comment-13778859"
        },
        {
            "date": "2013-09-26T15:06:10+0000",
            "content": "I also committed the fix to 45x branch; if we re-spin a new RC then I'll update the fix version here. ",
            "author": "Michael McCandless",
            "id": "comment-13778866"
        },
        {
            "date": "2013-09-26T15:31:33+0000",
            "content": "Commit 1526575 from Michael McCandless in branch 'dev/branches/lucene_solr_4_5'\n[ https://svn.apache.org/r1526575 ]\n\nLUCENE-5218: add CHANGES ",
            "author": "ASF subversion and git services",
            "id": "comment-13778903"
        },
        {
            "date": "2013-09-26T15:32:52+0000",
            "content": "Commit 1526577 from Michael McCandless in branch 'dev/branches/branch_4x'\n[ https://svn.apache.org/r1526577 ]\n\nLUCENE-5218: add CHANGES ",
            "author": "ASF subversion and git services",
            "id": "comment-13778905"
        },
        {
            "date": "2013-09-26T15:35:24+0000",
            "content": "Commit 1526579 from Michael McCandless in branch 'dev/trunk'\n[ https://svn.apache.org/r1526579 ]\n\nLUCENE-5218: add CHANGES ",
            "author": "ASF subversion and git services",
            "id": "comment-13778906"
        },
        {
            "date": "2013-10-05T10:19:03+0000",
            "content": "4.5 release -> bulk close ",
            "author": "Adrien Grand",
            "id": "comment-13787069"
        }
    ]
}