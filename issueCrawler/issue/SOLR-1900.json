{
    "id": "SOLR-1900",
    "title": "move Solr to flex APIs",
    "details": {
        "affect_versions": "4.0-ALPHA",
        "status": "Closed",
        "fix_versions": [
            "4.0-ALPHA"
        ],
        "components": [],
        "type": "Improvement",
        "priority": "Major",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "Solr should use flex APIs",
    "attachments": {
        "SOLR-1900-facet_enum.patch": "https://issues.apache.org/jira/secure/attachment/12443429/SOLR-1900-facet_enum.patch",
        "SOLR-1900_bigTerm.txt": "https://issues.apache.org/jira/secure/attachment/12454505/SOLR-1900_bigTerm.txt",
        "SOLR-1900_termsComponent.txt": "https://issues.apache.org/jira/secure/attachment/12444810/SOLR-1900_termsComponent.txt",
        "SOLR-1900_FileFloatSource.patch": "https://issues.apache.org/jira/secure/attachment/12451679/SOLR-1900_FileFloatSource.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Yonik Seeley",
            "id": "comment-12863200",
            "date": "2010-05-02T21:57:00+0000",
            "content": "Attaching draft flex use for the facet.enum method.\n\nThis currently fails with:\n\nSEVERE: Exception during facet counts:java.lang.IllegalStateException: external IndexReader requires skipDocs == MultiFields.getDeletedDocs()\n\tat org.apache.lucene.index.LegacyFieldsEnum$LegacyDocsEnum.reset(LegacyFieldsEnum.java:206)\n\tat org.apache.lucene.index.LegacyFieldsEnum$LegacyTermsEnum.docs(LegacyFieldsEnum.java:164)\n\tat org.apache.lucene.index.MultiTermsEnum.docs(MultiTermsEnum.java:276)\n\tat org.apache.solr.request.SimpleFacets.getFacetTermEnumCounts(SimpleFacets.java:566)\n\n\n\nNot sure if that's an issue with all compound readers (top-level readers as opposed to segment readers) or if it's an issue with SolrIndexReader.\n\nedit: this patch also makes BytesRef comparable. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12863201",
            "date": "2010-05-02T22:02:44+0000",
            "content": "Could this perhaps be an issue with FilterIndexReader?  It doesn't look like it delegates everything that it should?  (like fields() for example) "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12863206",
            "date": "2010-05-02T22:18:17+0000",
            "content": "Yep, it was FilterIndexReader... I randomly overrode a bunch of the methods and delegated to the inner reader, and everything started working. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12863224",
            "date": "2010-05-03T01:02:08+0000",
            "content": "Here's an updated patch that fixes the issue (actually works around it) by overriding and delegating in SolrIndexSearcher itself.\n\nI'm not going to commit this quite yet... the comparator used in BytesRef is not the same as the index order for code points outside the BMP... so people using those characters would see strange paging issues when sorting facet results by index order.  It looks like Lucene should be switching it's index order to pure code point order (which is exactly the same as comparing encoded UTF8 bytes when treated as unsigned). "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12863499",
            "date": "2010-05-03T20:20:42+0000",
            "content": "I did a facet.method=enum test with a large number of unique terms and a large minDf (so FilterCache won't be used, just enumerate over terms).\nThis patch increased throughput by 50%! "
        },
        {
            "author": "Michael McCandless",
            "id": "comment-12863503",
            "date": "2010-05-03T20:27:10+0000",
            "content": "Whoa that's great! "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12863854",
            "date": "2010-05-04T15:49:37+0000",
            "content": "The DocSet generation in SolrIndexReader was also upgraded to flex... (I committed it yesterday accidentally along with the fix that caused some tests to hang).  Anyway, a facet.method=enum w/o the minDf  and with a too-small filterCache (means it will all go through the filter cache, but generate misses, meaning the changed code in SolrIndexSearcher will be used for every term to generate a new filter) was 53% faster (throughput) after then change. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12867233",
            "date": "2010-05-13T20:01:24+0000",
            "content": "Just committed a fix (r943994) so that getDocSet skips deleted docs.\nThis didn't seem to cause any issues because the generated sets are always intersected with other sets (like a base doc set) that does exclude deleted docs. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12868725",
            "date": "2010-05-18T16:48:01+0000",
            "content": "This patch (SOLR-1900_termsComponent.txt) converts the terms component to use the flex API, and adds support to FieldType for converting to/from BytesRef.\n\nWhen rewriting this code, I noticed an existing bug when sorting by count - the tiebreak will be by external string label and hence won't be in index order.  I'll fix this before commit. "
        },
        {
            "author": "Michael McCandless",
            "id": "comment-12868748",
            "date": "2010-05-18T17:24:11+0000",
            "content": "and adds support to FieldType for converting to/from BytesRef.\n\nOoh!  This is one of my nocommits in LUCENE-2380 \u2013 that will help. "
        },
        {
            "author": "Hoss Man",
            "id": "comment-12872562",
            "date": "2010-05-27T22:07:53+0000",
            "content": "Bulk updating 240 Solr issues to set the Fix Version to \"next\" per the process outlined in this email...\n\nhttp://mail-archives.apache.org/mod_mbox/lucene-dev/201005.mbox/%3Calpine.DEB.1.10.1005251052040.24672@radix.cryptio.net%3E\n\nSelection criteria was \"Unresolved\" with a Fix Version of 1.5, 1.6, 3.1, or 4.0.  email notifications were suppressed.\n\nA unique token for finding these 240 issues in the future: hossversioncleanup20100527 "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12879594",
            "date": "2010-06-17T00:35:36+0000",
            "content": "closing.  LUCENE-2378 did the rest. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12896894",
            "date": "2010-08-10T14:28:52+0000",
            "content": "Now that flex term enumerators can seek, it looks like all of the related logic in FileFloatSource is redundant (keeping track if keys are sorted, trying next() a few times before seeking, etc). "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12896917",
            "date": "2010-08-10T16:00:01+0000",
            "content": "Here's a patch that simplifies FileFloatSource. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12909074",
            "date": "2010-09-14T00:54:07+0000",
            "content": "Attaching patch that moves bigTerm into ByteUtils, adds BytesRef.append(BytesRef), and uses those in the faceting code when a prefix is specified (instead of a String with \\uffff chars).\n\nIf people think that the append() is more Solr specific (i.e. not likely to be used in lucene) I can move it to Solr's ByteUtils. "
        },
        {
            "author": "Michael McCandless",
            "id": "comment-12909160",
            "date": "2010-09-14T09:16:16+0000",
            "content": "I think it makes sense to move append to BytesRef, though I wonder if it should it over-allocate (ArrayUtil.oversize) when it grows?  I realize for the current calls to append we don't need that (you just append bigTerm, once), but if someone uses this like a StringBuffer... though, this isn't really the intention of BytesRef, so maybe it's OK to not oversize. "
        }
    ]
}