{
    "id": "SOLR-877",
    "title": "Access to Lucene's TermEnum capabilities",
    "details": {
        "affect_versions": "None",
        "status": "Closed",
        "fix_versions": [
            "1.4"
        ],
        "components": [],
        "type": "New Feature",
        "priority": "Minor",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "I wrote a simple SearchComponent on the plane the other day that gives access to Lucene's TermEnum capabilities.  I think this will be useful for doing auto-suggest and other term based operations.  My first draft is not distributed, but it probably should be made to do so eventually.",
    "attachments": {
        "SOLR-877.patch": "https://issues.apache.org/jira/secure/attachment/12394562/SOLR-877.patch",
        "SOLR-877_2.patch": "https://issues.apache.org/jira/secure/attachment/12407681/SOLR-877_2.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Grant Ingersoll",
            "id": "comment-12650232",
            "date": "2008-11-24T15:51:45+0000",
            "content": "First draft "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12650981",
            "date": "2008-11-26T12:32:54+0000",
            "content": "This is close to ready to commit. "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12651562",
            "date": "2008-11-28T13:31:13+0000",
            "content": "Committed revision 721491.\n\nThis commit is slightly different from the last patch.  Fixed a couple of minor issues and added the ability to exclude the lower bound. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12651598",
            "date": "2008-11-28T16:38:12+0000",
            "content": "Looks useful, esp for distributed idf when we get around to it.\nA quick review:\n\n\t\"terms.fl\", fl normally stands for field list.  Would this make more sense as \"terms.f\"?\n\tstrings are returned instead of integers for the term count (it's even more obvious in JSON output)\n\thow does one ask for \"all terms after foo?\"  the docs suggest that upper or rows must be set... is the only way to set a really high rows value? If so, allowing terms.rows=-1 for \"unlimited\" might be nicer.\n\n\n\nActually, this is very much like faceting.... perhaps we should use the same parameters:\nterms.field\nterms.offset\nterms.limit\nterms.mincount (future)\nterms.sort (future)\n\nIf this is to be useful for distributed search, it needs to be able to handle the direct specifications of terms in multiple fields.  We necessarily need to implement this now, but we should think about having an output format that doesn't need to be deprecated when it is added.  At a minimum it seems like there should be an extra level.... something like\n\n\"terms\" = {\n  \"myfield\" = { \"foo\"=10, \"bar\"=5, ...}\n}\n\n\nOr if we want to get even more like faceting with the output:\n\n\"terms\" = {\n  \"fields\" = {\n    \"myfield\" = {\"foo\"=10,...}\n  }\n}\n\n\n\n\n\t\"terms.upr.incl\" and \"terms.lwr.incl\" hurt the eyes a little since we already have \"lower\" and \"upper\" in the names of other terms - seems error prone (but this is a purely aesthetic thing).\n\tThis is supposedly useful for auto suggest - how do I go about asking for all terms starting with \"abc\"?  Shouldn't there be a \"terms.prefix\" (just like faceting)?\n\n "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12651603",
            "date": "2008-11-28T16:50:36+0000",
            "content": "Yeah, it is sort of like faceting, but I didn't want to get too close to it, otherwise we're just duplicating effort.  I wanted it to be really lightweight.  We can add the pieces suggested here.  I'll switch to int output right now. "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12651604",
            "date": "2008-11-28T16:53:33+0000",
            "content": "Fixed the int issue.\n\n\nCommitted revision 721534. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12651607",
            "date": "2008-11-28T17:05:19+0000",
            "content": "It's not about duplicating effort (implementation), it's about reusing interface conventions, and what makes the most sense. "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12651609",
            "date": "2008-11-28T17:10:47+0000",
            "content": "The field thing makes sense, too.  I thought about it and originally decided against it to avoid having to ever go to deep into nested NamedLists, but in hindsight, it does make sense to be able to send in multiple fields, which means we can keep the terms.fl param. "
        },
        {
            "author": "Erik Hatcher",
            "id": "comment-12651713",
            "date": "2008-11-29T12:47:59+0000",
            "content": "Do note that suggestions using this component will be across the entire index, not confined with q/fq constraints.  For that capability, look to the facet.prefix feature of the facet component. "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12651715",
            "date": "2008-11-29T13:58:50+0000",
            "content": "It's not about duplicating effort (implementation), it's about reusing interface conventions, and what makes the most sense. \n\nTrue, I see what you mean.  For some reason, though, I tend to think of TermEnum in the terms of lower bound and upper bound instead of offset, b/c offset implies you are a certain number of items into an array (i.e. foo[10]), whereas lower bound just feels looser to me.  Semantics, I know.  As for term.limit, isn't that faceting duplicating the \"rows\" parameter?\n\n\n\nI just committed several changes:\n\n\n\tAdded terms.prefix so now the auto-suggest should be possible.  See the Wiki for an example\n\tChanged upr.incl -> upper.incl and lwr.incl -> lower.incl\n\tFixed a but w/ lower.incl = false that skipped the next term even if the first term was not a match for the input lower bound term.\n\n\n\nCommitted revision 721681. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12651717",
            "date": "2008-11-29T14:18:27+0000",
            "content": "For the purposes of this component, I think of TermEnum as an implementation, not the interface.... people will eventually want to do things like sort by high docfreq (just as in faceting), or only list terms above a certain count, or only list terms matching a certain pattern, etc.  All of these can make sense since we can do it more efficiently closer to the data.\n\nI tend to think of TermEnum in the terms of lower bound and upper bound instead of offset\n\nRight, offset doesn't make as much sense with the current semantics (but it might later).\n\nAs for term.limit, isn't that faceting duplicating the \"rows\" parameter?\n\nYes, we unfortunately have two ways of specifying this (\"rows\" and \"limit\").  I think limit is the better name though (and this will be highly associated with faceting in people's mind I think). "
        },
        {
            "author": "Khee Chin",
            "id": "comment-12652603",
            "date": "2008-12-02T23:56:56+0000",
            "content": "As a solr-user who uses this function for auto-complete, I'd like to filter out terms with a low-frequency count. Thus, I've implemented a quick-hack, against a 28th Nov checkout.\n\n/src/java/org/apache/solr/common/params/TermsParams.java\n  // Optional.  The minimum value of docFreq to be returned.  1 by default\n  public static final String TERMS_FREQ_MIN = TERMS_PREFIX + \"freqmin\";\n   // Optional.  The maximum value of docFreq to be returned.  -1 by default means no boundary\n  public static final String TERMS_FREQ_MAX = TERMS_PREFIX + \"freqmax\";\n\n \n\n\n/src/java/org/apache/solr/handler/component/TermsComponent.java\n    // At lines 55-56, after initializing boolean upperIncl and lowerIncl\n    int freqmin = params.getInt(TermsParams.TERMS_FREQ_MIN,1); // initialize freqmin\n    int freqmax = params.getInt(TermsParams.TERMS_FREQ_MAX,-1); // initialize freqmax\n    \n    // At line 69, replacing terms.add(theText, termEnum.docFreq());,    \n    if (termEnum.docFreq() >= freqmin && (freqmax==-1 || (termEnum.docFreq() <= freqmax))) {\n        terms.add(theText, termEnum.docFreq());\n    } else {\n        i--;\n    } \n\n \n\nThe new parameters could be used by calling\n  terms.freqmin=<value>\n  terms.freqmax=<value>\nboth of which, are optional. "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12652623",
            "date": "2008-12-03T00:30:46+0000",
            "content": "Can you supply as a patch with some simple unit tests? "
        },
        {
            "author": "Khee Chin",
            "id": "comment-12652879",
            "date": "2008-12-03T18:10:53+0000",
            "content": "As req, however, I have only done a single test case, but it should be trivial to add on more test cases in future. "
        },
        {
            "author": "Noble Paul",
            "id": "comment-12653184",
            "date": "2008-12-04T05:52:29+0000",
            "content": "We may need a faster solution for the autoSuggest feature. \nThis can be quite slow because we are doing a string compare for each string .Considering the fact that autoSuggest gets TOO MANY hits in a typical website it should not be doing so much of processing\n\nWe must use something like this http://en.wikipedia.org/wiki/Radix_tree to make it efficient and build the tree in the beginning (and after every commit).  \n\nSOLR-706 can be closed if that is included "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12653187",
            "date": "2008-12-04T06:01:45+0000",
            "content": "lol - didn't take too long for other faceting like features to pop up (i.e. facet.mincount).\nWe really should reuse the facet interface terminology here:  limit, mincount, etc. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12653189",
            "date": "2008-12-04T06:04:25+0000",
            "content": "Noble: would optionally using something like a radix tree change the external interface?  That's what we should be focused most on now in order to enable seamlessly adding optimizations in the future. "
        },
        {
            "author": "Noble Paul",
            "id": "comment-12653201",
            "date": "2008-12-04T06:29:53+0000",
            "content": "autosuggest is a very commonly used feature. And when they are used , the hits are just too many. \n\nwe can add extra options to optimize or not   (say memTree=true/false). \n\nIf the option is set we can build a the data structure . Potentially this tree can consume a lot of memory if there are too many terms . Users must have an option to turn it off.\n\nThe feature may be added with faceting component or the TermComponent. The problem here is that these components are already overloaded.with features. Adding this small option into these can cause more confusion. \n\nIMHO we should not pack too many features into one component unless we are sure that they are mostly used together. (For instance faceting and autosuggest are rarely done as a part of one request ).It would be better to write separate components for each functionality . Internally the components can share code and the users can mix and match if they need to\n "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12653202",
            "date": "2008-12-04T06:35:50+0000",
            "content": "Regardless of how optimizations are selected or turned on/off, do you see anything in the current API that we should change now to enable optimization later (or now for all I care).  I'm only asking about the API. "
        },
        {
            "author": "Noble Paul",
            "id": "comment-12653207",
            "date": "2008-12-04T06:49:40+0000",
            "content": "No changes in the TermComponent API (I mean the HTTP API). \nMay be a config param (in solrconfig.xml) "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12654066",
            "date": "2008-12-06T13:24:09+0000",
            "content": "lol - didn't take too long for other faceting like features to pop up (i.e. facet.mincount).\nWe really should reuse the facet interface terminology here: limit, mincount, etc. \n\nYeah, Yonik, I'm starting to think of this as Term Faceting.   I still like rows better than limit, but will change Khee's params to be mincount and maxcount "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12654102",
            "date": "2008-12-06T14:12:16+0000",
            "content": "I still like rows better than limit,\n\nSo are you advocating deprecating facet.limit and adding facet.rows,\nor that aligning the APIs doesn't matter in this case? "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12654103",
            "date": "2008-12-06T14:12:24+0000",
            "content": "Noble, have you done any performance testing of this approach versus the radix tree (or other tree/trie approaches)?\n\nAIUI, if you do the tree approach, doesn't that mean you need to build the tree from all of the terms in a given field?  And then what about if you want to go across multiple fields?  Seems like that would be a pretty large footprint.  In some sense, the Term dictionary in Lucene is already very similar to this structure, except it can't do the character matching like you are proposing (but it does very efficiently encodes the terms) "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12654104",
            "date": "2008-12-06T14:13:01+0000",
            "content": "Committed revision 723985.  Thanks, Khee!  I slightly changed the patch to use \"mincount\" and \"maxcount\" per Yonik's suggestion to overlap w/ faceting. "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12654110",
            "date": "2008-12-06T14:27:03+0000",
            "content": "So are you advocating deprecating facet.limit and adding facet.rows,\nor that aligning the APIs doesn't matter in this case?\n\nI don't know.  Does every param need to be consistent?  If that is the case, then I guess we should either decide on rows or limit across all of them.  \n\nOtherwise, I mean, all of these end up having a prefix attached to them (i.e. terms.rows), so it may not be a big deal, either.  I'm fine either way, I guess.  Your call. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12654118",
            "date": "2008-12-06T15:21:27+0000",
            "content": "Does every param need to be consistent?\n\nNo... there's certainly no mandate... \"rows\" and \"facet.limit\" are established enough now that neither should be changed IMO.\nIt just seems like more consistency rather than less generally seems like a good thing, balanced with other factors of course.  It also affects usability - if people think about this more like faceting, they are more likely to quickly type terms.limit by mistake.\n\nOf course these things are aesthetic and subjective  - would be nice to hear from someone else on preferences before a release. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12654120",
            "date": "2008-12-06T15:45:10+0000",
            "content": "Another thought I'll just throw out there w/o advocating: could this just be a faceting optimization?\n\nIf the faceting base query is :, and one can ignore deleted docs, then the facet counts are equivalent to the term df here.  So this could be implemented as an optimization to faceting w/ the addition of a facet.ignoreDeletes parameter.  Then the distributed part would already be done (once facet.sort=false is implemented for distributed search). "
        },
        {
            "author": "Noble Paul",
            "id": "comment-12654134",
            "date": "2008-12-06T16:56:52+0000",
            "content": "have you done any performance testing of this approach versus the radix tree (or other tree/trie approaches)? \n\nI haven't done a perf comparison. But , it occurred to me as I looked at the code .It goes through each Term one by one and does a startsWith()\n\nIt can be quite expensive for large no:of Terms\n\nMemory consumption can be a problem. \nThat is why I suggested a config param. User can make a call as to whether he wants to pay that price and he can afford that.\n "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12654164",
            "date": "2008-12-07T00:18:50+0000",
            "content": "\nAnother thought I'll just throw out there w/o advocating: could this just be a faceting optimization?\n\nIf the faceting base query is :, and one can ignore deleted docs, then the facet counts are equivalent to the term df here. So this could be implemented as an optimization to faceting w/ the addition of a facet.ignoreDeletes parameter. Then the distributed part would already be done (once facet.sort=false is implemented for distributed search).\n\nHmmm, probably true.  I tend to think of this as pretty lightweight, but I see no reason not to make your suggested changes in the facet code either. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12707594",
            "date": "2009-05-09T01:33:52+0000",
            "content": "I've been reviewing some interfaces in prep for the 1.4 release....  Here's a patch to this request handler:\n\n\tfixes the labels for non-text fields (makes them human readable)\n\tadds a terms.raw parameter just in case you really do want the raw internal indexed form of the term\n\tchanges terms.rows to terms.limit to match faceting (as predicted, people want to sort by freq too, so this is much closer to faceting than anything else)\n\tchanges the name of the request handler in the example schema to the more generic /terms (from /autoSuggest).  I could see this becoming a standard useful request handler, and limiting it to /autoSuggest doesn't sound right\n\n\n\nI'll commit shortly barring objections. "
        },
        {
            "author": "Matt Weber",
            "id": "comment-12707601",
            "date": "2009-05-09T03:27:33+0000",
            "content": "I wrote a patch for freq. sorting thar is attached to SOLR-1156. I will update that patch once you commit your latest changes. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12707661",
            "date": "2009-05-09T13:06:32+0000",
            "content": "Committed latest changes, will update wiki shortly. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12707667",
            "date": "2009-05-09T13:43:02+0000",
            "content": "Hmmm, looking at the wiki examples, I think there are some more quick improvements we can do...\n\nFrom the wiki:\nTo use in auto-suggest, add in a lower bound, an upper bound and make the lower bound exclusive of the input term, as in: http://localhost:8983/solr/terms?terms.fl=name&terms.lower=at&terms.prefix=at&terms.lower.incl=false&terms.upper=b&indent=true\n\nUnless I'm missing something, it doesn't make sense to exclude the lower bound... seems like it would often be useful to know if what the user typed in matched a term in the index.... excluding it would lead one to believe that it doesn't exist.\n\nBut the improvement is that one should simply be able to specify a prefix:\nhttp://localhost:8983/solr/terms?terms.fl=name&terms.prefix=at\n\nThe rest should be implementation details in Solr to make it efficient (i.e. Solr should know to start at \"at\" in the TermEnum if that's the prefix.) "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12707677",
            "date": "2009-05-09T14:42:29+0000",
            "content": "Found another bug: null pointer exception if you try a term enum past the end of the index (where lucene will return null from the term enum):\nhttp://localhost:8983/solr/terms?terms.fl=zzz_s "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12707723",
            "date": "2009-05-09T23:32:11+0000",
            "content": "Unless I'm missing something, it doesn't make sense to exclude the lower bound... seems like it would often be useful to know if what the user typed in matched a term in the index.... excluding it would lead one to believe that it doesn't exist.\n\nI think excluding the lower bound allows you to get the next item for suggestion, but I suppose it is up to the app to decide whether they want to confirm the existing word, or just suggest what could come next. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12707729",
            "date": "2009-05-10T01:30:08+0000",
            "content": "OK, I just committed a fix for the null pointer exceptions, changed to use intern'd comparisons, and a little restructuring.  Hopefully that's it. "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12775586",
            "date": "2009-11-10T15:51:51+0000",
            "content": "Bulk close for Solr 1.4 "
        }
    ]
}