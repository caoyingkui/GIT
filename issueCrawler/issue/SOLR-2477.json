{
    "id": "SOLR-2477",
    "title": "add analyzer type=\"phrase\"",
    "details": {
        "affect_versions": "None",
        "status": "Open",
        "fix_versions": [
            "4.9",
            "6.0"
        ],
        "components": [],
        "type": "Improvement",
        "priority": "Major",
        "labels": "",
        "resolution": "Unresolved"
    },
    "description": "This is just exposing LUCENE-2892, so you can easily configure things\nso that if users put things in double quotes they get a more precise search.",
    "attachments": {
        "SOLR-2477.patch": "https://issues.apache.org/jira/secure/attachment/12477329/SOLR-2477.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Robert Muir",
            "id": "comment-13024936",
            "date": "2011-04-25T19:58:18+0000",
            "content": "here's my example fieldtype from the test:\n\n      <analyzer type=\"index\">\n        <!--  pretty standard, except stopwords are indexed, and WDF preserves -->\n        <tokenizer class=\"solr.WhitespaceTokenizerFactory\"/>\n        <filter class=\"solr.WordDelimiterFilterFactory\"  preserveOriginal=\"1\" generateWordParts=\"1\" generateNumberParts=\"1\" catenateWords=\"1\" catenateNumbers=\"1\" catenateAll=\"0\" splitOnCaseChange=\"1\"/>\n        <filter class=\"solr.LowerCaseFilterFactory\"/>\n        <filter class=\"solr.KeywordMarkerFilterFactory\" protected=\"protwords.txt\"/>\n        <filter class=\"solr.PorterStemFilterFactory\"/>\n      </analyzer>\n      <analyzer type=\"query\">\n        <!--  remove stopwords, expand synonyms, WDF, etc etc. -->\n        <tokenizer class=\"solr.WhitespaceTokenizerFactory\"/>\n        <filter class=\"solr.SynonymFilterFactory\" synonyms=\"synonyms.txt\" ignoreCase=\"true\" expand=\"true\"/>\n        <filter class=\"solr.StopFilterFactory\" ignoreCase=\"true\" words=\"stopwords.txt\" enablePositionIncrements=\"true\"/>\n        <filter class=\"solr.WordDelimiterFilterFactory\" generateWordParts=\"1\" generateNumberParts=\"1\" catenateWords=\"0\" catenateNumbers=\"0\" catenateAll=\"0\" splitOnCaseChange=\"1\"/>\n        <filter class=\"solr.LowerCaseFilterFactory\"/>\n        <filter class=\"solr.KeywordMarkerFilterFactory\" protected=\"protwords.txt\"/>\n        <filter class=\"solr.PorterStemFilterFactory\"/>\n      </analyzer>\n      <analyzer type=\"phrase\">\n      <tokenizer class=\"solr.WhitespaceTokenizerFactory\"/>\n        <!--  in this case no synonyms are expanded, and the exact stopwords, punctuation, etc must be present  -->\n        <filter class=\"solr.LowerCaseFilterFactory\"/>\n        <filter class=\"solr.KeywordMarkerFilterFactory\" protected=\"protwords.txt\"/>\n        <filter class=\"solr.PorterStemFilterFactory\"/>\n      </analyzer>\n    </fieldType>\n\n "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13024944",
            "date": "2011-04-25T20:20:59+0000",
            "content": "Interesting idea having a separate analyzer to expose this.\nIt's probably important to come up with a good example for the example schema, because I could see it being error-prone if people do it themselves.  For example, if they tried your test example (which may look reasonable to someone at first blush)\nthey wouldn't get any matches for anything that the WDF would normally split? "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13024946",
            "date": "2011-04-25T20:24:40+0000",
            "content": "Well, we could maybe add something to the example, I thought it was sort of expert.\n\nWell in my example, they would get matches for things that WDF normally splits, but only if the punctuation is exactly as they entered it:\nassume doc 3 is 'foo bar' and doc4 is 'foo-bar'\n\n  /** \n   * test punctuation, we preserve the original for this purpose\n   */\n  public void testPunctuation() {\n    assertQ(\"normal query: \",\n       req(\"fl\", \"id\", \"q\", \"foo-bar\", \"sort\", \"id asc\" ),\n              \"//*[@numFound='2']\",\n              \"//result/doc[1]/int[@name='id'][.=3]\",\n              \"//result/doc[2]/int[@name='id'][.=4]\"\n    );\n    \n    assertQ(\"phrase query: \",\n        req(\"fl\", \"id\", \"q\", \"\\\"foo-bar\\\"\", \"sort\", \"id asc\" ),\n               \"//*[@numFound='1']\",\n               \"//result/doc[1]/int[@name='id'][.=4]\"\n     );\n  }\n\n\n\nBut, this was just an example, you don't have to involve WDF to take advantage of this (probably stopwords/synonyms/decompounders are the simplest way). I was just coming up with an examples to have some unit tests. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13024954",
            "date": "2011-04-25T20:44:33+0000",
            "content": "Well in my example, they would get matches for things that WDF normally splits, but only if the punctuation is exactly as they entered it\n\nAh, I had missed the \"preserveOriginal\" on the index analyzer. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13024958",
            "date": "2011-04-25T20:53:29+0000",
            "content": "Yeah, still even then, if we want something for the example, maybe its enough to just exclude the synonymfilter? "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13050642",
            "date": "2011-06-16T18:46:46+0000",
            "content": "At first glance this looks great to me ... but we should seriously consider whether FieldQParser should also be using getPhraseAnalyzer.  I think given the semantics the answer is \"yes\" \u2013 but either way it should be clearly documented.\n\nwe should also make sure analysis.jsp and the Analysis RequestHandler(s?) have options for using this.\n "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13050646",
            "date": "2011-06-16T18:52:38+0000",
            "content": "\nbut we should seriously consider whether FieldQParser should also be using getPhraseAnalyzer. \n\nLooking at how this is described, it seems to me it should use the phrase analyzer... we can document that it does this, and of course the change is backwards compatible (because if you don't define it, its your query analyzer).\n\n\nwe should also make sure analysis.jsp and the Analysis RequestHandler(s?) have options for using this.\n\nI agree... hopefully this isn't too bad. "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13067437",
            "date": "2011-07-19T01:38:09+0000",
            "content": "Having just looked at this code in SOLR-2663 i'm realizing that as we add more types of analyzers, we should really clean up the semantics of how a analyzers w/o \"type\" attributes are treated, and how each of hte analyzers default if they aren't specified.\n\nConsider the following (contrived) example...\n\n\n<fieldType name=\"hoss\" class=\"solr.TextField\" positionIncrementGap=\"100\">\n   <analyzer>\n     <tokenizer class=\"solr.WhitespaceTokenizerFactory\"/>\n   </analyzer>\n   <analyzer type=\"index\">\n     <tokenizer class=\"solr.KeywordTokenizerFactory\"/>\n   </analyzer>\n</fieldType>\n\n\n\nRight now (on trunk and with this patch) that config will result in all of the analyzers (index/query[/phrase]) using KeywordTokenizerFactory because the type-less analyzer is ignored if there is is an analyzer with type=\"index\".  I don't think that makes much sense, and as we add more types of analyzers it makes even less sense \u2013 an analyzer w/o a type attribute should really be the \"default\" for each other type\n\nI think we should change the overall flow to be (psudeo-code) ...\n\n\n// exactly what is in the config\nAnalyzer defaultA = readAnalyzer(xpath(\"./analyzer[not(@type)]\"));\nAnalyzer indexA = readAnalyzer(xpath(\"./analyzer[@type='index']\"));\nAnalyzer queryA = readAnalyzer(xpath(\"./analyzer[@type='query']\"));\nAnalyzer phraseA = readAnalyzer(xpath(\"./analyzer[@type='phrase']\"));\n\nif (null != defaultA) {\n  // we have an explicit default\n  if (null == indexA) indexA = defaultA;\n  if (null == queryA) queryA = defaultA;\n  if (null == phraseA) phraseA = defaultA;\n} else {\n  // implicit defaults, either historical or common sense\n  if (null == queryA) queryA = indexA;\n  if (null == phraseA) phraseA = queryA;\n}\n\n "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13067441",
            "date": "2011-07-19T01:45:41+0000",
            "content": "+1\n\nIf we decide to implement this or SOLR-219 via 'types of analyzers', I don't want to think of all the combinations if we do it any other way.\n\nI would even go so far as to say, dont call it defaultA, but instead globalA, and if you declare this thing, and then also declare some specific analyzer,\nwe throw an exception. "
        },
        {
            "author": "Steve Rowe",
            "id": "comment-13717305",
            "date": "2013-07-23T18:47:48+0000",
            "content": "Bulk move 4.4 issues to 4.5 and 5.0 "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-13971168",
            "date": "2014-04-16T12:57:21+0000",
            "content": "Move issue to Solr 4.9. "
        }
    ]
}