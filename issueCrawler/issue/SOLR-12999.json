{
    "id": "SOLR-12999",
    "title": "Index replication could delete segments first",
    "details": {
        "type": "Improvement",
        "status": "Open",
        "labels": "",
        "fix_versions": [],
        "components": [
            "replication (java)"
        ],
        "priority": "Major",
        "resolution": "Unresolved",
        "affect_versions": "None"
    },
    "description": "Index replication could optionally delete files that it knows will not be needed first.  This would reduce disk capacity requirements of Solr, and it would reduce some disk fragmentation when space get tight.\n\nSolr (IndexFetcher) already grabs the remote file list, and it could see which files it has locally, then delete the others.  Today it asks Lucene to deleteUnusedFiles at the end.  This new mode would probably only be useful if there is no SolrIndexSearcher open, since it would prevent the removal of files.\n\nThe motivating scenario is a SolrCloud replica that is going into full recovery.  It ought to not be fielding searches.  The code changes would not depend on SolrCloud though.\n\nThis option would have some danger the user should be aware of.  If the replication fails, leaving the local files incomplete/corrupt, the only recourse is to try full replication again.  You can't just give up and field queries.",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "id": "comment-16691897",
            "content": "I'm a little lost here. What's the definition of \"knows will not be needed\"? If it's a list of segments locally that are not present on the leader and therefore won't be necessary this seems fraught.\n\n> if a new searcher is opened for any reason, wouldn't it fail? Restarts, rogue commits, whatever.\n\n> Wouldn't the files still  be there on *nix systems if a searcher had them open?\n\n> On Windows systems, if a searcher has the files open would the delete fail in the first place?\n\nI know you know Lucene details far better than me, so I suspect I'm totally missing the point. ",
            "author": "Erick Erickson",
            "date": "2018-11-19T15:54:05+0000"
        },
        {
            "id": "comment-16692005",
            "content": "As noted by Erick these statements should be true:\n\nOn *nix, Lucene/Solr can successfully delete any file, but until the current searcher closes them, the space won't be released.  On Windows, trying to delete files that a searcher has open will fail.\n\nI like the idea, but for these reasons, I don't think it will actually work. ",
            "author": "Shawn Heisey",
            "date": "2018-11-19T17:02:18+0000"
        },
        {
            "id": "comment-16692096",
            "content": "On my old project we forked IndexFetcher to do something similar - when full replication was called for (so we'd be deleting every single file once it was done), we pointed the index to a newly-created dummy directory and made sure the Searcher was off the existing one before a cleanup was triggered on the original index directory, which would cause the underlying now-unneeded files to be deleted. \n\nJason Baik can probably add more to this. ",
            "author": "Michael Braun",
            "date": "2018-11-19T18:36:48+0000"
        },
        {
            "id": "comment-16692606",
            "content": "As Michael hints at indirectly, the motivating use-case is especially SolrCloud when full-replication is needed to get back in sync when a replica starts up after it had been down.  This is what I have in mind, any way.  In this circumstance, I am hoping and assuming a SolrIndexSearcher would not even be open since the replica isn't searchable in this case (right?). ",
            "author": "David Smiley",
            "date": "2018-11-20T03:41:36+0000"
        },
        {
            "id": "comment-16693497",
            "content": "Exactly - in the SolrCloud case where it can't PeerSync, index files need to be shipped over for recovery, and that recovering replica shouldn't be serving traffic (so the close of the searcher should be safe / it should have already been closed). \n\nThe other use case for this is if you're using more than 50% hard drive, copying index files could result in going out of disk. \n\nAlso one thing to note - fullCopy=false does not necessarily mean it won't copy basically an entire full index over. ",
            "author": "Michael Braun",
            "date": "2018-11-20T17:05:12+0000"
        },
        {
            "id": "comment-16693648",
            "content": "David Smiley Ah, ok. That makes sense. Deleting them first since you can't search anyway seems safe enough.\n\nMichael Braun\nThe other use case for this is if you're using more than 50% hard drive, copying index files could result in going out of disk\n\nThat's the dangerous case unless, as David indicates, the replica is never going to serve queries anyway. Say replication deletes segments, then for any reason, the sync fails to complete. No new searchers can be opened. Ever. Worse, if this cascaded through multiple replicas you could lose data.\n\nYou could refuse to start to replicate if the total size of the segments you knew you had to copy exceeded your available disk space (plus some fudge factor maybe), but there'd still be race conditions where more than one core/replica decided to do a full sync. ",
            "author": "Erick Erickson",
            "date": "2018-11-20T18:38:51+0000"
        },
        {
            "id": "comment-16693670",
            "content": "Erick Erickson right, it should never be serving queries as it's in a 'recovering' rather than 'active' state. If it were to serve queries it would be in out of sync data. The replica has to know it can never serve traffic again unless it fully recovers. If the sync fails to complete, it will need to start over rather than using what it has as an active replica.  ",
            "author": "Michael Braun",
            "date": "2018-11-20T19:06:41+0000"
        },
        {
            "id": "comment-16693677",
            "content": "OK, so maybe change the title or description to be explicit about when this is being considered? As it stands there's nothing indicating that there is an assumption that the core/replica is unusable in the first place when this option is applied. That's twice I've thought someone was talking about replication in general, including non-cloud setups.... ",
            "author": "Erick Erickson",
            "date": "2018-11-20T19:13:37+0000"
        },
        {
            "id": "comment-16693681",
            "content": "The title & description is intentionally general because it's plausibly useful for non-SolrCloud it depends.  The code involved would likely not even be SolrCloud centric (not care about ZK, etc.).  Nevertheless I'll enhance the description ",
            "author": "David Smiley",
            "date": "2018-11-20T19:17:24+0000"
        },
        {
            "id": "comment-16693689",
            "content": "Or I can just stop commenting on a  JIRA I know little about the genesis of  ",
            "author": "Erick Erickson",
            "date": "2018-11-20T19:20:16+0000"
        }
    ]
}