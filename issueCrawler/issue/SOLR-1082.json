{
    "id": "SOLR-1082",
    "title": "Refactor caching layer to be JCache compliant (jsr-107). In particular, consider using ehcache implementation",
    "details": {
        "affect_versions": "1.5",
        "status": "Resolved",
        "fix_versions": [],
        "components": [
            "search"
        ],
        "type": "New Feature",
        "priority": "Major",
        "labels": "",
        "resolution": "Won't Fix"
    },
    "description": "overhaul the caching layer to be compliant\nwith the upcoming Jcache api (jsr-107).\nIn specific, I've been experimenting some with ehcache\n(http://ehcache.sourceforge.net/ , Apache OS license) and it seems to be a\nvery comprehensive implementation, as well as fully compliant with the jcache API.\nI think the benefits are numerous: in respect to ehcache itself, it seems to\nbe a very mature implementation, supporting most classical cache schemes as\nwell as some interesting distributed cache options (and of course,\nperformance-wise its very lucrative in terms of reported multi-cpu scaling\nperformance and  some of the benchmark figures they show).\n\nFurther, abstracting away the caches to use the jcache api would probably\nmake it easier in the future to make the whole caching layer more easily\nswappable with some other implementations that will probably crop up.",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "author": "Noble Paul",
            "id": "comment-12688573",
            "date": "2009-03-24T05:30:10+0000",
            "content": "\n\tWhat is the usecase you are trying to solve by complying with JSR-107?\n\tWhy do you think ehcache is going to be useful?\n\tWhat are the shortcomings of the current caching as you see it?\n\n "
        },
        {
            "author": "Kaktu Chakarabati",
            "id": "comment-12688634",
            "date": "2009-03-24T10:31:21+0000",
            "content": "So:\n\n1. The suggestion for complying with jcache in itself is not in address of a pending critical problem as much as it is a suggestion for moving forward with the caching infrastructure to an implementation that will be more pluggable and transparent than the current one - in specific the possibility of allowing swapping in any 3rd-party implementation that can offer better performance/functionality than the basic caches available in solr currently. \nMoreover, the architecture of the caching layer as described (https://jsr-107-interest.dev.java.net/javadoc/javax/cache/package-summary.html) seems to be pretty well-rounded, including treatment of cache statistics, event listeners, and an application-wide access pattern to the caches (CacheManager). I think this is just a solid standard to go with for formalizing a caching layer that will work well and wont require too much tinkering with/refactoring in the long run.\n\n2. Ehcache is just one such implementation that seems to be already available, well-maintained and offer good performance and functionality out of the box - supporting among other things distributed caching/replication which i think is big, numerous eviction policies out of the box (LRU, LFU, FIFO), JMX and a highly pluggable framework. Its also heavily tested and has been used in major production environments as well some high-profile projects (Spring, Hibernate, Maven among others). Delegating implementation to such a project would probably do solr good in terms of both codebase maintenance  as well as performance, and again, doing it right via the API standard wont tie us down to it either.\n\n3. As I see it, the current caching is pretty basic, and does not scale well to the kind of production-usage scenarios i have in mind. in specific: Supporting only LRU eviction policy, lack of a thorough benchmarking/unit-testing framework such as the one EHcache has alongside publicly available benchmark data and metrics, lack of a well-defined access pattern across the application ( internal caches are defined very differently than user/generic caches in the SolrIndexSearcher, e.g generic caches are doubly referenced by both a Map and a List inside the searcher, much of this implementation logic should probably be abstracted away to a CacheManager kind of object).\nAlso, some of the more serious issues (OOM's) I see with the current behavior when committing index updates while serving requests and having two searcher instances running concurrently, requiring up to twice the space needed in terms of cached objects, might very well be addressed with an implementation such as ehcache that supports Cache/Element-based expiry policies, disk flushing, and cache event listeners. \n "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12688642",
            "date": "2009-03-24T11:11:28+0000",
            "content": "Kaktu, also see SOLR-667 and SOLR-665 if you haven't already.\n\nSome of us did look at ehcache's implementation when were looking for a better cache for the faceting part. I checked again to see if they have a better implementation but I don't think it has changed.\n\nSpecifically look at http://fisheye3.atlassian.com/browse/ehcache/trunk/core/src/main/java/net/sf/ehcache/concurrent/ConcurrentLinkedHashMap.java?r=910\n\nI haven't studied the code completely but from the javadocs:\n\nLeast Recently Used: An eviction policy based on the observation that entries that have been used recently will likely be used again soon. This policy provides a good approximation of an optimal algorithm, but suffers by being expensive to maintain. The cost of reordering entries on the list during every access operation reduces the concurrency and performance characteristics of this policy.\n\nCompare that implementation with Solr's own ConcurrentLRUCache.\nhttp://svn.apache.org/viewvc/lucene/solr/trunk/src/common/org/apache/solr/common/util/ConcurrentLRUCache.java?view=log\n\nThis was built from the ground up to be a fast LRU implementation suited for highly concurrent loads. If somebody can post some benchmarks showing if/how ehcache (or some other implementation) is improving the performance, we will be definitely interested.\n\n3. As I see it, the current caching is pretty basic, and does not scale well to the kind of production-usage scenarios i have in mind.\n\nDon't go on gut feel. I'd highly recommend benchmarking with real data and queries before you jump to any conclusions. Solr has a SolrCache interface. It shouldn't be very tough to write an implementation which uses ehcache for testing.\n\nAlso, some of the more serious issues (OOM's) I see with the current behavior when committing index updates while serving requests and having two searcher instances running concurrently, requiring up to twice the space needed in terms of cached objects, might very well be addressed with an implementation such as ehcache that supports Cache/Element-based expiry policies, disk flushing, and cache event listeners.\n\nThose may have nothing to do with the cache implementation itself. Simply switching to some other cache implementation will not solve the problem. Some of these are need based. A lot of those will be easier when Lucene/Solr can cache per-segment. I'll leave the more intricate details to somebody who knows more than I do about these things. But I can tell you that a lot of work is going on in Lucene/Solr to overcome these difficulties. "
        },
        {
            "author": "Hoss Man",
            "id": "comment-12688788",
            "date": "2009-03-24T18:45:33+0000",
            "content": "Ultimately this issue seems to be about supporting more choices for the users by implementing/utilizing a \"standard\" Caching API.  Specific arguments for/against the current implementations of the SolrCache interface, or comparisons of those implementations to something like ecache aren't really relevant at this time.\n\nwhat is relevant is: \n1) Would more options/features be available to users if the existing hooks for using SolrCache API were refactored to support the JCache API?\n2) what would be involved in making changes to do this?\n3) would these changes be backwards compatible for existing users \u2013 both in terms of \nfeatures and existing performance characteristics.\n\n\nThese seem like questions whose answers won't really be understood until there are some rough patches to discuss. "
        },
        {
            "author": "Ben Manes",
            "id": "comment-12689359",
            "date": "2009-03-26T05:04:05+0000",
            "content": "Yes, the LRU implementation in my CLHM is less than ideal, as I had originally intended to use a back-tracking algorithm but I just didn't trust it.  This is why I use the Second Chance policy in our production environment, as it provides LRU-like efficiency without any bad tricks.  I consider the watermark approach taken by ConcurrentLRUCache to be an equally bad trick, because it plays Russian rollet for which caller takes the hit.  So I was pounding my head trying to figure out how to do it elegantly, experimenting along the way, and hence the warning in the JavaDoc.\n\nIf you look at the google project page for the CLHM (see JavaDoc) you'll see that I've posted a document with a fairly nice design that should resolve your concerns.  There are a few optimizations that can be made that I should update the document with, and I am toying with a rework that may prove to be lock free.  Of course finding the actual bandwidth to implement the algorithm has been challenging.  But its a hobby project, or at least that's my excuse! \n\nSince Greg Luck found enough value in the current, though flawed, implementation he adopted it.  Just like I'm sure that Solr found enough value in the ConcurrentLRUCache - neither design is perfect, but good enough for now.  Hopefully I'll find some time shortly to continue working on my project and Ehcache can adopt a better version in a later release. "
        },
        {
            "author": "Noble Paul",
            "id": "comment-12689368",
            "date": "2009-03-26T05:47:22+0000",
            "content": "because it plays Russian rollet for which caller takes the hit\n\nThat is why it gives the option of cleaning up in a separate thread.  "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13604379",
            "date": "2013-03-16T19:08:59+0000",
            "content": "SPRING_CLEANING_2013. We can reopen if necessary. "
        }
    ]
}