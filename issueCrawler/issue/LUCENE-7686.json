{
    "id": "LUCENE-7686",
    "title": "NRT suggester should have option to filter out duplicates",
    "details": {
        "labels": "",
        "priority": "Major",
        "resolution": "Fixed",
        "affect_versions": "None",
        "status": "Closed",
        "type": "Improvement",
        "components": [],
        "fix_versions": [
            "6.5",
            "7.0"
        ]
    },
    "description": "Some of the other suggesters have this ability, and it's quite simple to add it to the NRT suggester as long as the thing we are filtering on is the suggest key itself, not e.g. another stored field from the document.",
    "attachments": {
        "LUCENE-7686.patch": "https://issues.apache.org/jira/secure/attachment/12852040/LUCENE-7686.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "id": "comment-15861134",
            "date": "2017-02-10T11:20:54+0000",
            "content": "Here's a patch; the duplicate handling needs to be done in the collector (and not the FST traversal) because dups could be across segments. ",
            "author": "Michael McCandless"
        },
        {
            "id": "comment-15861139",
            "date": "2017-02-10T11:22:30+0000",
            "content": "Hmm the patch is not quite right; I need to fix the TopNSearcher.acceptResult to return false in the duplicate case ... I'll iterate some more. ",
            "author": "Michael McCandless"
        },
        {
            "id": "comment-15861145",
            "date": "2017-02-10T11:26:04+0000",
            "content": "OK actually the patch is OK; this suggester effectively ignores that returned boolean since we don't use the returned result from TopNSearcher.search... ",
            "author": "Michael McCandless"
        },
        {
            "id": "comment-15861481",
            "date": "2017-02-10T16:24:57+0000",
            "content": "Another iteration ... it was trickier than I first realized because I have to handle the case where another (later) segment has the same suggestion with a better score, and replace the previous one in the priority queue.\n\nSo I broke out the dedup handling to a separate collector, DeduplicatingTopSuggestDocsCollector.\n\nAnd I added a new randomized test case in addition to the dedicated specific test case.\n\nI think it's ready. ",
            "author": "Michael McCandless"
        },
        {
            "id": "comment-15862397",
            "date": "2017-02-11T13:23:32+0000",
            "content": "Thanks Mike,\nI was busy yesterday because of updating Elasticsearch, so I was not able to look into it. Thanks for doing this.\nI will reply with some related suggestions on the Elastic issue.\nUwe ",
            "author": "Uwe Schindler"
        },
        {
            "id": "comment-15862442",
            "date": "2017-02-11T16:28:38+0000",
            "content": "Thanks Uwe Schindler ... here's the ES issue that led to this: https://github.com/elastic/elasticsearch/issues/22912 ",
            "author": "Michael McCandless"
        },
        {
            "id": "comment-15864589",
            "date": "2017-02-13T22:28:21+0000",
            "content": "Uwe Schindler had a good suggestion on the ES issue, to use the FST earlier to dedup, instead of doing it at collection time ... I'll explore this.  It should make dedup very fast. ",
            "author": "Michael McCandless"
        },
        {
            "id": "comment-15871609",
            "date": "2017-02-17T10:23:08+0000",
            "content": "Another iteration, this time filtering dups earlier in the top N\nsearch.  I added a new method, acceptPartialPath to the\nUtil.TopNSearcher class so that subclasses are able to prune a\nstill in-progress path, not just a completed path.  This should be\nquite efficient even when the number of duplicates is very high,\nbecause the top N search will quickly push to the one not deleted, not\nfiltered out, highest scoring document with the suggestion, record\nthat surface form, and then prune subsequent intermediate paths\nsharing that same surface form.\n\nI also added another \"extreme\" dedup test case to test the logic that\ncomputes the necessary queue size, and it's passing, and the new\nTestSuggestField.testRandom seems to survive moderate beasting...\n\nI think it's ready. ",
            "author": "Michael McCandless"
        },
        {
            "id": "comment-15879224",
            "date": "2017-02-22T21:04:37+0000",
            "content": "Commit 4e2cf61ac76db33f35d3aceacaf1563a9bd5edb2 in lucene-solr's branch refs/heads/master from Mike McCandless\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=4e2cf61 ]\n\nLUCENE-7686: add efficient de-duping to the NRT document suggester ",
            "author": "ASF subversion and git services"
        },
        {
            "id": "comment-15879747",
            "date": "2017-02-23T02:31:39+0000",
            "content": "Commit 0d5a61b3df04593691796867ae3b32d05e66a0c0 in lucene-solr's branch refs/heads/branch_6x from Mike McCandless\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=0d5a61b ]\n\nLUCENE-7686: add efficient de-duping to the NRT document suggester ",
            "author": "ASF subversion and git services"
        },
        {
            "id": "comment-15880220",
            "date": "2017-02-23T10:13:24+0000",
            "content": "Thanks Mike! Was not able to test it, but looks good to me! ",
            "author": "Uwe Schindler"
        }
    ]
}