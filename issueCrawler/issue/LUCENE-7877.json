{
    "id": "LUCENE-7877",
    "title": "Replace PrefixAwareTokenStream",
    "details": {
        "labels": "",
        "priority": "Major",
        "resolution": "Fixed",
        "affect_versions": "None",
        "status": "Resolved",
        "type": "Improvement",
        "components": [],
        "fix_versions": [
            "7.0"
        ]
    },
    "description": "PrefixAwareTokenStream/PrefixAndSuffixAwareTokenStream use the deprecated and broken Token class, which means they will not work with custom attributes.  We should fix/replace them.",
    "attachments": {
        "LUCENE-7877.patch": "https://issues.apache.org/jira/secure/attachment/12872934/LUCENE-7877.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "id": "comment-16048785",
            "date": "2017-06-14T07:22:53+0000",
            "content": "Patch, implementing a ConcatenatingTokenStream that takes an arbitrary number of token streams and concatenates them together, modifying the OffsetAttribute so that they look as if they all came from a single source. ",
            "author": "Alan Woodward"
        },
        {
            "id": "comment-16051684",
            "date": "2017-06-16T09:41:55+0000",
            "content": "It looks good to me but I'm not as familiar with the TokenStream API is Uwe Schindler is.\n\n\tshould we only add OffsetAttribute to the concatenated stream if it can be found on the sources?\n\tshould we use a single copyTo call instead of captureState+restoreState on every token?\n\tcould you use IOUtils.close to close all sources at once so that we keep trying to close other sources if any of them throws an exception upon closing?\n\tthe patch does not remove PrefixAwareTokenFilter, did you just forget to git rm it?\n\n ",
            "author": "Adrien Grand"
        },
        {
            "id": "comment-16053118",
            "date": "2017-06-18T08:45:59+0000",
            "content": "To me this looks good, although I have not verified all corner cases like how attributes behave when switching streams. I have just some comments for minor improvements, also related to Adrien Grand's comments:\n\nshould we only add OffsetAttribute to the concatenated stream if it can be found on the sources?\n\nThis is a good idea, but I don't think its necessary for 2 reasons:\n\n\tTokenFilters don't do this, too (and this is more like a TokenFilter taking multiple inputs)\n\tThe OffsetAttribute is always available by default with the combined AttributeSource.\n\n\n\nshould we use a single copyTo call instead of captureState+restoreState on every token?\n\nYes! In addition captureState and restoreState depend on order of tokens and should not be used cross attributesources. So I'd call copyTo also in the combineSourcesCheck. This is more safe for TokenStreams that added attributes in different order.\n\ncould you use IOUtils.close to close all sources at once so that we keep trying to close other sources if any of them throws an exception upon closing?\n\nYes, TokenStream implements Closeable, so this shuld work. And super.close() should be in a finally block (although not so important).\n\nThere is something I'd like to change: I'd cache source's OffsetAttributes also in ctor in an offsetAttributes[] with same size like the sources[] array. I'd also use \"addAttribute\" because otherwise you may miss those from sources that add the attributes later (but those may break this stream anyways - we can't do anything against that!).\n\nFinally, I am not sure if we should expose the first constructor to the users (I'd make it private) or at least add some checks that the AttributeSources are in sync. Otherwise this one is likely to fail for people who don't know the Attribute internals. The \"combineSources\" static is the only way to create an attributesource. If you just want to mimic other Tokenizers that take an attributesource: This is wrong here, as this item is more like a TokenFilter: It has to take the attributes from input(s). I'd like to have combineSources throw a more user-friendly exception. So if anything breaks in combineSources, throw some IAE with a more usefull explanation (including the root cause). ",
            "author": "Uwe Schindler"
        },
        {
            "id": "comment-16054053",
            "date": "2017-06-19T14:06:53+0000",
            "content": "Here's an updated patch folding in comments. ",
            "author": "Alan Woodward"
        },
        {
            "id": "comment-16054221",
            "date": "2017-06-19T15:34:46+0000",
            "content": "I was curious what this thing was, since I hadn't noticed it before.  It appears to have been introduced with LUCENE-1320 ShingleMatrixFilter.  ShingleMatrixFilter is today nowhere to be found; it was removed in LUCENE-2920 by Uwe Schindler because, in his words, it was unmaintained and buggy.  I wonder if it's worthwhile to even have these Prefix-etc. token filters?  Any way I have no opinion but I wanted to share what I dug up. ",
            "author": "David Smiley"
        },
        {
            "id": "comment-16054344",
            "date": "2017-06-19T17:04:20+0000",
            "content": "Thanks David!\n\nSo we can seafely remove them!\nAnyways, a ConcatenatingTokenStream is a good thing to have - I had the problem of concatting TokenStreams for several times.! ",
            "author": "Uwe Schindler"
        },
        {
            "id": "comment-16054385",
            "date": "2017-06-19T17:19:44+0000",
            "content": "LOL yes a ConcatenatingTokenStream is something I've used twice already too.  Here's mine: https://github.com/OpenSextant/SolrTextTagger/blob/master/src/main/java/org/opensextant/solrtexttagger/ConcatenateFilter.java\nShall I contribute Uwe Schindler ? ",
            "author": "David Smiley"
        },
        {
            "id": "comment-16054421",
            "date": "2017-06-19T17:35:24+0000",
            "content": "David Smiley: Your stream does something different than the one on this issue as replacement for the PrefixAwareTokenStream. Our's appends different token streams so they appear as one. It is therefor not a filter is the opposite of TeeSink. ",
            "author": "Uwe Schindler"
        },
        {
            "id": "comment-16058979",
            "date": "2017-06-22T08:25:19+0000",
            "content": "Commit a948e1714609ef662184c71eedb219caf44fc037 in lucene-solr's branch refs/heads/master from Alan Woodward\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=a948e17 ]\n\nLUCENE-7877: Add ConcatenatingTokenStream, remove PrefixAwareTokenFilter ",
            "author": "ASF subversion and git services"
        },
        {
            "id": "comment-16058981",
            "date": "2017-06-22T08:26:08+0000",
            "content": "Thanks for the reviews, chaps. ",
            "author": "Alan Woodward"
        }
    ]
}