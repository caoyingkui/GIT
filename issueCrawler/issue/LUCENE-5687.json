{
    "id": "LUCENE-5687",
    "title": "Split off SinkTokenStream from TeeSinkTokenFilter (was add PrefillTokenStream ...)",
    "details": {
        "type": "Improvement",
        "priority": "Minor",
        "labels": "",
        "resolution": "Won't Fix",
        "components": [
            "modules/analysis"
        ],
        "affect_versions": "4.9",
        "status": "Closed",
        "fix_versions": [
            "4.9"
        ]
    },
    "description": "",
    "attachments": {
        "LUCENE-5687.patch": "https://issues.apache.org/jira/secure/attachment/12728494/LUCENE-5687.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "id": "comment-14002232",
            "author": "Paul Elschot",
            "content": "This is a token stream that can be prefilled by adding token states.\nIt is taken from the proposed label module, LUCENE-5627, the tests there also pass when using this.\nThe tests from the analysis common module also pass.\n\nThe code is at pull request https://github.com/apache/lucene-solr/pull/53 .\n\nThis makes PrefillTokenStream a superclass of TeeSinkTokenFilter.SinkTokenStream.\nThe existing code duplication with CachingTokenStream from the core module is left as it is. ",
            "date": "2014-05-19T19:45:41+0000"
        },
        {
            "id": "comment-14002244",
            "author": "ASF GitHub Bot",
            "content": "Github user PaulElschot commented on the pull request:\n\n    https://github.com/apache/lucene-solr/pull/53#issuecomment-43547808\n\n    The lucene issue for this is LUCENE-5687, https://issues.apache.org/jira/browse/LUCENE-5687 ",
            "date": "2014-05-19T19:50:32+0000"
        },
        {
            "id": "comment-14084062",
            "author": "Paul Elschot",
            "content": "This depends on LUCENE-5861 for the use of ArrayList instead of LinkedList to save the token attribute states. Currently a LinkedList is used here. ",
            "date": "2014-08-03T18:14:00+0000"
        },
        {
            "id": "comment-14514823",
            "author": "Paul Elschot",
            "content": "Patch of 27 April 2015, just closed the github pull request.\nThis uses ArrayList instead of LinkedList, see also LUCENE-5861.\nThis makes PrefillTokenStream a superclass of TeeSinkTokenFilter.SinkTokenStream, and adds a javadoc link to CachingTokenFilter from the core analysis package. ",
            "date": "2015-04-27T19:47:34+0000"
        },
        {
            "id": "comment-15094271",
            "author": "Paul Elschot",
            "content": "Patch of 12 Jan 2016.\nUpdated to trunk. ",
            "date": "2016-01-12T16:56:26+0000"
        },
        {
            "id": "comment-15102110",
            "author": "Michael McCandless",
            "content": "Is this similar to CannedTokenStream that we use for tests? ",
            "date": "2016-01-15T17:20:48+0000"
        },
        {
            "id": "comment-15102310",
            "author": "Paul Elschot",
            "content": "PrefillTokenStream is not really similar to CannedTokenStream because the number of token states to be stored is not known at construction time.\n\nIt turns out that PrefillTokenStream is almost the same as TeeSinkTokenFilter.SinkTokenStream, see upcoming patch of today. ",
            "date": "2016-01-15T19:04:52+0000"
        },
        {
            "id": "comment-15102314",
            "author": "Paul Elschot",
            "content": "Patch of 15 Jan 2015.\nThis uses the new States in TeeSinkTokenFilter, see LUCENE-6973.\n\nPerhaps this States should be a top level class in the sinks package, PrefillTokenStream now uses States from TeeSinkTokenFilter. ",
            "date": "2016-01-15T19:07:56+0000"
        },
        {
            "id": "comment-15102319",
            "author": "Paul Elschot",
            "content": "I left some whitespace diff in the patch, sorry. It's only in javadoc comments, so I'll leave it as it is. ",
            "date": "2016-01-15T19:10:55+0000"
        },
        {
            "id": "comment-15102389",
            "author": "Shai Erera",
            "content": "Paul Elschot, can you please clarify what does PrefillTokenStream do that TeeSinkTokenFilter doesn't? E.g., if you call TeeSinkTokenFilter.consumeAllTokens(), is that the same? Sorry, I didn't dig through your patch yet, but having recently cleaning up TeeSinkTokenFilter, I'd appreciate if you can summarize the differences between the two. ",
            "date": "2016-01-15T20:03:59+0000"
        },
        {
            "id": "comment-15102412",
            "author": "Paul Elschot",
            "content": "PrefillTokenStream is a target for splitting a stream, and for that one needs public addState().\nFor example to split inTokenStream over prefillstream1 and prefillstream2:\n\n\n    while (inTokenStream.incrementToken()) {\n\n      switch (tokenType(some input token attribute)) {\n\n      case TYPE1:\n        prefillstream1.addState(inTokenStream.captureState());\n        break;\n\n      case TYPE2:\n        prefillstream2.addState(inTokenStream.captureState());\n        break;\n      }\n    }\n\n ",
            "date": "2016-01-15T20:19:50+0000"
        },
        {
            "id": "comment-15102427",
            "author": "Paul Elschot",
            "content": "I hope that answered the question.\n\nIs there another way to do such a split with classes from analysis.sinks package? ",
            "date": "2016-01-15T20:31:49+0000"
        },
        {
            "id": "comment-15102993",
            "author": "Shai Erera",
            "content": "Can you try\n\n\nTeeSinkTokenFilter tee = new TeeSinkTokenFilter(source);\nTokenStream typeASink = new TypeTokenFilter(tee.newSinkTokenStream(), \"typeA\");\nTokenStream typeBSink = new TypeTokenFilter(tee.newSinkTokenStream(), \"typeB\");\n\n\n\nThe idea is that you create a TeeSinkTokenFilter to wrap the common source for tokens, and then wrap the sinks w/ an additional TokenFilter which will drop tokens. I suggest that you use a FilteringTokenFilter which also adjusts the PositionIncrementAttribute, something that I'm not sure if your PrefillTokenStream currently does. ",
            "date": "2016-01-16T05:15:59+0000"
        },
        {
            "id": "comment-15103119",
            "author": "Paul Elschot",
            "content": "I considered that, but it does not not really fit my use case.\nTeeSinkTokenFilter buffers its input token states and then the sinks use this buffer.\n\nWhat I need is token state buffers after the split, also because the input can come from another source like the XMLEventReader parser.\nIn the XML case the token state needs to be created after parsing, and this depends on the parser state.\n\nThe position increments indeed need care when doing such a split, see LUCENE-5627 for that.\n\nI am not really happy with the current patch. After LUCENE-6973 PrefillTokenStream is too similar to TeeSinkTokenFilter.SinkTokenStream, and it is now hardly more than a wrapper around the new States that provides public methods.\n\nHow about making States public, for example as TokenStates, instead of introducing PrefillTokenStream?\nThat would allow to reuse this token state buffer of TeeSinkTokenFilter after splitting.\n ",
            "date": "2016-01-16T11:17:50+0000"
        },
        {
            "id": "comment-15103741",
            "author": "Paul Elschot",
            "content": "Patch of 17 Jan 2016.\n\nSplit off SinkTokenStream and TokenStates from TeeSinkTokenFilter, so they can be reused elsewhere.\nThis also adds a close() method to TeeSinkTokenFilter and some javadocs  there.\n\nShould TeeSinkTokenFilter.incrementToken() be a final method? ",
            "date": "2016-01-17T14:08:33+0000"
        },
        {
            "id": "comment-15975486",
            "author": "Paul Elschot",
            "content": "Not enough interest ",
            "date": "2017-04-19T20:46:15+0000"
        }
    ]
}