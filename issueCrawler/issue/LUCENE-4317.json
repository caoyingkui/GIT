{
    "id": "LUCENE-4317",
    "title": "Field.java does not reuse its inlined Keyword-TokenStream",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [
            "core/index"
        ],
        "type": "Bug",
        "fix_versions": [
            "4.0",
            "6.0"
        ],
        "affect_versions": "4.0-BETA",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "Field.java contains a inlined Keyword-TokenStream. Unfortunately this one is recreated all the time, although one reuses the same Field instance. For NumericTokenStream Field.java reuses it, but the Keyword one not.\n\nWe should apply the same logic and lazy init the TokenStream with a setter for the String value and reset(). This would be looking identical to SetNumeric(xx).",
    "attachments": {
        "LUCENE-4317-2.patch": "https://issues.apache.org/jira/secure/attachment/12542016/LUCENE-4317-2.patch",
        "LUCENE-4317.patch": "https://issues.apache.org/jira/secure/attachment/12541733/LUCENE-4317.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2012-08-21T09:08:06+0000",
            "content": "Patch:\n\n\tStreamlines handling of NumericTokenStreanm and a new internal StringTokenStream. Previous code was not easy to read.\n\tReuse of both (of course, not accross field instances). This improves the performance of reused Field instances enormous, as creating a new TokenStream for each small String is heavy (2 LinkedHashMaps, addition of attributes,...)\n\n\n\nWe should maybe think about a solution how to \"cache\" the instances across several instances (like IndexWriter did in 3.x). I was thinking about a singleton Analyzer...\n\nFor now this patch helps a lot. ",
            "author": "Uwe Schindler",
            "id": "comment-13438547"
        },
        {
            "date": "2012-08-21T09:08:52+0000",
            "content": "This patch also fixes StringTokenStream to correctly clearAttributes()! It also adds end(). ",
            "author": "Uwe Schindler",
            "id": "comment-13438548"
        },
        {
            "date": "2012-08-21T09:22:10+0000",
            "content": "Thanks for tackling this Uwe.  \n\nWe should maybe think about a solution how to \"cache\" the instances across several instances (like IndexWriter did in 3.x)\n\nDo you mean also for NumericTokenStream? or just StringTokenStream? ",
            "author": "Chris Male",
            "id": "comment-13438554"
        },
        {
            "date": "2012-08-21T09:25:27+0000",
            "content": "Do you mean also for NumericTokenStream? or just StringTokenStream?\n\nBoth, of course. A plain Analyzer will not help, as it expects a Reader  And creating a StringReader for every String is also a bad idea.\n\nI was thinking about some Analyzer-Like CloseableThreadLocal, but the problem is, we can never close it. IndexWriter previously managed to close the ThreadLocal (for its StringTokenStream-like internal AS), but thats no longer possible here. ",
            "author": "Uwe Schindler",
            "id": "comment-13438555"
        },
        {
            "date": "2012-08-21T10:37:14+0000",
            "content": "\nWe should maybe think about a solution how to \"cache\" the instances across several instances (like IndexWriter did in 3.x). I was thinking about a singleton Analyzer...\n\nThis is really simple: remove StringField, use KeywordAnalyzer if you want that.\n\nNobody gets confused with the StringField^H^H^H^NOT_ANALYZED trap anymore (since passing their same Analyzer used at indexing time to QueryParser nets the same results), there are not two different \"incomplete\" declarations of the analysis chain (1. Field, 2. Analyzer) to manage, instead just Analyzer, and you get reuse/closing/etc. ",
            "author": "Robert Muir",
            "id": "comment-13438589"
        },
        {
            "date": "2012-08-21T10:59:01+0000",
            "content": "Yeah I agree with Robert, using KeywordAnalyzer instead of having StringField would be more consistent, reduce a lot of confusion, and give us reuse. ",
            "author": "Chris Male",
            "id": "comment-13438604"
        },
        {
            "date": "2012-08-21T11:35:36+0000",
            "content": "Do we agree to fix the current problem and think about that StringField removal later? I disagree here, but that's another problem. In addition, the \"Robert solution\" still does not solve the numeric problem of recreating NumericTokenStreams over an over.\n\nIs it ok to commit the attached patch and discuss afterwards? ",
            "author": "Uwe Schindler",
            "id": "comment-13438618"
        },
        {
            "date": "2012-08-21T11:47:23+0000",
            "content": "\nIn addition, the \"Robert solution\" still does not solve the numeric problem of recreating NumericTokenStreams over an over.\n\nIt could: the problem here is the same, that it uses a special tokenstream instead of being a normal one integrated into the Analyzer.\nif it was fixed in the same way, it could have better QP support etc out of box as well (e.g. numeric queries work by default or whatever). ",
            "author": "Robert Muir",
            "id": "comment-13438625"
        },
        {
            "date": "2012-08-21T11:50:35+0000",
            "content": "The problem with numeric is that they are no strings, so it different. So NumericTokenStream is a plain TokenStream and no Tokenizer.\n\nBut that does not answer my question in my last comment. ",
            "author": "Uwe Schindler",
            "id": "comment-13438626"
        },
        {
            "date": "2012-08-21T11:53:00+0000",
            "content": "I'm +1 to committing this as a first step improvement but we should definitely pursue these other suggestions as well. ",
            "author": "Chris Male",
            "id": "comment-13438627"
        },
        {
            "date": "2012-08-21T11:55:17+0000",
            "content": "\nThe problem with numeric is that they are no strings, so it different. So NumericTokenStream is a plain TokenStream and no Tokenizer.\n\nBut there is, at query time. it could be a tokenizer also with its setInt() etc methods for easy use at index time... just ideas. ",
            "author": "Robert Muir",
            "id": "comment-13438628"
        },
        {
            "date": "2012-08-21T11:58:03+0000",
            "content": "To come back to Robert: We can of course remove the whole FieldTypes stuff altogether and only do this in Analyzer (which is then somehow a schema replacement). But then Analyzer.tokenStream() should be able to take other data types than Reader. If this would be the case I would +1 all your suggestions, izt would also solve the stupid wrapping of Strings with StringReader (that would be needed with removal of StringField) \n\nBtw.: As Solr is working on Strings solely, Solr can include the numerics into analyzers (and they do), but this adds \"locale specific\" String to numeric translation to the Tokenizer (which solr adds). I dont want this as the data sources for numeric fields are in most cases no strings. ",
            "author": "Uwe Schindler",
            "id": "comment-13438630"
        },
        {
            "date": "2012-08-21T12:00:35+0000",
            "content": "But there is, at query time. it could be a tokenizer also with its setInt() etc methods for easy use at index time... just ideas.\n\nI dont care about QueryParser, because when you indexed a numeric field, you should create a Query on your own and not use this query parser, that corrumpts everything because of its syntax and whitespace handling. ",
            "author": "Uwe Schindler",
            "id": "comment-13438633"
        },
        {
            "date": "2012-08-21T12:09:01+0000",
            "content": "\nTo come back to Robert: We can of course remove the whole FieldTypes stuff altogether and only do this in Analyzer (which is then somehow a schema replacement). But then Analyzer.tokenStream() should be able to take other data types than Reader. If this would be the case I would +1 all your suggestions, izt would also solve the stupid wrapping of Strings with StringReader (that would be needed with removal of StringField) \n\nWell its sorta always been this way, we tell people to check and make sure they use same analysis at index and query time. But with the current situation if they use things like StringFields and QueryParser they follow our best practices and get bogus or no results, thats why I get frustrated (this NOT_ANALYZED confusion has come up on the ML many times)\n\nBy the way as far as taking other data types than reader, i have no idea, i certainly feel like if we want to take String we could just apply StringReader ourself by default (someone could override). The problem with taking something other than reader would be the existence of charfilters in the chain (as these work on only readers).\n\n\ndont care about QueryParser, because when you indexed a numeric field, you should create a Query on your own and not use this query parser, that corrumpts everything because of its syntax and whitespace handling.\n\nBut you added support for this to the flexible QP last summer as part of GSOC right (LUCENE-1768) ? so its possible with Lucene's syntax? I'm confused I guess. ",
            "author": "Robert Muir",
            "id": "comment-13438636"
        },
        {
            "date": "2012-08-21T12:09:58+0000",
            "content": "by the way, of course I am +1 to commit the patch on this issue. If someone is going through the trouble to reuse fields we should not be making mounds of tokenstreams. ",
            "author": "Robert Muir",
            "id": "comment-13438637"
        },
        {
            "date": "2012-08-21T12:12:14+0000",
            "content": "+1 to the current patch and separately debating how to handle the long-standing NOT_ANALYZED trap.\n\nI do think StringField serves an important purpose though (it sets DOCS_ONLY, turns of norms), in addition to not analyzing.  But I don't like that it has its own little analyzer/tokenstream inside: it would be much better to simply use KeywordAnalyzer.\n\nOr (crazy idea): maybe we could simply call on the analyzer (like we do for normal tokenized fields), but then insist what was returned is in fact from KeywordAnalyzer?  This would force users of StringField to use PFAW w/ this field mapping to KeywordAnalyzer.  It's rather... anal though.  And will be confusing to users who \"forget\" to use PFAW (but then this is a service to them: it points out that at query-time their analysis is wrong).  Advanced users are free to use Field directly if somehow this checking becomes a problem ... ",
            "author": "Michael McCandless",
            "id": "comment-13438639"
        },
        {
            "date": "2012-08-21T12:16:44+0000",
            "content": "Mike: Or (crazy idea): maybe we could simply call on the analyzer (like we do for normal tokenized fields), but then insist what was returned is in fact from KeywordAnalyzer? This would force users of StringField to use PFAW w/ this field mapping to KeywordAnalyzer. It's rather... anal though. And will be confusing to users who \"forget\" to use PFAW (but then this is a service to them: it points out that at query-time their analysis is wrong). Advanced users are free to use Field directly if somehow this checking becomes a problem ...\n\nI disagree with that, this is too much magic and does not help with numerics again \n\nRobert: i certainly feel like if we want to take String we could just apply StringReader ourself by default (someone could override).\n\n+1. Just another idea: The Analyzer can internally also reuse a ReuseableStringReader like IndexWriter did in 3.x.\n\nPlease lets discuss all this in a separate issue and maybe for 5.0. Now it is too late for that (in my opinion). ",
            "author": "Uwe Schindler",
            "id": "comment-13438644"
        },
        {
            "date": "2012-08-21T12:19:02+0000",
            "content": "I wanted to add: The StringTokenStream in Field.java has one good thing: It does not copy too often. The String is used directly to populate CTA. With KeywordAnalyzer you do crazy per-char loops for nothing. In general we should maybe also add new KeywordTokenizer(String), setString(String) for easy use. ",
            "author": "Uwe Schindler",
            "id": "comment-13438645"
        },
        {
            "date": "2012-08-21T12:48:25+0000",
            "content": "Committed trunk revision: 1375507\nCommitted 4.x revision: 1375508\n\nIf you have ideas how to solve the \"internal TokenStream\" issue, open a new issue and discuss it there. I have no much interesta as I am happy with the current design. This issue was just to improve the current situation, not change it completely. ",
            "author": "Uwe Schindler",
            "id": "comment-13438678"
        },
        {
            "date": "2012-08-22T19:05:13+0000",
            "content": "I reopen this one to fix a second reuse problem:\n\n\tIt does not reuse the StringReader like Lucene 3.x did. If you look at the source code of StringReader in JDK, you are afraid of all synchronization and cost of initialization. In Lucene 3.x we had ReuseableStringReader, I will revive that in Field.java\n\tAlso the AttributeSource keeps a hard reference to the String. It should free the String on close. The above ReusableStringReader does that.\n\n ",
            "author": "Uwe Schindler",
            "id": "comment-13439767"
        },
        {
            "date": "2012-08-22T19:09:24+0000",
            "content": "Patch. It refactors ReusableStringReader a bit and also adds support for read(), because thats heavy (new char[1] on every call). It removes useless read(char[]) instead as this is just delegation in Reader.java.\nI will create a small test to be 100% sure that it's correct and then commit. ",
            "author": "Uwe Schindler",
            "id": "comment-13439771"
        },
        {
            "date": "2012-08-22T19:21:28+0000",
            "content": "Looks good, but i think we only need to set s to null in close(), since Tokenizer.java closes the reader anyway. ",
            "author": "Robert Muir",
            "id": "comment-13439778"
        },
        {
            "date": "2012-08-22T20:01:00+0000",
            "content": "Patch with test added. Setting to null before or after close does not matter, as it will never NPE.\n\nI will commit soon! ",
            "author": "Uwe Schindler",
            "id": "comment-13439801"
        },
        {
            "date": "2012-08-22T22:04:57+0000",
            "content": "Committed trunk revision 1376261, 4.x revision 1376265 ",
            "author": "Uwe Schindler",
            "id": "comment-13439899"
        },
        {
            "date": "2013-05-10T10:33:02+0000",
            "content": "Closed after release. ",
            "author": "Uwe Schindler",
            "id": "comment-13653804"
        }
    ]
}