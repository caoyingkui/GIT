{
    "id": "SOLR-8479",
    "title": "Add JDBCStream for integration with external data sources",
    "details": {
        "components": [
            "SolrJ"
        ],
        "type": "New Feature",
        "labels": "",
        "fix_versions": [
            "6.0"
        ],
        "affect_versions": "None",
        "status": "Closed",
        "resolution": "Implemented",
        "priority": "Minor"
    },
    "description": "Given that the Streaming API can merge and join multiple incoming SolrStreams to perform complex operations on the resulting combined datasets I think it would be beneficial to also support incoming streams from other data sources. \n\nThe JDBCStream will provide a Streaming API interface to any data source which provides a JDBC driver.",
    "attachments": {
        "SOLR-8479.patch": "https://issues.apache.org/jira/secure/attachment/12780199/SOLR-8479.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2016-01-02T03:01:33+0000",
            "author": "Dennis Gove",
            "content": "This is a first pass at the JDBCStream. There are still open questions and unimplemented pieces but I'm putting this out there to start the conversation. No tests are included.\n\n1. Currently it's handling the loading of JDBC Driver classes by requiring the driver class be provided and will then call \n\nClass.forName(driverClassName);\n\n\nduring open(). I'm wondering if there's a better way to handle this, particularly if we can do the loading via config file handling. ",
            "id": "comment-15076424"
        },
        {
            "date": "2016-01-02T15:03:08+0000",
            "author": "Joel Bernstein",
            "content": "+1\n\nSome great possibilities here. One I really like is combining it with the UpdateStream:\n\n\nupdate(jdbc(\"select ...\")) \n\n\n\nA simple way to populate a SolrCloud collection from a JDBC compliant data store. Since many NoSQL engines now support SQL we'll be able to pull data from places like Spark, Couchbase and any RDBMS.  ",
            "id": "comment-15076532"
        },
        {
            "date": "2016-01-02T20:26:58+0000",
            "author": "Dennis Gove",
            "content": "Adds some simple tests for the raw stream and as embedded inside a SelectStream and MergeStream where it is being merged with a CloudSolrStream. \n\nThe tests are using the in-memory database hsqldb with driver \"org.hsqldb.jdbcDriver\". I chose this as it's already being used in a contrib module. I'm open to other options as I'm not a huge fan of this particular in-memory database.\n\nStill doesn't implement Expressible interface (next on my list).  ",
            "id": "comment-15076655"
        },
        {
            "date": "2016-01-02T21:05:49+0000",
            "author": "Joel Bernstein",
            "content": "You could also use Solr's JDBC driver.\n ",
            "id": "comment-15076665"
        },
        {
            "date": "2016-01-02T21:08:27+0000",
            "author": "Joel Bernstein",
            "content": "\n    String zkHost = zkServer.getZkAddress();\n    Properties props = new Properties();\n    Connection con = DriverManager.getConnection(\"jdbc:solr://\" + zkHost + \"?collection=collection1\", props);\n    Statement stmt = con.createStatement();\n    ResultSet rs = stmt.executeQuery(\"select id, a_i, a_s, a_f from collection1 order by a_i desc limit 2\");\n\n\n ",
            "id": "comment-15076667"
        },
        {
            "date": "2016-01-02T21:08:41+0000",
            "author": "Dennis Gove",
            "content": "I considered that but I wanted to be sure the test covered non-Solr code bases. I think there's value in showing that a non-Solr external source can be used and functions as expected. ",
            "id": "comment-15076668"
        },
        {
            "date": "2016-01-02T22:19:54+0000",
            "author": "Joel Bernstein",
            "content": "We can probably just make the driver class name optional. If the parameter is present then call Class.forName(). If it's not then just skip this step.  ",
            "id": "comment-15076690"
        },
        {
            "date": "2016-01-04T21:30:07+0000",
            "author": "Dennis Gove",
            "content": "New patch with a few changes.\n\n1. Added some new tests\n2. Made driverClassName an optional property. if provided then we will call Class.forName(driverClassName); during open(). Also added a call to DriverManager.getDriver(connectionUrl) during open() to validate that the driver can be found. If not then an exception is thrown. This will prevent us from continuing if the jdbc driver is not loaded.\n3. Changed the default handling types so that Double is handled as a direct class while Float is converted to a Doube. This keeps in line with the rest of the Streaming API.  ",
            "id": "comment-15081838"
        },
        {
            "date": "2016-01-04T21:34:01+0000",
            "author": "Dennis Gove",
            "content": "Previous patch was a diff between the wrong hashes in the repo. This one is correct. ",
            "id": "comment-15081845"
        },
        {
            "date": "2016-01-04T21:46:25+0000",
            "author": "Dennis Gove",
            "content": "I intend to add a few more tests for failure scenarios and for setting connection properties. Barring any issues found with that, I think this will be ready to go . ",
            "id": "comment-15081873"
        },
        {
            "date": "2016-01-08T02:14:53+0000",
            "author": "Dennis Gove",
            "content": "Enhanced tests to include one which sets properties on the connection. Rebased against trunk. ",
            "id": "comment-15088588"
        },
        {
            "date": "2016-01-08T02:15:48+0000",
            "author": "Dennis Gove",
            "content": "This is ready to go. I intend to commit to trunk either tonight or tomorrow. ",
            "id": "comment-15088589"
        },
        {
            "date": "2016-01-08T15:56:34+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1723749 from dpgove@apache.org in branch 'dev/trunk'\n[ https://svn.apache.org/r1723749 ]\n\nOLR-8479: Add JDBCStream to Streaming API and Streaming Expressions for integration with external data sources\nSOLR-8479: Add JDBCStream to Streaming API and Streaming Expressions for integration with external data sources ",
            "id": "comment-15089397"
        },
        {
            "date": "2016-01-08T16:00:40+0000",
            "author": "Jason Gerlowski",
            "content": "This looks awesome.\n\nOnly comment would be that we might regret not having a test chaining JDBCStream and UpdateStream together.\n\nAs Joel mentioned, one of the interesting possibilities here is quick data-import using those two streams.  Just thought it might be nice to have a test to catch any future regressions there.\n\nMaybe it's not worth it though, or adding tests should be pushed to a different JIRA (since it looks like you're already working on committing this, and I'm commenting at the 11th hour here).\n\nOops, looks like I'm too late here.  Nevermind then : ) ",
            "id": "comment-15089404"
        },
        {
            "date": "2016-01-08T16:03:14+0000",
            "author": "Dennis Gove",
            "content": "I think a test like that is a great idea. I'll add it at some point in the future (perhaps under the guise of cleaning up our tests which was mentioned in the UpdateStream ticket). ",
            "id": "comment-15089412"
        },
        {
            "date": "2016-01-08T16:44:48+0000",
            "author": "Joel Bernstein",
            "content": "This is a great ticket!\n\nOne thing we can think about doing in the future is handling the defined sort differently. Possibly parsing it from the SQL statement.\n\nOne of the cool things about this is it allows you to distribute a SQL database as well. For example you could send the same query to multiple SQL servers then stream it all back together. ",
            "id": "comment-15089484"
        }
    ]
}