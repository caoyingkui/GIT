{
    "id": "SOLR-7377",
    "title": "SOLR Streaming Expressions",
    "details": {
        "components": [
            "clients - java"
        ],
        "type": "Improvement",
        "labels": "",
        "fix_versions": [
            "5.2",
            "6.0"
        ],
        "affect_versions": "None",
        "status": "Closed",
        "resolution": "Fixed",
        "priority": "Minor"
    },
    "description": "It would be beneficial to add an expression-based interface to Streaming API described in SOLR-7082. Right now that API requires streaming requests to come in from clients as serialized bytecode of the streaming classes. The suggestion here is to support string expressions which describe the streaming operations the client wishes to perform. \n\n\nsearch(collection1, q=*:*, fl=\"id,fieldA,fieldB\", sort=\"fieldA asc\")\n\n\n\nWith this syntax in mind, one can now express arbitrarily complex stream queries with a single string.\n\n\n// merge two distinct searches together on common fields\nmerge(\n  search(collection1, q=\"id:(0 3 4)\", fl=\"id,a_s,a_i,a_f\", sort=\"a_f asc, a_s asc\"),\n  search(collection2, q=\"id:(1 2)\", fl=\"id,a_s,a_i,a_f\", sort=\"a_f asc, a_s asc\"),\n  on=\"a_f asc, a_s asc\")\n\n// find top 20 unique records of a search\ntop(\n  n=20,\n  unique(\n    search(collection1, q=*:*, fl=\"id,a_s,a_i,a_f\", sort=\"a_f desc\"),\n    over=\"a_f desc\"),\n  sort=\"a_f desc\")\n\n\n\nThe syntax would support\n1. Configurable expression names (eg. via solrconfig.xml one can map \"unique\" to a class implementing a Unique stream class) This allows users to build their own streams and use as they wish.\n2. Named parameters (of both simple and expression types)\n3. Unnamed, type-matched parameters (to support requiring N streams as arguments to another stream)\n4. Positional parameters\n\nThe main goal here is to make streaming as accessible as possible and define a syntax for running complex queries across large distributed systems.",
    "attachments": {
        "SOLR-7377.patch": "https://issues.apache.org/jira/secure/attachment/12727774/SOLR-7377.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2015-04-10T19:53:47+0000",
            "author": "Dennis Gove",
            "content": "First-pass patch. Looking for initial feedback. ",
            "id": "comment-14490257"
        },
        {
            "date": "2015-04-10T22:14:58+0000",
            "author": "Joel Bernstein",
            "content": "All I can say is awesome! \n\nJust updated the description to reference SOLR-7082. ",
            "id": "comment-14490451"
        },
        {
            "date": "2015-04-20T16:46:17+0000",
            "author": "Dennis Gove",
            "content": "Updated the patch based on some additional items I wanted to include in this. Note that this patch adds a dependency on guava in the solr/solrj/ivy.xml file. We may want to revisit this additional dependency. Guava is being used for some basic string checks (to ensure operations only include supported characters) and this logic could be coded up if we want to avoid added a dependency.\n\n\n<dependency org=\"com.google.guava\" name=\"guava\" rev=\"${/com.google.guava/guava}\" conf=\"compile\"/>\n\n ",
            "id": "comment-14503160"
        },
        {
            "date": "2015-04-21T11:32:15+0000",
            "author": "Dennis Gove",
            "content": "Now allows a search expression to include a zkHost (though does not require it). Improved performance of EqualToComparator by moving some branching logic into the constructor and creating a lambda for the actual comparison. ",
            "id": "comment-14504800"
        },
        {
            "date": "2015-04-24T00:44:47+0000",
            "author": "Dennis Gove",
            "content": "Added ability to turn an ExpressibleStream into a StreamExpression. Combined with the already existing ability to turn a StreamExpression into a string, we can now go back and forth from string <--> stream.\n\nThis will allow us to modify ParallelStream to pass along the string expression of the stream it wants to parallelize. ",
            "id": "comment-14510157"
        },
        {
            "date": "2015-04-24T01:11:09+0000",
            "author": "Erick Erickson",
            "content": "Dennis:\n\nThat patch seems to remove and then re-add a bunch of files. It's 263K in length, did something go weird with generating the diff? Or did you move a bunch of files around or something? Or am I mis-reading it entirely?\n\nThe streaming stuff is cool you gotta admit, thanks for your work here!\n\nI'm a little confused. There is only one patch from just a few minutes ago. But from the comments, maybe you uploaded your original patch on 10-Apr? If that's the case, I'm guessing you deleted old your old patch when you put this one up. There's no need to do that, just keep re-uploading the patch with the same name. That'll keep all the copies with the older ones grayed out, and it's preferred to do it that way so history is preserved. My question about the size of hte patch is a case in point . ",
            "id": "comment-14510198"
        },
        {
            "date": "2015-04-24T01:17:21+0000",
            "author": "Dennis Gove",
            "content": "Well that makes it much clearer for me. I'm sorry for deleting all the older patches. In my reading of the \"How to Contribute\" I was under the impression that uploading a new patch (with same name) would just replace the old one. Each time I uploaded a new version I would see the previous one still there and figured I'd done something wrong so went ahead and deleted the old version. It didn't occur to me that the old versions would still stay there but just be greyed out. I won't be deleting the old versions going forward. Thanks for clearing that up for me!\n\nThe size of the patch is a function of a bit of package refactoring in the org.apache.solr.client.solrj.io package. This seems to be resulting in the diff showing a bunch of deleted/added files. ",
            "id": "comment-14510208"
        },
        {
            "date": "2015-04-24T02:03:13+0000",
            "author": "Erick Erickson",
            "content": "No apology necessary, just figured you might be confused by something about \"how we do things around here\" ... I'll see what I can to to clarify the \"How to Contribute\" page.\n\nAnd thanks for letting me know about the refactoring, just wanted to be sure that things were as you expected. ",
            "id": "comment-14510342"
        },
        {
            "date": "2015-04-24T22:26:51+0000",
            "author": "Joel Bernstein",
            "content": "Was reviewing the new Comparator package. Curious about the name EqualToComparator. This makes it sound like it's only used to determine equality. But it's also being used in certain situations to determine sort order. Since an equality comparator makes sense in certain situations, like with the ReducerStream, does it make sense to have two Comparator implementations?  ",
            "id": "comment-14511911"
        },
        {
            "date": "2015-04-25T01:36:47+0000",
            "author": "Dennis Gove",
            "content": "I was thinking that all comparators, no matter their implemented comparison logic, return one of three basic values when comparing A and B. \n\n1. A and B are logically equal to each other\n2. A is logically before B\n3. A is logically after B\n\nThe implemented comparison logic is then wholly dependent on what one might be intending to use the comparator for. For example, EqualToComparator's implemented comparison logic will return that A and B are logically equal if they are in fact equal to each other. Its logically before/after response depends on the sort order (ascending or descending) but is basically deciding if A is less than B or if A is greater than B.\n\nOne could, if they wanted to, create a comparator returning that two dates are logically equal to each other if they occur within the same week. Or a comparator returning that two numbers are logically equal if their values are within the same logarithmic order of magnitude. So on and so forth.\n\nMy thinking is that comparators determine the logical comparison and make no assumption on what that implemented logic is. This leaves open the possibility of implementing other comparators for given situations as they arise. ",
            "id": "comment-14512165"
        },
        {
            "date": "2015-04-25T04:41:43+0000",
            "author": "Joel Bernstein",
            "content": "Ok, I see what you're getting at.\n\nI'd been considering a variation on comparators that just determine equality. This is because some of the stream implementations like the UniqueStream and ReducerStream only need a way to determine Tuple equality. So I had already done a little research and turned up this:\n\nhttp://www.learnabout-electronics.org/Digital/dig43.php\n\nYou'll see a section on Equality Comparators.\n\nSo, I'm thinking a simpler name like FieldComp would do the trick.\n\nNo need to change just yet. Feel free to finish up the patch using the EqualToComparator. Before we do the commit we'll go through and finalize the names.\n\n\n\n ",
            "id": "comment-14512247"
        },
        {
            "date": "2015-04-26T00:28:22+0000",
            "author": "Dennis Gove",
            "content": "Made ParallelStream an ExpressibleStream and modified the StreamHandler to accept stream expression strings instead of bytecode.\n\nRefactored operation and operand into functionName and parameter. And refactored all required references and tangentially related variable/class names.\n\nRenamed EqualToComparator to FieldComparator to be a little more descriptive in the name.\n\nAdded ability to support pluggable streams by making it something you can configure in solrconfig.xml.\n\nAll stream-related tests pass. At this point I'd consider this functionally complete.  ",
            "id": "comment-14512791"
        },
        {
            "date": "2015-04-27T19:56:56+0000",
            "author": "Joel Bernstein",
            "content": "Dennis,\n\nThanks for this awesome piece of work. I should have a chance to review over the next couple days.  ",
            "id": "comment-14514846"
        },
        {
            "date": "2015-04-28T12:28:18+0000",
            "author": "Dennis Gove",
            "content": "Fixed a bug in CloudSolrStream when handling aliases. When filtering out the stream-only parameters from those that need to be passed to SOLR for query I was checking for parameter name \"alias\" when I should have been checking for \"aliases\". ",
            "id": "comment-14516954"
        },
        {
            "date": "2015-04-29T17:33:15+0000",
            "author": "Joel Bernstein",
            "content": "New patch is an svn diff that handles all the moving around of files in svn.  ",
            "id": "comment-14519783"
        },
        {
            "date": "2015-04-30T14:50:58+0000",
            "author": "Noble Paul",
            "content": "The patch is mostly moving files from one package to another. Is it possible to get  a patch that just adds the new functionality and do the package change later?  ",
            "id": "comment-14521601"
        },
        {
            "date": "2015-04-30T23:05:15+0000",
            "author": "Dennis Gove",
            "content": "I'm not totally against doing that but I feel like the refactoring is a required piece of this patch. I could, however, create a new ticket with just the refactoring and then make this one depend on that one. \n\nI am worried that such a ticket might look like unnecessary refactoring. Without the expression stuff added here I think the streaming stuff has a reasonable home in org.apache.solr.client.solrj.io.\n\nThat said, I certainly understand the benefit of smaller patches. ",
            "id": "comment-14522439"
        },
        {
            "date": "2015-04-30T23:53:11+0000",
            "author": "Joel Bernstein",
            "content": "This patch also changes every single class in the package. So even if we do a separate ticket for the package move we'll still have a patch with fairly significant changes to all the classes.\n\nI think the best way to review the ticket is probably to apply the patch and then look at the overall package. ",
            "id": "comment-14522509"
        },
        {
            "date": "2015-05-01T11:47:14+0000",
            "author": "Joel Bernstein",
            "content": "This patch looks really good. I'm planning on making only three changes:\n\n1) Allowing the ParallelStream to either use object serialization or Streaming Expressions as a transport mechanism. There will be use cases where people will want to use the Streaming API directly and not bother with Streaming Expressions constructs.  \n\n2) Add some tests for StreamingExpressions that use the ParallelStream.\n\n3) Add an ExpressionRunner that runs expressions from the command line. The initial version of this will only support built-in expressions. We should decide if we want to break out the name-to-class mapping in an external properties file so it can be used both by Solr and the ExpressionRunner. ",
            "id": "comment-14523097"
        },
        {
            "date": "2015-05-01T14:17:38+0000",
            "author": "Yonik Seeley",
            "content": "3) Add an ExpressionRunner that runs expressions from the command line.\n\nCan you expand on this some?  Our \"command line\" in the past has essentially been \"curl\", so I'm wondering what's different here that would make a command line tool specific to expressions make sense. ",
            "id": "comment-14523237"
        },
        {
            "date": "2015-05-01T14:58:45+0000",
            "author": "Joel Bernstein",
            "content": "I was thinking about having a local client (ExpressionRunner) that could run the expression and be used as part of a unix pipeline. \n\nAlso a local client can save a hop in the case of a parallel stream. The local client can directly push the Expression to the workers nodes.  ",
            "id": "comment-14523284"
        },
        {
            "date": "2015-05-01T15:21:35+0000",
            "author": "Joel Bernstein",
            "content": "The main use case that I have in mind for the unix pipeline is piping data from a Streaming Expression to R.\n\nBut there could be all kinds of fun stuff that could be cooked up with piping Streaming Expression output. ",
            "id": "comment-14523320"
        },
        {
            "date": "2015-05-02T16:24:25+0000",
            "author": "Joel Bernstein",
            "content": "New patch with the following changes:\n\n1) ParallelStream can use either Object serialization or streaming expressions as a transport mechanism. When the ParalleStream is created using a StreamingExpression it defaults to streaming expression transport. When it's created through the Streaming API it defaults to Object serialization.\n\n2) Added parallel tests for merge, unique, group, and top functions. Sample syntax:\n\n    parallel(collection1, \n                merge(\n                            search(collection1, q=\"id:(4 1 8 9)\", fl=\"id,a_s,a_i\", sort=\"a_i desc\", partitionKeys=\"a_i\"), \n                            search(collection1, q=\"id:(0 2 3 6)\", fl=\"id,a_s,a_i\", sort=\"a_i desc\", partitionKeys=\"a_i\"), \n                            on=\"a_i desc\"), \n                workers=\"2\", \n                sort=\"a_i desc\")\n\n\n\n\n3) Added the ExpressionRunner class, still needs tests. ",
            "id": "comment-14525333"
        },
        {
            "date": "2015-05-02T17:14:55+0000",
            "author": "Dennis Gove",
            "content": "I don't see the ExpressionRunner in the patch - am I missing it somewhere? Also, I noticed ParallelStream lines 94-100 have some System.out.println lines. I suspect you intended to remove those.\n\nTests look good. ",
            "id": "comment-14525364"
        },
        {
            "date": "2015-05-02T17:17:47+0000",
            "author": "Joel Bernstein",
            "content": "Forgot to add the class. Just put up a new patch with the ExpressionRunner. ",
            "id": "comment-14525367"
        },
        {
            "date": "2015-05-04T21:37:17+0000",
            "author": "Joel Bernstein",
            "content": "New patch without the ExressionRunner. While doing manual testing I found that it's simpler just to send an expression to Solr's /stream handler, as Yonik had mentioned. I think the idea of having a command line tool to use with unix pipes still make sense but it can be a ticket unto itself.\n\nAlso made some changes based on the manual testing. For example including the ParallelStream in the default streams known by the StreamHandler. ",
            "id": "comment-14527364"
        },
        {
            "date": "2015-05-05T10:24:36+0000",
            "author": "Dennis Gove",
            "content": "This looks good, I think. ",
            "id": "comment-14528228"
        },
        {
            "date": "2015-05-05T12:01:22+0000",
            "author": "Joel Bernstein",
            "content": "New patch with all tests passing. The main fix is that the StreamHandler.inform method was throwing NPE on non-SolrCloud setups. Once this was fixed all tests passed.\n ",
            "id": "comment-14528332"
        },
        {
            "date": "2015-05-05T12:03:15+0000",
            "author": "Joel Bernstein",
            "content": "I'll take a look at swapping out the guava code today. I was thinking of either using a Regex or the StreamTokenizer to validate the chars. ",
            "id": "comment-14528334"
        },
        {
            "date": "2015-05-05T12:07:53+0000",
            "author": "Dennis Gove",
            "content": "I believe I've found a bug in FieldComparator. I don't have time to create a new patch right now, but the bug is not checking for null on the field before calling compare. Fixed version is below\n\n\n  private void assignComparator(){\n    if(ComparatorOrder.DESCENDING == order){\n      // What black magic is this type intersection??\n      // Because this class is serializable we need to make sure the lambda is also serializable.\n      // This can be done by providing this type intersection on the definition of the lambda.\n      // Why not do it in the lambda interface? Functional Interfaces don't allow extends clauses\n      comparator = (ComparatorLambda & Serializable)(leftTuple, rightTuple) -> {\n        Comparable leftComp = (Comparable)leftTuple.get(leftField);        \n        Comparable rightComp = (Comparable)rightTuple.get(rightField);\n        \n        if(null == leftComp){ return -1; }\n        if(null == rightComp){ return 1; }\n        \n        return rightComp.compareTo(leftComp);\n      };\n    }\n    else{\n      // See above for black magic reasoning.\n      comparator = (ComparatorLambda & Serializable)(leftTuple, rightTuple) -> {\n        Comparable leftComp = (Comparable)leftTuple.get(leftField);\n        Comparable rightComp = (Comparable)rightTuple.get(rightField);\n        \n        if(null == leftComp){ return -1; }\n        if(null == rightComp){ return 1; }\n        \n        return leftComp.compareTo(rightComp);\n      };\n    }\n  }\n\n ",
            "id": "comment-14528339"
        },
        {
            "date": "2015-05-05T12:14:55+0000",
            "author": "Joel Bernstein",
            "content": "I'll incorporate this in the next patch. ",
            "id": "comment-14528352"
        },
        {
            "date": "2015-05-05T18:35:17+0000",
            "author": "Yonik Seeley",
            "content": "Should two nulls compare equal?\n\n        if(null == leftComp){ return rightComp==null ? 0 : -1 }\n        if(null == rightComp){ return 1; }\n\n\nOR\n\n        if (leftComp == rightComp) return 0;\n        if(null == leftComp){ return -1; }\n        if(null == rightComp){ return 1; }\n\n ",
            "id": "comment-14529015"
        },
        {
            "date": "2015-05-05T20:24:37+0000",
            "author": "Dennis Gove",
            "content": "We may want to make that configurable in solrconfig.xml. Also, should this respect the already configurable setting of whether nulls propagate to the start or end of result sets? ",
            "id": "comment-14529210"
        },
        {
            "date": "2015-05-05T20:36:33+0000",
            "author": "Yonik Seeley",
            "content": "We may want to make that configurable in solrconfig.xml.\n\nIf it makes sense to have it more than one way (I don't know that it does... just supposing), then it makes sense that some requests would want it one way and other requests would want it the other way.  Hence it should be something that one could somehow specify in a request, and not something that one would configure. ",
            "id": "comment-14529226"
        },
        {
            "date": "2015-05-05T20:43:58+0000",
            "author": "Dennis Gove",
            "content": "I do agree with you that two nulls should compare equal (I should've included that in my original fix), but I have seen a number of situations where users have balked at the decision (outside of solr). \n\nThat said, I think it's reasonable to insist that two nulls evaluate to equal. (I've never agreed with the case that they wouldn't). \n\nWere we to make it a user-overridable thing then I do like the idea to make it a query-time decision. ",
            "id": "comment-14529233"
        },
        {
            "date": "2015-05-05T21:04:37+0000",
            "author": "Joel Bernstein",
            "content": "New patch with two changes:\n\n1) The StreamHandler was getting a null value from the call to ZkController.getBaseUrl() which was causing a null pointer if the zkHost was not provided in the expression. I resolved this by calling zkController.getZkServerAddress() instead.\n\n2) Removed the dependency on guava, by adding the static StreamExpressionParser.wordToken method.  ",
            "id": "comment-14529268"
        },
        {
            "date": "2015-05-05T21:07:26+0000",
            "author": "Joel Bernstein",
            "content": "I'd like to move the null handling to another ticket. There are other issue's here with how the SortingResponseWriter handles nulls, that should be tackled at the same time. \n\nFor this release we can require default values.\n\n ",
            "id": "comment-14529274"
        },
        {
            "date": "2015-05-06T18:30:27+0000",
            "author": "Joel Bernstein",
            "content": "New patch with precommit passing. ",
            "id": "comment-14531131"
        },
        {
            "date": "2015-05-08T00:11:58+0000",
            "author": "Dennis Gove",
            "content": "Updated patch with a few changes.\n\nFieldComparator and StreamComparator have been collapsed into a single class StreamComparator. There was no need for a separate abstract class.\n\nAdded null checks in StreamComparator. For now if both are null then they will evaluate to equal. We can add a later enhancement under a new ticket to make that configurable.\n\nInterfaces ExpressibleStream and ExpressibleComparator have been collapsed into interface Expressible. They defined the same interface and there's no reason to have separate interfaces for them.\n\nPasses precommit checks. ",
            "id": "comment-14533649"
        },
        {
            "date": "2015-05-08T12:30:34+0000",
            "author": "Joel Bernstein",
            "content": "I believe we are a little out of sync on the patches. My last patch has the guava dependency removed and I see it back in with Dennis's latest patch. \n\nI think the best thing to do is to get this committed to trunk so we can start working with smaller patches. \n\nMy plan is to do some more manual testing, and then commit to trunk in a day or two.  ",
            "id": "comment-14534426"
        },
        {
            "date": "2015-05-08T12:40:06+0000",
            "author": "Dennis Gove",
            "content": "I can't figure out how I screwed that up - my only thought is that when I pulled down your latest with curl it failed and I didn't notice. Internet access on Amtrak trains can be splotchy. My apologies, I'll be more careful in the future. Let's forget my latest patch - I'll add those in a new smaller one after this is in trunk ",
            "id": "comment-14534432"
        },
        {
            "date": "2015-05-08T12:45:59+0000",
            "author": "Joel Bernstein",
            "content": "No worries. It's a big piece of work. We'll refine it more after it lands in trunk. ",
            "id": "comment-14534439"
        },
        {
            "date": "2015-05-11T12:37:21+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1678743 from Joel Bernstein in branch 'dev/trunk'\n[ https://svn.apache.org/r1678743 ]\n\nSOLR-7377: Streaming Expressions ",
            "id": "comment-14537885"
        },
        {
            "date": "2015-05-14T14:10:35+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1679376 from Joel Bernstein in branch 'dev/trunk'\n[ https://svn.apache.org/r1679376 ]\n\nSOLR-7377,SOLR-7524:Make Streaming Expressions Java 7 Compatible ",
            "id": "comment-14543704"
        },
        {
            "date": "2015-05-14T17:11:40+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1679407 from Joel Bernstein in branch 'dev/branches/branch_5x'\n[ https://svn.apache.org/r1679407 ]\n\nSOLR-7377,SOLR-7524:Make Streaming Expressions Java 7 Compatible ",
            "id": "comment-14544038"
        },
        {
            "date": "2015-05-15T15:54:55+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1679599 from Joel Bernstein in branch 'dev/trunk'\n[ https://svn.apache.org/r1679599 ]\n\nSOLR-7377: Update CHANGES.txt ",
            "id": "comment-14545695"
        },
        {
            "date": "2015-05-15T15:57:54+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1679600 from Joel Bernstein in branch 'dev/branches/branch_5x'\n[ https://svn.apache.org/r1679600 ]\n\nSOLR-7377: Update CHANGES.txt ",
            "id": "comment-14545701"
        },
        {
            "date": "2015-08-07T11:16:19+0000",
            "author": "Shalin Shekhar Mangar",
            "content": "Any specific reason why this uses Java serialization? That's a horrible choice for a high-performance streaming framework. Can we switch to javabin? ",
            "id": "comment-14661666"
        },
        {
            "date": "2015-08-07T11:33:28+0000",
            "author": "Joel Bernstein",
            "content": "The Streaming API has three transport mechanisms:\n\n1) Data is transported with JSON.\n2) The ParallelStream originally pushed bytecode out to worker nodes in parallel operations using Java serialization. This was only executable streaming code being pushed to worker nodes.\n3) Streaming Expressions provides a concise syntax for the ParallelStream to push streaming code to worker nodes. This ticket adds that functionality. It's extremely efficient. \n ",
            "id": "comment-14661688"
        },
        {
            "date": "2015-08-07T11:43:21+0000",
            "author": "Joel Bernstein",
            "content": "One of cool things about Streaming Expressions is that provides a high performance way to push operations to worker nodes ...\n\nAND\n\nIt's a query language that can be used on it's own.\n\nStreaming Expressions can model any operation that be done with the Streaming API.\n\nThe new parallel SQL interface, compiles SQL statements to Streaming API objects. Those object are then serialized to Streaming Expressions and sent to worker nodes to handle the map/reduce aggregations in parallel.\n\n\n ",
            "id": "comment-14661700"
        },
        {
            "date": "2015-08-07T11:48:05+0000",
            "author": "Noble Paul",
            "content": "You may use javabin for  more efficient faster streaming ",
            "id": "comment-14661708"
        },
        {
            "date": "2015-08-07T11:58:26+0000",
            "author": "Joel Bernstein",
            "content": "Streaming data with JSON was just the first step to get everything working.\n\nWhen we start optimizing, we can add faster transport mechanisms. ",
            "id": "comment-14661723"
        },
        {
            "date": "2015-08-07T12:16:37+0000",
            "author": "Joel Bernstein",
            "content": "To get a basic understanding of how the Streaming API, Streaming Expressions and Parallel SQL come together take a look at the \n\nthe doGroupByWithAggregates method in:\n\nhttps://svn.apache.org/viewvc/lucene/dev/trunk/solr/core/src/java/org/apache/solr/handler/SQLHandler.java ",
            "id": "comment-14661738"
        }
    ]
}