{
    "id": "LUCENE-6276",
    "title": "Add matchCost() api to TwoPhaseDocIdSetIterator",
    "details": {
        "resolution": "Fixed",
        "affect_versions": "None",
        "components": [],
        "labels": "",
        "fix_versions": [
            "5.4",
            "6.0"
        ],
        "priority": "Major",
        "status": "Closed",
        "type": "Improvement"
    },
    "description": "We could add a method like TwoPhaseDISI.matchCost() defined as something like estimate of nanoseconds or similar. \n\nConjunctionScorer could use this method to sort its 'twoPhaseIterators' array so that cheaper ones are called first. Today it has no idea if one scorer is a simple phrase scorer on a short field vs another that might do some geo calculation or more expensive stuff.\n\nPhraseScorers could implement this based on index statistics (e.g. totalTermFreq/maxDoc)",
    "attachments": {
        "LUCENE-6276.patch": "https://issues.apache.org/jira/secure/attachment/12766640/LUCENE-6276.patch",
        "LUCENE-6276-ExactPhraseOnly.patch": "https://issues.apache.org/jira/secure/attachment/12766041/LUCENE-6276-ExactPhraseOnly.patch",
        "LUCENE-6276-NoSpans.patch": "https://issues.apache.org/jira/secure/attachment/12766185/LUCENE-6276-NoSpans.patch",
        "LUCENE-6276-NoSpans2.patch": "https://issues.apache.org/jira/secure/attachment/12766405/LUCENE-6276-NoSpans2.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "id": "comment-14330343",
            "author": "Adrien Grand",
            "date": "2015-02-21T16:47:51+0000",
            "content": "I like the idea. I'm curious if you already have concrete ideas for the match costs of our existing queries? Maybe it should not only measure the cost of the operation but also how likely it is to match? This would make sloppy phrases more \"costly\" since they are more lenient about positions and thus more likely to match. "
        },
        {
            "id": "comment-14330411",
            "author": "Robert Muir",
            "date": "2015-02-21T19:54:45+0000",
            "content": "\nI'm curious if you already have concrete ideas for the match costs of our existing queries?\n\nSee above in the description. we know the average number of positions per doc (totalTermFreq/docFreq) and so on. So we can compute the amortized cost of reading one position, and its easy from there.\n\n\nMaybe it should not only measure the cost of the operation but also how likely it is to match?\n\nI don't agree. You can already get this with Scorer.getApproximation().cost()/Scorer.cost().  "
        },
        {
            "id": "comment-14909660",
            "author": "Paul Elschot",
            "date": "2015-09-27T08:59:35+0000",
            "content": "From the javadocs of DocIdSetIterator.cost():\nThis is generally an upper bound of the number of documents this iterator might match, but may be a rough heuristic, hardcoded value, or otherwise completely inaccurate.\n\nPerhaps this cost method can be renamed to for example expectedMaxMatchingDocs() with these javadocs:\nThis an expected upper bound of the number of documents this iterator might match.\n\nWould it make sense to put matchCost() at DocIdSetIterator? "
        },
        {
            "id": "comment-14909666",
            "author": "Adrien Grand",
            "date": "2015-09-27T09:27:50+0000",
            "content": "Perhaps this cost method can be renamed to for example expectedMaxMatchingDocs() with these javadocs: This an expected upper bound of the number of documents this iterator might match.\n\nPersonally I don't dislike \"cost\". Even if it does not carry very well the meaning of what it measures, it does a pretty good job at carrying what to do with the result of this method: if you have several iterators, you want to consume the least-costly ones first.\n\nWould it make sense to put matchCost() at DocIdSetIterator?\n\nThe DocIdSetIterator abstraction does not have the concept of \"matching\", only TwoPhaseIterator has it, so I think it would be awkward to have it on DocIdSetIterator? TwoPhaseIterator feels like a more appropriate place to have this method. "
        },
        {
            "id": "comment-14909685",
            "author": "Paul Elschot",
            "date": "2015-09-27T10:58:16+0000",
            "content": "As to TwoPhaseIterator or DocIdSetIterator, I think this boils down to whether the leading iterator in ConjunctionDISI should be chosen using the expected number of matching docs only, or also using the totalTermFreq's somehow. This is for more complex queries, for example a conjunction with at least one phrase or SpanNearQuery.\n\nBut for the more complex queries two phase approximation is already in place, so having matchCost() only in the two phase code could be enough even for these queries. "
        },
        {
            "id": "comment-14952463",
            "author": "Paul Elschot",
            "date": "2015-10-11T22:15:24+0000",
            "content": "Patch of 12 Oct 2015, starting matchCost for ExactPhraseScorer only, the rest does not compile because it still needs matchDoc.\n(A little bit too much whitespace was removed by the editor, please ignore the noise.)\n\nIs this the direction to take? "
        },
        {
            "id": "comment-14952926",
            "author": "Adrien Grand",
            "date": "2015-10-12T11:03:25+0000",
            "content": "I think it would make more sense to sum up totalTermFreq/docFreq for each term instead of totalTermFreq/conjunctionDISI.cost(), so that we get the average number of positions per document? But otherwise I think you got the intention right. Something else to be careful with is that TermStatistics.totalTermFreq() may return -1, so we need a fallback for that case. Maybe we could just assume 1 position per document?\n\nA related question is what definition we should give to matchCost(). The patch does not have the issue yet since it only deals with phrase queries, but eventually we should be able to compare the cost of eg. a phrase query against a doc values range query even though they perform very different computations. Maybe the javadocs of matchCost could suggest a scale of costs of operations that implementors of matchCost() could use in order to compute the cost of matching the two-phase iterator. It could be something like 1 for nextDoc(), nextPosition(), comparisons and basic arithmetic operations and eg. 10 for advance()? "
        },
        {
            "id": "comment-14953114",
            "author": "Robert Muir",
            "date": "2015-10-12T13:31:14+0000",
            "content": "\nAs to TwoPhaseIterator or DocIdSetIterator, I think this boils down to whether the leading iterator in ConjunctionDISI should be chosen using the expected number of matching docs only, or also using the totalTermFreq's somehow. This is for more complex queries, for example a conjunction with at least one phrase or SpanNearQuery.\n\nBut for the more complex queries two phase approximation is already in place, so having matchCost() only in the two phase code could be enough even for these queries.\n\nYes, to keep things simple, I imagined this api would just be the cost of calling matches() itself so I think the two phase API is the correct place to put it (like in your patch).\n\nWe already have a cost() api for DISI for doing things like conjunctions (yes its purely based on density and maybe that is imperfect) but I think we should try to narrow the scope of this issue to just the cost of the matches() operation, which can vary wildly depending on query type or document size.\n\nWhat adrien says about \"likelyhood of match\" is also interesting but I think we want to defer that too. To me that is just a matter of having more accurate cost() and it may not be easy or feasible to improve... "
        },
        {
            "id": "comment-14953518",
            "author": "Paul Elschot",
            "date": "2015-10-12T18:26:31+0000",
            "content": "it would make more sense to sum up totalTermFreq/docFreq for each term \n\nI'll change that and change the matchCost() method to return a float instead of a long.\n\nTermStatistics.totalTermFreq() may return -1\n\nI'll add a check for that.\n\nwhat definition we should give to matchCost()\n\nI'd like to have it reflect an avarage cost to process a single document, once the two phase iterator is at the document.\nThat would exclude the cost for next() and advance(), which would be better in the DISI.cost() method for now.\n\nHow much of the cost of matches() should be in there I don't know, we'll see. NearSpans also does work after matches() returns true.\n\nAnd the likelyhood of match is the probability that matches() returns true... "
        },
        {
            "id": "comment-14953571",
            "author": "Adrien Grand",
            "date": "2015-10-12T19:00:17+0000",
            "content": "change the matchCost() method to return a float instead of a long\n\nI liked having it as a long, like DISI.cost(). Maybe we could just round?\n\nI'd like to have it reflect an avarage cost to process a single document, once the two phase iterator is at the document. That would exclude the cost for next() and advance(), which would be better in the DISI.cost() method for now.\n\nIndeed this is what it should do! Sorry I introduced some confusion, the reason why I brought these methods is ReqExclScorer, whose TwoPhaseIterator calls DocIdSetIterator.advance() on the excluded iterator in oder to validate a match. So we need to decide how costly calling advance() is. "
        },
        {
            "id": "comment-14953855",
            "author": "Paul Elschot",
            "date": "2015-10-12T22:14:43+0000",
            "content": "Patch of 13 Oct 2015. No spans yet. \nLeft matchDoc() returning float because in many cases the avarage number of positions in a matching document will be close to 1.\nQuite a few nocommits at matchDoc implementations throwing an Error(\"not yet implemented\")\n\nThis includes a first attempt at sorting the DISI's in ConjunctionDISI.\n\nTo my surprise, quite a few tests pass, I have not yet tried all of them. "
        },
        {
            "id": "comment-14953889",
            "author": "Adrien Grand",
            "date": "2015-10-12T22:29:07+0000",
            "content": "The change in ConjunctionDISI does not look right to me: we should keep sorting the iterators based on DISI.cost, and only use TwoPhaseIterator.matchCost to sort TwoPhaseConjunctionDISI.twoPhaseIterators.\n\nI'm also unhappy about adding a method to TermStatistics, this class should remain as simple as possible. Can we make it private to PhraseWeight? "
        },
        {
            "id": "comment-14955579",
            "author": "Paul Elschot",
            "date": "2015-10-13T20:28:21+0000",
            "content": "... unhappy about  adding a method to TermStatistics, this class should remain as simple as possible. Can we make it private to PhraseWeight?\n\nWhy should TermStatistics remain as simple as possible? Having a method that returns an expected value in a ...Statistics class looks just right to me.\n\nI initially had the code in PhraseWeight, but there many getter methods from TermStatistics were used, so I moved the method to TermStatistics and used the return value as the match cost for a single term in PhraseWeight.\n\nI think we will need the same thing for spans (multiplied with a factor 4 or so), and in that case the method will have to be public, because the spans are in a different package. Can we reconsider moving the method until the spans are done here?\n\n... only use TwoPhaseIterator.matchCost to sort TwoPhaseConjunctionDISI.twoPhaseIterators.\n\nI missed that, I'll introduce it. "
        },
        {
            "id": "comment-14955692",
            "author": "Paul Elschot",
            "date": "2015-10-13T21:14:40+0000",
            "content": "Second patch of 13 Oct 2015:\nUse matchCost to sort twoPhaseIterators.\nAdd matchCost implementations in test code.\nRename method expPositionsPerDoc() to expTermFreqInMatchingDoc().\n "
        },
        {
            "id": "comment-14955697",
            "author": "Paul Elschot",
            "date": "2015-10-13T21:16:39+0000",
            "content": "matchCost is still not implemented for Spans (4 nocommits left), and now some test cases using Spans actually fail. "
        },
        {
            "id": "comment-14955721",
            "author": "Paul Elschot",
            "date": "2015-10-13T21:29:34+0000",
            "content": "We could take into account the different costs of advance() and nextDoc(), but at another issue.\nWith cost() as an estimation of the number of matching documents, as it is now:\nfor conjunctions that could become: 2 * (minimum cost()) * (cost of advance),\nand for disjunctions: (total cost()) * (cost of nextDoc).\n\nReqExclScorer could use the cost of advance in its matchCost already here, but I have no idea which value to use.\n "
        },
        {
            "id": "comment-14956557",
            "author": "Adrien Grand",
            "date": "2015-10-14T09:29:08+0000",
            "content": "TermStatistics is a class that we need to maintain backward compatibility for since it's not experimental/internal. So we shouldn't put more methods in there that we only need for implementation details of PhraseQuery/SpanNearQuery. I would rather duplicate the logic. In addition, the current implementation of this method is trappy as it assumes that the average term freq is 1 when totalTermFreq is not available. While this might be ok for the matchCost computation of phrase queries, it might not be for other use-cases.\n\nThe changes in ConjunctionDISI look good to me now, thanks.\n\n\n+            if (w.twoPhaseView != null) {\n+              matchCost += w.twoPhaseView.matchCost();\n+            } else {\n+              assert w.iterator instanceof TermScorer; // zero match cost.\n+            }\n\n\n\nw.twoPhaseView can be null on any scorer that does not expose an approximation. So it can be not only a TermScorer, but also a conjunction/disjunction of term scorers or even a custom query. "
        },
        {
            "id": "comment-14957621",
            "author": "Paul Elschot",
            "date": "2015-10-14T19:54:45+0000",
            "content": "TermStatistics.java has a @lucene.experimental javadoc in trunk.\n\nI'll remove the assert w.iterator instanceof TermScorer, I put it there to remind me to check what to do in other cases. "
        },
        {
            "id": "comment-14957817",
            "author": "Paul Elschot",
            "date": "2015-10-14T21:28:03+0000",
            "content": "Patch of 14 October 2015.\nNo more NOCOMMITS, existing tests pass.\nStill no tests to verify that matchCost() is used correctly.\n\nSome FIXME's for the cost values used.\nImprove javadoc for TermStatistics.expTermFreqInMatchingDoc.\nIn AssertingTwoPhaseView.matchCost() the cost should be non negative.\nSmall javadoc correction in TwoPhaseIterator.\n "
        },
        {
            "id": "comment-14958355",
            "author": "Robert Muir",
            "date": "2015-10-15T05:31:24+0000",
            "content": "I agree with Adrien here. TermStatistics and CollectionStatistics are what feed the scoring systems (and already hairy enough as is), so we should keep any of this optimization-related stuff out of them. They were added to allow IndexSearcher to support distributed search. "
        },
        {
            "id": "comment-14959580",
            "author": "Paul Elschot",
            "date": "2015-10-15T20:42:51+0000",
            "content": "2nd patch of 15 October 2015.\n\nThis adds Span.positionsCost() as the basic matchCost to be used for Spans.\nThis method has a NOCOMMIT in Spans.java: throw UOE or abstract in Spans?\nI'd prefer to throw an UOE but an abstract method is easier to find the places where positionsCost() really needs to be implemented.\nFor now I left it abstract and have some implementations throw UOE.\n\nOther changes to the previous patch:\nUse TermStatistics from trunk.\nMove expTermFreqInMatchingDoc() from TermStatistics into PhraseWeight and a copy into TermSpans.\nSimplified matchCost() implementations.\n\nExisting tests pass.\n\nThis will need improvements, and I hope it works decently for simple cases like a conjunction over a phrase and a SpanNear. "
        },
        {
            "id": "comment-14959624",
            "author": "Paul Elschot",
            "date": "2015-10-15T21:11:49+0000",
            "content": "Some TwoPhaseIterators in Solr will need to have matchCost() added with the latest patch.\nI am not familiar enough with Solr code for that. "
        },
        {
            "id": "comment-14962105",
            "author": "Paul Elschot",
            "date": "2015-10-17T22:47:12+0000",
            "content": "Patch of 18 Oct 2015.\n\n\n\tCalculate the matchCost per LeafReaderContext, because the sorting by matchCost is done at leaf level.\n\tIn the facet, join and spatial modules, add matchCost implementations returning 0, and with a CHECKME comment.\n\tFixed a bug in the earlier added added sort comparator in the TwoPhaseConjunctionDISI constructor, it was comparing the same object.\n\tDropped the NOCOMMIT for Spans.positionsCost(), pefer this to be an abstract method.\n\n\n\n\n\tIn AssertingSpans the positionCost should be positive.\n\tAdd some toString() implementations for inline subclasses of TwoPhaseIterator to ease debugging.\n\n\n\n "
        },
        {
            "id": "comment-14962369",
            "author": "Paul Elschot",
            "date": "2015-10-18T13:15:11+0000",
            "content": "2nd patch of 18 Oct 2015. More improvements:\n\n\tAdd TwoPhaseIterator.termPositionsCost() for use in matchCost() implementations. This replaces the earlier PhraseQuery.expTermFreqInMatchingDoc().\n\tIn SpanOrQuery use better avarage cost for matchCost().\n\tMove positionsCost() throwing UOE from Near/ContainSpans to ConjunctionSpans only.\n\tmatchCost must be non negative in AssertingScorer.\n\tUse a random matchCost in RandomApproximationQuery.\n\tBetter javadocs and code comments.\n\n "
        },
        {
            "id": "comment-14962471",
            "author": "David Smiley",
            "date": "2015-10-18T15:54:12+0000",
            "content": "This is neat.  Couple things...\n\n\n\tRandomAccessWeight's 2-phase should probably call to a protected method on RAW so that a subclass could define the cost based on how expensive using the Bits is.  Maybe it should be abstract and not zero?\n\tIt will be difficult for many of the 2-phase implementations to calculate a matchCost \u2013 particularly the ones not based on the number of term positions.  What to do?  A constant of '0' (which you often labelled FIXME) is way too cheap I think?  Maybe the best we can hope for is simply a stable sort of same-cost 2-phases and assuming that the order of queries added to a BooleanQuery.Builder remains stable.  This at least allows the user to tune performance by changing the clause order for such constant matchCost queries.  But I see that the latest BooleanQuery.Builder is not stable due to use of HashSet / MultiSet versus LinkedHashSet which would be stable.  What do you think Adrien Grand?  Alternatively (or in addition) a query wrapper could allow explicitly setting a cost  (vaguely similar to Solr's ExtendedQuery.getCost).  This could look similar to BoostQuery but for 2-phase matchCost instead of score.\n\tMaybe the explain could possibly display the matchCost?  It'd be nice to troubleshoot/inspect for diagnostics somehow.  Not critical, of course.\n\n "
        },
        {
            "id": "comment-14962541",
            "author": "Paul Elschot",
            "date": "2015-10-18T18:09:16+0000",
            "content": "I left the matchCosts that I could not easily determine at zero and added a CHECKME. This is more an indication that refinement is possible.\n\nSorting subscorers/subspans by cost and matchCost is probably better than relying on any given order.\nAnyway I don't expect the impact of matchCost on performance be more than 4-8% except maybe for really complex queries.\n\nShowing the matchCost in explain will be tricky because it is computed by LeafReaderContext, i.e. by segment.\n\nThe matchCost is not yet used for the second phase in disjunctions. Yet another priority queue might be needed for that, so I'd prefer to delay that to another issue.\n "
        },
        {
            "id": "comment-14962547",
            "author": "Paul Elschot",
            "date": "2015-10-18T18:20:52+0000",
            "content": "Another thing to be determined is this the relative cost of span queries vs phrase queries.\nThe code for that is in SpanTermQuery here:\n\n  /** A guess of\n   * the relative cost of dealing with the term positions\n   * when using a SpanNearQuery instead of a PhraseQuery.\n   */\n  private final float PHRASE_TO_SPAN_TERM_POSITIONS_COST = 4.0f;\n\n\nThis is a guess because it is only based on my recollection of a few years ago that the performance of PhraseQuery was about 4 times better than an ordered SpanNear.\nIn the long term it is probably better to make this a configurable parameter. "
        },
        {
            "id": "comment-14962553",
            "author": "Paul Elschot",
            "date": "2015-10-18T18:30:51+0000",
            "content": "Talking about priority queues, there is also this one: LUCENE-6453. "
        },
        {
            "id": "comment-14963379",
            "author": "Adrien Grand",
            "date": "2015-10-19T14:25:35+0000",
            "content": "It will be difficult for many of the 2-phase implementations to calculate a matchCost \u2013 particularly the ones not based on the number of term positions. What to do?\n\nAgreed: we need to come with a very simple definition of matchCost that could be applied regardless of how matches() is implemented. I think we have two options:\n\n\teither an estimate running time of matches() in nanoseconds,\n\tor an average number of operations that need to be performed in matches(), so that you would add +1 every time you do a comparison, arithmetic operation, consume a PostingsEnum, etc.\n\n\n\nRuntimes in nanoseconds could easily vary depending on hardware, JVM version, etc. so I think the 2nd option is more practical. For instance:\n\n\tfor a phrase query, we would return the sums of the average number of positions per documents (which is an estimate of how many times you will call PostingsEnum.nextPosition()). Maybe we could try to fold in the cost of balancing the priority queue too.\n\tfor a doc values range query on numbers, the match cost would be 3: one dv lookup and 2 comparisons\n\tfor a geo distance query that uses SloppyMath.haversin to confirm matches, we could easily count how many operations are performed by SloppyMath.haversin\n\n\n\nThis is simplistic but I think it would do the job and keep the implementation simple. For instance, a doc values range query would always be confirmed before a geo-distance query.\n\nBut I see that the latest BooleanQuery.Builder is not stable due to use of HashSet / MultiSet versus LinkedHashSet which would be stable. What do you think Adrien Grand? \n\nActually it is: those sets and multisets are only used for equals/hashcode. The creation of scorers is still based on the list of clauses, which maintains the order from the builder.\n\nShowing the matchCost in explain will be tricky because it is computed by LeafReaderContext, i.e. by segment.\n\n+1 to not do it\n\nThe matchCost is not yet used for the second phase in disjunctions. Yet another priority queue might be needed for that, so I'd prefer to delay that to another issue.\n\nFeel free to delay, I plan to explore this in LUCENE-6815. "
        },
        {
            "id": "comment-14963465",
            "author": "David Smiley",
            "date": "2015-10-19T15:26:18+0000",
            "content": "RE BooleanQuery stable ordering: thanks for correcting me; I'm very glad it's stable.  At least this gives the user some control.\n\nI think we may need to percolate the matchCost concept further into other APIs \u2013 namely ValueSource/FunctionValues.  This way the 2-phase iterator can enclose one of them to fetch the matchCost of it when composing it's aggregate matchCost.\n\nAnd I question if a numeric DV lookup or reading a posting is equivalent to one mathematical operation since those things involve some code behind them that aren't cheap one-liners that a math operation are.  Nonetheless, I get the concept you are suggesting.  \n\nI kind of like the time based approach you suggested better but what's needed is some automation to aid in establishing a baseline such that someone on their own machine can get an approximation slower/faster factor multiplier compared to some baseline server.  Like what if there was an ant target that ran some test based on Wikipedia data that established that the matchCost for a some PhraseQuery on the machine it's run on is ____ nanoseconds.  Then the output also displays some hard-coded value that we got when running this on some baseline server.  Dividing the two yields a relative difference between the local machine and the baseline server.  Then when working on a custom query, I could locally temporarily either modify the timing test to test my new query (perhaps plucking the geo data in Wikipedia out to a lat-lon spatial field) or timing it in my own way.  Then I apply the multiplier to determine which number to hard-code into the query going into Lucene.  Make sense?  \n\nThere is another aspect of the cost beyond a per-postings iteration cost.  The cost of reading the N+1 position is generally going to be much cheaper than reading the very first position since the first once possibly involves a seek.  If only postings based queries are being compared via matchCost, this is a wash since all of them have this cost but it'd be different for a doc-values based query.  Although perhaps it's a wash there too \u2013 assume one disk seek?  Worst case of course. "
        },
        {
            "id": "comment-14963540",
            "author": "Paul Elschot",
            "date": "2015-10-19T16:12:25+0000",
            "content": "an average number of operations that need to be performed in matches(), so that you would add +1 every time you do a comparison, arithmetic operation, consume a PostingsEnum, etc.\n\nThat sounds doable. The Lucene50PostingsReader takes about such 7 operations for a nextPosition() call  in case it does not seek and/or refill its buffer. I assume that would be the cost of consuming a PostingsEnum.\n\nThe cost of reading the N+1 position is generally going to be much cheaper than reading the very first position since the first once possibly involves a seek.\n\nTo take that into account an estimation of the seek/refill cost per term could be added in once per document.\n\nwe may need to percolate the matchCost concept further into other APIs \u2013 namely ValueSource/FunctionValues\n\nCould that be done at another issue? "
        },
        {
            "id": "comment-14963877",
            "author": "David Smiley",
            "date": "2015-10-19T19:13:10+0000",
            "content": "To take that into account an estimation of the seek/refill cost per term could be added in once per document.\n\nRight; I just wanted to point this out.\n\nwe may need to percolate the matchCost concept further into other APIs \u2013 namely ValueSource/FunctionValues\nCould that be done at another issue?\n\nYes, of course. "
        },
        {
            "id": "comment-14977202",
            "author": "Paul Elschot",
            "date": "2015-10-27T21:27:57+0000",
            "content": "Patch of 27 October 2015. This\n\n\tis against trunk of today,\n\tresolves the conflicts from Spans becoming a Scorer,\n\tchanges the matchCost to be an estimate of the number of operations needed for the positions. This uses a cost of 7 per position as in the codec code, and a basic cost 128 (no more than a guess) for the initial seek and refill.\n\tadds a few more implementations to make ant compile-test pass at top level.\n\n\n\nSince 7 is rather low and the expected number of positions per document containing the term is just above 1 in many cases, I left matchCost() returning a float. "
        },
        {
            "id": "comment-14980447",
            "author": "Adrien Grand",
            "date": "2015-10-29T13:46:48+0000",
            "content": "Some suggestions:\n\n\tcould the match costs be computed eagerly instead of lazily, like we compute the costs of DocIdSetIterators?\n\tcan you move the utility methods to compute costs of phrases from TwoPhaseIterator into PhraseWeight/SpanNearQuery. I don't like leaking implementation details of specific TwoPhaseIterators into TwoPhaseIterator.\n\tsome implementations of matchCost return 0 (eg. RandomAccessWeight); I'm fine with not implementing every match cost for now, but could you leave a TODO and use a higher constant (eg. 100)? I think it's safer to assume that such implementations are costly until they are implemented correctly.\n\tre: ReqExclScorer: indeed I think we should try to take into account the cost of advancing the excluded scorer. If this is complicated, I'm fine with tackling this problem later.\n\tre: DisjunctionScorer: I think your current definition of the match cost is fine. Maybe we could improve it by weighting the match cost of each TwoPhaseIterator by the cost of their approximation. I think it would make sense since we will call TwoPhaseIterator.matches() more often if their approximation matches more documents.\n\tAssertingSpans/AsseringScorer ensure that the match cost is >= 0. Maybe we should also check for NaN and document acceptable return values in the documentation of #matchCost?\n\n "
        },
        {
            "id": "comment-14980894",
            "author": "Paul Elschot",
            "date": "2015-10-29T17:43:59+0000",
            "content": "I basically agree to all of these.\n\n... move the utility methods to compute costs of phrases from TwoPhaseIterator into PhraseWeight/SpanNearQuery. I don't like leaking implementation details of specific TwoPhaseIterators into TwoPhaseIterator.\n\nand make them (package) private I assume? The only disadvantage of that is that some duplication of these methods is needed in the spans package.\n\nThe easiest way to avoid such duplication would be when Spans move from o.a.l.search.spans to o.a.l.search.\nIirc there was some talk of that not so long ago (Alan's plans for spans iirc), so how about waiting for that, possibly at a separate issue?\n\nIt will take a while (at least a week) before I can continue with this. Please feel free to take it on. "
        },
        {
            "id": "comment-14985922",
            "author": "Paul Elschot",
            "date": "2015-11-02T20:06:56+0000",
            "content": "Patch of 2 Nov 2015.\nThis addresses all the above concerns.\nIt also precomputes positionsCost in SpanOrQuery, weighted by the cost() in the same way as matchCost. "
        },
        {
            "id": "comment-14989595",
            "author": "Adrien Grand",
            "date": "2015-11-04T14:15:24+0000",
            "content": "\n\tcan you add to the javadocs of TwoPhaseIterator#matchCost that match costs need to be a positive number?\n\tcan you add some comments around the cost computation for disjunctions/conjunctions to explain the reasoning?\n\tI would prefer termPositionsCost to be duplicated in PhraseWeight and SpanNearQuery than in TwoPhaseIterator, like we do for disjunctions (SpanOrQuery and DisjunctionScorer). I can understand the concerns around duplication but I think it's still cleaner than trying to share the logic by adding utility methods to TwoPhaseIterator.\n\tI think SpanTermQuery.PHRASE_TO_SPAN_TERM_POSITIONS_COST should be static?\n\n\n\nOtherwise the change looks good to me, I like the cost definition for conjunctions/disjunctions/phrases and we can tackle other queries in follow-up issues, but I think this is already a great start and will help execute slow queries more efficiently! "
        },
        {
            "id": "comment-14995427",
            "author": "Paul Elschot",
            "date": "2015-11-07T22:21:24+0000",
            "content": "Patch of 7 Nov 2015.\nThis addresses all concerns of 3 days ago.\ntermPositionsCost moved from TwoPhaseIterator to PhraseQuery, I left a copy in SpanTermQuery because that is where it is used.\n\nPerhaps the result of ConjunctionSpans.asTwoPhaseIterator() should look more like TwoPhaseConjunctionDISI, at the moment I cannot get my head around this.\n "
        },
        {
            "id": "comment-14997422",
            "author": "Paul Elschot",
            "date": "2015-11-09T21:45:39+0000",
            "content": "I went over the patch and the earlier posts to get an overview of open points, TODO's, etc.\nThere are quite a lot of them, so we'll need to prioritize and/or move/defer to other issues.\n\nlucene core:\n\nConjunctionDISI matchCost(): give the lower matchCosts a higher weight\n\nPhraseQuery:\nTERM_POSNS_SEEK_OPS_PER_DOC = 128, guess\nPHRASE_TO_SPAN_TERM_POSITIONS_COST = 4, guess\n\nTwoPhaseIterator: Return value of matchCost(): long instead of float?\n\nRandomAccessWeight matchCost(): 10, use cost of matchingDocs.get()\n\nReqExclScorer matchCost(): also use cost of exclApproximation.advance()\n\nSpanTermQuery: termPositionsCost is copy of PhraseQuery termPositionsCost\n\nSpanOrQuery: add cost of balancing priority queues for positions?\n\n\nfacet module (defer to other issue):\n\nDoubleRange matchCost(): 100, use cost of range.accept()\nLongRange matchCost(): 100, use cost of range.accept()\n\n\njoin module (defer to other issue ?):\n\nGlobalOrdinals(WithScore)Query matchCost(): 100, use cost of values.getOrd() and foundOrds.get()\nGlobalOrdinals(WithScore)Query 2nd matchCost(): 100, use cost of values.getOrd() and foundOrds.get()\n\n\nqueries module (defer to other issue):\n\nValueSourceScorer matchCost(): 100, use cost of ValueSourceScorer.this.matches()ValueSourceScorer matchCost(): 100, use cost of \n\n\nspatial module (defer to other issue)::\n\nCompositeVerifyQuery matchCost(): 100, use cost of predFuncValues.boolVal()\nIntersectsRPTVerifyQuery matchCost(): 100, use cost of exactIterator.advance() and predFuncValues.boolVal()\n\ntest-framework module:\n\nRandomApproximationQuery randomMatchCost: between 0 and 200: ok?\n\nsolr core:\n\nFilter matchCost(): 10, use cost of bits.get() ?\n\n\nAt this issue:\n\nPerformance test based on Wikipedia to estimate guessed values.\n\ntests for matchCost() ?\n\nCheck result of ConjunctionSpans.asTwoPhaseIterator: more similar to TwoPhaseConjunctionDISI ?\n\n\nFor other issues:\n\nAt LUCENE-6871 remove copy of SpanTermQuery.termPositionsCost(). \n\nSpanOrQuery is getting too big, split off DisjunctionSpans.\n\ncost() implementation of conjunctions and disjunctions could improve: add use of indepence assumption.\nThe result of cost() is used here for weighting, so it should be good as possible. "
        },
        {
            "id": "comment-14997705",
            "author": "Adrien Grand",
            "date": "2015-11-10T00:05:41+0000",
            "content": "ConjunctionDISI matchCost(): give the lower matchCosts a higher weight\n\nWe could use the likelyness of a match, which should be given by Scorer.asTwoPhaseApproximation().approximation().cost()/Scorer.cost() even though I suspect that most implementations have no way to figure it out (eg. numeric doc values ranges). But I think we should defer, it's fine to assume worst case like the patch does today.\n\nTwoPhaseIterator: Return value of matchCost(): long instead of float?\n\nI would be ok with both, but given that matchCost is documented as \"an expected cost in number of simple operations\", maybe a long makes more sense? It also has the benefit of avoiding issues with \u00b10, Nans, infinities, etc.\n\nPerformance test based on Wikipedia to estimate guessed values.\n\nI think this change is very hard to benchmark... I'm personally fine with moving on here without performance benchmarks.\n\nFor other ones that I did not reply to, I suggest that we defer them: I don't think they should hold this change. "
        },
        {
            "id": "comment-14998236",
            "author": "Paul Elschot",
            "date": "2015-11-10T08:20:23+0000",
            "content": "As to long/float: the expected outcome of rolling a dice is not a whole number, and as it happens, that has some similarities with the situation here. "
        },
        {
            "id": "comment-15001142",
            "author": "Paul Elschot",
            "date": "2015-11-11T21:31:41+0000",
            "content": "I have opened LUCENE-6894 for the independence assumption for DISI.cost(). "
        },
        {
            "id": "comment-15001228",
            "author": "Adrien Grand",
            "date": "2015-11-11T22:15:05+0000",
            "content": "I'm +1 on the patch. I'll do some more testing locally in the next days and commit it. "
        },
        {
            "id": "comment-15002373",
            "author": "Adrien Grand",
            "date": "2015-11-12T16:39:10+0000",
            "content": "Hmm, I'm getting failures with ComplexPhraseQuery:\n\n\n   [junit4] Suite: org.apache.lucene.queryparser.complexPhrase.TestComplexPhraseQuery\n   [junit4]   2> NOTE: reproduce with: ant test  -Dtestcase=TestComplexPhraseQuery -Dtests.method=testComplexPhrases -Dtests.seed=E7F242A6F40525AB -Dtests.slow=true -Dtests.locale=in_ID -Dtests.timezone=Africa/Banjul -Dtests.asserts=true -Dtests.file.encoding=ISO-8859-1\n   [junit4] FAILURE 0.18s J2 | TestComplexPhraseQuery.testComplexPhrases <<<\n   [junit4]    > Throwable #1: java.lang.AssertionError\n   [junit4]    > \tat __randomizedtesting.SeedInfo.seed([E7F242A6F40525AB:8259F91767B2FFA3]:0)\n   [junit4]    > \tat org.apache.lucene.search.spans.SpanOrQuery$SpanOrWeight$1.positionsCost(SpanOrQuery.java:261)\n   [junit4]    > \tat org.apache.lucene.search.spans.ScoringWrapperSpans.positionsCost(ScoringWrapperSpans.java:88)\n   [junit4]    > \tat org.apache.lucene.search.spans.FilterSpans$2.matchCost(FilterSpans.java:167)\n   [junit4]    > \tat org.apache.lucene.search.ConjunctionDISI$TwoPhaseConjunctionDISI.<init>(ConjunctionDISI.java:186)\n   [junit4]    > \tat org.apache.lucene.search.ConjunctionDISI$TwoPhaseConjunctionDISI.<init>(ConjunctionDISI.java:164)\n   [junit4]    > \tat org.apache.lucene.search.ConjunctionDISI$TwoPhase.<init>(ConjunctionDISI.java:227)\n   [junit4]    > \tat org.apache.lucene.search.ConjunctionDISI$TwoPhase.<init>(ConjunctionDISI.java:221)\n   [junit4]    > \tat org.apache.lucene.search.ConjunctionDISI.intersect(ConjunctionDISI.java:50)\n   [junit4]    > \tat org.apache.lucene.search.spans.ConjunctionSpans.<init>(ConjunctionSpans.java:43)\n   [junit4]    > \tat org.apache.lucene.search.spans.NearSpansOrdered.<init>(NearSpansOrdered.java:56)\n   [junit4]    > \tat org.apache.lucene.search.spans.SpanNearQuery$SpanNearWeight.getSpans(SpanNearQuery.java:223)\n   [junit4]    > \tat org.apache.lucene.search.spans.SpanWeight.scorer(SpanWeight.java:134)\n   [junit4]    > \tat org.apache.lucene.search.Weight.bulkScorer(Weight.java:135)\n   [junit4]    > \tat org.apache.lucene.search.AssertingWeight.bulkScorer(AssertingWeight.java:69)\n   [junit4]    > \tat org.apache.lucene.search.AssertingWeight.bulkScorer(AssertingWeight.java:69)\n   [junit4]    > \tat org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:667)\n   [junit4]    > \tat org.apache.lucene.search.AssertingIndexSearcher.search(AssertingIndexSearcher.java:92)\n   [junit4]    > \tat org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:474)\n   [junit4]    > \tat org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:593)\n   [junit4]    > \tat org.apache.lucene.search.IndexSearcher.searchAfter(IndexSearcher.java:451)\n   [junit4]    > \tat org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:462)\n   [junit4]    > \tat org.apache.lucene.queryparser.complexPhrase.TestComplexPhraseQuery.checkMatches(TestComplexPhraseQuery.java:116)\n   [junit4]    > \tat org.apache.lucene.queryparser.complexPhrase.TestComplexPhraseQuery.testComplexPhrases(TestComplexPhraseQuery.java:58)\n   [junit4]    > \tat java.lang.Thread.run(Thread.java:745)\n   [junit4]   2> NOTE: test params are: codec=Asserting(Lucene60): {role=PostingsFormat(name=Memory doPackFST= false), name=PostingsFormat(name=LuceneFixedGap), id=PostingsFormat(name=LuceneFixedGap)}, docValues:{}, sim=RandomSimilarityProvider(queryNorm=true,coord=no): {role=DFR I(n)LZ(0.3), name=DFR I(n)3(800.0), id=DFR I(n)3(800.0)}, locale=in_ID, timezone=Africa/Banjul\n   [junit4]   2> NOTE: Linux 3.13.0-68-generic amd64/Oracle Corporation 1.8.0_66-ea (64-bit)/cpus=8,threads=1,free=187449736,total=253231104\n   [junit4]   2> NOTE: All tests run in this JVM: [TestNumericRangeQueryBuilder, TestExtendableQueryParser, TestSpanQueryParser, TestExtensions, TestComplexPhraseQuery]\n   [junit4] Completed [11/27] on J2 in 0.50s, 5 tests, 1 failure <<< FAILURES!\n\n\n\nI haven't looked into it yet. "
        },
        {
            "id": "comment-15002694",
            "author": "Paul Elschot",
            "date": "2015-11-12T19:19:43+0000",
            "content": "The test failure reproduces here. I'll take a look, thanks. "
        },
        {
            "id": "comment-15002831",
            "author": "Paul Elschot",
            "date": "2015-11-12T20:10:29+0000",
            "content": "This failure disappeared after adding asTwoPhaseIterator() to ScoringWrapperSpans. I'll post a new patch later. "
        },
        {
            "id": "comment-15003010",
            "author": "Paul Elschot",
            "date": "2015-11-12T21:55:16+0000",
            "content": "Patch of 12 Nov 2015.\nAdds ScoringWrapperSpans.asTwoPhaseIterator().\n\nThis missing method could be a bug in itself. "
        },
        {
            "id": "comment-15004632",
            "author": "ASF subversion and git services",
            "date": "2015-11-13T20:08:02+0000",
            "content": "Commit 1714261 from Adrien Grand in branch 'dev/trunk'\n[ https://svn.apache.org/r1714261 ]\n\nLUCENE-6276: Added TwoPhaseIterator.matchCost(). "
        },
        {
            "id": "comment-15004701",
            "author": "ASF subversion and git services",
            "date": "2015-11-13T20:55:21+0000",
            "content": "Commit 1714266 from Adrien Grand in branch 'dev/branches/branch_5x'\n[ https://svn.apache.org/r1714266 ]\n\nLUCENE-6276: Added TwoPhaseIterator.matchCost(). "
        },
        {
            "id": "comment-15004703",
            "author": "Adrien Grand",
            "date": "2015-11-13T20:56:01+0000",
            "content": "I just committed the changes. Thanks Paul! "
        }
    ]
}