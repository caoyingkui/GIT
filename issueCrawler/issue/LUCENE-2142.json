{
    "id": "LUCENE-2142",
    "title": "FieldCache.getStringIndex should not throw exception if term count exceeds doc count",
    "details": {
        "labels": "",
        "priority": "Minor",
        "components": [
            "core/search"
        ],
        "type": "Bug",
        "fix_versions": [
            "2.9.4",
            "3.0.3",
            "3.1",
            "4.0-ALPHA"
        ],
        "affect_versions": "None",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "Spinoff of LUCENE-2133/LUCENE-831.\n\nCurrently FieldCache cannot handle more than one value per field.\nWe may someday want to fix that... but until that day:\n\nFieldCache.getStringIndex currently does a simplistic check to try to\ncatch when you've accidentally allowed more than one term per field,\nby testing if the number of unique terms exceeds the number of\ndocuments.\n\nThe problem is, this is not a perfect check, in that it allows false\nnegatives (you could have more than one term per field for some docs\nand the check won't catch you).\n\nFurther, the exception thrown is the unchecked RuntimeException.\n\nSo this means... you could happily think all is good, until some day,\nwell into production, once you've updated enough docs, suddenly the\ncheck will catch you and throw an unhandled exception, stopping all\nsearches [that need to sort by this string field] in their tracks.\nIt's not gracefully degrading.\n\nI think we should simply remove the test, ie, if you have more terms\nthan docs then the terms simply overwrite one another.",
    "attachments": {
        "LUCENE-2142-fix-trunk.patch": "https://issues.apache.org/jira/secure/attachment/12447528/LUCENE-2142-fix-trunk.patch",
        "LUCENE-2142-fix-3x.patch": "https://issues.apache.org/jira/secure/attachment/12447527/LUCENE-2142-fix-3x.patch",
        "LUCENE-2142-trunk.patch": "https://issues.apache.org/jira/secure/attachment/12447940/LUCENE-2142-trunk.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2009-12-10T21:05:42+0000",
            "content": "+1 ",
            "author": "Yonik Seeley",
            "id": "comment-12788925"
        },
        {
            "date": "2009-12-11T19:19:01+0000",
            "content": "+1 ",
            "author": "Earwin Burrfoot",
            "id": "comment-12789474"
        },
        {
            "date": "2010-05-30T12:29:23+0000",
            "content": "backport ",
            "author": "Michael McCandless",
            "id": "comment-12873415"
        },
        {
            "date": "2010-06-07T01:07:04+0000",
            "content": "\nI think we should simply remove the test, ie, if you have more terms\nthan docs then the terms simply overwrite one another.\nI think the remove still throws unhandled exception (AIOOBE)? ",
            "author": "Koji Sekiguchi",
            "id": "comment-12876102"
        },
        {
            "date": "2010-06-18T22:12:47+0000",
            "content": "I think the remove still throws unhandled exception (AIOOBE)?\n\nDuh, right!\n\nI'm not sure what I was smoking when I did this... the fix makes the exception worse since you now get a cryptic AIOOBE instead of a RuntimeException explaining what's wrong. ",
            "author": "Michael McCandless",
            "id": "comment-12880344"
        },
        {
            "date": "2010-06-19T06:38:38+0000",
            "content": "When does it throw AIOOBE (have not tested it...)? For me the code looked fine, too, so I don't think Mike was smoking something.  ",
            "author": "Uwe Schindler",
            "id": "comment-12880432"
        },
        {
            "date": "2010-06-19T07:11:20+0000",
            "content": "After a coffee i have seen the problem, too - stupoid \n\nHere is the fix for 3.x (also 3.0 and 2.9) - in trunk the fix is not needed, as there are growable arrays. Maybe we should add a simple test to all branches!\n ",
            "author": "Uwe Schindler",
            "id": "comment-12880441"
        },
        {
            "date": "2010-06-19T08:15:32+0000",
            "content": "Here patch with test for 3.x and before. Trunk patch only contains test, which passes. ",
            "author": "Uwe Schindler",
            "id": "comment-12880456"
        },
        {
            "date": "2010-06-19T09:08:43+0000",
            "content": "Thanks Uwe!\n\nSo your fix avoids any exception altogether.  On 3x, you just stop\nloading when we hit a termOrd > number of docs.  On trunk, we keep\nloading, simply growing the array as needed.\n\nI'm torn on what the best disposition here is.  This API should only\nbe used on single-token (per doc) fields, so this handling we're\nadding/fixing is about how to handle the misuse of the API.\n\nNeither solution is great \u2013 throwing an exception is nasty since you\ncould be fine for some time and then only on indexing enough docs,\nperhaps well into production, trip the exception.  But then silently\npretending nothing is wrong is also not great because the app then has\nno clue.\n\nReally this'd be a great time to use a logging framework \u2013 we'd drop\na error, and then not throw an exception.\n\nNet/net I think your solution (don't throw an exception) is the lesser\nevil at this time, so I think we should go with that.\n\nBut: I think we should also fix trunk?  Ie, if hit termOrd > numDocs,\nsilently break, instead of trying to grow the array.  Because now (on\ntrunk) if you try to load a DocTermsIndex on a large tokenized text\nfield in a large index you'll (try to) use insane amounts of memory...\n ",
            "author": "Michael McCandless",
            "id": "comment-12880463"
        },
        {
            "date": "2010-06-24T10:42:38+0000",
            "content": "Committed in trunk, 3x, 3.0, 2.9 branches.\n\nTrunk is still missing the escape-branch when term count exceeds doc count. ",
            "author": "Uwe Schindler",
            "id": "comment-12882119"
        },
        {
            "date": "2010-06-24T11:10:22+0000",
            "content": "Patch to fix trunk to stop loading when number of terms > maxDoc. ",
            "author": "Michael McCandless",
            "id": "comment-12882129"
        }
    ]
}