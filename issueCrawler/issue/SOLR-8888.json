{
    "id": "SOLR-8888",
    "title": "Add shortestPath Streaming Expression",
    "details": {
        "components": [],
        "type": "Improvement",
        "labels": "",
        "fix_versions": [
            "6.1"
        ],
        "affect_versions": "6.1",
        "status": "Closed",
        "resolution": "Implemented",
        "priority": "Major"
    },
    "description": "This ticket is to implement a distributed shortest path graph traversal as a Streaming Expression.\n\nExpression syntax:\n\n\nshortestPath(collection, \n                     from=\"john@company.com\", \n                     to=\"jane@company.com\",\n                     edge=\"from=to\",\n                     threads=\"6\",\n                     partitionSize=\"300\", \n                     fq=\"limiting query\", \n                     maxDepth=\"4\")\n\n\n\nThe expression above performs a breadth first search to find the shortest paths in an unweighted, directed graph. The search starts from the node john@company.com  and searches for the node jane@company.com, traversing the edges by iteratively joining the from and to columns. Each level in the traversal is implemented as a parallel partitioned nested loop join across the entire collection. The threads parameter controls the number of threads performing the join at each level. The partitionSize controls the of number of nodes in each join partition. maxDepth controls the number of levels to traverse. fq is a limiting query applied to each level in the traversal.\n\nFuture implementations can add more capabilities such as weighted traversals.",
    "attachments": {
        "SOLR-8888.1.patch": "https://issues.apache.org/jira/secure/attachment/12802913/SOLR-8888.1.patch",
        "SOLR-8888.patch": "https://issues.apache.org/jira/secure/attachment/12795643/SOLR-8888.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2016-03-23T19:19:46+0000",
            "author": "Dennis Gove",
            "content": "What does the colA and colB refer to in each of those nodes? ",
            "id": "comment-15208985"
        },
        {
            "date": "2016-03-23T19:32:11+0000",
            "author": "Joel Bernstein",
            "content": "I've changed the syntax a couple of times. But in the latest colA and colB are the field names. So basically traverse from colA to colB iteratively until colB=node2 is found.\n\nThe implementation would parse the columns from the from and to parameters. \n\nThe intial query params would be:\n\ncolA:node1,\nfl=\"colB\",\nsort=\"colB asc\"\n\nThe subsequent join queries would be done in batches:\n\ncolA:(nodeX, nodeY, ....)\nfl:\"colB\",\nsort=\"colB asc\"\n\n\n\n\n\n\n\n\n\n ",
            "id": "comment-15209000"
        },
        {
            "date": "2016-03-23T19:36:45+0000",
            "author": "Joel Bernstein",
            "content": "The implementation will need to keep sorted files for each iteration that look like this:\n\nnodeA, parentNode\nnodeB, parantNode\n....\n\nThese files can then be intersected with each join to implement cycle detection. The files will also be used to trace back through the nodes to get the path when the node being traversed to is found. ",
            "id": "comment-15209005"
        },
        {
            "date": "2016-03-23T19:41:40+0000",
            "author": "Dennis Gove",
            "content": "Oh I see. How about something that is explicit about what edge should be followed\n\n\nshortestPath(collection, \n                     from=\"node1\", \n                     to=\"node2\",\n                     edge=\"colA=colB\" \n                     fq=\"limiting query\", \n                     maxDepth=\"10\")\n\n\n\nThis would make the edge just a use of the FieldEqualitor and possibly simplify the creation of the joins. Also, as we expand the set of FieldEqualitors the graph queries can benefit.\n\nAs an example to the expansion of FieldEqualitor, though outside the scope of this ticket, imagine a case where we'd want to say colA=colB+-5, which would translate to two fields being within 5 of each other. An equalitor could be created to support such a range case. ",
            "id": "comment-15209011"
        },
        {
            "date": "2016-03-23T20:03:31+0000",
            "author": "Joel Bernstein",
            "content": "That's much nicer. I'll work from this syntax. Thanks! ",
            "id": "comment-15209060"
        },
        {
            "date": "2016-03-24T13:26:45+0000",
            "author": "Joel Bernstein",
            "content": "I've been digging into the implementation and it looks like Streaming provides some real advantages.\n\nThe biggest advantage comes from the ability to sort entire results by the Node id and do this in parallel across the cluster. This means that once the Nodes arrive at the worker they can simply be written to memory mapped files for the book keeping. The book keeping files need to be sorted by Node Id and most likely need offset information to support binary searching and skipping during intersections. I looked at using MapDB for the book keeping and if the data wasn't already coming in sorted then this would have been the approach to use. But even as fast as MapDB is there is still overhead that we don't need in managing the BTree's.\n\nSo, in order to get the maximum speed in reading and writing the book keeping files I'm planning on just using memory mapped files with offsets. This is going to take more time to develop but will pay off when there are large traversals.\n ",
            "id": "comment-15210206"
        },
        {
            "date": "2016-03-28T16:23:44+0000",
            "author": "Joel Bernstein",
            "content": "First patch which implements a breadth first search using a threaded nested loop join. Each join in the traversal is split up into batches and is executed in threads within the worker node. This approach spreads the join across all replicas. The bottleneck in this scenario will be the network as potentially dozens of search nodes will be returning nodes in parallel to the same worker to satisfy the join. This bottleneck can be greatly reduced by compression because the edges are returned sorted by the toField, which will cause large amount of repeated data to be streamed in the same compression block. SOLR-8910 has been opened to add Lz4 compression to the /export handler. \n\nIn my last comment I mentioned using sorted memory mapped files for the book keeping. In this patch all book keeping is done in memory using HashMaps.  ",
            "id": "comment-15214407"
        },
        {
            "date": "2016-03-28T18:53:20+0000",
            "author": "Joel Bernstein",
            "content": "Added first simple test case. \n\nI'll also be testing with some scale using the Enron emails data set. ",
            "id": "comment-15214677"
        },
        {
            "date": "2016-03-28T21:43:18+0000",
            "author": "Joel Bernstein",
            "content": "Latest patch fixes bug found during manual testing with Enron email ",
            "id": "comment-15214949"
        },
        {
            "date": "2016-03-29T01:03:49+0000",
            "author": "Joel Bernstein",
            "content": "New patch adds a subsort to the queries to ensure results are deterministic. ",
            "id": "comment-15215186"
        },
        {
            "date": "2016-03-29T01:12:45+0000",
            "author": "Joel Bernstein",
            "content": "Initial manual testing with the Enron emails is going well and returning the shortest path nicely. Next step is to add the Streaming Expression syntax and add more junit tests. ",
            "id": "comment-15215198"
        },
        {
            "date": "2016-03-29T14:00:24+0000",
            "author": "Dennis Gove",
            "content": "I think the edge format should be an equality, like colA=colB\n\n\nshortestPath(collection, \n                     from=\"node1\", \n                     to=\"node2\",\n                     edge=\"colA=colB\",\n                     threads=\"6\",\n                     partitionSize=\"300\", \n                     fq=\"limiting query\", \n                     maxDepth=\"10\")\n\n\n\nAside from the discussion above, this would allow situations where multiple fields are used in the join\n\n\nshortestPath(collection, \n                     from=\"node1\", \n                     to=\"node2\",\n                     edge=\"colA=colB, colC=colD\",\n                     threads=\"6\",\n                     partitionSize=\"300\", \n                     fq=\"limiting query\", \n                     maxDepth=\"10\")\n\n\n\nas well as situations where the nodes have the same field names\n\n\nshortestPath(collection, \n                     from=\"node1\", \n                     to=\"node2\",\n                     edge=\"colA=colB, colC\",\n                     threads=\"6\",\n                     partitionSize=\"300\", \n                     fq=\"limiting query\", \n                     maxDepth=\"10\")\n\n ",
            "id": "comment-15216038"
        },
        {
            "date": "2016-03-29T14:06:38+0000",
            "author": "Dennis Gove",
            "content": "Would it be reasonable to give another thought to the structure of this? I was thinking it could take the same route as the ReduceStream where one can do all kinds of reductions on the tuples. Would it be possible to create a GraphStream and apply operations (don't know if 'operation' is the correct term for this) over the graph, with one such operation being ShortestPath? ",
            "id": "comment-15216049"
        },
        {
            "date": "2016-03-29T14:24:01+0000",
            "author": "Joel Bernstein",
            "content": "I think we can approach graph work in much the same way we approached relational algebra. We have some specific streams that do joins etc... and we have a ReducerStream which can do lot's of relational algebra on it's own. Eventually the ReducerStream could power some of the joins like it currently powers unique.\n\nWith graph queries we can have some specific expressions and a generic reduce expression as well.  ",
            "id": "comment-15216080"
        },
        {
            "date": "2016-03-29T14:26:19+0000",
            "author": "Joel Bernstein",
            "content": "What the syntax is trying to express is \"traverse this edge\".\n\nThe \"=\" sign implies that the nodes in the edge are equal. ",
            "id": "comment-15216084"
        },
        {
            "date": "2016-03-29T14:30:08+0000",
            "author": "Dennis Gove",
            "content": "I guess my thinking is that an edge exists when two nodes (1 and 2) have the same value for some field or fields (A and B). That is, if node1.colA = node2.colB then there exists an edge between node1 and node2. With this, the `edge` parameter defines what constitutes the existence of an edge between two nodes. ",
            "id": "comment-15216089"
        },
        {
            "date": "2016-03-29T14:32:23+0000",
            "author": "Joel Bernstein",
            "content": "Ok, I do see how the columns are \"=\" during join, so it does makes sense. I'll change the syntax. ",
            "id": "comment-15216094"
        },
        {
            "date": "2016-03-29T14:45:20+0000",
            "author": "Dennis Gove",
            "content": "I wasn't suggesting that the ReduceStream be used for graph traversals, just that a similar approach to the design be used. For example,\n\n\ngraph(\n  collection,\n  set=node([some q and fq defining the nodes to include in graph]),\n  selector=shortestPath(\n     from=node([some q and fq defining a starting node or nodes]),\n     to=node([some q and fq defining an ending node or nodes]),\n     edge=\"fieldA=fieldB\"\n  )\n)\n\n\n\nor use a stream as the input set with\n\n\ngraph(\n  streamOfTuples,\n  selector=shortestPath(\n     from=node([some q and fq defining a starting node or nodes]),\n     to=node([some q and fq defining an ending node or nodes]),\n     edge=\"fieldA=fieldB\"\n  )\n)\n\n ",
            "id": "comment-15216113"
        },
        {
            "date": "2016-03-29T14:52:30+0000",
            "author": "Joel Bernstein",
            "content": "I was suggesting that we can have both a generic approach to graph traversals (like the ReducerStream) and specific graph expressions. Eventually the generic approach could power the specific expression.\n\nIn the beginning it's easier to start with a couple of specific uses cases to iron out the mechanics of how to do the distributed traversals. This will help us come up with a generic approach.\n ",
            "id": "comment-15216129"
        },
        {
            "date": "2016-03-29T18:33:28+0000",
            "author": "Joel Bernstein",
            "content": "Patch with the StreamExpression methods implemented and Stream Exrpression test cases ",
            "id": "comment-15216584"
        },
        {
            "date": "2016-03-29T19:03:05+0000",
            "author": "Joel Bernstein",
            "content": "I think this almost ready to commit. As Dennis Gove points out it's not a generic solution for graph traversals, but it's a useful recipe that probably deserves a top level expression. As more generic approaches are developed we can always swap out the implementation to use generic solutions.\n\nThe next step I believe would be to implement a nodes() expression, which would use the same parallel joining technique used in this ticket. But instead of finding the shortest path it will simply iterate the nodes and track the traversal. This could be wrapped by other streams to operate over.\n\nThe nodes() expression will also be needed to support Tinkerpop/Gremlin, which is an important goal as well. ",
            "id": "comment-15216649"
        },
        {
            "date": "2016-03-30T17:30:31+0000",
            "author": "Joel Bernstein",
            "content": "New patch which returns all of the shortest paths. Manual tests look good but more unit tests are needed with this algorithm. ",
            "id": "comment-15218402"
        },
        {
            "date": "2016-03-31T19:13:29+0000",
            "author": "Joel Bernstein",
            "content": "Added GraphExpressionTests returning all the shortest paths found. ",
            "id": "comment-15220497"
        },
        {
            "date": "2016-03-31T20:19:12+0000",
            "author": "Joel Bernstein",
            "content": "OK, feel pretty good about this. Committing to trunk shortly. ",
            "id": "comment-15220598"
        },
        {
            "date": "2016-03-31T20:19:51+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 3500b45d6d28253d44e48ff8e444774a5fb3ace0 in lucene-solr's branch refs/heads/master from jbernste\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=3500b45 ]\n\nSOLR-8888: Add shortestPath Streaming Expression ",
            "id": "comment-15220600"
        },
        {
            "date": "2016-03-31T20:30:13+0000",
            "author": "ASF subversion and git services",
            "content": "Commit ffdfceba5371b1c3f96b44c727025f2f27bbf12b in lucene-solr's branch refs/heads/branch_6x from jbernste\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=ffdfceb ]\n\nSOLR-8888: Add shortestPath Streaming Expression ",
            "id": "comment-15220616"
        },
        {
            "date": "2016-04-01T00:51:15+0000",
            "author": "ASF subversion and git services",
            "content": "Commit f8ae0d0deb0f2a8c035c89dbf118646531f60f71 in lucene-solr's branch refs/heads/master from jbernste\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=f8ae0d0 ]\n\nSOLR-8888: Update CHANGES.txt ",
            "id": "comment-15220942"
        },
        {
            "date": "2016-04-01T00:53:50+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 586afc3db117eabb31e2572da9bd3b7665cdccc8 in lucene-solr's branch refs/heads/branch_6x from jbernste\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=586afc3 ]\n\nSOLR-8888: Update CHANGES.txt ",
            "id": "comment-15220944"
        },
        {
            "date": "2016-05-09T03:01:10+0000",
            "author": "Cao Manh Dat",
            "content": "I just wanna refactor the code a little bit.\nJoel Bernstein Please review. ",
            "id": "comment-15275890"
        },
        {
            "date": "2016-05-09T13:18:35+0000",
            "author": "Joel Bernstein",
            "content": "Thanks for the patcht! Let's create a new for ticket for this though, something like \"refactor shortestPath streaming expression\". ",
            "id": "comment-15276343"
        }
    ]
}