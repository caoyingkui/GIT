{
    "id": "SOLR-1508",
    "title": "Use field cache when creating response, if available and configured.",
    "details": {
        "affect_versions": "1.3",
        "status": "Reopened",
        "fix_versions": [],
        "components": [
            "search"
        ],
        "type": "New Feature",
        "priority": "Major",
        "labels": "",
        "resolution": "Unresolved"
    },
    "description": "Allow the user to configure a field to be returned to the user from the field cache, instead of getting the field from disk. Relies on lucene-1981",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "author": "Yonik Seeley",
            "id": "comment-12765159",
            "date": "2009-10-13T17:27:02+0000",
            "content": "We're not going to be updating Lucene as much as we have in the past, so putting something in Lucene just for a Solr feature isn't a great idea.\nAnyway, as I commented on LUCENE-1981, all of the public APIs exist to do this, we don't need any changes in Lucene for this feature. "
        },
        {
            "author": "Erik Hatcher",
            "id": "comment-12765166",
            "date": "2009-10-13T17:47:33+0000",
            "content": "Agreed with Yonik - would like to see this wired purely into Solr where it retrieves stored values.  This might require some slight refactoring of the response writers. "
        },
        {
            "author": "Tom Hill",
            "id": "comment-12765214",
            "date": "2009-10-13T20:08:43+0000",
            "content": "The key thing I was trying to achieve here was to use per-segment caches. \n\nTo do this, I think I need to know which SegmentReader is handling the segment containing the doc I care about. Unfortunately, DirectoryReader.readerIndex() and DirectoryReader.starts() are both private, and I think I need this information to get the cache on a per-segment basis. Corrections welcome!\n\nI went with modifying IndexReader, as the IndexReader hides the implementation. With this approach, the callers code works, even if the implementation changes; if someone is wraps your DirectoryReader in a FilterReader, you still just called getFieldCachedValue.\n\nAny alternate suggestions for getting per-segment caches?\n\nThanks!\n\n "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12765228",
            "date": "2009-10-13T20:48:41+0000",
            "content": "IndexReader has getSequentialSubreaders(), and I think in Lucene trunk the offsets and readers are also available from IndexSearcher. SolrIndexReader also gives you access to the list of offsets and subreaders. But the lucene part of this is easy... as usual, the hard part is good interfaces and integration... coming up with the right way to express it all.\n\nThis also seems like it could be related to SOLR-1298... one should be able to return the value of any arbitrary function (even those of non-indexed fields such as ExternalFileField), not just the straight field value.\n\nOther things to think about:\n\n\thow does this fit in with proposed interfaces that let one store \"stored fields\" somewhere else, like a DB?\n\thow does this fit in with future column stored fields? future payload stored fields?\n\tif a field is stored and indexed, and a user requests the complete document, what do we use for the FieldCache field?\n\tmulti-valued support using UnInvertedField?\n\tfl=*, does it select all of these fields, or does one have to explicitly ask?\n\thow to distinguish a field that has a value from one that doesn't (not all FieldCache entries can tell you this)\n\n\n\nAnyway, my main suggestion is that we start with the hard part - the interfaces (proposed HTTP args, schema.xml markup, etc)  "
        },
        {
            "author": "Tom Hill",
            "id": "comment-12765288",
            "date": "2009-10-13T22:46:12+0000",
            "content": "Starting with the hard part makes some sense, not sure if we should continue that part here, or in SOLR-1298.\n\nComments on \"things to think about\"\n\n1 & 2) I think this (SOLR-1508) would work as one implementation of a mechanism to get things other than 'normal' fields (cache, function queries). It makes sense for there to be an overall common interface for this.\n\n3) a) In this implementation, the user configures an alternate name for the field. (e.g. foobar_cached). If they ask for that, they get the cached version. If they use the real name, they retrieve as usual. b) I think it would make sense to allow the cache to be configurable to cache a stored field or an indexed term, but I have not done this yet.\n\n4) I can't comment on this one, as I haven't looked at uninvertedField.\n\n5) For this use case, I think it makes sense for fl=* to get only the original document. If you are getting any other fields, you have to go to the disk, so the advantage of the cache will largely be lost. But I do think this also might be a reasonable default for the other cases. That is, \"Ask for it, if you want something extra\"\n\n6) I don't have an answer on this one yet. I'm working with Strings right now.\n\nAnd, as for this implementation, you are right, IndexSearcher does have start information. I'd looked for accessors, I hadn't thought to look for other places the same info was recreated.\n\nAnd you could then call DirectoryReader.readerIndex(), passing in starts[]. But the implementation of gatherSubreaders is recursive, and the implementation in DirectoryReader is not, and I'm really not clear if that would matter. It just seems a lot more stable to have each class do its own look offset calculations and segment look-up.\n\nAlso, If you wanted to not have the caches baked into IndexReader's api, we could make a method that returns the relevant reader and offset and then use that to look up in the cache externally. It's a little more general, but a little more code, so I initially went with the simpler approach. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13835671",
            "date": "2013-11-30T12:41:19+0000",
            "content": "2013 Old JIRA cleanup "
        }
    ]
}