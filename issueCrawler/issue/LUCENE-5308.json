{
    "id": "LUCENE-5308",
    "title": "explore per-dimension fixed-width ordinal encoding",
    "details": {
        "components": [
            "modules/facet"
        ],
        "fix_versions": [],
        "affect_versions": "None",
        "priority": "Major",
        "labels": "",
        "type": "Improvement",
        "resolution": "Unresolved",
        "status": "Open"
    },
    "description": "I've been testing performance of Solr vs Lucene facets, and one area\nwhere Solr's \"fcs\" method shines (low RAM, high faceting perf) is in\nlow-cardinality dimensions.\n\nI suspect the gains are because with the field-cache entries the ords\nare encoded in \"column-stride\" form, and are private to that dim (vs\nfacet module's shared ord space).\n\nSo I thought about whether we could do something like this in the\nfacet module ...\n\nI.e., if we know certain documents will have a specific set of\nsingle-valued dimensions, we can pick an encoding format for the\nper-doc byte[] \"globally\" for all such documents, and use private ord\nspace per-dimension to improve compression.\n\nThe basic idea is to pre-assign up-front (before the segment is\nwritten) which bytes belong to which dim.  E.g., date takes bytes 0-1\n(<= than 65536 unique labels), imageCount takes byte 2 (<= 256\nunique labels), username takes bytes 3-6 (<= 16.8 M unique labels),\netc.  This only works for single-valued dims, and only works if all\ndocs (or at least an identifiable subset?) have all dims.\n\nTo test this idea, I made a hacked up prototype patch; it has tons of\nlimitations so we clearly can't commit it, but I was able to test full\nwikipedia en with 6 facet dims (date, username, refCount, imageCount,\nsectionCount, subSectionCount, subSubSectionCount).\n\nTrunk (base) requires 181 MB of net doc values to hold the facet ords,\nwhile the patch requires 183 MB.\n\nPerf:\n\n\nReport after iter 19:\n                    Task    QPS base      StdDev    QPS comp      StdDev                Pct diff\n                 Respell       54.30      (3.1%)       54.02      (2.7%)   -0.5% (  -6% -    5%)\n         MedSloppyPhrase        3.58      (5.6%)        3.60      (6.0%)    0.6% ( -10% -   12%)\n            OrNotHighLow       63.58      (6.8%)       64.03      (6.9%)    0.7% ( -12% -   15%)\n        HighSloppyPhrase        3.80      (7.4%)        3.84      (7.1%)    1.1% ( -12% -   16%)\n             LowSpanNear        8.93      (3.5%)        9.09      (4.6%)    1.8% (  -6% -   10%)\n               LowPhrase       12.15      (6.4%)       12.43      (7.2%)    2.3% ( -10% -   17%)\n              AndHighLow      402.54      (1.4%)      425.23      (2.3%)    5.6% (   1% -    9%)\n         LowSloppyPhrase       39.53      (1.6%)       42.01      (1.9%)    6.3% (   2% -    9%)\n             MedSpanNear       26.54      (2.8%)       28.39      (3.6%)    7.0% (   0% -   13%)\n              HighPhrase        4.01      (8.1%)        4.30      (9.7%)    7.4% (  -9% -   27%)\n                  Fuzzy2       44.01      (2.3%)       47.43      (1.8%)    7.8% (   3% -   12%)\n            OrNotHighMed       32.64      (4.7%)       35.22      (5.5%)    7.9% (  -2% -   19%)\n                  Fuzzy1       62.24      (2.1%)       67.35      (1.9%)    8.2% (   4% -   12%)\n               MedPhrase      129.06      (4.9%)      141.14      (6.2%)    9.4% (  -1% -   21%)\n              AndHighMed       27.71      (0.7%)       30.32      (1.1%)    9.4% (   7% -   11%)\n            HighSpanNear        5.15      (3.5%)        5.63      (4.2%)    9.5% (   1% -   17%)\n             AndHighHigh       24.98      (0.7%)       27.89      (1.1%)   11.7% (   9% -   13%)\n           OrNotHighHigh       15.13      (2.0%)       17.90      (2.6%)   18.3% (  13% -   23%)\n                Wildcard        9.06      (1.4%)       10.85      (2.6%)   19.8% (  15% -   24%)\n           OrHighNotHigh        8.84      (1.8%)       10.64      (2.6%)   20.3% (  15% -   25%)\n              OrHighHigh        3.73      (1.6%)        4.51      (2.4%)   20.9% (  16% -   25%)\n               OrHighLow        5.22      (1.5%)        6.34      (2.5%)   21.4% (  17% -   25%)\n            OrHighNotLow        8.94      (1.6%)       10.95      (2.5%)   22.5% (  18% -   26%)\n                 Prefix3       27.61      (1.2%)       33.90      (2.3%)   22.8% (  19% -   26%)\n               OrHighMed       11.72      (1.6%)       14.56      (2.3%)   24.3% (  20% -   28%)\n            OrHighNotMed       14.74      (1.5%)       18.34      (2.2%)   24.5% (  20% -   28%)\n                 MedTerm       26.37      (1.2%)       32.85      (2.7%)   24.6% (  20% -   28%)\n                  IntNRQ        2.61      (1.2%)        3.25      (3.0%)   24.7% (  20% -   29%)\n                HighTerm       19.69      (1.3%)       25.33      (3.0%)   28.7% (  23% -   33%)\n                 LowTerm      131.50      (1.3%)      170.49      (3.0%)   29.7% (  25% -   34%)\n\n\n\nI think the gains are sizable, and the increase in index size quite\nminor (in another test with fewer dims I saw the index size get a bit\nsmaller) ... at least for this specific test.\n\nHowever, finding a clean solution here will be tricky...",
    "attachments": {
        "LUCENE-5308.patch": "https://issues.apache.org/jira/secure/attachment/12610456/LUCENE-5308.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2013-10-26T18:27:03+0000",
            "content": "Totally hacked up, but I think working, patch. ",
            "author": "Michael McCandless",
            "id": "comment-13806149"
        },
        {
            "date": "2013-10-26T19:09:41+0000",
            "content": "It's a nice idea. You could probably do the \"right\" thing if you extend FacetFields and override the CountingListBuilder to generate this fixed-encoding. And instead of FacetsAccumlator write a FacetsAggregator which decodes per-document, and then you get top-K computation for free .. I think?\n\nI guess if an app truly knows it has a fixed taxonomy, and that every document contains all facets, this could be useful. Maybe instead of asking the app to specify uniqueValueCount we write a FixedTaxonomyWriter where the app has to build once before it adds any document, with all categories, and we compute uniqueValueCount ourselves?\n\nI mean, this could eliminate app making mistakes - e.g. FixedFacetFields would not even get a TaxonomyWriter, so if app tries to find a CategoryPath which wasn't added already, it hits a hard exception. Hmm, now it also hits it if the uniqueValueCount smaller than an ord a CP gets, but I think it makes things more clear that you must create the taxonomy up front.\n\nAlthough, I can see an app saying \"I don't know which categories I'll see, but there will never be more than X of them\" ... so maybe a uniqueValueCount constraint is good as well.\n\nNet/net, this is a very limited solution which an app needs to think about before using it. If it matches app's needs, it can speed things up. I wonder what the speedups will be when it's fully \"productized\", and whether it will still be worth keeping in the code base.\n\nI do think though that we could think about per CategoryList ordinal space (separate issue) by default. It requires heavy changes to the taxonomy index and supporting code, but maybe it will be worth it too (compression-wise and hopefully decoding time too). ",
            "author": "Shai Erera",
            "id": "comment-13806157"
        },
        {
            "date": "2013-10-26T19:14:30+0000",
            "content": "Another comment \u2013 instead of per dimension TaxoWriter, I wonder if we could write a FixedTaxoWriter/Reader which manages the per-dimension ordinals internally (and even assert that you add the right amount). This then would become a full solution:\n\n\n\tFixedTaxonomyWriter/Reader\n\tFixedFacetFields (extends FacetFields)\n\tFixedFacetsAggregator\n\n\n\nJust a thought. ",
            "author": "Shai Erera",
            "id": "comment-13806158"
        },
        {
            "date": "2013-10-26T20:51:08+0000",
            "content": "One nice side effect of the fixed-width encoding is it'd be simple to\nbuild specialized decoders; it'd be done once (globally) after opening\na new reader, using asm.\n\nTo test this perf gain I hand-specialized for my current index, with\nthis:\n\n\n        // imageCount\n        counts[bytes[offset] & 0xFF]++;\n        // refCount\n        counts[234 + (bytes[offset+1] & 0xFF)]++;\n        // sectionCount\n        counts[490 + (bytes[offset+2] & 0xFF)]++;\n        // subSectionCount\n        counts[713 + (bytes[offset+3] & 0xFF)]++;\n        // subSubSectionCount\n        counts[950 + (bytes[offset+4] & 0xFF)]++;\n        // date\n        counts[1193 + ((bytes[offset+5] & 0xFF)<<8) + (bytes[offset+6] & 0xFF)]++;\n        // userName\n        counts[4473 + ((bytes[offset+7] & 0xFF)<<16) + ((bytes[offset+8] & 0xFF)<<8) + (bytes[offset+9]&0xFF)]++;\n\n\n\nAnd it gave a nice further speedup:\n\n\n                    Task    QPS base      StdDev    QPS comp      StdDev                Pct diff\n                 Respell       54.06      (4.1%)       52.89      (3.3%)   -2.2% (  -9% -    5%)\n            OrNotHighLow       62.13      (6.9%)       62.79      (7.7%)    1.1% ( -12% -   16%)\n         MedSloppyPhrase        3.58      (6.5%)        3.63      (7.1%)    1.4% ( -11% -   16%)\n        HighSloppyPhrase        3.86      (8.6%)        3.93      (9.7%)    1.7% ( -15% -   21%)\n             LowSpanNear        9.06      (4.3%)        9.21      (4.8%)    1.7% (  -7% -   11%)\n               LowPhrase       12.30      (6.4%)       12.61      (7.0%)    2.5% ( -10% -   16%)\n              AndHighLow      401.45      (1.4%)      429.51      (1.9%)    7.0% (   3% -   10%)\n                  Fuzzy1       62.28      (2.2%)       66.91      (2.3%)    7.4% (   2% -   12%)\n         LowSloppyPhrase       39.37      (1.7%)       42.77      (2.2%)    8.6% (   4% -   12%)\n             MedSpanNear       26.77      (3.1%)       29.15      (3.2%)    8.9% (   2% -   15%)\n            OrNotHighMed       32.14      (4.8%)       35.52      (6.4%)   10.5% (   0% -   22%)\n              HighPhrase        4.07      (8.1%)        4.54     (10.0%)   11.7% (  -5% -   32%)\n              AndHighMed       27.72      (1.0%)       31.10      (0.8%)   12.2% (  10% -   14%)\n                  Fuzzy2       43.95      (2.4%)       50.09      (2.7%)   14.0% (   8% -   19%)\n             AndHighHigh       25.06      (1.0%)       28.58      (0.9%)   14.0% (  12% -   16%)\n            HighSpanNear        5.19      (3.5%)        6.03      (4.4%)   16.3% (   8% -   25%)\n               MedPhrase      129.83      (4.8%)      151.45      (6.8%)   16.7% (   4% -   29%)\n                 Prefix3       27.68      (1.1%)       34.91      (1.2%)   26.1% (  23% -   28%)\n           OrNotHighHigh       15.03      (2.1%)       19.11      (4.1%)   27.1% (  20% -   34%)\n                 MedTerm       26.60      (1.5%)       35.40      (3.1%)   33.1% (  27% -   38%)\n                Wildcard        9.05      (1.8%)       12.15      (2.0%)   34.2% (  29% -   38%)\n            OrHighNotMed       14.68      (1.6%)       19.84      (3.4%)   35.2% (  29% -   40%)\n           OrHighNotHigh        8.79      (2.0%)       11.91      (4.3%)   35.5% (  28% -   42%)\n                HighTerm       19.85      (1.7%)       26.98      (3.3%)   35.9% (  30% -   41%)\n                 LowTerm      132.41      (1.4%)      180.49      (3.9%)   36.3% (  30% -   42%)\n               OrHighMed       11.67      (1.5%)       16.36      (3.4%)   40.2% (  34% -   45%)\n              OrHighHigh        3.70      (1.9%)        5.34      (4.4%)   44.3% (  37% -   51%)\n            OrHighNotLow        8.89      (1.7%)       12.90      (4.3%)   45.2% (  38% -   52%)\n               OrHighLow        5.20      (1.7%)        7.57      (4.2%)   45.7% (  39% -   52%)\n                  IntNRQ        2.61      (1.1%)        4.03      (1.7%)   54.4% (  50% -   57%)\n\n ",
            "author": "Michael McCandless",
            "id": "comment-13806164"
        }
    ]
}