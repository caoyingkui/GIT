{
    "id": "SOLR-665",
    "title": "FIFO Cache (Unsynchronized): 9x times performance boost",
    "details": {
        "affect_versions": "1.3",
        "status": "Closed",
        "fix_versions": [],
        "components": [],
        "type": "Improvement",
        "priority": "Major",
        "labels": "",
        "resolution": "Duplicate"
    },
    "description": "Attached is modified version of LRUCache where \n1. map = new LinkedHashMap(initialSize, 0.75f, false) - so that \"reordering\"/true (performance bottleneck of LRU) is replaced to \"insertion-order\"/false (so that it became FIFO)\n2. Almost all (absolutely unneccessary) synchronized statements commented out\n\nSee discussion at http://www.nabble.com/LRUCache---synchronized%21--td16439831.html\n\nPerformance metrics (taken from SOLR Admin):\n\nLRU\nRequests: 7638\nAverage Time-Per-Request: 15300\nAverage Request-per-Second: 0.06\n\nFIFO:\nRequests: 3355\nAverage Time-Per-Request: 1610\nAverage Request-per-Second: 0.11\n\nPerformance increased 9 times which roughly corresponds to a number of CPU in a system, http://www.tokenizer.org/ (Shopping Search Engine at Tokenizer.org)\n\nCurrent number of documents: 7494689\nname: \t filterCache  \nclass: \torg.apache.solr.search.LRUCache  \nversion: \t1.0  \ndescription: \tLRU Cache(maxSize=10000000, initialSize=1000)  \nstats: \tlookups : 15966954582\nhits : 16391851546\nhitratio : 0.102\ninserts : 4246120\nevictions : 0\nsize : 2668705\ncumulative_lookups : 16415839763\ncumulative_hits : 16411608101\ncumulative_hitratio : 0.99\ncumulative_inserts : 4246246\ncumulative_evictions : 0 \n\n\n\nThanks",
    "attachments": {
        "ConcurrentLRUWeakCache.java": "https://issues.apache.org/jira/secure/attachment/12387161/ConcurrentLRUWeakCache.java",
        "ConcurrentFIFOCache.java": "https://issues.apache.org/jira/secure/attachment/12387083/ConcurrentFIFOCache.java",
        "ConcurrentLRUCache.java": "https://issues.apache.org/jira/secure/attachment/12387089/ConcurrentLRUCache.java",
        "SimplestConcurrentLRUCache.java": "https://issues.apache.org/jira/secure/attachment/12387200/SimplestConcurrentLRUCache.java",
        "FIFOCache.java": "https://issues.apache.org/jira/secure/attachment/12387002/FIFOCache.java"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Fuad Efendi",
            "id": "comment-12617357",
            "date": "2008-07-28T03:29:08+0000",
            "content": "I renamed to FIFOCache just before opening an issue; in a local system it is (modified) LRUCache so that filterCache has reference to 'old' name... "
        },
        {
            "author": "Fuad Efendi",
            "id": "comment-12617359",
            "date": "2008-07-28T04:34:01+0000",
            "content": "Almost forgot: I am estimating performance gains basing on real application in-production, multithreaded, Tomcat 6.0.16 & JRockit R27 (Java 6) & SLES10 & two quad-core Opteron 2350 (8 CPUs total) & 25Gb for SOLR...\nAnd, first queries run a long, more than a minute (warming up caches with faceted query id:[* TO *]) average Time-Per-Request decreases over time and it is now 1591.5232 giving 10x performance boost.\nFacets are highly distributed as you can see from website and filterCache... HTTP caching is supported - to see real timing you should execute real queries...\nConcurrentHashMap is not applicable - we are not modifying cached item indeed... FIFO is without 'Out' if we have enough memory. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12617420",
            "date": "2008-07-28T13:29:31+0000",
            "content": "This implementation isn't thread safe (due the the removed synchronization). "
        },
        {
            "author": "Noble Paul",
            "id": "comment-12617422",
            "date": "2008-07-28T13:37:49+0000",
            "content": "Why do we have almost the entire get() method synchronized on the map in LRUCache . \nstats increment can possibly be put out of synchronized  "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12617427",
            "date": "2008-07-28T13:52:26+0000",
            "content": "Why do we have almost the entire get() method synchronized on the map in LRUCache . \n\nIt simplified the code and reduced the number of branches.  What's your proposed version?\nHere is the current method:\n\n  public Object get(Object key) {\n    synchronized (map) {\n      Object val = map.get(key);\n      if (state == State.LIVE) {\n        // only increment lookups and hits if we are live.\n        lookups++;\n        stats.lookups.incrementAndGet();\n        if (val!=null) {\n          hits++;\n          stats.hits.incrementAndGet();\n        }\n      }\n      return val;\n    }\n  }\n\n "
        },
        {
            "author": "Noble Paul",
            "id": "comment-12617431",
            "date": "2008-07-28T14:06:45+0000",
            "content": "I guess this is safe and faster\n\npublic Object get(Object key) {\n    synchronized (map) {\n      Object val = map.get(key);\n      if (state == State.LIVE) {\n        // only increment lookups and hits if we are live.\n        lookups++;\n      }\n    }\n      stats.lookups.incrementAndGet();\n      if (val != null) {\n        //hits++; this must be removed\n        stats.hits.incrementAndGet();\n      }\n      return val;\n  }\n\n\n\nlet us remove the field hits and use stats.hits wherever we need it "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12617436",
            "date": "2008-07-28T14:35:23+0000",
            "content": "Your version changes what the method does in a couple of respects though.\nlet us remove the field hits and use stats.hits wherever we need it\nstats.hits is for all caches of this type (it's shared across searchers).  hits is local to this cache instance. "
        },
        {
            "author": "Fuad Efendi",
            "id": "comment-12617441",
            "date": "2008-07-28T14:56:49+0000",
            "content": "Regarding Thread Safety:\n\n\n\tyes, we need synchronized get() method for LRU cache because each access reorders LinkedHashMap.\n\tabsolutely no need to synchronize get() method for FIFO!\n\tprobably we need to deal with insertion, but do not synchronize it: instead, extend LinkedHashMap and make some 'removal' synchronized...  With caches large enough to store all object we do not need it. We probably do not need to synchronize 'removal' at all - it removes entry but does not remove/finalize referenced object.\n\n\n\nFrom JavaDoc: \"Note that this implementation is not synchronized. If multiple threads access a linked hash map concurrently, and at least\none of the threads modifies the map structurally, it must be  synchronized externally.\"\nHowever, we do not modify cache structurally during iteration loop or any other 'structure' access (we do not use Iterator!) - so, advice from JavaDoc is not applicable.\n\nWe should synchronize only removeEntryForKey of HashMap; unfortunately we can't do it without rewriting HashMap. Probably we can use ConcurrentHashMap as a base class of LinkedHashMap, but I don't know answer yet... I am guessing that unsynchronized entry removal won't be significant issue in multithreaded environment. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12617442",
            "date": "2008-07-28T15:10:54+0000",
            "content": "absolutely no need to synchronize get() method for FIFO!\n\nA cache is not a read-only object.  Gets need to be synchronized because other threads can be changing the cache.\nIf anyone wants to learn more about thread safety and concurrency, I'd recommend \"Java concurrency in practice\"\nhttp://www.javaconcurrencyinpractice.com/ "
        },
        {
            "author": "Fuad Efendi",
            "id": "comment-12617443",
            "date": "2008-07-28T15:13:02+0000",
            "content": "\n\tClasses from java.util.concurrent.atomic designed NOT to be synchronized, per-instance stats should be replaced to AtomicLong instead of long:\n{{  private long lookups;\n  private long hits;\n  private long inserts;\n  private long evictions;}}\n\tget() method of FIFO do not need any synchronization\n\tget() method of LRU reorers LinkedHashMap, unsynchronized access may cause orphan Entry objects\n\tsynchronized insertion for FIFO won't cause performance degradation because get() is unsynchronized.\n\n "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12617444",
            "date": "2008-07-28T15:18:16+0000",
            "content": "per-instance stats should be replaced to AtomicLong instead of long.\n\nSince we need to synchronize anyway, it's more efficient to just stick things like hits++ inside the sync block instead of having a separate AtomicLong. "
        },
        {
            "author": "Fuad Efendi",
            "id": "comment-12617445",
            "date": "2008-07-28T15:19:28+0000",
            "content": "bq. absolutely no need to synchronize get() method for FIFO!\n\nA cache is not a read-only object. Gets need to be synchronized because other threads can be changing the cache.\n\nI am familiar with Doug Lea's findings (he wrote his book in 1996, and it became part of java.util.concurrent after 10(!!!) years). \n\nchanging the cache\n\n\twhat is 'cache change'?\nChanging the stored Key, changing the referenced object - never ever happens in SOLR. Removal of object - yes. More correctly: removal of key. get(MyKey) will return null OR will return MyValue, and \"ConcurentCacheModification\" will never be thrown in SOLR (we are not using Iterator!). We can insert concurrently the same (key, value) pairs - not a problem.\n\n "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12617447",
            "date": "2008-07-28T15:30:04+0000",
            "content": "what is 'cache change'?\n\nAdding a new key/value pair to the cache, or removal of a key/value pair from the cache.\n\nget(MyKey) will return null OR will return MyValue, and \"ConcurentCacheModification\" will never be thrown in SOLR\n\nThis would only be under very specific usage patterns - everything pre-cached, and no adds or removes once the cache is \"LIVE\" (accessed by more than one thread concurrently).\nConcurentModification is best effort, not guaranteed.  You can still get incorrect results or other exceptions from code that isn't thread safe, even when a ConcurentModification isn't thrown. "
        },
        {
            "author": "Sean Timm",
            "id": "comment-12617448",
            "date": "2008-07-28T15:33:50+0000",
            "content": "Fuad--\n\nI agree with Yonik here.  From the HashMap Javadoc:\n\nIf multiple threads access this map concurrently, and at least one of the threads modifies the map structurally, it must be synchronized externally. (A structural modification is any operation that adds or deletes one or more mappings; merely changing the value associated with a key that an instance already contains is not a structural modification.) "
        },
        {
            "author": "Fuad Efendi",
            "id": "comment-12617454",
            "date": "2008-07-28T16:05:27+0000",
            "content": "If multiple threads access this map concurrently, and at least one of the threads modifies the map structurally, it must be synchronized externally. (A structural modification is any operation that adds or deletes one or more mappings; merely changing the value associated with a key that an instance already contains is not a structural modification.)\n\nI already commented it. Just try to avoid 'books' and 'authors', also try to find meaning in JavaDocs and try to browse JavaSource instead...\n\n\n\tstructural  modification, related ConcurrentModificationException, and related Iterator: not applicable to SOLR Cache.\n\n\n\nWill never happen. We need to synchronize inserts because each insert may calculate size and remove 'eldest' entry, and we need to avoid OOMs. We need to synchronize retrieves for LRU because 'Linked' HashMap (with Access Order) will change links (will reorder Map). And we do not need to synchronize retrieves from Insertion-Ordered LinkedHashMap (FIFO). It is classic... i'd like to research more java.util.concurrent "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12617458",
            "date": "2008-07-28T16:22:34+0000",
            "content": "Closing, since it's pretty much impossible to avoid all forms of synchronization and memory barriers for get() on a shared Map object. "
        },
        {
            "author": "Fuad Efendi",
            "id": "comment-12617466",
            "date": "2008-07-28T16:43:32+0000",
            "content": "Why? We have PoC at least, and we know the bottleneck! \nWe need improvement: avoid some synchronization; it is extremely easy with FIFO. We may try to improve LRU too.\nNot everything in JAVA is extremely good: for instance, synchronization. Even for single-threaded application, it needs additionally 600 CPU cycles (I've read it somewhere for SUN Java 1.3 on Windows)\n\nYonik, please allow some time to think / to discuss. \n\nI'll try also to provide 'concurrent' LRU; but this issue is FIFO related. "
        },
        {
            "author": "Fuad Efendi",
            "id": "comment-12617469",
            "date": "2008-07-28T16:50:10+0000",
            "content": "get() method do not need to be synchronized for FIFO cache. Unsynchronized object retrieval is not structural modification of Insertion-Ordered LinkedHashMap. Unsynchronized cache improves performance of multithreaded applications linear to number of CPUs. "
        },
        {
            "author": "Noble Paul",
            "id": "comment-12617479",
            "date": "2008-07-28T17:25:18+0000",
            "content": "OK.Let us try to study the failure cases .\nget() does no state modification. \n\nSo if the get is unsynchronized the worst case scenario is that we may get an Exception (I dunno what ConcurrentModificationException? ArrayIndexOutOfBoundsException? ). How often does it happen? What is the probability?\n\nWhat is the big deal ?(the system won't crash). We can catch the Exception and return null as if the entry was not found . That means that Solr may have to recompute results where it did not have to (this is a cost). \n\nhere we totally eliminated the cost of synchronization (benefit). I guess if you do a cost benefit analysis this does not turn out to be as bad as it is projected to be. \n\nAnd after all the user is knowingly using this fully aware of the cost. is there anything else I have not considered  "
        },
        {
            "author": "Fuad Efendi",
            "id": "comment-12617481",
            "date": "2008-07-28T17:27:49+0000",
            "content": "...and at least one of the threads modifies the map structurally, it <i>must</i> be synchronized externally.\n\n\n\tso that thread running on insert must be synchronized and not thread running on retrieve. Again, we need synchronize insert only to avoid memory leaks, not more. SOLR does not iterate Map.\n\n "
        },
        {
            "author": "Fuad Efendi",
            "id": "comment-12617482",
            "date": "2008-07-28T17:30:56+0000",
            "content": "ConcurrentModificationException is thrown only when we iterate Map and another thread modified structure; with LRU each get() modifies structure, with FIFO - only inserts... "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12617490",
            "date": "2008-07-28T17:42:48+0000",
            "content": "I think Fuad has a point. In an Insertion ordered LinkedHashMap, get makes no structural modification and if we synchronize put/remove, we should be fine. The cache warming is already thread-safe and we don't have iterators anywhere. Am I missing something here? "
        },
        {
            "author": "Mark Miller",
            "id": "comment-12617509",
            "date": "2008-07-28T18:41:45+0000",
            "content": "Sent to the mailing List:\n\n>>Depends on if you want to go by the javadoc or not - it says that if any of the threads accessing the map concurrently make a structural change, the map must be synchronized.  It's clear that get does not >>make a structural change when using  insertion order,  but can  any other threads possibly make a mapping change while calling get? Sounds like yes, and so the contract would seem to indicate you >>synchronize...\n\n>>Put can modify shared variables that get accesses - sounds like dangerous ground to me. If it works, its got to be sneaky enough to warrant code smell...\n\n>>- Mark\n\nFurther:\n\nHere is just one of possibly many problems - a put call can resize and make an entirely new table array. A get call can do something like the following with the table array:\n\ntable[indexFor(hash, table.length)\n\nDo to execution reordering / memory barriers, would seem to me that the table being indexed into and the table.length may not be the values you were hoping for...\n "
        },
        {
            "author": "Mike Klaas",
            "id": "comment-12617512",
            "date": "2008-07-28T18:58:32+0000",
            "content": "I haven't looked at the proposed code at all, but it is possible to design this kind of datastructure, with much care:\n\nhttp://www.ddj.com/hpc-high-performance-computing/208801974 "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12617514",
            "date": "2008-07-28T19:00:33+0000",
            "content": "Yes, I'm sorry for speaking out of turn here. "
        },
        {
            "author": "Noble Paul",
            "id": "comment-12617515",
            "date": "2008-07-28T19:03:40+0000",
            "content": "OK . I take my words back. LinkedHashMap is backed a by a HashMap . The table can get resized during the lifetime of a map (and hence during a get operation also). So the get() may return a wrong value (which is unacceptable) and it may never throw an Exception. \n\nIf we ever want to have an LRUCache with a non -synchronized get() we must have it backed by a ConcurrentHashMap "
        },
        {
            "author": "Fuad Efendi",
            "id": "comment-12617516",
            "date": "2008-07-28T19:05:54+0000",
            "content": "Mark, thanks for going deeper. Yes, resize may change ( Entry[ ] ) table, key will disappear from bucket and _get() returns null:\n\n    /**\n     * The table, resized as necessary. Length MUST Always be a power of two.\n     */\n    transient Entry[] table;\n...\n    public V get(Object key) {\n\tif (key == null)\n\t    return getForNullKey();\n        int hash = hash(key.hashCode());\n        for (Entry<K,V> e = table[indexFor(hash, table.length)];\n             e != null;\n             e = e.next) {\n            Object k;\n            if (e.hash == hash && ((k = e.key) == key || key.equals(k)))\n                return e.value;\n        }\n        return null;\n    }\n\n\n\nMight get  null instead of MyValue (during resize by another thread); not a big deal! It is still Thread-Safe. Will add new entry (overwrite existing) in such extremely rare cases.\n\n\n\tget() will never return wrong value (Entry object is immutable in our case):\n\nif (e.hash == hash && ((k = e.key) == key || key.equals(k)))\n                return e.value;\n\n\n\n\n "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12617517",
            "date": "2008-07-28T19:13:59+0000",
            "content": "Fuad, before going further on this, we must also consider users who use alternate JVM implementations. Since the contract is to synchronize, we cannot base our decision on Sun JDK's implementation. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-12617518",
            "date": "2008-07-28T19:15:47+0000",
            "content": "I don't have time to look at this right now, but I'll certainly spend some time tonight Efendi.\n\nA quick to my point though: I mentioned something that might be done in an implementation that could be an issue - you came back with a specific implementation that may (or may not, I don't have time at the moment) not work anyway. We can't program to an implementation though - we must program to the contract. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12617519",
            "date": "2008-07-28T19:21:44+0000",
            "content": "resize() is only the most obvious problem... there are tons of ways this can fail, even if you get around the resize (and your \"null\" fix for resize() won't work).  Some of the failures can be in the form of incorrect results rather than null pointers or exceptions (so you can't just retry).\n\nI'll reiterate:\nit's pretty much impossible to avoid all forms of synchronization and memory barriers for get() on a shared Map object. "
        },
        {
            "author": "Fuad Efendi",
            "id": "comment-12617520",
            "date": "2008-07-28T19:21:50+0000",
            "content": "Shalin, we are already using AtomicLong of Java 5; JVM is defferent story... JRockit R27 is JVM from BEA-Oracle, and its JDK 6 powered (rt.jar comes from SUN).\nI just tried to compare synchronized with unsynchronized and found it is the main problem for faceting...\nAnother problem: somehow faceting recalculates each time (using filterCache during repeated recalculations), queryCache is not enough... "
        },
        {
            "author": "Fuad Efendi",
            "id": "comment-12617523",
            "date": "2008-07-28T19:31:51+0000",
            "content": "We need to invite Doug Lea to this discussion...\nhttp://en.wikipedia.org/wiki/Doug_Lea\nhttp://gee.cs.oswego.edu/dl/index.html\n\nWe may simply use java.util.concurrent.locks instead of heavy synchronized... we may also use Executor framework instead of single-thread faceting... We may even base SOLR on Apache MINA project. "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12617526",
            "date": "2008-07-28T19:37:32+0000",
            "content": "I just tried to compare synchronized with unsynchronized and found it is the main problem for faceting...\nFuad, I am completely with you on this. Everybody will agree that a more efficient implementation will be a very useful addition to Solr. However, Yonik's concerns on the current patch are valid and we cannot go ahead with the current one. "
        },
        {
            "author": "Fuad Efendi",
            "id": "comment-12617529",
            "date": "2008-07-28T19:45:41+0000",
            "content": "concerns are probably because of misunderstanding of  some contract... \n\n\n    /**\n     * The table, resized as necessary. Length MUST Always be a power of two.\n     */\n    transient Entry[] table;\n\n    void resize(int newCapacity) {\n        Entry[] oldTable = table;\n        int oldCapacity = oldTable.length;\n        if (oldCapacity == MAXIMUM_CAPACITY) {\n            threshold = Integer.MAX_VALUE;\n            return;\n        }\n\n        Entry[] newTable = new Entry[newCapacity];\n        transfer(newTable);\n        table = newTable;\n        threshold = (int)(newCapacity * loadFactor);\n    }\n\n\n    public V get(Object key) {\n\tif (key == null)\n\t    return getForNullKey();\n        int hash = hash(key.hashCode());\n        for (Entry<K,V> e = table[indexFor(hash, table.length)];\n             e != null;\n             e = e.next) {\n            Object k;\n            if (e.hash == hash && ((k = e.key) == key || key.equals(k)))\n                return e.value;\n        }\n        return null;\n    }\n\n\n\n\n\n\n\tin worst case we will have pointer to old table and even with new one of smaller size we won't get any ArrayIndexOutOfBounds.\n\tThere is no any contract requiring synchronization on get() of HashMap or LinkedHashMap; it IS application specific.\n\twe will never have wrong results because Entry is immutable\n\n\n\n\n    /** \n     * Transfer all entries from current table to newTable.\n     */\n    void transfer(Entry[] newTable) {\n        Entry[] src = table;\n        int newCapacity = newTable.length;\n        for (int j = 0; j < src.length; j++) {\n            Entry<K,V> e = src[j];\n            if (e != null) {\n                src[j] = null;\n                do {\n                    Entry<K,V> next = e.next;\n                    int i = indexFor(e.hash, newCapacity);  \n                    e.next = newTable[i];\n                    newTable[i] = e;\n                    e = next;\n                } while (e != null);\n            }\n        }\n    }\n\n\n\n\n\tWe won't have even any NullPointerException after src[j] = null.\n\n\n\nP.S.\nOf course, I agree - it is Java internals, and it is not public Map interface-contract - should we avoid to use implementation then? I believe it is specified somewhere in JSR too...\n\n * @author  Doug Lea\n * @author  Josh Bloch\n * @author  Arthur van Hoff\n * @author  Neal Gafter\n * @version 1.65, 03/03/05\n\n\n\nP.P.S.\nDo not forget to look at the top of this discussion:\n\ndescription: xxx Cache(maxSize=10000000, initialSize=1000) \nsize : 2668705\ncumulative_inserts : 4246246\n\n\n\n\n\tcumulative_inserts is almost double of size which shows that double-inserts are real\n\tI checked catalina_out: no any NullPointerException, ArrayIndexOutOfBoundsException, and etc.\n\tI don't think we should be worried too much about possible change of Map implementation by SUN ... in this case we should use neither java.lang.String nor java.util.Date (some are placed in wrong packages).\n\tabout thread safety: some participants are wrongly guessing that making object access totally synchronized will make their code thread-safe... deadlock.\n\n "
        },
        {
            "author": "Mike Klaas",
            "id": "comment-12617549",
            "date": "2008-07-28T21:16:57+0000",
            "content": "[quote]We may simply use java.util.concurrent.locks instead of heavy synchronized... we may also use Executor framework instead of single-thread faceting... We may even base SOLR on Apache MINA project.[/quote]\n\nSimply replacing synchronized with java.util.concurrent.locks doesn't increase performance.  There needs to be a specific strategy for employing these locks in a way that makes sense.\n\nFor instance, one idea would be to create a read/write lock with the put()'s covered by write and get()'s covered by read.  This would allow multiple parallel reads and will be thread-safe.  Another is to create something like ConcurrentLinkedHashMap.\n\nThese strategies should be tested before trying to create a lock-free get() version, which if even possible, would rely deeply on the implementation (such a structure would have to be created from scratch, I believe).  I'd expect anyone that is able to create such a thing be familiar enough wiht memory barriers and such issues to be able to deeply explain the problems with double-checked locking off the top of their head (and immediately see such problems in other code) "
        },
        {
            "author": "Fuad Efendi",
            "id": "comment-12617562",
            "date": "2008-07-28T21:34:46+0000",
            "content": "Simply replacing synchronized with java.util.concurrent.locks doesn't increase performance. There needs to be a specific strategy for employing these locks in a way that makes sense.\n\nI absolutely agree... \n\nConcurrentHashMap is based on some level of acceptable safety, for specific tasks only\nThey do not throw ConcurrentModificationException. However, iterators are designed to be used by only one thread at a time. \n\nWe can try to design specific caches directly implementing Map or ConcurrentMap interfaces. We should define 'safety' levels (for instance, null is not a problem if cache already contains this object added by another thread concurrently; cache elements are explicitly immutable objects; and etc.) \nFIFO looks simplest and it does work indeed; for LRU we need reordering for each get(), OR we can make it weaker using weak (approximate) reordering somehow... "
        },
        {
            "author": "Fuad Efendi",
            "id": "comment-12617639",
            "date": "2008-07-29T01:19:41+0000",
            "content": "This is extremely simple Concurrent LRU, I spent an hour to create it; it is based on ConcurrentHashMap. I don't use java.util.concurrent.locks, and I am trying to focus on requirements only avoiding implementing unnecessary methods of Map interface (so that I am not following contract  very sorry!)\n\n\nimport java.util.Map;\nimport java.util.concurrent.ConcurrentHashMap;\n\npublic class ConcurrentLRU<K, V> {\n\n\tprotected ConcurrentHashMap<K, ValueWrapper<V>> map;\n\tprotected int maxEntries;\n\n\tpublic ConcurrentLRU(int maxEntries) {\n\t\tmap = new ConcurrentHashMap<K, ValueWrapper<V>>();\n\t\tthis.maxEntries = maxEntries;\n\t}\n\n\tpublic V put(K key, V value) {\n\t\tValueWrapper<V> wrapper = map.put(key, new ValueWrapper<V>(value));\n\t\tcheckRemove();\n\t\treturn value;\n\t}\n\n\tvoid checkRemove() {\n\t\tif (map.size() <= maxEntries)\n\t\t\treturn;\n\t\tMap.Entry<K, ValueWrapper<V>> eldestEntry = null;\n\t\tfor (Map.Entry<K, ValueWrapper<V>> entry : map.entrySet()) {\n\t\t\tlong popularity = entry.getValue().popularity;\n\t\t\tif (eldestEntry == null || eldestEntry.getValue().popularity > popularity) {\n\t\t\t\teldestEntry = entry;\n\t\t\t}\n\t\t}\n\t\tmap.remove(eldestEntry.getKey(), eldestEntry.getValue());\n\t}\n\n\tpublic V get(Object key) {\n\t\tValueWrapper<V> wrapper = map.get(key);\n\t\treturn wrapper == null ? null : wrapper.getValue();\n\t}\n\n\tpublic final static class ValueWrapper<V> {\n\t\tstatic volatile long popularityCounter;\n\t\tvolatile long popularity;\n\t\tV value;\n\n\t\tValueWrapper(V value) {\n\t\t\tthis.value = value;\n\t\t\tpopularity = popularityCounter++;\n\t\t}\n\n\t\tpublic boolean equals(Object o) {\n\t\t\tif (!(o instanceof ValueWrapper)) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t\treturn (value == null ? ((ValueWrapper) o).value == null : value.equals(((ValueWrapper) o).value));\n\t\t}\n\n\t\tpublic int hashCode() {\n\t\t\treturn value.hashCode();\n\t\t}\n\n\t\tpublic V getValue() {\n\t\t\tpopularity = popularityCounter++;\n\t\t\treturn value;\n\t\t}\n\n\t}\n\n}\n\n\n\nP.S.\nDo we need to synchronize put() or checkRemove()? The only hypothetical problem is OutOfMemoryException. But it is just first draft, very simplified... we do not need to sort array. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12617646",
            "date": "2008-07-29T01:40:31+0000",
            "content": "Fuad, you are on the right track now by using something that is thread-safe (ConcurrentHashMap).  A couple of minor points:\n\n\tI don't see the point of the static popularityCounter... that looks like a bug.\n\tincrements aren't atomic, but losing an increment once in a while should be fine in this scenario\n\n\n\nAnyway, If this works for you, use it!\nIt's likely to be very specific to your use-case though (with millions of cache entries, millions of lookups per request, and no evictions).  The eviction code looks like it would be relatively expensive. "
        },
        {
            "author": "Lars Kotthoff",
            "id": "comment-12617648",
            "date": "2008-07-29T01:49:10+0000",
            "content": "Not everything in JAVA is extremely good: for instance, synchronization. Even for single-threaded application, it needs additionally 600 CPU cycles (I've read it somewhere for SUN Java 1.3 on Windows)\n\nThat's probably not true for modern JVMs though \u2013 cf. http://www.ibm.com/developerworks/library/j-jtp04223.html.\n\n...9x times performance boost...\n\nHow did you measure that exactly? The Solr admin pages will not give you exact measurements. Could you describe the test setup in detail? I'm guessing that you're caching the results of all queries in memory such that no disk access is necessary. Are you using highlighting or anything else that might be CPU-intensive at all? From my personal experience with Solr I wouldn't expect synchronization for the caches to be that big of a performance penalty. In some of my tests with a several GB index where all results where cached and highlighting was turned on I've seen throughputs in excess of 400 searches per second. I think that the performance bottleneck in this case was the network interface for sending the replies.\n\nabsolutely no need to synchronize get() method for FIFO!\n\nConsider the following case: thread A performs a synchronized put, thread B performs an unsynchronized get on the same key. B gets scheduled before A completes, the returned value will be undefined. Yes, we could do sanity checks to minimise these cases, but that would probably end up being more expensive than the synchronization.\n\nFrom JavaDoc: \"Note that this implementation is not synchronized. If multiple threads access a linked hash map concurrently, and at least\none of the threads modifies the map structurally, it must be synchronized externally.\"\n\nThat's exactly the case here \u2013 the update thread modifies the map structurally! It doesn't do this at all times, probably even never after the cache has been populated, but there's no way to know for sure unless you explicitely remove the put method.\n\nI'm not convinced that we should change the current implementation for the following reasons:\n\n\tConcurrency is traditionally a discipline which is very hard to get right. Furthermore the serious bugs tend to show up only when you really get race conditions and the like, i.e. when the machine is under heavy load and any disruption will hit you seriously.\n\tYou've already started to amend your implementation with sanity checks and the like \u2013 as I've said before, this might end up being more expensive than synchronization.\n\tA FIFO cache might become a bottleneck itself \u2013 if the cache is very large and the most frequently accessed item is inserted just after the cache is created, all accesses will need to traverse all the other entries before getting that item.\n\n\n\nThat said, if you can show conclusively (e.g. with a profiler) that the synchronized access is indeed the bottleneck and incurs a heavy penalty on performance, then I'm all for investigating this further. "
        },
        {
            "author": "Fuad Efendi",
            "id": "comment-12617654",
            "date": "2008-07-29T02:19:27+0000",
            "content": "The Solr admin pages will not give you exact measurements. \nYes, and I do not need exact measurements! It gives me averageTimePerRequest which improved almost 10 times on production server. Should I right JUnit tests and execute it in a single-threaded environment? Better is to use The Grinder, but I don't have time and spare CPUs.\n\nI've seen throughputs in excess of 400 searches per second. \nBut 'searches per second' is not the same as 'average response time'!!!\n\nAre you using highlighting or anything else that might be CPU-intensive at all? \nYes, I am using highlighting. You can see it at http://www.tokenizer.org\n\n\nI'm guessing that you're caching the results of all queries in memory such that no disk access is necessary.\n But this is another bug of SOLR!!! I am using extremely large caches but SOLR still recalculates facet intersections.  - SOLR-669\n\nA FIFO cache might become a bottleneck itself - if the cache is very large and the most frequently accessed item is inserted just after the cache is created, all accesses will need to traverse all the other entries before getting that item.\n\n\n\tsorry, I didn't understand... yes, if cache contains 100000 entries and 'most popular item' is removed... Why 'traverse all the other entries before getting that item'? why 99999 items are less popular (cumulative) than single one (absolute)?\n\n\n\nYou probably mean 'LinkedList traversal' but this is not the case. This is why we need to browse JavaSource... LinkedHashMap extends HashMap and there is no any 'traversal',\n\n    public V get(Object key) {\n        Entry<K,V> e = (Entry<K,V>)getEntry(key);\n        if (e == null)\n            return null;\n        e.recordAccess(this);\n        return e.value;\n    }\n\n\n\n\nConsider the following case: thread A performs a synchronized put, thread B performs an unsynchronized get on the same key. B gets scheduled before A completes, the returned value will be undefined.\nthe returned value is well defined: it is either null or correct value.\n\nThat's exactly the case here - the update thread modifies the map structurally! \nWho cares? We are not iterating the map!\n\nThat said, if you can show conclusively (e.g. with a profiler) that the synchronized access is indeed the bottleneck and incurs a heavy penalty on performance, then I'm all for investigating this further.\n\nWhat?!!\n\n\nAnyway, I believe simplified ConcurrentLRU backed by ConcurrentHashMap is easier to understand and troubleshoot...\n\nI don't see the point of the static popularityCounter... that looks like a bug.\nNo, it is not a bug. it is virtually \"checkpoint\", like as a timer, one timer for all instances. We can use System.currentTimeMillis() instead, but static volatile long is faster.\n\nAbout specific use case: yes... if someone has 0.5 seconds response time for faceted queries I am very happy... I had 15 seconds before going with FIFO.  "
        },
        {
            "author": "Fuad Efendi",
            "id": "comment-12617655",
            "date": "2008-07-29T02:25:57+0000",
            "content": "The eviction code looks like it would be relatively expensive\n\nbut get() method of LinkedHashMap reorders whole map!!! (Of course, CPU load is evenly distributed between several get() so that we can't see it) Other implementations even use Arrays.sort() or something similar. I don't see easier solution than that... probably some random-access policy with predictable range of \"popularity\", we can evict anything 'old' and not necessarily 'eldest'... "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12617656",
            "date": "2008-07-29T02:31:51+0000",
            "content": "but get() method of LinkedHashMap reorders whole map!!! \n\nNo it doesn't... think linked-list.  It moves a single item, which is pretty fast. "
        },
        {
            "author": "Fuad Efendi",
            "id": "comment-12617657",
            "date": "2008-07-29T02:31:53+0000",
            "content": "Lars, I used FIFO because it is extremely simple to get unsynchronized get():\n\nmap = new LinkedHashMap(initialSize, 0.75f, true)  - LRU Cache\n(and we need synchronized get())\nmap = new LinkedHashMap(initialSize, 0.75f, false) - FIFO\n(and we do not need synchronized get()) \n\n\n\nYonik, I'll try to improve ConcurrentLRU and to share findings... of course FIFO is not what we need.\n\nNo it doesn't... think linked-list. It moves a single item, which is pretty fast.\nyes, so I wrote 'evenly distributed between several get() so we can't see it' - it keeps List ordered and we can't unsynchronize it with all subsequences!!! "
        },
        {
            "author": "Lars Kotthoff",
            "id": "comment-12617658",
            "date": "2008-07-29T02:31:59+0000",
            "content": "the returned value is well defined: it is either null or correct value.\n\nIt is if nothing is modifying the map during the get. If something is modifying the map you don't know how the implementation handles the insert of a new value. It might copy the object, and you'd end up with half an object or even an invalid memory location. That's why the javadoc says that you must synchronize accesses if anything modifies the map \u2013 this is not limited to iterators. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12617662",
            "date": "2008-07-29T02:43:50+0000",
            "content": "the returned value is well defined: it is either null or correct value.\n\nNo, it is not!  Your analysis seems to ignore the java memory model (partially constructed objects and all that).  I don't know how many different ways to say it.... please do yourself a favor and read up on the java memory model (and the book I previously referenced is great for this).  This is hard stuff (at the lowest levels). "
        },
        {
            "author": "Fuad Efendi",
            "id": "comment-12617664",
            "date": "2008-07-29T02:45:30+0000",
            "content": "It is if nothing is modifying the map during the get. If something is modifying the map you don't know how the implementation handles the insert of a new value. It might copy the object, and you'd end up with half an object or even an invalid memory location. That's why the javadoc says that you must synchronize accesses if anything modifies the map - this is not limited to iterators.\n\nJavaDoc does not say that. Instead, it says (I am repeating):\n..and at least one of the threads modifies the map structurally, it must be synchronized externally. \n\n\n\tonly thread doing  structural modification must be synchronized. In case of LinkedHashMap, for instance, we need to synchronize inserts in order to avoid Entry instances referencing themselves (orphans).\n\n\n\n\nyou don't know how the implementation handles the insert of a new value\n\nI know exactly: SOLR does not modify 'value' during 'insert', Map.Entry instances are immutable in SOLR, etc. Table resize is main problem - but after analyzing source code I don't see any problem. Consern that 'wrong value will be returned for a key' is not applicable. And JavaDocs does not say anything about that. Collections internally use Map.Entry in an immutable way, do not change it. "
        },
        {
            "author": "Fuad Efendi",
            "id": "comment-12617668",
            "date": "2008-07-29T02:55:27+0000",
            "content": "No, it is not! Your analysis seems to ignore the java memory model (partially constructed objects and all that). I don't know how many different ways to say it.... please do yourself a favor and read up on the java memory model (and the book I previously referenced is great for this). This is hard stuff (at the lowest levels).\n\nOk. May be I can get reference to wrong object type, or even object scheduled for finalization... But we are not inserting into Map 'partially constructed objects', isn't it?\n\nSimplest scenario: Thread A tries to get variable (4 bytes of address in JVM) pointing to object O. Another thread B concurrently assigns null to that variable. Isn't it solved at CPU level yet? Or, may be on 64bit system thread B assigns zero to first 2 bytes, and then to another 2 bytes?\n\nI need to study this book... BTW, I am running JVM with '-server' option. "
        },
        {
            "author": "Lars Kotthoff",
            "id": "comment-12617669",
            "date": "2008-07-29T02:56:42+0000",
            "content": "The way I understand the javadoc is\n\n..and at least one of the threads modifies the map structurally, it must be synchronized externally.\n\nThe it references the map. It says explicitely that the map must be synchronized, i.e. all operations on it. It does not say that only the thread modifying it must be synchronized. Consider the case where only one thread modifies the map. You're saying that in this case synchronization would not be necessary, as only modifications themselves need to be synchronized and there is only one thread doing that. The javadoc explicitely says that it is necessary. "
        },
        {
            "author": "Fuad Efendi",
            "id": "comment-12617673",
            "date": "2008-07-29T03:07:06+0000",
            "content": "The it references the map. It says explicitely that the map must be synchronized.\n\n\n\tI agree, thanks for pointing to it. Synchronize!\n\n\n\nBTW, Joshua Bloch developed Arrays.sort(), and bug was found after 9 years. Nothing is perfect.\n\nConcurrentLRU looks extremely simple and easy to improve. Should we check SUN's bug database before using ConcurrentHashMap? It has some related... "
        },
        {
            "author": "Craig McClanahan",
            "id": "comment-12617676",
            "date": "2008-07-29T03:44:21+0000",
            "content": "Just a quick comment from the Peanut Gallery.\n\nInstead of arguing about what the semantics of what the JavaDocs for java.util.Map and friends actually say, and worrying about whether particular implementations actually follow the rules but provide reasonable performance, this seems like a good opportunity to design and build an application specific data structure that has the behavioral characteristics you want (Fuad is after fastest-possible reads, everybody is after reasonable behavior in the face of concurrent writes).  My only recommendation in this regard would be this:  don't make a custom implementation say \"implements java.util.LinkedHashMap\" (again, or whatever implementation is currently in use) unless it does actually implement the documented semantics for java.util.LinkedHashMap.\n\nIt's fine to have a custom FifoCacheMap (or whatever name you like) class that does not implement java.util.Map.  It's not fine to say you implement an interface but then break the documented contract. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12617682",
            "date": "2008-07-29T03:58:31+0000",
            "content": "It's fine to have a custom FifoCacheMap (or whatever name you like) class that does not implement java.util.Map.\n\nRight.  Any solr cache must currently implement the SolrCache interface, and LinkedHashMap is simply an implementation detail of the LRUCache implementation of SolrCache (which has no relationship to the Map interface). "
        },
        {
            "author": "Fuad Efendi",
            "id": "comment-12617684",
            "date": "2008-07-29T04:05:07+0000",
            "content": "Fuad is after fastest-possible reads, everybody is after reasonable behavior in the face of concurrent writes\n\nThanks and sorry for runtime errors;\n\nFIFO looks strange at first, but... for large cache (100000 items), most popular item can be mistakenly removed... but I don't think there are any 'most popular facets' etc.; it's evenly distributed in most cases.\n\nAnother issue: SOLR always tries recalculate facets even with extremely large filterCache & queryResultCache, even the same faceted query shows always the same long response times.\n\nIt is if nothing is modifying the map during the get. If something is modifying the map you don't know how the implementation handles the insert of a new value. It might copy the object, and you'd end up with half an object or even an invalid memory location. That's why the javadoc says that you must synchronize accesses if anything modifies the map - this is not limited to iterators.\n\nI agree of course... However, we are not dealing with unknown implementation of java.util.Map clonig (java.lang.Cloneable) objects somehow or using some weird object introspection etc....  "
        },
        {
            "author": "Fuad Efendi",
            "id": "comment-12617692",
            "date": "2008-07-29T04:54:10+0000",
            "content": "BTW there is almost no any functional difference between LRU and FIFO. And there is huge difference between LRU (Least Recently Used) and LFU (Least Frequently Used).\nIt's easy to implement ConcurrentLFU based on provided ConcurrentLRU template; of course, following the main contract org.apache.solr.search.SolrCache. "
        },
        {
            "author": "Noble Paul",
            "id": "comment-12617693",
            "date": "2008-07-29T04:59:04+0000",
            "content": "I Fuad. This is a worthwhile effort to undertake. Why don't you implement a LRUCache implementation and post it (as a java file) .  Let everyone review and see if it can be improved "
        },
        {
            "author": "Fuad Efendi",
            "id": "comment-12617699",
            "date": "2008-07-29T05:08:38+0000",
            "content": "Paul, I want to do it... understand me, since February I am having constant performance problems with faceted queries (15-20 seconds response time), I ordered new server with 32 Gb & 2x quad-core (8x times more power!) but it didn't improve performance; finally I commented sync in LRUCache and made it FIFO... I was very impatient with this post, just tried to share very real staff...  "
        },
        {
            "author": "Noble Paul",
            "id": "comment-12617720",
            "date": "2008-07-29T06:26:12+0000",
            "content": "A FIFOCache using ConcurrentHashMap.\nPlease give feedback "
        },
        {
            "author": "Noble Paul",
            "id": "comment-12617753",
            "date": "2008-07-29T09:34:51+0000",
            "content": "Another one this is LRU. uses ConcurrentHashMap again\n\n\n\tGets are free\n\tPuts are expensive (very expensive) after the high watermark . Till then it is free\n\tTo lighten the load on put an extra thread is employed to do a concurrent mark and sweep\n\tthere is a high-water-mark and a low-water-mark . The extra thread cleans anything if low-water-mark is crossed. Put must removes if level crosses high-water-mark\n\n "
        },
        {
            "author": "Noble Paul",
            "id": "comment-12617801",
            "date": "2008-07-29T14:42:39+0000",
            "content": "bug fix "
        },
        {
            "author": "Fuad Efendi",
            "id": "comment-12618057",
            "date": "2008-07-30T04:32:14+0000",
            "content": "Thanks Paul, I am always trying to simplify... AtomicReference is a pointer to (approximately) least recently used 'key'... "
        },
        {
            "author": "Fuad Efendi",
            "id": "comment-12618060",
            "date": "2008-07-30T04:40:37+0000",
            "content": "bug fix "
        },
        {
            "author": "Fuad Efendi",
            "id": "comment-12618061",
            "date": "2008-07-30T04:50:04+0000",
            "content": "another bug... and AtomicReference is generic... never used it before. Could be even 'weaker' if we use 'hashcode' which is long (and atomic) instead of Key which is object (and unsafe), and distribution of hashcode is ok... "
        },
        {
            "author": "Noble Paul",
            "id": "comment-12618064",
            "date": "2008-07-30T05:04:07+0000",
            "content": "There are a few obvious issues w/ your patch.\nEffendi your implementation is wrong\n\n\n\t if (wrapper.lastAccessed < pointer.lastAccessed) {\n\t\t\tref.set(new Pointer(key, wrapper.lastAccessed));\n}\n\t\n\nwill always evaluate to false. And the reference will always have one value\nWe must be removing the entry which was accessed first (not last).. To get that you must maintian a linkedlist the way linkedhashmap maintains. No other shortcut. Keeping one reference will not work. \n\nIn that implementation there is always a contention on the head so gets are bound to be slow. That is why i did not go that route\nAnd the static volatile counter is not threadsafe. \nstatic in general is not a good idea\n\n\nThere is no need to use a WeakReference anywhere. This is a cache. So it must maintain strong reference "
        },
        {
            "author": "Noble Paul",
            "id": "comment-12618074",
            "date": "2008-07-30T06:21:58+0000",
            "content": "I have opened SOLR-667 for LRU implementations "
        },
        {
            "author": "Fuad Efendi",
            "id": "comment-12618339",
            "date": "2008-07-30T14:01:11+0000",
            "content": "Noble, thanks for feedback!\n\nOf course my code is buggy but I only wanted to illustrate simplest idea; I am extremely busy with other staff (Liferay) and can't focus on SOLR improvements... may be during weekend.\n\n...will always evaluate to false. And the reference will always have one value\n\n\tyes, this is bug. There are other bugs too...\n\n\n\nWe must be removing the entry which was accessed first (not last).. \nI mean (and code too) the same; probably wrong wording\n\nAnd the static volatile counter is not threadsafe. \nDo we really-really need thread safety here? By using 'volatile' I only prevent some JVMs from trying to optimize some code (and cause problems).\n\nThere is no need to use a WeakReference anywhere\nAgree... \n\nTo get that you must maintian a linkedlist the way linkedhashmap maintains. No other shortcut. \nMay be... but looks similar to Arrays.sort(), or TreeSet, and etc.... I am trying to avoid this. 'No other shortcut' - may be, but I am unsure.\n\nThanks!\n "
        },
        {
            "author": "Fuad Efendi",
            "id": "comment-12618766",
            "date": "2008-07-31T17:34:42+0000",
            "content": "I don't think ConcurrentHashMap will improve performance, and ConcurrentMap is not what SOLR needs:\n\n    V putIfAbsent(K key, V value);\n    V replace(K key, V value);\n    boolean replace(K key, V oldValue, V newValue);\n\n\n\nThere is also some(...) overhead with oldValue and the state of the hash table at some point; additional memory requirements; etc... can we design something plain-simpler being focused on SOLR specific requirements? Without all functionality of Map etc... "
        },
        {
            "author": "Fuad Efendi",
            "id": "comment-12619058",
            "date": "2008-08-01T16:12:34+0000",
            "content": "Guys at LingPipe (Natural Language Processing) http://alias-i.com/ are using excellent Map implementations with optimistic concurrency strategy:\nhttp://alias-i.com/lingpipe/docs/api/com/aliasi/util/FastCache.html\nhttp://alias-i.com/lingpipe/docs/api/com/aliasi/util/HardFastCache.html "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12675568",
            "date": "2009-02-21T15:31:33+0000",
            "content": "closing as duplicate since we have a concurrent cache impl now. "
        }
    ]
}