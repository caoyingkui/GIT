{
    "id": "SOLR-6803",
    "title": "Pivot Performance",
    "details": {
        "components": [
            "faceting"
        ],
        "type": "Bug",
        "labels": "",
        "fix_versions": [],
        "affect_versions": "5.1",
        "status": "Open",
        "resolution": "Unresolved",
        "priority": "Minor"
    },
    "description": "I found that my pivot search for terms per day was taking an age so I knocked up a quick test, using a collection of 1 million documents with a different number of random terms and times, to compare different ways of getting the counts.\n\n1) Combined = combining the term and time in a single field.\n2) Facet = for each term set the query to the term and then get the time facet \n3) Pivot = use the term/time pivot facet.\n\nThe following two tables present the results for version 4.9.1 vs 4.10.1, as an average of five runs.\n\n4.9.1 (Processing time in ms)\n\n\n\nValues (#)   \n  Combined (ms)\n     Facet (ms)\n     Pivot (ms)\n\n\n100       \n        22\n        21\n        52\n\n\n1000      \n       178\n        57\n       115\n\n\n10000     \n      1363\n       211\n       310\n\n\n100000    \n      2592\n      1009\n       978\n\n\n500000    \n      3125\n      3753\n      2476\n\n\n1000000   \n      3957\n      6789\n      3725\n\n\n\n\n\n4.10.1 (Processing time in ms)\n\n\n\nValues (#)   \n  Combined (ms)\n     Facet (ms)\n     Pivot (ms)\n\n\n100       \n        21\n        21\n        75\n\n\n1000      \n       188\n        60\n       265\n\n\n10000     \n      1438\n       215\n      1826\n\n\n100000    \n      2768\n      1073\n     16594\n\n\n500000    \n      3266\n      3686\n     99682\n\n\n1000000   \n      4080\n      6777\n    208873\n\n\n\n\n\nThe results show that, as the number of pivot values increases (i.e. number of terms * number of times), pivot performance in 4.10.1 get progressively worse.\n\nI tried to look at the code but there was a lot of changes in pivoting between 4.9 and 4.10, and so it is not clear to me what has cause the performance issues. However the results seem to indicate that if the pivot was simply a combined facet search, it could potentially produce better and more robust performance.",
    "attachments": {
        "PivotPerformanceTest.java": "https://issues.apache.org/jira/secure/attachment/12686607/PivotPerformanceTest.java"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2014-12-08T17:54:08+0000",
            "author": "Hoss Man",
            "content": "I knocked up a quick test, using a collection of 1 million documents with a different number of random terms and times, to compare different ways of getting the counts.\n\ncan you post more details about your test? ie...\n\n\n\tthe schema/configs you used\n\thow you generated your test data\n\thow you generated your load (ie: test queries)\n\n ",
            "id": "comment-14238142"
        },
        {
            "date": "2014-12-08T18:09:00+0000",
            "author": "Hoss Man",
            "content": "Neil: I tried to fix the issue description so the tables are formatted correctly (as best as i can understand what the data ment) .. please confirm they look the way you ment. ",
            "id": "comment-14238181"
        },
        {
            "date": "2014-12-08T18:15:11+0000",
            "author": "Neil Ireson",
            "content": "I've attached my test file...\n\nI just used the example solr configuration which comes with the distribution, I used the 4.9.1 version for both tests. ",
            "id": "comment-14238188"
        },
        {
            "date": "2014-12-08T18:24:26+0000",
            "author": "Neil Ireson",
            "content": "The test file has two versions:\n\n1) The first one creates a new set of 1,000,000 documents for each iteration of the number of values, so that the facet/pivot search is on all the values, i.e. facet.limit == -1.\n2) The second (faster) version creates one set of data with 1,000,000 documents, which have the 1,000,000 values and then uses varying facet.limit to determine the number of values in the search.\n\nThe above tables only report the second test.\n\nPS Thank you, the tables look correct now. ",
            "id": "comment-14238199"
        },
        {
            "date": "2014-12-10T23:13:28+0000",
            "author": "Neil Ireson",
            "content": "I ran JProfiler to see if it would cast any light on what's happening. Below is a snippet of the call tree...\n\n  100.0% - 482 s - 1 inv. org.apache.solr.handler.component.PivotFacetProcessor.processSingle\n  100.0% - 482 s - 1 inv. org.apache.solr.handler.component.PivotFacetProcessor.doPivots\n  99.4% - 479 s - 180 inv. org.apache.solr.handler.component.PivotFacetProcessor.doPivots\n  98.6% - 475 s - 179,920 inv. org.apache.solr.handler.component.PivotFacetProcessor.getSubset\n  98.3% - 474 s - 179,920 inv. org.apache.solr.search.SolrIndexSearcher.getDocSet\n  96.5% - 465 s - 153,059 inv. org.apache.solr.search.SolrIndexSearcher.getDocSetNC\n  95.9% - 462 s - 153,059 inv. org.apache.lucene.search.IndexSearcher.search\n  39.9% - 192 s - 1,523,680,993 inv. org.apache.solr.search.DocSetCollector.collect\n\nThe problem seems to be with the call to getSubset method in the PivotFacetProcessor doPivots method.\n\nAlthough I'm not actually sure how the doPivots method works, it would seem that the getSubset method only needs to be called if subField != null (in my case subField is always null). Therefore I think the performance issue maybe fixed by simply moving the getSubset method call to after the subField != null check, although it'd be nice if someone more au fait with the code could confirm.  ",
            "id": "comment-14241920"
        },
        {
            "date": "2014-12-11T11:55:54+0000",
            "author": "Neil Ireson",
            "content": "Well I compile 4.10.2 with the above changes (i.e. shuffling the getSubset call down a couple of lines) and obtained the following times.\n\n4.10.2 - patched (Processing time in ms)\n\n\n\n Values (#) \n\tCombined (ms) \n\tFacet (ms) \n\tPivot (ms) \n\n\n 100       \n        25\n        37\n        79\n\n\n 1000      \n       203\n        77\n       135\n\n\n 10000     \n      1577\n       289\n       404\n\n\n 100000    \n      2985\n      1096\n      1158\n\n\n 500000    \n      3474\n      3892\n      2921\n\n\n 1000000   \n      4421\n      7123\n      4655\n\n\n\n\n\nSo these results look back inline with version 4.9. I ran \"ant test\" and everything went fine but I don't know if the PivotFacetProcessor code between subField != null is tested. ",
            "id": "comment-14242440"
        },
        {
            "date": "2014-12-11T14:06:03+0000",
            "author": "Steve Molloy",
            "content": "The subset will be needed even if subfield is null when computing stats, ranges or queries (see SOLR-6348). All this isn't in branch 4.x though, and even in 5.x/trunk we may think of only calling it if any of those is needed (subField not null or stats or ranges or queries...). Have you tried with more than 2 levels? If so, are you seeing similar behaviour? ",
            "id": "comment-14242545"
        },
        {
            "date": "2014-12-11T15:38:35+0000",
            "author": "Neil Ireson",
            "content": "I'm not really sure what you are asking. The issue is the significant fall in performance for \"1-level\" pivots (which I imagine covers the vast majority of use cases), I'm not sure what is to be gained from looking at higher levels of pivots.\n\nIn general I would say that simply making repeated calls to the facet code would be the expected baseline performance of the pivot code, unless pivoting is providing some additional funky functionality. At the moment even when I'm making the calls to faceting from within my code and aggregating the results I am, in general (i.e. up to 100,000 values), getting better performance than when I use pivots, which, from my naive perspective, does not seem right. ",
            "id": "comment-14242697"
        },
        {
            "date": "2015-01-13T10:29:49+0000",
            "author": "Neil Ireson",
            "content": "So can we wrap the code in an \"if (calcSubset) {}\" condition so that pivot doesn't perform all the calculations if they are unnecessary, e.g. in the current branch 4.x.\n\nI'd really appreciate some way to resolve this issue as at the moment I am having to release my code with version 4.9, due to the severe performance issues with pivot in 4.10+. ",
            "id": "comment-14275037"
        },
        {
            "date": "2015-01-13T10:37:33+0000",
            "author": "Neil Ireson",
            "content": "After coming back to this I think I understand what you are asking now. Using my patched version, does pivot performance improve relative to my combined and facet techniques for higher dimension pivots? This will involve a bit of messing about with the test code, when I get some time I'll look into it and report back. ",
            "id": "comment-14275040"
        },
        {
            "date": "2015-05-11T21:41:41+0000",
            "author": "Neil Ireson",
            "content": "Just ran the test on version 5.1.0, here's the result...\n\n\n\n\n Values     \n  Combined \n     Facet \n     Pivot \n\n\n 100        \n       188 \n       124 \n       100 \n\n\n 1000       \n       206 \n       169 \n       280 \n\n\n 10000      \n       245 \n       372 \n      1998 \n\n\n 100000     \n       451 \n      1222 \n     19457 \n\n\n 500000     \n      1125 \n      3940 \n    116826 \n\n\n 1000000    \n      2612 \n      7001 \n    251576 \n\n\n\n\n\nNo real change for the faceting, the combined (or basic) querying seems pleasantly faster, but the pivot appears to have even worse performance. \n ",
            "id": "comment-14538691"
        },
        {
            "date": "2015-05-12T11:29:29+0000",
            "author": "Neil Ireson",
            "content": "I also made the naive change of removed the offending line from the code, by replacing\n\n\n        DocSet subset = getSubset(docs, sfield, fieldValue);\n\n\nwith\n\n        DocSet subset = null;\n        if ( subField != null || ((isShard || 0 < pivotCount) && ! statsFields.isEmpty()) ) {\n          subset = getSubset(docs, sfield, fieldValue);\n        }\n\n\nJust to show that in this case the pivot still provides the best results.\n\n\n\n\n Values     \n  Combined \n     Facet \n     Pivot \n\n\n 100        \n       202 \n       133 \n        67 \n\n\n 1000       \n       215 \n       183 \n        73 \n\n\n 10000      \n       255 \n       392 \n       145 \n\n\n 100000     \n       464 \n      1301 \n       395 \n\n\n 500000     \n      1307 \n      4458 \n      1179 \n\n\n 1000000    \n      2471 \n      7783 \n      2148 \n\n\n\n\n\nNote that with this change the code passed all the compile tests, so it's still not clear why to me why getSubset has to be called every time.  ",
            "id": "comment-14539672"
        }
    ]
}