{
    "id": "SOLR-7441",
    "title": "Improve overall robustness of the Streaming stack: Streaming API, Streaming Expressions, Parallel SQL",
    "details": {
        "components": [],
        "type": "Improvement",
        "labels": "",
        "fix_versions": [
            "6.0"
        ],
        "affect_versions": "5.1",
        "status": "Closed",
        "resolution": "Fixed",
        "priority": "Minor"
    },
    "description": "It's harder than it could be to figure out what the error is when using Streaming Aggregation. For instance if you specify an fl parameter for a field that doesn't exist it's hard to figure out that's the cause. This is true even if you look in the Solr logs.\n\nI'm not quite sure whether it'd be possible to report this at the client level or not, but it seems at least we could repor something more helpful in the Solr logs.",
    "attachments": {
        "SOLR-7441.patch": "https://issues.apache.org/jira/secure/attachment/12727280/SOLR-7441.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2015-04-22T01:12:34+0000",
            "author": "Joel Bernstein",
            "content": "Let's get this fixed for 5.2. I remember running across an error that didn't make it to the logs. Later when I went back to see if I could find an error that was not appearing in the logs I wasn't able to find one.\n\nIs the fl error not ending up in the logs, or just being logged in a complicated way?\n\nIn parallel mode you also end up with a json error on the worker node, as well as the original error on the search node.Would be good propagate the original error from the search node to the worker node to the client so you don't have dig around in the logs. ",
            "id": "comment-14506178"
        },
        {
            "date": "2015-04-22T04:33:44+0000",
            "author": "Erick Erickson",
            "content": "Nothing came out in the server log, and the client log was unhelpful (not quite sure what it was now...). This was just using a CloudSolrStream....\n\nI'm not at all sure when opening a stream and expecting back a TupleStream but get an error message how it would be decoded into a log message though, so just dumping it into the server log would certainly be a step forward. ",
            "id": "comment-14506408"
        },
        {
            "date": "2015-04-22T11:57:37+0000",
            "author": "Joel Bernstein",
            "content": "Ok, I'll take a look and figure out why this error is not making into the logs. ",
            "id": "comment-14506931"
        },
        {
            "date": "2015-04-22T17:07:41+0000",
            "author": "Gus Heck",
            "content": "Exceptions on open/start/finish/close are hard, but I think I have a solution for passing back exceptions encountered while reading (with test) if you want it? ",
            "id": "comment-14507429"
        },
        {
            "date": "2015-04-22T17:17:01+0000",
            "author": "Erick Erickson",
            "content": "Gus:\n\nIt's always appropriate attach a patch!\n\nWe usually label them SOLR-7441.patch in this case, don't worry multiple versions with the same name are preserved so that makes it easy to know what the most recent was.\n\nThanks! ",
            "id": "comment-14507453"
        },
        {
            "date": "2015-04-22T17:22:50+0000",
            "author": "Gus Heck",
            "content": "Patch vs 5.x branch for passing exceptions that happen during reading of the stream on the server back to the client. ",
            "id": "comment-14507470"
        },
        {
            "date": "2015-04-22T17:34:26+0000",
            "author": "Gus Heck",
            "content": "oops, let me send another, just realized that a file got missed (also want to take out spurious whitespace changes that my IDE did) ",
            "id": "comment-14507497"
        },
        {
            "date": "2015-04-22T17:43:45+0000",
            "author": "Gus Heck",
            "content": "Improved & complete patch ",
            "id": "comment-14507522"
        },
        {
            "date": "2015-04-22T18:48:57+0000",
            "author": "Joel Bernstein",
            "content": "Let's break this into two tickets. One for the specific logging issue with the fl and another ticket for error propagation.  ",
            "id": "comment-14507647"
        },
        {
            "date": "2015-04-22T19:23:26+0000",
            "author": "Joel Bernstein",
            "content": "SInce this already has a patch attached, I'll create a ticket for the fl logging issue ",
            "id": "comment-14507720"
        },
        {
            "date": "2015-04-25T14:07:20+0000",
            "author": "Joel Bernstein",
            "content": "Erick Erickson, just ran a test case with an incorrect fl and got the error below. So I think there is another factor involved when the error doesn't appear in the logs. I'll see if I can reproduce the issue. Let me know if you can reproduce it.\n\nThrowable #1: org.apache.solr.common.SolrException: undefined field: \"blah1\"\n   [junit4]    > \tat __randomizedtesting.SeedInfo.seed([1A2758A869E78AB2:AED7CFC964A88012]:0)\n   [junit4]    > \tat org.apache.solr.schema.IndexSchema.getField(IndexSchema.java:1223)\n   [junit4]    > \tat org.apache.solr.response.SortingResponseWriter.getFieldWriters(SortingResponseWriter.java:232)\n   [junit4]    > \tat org.apache.solr.response.SortingResponseWriter.write(SortingResponseWriter.java:120)\n   [junit4]    > \tat org.apache.solr.util.TestHarness.query(TestHarness.java:326)\n   [junit4]    > \tat org.apache.solr.util.TestHarness.query(TestHarness.java:302)\n   [junit4]    > \tat org.apache.solr.response.TestSortingResponseWriter.testSortingOutput(TestSortingResponseWriter.java:145)\n   [junit4]    > \tat java.lang.Thread.run(Thread.java:745) ",
            "id": "comment-14512502"
        },
        {
            "date": "2015-04-25T14:09:07+0000",
            "author": "Joel Bernstein",
            "content": "Also I'm assuming you're using the \"/export\" handler. ",
            "id": "comment-14512503"
        },
        {
            "date": "2015-04-25T14:15:24+0000",
            "author": "Joel Bernstein",
            "content": "Ok, found the problem. The exception is being thrown but not logged. So it appears in the test and the browser but not in the log. I'll figure out why. ",
            "id": "comment-14512505"
        },
        {
            "date": "2015-04-25T15:17:42+0000",
            "author": "Joel Bernstein",
            "content": "SOLR-7472 has a patch which resolves the fl logging issue. This fix will be in 5.2.\n\nWe can continue to work with Gus's patch in this ticket. ",
            "id": "comment-14512546"
        },
        {
            "date": "2015-04-27T16:54:17+0000",
            "author": "Gus Heck",
            "content": "I'm sure there are plenty of more important patches out there, but I'd be interested to know if anyone has feedback on my patch. \n\nTo summarize the patch, I catch any exception, serialize it, toss it in the maps with a special key (there seem to be a couple of those already). Then I check for the presence of an exception on the other end, and deserialize/throw rather than adding to the TreeSet when I find an exception. This is nice since if you are running the code from your IDE while developing, it shows up in the local output, and the stack trace becomes clickable (if your ide does that). In normal production use, it will allow the exception to show up in the logs for the client that made the request rather than showing up in the log of one of the N nodes in the cluster. One could event catch and handle different exceptions from the worker nodes differently. It does however leave the client with an incomplete set of tuples, so perhaps those should be cleared when an exception is found, or perhaps there should be best-effort & fail-fast modes, with best-effort collecting a list of exceptions instead?\n\nAn additional enhancement might be to find a way to identify the node on which this exception occurred and wrap the original exception in an exception with the node identity information added to the message before serializing it, but I thought of that after I submitted the patch and haven't actually gone back to attempt it yet. ",
            "id": "comment-14514438"
        },
        {
            "date": "2015-05-09T19:21:57+0000",
            "author": "Gus Heck",
            "content": "any thoughts on this? ",
            "id": "comment-14536832"
        },
        {
            "date": "2015-05-25T20:18:53+0000",
            "author": "Gus Heck",
            "content": "Will this make 5.2? Is there anything you need from me? ",
            "id": "comment-14558501"
        },
        {
            "date": "2015-05-26T00:23:31+0000",
            "author": "Joel Bernstein",
            "content": "I haven't yet had a chance to review the ticket, but I will try to get to it soon. I have a pretty big backlog of work on the Streaming API, Streaming Expressions and Parallel SQL stack, but error handling is an important part of the stack. ",
            "id": "comment-14558596"
        },
        {
            "date": "2015-06-26T12:27:05+0000",
            "author": "Joel Bernstein",
            "content": "Gus Heck, I've had a chance to review the patch. I think there are some things in there that we can use. The idea of having a field in the Tuple to hold the error makes it easy to propagate errors through the tiers. The trick will be getting the error added to an outgoing tuple in all the different places in the stack where an error can originate. Below is a preliminary list of the areas where exceptions may originate in the stack. Some of the areas are handled by the patch you provided. \n\n1) Error from the /select handler before the stream is started (JSONResponseWriter)\n2) Error from the /export handler before the stream is started (SortingResponseWriter)\n3) Error midstream from the /select handler;\n4) Error midstream from the /export handler.\n5) Error from the Streaming API, before the request is sent. (Non-parallel mode)\n6) Error from the Streaming API, before the request is sent. (In Parallel mode or on the worker)\n7) Error from the SQL Parser (SQLHandler) ",
            "id": "comment-14602805"
        },
        {
            "date": "2015-06-30T15:02:25+0000",
            "author": "Joel Bernstein",
            "content": "Added a patch that adds an Exception handling framework to the Streaming API.\n\nThe new ExceptionStream wraps a TupleStream and catches any exceptions from the underlying Stream. It then logs the exception and returns a Tuple with the exception message included. \n\nThe SolrStream has some code added to look for Tuples with an\nException message and then to throw an Exception passing along the exception message from the Tuple.\n\nThis effectively allows exceptions to be passed through any number of distributed tiers. \n\nThe nice thing about this design is that the SolrStream throws and the ExceptionStream catches. All other Streams in between can ignore exception handling entirely.\n\nNo tests yet to prove this concept actually works, but it looks promising.\n ",
            "id": "comment-14608428"
        },
        {
            "date": "2015-07-03T16:24:02+0000",
            "author": "Joel Bernstein",
            "content": "Patch with all tests passing ",
            "id": "comment-14613285"
        },
        {
            "date": "2015-07-03T16:32:09+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1689045 from Joel Bernstein in branch 'dev/trunk'\n[ https://svn.apache.org/r1689045 ]\n\nSOLR-7441, SOLR-7647: Improve overall robustness of the Streaming stack: Streaming API, Streaming Expressions, Parallel SQL ",
            "id": "comment-14613293"
        },
        {
            "date": "2015-07-07T02:18:31+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1689559 from Joel Bernstein in branch 'dev/trunk'\n[ https://svn.apache.org/r1689559 ]\n\nSOLR-7441: Disable failing test ",
            "id": "comment-14616068"
        },
        {
            "date": "2015-07-21T20:28:36+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1692193 from Joel Bernstein in branch 'dev/trunk'\n[ https://svn.apache.org/r1692193 ]\n\nSOLR-7441:Improve overall robustness of the Streaming stack: Streaming API, Streaming Expressions, Parallel SQL ",
            "id": "comment-14635758"
        },
        {
            "date": "2015-07-22T03:57:54+0000",
            "author": "Gus Heck",
            "content": "Joel Bernstein thx for reviewing this in and carrying it forward. I got behind on my list mail and didn't see your comments. Sorry! ",
            "id": "comment-14636176"
        },
        {
            "date": "2015-07-22T04:00:05+0000",
            "author": "Gus Heck",
            "content": "Also, if you or anyone reading this has the karma, please disable the gus.heck@olin.edu account. Mail to it (and thus the inline references you used here) don't actually reach me. I haven't worked there since 2004, and there is no way for me to regain control of that account using that address. ",
            "id": "comment-14636178"
        },
        {
            "date": "2015-08-09T20:55:16+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1694909 from Joel Bernstein in branch 'dev/trunk'\n[ https://svn.apache.org/r1694909 ]\n\nSOLR-7441: Updated CHANGES.txt ",
            "id": "comment-14679340"
        },
        {
            "date": "2015-08-09T20:55:56+0000",
            "author": "Joel Bernstein",
            "content": "Release with Solr 6 ",
            "id": "comment-14679341"
        }
    ]
}