{
    "id": "SOLR-7583",
    "title": "API to download snapshot files/restore via upload",
    "details": {
        "components": [
            "SolrCloud"
        ],
        "type": "Improvement",
        "labels": "",
        "fix_versions": [],
        "affect_versions": "None",
        "status": "Open",
        "resolution": "Unresolved",
        "priority": "Major"
    },
    "description": "What we are looking for:\nSolrCloud and Solr should have APIs to download a snapshot via HTTP. \nFor single node Solr, this API will find a snapshot and stream it back over HTTP. For SolrCloud, this API will find a Replica that has the snapshot with requested name and stream the snapshot from that replica. Since there are multiple files inside a snapshot, the API should probably zip the snapshot folder before sending it back to the client.\n\nWhy we need this:\nthis will allow us to create and fetch fully contained archives of customer data where each backup archive will contain Solr index as well as other customer data (DB, metadata, files, etc).",
    "attachments": {
        "SOLR-7583.patch": "https://issues.apache.org/jira/secure/attachment/12734941/SOLR-7583.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2015-05-22T17:58:49+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1681173 from Timothy Potter in branch 'dev/trunk'\n[ https://svn.apache.org/r1681173 ]\n\nSOLR-7583: Allow auto-commit to be set with system properties in data_driven_schema_configs and enable auto soft-commits for the bin/solr -e cloud example using the Config API. ",
            "id": "comment-14556518"
        },
        {
            "date": "2015-05-22T18:00:13+0000",
            "author": "Timothy Potter",
            "content": "Wrong ticket number ... reverting! sorry for the noise ",
            "id": "comment-14556522"
        },
        {
            "date": "2015-05-22T21:17:48+0000",
            "author": "Greg Solovyev",
            "content": "This patch has this feature implemented on 5_x branch. The patch includes unit test for downloading a snapshot as a zip file.\nREST API for downloading a zipped snapshot:\n\nhttp://localhost:8983/solr/collection1/replication?command=downloadbackup&name=namedBackupName&wt=filestream\n\nThe response returns a chunked filestream. First 8 bytes have the file size, and rest of the stream is structured the same way as if you were making \"filecontent\" request: \n\n\t4 bytes for chunk size\n\tN bytes for next chunk\n\n\n\nthere is no support for checksum yet ",
            "id": "comment-14556842"
        },
        {
            "date": "2015-05-26T18:14:25+0000",
            "author": "Greg Solovyev",
            "content": "Updated patch for trunk. Patch includes:\n\n\tAPI + unit tests for downloading zipped snapshot\n\tAPI + unit tests for restoring a core by uploading snapshot files\n\tAPI + unit tests for restoring a core by uploading a zipped snapshot directory\n\n ",
            "id": "comment-14559529"
        },
        {
            "date": "2015-05-26T18:14:36+0000",
            "author": "Greg Solovyev",
            "content": "\nDownloading a zipped snapshot:\n\nhttp://solr-host:solr-port/collection-name/replication?command=downloadbackup&name=snaphostname&wt=filestream\n\n\n    InputStream stream = null;\n    URL url = new URL(requestURL);\n    stream = url.openStream();\n    FastInputStream is = new FastInputStream((InputStream) stream);  \n    String fileName = \"downloaded.\" + backupName + \".zip\";\n    String savePath = createTempDir().resolve(fileName).toAbsolutePath().toString();\n    File outFile = new File(savePath);\n    FileOutputStream fos = new FileOutputStream(outFile);\n    Long totalRead = 0L;\n    try {\n      byte[] longbytes = new byte[8];\n      is.readFully(longbytes);\n      Long fileSize = readLong(longbytes);\n      while(fileSize > totalRead) {\n        //store bytes representing packet size here\n        byte[] intbytes = new byte[4]; \n        //read packet size\n        is.readFully(intbytes);\n        int packetSize = readInt(intbytes);\n        //read the packet\n        byte[] buf = new byte[packetSize];\n        is.readFully(buf, 0, packetSize);\n        fos.write(buf);\n        fos.flush();\n        totalRead+=(long)packetSize;\n      }\n    } finally  {\n      //close streams\n      IOUtils.closeQuietly(is);\n      fos.close();      \n    }\n\n ",
            "id": "comment-14559530"
        },
        {
            "date": "2015-05-26T18:17:54+0000",
            "author": "Greg Solovyev",
            "content": "Restoring a core by uploading a zipped snapshot:\n\n    ContentStreamUpdateRequest restoreReq = new ContentStreamUpdateRequest(\"/replication\");\n    restoreReq.setParam(ReplicationHandler.COMMAND, ReplicationHandler.CMD_RESTORE);\n    restoreReq.setParam(ReplicationHandler.FILE_FORMAT, ReplicationHandler.FILE_FORMAT_ZIP);\n    restoreReq.addFile(zipFileOutput, \"application/octet-stream\");\n    \n    HttpSolrClient client = new HttpSolrClient(\"http://localhost:8983/\" + restoredCoreName);  \n    NamedList<Object> result = client.request(restoreReq);\n\n ",
            "id": "comment-14559539"
        },
        {
            "date": "2015-05-26T18:19:04+0000",
            "author": "Greg Solovyev",
            "content": "Restoring a core by uploading a snapshot folder:\n\n    ContentStreamUpdateRequest restoreReq = new ContentStreamUpdateRequest(\"/replication\");\n    restoreReq.setParam(\"command\", ReplicationHandler.CMD_RESTORE);\n    files = tmpBackupDir.listFiles(); //folder where we have snapshot files\n    haveFiles = false;\n    if (files != null) {\n        for (File f : files) {\n            if (f != null && f.getName() != null && f.exists()\n                    && f.length() > 0) {\n                haveFiles = true;\n                restoreReq.addFile(f, \"application/octet-stream\");\n            }\n        }\n    }\n\n ",
            "id": "comment-14559544"
        },
        {
            "date": "2015-05-26T18:25:44+0000",
            "author": "Greg Solovyev",
            "content": "cleaned up the patch ",
            "id": "comment-14559561"
        },
        {
            "date": "2015-06-01T16:11:58+0000",
            "author": "Ramkumar Aiyengar",
            "content": "I mainly looked at this from an API PoV. Do we need a separate 'downloadbackup' command? May be we can extend 'backup' to have it \"output\" to the request? I was actually talking to Varun Thacker today at Berlin Buzzwords about backup today and he was mentioning that he wishes to extend backups to arbitrary streams.. ",
            "id": "comment-14567500"
        },
        {
            "date": "2015-06-02T03:40:40+0000",
            "author": "Greg Solovyev",
            "content": "Hi Ramkumar Aiyengar, I thought of adding an \"output\" kind of option to backup command, but given that backup is asynchronous, it didn't make sense to block the request and hold it until a backup completes. Maybe, the alternative to current implementation is to stream directly back to the response without an intermediate step of copying files and compressing them. The downside of streaming the zipped archive directly back is that when a download fails due to network interruption, it won't be possible to followup with a \"continue\" request that will skip to the last byte in the previously requested backup and continue streaming where previous request dropped off.  With current approach, because the backup is stored and is immutable, it is possible to add an option to continue the download where it was left of and to add checksum verification. ",
            "id": "comment-14568459"
        },
        {
            "date": "2015-06-02T07:47:47+0000",
            "author": "Ramkumar Aiyengar",
            "content": "There may be value in adding an 'async' option to backup so that you have the option for it to be synchronous. Many of our other APIs do it. You can then force async=false when an output is desired. ",
            "id": "comment-14568716"
        }
    ]
}