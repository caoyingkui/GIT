{
    "id": "LUCENE-1100",
    "title": "StandardTokenizer incorrectly types certain values",
    "details": {
        "labels": "",
        "priority": "Minor",
        "components": [
            "modules/analysis"
        ],
        "type": "Bug",
        "fix_versions": [],
        "affect_versions": "2.2",
        "resolution": "Won't Fix",
        "status": "Closed"
    },
    "description": "The StandardTokenizer incorrectly marks floating point values as <HOST>.  See https://issues.apache.org/jira/browse/LUCENE-1068.  There may be other things like this that are marked as incorrectly as well.",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "date": "2010-03-01T13:19:35+0000",
            "content": "when having in a text : \"5.3.2-bl\u00e0hblah\" this is detected as a NUM... and \"2.45\" is detected as a HOST...\nI think when there's a mix of alpha and num the '-' should be considered as a whitespace... and that a \n{NUMERIC}[.,]{NUMERIC}\n must be a NUM and not a HOST.\nalso something like \"image.gif\" shouldn't be a HOST...\nI know it's very difficult to make this flex file perfect.\n\n\"TEST\" and \"2010\" are ALPHANUM, I would prefer to distinguish a ALPHA and a NUMERIC instead of ALPHANUM...\n\"2,5\" and \"9-juin-2009\" are NUM, i would prefer to distinguish NUM_DECIMAL and NUM_LIKE\n\ni think sometimes we would have a better index if we could have 2 tokens with the same part of the file.\nfor exemple : \"5.3.2-bl\u00e0hblah\" would make a token but another token \"bl\u00e0hblah\" should be added.\nmaybe we should do it in the StandardTokenizer to complete the power of the flex file ? ",
            "author": "Ronan KERDUDOU",
            "id": "comment-12839670"
        },
        {
            "date": "2011-01-26T12:08:05+0000",
            "content": "The old StandardTokenizer behaviour was deprecated in Lucene 3.1 and replaced by a new one doing Unicode Standard Annex #29 segmentation. The deprecated code will not get any fixes anymore. ",
            "author": "Uwe Schindler",
            "id": "comment-12986970"
        }
    ]
}