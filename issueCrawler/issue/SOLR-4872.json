{
    "id": "SOLR-4872",
    "title": "Allow schema analysis object factories to be cleaned up properly when the core shuts down",
    "details": {
        "affect_versions": "4.3",
        "status": "Open",
        "fix_versions": [],
        "components": [],
        "type": "Improvement",
        "priority": "Major",
        "labels": "",
        "resolution": "Unresolved"
    },
    "description": "I have a need, in an TokenizerFactory or TokenFilterFactory, to have a shared cache that is cleaned up when the core is torn down. \n\nThere is no 'close' protocol on these things, and Solr rejects analysis components that are SolrCoreAware. \n\nPossible solutions:\n\n\n\tadd a close protocol to these factories and make sure it gets called at core shutdown.\n\tallow these items to be 'core-aware'.\n\tinvent some notion of 'schema-lifecycle-aware'.",
    "attachments": {
        "solr-4872.patch": "https://issues.apache.org/jira/secure/attachment/12587616/solr-4872.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Steve Rowe",
            "id": "comment-13669552",
            "date": "2013-05-29T18:37:47+0000",
            "content": "On SOLR-414, Ryan McKinley wrote about the SolrResourceLoader's *Aware restrictions:\n\n\nAdds valid class checking for \"aware\" registration. This is a simple check made to limit the scope of who can implement SolrCoreAware/ResourceLoaderAware if we want, we could easily remove this constraint\n\nSo I think we could just remove them entirely.  Does anybody object? "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13669559",
            "date": "2013-05-29T18:46:15+0000",
            "content": "Also note hossmans cooment in that same issue:\n\nhttps://issues.apache.org/jira/browse/SOLR-414?focusedCommentId=12548501&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-12548501 "
        },
        {
            "author": "Benson Margulies",
            "id": "comment-13669564",
            "date": "2013-05-29T18:49:32+0000",
            "content": "I added a comment to 414, which I'll repeat here.\n\nI need a cleanup, since finalizers are evil and creating an entire PhantomReference thread/queue seems extreme. I'd be happy for some other means for an analyzer factory to be called back for cleanup at an appropriate time (which happens to be when the core comes down). "
        },
        {
            "author": "Benson Margulies",
            "id": "comment-13681131",
            "date": "2013-06-12T11:29:02+0000",
            "content": "Due to LUCENE-2145, Tokenizers can't clean themselves up completely on close, which makes this more urgent. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13681322",
            "date": "2013-06-12T15:13:43+0000",
            "content": "This issue is confusing, because the title refers \"Analyzer\" but them there are comments referring to \"Tokenizer\".\n\nHere is my suggestion:\n1. Figure out which class you are working with \n2. Make sure Analyzer.close() is called correctly from solr.\n3. Override this method to clean things up "
        },
        {
            "author": "Benson Margulies",
            "id": "comment-13681348",
            "date": "2013-06-12T15:55:48+0000",
            "content": "I'm working with all of these classes, of course.\n\nIn the schema.xml, I have an analyzer element. It does not name an analyzer class, but rather a tokenizer class and some filters. Robert's comment suggests that the solution to my problem might be to subclass StandardAnalyzer to handle my closing needs instead of depending on the implicit use of it. Assuming, of course, that item #2 in Robert's list proves out.\n\nMy original request was to have CoreAware work for my TokenizerFactory, because I wanted to use ThreadLocals to keep around some per-core (or, if you prefer, per-schema) items that would live for the lifetime of a core.\n\nThere is no close protocol on TokenizerFactory. If there was one, all would be OK.\n\nSolr TokenizerFactories don't return Analyzers, they return Tokenizers. Tokenizers have a close. So, in theory, I could work something off of the Tokenizer close method. Except, maybe, for LUCENE-2145, which reports that Tokenizer.close is not the last word in the lifetime of a Tokenizer. If Solr doesn't participate in that trick, I could still use it.\n\nI honestly don't entirely understand why Ben, an ex-co-worker-of mine, dragged Analyzers into the picture in his remarks in LUCENE-2145. However, if he's right, and Tokenizer.close() amounts to Tokenizer.cleanUpReader(), I am left wishing over there that there was, a Tokenizer.reallyClose(). But that's a wish on LUCENE-2145.\n\n\n "
        },
        {
            "author": "Benson Margulies",
            "id": "comment-13681442",
            "date": "2013-06-12T18:02:21+0000",
            "content": "Here's a little more research. While it is possible to configure Solr to use a particular Lucene analyzer, it's very undesirable. The usual thing is to use the invisible (and final) TokenizerChain analyzer, which accepts the a tokenizer and a list of filters. Since users want to mix-and-match tokenizers and filters, it is not a good idea to supplant TokenizerChain with an Analyzer. TokenizerChain does not override close(). The net result as far as I can see is that there is no good way to control the reuseStrategy or otherwise get close() behavior inside Solr.\n "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13681446",
            "date": "2013-06-12T18:06:26+0000",
            "content": "\nHowever, if he's right, and Tokenizer.close() amounts to Tokenizer.cleanUpReader(), I am left wishing over there that there was, a Tokenizer.reallyClose().\n\nThe close method is on TokenStream. Maybe it would be better if TokenStream.close() meant reallyClose \n\nI dont understand why Tokenizer.close() needs to do anything with a Reader. Really since the reader is passed in from the consumer, consumer should be responsible for closing it. At least this is my opinion.\n\nThe only downside to changing all this, is it would impact all lucene installations in a sneaky way, as now the users are responsible for closing their Readers, whereas they weren't before. "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13681802",
            "date": "2013-06-13T00:34:42+0000",
            "content": "This issue seems to have gotten really convoluted and confusing, so lemme type my understanding of what's going on here to see if it clears things up for people (or if i myself am totally misunderstanding)...\n\n\n\tBenson filed an issue requesting that Solr allow \"analyzers\" to be SolrCoreAware\n\t\n\t\tthe (entire?) motivation for this apparently being that he wants to be able to register a CloseHook with the SolrCore that can do some housekeeping when it's no longer needed (ie: the SolrCore is closed)\n\t\tie: Benson doesn't actually seem to specifically want/need access to the SolrCore in his analysis code, he just wants some mechanism to cleanup stuff and having SolrCoreAware+CloseHook would give him a mechanism ... (XY Problem?)\n\t\n\t\n\tBenson said \"analyzer\" in the summary of the issue, but what he really ment was\nanalysis factories\n\tthen there was some confusion about Tokenizer.close(), and a ref to LUCENE-2145 (which i suspect isn't particularly applicable since it's pretty old and the APIs have evolved heavily since then)\n\t\n\t\tRob pointed out that Tokenizer.close() probably shouldn't close the reader, that should be the callers job \u2013 this seems like a completely independent discussion that should happen in another more specific Jira\n\t\tall of this seems like a red herring to the matter at hand since, as mentioned above, what (seems to be) really desired is a way for the factories to be able to create some data reused by multiple instances those factories create, and then clean that data up in a responsible manner.\n\t\n\t\n\n\n\n\n\nDoes that sound like an accurate summary of things so far?\n\nI think rob hit the nail on the head with part of the problem...\n\nMake sure Analyzer.close() is called correctly from solr.\n\nAssuming Analyzer's are being closed properly in Solr, then benson's goal (seems) to be easily solved be making sure the the analyzer's that Solr constructs on the fly using analysis factories close those factories if they need it \u2013 A quick skim of the code doesn't give me any confidence that Solr (specifically i would expect it to be something in IndexSchema) is closing analyzers properly ... probably because way, way, WAY, back in the day Analyzer didn't have a close method, and i guess nothing in Solr broke when that method was added.\n\nSo i think the best way forward is to:\n\n\n\tfix whatever needs fixed to make sure IndexSchema closes all of the Analyzer's it's keeping track of when appropriate to do so.\n\tdo one of the following...\n\t\n\t\tmake AbstractAnalysisFactory implement Closable with a NOOP default and add a close() method to Solr's TokenizerChain that delegates to all the factories\n\t\tadd a close() method to Solr's TokenizerChain that does \"instanceof Closable\" checks on each factory it's wrapping to know which ones want to be closed.\n\t\n\t\n\n\n\nthoughts? "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13681810",
            "date": "2013-06-13T00:49:36+0000",
            "content": "\nthen there was some confusion about Tokenizer.close(), and a ref to LUCENE-2145 (which i suspect isn't particularly applicable since it's pretty old and the APIs have evolved heavily since then) \n\nNo, I think this is actually the core issue. Tokenizer.close() doesnt mean... close the Tokenizer. it means close the reader. This is super-confusing and it means Benson has no way to release resources. I really think we should fix this, not add any hacks to solr. "
        },
        {
            "author": "Benson Margulies",
            "id": "comment-13681816",
            "date": "2013-06-13T00:58:02+0000",
            "content": "Hoss is right that I made a mess of my original description. So I fixed the description.\n\nSo, let's imagine that the TokenizerChain (a subclass of Analyzer) class had an override of close(), and that Solr arranged to call called at core shutdown. \n\nWhat would it do? The factories that are referenced by TokenizerChain have no close protocol at all. \n\nAs Rob points out, the individual Tokenizers that the factories produce do have a close() protocol that causes other problems. But my real issue, sadly obscured by my sloppy original writing job, is not with tokenizers, it's with TokenizerFactory and TokenFilterFactory-ies.\n\nIndependently, when people are using our Lucene classes from Lucene-and-not Solr, the problem in LUCENE-2145 makes it hard to clean up properly. However, for performance reasons, I want to hold the resources up in the factories, not down in the Tokenizers.\n\n "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13681819",
            "date": "2013-06-13T00:59:14+0000",
            "content": "No, I think this is actually the core issue. Tokenizer.close() doesnt mean... close the Tokenizer. it means close the reader. This is super-confusing and it means Benson has no way to release resources. \n\nYou're assuming that the resources in question are tied to a concrete Tokenizer instance \u2013 but if you use TokenizerFactories (which 99.999% of solr users do) then you're going to get a shiny new Tokenizer instance for every Reader \u2013 hence my point that it seems like you really want the factory to be caching the data, and then cleaning it up when the factory is closed.  \n\nThere may also be changes desired to the semantics of Tokenizer.close, but that seems like a much bigger, and largely independent issue: even if that happens, we still need to get Solr closing analyzers and having TokenizerChain call close on any Analysis Factories it has in it. "
        },
        {
            "author": "Benson Margulies",
            "id": "comment-13681821",
            "date": "2013-06-13T01:00:24+0000",
            "content": "Hoss, did I misread? It seemed to me that there was no close() protocol in the factory structure, but I could easily have missed one? "
        },
        {
            "author": "Benson Margulies",
            "id": "comment-13682167",
            "date": "2013-06-13T12:07:25+0000",
            "content": "I'm working on this. "
        },
        {
            "author": "Benson Margulies",
            "id": "comment-13682187",
            "date": "2013-06-13T12:36:15+0000",
            "content": "If schemas are shared in a container, how do we decide when to close down the analyzers in them? "
        },
        {
            "author": "Benson Margulies",
            "id": "comment-13682192",
            "date": "2013-06-13T12:43:16+0000",
            "content": "Just so you can see how this is shaping \u2013 definitely not done. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13682283",
            "date": "2013-06-13T14:25:33+0000",
            "content": "\nYou're assuming that the resources in question are tied to a concrete Tokenizer instance \u2013 but if you use TokenizerFactories (which 99.999% of solr users do) then you're going to get a shiny new Tokenizer instance for every Reader \u2013 hence my point that it seems like you really want the factory to be caching the data, and then cleaning it up when the factory is closed. \n\nYou don't know what you are talking about. Please dont accuse me of assuming anything.\n\nALL Tokenizers are created once per-thread per-field and reused across multiple readers.\n\nThanks "
        },
        {
            "author": "Benson Margulies",
            "id": "comment-13682347",
            "date": "2013-06-13T15:33:45+0000",
            "content": "Rob,\n\nI'm proceeding with the missing close protocols at the level of the Solr index and the Solr TokenizerChain analyzer, and I hope that you and Hoss can agree on what comes next after that.\n\n--benson "
        },
        {
            "author": "Benson Margulies",
            "id": "comment-13682349",
            "date": "2013-06-13T15:37:21+0000",
            "content": "improved patch. This gets as far as seeing FieldTypes get closed when the core gets closed. "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13682471",
            "date": "2013-06-13T17:52:30+0000",
            "content": "You don't know what you are talking about.\n\nI know enough to know that i don't understand tokenstream re-use enough to have an opinion about your opinions/concerns relating to Tokenizer.close() \u2013 which is why i didn't want to talk about that and suggested it was a distinct issue that should be discussed separately.\n\nBecause i also know enough to know that for a lot of users, caching some data \"once per-thread per-field and reused across multiple readers\" isn't what they want \u2013 if it was, then classes like StopFilterFactory wouldn't need to bother keeping track of \"CharArraySet stopWords\" from a parsed file and passing it to each instance the factory creates, they could just let the filter parse the file in it's constructor.\n\nSome users may want to use/cache data/services in the factory and re-use those in all instances produced by that factory, even if those instances are for different fields (or in different threads) ... that was the point behind my suggestion:\n\n\n\tfix solr to make sure we're closing Analyzers properly\n\tmake analysis factories (optionally?) implement closable so they can cleanup resources\n\tmake solr's TOkenizerChain (analyzer) call close on the analysis factories it wraps\n\n\n\nBecause then that way, if people like benson want to create something similar to SynonymFilter but backed by some RemoteSynonymNetworkService, he can instantiate a single RemoteSynonymNetworkService in his BensonsSynonymFilterFactory, reuse his single instance of RemoteSynonymNetworkService across all fields (and all threads) that use the same BensonsSynonymFilterFactory instance (ie: all Solr fields and dynamic fields that re-use the same <fieldType/>) and tear down his (single) RemoteSynonymNetworkService when BensonsSynonymFilterFactory.close() is called.\n "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13682692",
            "date": "2013-06-13T20:44:59+0000",
            "content": "If schemas are shared in a container, how do we decide when to close down the analyzers in them?\n\nNo analysis components in core Lucene/Solr need to explicitly release resources AFAIK, so it's a rather new issue (and perhaps very rare?)\n\nOne random idea: Maybe you could use a finalizer on your custom factory?  This may or may not work depending on the nature of the cleanup you need to do - finalizers are tricky.\n\nAnother idea: do cleanup when whole core-container is closed, not individual cores.  Whether this would work or not again depends on the nature of the resources being freed I guess. "
        },
        {
            "author": "Benson Margulies",
            "id": "comment-13682725",
            "date": "2013-06-13T20:58:50+0000",
            "content": "Yonik,\n\nFinalizers have horrible GC characteristics. Also, their timing is indeterminate, which might bother someone.\n\nIf you look at the patch, for a non-shared schema, the patch sets off cleanup when a core is closed. For a shared schema, it cleans up when the container is closed. This is adequate for my purposes.\n\n--benson "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13682731",
            "date": "2013-06-13T21:05:53+0000",
            "content": "Finalizers have horrible GC characteristics.\n\nYeah, I know in general... but seems negligible for a few really long lived objects? "
        },
        {
            "author": "Benson Margulies",
            "id": "comment-13682749",
            "date": "2013-06-13T21:12:44+0000",
            "content": "Yonik,\n\nThis sort of travels around full circle in the exchange of views between Hoss and Rob.\n\nFor the top-level factory components, I have to agree. They are few in number and so having them carry finalizers around would be pretty painless.\n\nFor individual objects of shorter lifetime, finalizers are more of a problem.\n\nIn any case, what I really want to know is if you are objecting to my patch. I don't want to do the work to finish it if you, or anyone else, is going to -1 it into limbo. \n\nHere's an argument by analogy: why bother to have CoreAware on the solrconfig side? All those handler objects are similarly few in number and could have finalizers, but someone felt that it was important for them to be explicitly aware of the core lifecycle. My idea here is to correspondingly make the schema objects aware of the schema lifecycle. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13683402",
            "date": "2013-06-14T14:33:37+0000",
            "content": "For individual objects of shorter lifetime, finalizers are more of a problem.\n\nRight, but I'm not proposing adding any new finalizers in lucene/solr - I was proposing you solve your specific issue that way.\n\nHere's the thing: guaranteeing that you call close() once and only once after all users are done with an object adds a lot of complexity and constrains implementation.  The schema sharing code is likely to change in the future esp as we move toward named schemas, and I imagine sharing would be the default (I can't imagine why it wouldn't be at least).  Modifiable schemas (adding fields / field types) on the fly also complicate things, esp in the future if/when we are able to change an existing field type.  This would also constrain other optimizations we might do like share common analysis components between different field types.  So the more I think about it, the more it seems like a bad idea to have close() on FieldType and friends.\n\nIt seems fine to allow SolrCoreAware, and I could also see value in the addition of a CoreContainer.addShutdownHook() as well.   "
        },
        {
            "author": "Benson Margulies",
            "id": "comment-13683443",
            "date": "2013-06-14T15:28:51+0000",
            "content": "Originally, Hoss documented some disquiet with using SolrCoreAware. If I add you two together and divide, I come up with the following proposal ...\n\n\n\twhat you can see in the patch so far; a mechanism to get lifecycle awareness into the schema object.\n\tinstead of a close method on the factories, allow them to implement a new interface, SchemaComponentLifecycle. This would achieve Hoss' goal of avoiding tangling schema and core. Then IndexSchema would invoke via this interface upon schema teardown.\n\n\n\nUltimately, I have to navigate amongst you all, so I will await further exchange of views. "
        },
        {
            "author": "Mikhail Khludnev",
            "id": "comment-14220645",
            "date": "2014-11-21T08:05:48+0000",
            "content": "fwiw, if someone else need to shoot himself in leg make TokenizerFactory or TokenFilterFactory SolrCoreAware ie violate restriction described at https://wiki.apache.org/solr/SolrPlugins#SolrCoreAware, just make your class implements QueryResponseWriter, and supply it with empty method impls. It will work until the assertion is improved. "
        }
    ]
}