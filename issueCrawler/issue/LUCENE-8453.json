{
    "id": "LUCENE-8453",
    "title": "Add example settings to Korean analyzer components' javadocs",
    "details": {
        "components": [
            "general/javadocs"
        ],
        "status": "Closed",
        "resolution": "Fixed",
        "fix_versions": [
            "7.5",
            "master (8.0)"
        ],
        "affect_versions": "7.4",
        "labels": "",
        "priority": "Minor",
        "type": "Improvement"
    },
    "description": "Korean analyzer (nori) javadoc needs example schema settings.\n\nI'll create a patch.",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "id": "comment-16576242",
            "author": "Tomoko Uchida",
            "content": "Created a PR. It is based on Kuromoji's examples.\n\nhttps://github.com/apache/lucene-solr/pull/434\n\nNote: I've tested all parameters in this example schemas with\u00a0CustomAnalyzer, but not tested with Solr yet. Check the XML settings with Solr, please. ",
            "date": "2018-08-10T13:09:36+0000"
        },
        {
            "id": "comment-16576321",
            "author": "Tomoko Uchida",
            "content": "And, I think it would be better if Korean natives check that example values are good as default\u00a0\u00a0 ",
            "date": "2018-08-10T14:02:57+0000"
        },
        {
            "id": "comment-16576876",
            "author": "Uwe Schindler",
            "content": "I added the solr schema fragment to the solr issue. Works for me: SOLR-12655\n\nYour example is missing lowercasing (like the analyzer does), so western text is correctly normalized. ",
            "date": "2018-08-10T21:29:22+0000"
        },
        {
            "id": "comment-16576880",
            "author": "Uwe Schindler",
            "content": "The full schema snippet is that is identical to default KoreanAnalyzer as shipped in Lucene:\n\n\n<fieldType name=\"text_ko\" class=\"solr.TextField\" >\n  <analyzer>\n    <!-- decompoundMode: mixed (is keep original term and add all decompounded terms), discard (default, removes the compound form, only keeps the parts), none (no decompounding) -->\n    <tokenizer class=\"solr.KoreanTokenizerFactory\" decompoundMode=\"discard\" outputUnknownUnigrams=\"false\"/>\n    <!-- removes some part of speech stuff like EOMI (Pos.E) -->\n    <filter class=\"solr.KoreanPartOfSpeechStopFilterFactory\" />\n    <!-- Replaces term text with the Hangul transcription of Hanja characters, if applicable: -->\n    <filter class=\"solr.KoreanReadingFormFilterFactory\" />\n    <filter class=\"solr.LowerCaseFilterFactory\" />\n  </analyzer>\n</fieldType>\n\n ",
            "date": "2018-08-10T21:30:57+0000"
        },
        {
            "id": "comment-16576915",
            "author": "Tomoko Uchida",
            "content": "KoreanAnalyzer discards some parameters (for example, KoreanTokenizerFactory has additional parameters \"userDictionary\" and \"userDictionaryEncoding\".)\u00a0 I think Javadoc examples should include all available parameters so my example settings include all parameters which are accepted by TokenizerFactory/TokenFilterFactoys.\n\nAbout LowerCaseFilterFactory, of course it is needed in complete Analyzer settings,\u00a0\n\nI \"feel\" Javadoc example should focus on the targeted\u00a0component only (like Kuromoji example settings below.)\n\nhttps://lucene.apache.org/core/7_4_0/analyzers-kuromoji/org/apache/lucene/analysis/ja/JapanesePartOfSpeechStopFilterFactory.html ",
            "date": "2018-08-10T22:11:35+0000"
        },
        {
            "id": "comment-16576941",
            "author": "Tomoko Uchida",
            "content": "So here are my proposal for javadoc's example settings (my pull request)\u00a0\u00a0\n\nFor KoreanTokenizerFactory:\n\n<fieldType name=\"text_ko\" class=\"solr.TextField\">\n   <analyzer>\n     <tokenizer class=\"solr.KoreanTokenizerFactory\"\n       decompoundMode=\"discard\"\n       userDictionary=\"user.txt\"\n       userDictionaryEncoding=\"UTF-8\"\n       outputUnknownUnigrams=\"false\"\n     />\n  </analyzer>\n </fieldType>\n\n\nFor KoreanPartOfSpeechStopFilterFactory:\n\n<fieldType name=\"text_ko\" class=\"solr.TextField\">\n    <analyzer>\n      <tokenizer class=\"solr.KoreanTokenizerFactory\"/>\n      <filter class=\"solr.KoreanPartOfSpeechStopFilterFactory\"\n              tags=\"E,J\"/>\n    </analyzer>\n </fieldType>\n\n\nFor KoreanReadingFormFilterFactory:\n\n<fieldType name=\"text_ko\" class=\"solr.TextField\">\n   <analyzer>\n     <tokenizer class=\"solr.KoreanTokenizerFactory\"/>\n     <filter class=\"solr.KoreanReadingFormFilterFactory\"/>\n   </analyzer>\n </fieldType>\n\n\n\nUpdate:\nAdded brief descriptions for each parameter (please see the pull request,) though unfortunately, Kuromoji's documentation lacks those. ",
            "date": "2018-08-10T22:49:34+0000"
        },
        {
            "id": "comment-16577014",
            "author": "Tomoko Uchida",
            "content": "Slightly off topic, feel free to ignore, but I think Solr example settings should be removed from TokenizerFactory/TokenFilterFactory/CharFilterFactory documentation. I suppose there may be historical reasons, so I followed the convention, but it is not reasonable to add Solr schema examples here. Not XML schema examples, but parameter descriptions are needed to each Factory documentation. ",
            "date": "2018-08-11T02:19:04+0000"
        },
        {
            "id": "comment-16577100",
            "author": "Tomoko Uchida",
            "content": "I've tested those three settings with Solr 7.4.0, works for me. (I copied `lucene-analyzers-nori-7.4.0.jar` and user dictionary file from lucene distribution package to solr lib directory.)  ",
            "date": "2018-08-11T08:42:21+0000"
        },
        {
            "id": "comment-16577106",
            "author": "Tomoko Uchida",
            "content": "I think this pull request is almost ready to merge. Could anyone take care this? I believe documentation for analyzer components is very important & a good starting point to newbies.  ",
            "date": "2018-08-11T09:08:38+0000"
        },
        {
            "id": "comment-16577125",
            "author": "Uwe Schindler",
            "content": "+1. I will merge it soon!\n\nSlightly off topic, feel free to ignore, but I think Solr example settings should be removed from TokenizerFactory/TokenFilterFactory/CharFilterFactory documentation. I suppose there may be historical reasons, so I followed the convention, but it is not reasonable to add Solr schema examples here. Not XML schema examples, but parameter descriptions are needed to each Factory documentation.\n\nThere is an issue open already (I think, can't find it now). I agree, the XML snippets should go away. Instead we can add some Javadoc tag for this like @factoryProp name description. This is much better. We should also document the SPI name of each factory. ",
            "date": "2018-08-11T10:34:32+0000"
        },
        {
            "id": "comment-16577130",
            "author": "Tomoko Uchida",
            "content": "Thank you Uwe Schindler !\n\nand, thanks for your explanation.\nThere is an issue open already (I think, can't find it now). I agree, the XML snippets should go away. Instead we can add some Javadoc tag for this like @factoryProp name description. This is much better. We should also document the SPI name of each factory. ",
            "date": "2018-08-11T10:44:58+0000"
        },
        {
            "id": "comment-16577132",
            "author": "Uwe Schindler",
            "content": "No problem. I merged already. Just running document-linter to verify correctness of Javadocs. ",
            "date": "2018-08-11T10:46:53+0000"
        },
        {
            "id": "comment-16577133",
            "author": "Uwe Schindler",
            "content": "Another idea: To make the propertie sof all analyzers easily available for inspection by the APIs in Solr, we may add runtime annotations to those classes, describing the properties. Just an idea. ",
            "date": "2018-08-11T10:48:57+0000"
        },
        {
            "id": "comment-16577134",
            "author": "ASF subversion and git services",
            "content": "Commit e9addea0871a28517c5202e9d12969719d20c90e in lucene-solr's branch refs/heads/master from Uwe Schindler\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=e9addea ]\n\nMerge branch 'jira/lucene-8453' of https://github.com/mocobeta/lucene-solr-mirror\nLUCENE-8453: Add documentation to analysis factories of Korean (Nori) analyzer module\nThis closes #434 ",
            "date": "2018-08-11T10:50:40+0000"
        },
        {
            "id": "comment-16577135",
            "author": "ASF subversion and git services",
            "content": "Commit d8ecf976124eb519e1f8c66e6749e246976a95d9 in lucene-solr's branch refs/heads/branch_7x from Uwe Schindler\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=d8ecf97 ]\n\nMerge branch 'jira/lucene-8453' of https://github.com/mocobeta/lucene-solr-mirror\nLUCENE-8453: Add documentation to analysis factories of Korean (Nori) analyzer module\nThis closes #434 ",
            "date": "2018-08-11T10:52:17+0000"
        },
        {
            "id": "comment-16577136",
            "author": "Uwe Schindler",
            "content": "Thanks Tomoko Uchida! ",
            "date": "2018-08-11T10:53:10+0000"
        },
        {
            "id": "comment-16577604",
            "author": "Tomoko Uchida",
            "content": "It may not be good manners to add comments to closed issue, but I'd like to leave a reminder for myself.\nAnother idea: To make the propertie sof all analyzers easily available for inspection by the APIs in Solr, we may add runtime annotations to those classes, describing the properties. Just an idea.\nI like the idea, it would be nice that some kind of properties management/discovery mechanism (I have no concrete implementation image, just a vague concept) is equipped in\u00a0 {Tokenizer|CharFilter|TokenFilter}Factorys.\n\nIt will be handy for documentation and Solr, and also for CustomAnalyser (I sometimes use it for my nlp projects.)\n\nI'll try it, not soon, after I'll have finished current ongoing projects. ",
            "date": "2018-08-12T14:34:50+0000"
        }
    ]
}