{
    "id": "SOLR-12659",
    "title": "HttpSolrClient.createMethod does not handle both stream and large data",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [
            "SolrJ"
        ],
        "type": "Bug",
        "fix_versions": [],
        "affect_versions": "6.6.2,                                            7.4",
        "resolution": "Unresolved",
        "status": "Open"
    },
    "description": "When using a ContentStreamUpdateRequest with stream data (through addContentStream()), all other parameters are passed on the URL, leading to the server failing with \"URI is too large\".\n\nThe code below provokes the error using Solrj 7.4, but was first seen on Solr 6.6.2. The problem is in HttpSolrClient.createMethod(), where the presence of stream data leads to all other fields being put on the URL\n\nExample code\n\n\nString stringValue = StringUtils.repeat('X', 16*1024);\n\nSolrClient solr = new HttpSolrClient.Builder(BASE_URL).build();\n\nContentStreamUpdateRequest updateRequest = new ContentStreamUpdateRequest(\"/update/extract\");\nupdateRequest.setParam(\"literal.id\", \"UriTooLargeTest-simpleTest\");\nupdateRequest.setParam(\"literal.field\", stringValue);\nupdateRequest.addContentStream(new ContentStreamBase.StringStream(stringValue));\n\nupdateRequest.process(solr);\n\n\n\nThe client sees the following error:\n\n\norg.apache.solr.client.solrj.impl.HttpSolrClient$RemoteSolrException: Error from server at http://server/solr/core: Expected mime type application/octet-stream but got text/html. <h1>Bad Message 414</h1><pre>reason: URI Too Long</pre>\n\n\n\nError fragment from HttpSolrClient.createMethod\n\n\n      if(contentWriter != null) {\n        String fullQueryUrl = url + wparams.toQueryString();\n        HttpEntityEnclosingRequestBase postOrPut = SolrRequest.METHOD.POST == request.getMethod() ?\n            new HttpPost(fullQueryUrl) : new HttpPut(fullQueryUrl);",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "date": "2018-08-12T15:37:13+0000",
            "content": "I don't think this problem can be fixed without a low-level change to how Solr handles requests, and a corresponding change to how SolrJ puts the request together.\n\nNormally when a \"URI Too Long\" error is encountered, the fix is to change the request from GET to POST, so that the parameters are moved into the request body instead of being part of the URL.  But here, the request is already a POST.  SolrJ uses POST requests for updates, and in this particular case, the body is being used to transfer binary data.\n\nThe only way I can imagine this getting fixed is to change the ERH so that it can handle a multi-part POST \u2013 where one part is the binary data and one part is the parameters.  Then SolrJ will need an adjustment to create these parts separately.  I do not know if this capability is already present or not, but I would suspect that it is not.\n\nSide note:  You are aware that we strongly recommend NOT using the Extracting Request Handler in production, I hope?  It can cause Solr to crash even if you do everything right.  The Tika software which extracts data from rich documents should be run in a completely separate program, so that if it crashes, Solr doesn't go down.  This would indirectly fix the problem described here too \u2013 because the input document(s) would be fully formed and wouldn't need parameters like literal.XXXX to populate the data. ",
            "author": "Shawn Heisey",
            "id": "comment-16577630"
        }
    ]
}