{
    "id": "LUCENE-8087",
    "title": "Record per-term max term frequencies",
    "details": {
        "labels": "",
        "priority": "Minor",
        "resolution": "Unresolved",
        "affect_versions": "None",
        "status": "Resolved",
        "type": "Wish",
        "components": [],
        "fix_versions": []
    },
    "description": "I was mostly interested in doing that in order to get better score upper bounds for LUCENE-4100. However this doesn't help, at least with the tasks that we have for wikimedium10m. I dug this a bit, and this is due to the fact that the upper bound is not much better if we can't make assumptions about the value of the length. Ideally we'd need something like the maximum term frequency for each norm value. I'll post the patch in case someone has another use-case for per-term max term frequencies.",
    "attachments": {
        "LUCENE-8087.patch": "https://issues.apache.org/jira/secure/attachment/12901253/LUCENE-8087.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "id": "comment-16283772",
            "date": "2017-12-08T16:08:12+0000",
            "content": "Here is the patch (which I don't plan to push as explained in the description). ",
            "author": "Adrien Grand"
        },
        {
            "id": "comment-16283818",
            "date": "2017-12-08T16:46:14+0000",
            "content": "\nIdeally we'd need something like the maximum term frequency for each norm value.\n\nI agree this would be ideal: it would let similarity defer computing the maximum impact to query time. Maybe its the right tradeoff to look into, if we get good performance without bloating the index? For big terms it'd be at worst 256 integers. For terms appearing only once or twice the overhead could be kept smaller if we don't encode zeros, etc. ",
            "author": "Robert Muir"
        },
        {
            "id": "comment-16283823",
            "date": "2017-12-08T16:51:08+0000",
            "content": "also for omit norms and omit frequencies cases some stuff would be implicit, if you set both options nothing needs to be written at all. ",
            "author": "Robert Muir"
        },
        {
            "id": "comment-16303854",
            "date": "2017-12-26T13:41:17+0000",
            "content": "I started looking into it but I'm a bit unhappy that this would have a significant impact on the terms dictionary in terms of API and size, while still being subject to poisonous documents that could bump the value of the maximum score for an entire segment. ",
            "author": "Adrien Grand"
        },
        {
            "id": "comment-16303984",
            "date": "2017-12-26T19:40:05+0000",
            "content": "Maybe it doesnt belong in the terms dict? Thinking about the poisonous docs, that kinda implies we should be looking at skipdata or similar? I don't know the new disjunction stuff well, but seems like instead of advance()'ing to the first docid > N, you instead want advance() to work differently. seems hard without baking in the similarity's logic at index time. ",
            "author": "Robert Muir"
        },
        {
            "id": "comment-16304050",
            "date": "2017-12-26T22:55:16+0000",
            "content": "Maybe it doesnt belong in the terms dict? Thinking about the poisonous docs, that kinda implies we should be looking at skipdata or similar? I don't know the new disjunction stuff well, but seems like instead of advance()'ing to the first docid > N, you instead want advance() to work differently.\n\nAgreed. I think this is needed anyway if we want to be able to speed up top-k selection on term queries?\n\nseems hard without baking in the similarity's logic at index time.\n\nI guess the only way to avoid recording similarity-specific information is to record all competitive (freq,norm) pairs for every block of X documents. X would likely need to be quite large since we would need to compute the score for every pair to know the best score in the block. ",
            "author": "Adrien Grand"
        },
        {
            "id": "comment-16304054",
            "date": "2017-12-26T23:06:34+0000",
            "content": "Well its not just similarity-specific information right? Thats annoying in itself, I think its wrong to have to reindex to change a bm25 parameter. But its more than that, It'd have the same challenges as LUCENE-4100: incompatibility with distributed search and incorrect with incremental indexing, except for TFxIDF-type equations where term/collection statistics can be easily factored out. ",
            "author": "Robert Muir"
        },
        {
            "id": "comment-16304061",
            "date": "2017-12-26T23:12:16+0000",
            "content": "\nI guess the only way to avoid recording similarity-specific information is to record all competitive (freq,norm) pairs for every block of X documents. X would likely need to be quite large since we would need to compute the score for every pair to know the best score in the block.\n\nWell again, i'm not sure it'd be so huge in practice. For omitTF+omitNorm fields, we dont have to write anything at all, its implicit. When either TF or norms are omitted, we only have to write a single value. In all other cases, its only \"big terms\", it already takes at least N (256?) docs for the term to even get skipdata at all. I agree it would be best at higher skip levels only though (your X). ",
            "author": "Robert Muir"
        },
        {
            "id": "comment-16309826",
            "date": "2018-01-03T15:55:01+0000",
            "content": "I flushed some ideas about storing information about max scores in skip data at LUCENE-4198. ",
            "author": "Adrien Grand"
        },
        {
            "id": "comment-16350293",
            "date": "2018-02-02T13:10:47+0000",
            "content": "Superseded by LUCENE-4198. ",
            "author": "Adrien Grand"
        }
    ]
}