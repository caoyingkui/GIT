{
    "id": "LUCENE-1701",
    "title": "Add NumericField, make plain text numeric parsers public in FieldCache, move trie parsers to FieldCache",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [
            "core/index",
            "core/search"
        ],
        "type": "New Feature",
        "fix_versions": [
            "2.9"
        ],
        "affect_versions": "2.9",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "In discussions about LUCENE-1673, Mike & me wanted to add a new NumericField to o.a.l.document specific for easy indexing. An alternative would be to add a NumericUtils.newXxxField() factory, that creates a preconfigured Field instance with norms and tf off, optionally a stored text (LUCENE-1699) and the TokenStream already initialized. On the other hand NumericUtils.newXxxSortField could be moved to NumericSortField.\n\nI and Yonik tend to use the factory for both, Mike tends to create the new classes.\n\nAlso the parsers for string-formatted numerics are not public in FieldCache. As the new SortField API (LUCENE-1478) makes it possible to support a parser in SortField instantiation, it would be good to have the static parsers in FieldCache public available. SortField would init its member variable to them (instead of NULL), so making code a lot easier (FieldComparator has this ugly null checks when retrieving values from the cache).\n\nMoving the Trie parsers also as static instances into FieldCache would make the code cleaner and we would be able to hide the \"hack\" StopFillCacheException by making it private to FieldCache (currently its public because NumericUtils is in o.a.l.util).",
    "attachments": {
        "LUCENE-1701.patch": "https://issues.apache.org/jira/secure/attachment/12411313/LUCENE-1701.patch",
        "NumericField.java": "https://issues.apache.org/jira/secure/attachment/12411242/NumericField.java",
        "LUCENE-1701-test-tag-special.patch": "https://issues.apache.org/jira/secure/attachment/12411317/LUCENE-1701-test-tag-special.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2009-06-19T13:59:57+0000",
            "content": "I vote for factories - escaping back-compat woes by exposing minimum interface. ",
            "author": "Earwin Burrfoot",
            "id": "comment-12721787"
        },
        {
            "date": "2009-06-19T15:14:29+0000",
            "content": "Uwe can you also open an issue for handling byte/short/Date with\nNumeric*?\n\nI vote for factories - escaping back-compat woes by exposing minimum interface.\n\nBy this same logic, should we remove NumericRangeFilter/Query and use\nstatic factories instead?\n\nWe can't let fear of our back-compat policies prevent progress.\n\nI seem to be the only one [who's speaking up, at least] who feels\nconsumability of Lucene's APIs is important...\n\nHere's my reasoning: numeric fields are common; many apps need them.\nBut, it's painful to use them today; it's a trap for users because\nLucene acts like it can handle them (eg SortField.INT exists) but then\nRangeQuery is buggy unless you encode the numbers (zero pad ints, use\nSolr's or your own NumberUtils for floats/doubles).  And once you\nfigured out the encoding, you discovered RangeQuery can have horrific\nperformance.\n\nFor the longest time Lucene could not provide good ootb handling of\nnumerics, but now finally an awesome step forward (thank you Uwe!)\ncomes along... and Lucene can provide correct & performant handling of\nnumerics.\n\nSuch an important & useful functionality deserves a consumable API.\nIt should be obvious to people playing with Lucene how to use numeric\nfields.  I should be able to do this:\n\n\nDocument doc = new Document();\ndoc.add(new NumericField(\"price\", 15.50f));\n\n\n\nnot this:\n\n\nDocument doc = new Document();\nField f = new Field(\"price\", new NumericTokenStream(4).setFloatValue(15.50f));\nf.setOmitNorms(true);\nf.setOmitTermFreqAndPositions(true);\ndoc.add(field);\n\n\n\nnor, this:\n\n\nDocument doc = new Document();\ndoc.add(NumericUtils.createFloatField(\"price\", 15.50f));\n\n\n\nWhen I want to reuse, I should be able to call\nNumericField.setFloatValue(), not ask the TokenStream to set the\nvalue.\n\nIn fact, as a user of this API, I shouldn't even have to know that a\npowerful TokenStream was created to index my NumericField.  I\nshouldn't have to know to set those advanced flags on Field.  These\nare implementation details.  In fact with time we may make\nimprovements to these \"implemenation details\", so we don't want such\nimplementation details out in the user's code.\n\nNumericUtils should be utility methods used only by the current\nimplemention.  Ideally it would not even be public, but Java doesn't\ngive us the ability to be package private to \"org.apache.lucene.*\".\n\nHere's what I propose:\n\n\n\tAdd NumericField and NumericSortField, and\n    rename RangeQuery -> TermRangeQuery  (TextRangeQuery?).\n\n\n\n\n\tMove the Numeric FieldCache parsers into FieldCache,\n    and make them (PLAIN_TEXT_INT_PARSER vs NUMERIC_INT_PARSER) public.\n\n\n\n\n\tI would also really like to have NumericField come back when you\n    retrieve the doc; this only requires 1 bit added to the flags\n    stored in each doc's entry in the .fdt file.\n\n\n\nWhy should we make such an excellent addition to Lucene, only to make\nit hard to use? ",
            "author": "Michael McCandless",
            "id": "comment-12721810"
        },
        {
            "date": "2009-06-19T15:41:18+0000",
            "content": "But the same problem like with NumericTokenStream affects also NumericField, because of type safety it will only work with a setXxxValue (if not factory), e.g.\n\ndoc.add(new NumericField(\"price\", precisionStep).setFloatValue(15.50f));\n\n\n\nThis code is not shorter than:\n\ndoc.add(NumericUtils.newFloatField(\"price\", precisionStep, 15.50f));\n\n\n\nAdditionally with LUCENE-1699, we could also add Field.Store.XXX to the factory/ctor. \n\nOK, the factory solution has the problem, that you cannot reuse the field for effectiveness, so this is an argument for the extra class, that has setXxXValue().\n\nFor SortField: The factory code inside NumericUtils is only one Line, you only create a conventional SortField with a specific parser. If we do not want to have the factory in NumericUtils, I could also add an additional ctor option to the normal sortfield (which is still there: it takes the parser, LUCENE-1478). When all parsers are central in the FieldCache, one can create a SortField with one line of code (the current factory demonstrates this). ",
            "author": "Uwe Schindler",
            "id": "comment-12721827"
        },
        {
            "date": "2009-06-19T15:48:32+0000",
            "content": "Mike, I very much agree with everything you said, except \"factory is less consumable than constructor\" and \"add stuff to index to handle NumericField\".\n\nOut of your three examples the second one is bad, no questions. But first and last are absolutely equal in terms of consumability.\nStatic factories are cool (they allow to switch implementations and instantiation logic without changing API) and are as easy to use (probably even easier with generics in Java5) as constructors.\n\nIf we add some generic storable flags for Lucene fields, this is cool (probably), NumericField can then capitalize on it, as well as users writing their own NNNFields.\nTying index format to some particular implementation of numerics is bad design. Why on earth can't my own split-field (vs single-field as in current Lucene) trie-encoded number enjoy the same benefits as NumericField from Lucene core?\n\nBy this same logic, should we remove NumericRangeFilter/Query and use static factories instead?\nI do use factory methods for all my queries and filters, and it makes me feel warm and fuzzy!  Under the hood some of them consult FieldInfo to instantiate custom-tailored query variants, so I just use range(CREATION_TIME, from, to) and don't think if this field is trie-encoded or raw.\n\n\"Simple things should be simple\", okay. Complex things should be simple too, argh!  ",
            "author": "Earwin Burrfoot",
            "id": "comment-12721830"
        },
        {
            "date": "2009-06-19T16:47:37+0000",
            "content": "Here is a first draft of NumericField with the same handling as NumericTokenStream. It is for indexing only, on retrieving stored fields, one would get the numeric field value as a string (according to Number.toString()). Because of this, this class returns in stringValue() the string representation of the numeric value and with tokenStreamValue the NumericTokenStream is returned.\n\nFor SortField I still have the very strong opinion, that here a extra class is not needed. A factory is enough (and even too much, supplying the Parser to SortField would be enough).\n\nI will later post a patch with this file and the moved/made public Parsers. ",
            "author": "Uwe Schindler",
            "id": "comment-12721873"
        },
        {
            "date": "2009-06-19T17:04:50+0000",
            "content": "Having the trie parsers public is good (or public factory method(s) to get the right parser given a set of trie params), but shouldn't they stay with the trie classes?  Or am I misunderstanding where you are proposing to move the parsers? ",
            "author": "Yonik Seeley",
            "id": "comment-12721880"
        },
        {
            "date": "2009-06-19T18:06:19+0000",
            "content": "Yonik, I will explain my intention:\nThe real numeric parsing is always done in NumericUtils, as for conventional FieldCache the real parsing is done in Integer.parseInt() and so on.\nSpecific to the FieldCache is the Parser interface. This parser interface is a java interface specific to FieldCache. FieldCache currently has (private) static parser instances for Number.toString()-type fields. These parser are simple 5-liners and singletons. For trie fields, this is the same, the static parser instances (also singletons) should be moved also to FieldCache, after that both as public constants (like Mike said: PLAIN_TEXT_INT_PARSER and NUMERIC_INT_PARSER).\nCurrently for Trie fields there is a ugly hack in FieldCache, that stops parsing, when a term with lower precision is reached (as trie terms are ordered with highest precision first, the cache for a field is filled, when the first lower-precision term comes). Because of this, the trie parsers throw a unchecked StopFillCacheException to stop the iteration of TermEnum/TermDocs in the Uninverter. This is just a hack and because of package differences this FieldCache-internal exception is made public (see Javadocs). When moving the parser interfaces to FieldCace, this Exception can be hidden again and made private to the FieldCache implementation (until we have the better univerters some time in future, see LUCENE-831). NumericUtils then will only just export a method to get the shift value out of a encoded string (which I forgot to add in LUCENE-1673 when removing ShiftAttribute).\nTrie field parsing does not depend on Trie-specific flags, precisionStep is not needed, so the parsers are real singletons.\n\nSortFields can then simply created in the Following way: new SortField(field, FieldCache.PLAIN_TEXT_INT_PARSER) for a conventional int field (like with SortField.INT) or new SortField(field, FieldCache.NUMERIC_INT_PARSER). giving a NULL parser still does the same as before, it uses FieldCache.PLAIN_TEXT_INT_PARSER implicitely. ",
            "author": "Uwe Schindler",
            "id": "comment-12721914"
        },
        {
            "date": "2009-06-19T18:19:47+0000",
            "content": "Regardless of the fact that plain_int parser is on FieldCache, it still doesn't seem like we should add parsers to FieldCache for every field type.  It's also the case that a single static parser won't be able to handle all the cases... consider future functionality of using positions or payloads to fill out the full value.  A factory allows you to return the correct implementation given the parameters (number of bits to store as position, etc). ",
            "author": "Yonik Seeley",
            "id": "comment-12721915"
        },
        {
            "date": "2009-06-19T18:27:39+0000",
            "content": "When this comes (payloads, CSF,...) we will have the new LUCENE-831 field cache, where we will have a ValueSource-like thing. Until then, a static parser is enough, and the static parser is still in NumericUtils! I want to move it because of this hack with the unchecked exception. When the new FieldCache is alive this is all nonsense. ",
            "author": "Uwe Schindler",
            "id": "comment-12721920"
        },
        {
            "date": "2009-06-19T18:53:42+0000",
            "content": "The exception certainly is a hack - but any new field cache API should be powerful enough to handle trie through the normal APIs that anyone else would have to go through when implementing their own field type.  If Trie needs to be part of the new field cache implementation, that would be a big red flag. ",
            "author": "Yonik Seeley",
            "id": "comment-12721929"
        },
        {
            "date": "2009-06-19T19:20:01+0000",
            "content": "ut any new field cache API should be powerful enough to handle trie through the normal APIs that anyone else would have to go through when implementing their own field type\n\nThis is true, the LUCENE-831 patch contains a TrieValueSource for that (but it does not apply anymore, as contrib/search/trie is no longer available). Because of this, it can be implemented very cleanly.\n\nFor easy usage, I would simply suggest to have the parsers for the current plain text and trie field cache implementation public available as singletons, very simple and hurts nobody. I will post a patch for the whole case soon. NumericField will be tested in the NumericRangeQuery index creation (which is currently very ugly, like meikes comments about the code and reusing Fields/TokenStreams, with NumericField it looks like any other index code).\n\nFor Solr (SOLR-940), there is not need to use NumericField (which is just a helper), the code of TrieField can stay as it is, only some renamings and so on. It just presents a TokenStream to the underlying Solr indexer, as before. ",
            "author": "Uwe Schindler",
            "id": "comment-12721946"
        },
        {
            "date": "2009-06-19T19:37:38+0000",
            "content": "Here is a first draft of NumericField with the same handling as NumericTokenStream.\n\nLooks good Uwe!  Is there an OK default for precisionStep so we don't have\nto make that a required arg?  4? ",
            "author": "Michael McCandless",
            "id": "comment-12721956"
        },
        {
            "date": "2009-06-19T19:49:36+0000",
            "content": "Static factories are cool (they allow to switch implementations and instantiation logic without changing API) and are as easy to use (probably even easier with generics in Java5) as constructors.\n\nCoolness is in the eye of the beholder?\n\nYes, they are cool in that they give the developer (us) future\nfreedom (to change the actual class returned, re-use instances, use\nsingletons, etc.), but not cool (in my eyes) for consumability.\n\nStatic factory classes are a good fit when the impls really should\nremain anonymous because there are trivial differences.  EG the 12\ndifferent impls that can be returned by TopFieldCollector.create are a\ngood example.\n\nBut NumericField vs Field, and SortField vs NumericSortField, are\ndifferent and should be seen as different to consumer of Lucene's API.\n\nIf we add some generic storable flags for Lucene fields, this is cool (probably), NumericField can then capitalize on it, as well as users writing their own NNNFields.\n\n+1  Wanna make a patch?\n\nThen NumericField would just tap in to this extensibility... and,\nsomehow, in our future improved search time document() API, have the\nability to make a NumericField.\n\nWhy on earth can't my own split-field (vs single-field as in current Lucene) trie-encoded number enjoy the same benefits as NumericField from Lucene core?\n\nBecause.... we've decided that this is our core approach to numerics?\n\nSeriously, I don't see that as unfair.  Trie works well.  We have\nchosen it as our way (for now, until something better comes along) of\nhandling numerics.  Just like we've picked a certain format for the\nterms dict and prx file.\n\nSure, we should make it easy (add extensibility) so external fields\ncould store stuff in the index, but that doesn't mean we should hold\nback on Numeric* consumability until we get that extensibility.\n\nI do use factory methods for all my queries and filters, and it makes me feel warm and fuzzy!  Under the hood some of them consult FieldInfo to instantiate custom-tailored query variants, so I just use range(CREATION_TIME, from, to) and don't think if this field is trie-encoded or raw.\n\nSomeday maybe I'll convince you to donate this \"schema\" layer on top\nof Lucene  But I hope there are SOME named classes in there and not\nall static factory methods returning anonymous untyped impls.\n\n\"Simple things should be simple\", okay. Complex things should be simple too, argh! \n\nWhoa, this is all simple stuff?  What should be complex about using\nnumeric fields in Lucene?  This whole issue is \"simple things should\nbe simple\". ",
            "author": "Michael McCandless",
            "id": "comment-12721961"
        },
        {
            "date": "2009-06-19T20:02:40+0000",
            "content": "Because.... we've decided that this is our core approach to numerics?\n\nWe decided to move trie from contrib to core because it was the most stable and usable numeric implementation.  We did not decide to rewrite it, or make it \"special\".  It's not sufficient for everyone, there will be (many) enhancements to trie, and there will be other numeric field types.  Trie is not, and should not be the only numeric field, and should not be baked into the index format.\n\nThe next step after adding NumericField seems to be \"it's a bug if getDocument() doesn't return a NumericField, so we must encode it in the index\".  If that's the case, I'm -1 on adding NumericField in the first place. ",
            "author": "Yonik Seeley",
            "id": "comment-12721972"
        },
        {
            "date": "2009-06-19T20:16:15+0000",
            "content": "I still think we should make NumericSortField strongly typed (not a\nfactory method that returns a SortField w/ the right parser).\n\nI think it's far more consumable, from the user's standpoint. I made\na NumericField when indexing so making a NumericSortField to sort\nmakes it \"obvious\".\n\nIe this:\n\nnew NumericSortField(\"price\");\n\n\n\nis better than this:\n\nnew SortField(\"price\", FieldCache.NUMERIC_FLOAT_PARSER);\n\n\n\nor this:\n\nSortField.getNumericSortField(\"price\", SortField.FLOAT);\n\n\n\nUwe, I agree that if we take the developer's (us) standpoint, the\nimplementation of NumericSortField is so trivial (just pick the right\nparser) that it's tempting to not name the class.  But from the user's\nstandpoint it's less consumable.\n\nRegardless of the fact that plain_int parser is on FieldCache, it still doesn't seem like we should add parsers to FieldCache for every field type.\n\n{Extended,}\nFieldCache already is the central place that holds parsers\nfor all of Lucene's core types; why change that?  Leaving Numeric* out\nis dangerous because then people will naturally assume getFloats() is\nthe method to call. ",
            "author": "Michael McCandless",
            "id": "comment-12721979"
        },
        {
            "date": "2009-06-19T20:26:29+0000",
            "content": "new NumericSortField(\"price\");\n\nMagic.\nHow is this supposed to work?\nHow will the sort field know the exact encoding?  How many bits are stored in a payload or in the position?\nCould I make my own field type that had the same privileges? ",
            "author": "Yonik Seeley",
            "id": "comment-12721983"
        },
        {
            "date": "2009-06-19T20:34:31+0000",
            "content": "I aggree with Yonik, this is too much magic and would not work. There must be at least the type, which would be SortField.FLOAT or something like that). If you keep that in mind, there is really no difference between:\n\n\nnew SortField(\"price\", FieldCache.NUMERIC_FLOAT_PARSER)\n\n\n\nand\n\n\nnew SortField(\"price\", FieldCache.PLAIN_TEXT_FLOAT_PARSER)\n\n\n\nequivalent to:\n\n\nnew SortField(\"price\", SortField.FLOAT)\n\n ",
            "author": "Uwe Schindler",
            "id": "comment-12721988"
        },
        {
            "date": "2009-06-19T20:36:43+0000",
            "content": "It's not sufficient for everyone, there will be (many) enhancements to trie, and there will be other numeric field types. Trie is not, and should not be the only numeric field, and should not be baked into the index format.\n\nBut trie is the best we have today?\n\nAnd it's sooooo much better than we had before?  Prior to trie, with\nLucene directly if you did a RangeQuery on a float/double field, it\nwas a nightmare.  You had to get Solr's NumberUtils (or, roll your\nown) to get something that even returned the correct results.  Then,\nyou'll discover that performance was basically unusable.\n\nThe addition of numeric indexing to Lucene is a major step forward.\nWhy not make it work well with Lucene, today, and as these future\nimprovements arrive, we take them as they come?  Design for today.\n\nAnyway, if push comes to shove (which it seems to be doing!), I can\naccept just returning a Field (not NumericField) from the document at\nsearch time.  I think it's a worse user experience, and will be seen\nas buggy, but it would in fact mean zero change to the index format. ",
            "author": "Michael McCandless",
            "id": "comment-12721989"
        },
        {
            "date": "2009-06-19T20:39:58+0000",
            "content": "\n\nnew NumericSortField(\"price\");\n\nMagic.\nHow is this supposed to work?\nHow will the sort field know the exact encoding? How many bits are stored in a payload or in the position?\nCould I make my own field type that had the same privileges?\n\nWoops, sorry, you're right: you'd need to specify the type, at least.\n\nSo.... how about for SortField we make the parser a required arg (as\nUwe suggested) for numeric types?  Allow null to mean \"give me the\ndefault parser\" for all other types.  And we consolidate all parsers\nin FieldCache. ",
            "author": "Michael McCandless",
            "id": "comment-12721993"
        },
        {
            "date": "2009-06-19T20:53:44+0000",
            "content": "That is what I was talking about all the time!\n\nBut this is all not really the best solution. It is too bad, that LUCENE-831 (not in current form, it is just not discussed to the end) is not to be included into 2.9. I know we will have to stick with parsers until end of days, because the new ValueSource staff and Uninverters was not introduces early enough to be removed with 3.0. And Trie fields with positions/payloads would never work with current FieldCache, so I need no factories.\n\nSo this would be postponed until this is done. Then we could have a ValueSource for trie fields, where you could add these magic stuff like payloads and so on. But until this comes to reality (including CSF), the static parsers is all we have until now and is best placed in FieldCache (because of the strong linkage with this ugly exception to be hidden to the outside).\n\nEarwin, Yonik: I know TrieRange is only one implementation of the whole numeric problem, but none of you ever presented your implementation to the public. This is the best we have now, its included into core and everybody is happy. If you have a better private implementation, you can still use it! ",
            "author": "Uwe Schindler",
            "id": "comment-12722002"
        },
        {
            "date": "2009-06-19T21:19:18+0000",
            "content": "That is what I was talking about all the time!\n\nEh, yeah... somethings things just need a good hashing out!\n\n2.9 is really shaping up to be an awesome release...\n\nBut this is all not really the best solution. It is too bad, that LUCENE-831 (not in current form, it is just not discussed to the end) is not to be included into 2.9.\n\nProgress not perfection!\n\nI know we will have to stick with parsers until end of days, because the new ValueSource staff and Uninverters was not introduces early enough to be removed with 3.0.\n\nWell we are discussing relaxing the back-compat policy... so maybe\nearlier than \"end of days\".\n\nAnd Trie fields with positions/payloads would never work with current FieldCache, so I need no factories.\n\nWe'll cross that bridge when we get there...\n\nSo this would be postponed until this is done. Then we could have a ValueSource for trie fields, where you could add these magic stuff like payloads and so on. But until this comes to reality (including CSF), the static parsers is all we have until now and is best placed in FieldCache (because of the strong linkage with this ugly exception to be hidden to the outside).\n\nI agree.\n\nEarwin, Yonik: I know TrieRange is only one implementation of the whole numeric problem, but none of you ever presented your implementation to the public. This is the best we have now, its included into core and everybody is happy. If you have a better private implementation, you can still use it!\n\nWe shouldn't weaken trie's integration to core just because others\nhave private implementations.  What's important is that we don't\nweaken those private implementations with trie's addition, and I don't\nthink our approach here has done that. ",
            "author": "Michael McCandless",
            "id": "comment-12722017"
        },
        {
            "date": "2009-06-19T22:19:47+0000",
            "content": "Someday maybe I'll convince you to donate this \"schema\" layer on top of Lucene\nIt's not generic enough to be of use for every user of Lucene, and it doesn't aim to be such. It also evolves, and donating something to Lucene means casting it in concrete.\nSo that's not me being greedy or lazy (okay, maybe a little bit of the latter), it's simply not public-quality (as I understand it) code.\nI can share the design if anybody's interested, but everyone's coping with it themselves it seems.\n\nSolr has its own schema approach, and it has its merits and downfalls compared to mine. That's what is nice, we're able to use the same library in differing ways, and it doesn't force its sense of 'best practices' on us. \n\nBut I hope there are SOME named classes in there and not all static factory methods returning anonymous untyped impls.\nSOME of them aren't static :-D\n\nWe shouldn't weaken trie's integration to core just because others have private implementations.\nYou shouldn't integrate into core something that is not core functionality. Think microkernels.\nIt's strange seeing you drive CSFs, custom indexing chains, pluggability everywhere on one side, and trying to add some weird custom properties into index that are tightly interwoven with only one of possible numeric implementations on the other side.\n\nDesign for today.\nAnd spend two years deprecating and supporting today's designs after you get a better thing tomorrow. Back-compat Lucene-style and agile design aren't something that marries well.\n\nWhat's important is that we don't weaken those private implementations with trie's addition, and I don't think our approach here has done that.\nYou're weakening Lucene itself by introducing too much coupling between its components.\n\nIndexReader/Writer pair is a good example of what I'm arguing against. A dusty closet of microfeatures that are tightly interwoven into a complex hard-to-maintain mess with zillions of (possibly broken) control paths - remember mutable deletes/norms+clone/reopen permutations? It could be avoided if IR/W were kept to the bare minimum (which most people are going to use), and more advanced features were built on top of it, not in the same place.\n\nNRT seems to tread the same path, and I'm not sure it's going to win that much turnaround time after newly-introduced per-segment collection. Some time ago I finished a first version of IR plugins, and enjoy pretty low reopen times (field/facet/filter cache warmups included). (Yes, I'm going to open an issue for plugins once they stabilize enough)\n\n\n> If we add some generic storable flags for Lucene fields, this is cool (probably), NumericField can then capitalize on it, as well as users writing their own NNNFields.\n+1 Wanna make a patch?\n\nNo, I'd like to continue IR cleanup and play with positionIncrement companion value that could enable true multiword synonyms. \nI know, I know, it's do-a-cracy. But it's not an excuse for hacks. ",
            "author": "Earwin Burrfoot",
            "id": "comment-12722060"
        },
        {
            "date": "2009-06-20T10:35:29+0000",
            "content": "\nSomeday maybe I'll convince you to donate this \"schema\" layer on top of Lucene\n\nIt's not generic enough to be of use for every user of Lucene, and it doesn't aim to be such.\n\nOh, OK.\n\nSolr has its own schema approach, and it has its merits and downfalls compared to mine. That's what is nice, we're able to use the same library in differing ways, and it doesn't force its sense of 'best practices' on us.\n\nThere's no forcing going on, here.  Even had we added the bit into the\nindex, there's still no \"forcing\".  We're not preventing advanced uses\nof Lucene by providing strong Numeric* support in Lucene.  Simple\nthings should be simple; complex things should be possible...\n\n\n\nBut I hope there are SOME named classes in there and not all static factory methods returning anonymous untyped impls.\n\nSOME of them aren't static :-D\n\nHeh.\n\n\nWe shouldn't weaken trie's integration to core just because others have private implementations.\n\nYou shouldn't integrate into core something that is not core functionality. Think microkernels.\nIt's strange seeing you drive CSFs, custom indexing chains, pluggability everywhere on one side, and trying to add some weird custom properties into index that are tightly interwoven with only one of possible numeric implementations on the other side.\n\nI agree: if Lucene had all extension points that'd make it possible\nfor a good integration of Numeric* without being in \"core\", we should\nuse that.  But we're just not there yet.  We want to get there, and we\nwill, but we can't hold up progress just because we think someday\nwe'll get there.  That's like saying we can't improve the terms dict\nformat because it's not pluggable yet.\n\n\nDesign for today.\n\nAnd spend two years deprecating and supporting today's designs after you get a better thing tomorrow. Back-compat Lucene-style and agile design aren't something that marries well.\n\ndonating something to Lucene means casting it in concrete.\n\nWe can't let fear of back-compat prevent us from making progress.\n\nIndexReader/Writer pair is a good example of what I'm arguing against. A dusty closet of microfeatures that are tightly interwoven into a complex hard-to-maintain mess with zillions of (possibly broken) control paths - remember mutable deletes/norms+clone/reopen permutations? It could be avoided if IR/W were kept to the bare minimum (which most people are going to use), and more advanced features were built on top of it, not in the same place.\n\nSure, our approach today isn't perfect (\"progress not perfection\").\nThere are always improvements to be done.  If you see concrete steps\nto simplify the current approach without losing functionality, please\npost a patch.  I too would love to see such simplifications...\n\nNRT seems to tread the same path, and I'm not sure it's going to win that much turnaround time after newly-introduced per-segment collection.\n\nI agree, per-segment collection was the bulk of the gains needed for\nNRT.  This was a big change and a huge step forward in simple reopen\nturnaround.\n\nBut, not having to write & read deletes to disk, not commit (fsync)\nfrom writer in order to see those changes in reader should also give\nus decent gains.  fsync is surprisingly and intermittently costly.\n\nAnd this integration lets us take it a step further with LUCENE-1313,\nwhere recently created segments can remain in RAM and be shared with\nthe reader.\n\nIf you have good simplifications/improvements on the approach here,\nplease post them.\n\nSome time ago I finished a first version of IR plugins, and enjoy pretty low reopen times (field/facet/filter cache warmups included). (Yes, I'm going to open an issue for plugins once they stabilize enough)\n\nI'm confused: I thought that effort was to make SegmentReader's\ncomponents fully pluggable?  (Not to actually change what components\nSegmentReader is creating).  EG does this modularization alter the\napproach to NRT?  I thought they were orthogonal.\n\n\nIf we add some generic storable flags for Lucene fields, this is cool (probably), NumericField can then capitalize on it, as well as users writing their own NNNFields.\n+1 Wanna make a patch?\n\nNo, I'd like to continue IR cleanup and play with positionIncrement companion value that could enable true multiword synonyms. \n\nWell I'm looking forward to seeing your approach on these two! ",
            "author": "Michael McCandless",
            "id": "comment-12722166"
        },
        {
            "date": "2009-06-20T16:46:17+0000",
            "content": "Patch with all changes, including LUCENE-1687 (it is easier to do this together):\n\n\tAdd NumericField, change JavaDocs to prefer this where possible.\n\tChange range tests to use NumericField during build of test index, this also tests stored fields with NumericField (much cleaner now)\n\tRemove SortField factory from NumericUtils, this class is now almost only for expert users; creating a SortField is possible with SortField ctor using parser instance.\n\tMake all parsers in FieldCache public (DEFAULT_XXX_PARSER)\n\tAdd trie parsers to FieldCache, too (NUMERIC_UTILS_XXX_PARSER)\n\tHide StopFillCacheException-hack\n\tChange SortField to automatically initialize the correct parser according to the type (defaults to text-only parsers) \u2013 there is still some good javadocs missing to tell the user, that it is better to use SortField(String, Parser) instead of SortField(String, type-int) for numeric values, especially when indexed using NumericField.\n\tBecause SortField is serializable, all parsers were made singletons and serializable, too (superinterface Parser extends Serializable, default parsers define readResolve() to enforce singletons, which are important for FieldCache to work correctly)\n\tRemove now unneeded (parser==null) checks in sorting code, as SortField enforces a non-null parser now.\n\tRemove all code from ExtendedFieldCache and move to FieldCache (see LUCENE-1687), keep a stub for binary backwards-compatibility. The only implementation is now FieldCacheImpl referred to by DEFAULT (and EXT_DEFAULT for bw).\n\n\n\nA short note: SortField is only serializable, if all custom comparators used are also serializable, maybe we should also note this in the docs. Parsers are automatically serializable (because superinterface), but not automatically real singletons (but this is not Lucenes problem). ",
            "author": "Uwe Schindler",
            "id": "comment-12722216"
        },
        {
            "date": "2009-06-20T16:58:03+0000",
            "content": "I know you will kill me, Yonik, and Mike will love me  but there is a possibility to also support Trie fields with standard SortField.XXX constants using autodetection. Trie fields always start with a shift-prefix defining the type and so for sure contain non-digits. So FieldCache could simply test and catch NumberFormatException.\n\nSo maybe this would be an option, to make the default (parser== null in FieldCaches getInts(),...) detect this automatically.\n\nUsers then could use SortField/FieldCache as before, ignoring the real encoding. If I would implement this, I could remove the enforcing to parser==null in SortField again and make FieldCache do the detection in this case. ",
            "author": "Uwe Schindler",
            "id": "comment-12722218"
        },
        {
            "date": "2009-06-20T17:48:45+0000",
            "content": "The last patch was still not 100% backwards compatible, now it is. The modified test-tag TestExtendedFieldCache shows it, it will be committed to backwards-compatibility branch ",
            "author": "Uwe Schindler",
            "id": "comment-12722228"
        },
        {
            "date": "2009-06-20T19:53:48+0000",
            "content": "I'll quote myself, and then attempt to not repeat myself further after this point (the back and forth is silly).\nThe next step after adding NumericField seems to be \"it's a bug if getDocument() doesn't return a NumericField, so we must encode it in the index\". If that's the case, I'm -1 on adding NumericField in the first place.\n\nEveryone thinks good APIs, good architecture, and good performance is important.  It imply otherwise is also silly. ",
            "author": "Yonik Seeley",
            "id": "comment-12722257"
        },
        {
            "date": "2009-06-20T22:54:44+0000",
            "content": "there is a possibility to also support Trie fields with standard SortField.XXX constants using autodetection.\n\nMeaning we wouldn't be forced to specify FieldCache.DEFAULT_INT_PARSER/FieldCache.NUMERIC_UTILS_INT_PARSER when creating SortField or calling FieldCache.getInts?  And we'd make the core parsers package private again?\n\nSo users could simply do SortField(\"price\", SortField.FLOAT) and it'd just work?\n\nI think this is is compelling!  Why not take this approach?  There would then be no user visible changes to how you sort by numeric fields... ",
            "author": "Michael McCandless",
            "id": "comment-12722271"
        },
        {
            "date": "2009-06-21T06:14:34+0000",
            "content": " Yes, it would work this way. This only would violate Yoniks complaints about not miximg Trie too much into the other code, but this is already done because of this StopFillCacheException usage. When we do LUCENE-831, this should be thought about, too.\n\nSortField.AUTO is deprecated and will not be changed (only detect text numbers). There should be a note, that it would not work with the \"new\" NumericFields.\n\nI would make the core parsers public to enable users to have full control (on the other hand I could now hide also the trie parsers). But this is a bad approach, wherever automatisms are envolved, oneshould always have the possibility to fix to one parser. And why do we have the SortField/FieldCache accessors with parser parameter, when you cannot even use the default ones?\n\nP.S.: About payloads & positions and the need for extra parameters to the parser: After adding support for positions or payloads to encode the highest precision, there is still no need for an extra SortField/Parser class or factory. The future \"ValueSource\" starts to decode the values until a change in shift occurs. This first shift is for sure the highest precision (because of term ordering), if it is 0, its like now (no payloads/prositions); if the first visible shift>0, payloads/positions were used and the numbero of bits there is also known. ",
            "author": "Uwe Schindler",
            "id": "comment-12722305"
        },
        {
            "date": "2009-06-21T06:27:55+0000",
            "content": "\nI'll quote myself, and then attempt to not repeat myself further after this point (the back and forth is silly).\nThe next step after adding NumericField seems to be \"it's a bug if getDocument() doesn't return a NumericField, so we must encode it in the index\". If that's the case, I'm -1 on adding NumericField in the first place.\n\nIt is mentioned in the docs, that this class is for indexing only:\n\n\n* <p><b>Please note:</b> This class is only used during indexing. You can also create\n* numeric stored fields with it, but when retrieving the stored field value\n* from a {@link Document} instance after search, you will get a conventional\n* {@link Fieldable} instance where the numeric values are returned as {@link String}s\n* (according to <code>toString(value)</code> of the used data type).\n\n\n\nIn my opinion: Storing this info in the segments is not doable without pitfalls: If somebody indexes a normal field name in one IndexWriter session and starts to index using NumericFiled in the next session, he would have two segments with different encoding and two different \"flags\". When these two segments are merged later, what do with the flag?\n\nIf we want to have such Schemas, they must be index wide and we have no possibility in Lucene for that at the moment.\n\nIf somebody creates a schema, that can do this (by storing the schema in a separate file next to the segments file), we can think about it again (with all problems, like: MultiReader on top of two indexes with different schemas - forbid that because schema different?). All this says me, we should not do this, it is the task of Solr, my own project panFMP, or Earwin's own schema, to enforce it. ",
            "author": "Uwe Schindler",
            "id": "comment-12722306"
        },
        {
            "date": "2009-06-21T07:30:29+0000",
            "content": "Here a patch with the auto-detection. All tests pass, also backwards-tests. The parsers are still public for total control on the conversion. ",
            "author": "Uwe Schindler",
            "id": "comment-12722310"
        },
        {
            "date": "2009-06-21T09:25:13+0000",
            "content": "In my opinion: Storing this info in the segments is not doable without pitfalls:\n\nThe proposal was not to store it into the segments file (which I agree it has serious problems, since it's global).  I had considered FieldInfos (which is \"roughly\" Lucene's \"schema\", per segment), but that too has clear problems.\n\nMy proposal was the flags per-field stored in the fdt file.  In that file, we are already writing one byte's worth of flags (only 3 of the bits are used now), for every stored field instance.  This is in FieldsWriter.java ~ line 181.  The flags now record whether each specific field instance was tokenized, compressed, binary.  FieldsReader then uses these flags to reconstruct the Field instances when building the document. This bits are never merged; they are copied (because they apply to that one field instance, in that one document).\n\nMy proposal was to add another flag bit (numeric) and make use of that to return a NumericField instance when you get your document back.  It would have no impact to the index size, since we still have 5 free bits to use.\n\nBut, it is technically a (one bit) change to the index format, which people seriously objected to.  So net/net I'm OK going forward without it. ",
            "author": "Michael McCandless",
            "id": "comment-12722324"
        },
        {
            "date": "2009-06-21T09:49:21+0000",
            "content": "Here an updated patch:\n\n\tfix some copy/paste duplicates in assignments\n\tadd extra check to fail early when autodetection fails\n\n\n\nThe patch (and the one before) checks the autodetection two times (so you see in the trie tests, how one would use SortField with trie), what do you think about all this?\n\nBut, it is technically a (one bit) change to the index format, which people seriously objected to.  So net/net I'm OK going forward without it.\n\nI agree, and for the reasons noted before, I would like to see NumericField as only a helper for indexing. Storing the number as plain-text string (as done in the patch) does not justify a NumericField on getting stored fields.\n\nWhen Yonik committed LUCENE-1699, I would do some additional NumericField fine tuning, but the patch is finished now. ",
            "author": "Uwe Schindler",
            "id": "comment-12722327"
        },
        {
            "date": "2009-06-21T10:08:18+0000",
            "content": "Uwe, with your patch, it looks like if I ask for eg doubles w/ parser=null, and then ask again w/ parser=FieldCache.DEFAULT_DOUBLE_PARSER, I get double entries stored?  Is there some way to take the auto-detected parser and use it (not null) in the cache key? ",
            "author": "Michael McCandless",
            "id": "comment-12722330"
        },
        {
            "date": "2009-06-21T10:23:42+0000",
            "content": "Uwe, with your patch, it looks like if I ask for eg doubles w/ parser=null, and then ask again w/ parser=FieldCache.DEFAULT_DOUBLE_PARSER, I get double entries stored? Is there some way to take the auto-detected parser and use it (not null) in the cache key?\n\nThis is correct, the cache key is different for NULL vs. explicit parser, because the result may be different (which is unlikely the case) but they are two different things. When you ask for an auto-cache (we should deprecate the AUTO-part in field cache, too! It is not used anymore with new sorting code, even when SortField.AUTO is enabled), you also get different cache keys! ",
            "author": "Uwe Schindler",
            "id": "comment-12722334"
        },
        {
            "date": "2009-06-21T10:32:42+0000",
            "content": "But, with the new public exposure of the field cache parsers, this is a newly added trap?  You could accidentally consume 2X the RAM.  Since auto-detection of the parser simply means a specific parser was chosen, why can't we then cache using that chosen parser?  Then you would not risk 2X memory usage.  Or, maybe we should leave the parsers private to not have this risk. ",
            "author": "Michael McCandless",
            "id": "comment-12722335"
        },
        {
            "date": "2009-06-21T10:42:09+0000",
            "content": "Not sure! And it is a trap for the BYTE and SHORT caches, too!\n\nBut for sure, the old, never used auto-cache should be deprecated, too! ",
            "author": "Uwe Schindler",
            "id": "comment-12722341"
        },
        {
            "date": "2009-06-21T17:44:40+0000",
            "content": "Here a new patch:\n\n\tdeprecated the AUTO cache parts\n\tthe test TestFieldCache tests the following algorithm, too\n\tchanged autodetection for triefields to work like the auto cache:\n\n\n\tin createValue, it is checked if parser==null, if this is so, the method calls the FieldCache.getInts() again, specifying each of the two possible parsers (for byte and short currently only one).\n\tAfter this, the cache will then contain the same array reference for both key variants (\"finally used parser\" and \"null\"). Somebody coming later and asking for a specific parser array will get the already cached one, the same for later consumers asking with null parser.\n\tTo optimize the array allocation, it was delayed until the first value was successfully decoded. In case of an error, the array stays null and GC is happy \n\n ",
            "author": "Uwe Schindler",
            "id": "comment-12722392"
        },
        {
            "date": "2009-06-22T10:30:38+0000",
            "content": "The last patch looks great Uwe!  I think we're nearly done here:\n\n\n\tI like how FieldComparator, and function/*FieldSource, are now\n    simplified to longer have duplicated code for picking the default\n    parser (and simply pass null instead).  Default selection is now\n    single source.\n\n\n\n\n\tCould you add the \"<b>NOTE:</b> This API is experimental and might\n    change in incompatible ways in the next release.\" caveat to the\n    javadocs?\n\n\n\n\n\tCan you change this:\n\nif (parser == null) try {\n  return getLongs(reader, field, DEFAULT_LONG_PARSER);\n} catch (NumberFormatException ne) {\n  return getLongs(reader, field, NUMERIC_UTILS_LONG_PARSER);      \n}\n\n\nto this:\n\nif (parser == null) {\n  try {\n    return getLongs(reader, field, DEFAULT_LONG_PARSER);\n  } catch (NumberFormatException ne) {\n    return getLongs(reader, field, NUMERIC_UTILS_LONG_PARSER);      \n  }\n}\n\n\n?\n\tI think we can't actually deprecate NumberTools until we can call\n    FieldCache.getShorts/getBytes on a NumericField?  Ie, people\n    relying on short/byte (to consume much less memory in FieldCache)\n    cannot switch to numeric, and so must continue to zero-pad if they\n    need to use RangeQuery/Filter?\n\n\n\n\n\tYou need a CHANGES entry.\n\n ",
            "author": "Michael McCandless",
            "id": "comment-12722551"
        },
        {
            "date": "2009-06-22T10:55:00+0000",
            "content": "Could you add the \"<b>NOTE:</b> This API is experimental and might change in incompatible ways in the next release.\" caveat to the javadocs?\n\nFor the whole TrieAPI or only NumericUtils? If the first, I would do this with an general JavaDoc commit after this issue. If only NumericField, I could do it now.\n\nCan you change this: \n\nSure, we had this the last time, too (I like my variant more, so I always automatically write it in that way)\n\nI think we can't actually deprecate NumberTools until we can call FieldCache.getShorts/getBytes on a NumericField? Ie, people relying on short/byte (to consume much less memory in FieldCache) cannot switch to numeric, and so must continue to zero-pad if they need to use RangeQuery/Filter?\n\nI will open an issue because of this byte/short trie fields (LUCENE-1710)\n\nNumberTools does not handle zero-padding, so it could stay deprecated. Numbers encoded with NumberTools cannot be natively sorted on at all (only using StringIndex) and can only handle longs.\n\nYou may mean NumberUtils from Solr in contrib/spatial, but this class is not yet released and is only used for spatial.\n\nYou need a CHANGES entry. \n\nWill come. ",
            "author": "Uwe Schindler",
            "id": "comment-12722558"
        },
        {
            "date": "2009-06-22T12:34:49+0000",
            "content": "\nCould you add the \"<b>NOTE:</b> This API is experimental and might change in incompatible ways in the next release.\" caveat to the javadocs?\n\nFor the whole TrieAPI or only NumericUtils? If the first, I would do this with an general JavaDoc commit after this issue. If only NumericField, I could do it now.\n\nFor the whole thing; I think an added NOTE at each class level\njavadoc is what we need.  A separate javadoc issue is good, but\nit needs to be done for 2.9.\n\n\nCan you change this:\n\nSure, we had this the last time, too (I like my variant more, so I always automatically write it in that way)\n\nWhich \"last time\"?  Is there somewhere in the code base now where\nwe do this?\n\nWe generally try (though, don't always succeed) to follow Sun's coding\nguidelines (http://java.sun.com/docs/codeconv/) except 2-space indent\nnot 4.\n\n\nI think we can't actually deprecate NumberTools until we can call FieldCache.getShorts/getBytes on a NumericField? Ie, people relying on short/byte (to consume much less memory in FieldCache) cannot switch to numeric, and so must continue to zero-pad if they need to use RangeQuery/Filter?\n\nNumberTools does not handle zero-padding, so it could stay deprecated. Numbers encoded with NumberTools cannot be natively sorted on at all (only using StringIndex) and can only handle longs.\n\nActually, I believe it does do 0 padding and handles negative numbers\ncorrectly (NumberTools.longToString)?\n\nIe, I can take a short now, call longToString, index with that, do\n[possibly inefficient] RangeQuery against it, and sort against it\nusing only 2 bytes per doc, today?\n\nI will open an issue because of this byte/short trie fields (LUCENE-1710)\n\nOK but since we've marked it 3.1 (which I think is OK; though in\nCHANGES lets document the limitation?), we should un-deprecate\nNumberTools, now, and deprecate it again along with LUCENE-1710? ",
            "author": "Michael McCandless",
            "id": "comment-12722577"
        },
        {
            "date": "2009-06-22T12:51:22+0000",
            "content": "\nSure, we had this the last time, too (I like my variant more, so I always automatically write it in that way)\n\nWhich \"last time\"?  Is there somewhere in the code base now where\nwe do this?\n\nWe generally try (though, don't always succeed) to follow Sun's coding\nguidelines (http://java.sun.com/docs/codeconv/) except 2-space indent\nnot 4.\n\nThis was not against the change. With \"last time\" I meant that some time ago you mentioned the same in a different patch from me. I will change it.\n\nMy note was only, that I \"automatically\" create such code, because I for myself find its better readable. That was all \n\n\nNumberTools does not handle zero-padding, so it could stay deprecated. Numbers encoded with NumberTools cannot be natively sorted on at all (only using StringIndex) and can only handle longs.\n\nActually, I believe it does do 0 padding and handles negative numbers\ncorrectly (NumberTools.longToString)?\n\nIe, I can take a short now, call longToString, index with that, do\n[possibly inefficient] RangeQuery against it, and sort against it\nusing only 2 bytes per doc, today?\n\nYou cannot do this with NumberTools. NumberTools uses an special radix 36 encoding (and not radix 10 like normal numbers). The encoding is just like NumericUtils not human-readable and so cannot be parsed with Number.toString(). To convert back, you need the method from the same class.\n\nBecause of this you have two possilities: Write your own parser and pass it to SortField/FieldCache or sort using StringIndex (because it is sortable according to String.compareTo).\n\nSo it can be deprecated.\n\nIf sombody want to do encoding and parsing with FieldCache.getShorts() there is no way around a DecimalFormat with zero-padding and the problem with negative numbers. ",
            "author": "Uwe Schindler",
            "id": "comment-12722579"
        },
        {
            "date": "2009-06-22T15:28:12+0000",
            "content": "\nYou cannot do this with NumberTools.\n\nWhoa! Sorry, you are right.  Nothing in FieldCache can handle decoding\nthis encoding into short/byte; so you'd need something outside of\nLucene's core, today, to do that.\n\nThough it does allow you to do RangeQuery, with short/byte, and you\ncould sort as SortField.STRING, (quite hideously memory inefficient).\n\nSo I now agree: we should deprecate NumberTools entirely, now.\n\nIf people ask how to handle short/byte beforew we resolve LUCENE-1710,\nthe answer is to upgrade everything to int.  The resulting wasteful\nint[] that'd be in the FieldCache is not nearly as wasteful as the\nString[] you'd need to use to do sorting, today.  And you could always\nmake a custom parser using NumericUtils that downcasts to byte/short,\nanyway, since the needed APIs are public. ",
            "author": "Michael McCandless",
            "id": "comment-12722639"
        },
        {
            "date": "2009-06-22T17:50:59+0000",
            "content": "Attached is a patch wil the latest changes:\n\n\tExperimental-warning to all Numeric* classes\n\tFormatting fixes\n\tCHANGES.txt\n\n ",
            "author": "Uwe Schindler",
            "id": "comment-12722711"
        },
        {
            "date": "2009-06-22T18:09:38+0000",
            "content": "Uwe, can we give a default (4?) for precisionStep, when creating a NumericField, NumericRangeFilter/Query? ",
            "author": "Michael McCandless",
            "id": "comment-12722730"
        },
        {
            "date": "2009-06-22T19:02:01+0000",
            "content": "Uwe, can we give a default (4?) for precisionStep, when creating a NumericField, NumericRangeFilter/Query? If we find a good default, it can simplier applied in one issue (just some additional ctors and factories).\n\nCan you open an issue? There are some problems with defining a good default. In my environment, 8 makes the best results, 4 is only little faster.\nProblems are described in JavaDocs: smaller precisionStep -> more different precisions:\n\n\tmore seek operations and new TermEnums\n\tbut less terms\nFor my index with 8 is in good relation to each other, with 4 seeking gets costly and with 2, I see no difference, only a much larger index (600,000 docs on PANGAEA, 4 Mio doc index locally on Laptop with only trie numbers).\n\n\n\nSo I do not want to set a default with enough tests from different people/scenarios, and this comes when 2.9 is out and everybody tries out \n\nI will commit this patch in a day or two after applying LUCENE-1701-test-tag-special.patch to 2.4-test-branch. ",
            "author": "Uwe Schindler",
            "id": "comment-12722765"
        },
        {
            "date": "2009-06-22T19:15:09+0000",
            "content": "Using 4 for int, 6 for long. Dates-as-longs look a bit sad on 8.\n\nThough, if you want really fast dates, chosing hour/day/month/year as precision steps is vastly superior, plus it also clicks well with user-selected ranges. Still, I dumped this approach for uniformity and clarity. ",
            "author": "Earwin Burrfoot",
            "id": "comment-12722769"
        },
        {
            "date": "2009-06-22T19:33:17+0000",
            "content": "Using 4 for int, 6 for long. Dates-as-longs look a bit sad on 8.\n\nI think 4 for ints is a good start, better as 4 for longs (which produces 16 different precision terms and upto 31 term enums [= precision changes] per range). 6 is a good idea, it brings a little bit more than 8 but does not produce too much precision changes. I tested that also with my 2 M numeric-only index here.\n\nMike: As you see, the precision step is a good config approach, so an default is should be choosen carefully.\nIt may even be different for the same data type, when e.g. you have longs, but all longs in your index are only in a very limited range \u2013 ok. You could use an int, too. But e.g. if you index dates as long and your dates are only between two years or something like that, 4 may still good. This is because on a smaller range, the algorith does not need to to up to the lowest precision.\n\nThough, if you want really fast dates, chosing hour/day/month/year as precision steps is vastly superior, plus it also clicks well with user-selected ranges. Still, I dumped this approach for uniformity and clarity.\n\nThat is clear. Because these precisions are fitting exact to users queries in case of dates (often users take full days when selecting the range).\n\nNice to hear, that you use TrieRange? What is your index spec and measured query speeds (if it does not go too far into company internals)? ",
            "author": "Uwe Schindler",
            "id": "comment-12722774"
        },
        {
            "date": "2009-06-22T19:34:14+0000",
            "content": ">>> Design for today.\n>> And spend two years deprecating and supporting today's designs after you get a better thing tomorrow. Back-compat Lucene-style and agile design aren't something that marries well.\n>> donating something to Lucene means casting it in concrete.\n> We can't let fear of back-compat prevent us from making progress.\nMy point was that strict back-compat prevents people from donating work which is not yet finalized. They either lose comfortable volatility of private code, or have to maintain two versions of it - private and Lucene.\n\n>> NRT seems to tread the same path, and I'm not sure it's going to win that much turnaround time after newly-introduced per-segment collection.\n> I agree, per-segment collection was the bulk of the gains needed for\n> NRT. This was a big change and a huge step forward in simple reopen\n> turnaround.\nI vote it for the most frustrating (in terms of adopting your custom code) and most useful change of 2.9 \n\n> But, not having to write & read deletes to disk, not commit (fsync)\n> from writer in order to see those changes in reader should also give\n> us decent gains. fsync is surprisingly and intermittently costly.\nI'm not sure this can't be achieved without messing with IR/W guts so much. Guys from LinkedIn that drive this feature (if i'm not mistaken), they had a prior solution with separate indexes, one on disk, one in RAM. Per-segment collection adds superfast reopens and MultiReader that is way greater than MultiSearcher - you can finally do adequate fast searches across separate indexes. Do we still need to add complexity for minor performance gains?\n\n> And this integration lets us take it a step further with LUCENE-1313,\n> where recently created segments can remain in RAM and be shared with\n> the reader.\nRAMDirectory?\n\n>> Some time ago I finished a first version of IR plugins, and enjoy pretty low reopen times (field/facet/filter cache warmups included). (Yes, I'm going to open an issue for plugins once they stabilize enough)\n> I'm confused: I thought that effort was to make SegmentReader's\n> components fully pluggable? (Not to actually change what components\n> SegmentReader is creating). EG does this modularization alter the\n> approach to NRT? I thought they were orthogonal.\nYes, they are orthonogal. This was yet another praise to per-segment collection and an example of how this approach can be extended on your custom stuff (like filtercache). ",
            "author": "Earwin Burrfoot",
            "id": "comment-12722775"
        },
        {
            "date": "2009-06-22T20:58:47+0000",
            "content": "Using 4 for int, 6 for long. \n\nUnfortunately we can't easily conditionalize the default by int vs long.  Ie use you NumericField like this:\n\n\nNumericField f = new NumericField(\"price\", 4);\nf.setFloatValue(15.50);\n\n\n\nMike: As you see, the precision step is a good config approach, so an default is should be choosen carefully.\n\nAgreed!  But, it need not be \"perfect\".  Advanced users can test & iterate to find the best tradeoff for their particular field's value distribution.  For slow ranges now with RangeQuery (because of many unique terms), NumericRangeQuery will be a massive speedup with eg a default of 4.\n\nNew users shouldn't have to understand what precisionStep means, or anything about \"what's under the hood\", in order to use NumericField.  I should be able to simply:\n\nnew NumericField(\"price\", 15.50);\n\n\n\nErring towards more terms (and faster searches) is fine, I think, because in a \"typical\" index the text fields with dwarf any small added disk space (hence my proposal of 4 as the default precisionStep).\n\nCan you open an issue?\n\nOK I'll open a new issue. ",
            "author": "Michael McCandless",
            "id": "comment-12722820"
        },
        {
            "date": "2009-06-22T21:10:01+0000",
            "content": "OK I opened spinoff issues LUCENE-1712 (default for precisionStep) and LUCENE-1713 (rename RangeQuery -> TextRangeQuery, or something). ",
            "author": "Michael McCandless",
            "id": "comment-12722829"
        },
        {
            "date": "2009-06-22T22:14:42+0000",
            "content": "My point was that strict back-compat prevents people from donating work which is not yet finalized. They either lose comfortable volatility of private code, or have to maintain two versions of it - private and Lucene.\n\nThat's a good point, though if it's contrib and you're a contrib committer it lessens the challenge, but the challenge is still there....\n\nI vote it for the most frustrating (in terms of adopting your custom code) and most useful change of 2.9 \n\nNo pain no gain?\n\nDo we still need to add complexity for minor performance gains?\n\nThe problem is I've seen fsync take a ridiculous amount of time; it's not very predictable.  So I think we do need some way to not put fsync between the changes to the index and the ability to search those changes.\n\n\n> And this integration lets us take it a step further with LUCENE-1313,\n> where recently created segments can remain in RAM and be shared with\n> the reader.\n\nRAMDirectory?\n\nExactly; that's what LUCENE-1313 is doing (flush new segments to a RAMDir).\n\nThis was yet another praise to per-segment collection and an example of how this approach can be extended on your custom stuff (like filtercache).\n\nOK. ",
            "author": "Michael McCandless",
            "id": "comment-12722862"
        },
        {
            "date": "2009-06-23T15:43:21+0000",
            "content": "Final patch. ",
            "author": "Uwe Schindler",
            "id": "comment-12723136"
        },
        {
            "date": "2009-06-23T15:43:50+0000",
            "content": "Commited backwards tests: revision 787714\nCommitted patch: revision 787723\n\nThanks Mike! ",
            "author": "Uwe Schindler",
            "id": "comment-12723137"
        }
    ]
}