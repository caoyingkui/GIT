{
    "id": "SOLR-7175",
    "title": "<optimize maxSegments=\"2\"/> results in more than 2 segments after optimize finishes",
    "details": {
        "components": [],
        "type": "Bug",
        "labels": "",
        "fix_versions": [],
        "affect_versions": "4.10.2",
        "status": "Closed",
        "resolution": "Not A Problem",
        "priority": "Minor"
    },
    "description": "After finishing indexing and running a commit, we issue an <optimize maxSegments=\"2\"/> to Solr.  With Solr 4.10.2 we are seeing one or two shards (out of 12) with 3 or 4 segments after the optimize finishes.  There are no errors in the Solr logs or indexwriter logs.",
    "attachments": {
        "build-1.indexwriterlog.2015-02-23.gz": "https://issues.apache.org/jira/secure/attachment/12701388/build-1.indexwriterlog.2015-02-23.gz",
        "solr4.shotz": "https://issues.apache.org/jira/secure/attachment/12701389/solr4.shotz",
        "build-4.iw.2015-02-25.txt.gz": "https://issues.apache.org/jira/secure/attachment/12701390/build-4.iw.2015-02-25.txt.gz"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2015-02-27T16:56:41+0000",
            "author": "Tom Burton-West",
            "content": "Attached is an indexwriter log where after a large merge down to 2 segments,  startFullFlush was called and found additional docs in ram which were then written to 2 new segments.These new segments were not merged so the end result of calling <optimize maxSegments=2> was a shard with 4 segments.\n\nAttached also is our solrconfig.xml file in case the problem is caused by some configuration error that overides the maxSegments=2. ",
            "id": "comment-14340369"
        },
        {
            "date": "2015-02-27T17:00:37+0000",
            "author": "Tom Burton-West",
            "content": "solrconfig.xml file ",
            "id": "comment-14340372"
        },
        {
            "date": "2015-02-27T17:09:39+0000",
            "author": "Tom Burton-West",
            "content": "Previous file did not have an explicit commit.\nThis file: build-4.iw.2015-02-25.txt includes a restart of Solr, a commit, and then the optimize maxSegments=2.   Same scenario where after the major merge down to 2 segments a flush finds docs in ram and additional segments are written to disk. ",
            "id": "comment-14340381"
        },
        {
            "date": "2015-03-05T18:56:32+0000",
            "author": "Michael McCandless",
            "content": "Hmm from the IW log it looks like findForcedMerges ran, merged down to 2 segments, and then after that succeeded, IW.commit was called, but there were some indexed documents in RAM so they were flushed to two new segments.  Was indexing happening while force merge was running? ",
            "id": "comment-14349270"
        },
        {
            "date": "2015-03-06T16:56:30+0000",
            "author": "Tom Burton-West",
            "content": "Hi Mike,\n\nOur code is supposed to completely finish indexing before then calling a commit and optimize.\nI was trying to figure out how indexed documents could be in RAM after we called a commit and the resulting flush finished. Indexing should have completed prior to our code calling a commit and then optimize (ie. force merge).  We will double check our code and of course if we find a bug in the code we'll fix the bug, test, and  close the issue.   The reason we suspected something on the Solr4/Lucene4 end is that we haven't made any changes to the indexing/optimizing code in quite a while and we were not seeing this issue with Solr 3.6.\n ",
            "id": "comment-14350575"
        },
        {
            "date": "2015-03-06T20:21:53+0000",
            "author": "Tom Burton-West",
            "content": "Hi Mike,\nThanks for taking a look.  We found a race condition in our code that resulted in the driver thinking all the indexers were finished when they sometimes weren't.  It just happened that we inserted this bug in the code about the time we switched from Solr 3.6 to Solr 4.10.2 so I jumped to the wrong conclusion.  I'll go ahead and close the issue.\n\nTom ",
            "id": "comment-14350835"
        },
        {
            "date": "2015-03-06T20:23:25+0000",
            "author": "Tom Burton-West",
            "content": "Problem was in our client code erroneously sending items to Solr to index after sending the optimize command.  Not a Solr issue. ",
            "id": "comment-14350839"
        },
        {
            "date": "2015-03-07T18:23:09+0000",
            "author": "Michael McCandless",
            "content": "Thanks for bringing closure Tom Burton-West. ",
            "id": "comment-14351729"
        }
    ]
}