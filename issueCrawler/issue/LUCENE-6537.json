{
    "id": "LUCENE-6537",
    "title": "Make NearSpansOrdered use lazy iteration",
    "details": {
        "resolution": "Fixed",
        "affect_versions": "None",
        "components": [],
        "labels": "",
        "fix_versions": [
            "5.3"
        ],
        "priority": "Minor",
        "status": "Closed",
        "type": "Improvement"
    },
    "description": "",
    "attachments": {
        "LUCENE-6537.patch": "https://issues.apache.org/jira/secure/attachment/12738586/LUCENE-6537.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "id": "comment-14578870",
            "author": "Alan Woodward",
            "date": "2015-06-09T13:17:47+0000",
            "content": "NearSpansOrdered uses an eager algorithm to only return the shortest possible matches from a document.  This means that its subspans are out of position when nextStartPosition() returns, making it difficult to collect any information about the subspans. "
        },
        {
            "id": "comment-14578878",
            "author": "Alan Woodward",
            "date": "2015-06-09T13:21:06+0000",
            "content": "Patch moving NearSpansOrdered to a lazy algorithm.  This makes span collection much simpler, and it will also slightly improve performance when scores are not required, as nextStartPosition() can return as soon as it finds a match, without having to shrink the spans. "
        },
        {
            "id": "comment-14578895",
            "author": "Adrien Grand",
            "date": "2015-06-09T13:44:10+0000",
            "content": "+1 "
        },
        {
            "id": "comment-14578906",
            "author": "Robert Muir",
            "date": "2015-06-09T13:54:12+0000",
            "content": "Is it supposed to behave differently? I tried to benchmark the patch:\n\nRuntimeError: results differ: ([], [\"query=spanNear([body:image_flag, body:image_seal], 10, true) filter=None sort=None groupField=None hitCount=36851: self=spanNear([body:image_flag, body:image_seal], 10, true): wrong collapsed hit count: 7 vs 8\\n  [([1142287], '1.2319405'), ([9531898], '1.1640743'), ([9087082], '1.1405553'), ([9531891], '1.0431801'), ([2841408, 5764103], '1.0081179'), ([8760783], '0.99798584'), ([16470, 22367, 85504], '0.93125945')] vs [([1142287], '1.2319405'), ([9531898], '1.1640743'), ([9087082], '1.1405553'), ([3979685], '1.077948'), ([9531891], '1.0431801'), ([2841408, 5764103], '1.0081179'), ([8760783], '0.99798584'), ([16470, 22367], '0.93125945')]\\n  [(1142287, '1.2319405'), (9531898, '1.1640743'), (9087082, '1.1405553'), (9531891, '1.0431801'), (2841408, '1.0081179'), (5764103, '1.0081179'), (8760783, '0.99798584'), (16470, '0.93125945'), (22367, '0.93125945'), (85504, '0.93125945')] vs [(1142287, '1.2319405'), (9531898, '1.1640743'), (9087082, '1.1405553'), (3979685, '1.077948'), (9531891, '1.0431801'), (2841408, '1.0081179'), (5764103, '1.0081179'), (8760783, '0.99798584'), (16470, '0.93125945'), (22367, '0.93125945')]\"])\n\n "
        },
        {
            "id": "comment-14578911",
            "author": "Alan Woodward",
            "date": "2015-06-09T13:59:50+0000",
            "content": "It should return the same document matches, but it will return some extra Span hits within each document, so scores might be different.  Is that benchmark result saying that there are unexpected document matches, or that the scores have changed? "
        },
        {
            "id": "comment-14578917",
            "author": "Alan Woodward",
            "date": "2015-06-09T14:03:48+0000",
            "content": "It looks as though there's an extra hit in there, on document 3979685. "
        },
        {
            "id": "comment-14578924",
            "author": "Adrien Grand",
            "date": "2015-06-09T14:10:46+0000",
            "content": "I think we only have a slight difference in the top hits: 3979685 enters the top hits with its new score of 1.077948 and moves 85504 out. If we had a difference in the number of hits, luceneutil would complain earlier with the following message: \"wrong hit count: X vs Y\". "
        },
        {
            "id": "comment-14578925",
            "author": "Robert Muir",
            "date": "2015-06-09T14:10:47+0000",
            "content": "Do no tests fail? Maybe it requires beasting for them to trip, but i am depressed if the benchmarks find bugs like this and our tests don't... "
        },
        {
            "id": "comment-14579075",
            "author": "Alan Woodward",
            "date": "2015-06-09T15:26:16+0000",
            "content": "I think it's scoring changes.  The benchmark is getting the top ten hits, ranking them by score, merging any docs that have the same score into a group, and then counting the groups.  What's happened here is that doc 3979685's score has increased (presumably because NSO is now finding an extra Span in that document that was being discarded by the eager shrink-to-smallest-fit algorithm before), and it has pushed doc 85504 out of the top 10.  But 85504 was part of a group of three docs with identical scores, so the number of score groups has increased by one.\n\nI'm not sure what the point of doing the score-grouping is though?  It seems a pretty arbitrary thing to be checking? "
        },
        {
            "id": "comment-14579116",
            "author": "Robert Muir",
            "date": "2015-06-09T15:45:42+0000",
            "content": "We may have to get Michael McCandless to comment on that. I dont know what they python is telling me, except that scores are changed. If i disable score verification, performance in the patch is fine. "
        },
        {
            "id": "comment-14579118",
            "author": "Robert Muir",
            "date": "2015-06-09T15:46:01+0000",
            "content": "\n             MedSpanNear       78.96      (2.4%)       81.41      (2.8%)    3.1% (  -2% -    8%)\n             LowSpanNear      251.16      (3.8%)      264.27      (4.4%)    5.2% (  -2% -   14%)\n            HighSpanNear       10.13      (4.2%)       10.68      (5.2%)    5.4% (  -3% -   15%)\n\n "
        },
        {
            "id": "comment-14579136",
            "author": "Paul Elschot",
            "date": "2015-06-09T15:56:37+0000",
            "content": "Lots of deleted code lines and scoring behaviour changed a little as expected, LGTM.\nDo I understand correctly that with this patch the span queries are also faster? "
        },
        {
            "id": "comment-14579145",
            "author": "Paul Elschot",
            "date": "2015-06-09T16:06:26+0000",
            "content": "Do no tests fail? Maybe it requires beasting for them to trip, but i am depressed if the benchmarks find bugs like this and our tests don't...\n\nOn this document:\nw1 w1 w2\nan ordered span near query with slop 1 should provide one span (w1 w2) without the patch here,\nand two spans (w1 .. w2) and (w1 w2) with the patch. "
        },
        {
            "id": "comment-14579282",
            "author": "Michael McCandless",
            "date": "2015-06-09T17:34:03+0000",
            "content": "If it's expected that scores would have changed, since we don't test for that but luceneutil does catch it, then we can ignore it when benching (I think there is an option per competition to do so).\n\nI'm not sure what the point of doing the score-grouping is though? It seems a pretty arbitrary thing to be checking?\n\nI think the idea here was not to fail if the docIDs different in sort order when they had identical scores, maybe ... "
        },
        {
            "id": "comment-14579296",
            "author": "Alan Woodward",
            "date": "2015-06-09T17:45:11+0000",
            "content": "Thanks Mike.  So I think this is good to go then? "
        },
        {
            "id": "comment-14579537",
            "author": "Paul Elschot",
            "date": "2015-06-09T20:43:47+0000",
            "content": "Same patch with two extra test methods showing that repeated matches occur only when the first term repeats and there is enough slop:\nFor ordered span near t1 t2 with slop 1:\nt1 t1 t2 matches twice,\nt1 t2 t2 matches once. "
        },
        {
            "id": "comment-14580229",
            "author": "ASF subversion and git services",
            "date": "2015-06-10T08:34:11+0000",
            "content": "Commit 1684600 from Alan Woodward in branch 'dev/trunk'\n[ https://svn.apache.org/r1684600 ]\n\nLUCENE-6537: NearSpansOrdered should use lazy iteration "
        },
        {
            "id": "comment-14580250",
            "author": "Alan Woodward",
            "date": "2015-06-10T08:51:35+0000",
            "content": "I started back-porting this to 5x, but I think it makes more sense to backport LUCENE-6490 and LUCENE-6371 first. "
        },
        {
            "id": "comment-14585667",
            "author": "ASF subversion and git services",
            "date": "2015-06-15T09:01:53+0000",
            "content": "Commit 1685517 from Alan Woodward in branch 'dev/branches/branch_5x'\n[ https://svn.apache.org/r1685517 ]\n\nLUCENE-6537: NearSpansOrdered should be lazy "
        },
        {
            "id": "comment-14585669",
            "author": "Alan Woodward",
            "date": "2015-06-15T09:03:29+0000",
            "content": "Turned out to be simpler to do this separately. "
        },
        {
            "id": "comment-14713194",
            "author": "Shalin Shekhar Mangar",
            "date": "2015-08-26T13:06:02+0000",
            "content": "Bulk close for 5.3.0 release "
        }
    ]
}