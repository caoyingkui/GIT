{
    "id": "LUCENE-3357",
    "title": "Unit and integration test cases for the new Similarities",
    "details": {
        "labels": "",
        "priority": "Minor",
        "components": [
            "core/query/scoring"
        ],
        "type": "Sub-task",
        "fix_versions": [
            "flexscoring branch"
        ],
        "affect_versions": "flexscoring branch",
        "resolution": "Fixed",
        "status": "Resolved"
    },
    "description": "Write test cases to test the new Similarities added in LUCENE-3220. Two types of test cases will be created:\n\n\tunit tests, in which mock statistics are provided to the Similarities and the score is validated against hand calculations;\n\tintegration tests, in which a small collection is indexed and then searched using the Similarities.\n\n\n\nPerformance tests will be performed in a separate issue.",
    "attachments": {
        "LUCENE-3357.patch": "https://issues.apache.org/jira/secure/attachment/12489572/LUCENE-3357.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2011-08-06T15:52:35+0000",
            "content": "Integration tests added. There are two of them; however, ant test runs only one? ",
            "author": "David Mark Nemeskey",
            "id": "comment-13080416"
        },
        {
            "date": "2011-08-08T11:11:58+0000",
            "content": "\n\tEasySimilarity subclasses return their names in toString()\n\tThe two test cases return the name of the Similarity that failed the test.\n\n ",
            "author": "David Mark Nemeskey",
            "id": "comment-13080898"
        },
        {
            "date": "2011-08-08T14:22:35+0000",
            "content": "Unit tests added. ",
            "author": "David Mark Nemeskey",
            "id": "comment-13080962"
        },
        {
            "date": "2011-08-09T11:49:57+0000",
            "content": "Rebased the changes on the current state of trunk. ",
            "author": "David Mark Nemeskey",
            "id": "comment-13081578"
        },
        {
            "date": "2011-08-09T18:27:27+0000",
            "content": "looks good as a start: can you add apache license header to the new test file? ",
            "author": "Robert Muir",
            "id": "comment-13081818"
        },
        {
            "date": "2011-08-09T20:34:39+0000",
            "content": "License added. ",
            "author": "David Mark Nemeskey",
            "id": "comment-13081897"
        },
        {
            "date": "2011-08-09T20:53:06+0000",
            "content": "Fixed integer division bug in BasicModelG. ",
            "author": "David Mark Nemeskey",
            "id": "comment-13081918"
        },
        {
            "date": "2011-08-09T21:30:42+0000",
            "content": "Fixed a bug in TestEasySimilarity that prevented Similarities that use a subclass of EasyStats to be tested. Also, modified EasyStats so that totalBoost is set to the value of queryBoost in the constructor. ",
            "author": "David Mark Nemeskey",
            "id": "comment-13081940"
        },
        {
            "date": "2011-08-09T21:32:42+0000",
            "content": "Some of the tests fail at certain Similarities, so those have to be fixed as well. ",
            "author": "David Mark Nemeskey",
            "id": "comment-13081942"
        },
        {
            "date": "2011-08-10T00:06:56+0000",
            "content": "I wouldn't worry about the scores being negative necessarily myself: there is nothing wrong with this.\n\nBut we should fix the Nan/Inf score problems.\n\nAlso: some of the stats that are newer in Lucene will get stupid results with PreFlex codec, it doesnt support them.\n\nIn my opinion add the following to the test's setup:\n\n    assumeFalse(\"test cannot run with PreFlex codec !\", \n        \"PreFlex\".equals(CodecProvider.getDefault().getDefaultFieldCodec()));\n\n\n\nand I can help in the places where EasySim collects these stats, for example I think we should add checks in case totalTermFreq = -1, and throw UOE here instead. ",
            "author": "Robert Muir",
            "id": "comment-13082011"
        },
        {
            "date": "2011-08-10T09:56:13+0000",
            "content": "Added a spoof version for all search-related classes that are necessary to properly fill the EasyStats object in EasySimilarity subclasses. ",
            "author": "David Mark Nemeskey",
            "id": "comment-13082259"
        },
        {
            "date": "2011-08-10T10:01:02+0000",
            "content": "Robert: I'm on the Nan/Inf problems. As for the negative score, I'll leave it there for the time being, these Similarities should always return positive scores. I don't feel very confident about this test myself, so I guess I'll remove it (or at least make it optional) once all tests are successful.\n\nAs for the PreFlex codec, I must admit I am not familiar with it, so I would be grateful for a few pointers. ",
            "author": "David Mark Nemeskey",
            "id": "comment-13082261"
        },
        {
            "date": "2011-08-10T12:17:52+0000",
            "content": "\nRobert: I'm on the Nan/Inf problems. As for the negative score, I'll leave it there for the time being, these Similarities should always return positive scores. I don't feel very confident about this test myself, so I guess I'll remove it (or at least make it optional) once all tests are successful.\n\nAhh, ok. I didn't know the sims should always return positive scores! If this is really the case, then its good to test for it.\n\n\nAs for the PreFlex codec, I must admit I am not familiar with it, so I would be grateful for a few pointers.\n\nPreFlex codec emulates the Lucene 3.x index format, which does not support TotalTermFreq, SumTotalTermFreq, SumDocFreq, etc. It will return -1 here.\nThough I just realized: in some situations any codec can return -1 for these values, for example if frequencies are omitted by the user (omitTFAP).\nSo currently, unfortunately, similarities have to deal with this case (and also the case where norms == null, because norms are omitted by the user (omitNorms) !).\n\nI've been working on the BM25 sim with all these regards, Ill commit an update to it as an example. ",
            "author": "Robert Muir",
            "id": "comment-13082301"
        },
        {
            "date": "2011-08-10T12:23:45+0000",
            "content": "Ok, here is what i did here for BM25:\n\nin the case norms are omitted by the user, the formula behaves as if b=0 (no length normalization). so this is always a possibility sims should handle, thoguh for EasySimilarity perhaps it should just supply doclen=1 or something of that nature?\n\nin the case norms are available, but sumTotalTermFreq is not (e.g. frequencies are omitted by the user), I use a value of 1 for avg doc len... This is probably ok\nsince in the case of omitTF all the TF values will be 1 anyway. ",
            "author": "Robert Muir",
            "id": "comment-13082303"
        },
        {
            "date": "2011-08-10T21:50:57+0000",
            "content": "Fixed NaN and infinite scores in DFR and IB; all that's left is to fix the negative scores as well. ... and everything else discussed earlier. ",
            "author": "David Mark Nemeskey",
            "id": "comment-13082702"
        },
        {
            "date": "2011-08-11T01:23:47+0000",
            "content": "I committed this to the branch, even though we have the failing tests with negative scores, i think it will prevent the patch from becoming hellacious. ",
            "author": "Robert Muir",
            "id": "comment-13082841"
        },
        {
            "date": "2011-08-11T01:36:37+0000",
            "content": "Ok I added some things (marked nocommit for your review):\n\nBasically we have the case for norms/totalTermFreq/sumTotalTermFreq that they can be unavailable because\nfreqs or norms are omitted, but currently all sims have to deal with this problem \n\nIdeally sims would not have to deal with this stuff, but for the time being it prevents NaN/Inf for the hearts test\nif the test gets preflexcodec (about 1/4 of the time), and it will prevent NPE if norms are omitted.\n\nin the case these values are unavailable i set these to \"1\"... if you can review that this is ok, we can nuke the nocommits. ",
            "author": "Robert Muir",
            "id": "comment-13082847"
        },
        {
            "date": "2011-08-11T01:57:57+0000",
            "content": "For the negative in the IF model, one solution is this:\n\n\n-    return tfn * (float)(log2((N + 1) / (F + 0.5)));\n+    return tfn * (float)(log2(1 + (N + 1) / (F + 0.5)));\n\n\n\nin quick relevance tests, this was slightly better (likely not significant either way). ",
            "author": "Robert Muir",
            "id": "comment-13082859"
        },
        {
            "date": "2011-08-11T02:20:34+0000",
            "content": "OK I committed this, ran on 3 test collections, i was definitely getting negative scores (not crazy corner cases).\nIn one case, fixing this improved MAP > 10%, so I think its important. ",
            "author": "Robert Muir",
            "id": "comment-13082865"
        },
        {
            "date": "2011-08-11T12:02:58+0000",
            "content": "Apparently the Dirichlet method returns a negative score if the tf / docLen < corpusTf / corpusLen. Unfortunately the negative number can be arbitrarily large, so it's not as easy as adding a constant to the score. This of course makes sense if all documents are scored, as the function is monotone and consequently documents, whose tf is 0, will always be ranked lower than those that contain the word. But this is not how IR engines work.\n\nHaving said that, I believe that we could simulate such a system. I don't know exactly how the query architecture works, but I presume the clauses that don't match a document are assigned a zero value. Now instead of this zero, the Scorer (or whatever class does this) could ask for a default value from the Similarity. In this case LMDirichletSimilarity could return score(stats, 0, Integer.MAX_VALUE), which is somewhere around -12.\n\nIf we don't do this, we have three options:\n1. add score(stats, 0, Integer.MAX_VALUE) to the score\n2. if (score < 0) return 0\n3. add corpusTf / corpusLen * docLen to tf\n\nAll ensure a positive score, but also each has its own disadvantage.\n1. adds a pretty big constant to the score, which may not play well with the other parts of the query\n2. some documents that contain the term get the same 0 score as documents that don't (though I cannot say this is not in line with the LM approach)\n3. this introduces a transformation that is difficult to characterize\n\nFor the time being, I'll go with 2, but we have to discuss this. ",
            "author": "David Mark Nemeskey",
            "id": "comment-13083080"
        },
        {
            "date": "2011-08-11T12:11:50+0000",
            "content": "heh, i fought that guy last night for quite some time... couldn't figure out a good solution.\n\nif you make a patch I can do some sanity testing though to try to help. ",
            "author": "Robert Muir",
            "id": "comment-13083084"
        },
        {
            "date": "2011-08-11T12:54:51+0000",
            "content": "Fixed LMDirichletSimilarity (see my last comment). ",
            "author": "David Mark Nemeskey",
            "id": "comment-13083101"
        },
        {
            "date": "2011-08-11T14:38:39+0000",
            "content": "Did something so that D and P (the binomial models) return only positive scores, but neither is it theoretically sound, nor do I like it much.\n\nRobert: could you test D please, to see how the results are affected? ",
            "author": "David Mark Nemeskey",
            "id": "comment-13083136"
        },
        {
            "date": "2011-08-11T16:08:25+0000",
            "content": "Robert: I modified the nocommits a bit to provide input to the Similarities that looks somewhat plausible. I think it's better to avoid situations where e.g. docLen < freq to minimize the chance of error.\n\nPlease let me know what you think of these modifications; if they're OK, I'll nuke the nocommits. ",
            "author": "David Mark Nemeskey",
            "id": "comment-13083194"
        },
        {
            "date": "2011-08-12T12:48:42+0000",
            "content": "I think the change to D is fine? what about the rest of the equation? (especially the variable \"D\") \n\nI tested D and its fine with this change, however with some of the other sims the changes had some negative effect... lets figure out D for now.\n\nAlso as far as the values if you omit stuff: i don't think we should provide fake values that seem plausible: remember if you omit term frequencies such that totalTermFreq is unavailable, then freq will always be 1  ",
            "author": "Robert Muir",
            "id": "comment-13084080"
        },
        {
            "date": "2011-08-12T13:06:23+0000",
            "content": "D: good question, I think if F > tfn, then D > 0, but I guess I have to prove it (and fix it if it isn't).\n\nCould you tell me which sims were affected negatively?\n\nfreq: I didn't know about that! Still, I want to provide not \"plausible\", but at least \"safe\" statistics in this case. You didn't touch docFreq and numberOfDocuments, so I assumed at least these two are filled with the actual values, is that so? ",
            "author": "David Mark Nemeskey",
            "id": "comment-13084096"
        },
        {
            "date": "2011-08-12T13:19:53+0000",
            "content": "\nfreq: I didn't know about that! Still, I want to provide not \"plausible\", but at least \"safe\" statistics in this case. You didn't touch docFreq and numberOfDocuments, so I assumed at least these two are filled with the actual values, is that so?\n\nBut I don't think we should populate it with arbitrary ones, I like 1 because this is consistent with what you asked for if you omit term frequency (I think its confusing to put something other than 1 here, its inconsistent with how omitTF works for lucene's default scoring).\n\nright, docFreq is always populated. but if you omitTF, freq will be 1 (for exact scorers) or <= 1 (for sloppy scorers) as no frequency is available.\n\nI ran a quick test and got decreases in MAP (probably slight, maybe not even significant) with PL2 and dirichlet with the changes. I figure we can first fix D and then move on to P and such, save LM for last as its a major pain  ",
            "author": "Robert Muir",
            "id": "comment-13084104"
        },
        {
            "date": "2011-08-12T14:08:12+0000",
            "content": "Fixed the omit norms case. ",
            "author": "David Mark Nemeskey",
            "id": "comment-13084141"
        },
        {
            "date": "2011-08-18T21:22:12+0000",
            "content": "I've added the correctness tests (is there a better name for these?). Do you think that I should re-write the ones where the computation of the gold value is missing? Or the other way around?  ",
            "author": "David Mark Nemeskey",
            "id": "comment-13087301"
        },
        {
            "date": "2011-08-18T21:29:53+0000",
            "content": "\nDo you think that I should re-write the ones where the computation of the gold value is missing? Or the other way around?\n\nI don't think so, i think we will take whatever we can get as far as tests  I would just shoot for 'breadth' as far as across the different sims? ",
            "author": "Robert Muir",
            "id": "comment-13087308"
        },
        {
            "date": "2011-08-19T06:56:15+0000",
            "content": "I would just shoot for 'breadth' as far as across the different sims?\nWhat do you mean by 'breadth'? Unit and integration tests (well... the \"heart\" test) already cover all the sims, and this includes score vs explanation comparison. As for the correctness tests, both LM and IB sims are tested, as well as four DFR methods. I can write tests for the three missing DFR sims, but that is as much breadth as I can add. Or do you have something else in mind? ",
            "author": "David Mark Nemeskey",
            "id": "comment-13087578"
        },
        {
            "date": "2011-08-19T10:26:34+0000",
            "content": "\nI can write tests for the three missing DFR sims, but that is as much breadth as I can add. Or do you have something else in mind?\n\nThat sounds good!  ",
            "author": "Robert Muir",
            "id": "comment-13087632"
        },
        {
            "date": "2011-08-20T11:04:33+0000",
            "content": "Correctness tests added for the rest of the DFR sims. ",
            "author": "David Mark Nemeskey",
            "id": "comment-13088181"
        },
        {
            "date": "2011-08-20T11:06:49+0000",
            "content": "Robert: with this, all EasySimilarity-based classes have been tested. Do you think we could close this issue? ",
            "author": "David Mark Nemeskey",
            "id": "comment-13088182"
        },
        {
            "date": "2011-08-20T12:51:00+0000",
            "content": "Ah, I forgot to modify the explain() methods to handle the omitted norms case in the same way as score(). Fixed it now. ",
            "author": "David Mark Nemeskey",
            "id": "comment-13088193"
        },
        {
            "date": "2011-08-20T16:13:32+0000",
            "content": "I think we must be very close: I just need to review this patch and lets get it committed and close the issue. ",
            "author": "Robert Muir",
            "id": "comment-13088209"
        },
        {
            "date": "2011-08-20T17:16:44+0000",
            "content": "great work! \n\nThese tests were very effective at finding problems in these formulas  ",
            "author": "Robert Muir",
            "id": "comment-13088227"
        }
    ]
}