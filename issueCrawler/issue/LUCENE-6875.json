{
    "id": "LUCENE-6875",
    "title": "New Serbian Filter",
    "details": {
        "resolution": "Fixed",
        "affect_versions": "None",
        "components": [
            "modules/analysis"
        ],
        "labels": "",
        "fix_versions": [
            "5.4",
            "6.0"
        ],
        "priority": "Minor",
        "status": "Closed",
        "type": "Improvement"
    },
    "description": "This is a new Serbian filter that works with regular Latin text (the current filter works with \"bald\" Latin). I described in detail what does it do and why is it necessary at the wiki.",
    "attachments": {
        "LUCENE-6875.patch": "https://issues.apache.org/jira/secure/attachment/12770793/LUCENE-6875.patch",
        "Lucene-Serbian-Regular-1.patch": "https://issues.apache.org/jira/secure/attachment/12770527/Lucene-Serbian-Regular-1.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "id": "comment-14985116",
            "author": "Dawid Weiss",
            "date": "2015-11-02T12:10:15+0000",
            "content": "Interesting. Are these transliteration rules somehow normalized? Or are they something you came up with? If they're normalized it'd be nice to include a reference in the JavaDoc. For example \u045f is transliterated as \u017e, but so is \u0436? I only found this, but it doesn't talk much on the subject:\n\nhttps://en.wikipedia.org/wiki/Romanization_of_Serbian\n "
        },
        {
            "id": "comment-14985724",
            "author": "Nikola Smolenski",
            "date": "2015-11-02T18:44:11+0000",
            "content": "I'm not sure what do you mean by \"normalized\". There are the two alphabets, and this is the conversion between them. This is the common conversion, not something I came up with. Regarding the letters you mentioned, \u0436 is transliterated as \u017e, but \u045f is transliterated as d\u017e. "
        },
        {
            "id": "comment-14985944",
            "author": "Dawid Weiss",
            "date": "2015-11-02T20:18:50+0000",
            "content": "By normalized I meant some kind of standard that defines this transliteration. I'm (fairly) confident there is a transliteration guide for doing cyrillic -> Polish (latin and diacritics), but I'd have to look for exact reference.\n\nI was just curious, it wasn't meant to be a negative remark \n\nRegarding the letters you mentioned, \u0436 is transliterated as \u017e, but \u045f is transliterated as d\u017e.\n\nOops, sorry \u2013 I only looked at the patch and the aligned conversion strings being compared, my bad. "
        },
        {
            "id": "comment-14985962",
            "author": "Robert Muir",
            "date": "2015-11-02T20:28:35+0000",
            "content": "Dawid, at least http://geonames.nga.mil/gns/html/Romanization/Romanization_Serbian.pdf defines it in this way. "
        },
        {
            "id": "comment-14985979",
            "author": "Dawid Weiss",
            "date": "2015-11-02T20:37:27+0000",
            "content": "Thanks Robert. I looked up the Polish norm (note the lack of quotes, it actually is a Polish country standard), it is a translated (and adopted) version of ISO-9 [2]. A rough scan is at [3], the norm (for a fee) available at [1]. \n\n[1] http://sklep.pkn.pl/pn-iso-9-2000p.html\n[2] https://en.wikipedia.org/wiki/ISO_9\n[3] http://bg.p.lodz.pl/dokumenty/cyrylica1.pdf "
        },
        {
            "id": "comment-14987157",
            "author": "Nikola Smolenski",
            "date": "2015-11-03T12:01:29+0000",
            "content": "This is so ubiquitous that I can't find a reference. The official orthography of Serbian lists the two alphabets, but doesn't explicitly specify how to convert between them. You can see that various other software projects use the same conversion, for example GNU GetText http://cvs.savannah.gnu.org/viewvc/gettext/gettext-tools/src/filter-sr-latin.c?revision=1.4&root=gettext&view=markup or MediaWiki https://phabricator.wikimedia.org/diffusion/MW/browse/master/languages/classes/LanguageSr.php\n\nI have never seen ISO 9 used in practice, and it wouldn't be useful here anyway, since no one would enter the queries in ISO 9. "
        },
        {
            "id": "comment-14987385",
            "author": "Robert Muir",
            "date": "2015-11-03T14:42:52+0000",
            "content": "I think the scheme is fine.\n\nin the patch, the \"regular\" filter actually documents that it goes to \"bald\". I think this is just an accident? "
        },
        {
            "id": "comment-14987403",
            "author": "Dawid Weiss",
            "date": "2015-11-03T14:55:33+0000",
            "content": "It's fine with me as well, I was just curious. I am definitely not the authority to tell whether it's good or bad  "
        },
        {
            "id": "comment-14988915",
            "author": "Nikola Smolenski",
            "date": "2015-11-04T05:26:15+0000",
            "content": "Yes, that was a remnant of the copy/paste. Here is the new patch with corrected comment. "
        },
        {
            "id": "comment-14989132",
            "author": "Dawid Weiss",
            "date": "2015-11-04T08:49:12+0000",
            "content": "TestAllAnalyzersHaveFactories does not pass (SPI entry missing). Run ant test. "
        },
        {
            "id": "comment-14989152",
            "author": "Dawid Weiss",
            "date": "2015-11-04T08:57:50+0000",
            "content": "Hmm... this is in fact I think a problem with the test because the factory is there, but there are two different filters that accompany it:\n\nSerbianNormalizationFilter.java\nSerbianNormalizationFilterFactory.java\nSerbianNormalizationRegularFilter.java\n\n\nand the test complains about the other one:\n\n[09:53:30.679] ERROR   1.09s J3 | TestAllAnalyzersHaveFactories.test <<<\n   > Throwable #1: java.lang.IllegalArgumentException: A SPI class of type org.apache.lucene.analysis.util.TokenFilterFactory with name 'SerbianNormalizationRegular' does not exist. You need to add the corresponding JAR file supporting this SPI to your classpath. The current classpath supports the following names: [apostrophe, arabicnormalization, arabicstem, bulgarianstem, brazilianstem, cjkbigram, cjkwidth, soraninormalization, soranistem, commongrams, commongramsquery, dictionarycompoundword, hyphenationcompoundword, decimaldigit, lowercase, stop, type, uppercase, czechstem, germanlightstem, germanminimalstem, germannormalization, germanstem, greeklowercase, greekstem, englishminimalstem, englishpossessive, kstem, porterstem, spanishlightstem, persiannormalization, finnishlightstem, frenchlightstem, frenchminimalstem, irishlowercase, galicianminimalstem, galicianstem, hindinormalization, hindistem, hungarianlightstem, hunspellstem, indonesianstem, indicnormalization, italianlightstem, latvianstem, asciifolding, capitalization, codepointcount, fingerprint, hyphenatedwords, keepword, keywordmarker, keywordrepeat, length, limittokencount, limittokenoffset, limittokenposition, removeduplicates, stemmeroverride, trim, truncate, worddelimiter, scandinavianfolding, scandinaviannormalization, edgengram, ngram, norwegianlightstem, norwegianminimalstem, patternreplace, patterncapturegroup, delimitedpayload, numericpayload, tokenoffsetpayload, typeaspayload, portugueselightstem, portugueseminimalstem, portuguesestem, reversestring, russianlightstem, shingle, snowballporter, serbiannormalization, classic, standard, swedishlightstem, synonym, turkishlowercase, elision]\n\n\n\nRobert, should there be a separate factory for that filter? "
        },
        {
            "id": "comment-14989556",
            "author": "Robert Muir",
            "date": "2015-11-04T13:53:52+0000",
            "content": "in general most are 1-1, but in this case i think the factory setup is fine, i think there should be an exception list in the test? "
        },
        {
            "id": "comment-14990211",
            "author": "Nikola Smolenski",
            "date": "2015-11-04T19:17:29+0000",
            "content": "I was considering making two separate factories, but in the end I decided against it because all the other analyzers in the chain might need to be separate as well (for example there could be a regular stemmer and a bald stemmer etc) and so all would need separate factories... "
        },
        {
            "id": "comment-14991584",
            "author": "Dawid Weiss",
            "date": "2015-11-05T12:02:14+0000",
            "content": "Added an exception to the test. Added CHANGES.txt entry. Nikola, it'd be good if you could perhaps add a sentence or two in CHANGES on what the \"new\" filter does. There are actually people who read CHANGES.txt  "
        },
        {
            "id": "comment-14999096",
            "author": "ASF subversion and git services",
            "date": "2015-11-10T18:45:43+0000",
            "content": "Commit 1713712 from Dawid Weiss in branch 'dev/trunk'\n[ https://svn.apache.org/r1713712 ]\n\nLUCENE-6875: New Serbian Filter. (Nikola Smolenski via Robert Muir, Dawid Weiss) "
        },
        {
            "id": "comment-14999100",
            "author": "ASF subversion and git services",
            "date": "2015-11-10T18:46:42+0000",
            "content": "Commit 1713714 from Dawid Weiss in branch 'dev/branches/branch_5x'\n[ https://svn.apache.org/r1713714 ]\n\nLUCENE-6875: New Serbian Filter. (Nikola Smolenski via Robert Muir, Dawid Weiss) "
        },
        {
            "id": "comment-14999103",
            "author": "Dawid Weiss",
            "date": "2015-11-10T18:47:22+0000",
            "content": "Thanks Nikola. "
        },
        {
            "id": "comment-14999144",
            "author": "Steve Rowe",
            "date": "2015-11-10T19:11:39+0000",
            "content": "Dawid Weiss, my Jenkins reports that TestAllAnalyzersHaveFactories is failing: http://jenkins.sarowe.net/job/Lucene-Solr-tests-5.x-Java8/3309/ and http://jenkins.sarowe.net/job/Lucene-Solr-tests-trunk/3647/\n\n\n1 tests failed.\nFAILED:  org.apache.lucene.analysis.core.TestAllAnalyzersHaveFactories.test\n\nError Message:\nA SPI class of type org.apache.lucene.analysis.util.TokenFilterFactory with name 'SerbianNormalizationRegular' does not exist. You need to add the corresponding JAR file supporting this SPI to your classpath. The current classpath supports the following names: [apostrophe, arabicnormalization, arabicstem, bulgarianstem, brazilianstem, cjkbigram, cjkwidth, soraninormalization, soranistem, commongrams, commongramsquery, dictionarycompoundword, hyphenationcompoundword, decimaldigit, lowercase, stop, type, uppercase, czechstem, germanlightstem, germanminimalstem, germannormalization, germanstem, greeklowercase, greekstem, englishminimalstem, englishpossessive, kstem, porterstem, spanishlightstem, persiannormalization, finnishlightstem, frenchlightstem, frenchminimalstem, irishlowercase, galicianminimalstem, galicianstem, hindinormalization, hindistem, hungarianlightstem, hunspellstem, indonesianstem, indicnormalization, italianlightstem, latvianstem, asciifolding, capitalization, codepointcount, fingerprint, hyphenatedwords, keepword, keywordmarker, keywordrepeat, length, limittokencount, limittokenoffset, limittokenposition, removeduplicates, stemmeroverride, trim, truncate, worddelimiter, scandinavianfolding, scandinaviannormalization, edgengram, ngram, norwegianlightstem, norwegianminimalstem, patternreplace, patterncapturegroup, delimitedpayload, numericpayload, tokenoffsetpayload, typeaspayload, portugueselightstem, portugueseminimalstem, portuguesestem, reversestring, russianlightstem, shingle, snowballporter, serbiannormalization, classic, standard, swedishlightstem, synonym, turkishlowercase, elision]\n\n "
        },
        {
            "id": "comment-14999149",
            "author": "Dawid Weiss",
            "date": "2015-11-10T19:16:05+0000",
            "content": "Hmm... looking into it.  "
        },
        {
            "id": "comment-14999158",
            "author": "ASF subversion and git services",
            "date": "2015-11-10T19:18:58+0000",
            "content": "Commit 1713716 from Dawid Weiss in branch 'dev/trunk'\n[ https://svn.apache.org/r1713716 ]\n\nReverting 1713712 (LUCENE-6875), wrong patch. "
        },
        {
            "id": "comment-14999161",
            "author": "ASF subversion and git services",
            "date": "2015-11-10T19:19:58+0000",
            "content": "Commit 1713717 from Dawid Weiss in branch 'dev/branches/branch_5x'\n[ https://svn.apache.org/r1713717 ]\n\nReverting 1713712 (LUCENE-6875), wrong patch. "
        },
        {
            "id": "comment-14999163",
            "author": "Dawid Weiss",
            "date": "2015-11-10T19:20:40+0000",
            "content": "Don't know how it happened, but I committed the wrong patch... Sorry about it! Thanks for the heads up, Steve. I've reverted the wrong patch and will commit the corrected one shortly. "
        },
        {
            "id": "comment-14999196",
            "author": "ASF subversion and git services",
            "date": "2015-11-10T19:46:40+0000",
            "content": "Commit 1713719 from Dawid Weiss in branch 'dev/branches/branch_5x'\n[ https://svn.apache.org/r1713719 ]\n\nLUCENE-6875: New Serbian Filter. (Nikola Smolenski via Robert Muir, Dawid Weiss) "
        },
        {
            "id": "comment-14999202",
            "author": "ASF subversion and git services",
            "date": "2015-11-10T19:46:54+0000",
            "content": "Commit 1713720 from Dawid Weiss in branch 'dev/trunk'\n[ https://svn.apache.org/r1713720 ]\n\nLUCENE-6875: New Serbian Filter. (Nikola Smolenski via Robert Muir, Dawid Weiss) "
        },
        {
            "id": "comment-14999447",
            "author": "ASF subversion and git services",
            "date": "2015-11-10T22:16:40+0000",
            "content": "Commit 1713737 from janhoy@apache.org in branch 'dev/branches/branch_5x'\n[ https://svn.apache.org/r1713737 ]\n\nLUCENE-6875: Fix svn eol-style and space instead of tab, to pass precommit "
        },
        {
            "id": "comment-14999476",
            "author": "ASF subversion and git services",
            "date": "2015-11-10T22:33:23+0000",
            "content": "Commit 1713740 from janhoy@apache.org in branch 'dev/trunk'\n[ https://svn.apache.org/r1713740 ]\n\nLUCENE-6875: Fix svn eol-style and space instead of tab, to pass precommit "
        },
        {
            "id": "comment-15032233",
            "author": "Hoss Man",
            "date": "2015-11-30T18:42:47+0000",
            "content": "Nikola: huge thank you for creating that Solr wiki page - very helpful for understanding the pros/cons of the different approaches. "
        }
    ]
}