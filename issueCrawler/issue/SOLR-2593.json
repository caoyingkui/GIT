{
    "id": "SOLR-2593",
    "title": "A new core admin action 'split' for splitting index",
    "details": {
        "affect_versions": "None",
        "status": "Closed",
        "fix_versions": [
            "4.3"
        ],
        "components": [],
        "type": "New Feature",
        "priority": "Major",
        "labels": "",
        "resolution": "Duplicate"
    },
    "description": "If an index is too large/hot it would be desirable to split it out to another core .\nThis core may eventually be replicated out to another host.\n\nThere can be to be multiple strategies \n\n\trandom split of x or x%\n\tfq=\"user:johndoe\"\n\n\n\n\nexample :\naction=split&split=20percent&newcore=my_new_index\nor\naction=split&fq=user:johndoe&newcore=john_doe_index",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "author": "Koji Sekiguchi",
            "id": "comment-13049713",
            "date": "2011-06-15T10:58:12+0000",
            "content": "CoreAdminHandler uses action, not command. "
        },
        {
            "author": "Peter Sturge",
            "id": "comment-13049727",
            "date": "2011-06-15T11:30:03+0000",
            "content": "This is a really great idea, thanks!\nIf it's possible, it would be cool to have config parameters to:\n create a new core\n overwrite an existing core\n rename an existing core, then create (rolling backup)\n merge with an existing core (ever-growing, but kind of an accessible 'archive' index) "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13050137",
            "date": "2011-06-15T23:15:16+0000",
            "content": "If it's possible, it would be cool to have config parameters to:\n\n...those seem like they should be discrete actions that can be taken after the split has happened.  the simplest thing is to have a \"split\" action that just creates a new core with the docs selected either using the fq (or randomly selection) and then use other CoreAdmin actions for the other stuff: rename, swap, swap+delete (the old one), merge ... merge is really the only one we don't have at a \"core\" level yet (i think)\n "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13050139",
            "date": "2011-06-15T23:19:57+0000",
            "content": "one thing to think about when talking about the API is how the implementation will actually work.\n\nthe fq type option is basically going to require making a full copy of hte index and then deleting by query. (unless i'm missing something) but for people who don't care how the index is partitioned a more efficient approach could probably happen by working at the segment level \u2013 let the user say \"split off a hunk of at least 20% but no more then 50%\" and then you can look at individual segments and doc counts and see if it's possible to just move segments around (and maybe only do the \"copy+deleteByQuery\" logic on a single segment. "
        },
        {
            "author": "Noble Paul",
            "id": "comment-13050236",
            "date": "2011-06-16T06:24:02+0000",
            "content": "the fq type option is basically going to require making a full copy of hte index and then deleting by query...\n\nLucene does it better. We can pass a Filtered Index to a new writer and it creates a new index w/ only those docs. I was surprised at the speed at which it split a dummy 1million doc index in < 1 sec\n\n\n "
        },
        {
            "author": "Terrance A. Snyder",
            "id": "comment-13153533",
            "date": "2011-11-19T17:51:06+0000",
            "content": "@Noble Paul - do you have more information on this, we have a unique requirement that would greatly benefit from being able to take a 'slice' of data a user has modified and persist it in such a fashion. "
        },
        {
            "author": "Jason Rutherglen",
            "id": "comment-13207407",
            "date": "2012-02-14T00:50:59+0000",
            "content": "Is there a patch for this issue available?  If not it's fine. "
        },
        {
            "author": "Andrzej Bialecki",
            "id": "comment-13207452",
            "date": "2012-02-14T01:44:53+0000",
            "content": "Jason, see LUCENE-2632 for a possible way to implement this at the Lucene level. Splitting into arbitrary parts so far required multiple passes over input data, using the approach of tee/filter codecs it's possible to do this in one pass over the input data. "
        },
        {
            "author": "Deepak Kumar",
            "id": "comment-13483335",
            "date": "2012-10-24T15:55:54+0000",
            "content": "I have a situation which demands 2 core merging, re-create data partitions, split & install in 2(or more) cores, seems like this place has got somewhat things closer in that area, basically the case is that there are 2 cores on same schema roughly of 55G and 35G(and growing) each and data keeps on getting pushed continuously on 35G core, we can't allow it to get filled infinitely so essentially over a period of time(offline period/maintenance period) we regenrate(by re-indexing to a fresh core) both the cores with the desired set of data keyed on some unique key, discard the old oversized cores and install the fresh ones, re-indexing is a kind of pain and eventually it'll create the same set of documents but the older core will loose too older docs due to size constraint and the smaller core would be further shrinked as it'll probably be holding lesser documents due to docs getting shifted to bigger one, this can be considered as a sliding time window based core, so the basic steps in demand could be:\n\n1.) Merge N cores to 1 big core(high cost).\n2.) Scan through all the documents of the big core and create N(num of cores that were merged initially) new cores till allowed size by the side.\n3.) Hot swap the main cores with the fresh ones.\n4.) Discard the old cores probably after backing it up.\n\nAbove 1 may be omitted if we can directly scan through documents of N cores and keep on pushing the new docs over to target cores. "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-13600074",
            "date": "2013-03-12T14:44:23+0000",
            "content": "Committed as part of SOLR-3755 changes. "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-13653886",
            "date": "2013-05-10T10:33:18+0000",
            "content": "Closed after release. "
        }
    ]
}