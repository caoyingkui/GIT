{
    "id": "SOLR-8963",
    "title": "And new TimeStream to support fine grain time series operations",
    "details": {
        "components": [],
        "type": "New Feature",
        "labels": "",
        "fix_versions": [
            "6.2",
            "7.0"
        ],
        "affect_versions": "None",
        "status": "Closed",
        "resolution": "Duplicate",
        "priority": "Major"
    },
    "description": "The TimeStream will read Tuples from an underlying stream and expand a unix timestamp into the individual fields: year, month, day, hour, week, minute, second, milli-second).\n\nThis will allow rollups to made on any time grain. This should be very useful for time series log analysis.\n\nSample syntax:\n\n\nrollup(\n            time(search(...,sort=\"timestamp asc\", fl=\"timestamp,...\"), field=\"timestamp\")\n            over=\"year, month,day,hour,minute,second,millis\",\n            sum(a_i),\n            sum(a_f),\n            min(a_i),\n            min(a_f),\n            max(a_i),\n           max(a_f),\n           avg(a_i),\n           avg(a_f),\n           count(*))\n\n\n\nExample broken down by customer:\n\n\nrollup(\n            time(search(...,sort=\"customer asc, timestamp asc\", fl=\"timestamp,...\"), field=\"timestamp\")\n            over=\"customer, year, month,day,hour,minute,second,millis\",\n            sum(a_i),\n            sum(a_f),\n            min(a_i),\n            min(a_f),\n            max(a_i),\n           max(a_f),\n           avg(a_i),\n           avg(a_f),\n           count(*))\n\n\n\nTo do parallel time series rollups just wrap in a parallel stream and add the partitionKeys to the search.\n\nparalllel(..., (rollup(\n            time(search(...,sort=\"customer asc, timestamp asc\", fl=\"timestamp,...\", partitionKeys=\"customer\"), field=\"timestamp\")\n            over=\"customer, year, month,day,hour,minute,second,millis\",\n            sum(a_i),\n            sum(a_f),\n            min(a_i),\n            min(a_f),\n            max(a_i),\n           max(a_f),\n           avg(a_i),\n           avg(a_f),\n           count(*)))",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "date": "2016-04-09T19:06:43+0000",
            "author": "Yonik Seeley",
            "content": "probably need an optional timezone argument as well? ",
            "id": "comment-15233683"
        },
        {
            "date": "2016-04-09T19:11:44+0000",
            "author": "Joel Bernstein",
            "content": "Yeah this would probably be needed. ",
            "id": "comment-15233686"
        },
        {
            "date": "2016-04-09T19:15:15+0000",
            "author": "Joel Bernstein",
            "content": "Need to do some research into the best practices around timezones. I suspect lot's of dev-ops people have all servers syncing to GMT, but I could be wrong. ",
            "id": "comment-15233687"
        },
        {
            "date": "2016-04-09T19:20:16+0000",
            "author": "Joel Bernstein",
            "content": "We should also add a skew parameter to skew the time X seconds to support cross-correlation. ",
            "id": "comment-15233689"
        }
    ]
}