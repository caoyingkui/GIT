{
    "id": "LUCENE-6079",
    "title": "PatternReplaceCharFilter crashes JVM with OutOfMemoryError",
    "details": {
        "resolution": "Unresolved",
        "affect_versions": "4.10.2",
        "components": [
            "modules/analysis"
        ],
        "labels": "",
        "fix_versions": [],
        "priority": "Critical",
        "status": "Open",
        "type": "Bug"
    },
    "description": "PatternReplaceCharFilter fills memory with input data until an OutOfMemoryError is thrown.\n\njava.lang.OutOfMemoryError: Java heap space\n\tat java.util.Arrays.copyOf(Arrays.java:3332)\n\tat java.lang.AbstractStringBuilder.expandCapacity(AbstractStringBuilder.java:137)\n\tat java.lang.AbstractStringBuilder.ensureCapacityInternal(AbstractStringBuilder.java:121)\n\tat java.lang.AbstractStringBuilder.append(AbstractStringBuilder.java:569)\n\tat java.lang.StringBuilder.append(StringBuilder.java:190)\n\tat org.apache.lucene.analysis.pattern.PatternReplaceCharFilter.fill(PatternReplaceCharFilter.java:84)\n\tat org.apache.lucene.analysis.pattern.PatternReplaceCharFilter.read(PatternReplaceCharFilter.java:74)\n    ...\n\nPatternReplaceCharFilter should read data chunk-wise and pass the transformed output chunk-wise to the caller.",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "id": "comment-14227671",
            "author": "Jack Krupansky",
            "date": "2014-11-27T13:47:39+0000",
            "content": "But the pattern might in fact need the entire input, such as to match the end of the input with \"$\".\n\nStill, it would be nice to have an optional \"chunked mode\" for cases such as this (assuming that pattern doesn't end with \"$\"), such as input which is the full text of a multi-MB PDF file. I would suggest that such as mode be the default, with a reasonable chunk size such as 100K. There should also be an \"overlap\" size so that when reading the next chunk it would start matching with an overlap from the end of the previous chunk, and not perform a match that extends into the overlap area at the end of a chunk unless it is the last chunk, so that matches could be made across chunk boundaries.\n\nActually, it turns out that there was such a feature, with a \"maxBlockChars\" parameter, but it was deprecated long ago - no mention in CHANGES.TXT. But... it's still supported in the factory code, with only a \"TODO\" comment suggesting that a warning would be appropriate, but the actual Lucene filter constructor simply ignores this parameter.\n "
        }
    ]
}