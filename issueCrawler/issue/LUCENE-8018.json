{
    "id": "LUCENE-8018",
    "title": "FieldInfos retains garbage if non-sparse",
    "details": {
        "labels": "",
        "priority": "Major",
        "resolution": "Fixed",
        "affect_versions": "6.5",
        "status": "Closed",
        "type": "Bug",
        "components": [
            "core/store"
        ],
        "fix_versions": [
            "7.2",
            "master (8.0)"
        ]
    },
    "description": "A heap dump revealed a lot of TreeMap.Entry instances (millions of them) for a system with about ~1000 active searchers.",
    "attachments": {
        "LUCENE-8018.patch": "https://issues.apache.org/jira/secure/attachment/12894142/LUCENE-8018.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "id": "comment-16220573",
            "date": "2017-10-26T14:59:42+0000",
            "content": "Patch looks good to me. I'll just wait some time to give other people the opportunity to take a look.\n\na system with about ~1000 active searchers.\n\nJust in case, if you are talking about searchers over the same directory, you could actually share them: IndexSearcher is thread-safe. ",
            "author": "Adrien Grand"
        },
        {
            "id": "comment-16220586",
            "date": "2017-10-26T15:04:40+0000",
            "content": "Hi Adrien,\n\nThanks for your fast response. We use searchers from multiple threads but we have a lot of them for consistent pagination. Ours is really an unusual workload for Lucene I guess. ",
            "author": "Julian Vassev"
        },
        {
            "id": "comment-16220783",
            "date": "2017-10-26T17:01:46+0000",
            "content": "Btw I noticed the FieldInfo[] parameter is always sorted by number (when read from segments).\n\nHow do you think, does it make sense to check if is sorted and skip TreeMap creation altogether? Or add isSorted parameter to the constructor.\n\nThanks,\nJulian ",
            "author": "Julian Vassev"
        },
        {
            "id": "comment-16221792",
            "date": "2017-10-27T06:27:29+0000",
            "content": "That could work, but I suspect this is never a problem for any workload, so we should keep things simple? ",
            "author": "Adrien Grand"
        },
        {
            "id": "comment-16221802",
            "date": "2017-10-27T06:37:37+0000",
            "content": "Commit 85f8216b7bd972e276396f022057bf8aa9aa1c1f in lucene-solr's branch refs/heads/branch_7x from Adrien Grand\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=85f8216 ]\n\nLUCENE-8018: FieldInfos retains garbage if non-sparse. ",
            "author": "ASF subversion and git services"
        },
        {
            "id": "comment-16221803",
            "date": "2017-10-27T06:37:39+0000",
            "content": "Commit 401dda7e064b6f621cba405985143724d79620c4 in lucene-solr's branch refs/heads/master from Adrien Grand\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=401dda7 ]\n\nLUCENE-8018: FieldInfos retains garbage if non-sparse. ",
            "author": "ASF subversion and git services"
        },
        {
            "id": "comment-16221814",
            "date": "2017-10-27T06:38:25+0000",
            "content": "Thank you Julian! ",
            "author": "Adrien Grand"
        },
        {
            "id": "comment-16221837",
            "date": "2017-10-27T07:07:38+0000",
            "content": "I am concerned about the complexity here introduced by \"millions of fields\" abuse case.\n\nI pushed back against this from the very beginning and it appears the nightmare i predicted has become the reality: I can't tell what any of this FieldInfos code is even doing here, much less this patch.\n\nI definitely don't think we should be adding any optimization here. Instead we should be carefully undoing existing optimizations to try to manage the technical debt here. ",
            "author": "Robert Muir"
        },
        {
            "id": "comment-16221874",
            "date": "2017-10-27T07:37:41+0000",
            "content": "I agree there is some complexity here, but this is unrelated to this patch to me. The patch actually makes things more consistent: the comment about the memory threshold makes no sense if we are retaining a reference to the TreeMap in any case. Moreover, it feels wrong to penalize users who have dense fields vs. sparse fields.\n\nundoing existing optimizations to try to manage the technical debt here\n\nI'd be ok with going with the array approach all the time. ",
            "author": "Adrien Grand"
        },
        {
            "id": "comment-16222299",
            "date": "2017-10-27T12:44:59+0000",
            "content": "I accidentally hit some keys on my keyboard while looking at this jira and it assigned it to me!  Sorry for the noise; I reverted it. ",
            "author": "David Smiley"
        },
        {
            "id": "comment-16233882",
            "date": "2017-11-01T10:10:07+0000",
            "content": "We use searchers from multiple threads but we have a lot of them for consistent pagination. Ours is really an unusual workload for Lucene I guess.\n\nWow!   Impressive   Lucene's point-in-time searchers make it possible to have consistent pagination; I'm glad you're using it that way, and I wouldn't say it's unusual.\n\nBut how does that result in 1000s of open IndexSearcher}}s at once?  Seems like once an {{IndexSearcher is no longer the latest one, and is no longer involved in an active user session, it can be closed?  Do you have a very long timeout in the user session before you consider the user done searching? ",
            "author": "Michael McCandless"
        },
        {
            "id": "comment-16234330",
            "date": "2017-11-01T16:28:20+0000",
            "content": "Hi Michael,\nThank you for your interest in this matter.\n\nYes, the default session timeout is 30 minutes. As new documents are indexed almost every 10 seconds, every new session creates a searcher. This also prevents efficient merging and during a synthetic test I can observe segment file count grow as much 2.5x the number of documents.\n\nI tried with using NRTCachingDirectory but it seems to make no difference. ",
            "author": "Julian Vassev"
        },
        {
            "id": "comment-16234379",
            "date": "2017-11-01T16:58:46+0000",
            "content": "Hi Julian Vassev, hmm it should not prevent merging, but rather prevent deleting of index files that are still in use by old searchers, even if they have been merged away in the latest index.  I.e. if you print the latest searcher you should see a \"contained\" number of segments in it.\n\nAlso, if you refresh every 10 seconds, and every such searcher is used (i.e. a new search always happens within the 10 seconds), then shouldn't you at worst every have 30 * 6 = 180 live searchers?\n\nDo you use SearcherLifetimeManager to track all these searchers? ",
            "author": "Michael McCandless"
        },
        {
            "id": "comment-16235471",
            "date": "2017-11-02T09:50:54+0000",
            "content": "Instead we should be carefully undoing existing optimizations to try to manage the technical debt here.\n\nOK, I opened LUCENE-8018 to discuss this. ",
            "author": "Adrien Grand"
        }
    ]
}