{
    "id": "LUCENE-6736",
    "title": "SmartChineseAnalyzer chops English tokens in a chinese-english mixed sentence.",
    "details": {
        "resolution": "Invalid",
        "affect_versions": "5.1",
        "components": [
            "modules/analysis"
        ],
        "labels": "",
        "fix_versions": [],
        "priority": "Major",
        "status": "Closed",
        "type": "Bug"
    },
    "description": "I am new with Lucene Analyzer. The following code has predefined the sentence in \"testStr\":\n\t\tString testStr = \"\u5973\u5355\u65b9\u9762\uff0c\u738b\u9002\u5a34second seed\u548c\u5934\u53f7\u79cd\u5b50\u536b\u5195\u51a0\u519b\u897f\u73ed\u7259\u9009\u624b\u9a6c\u6797first seed\u540c\u59041/4\u533a\uff0c3\u53f7\u79cd\u5b50\u674e\u96ea\u82ae\u548c\u97e9\u56fd\u9009\u624bKorean player\u6210\u6c60\u94c9\u5904\u57282/4\u533a\uff0c\u4e0d\u8fc7\u6210\u6c60\u94c9\u5148\u8981\u8fc7\u65e5\u672c\u5c0f\u5c06(Japanese player)\u5965\u539f\u5e0c\u671b\u8fd9\u5173\u3002\u4e0b\u534a\u533a\uff0c6\u53f7\u79cd\u5b50\u738b\u4eea\u6db5\u82e5\u60f3\u664b\u7ea7\u51b3\u8d5bsecure position. congratulations.\";\n\n The printed tokenized result is:\n\n \u5973 \u5355 \u65b9\u9762 \u738b \u9002 \u5a34 second seed \u548c \u5934\u53f7 \u79cd\u5b50 \u536b\u5195 \u51a0\u519b \u897f\u73ed\u7259 \u9009\u624b \u9a6c \u6797 first seed \u540c \u5904 1 4 \u533a 3 \u53f7 \u79cd\u5b50 \u674e \u96ea \u82ae \u548c \u97e9\u56fd \u9009\u624b korean player \u6210 \u6c60 \u94c9 \u5904\u5728 2 4 \u533a \u4e0d\u8fc7 \u6210 \u6c60 \u94c9 \u5148 \u8981 \u8fc7 \u65e5\u672c \u5c0f\u5c06 japanes player \u5965 \u539f \u5e0c\u671b \u8fd9 \u5173 \u4e0b \u534a \u533a 6 \u53f7 \u79cd\u5b50 \u738b \u4eea \u6db5 \u82e5 \u60f3 \u664b\u7ea7 \u51b3\u8d5b secur posit congratul\n\nAs you can see some long English tokens such as Japanese, position and congratulations are cut short in the tokenization process. I hope I didn't use it wrong.\n\nTest code:\n\n\tprivate static void testChineseTokenizer() {\n\t\tString testStr = \"\u5973\u5355\u65b9\u9762\uff0c\u738b\u9002\u5a34second seed\u548c\u5934\u53f7\u79cd\u5b50\u536b\u5195\u51a0\u519b\u897f\u73ed\u7259\u9009\u624b\u9a6c\u6797first seed\u540c\u59041/4\u533a\uff0c3\u53f7\u79cd\u5b50\u674e\u96ea\u82ae\u548c\u97e9\u56fd\u9009\u624bKorean player\u6210\u6c60\u94c9\u5904\u57282/4\u533a\uff0c\u4e0d\u8fc7\u6210\u6c60\u94c9\u5148\u8981\u8fc7\u65e5\u672c\u5c0f\u5c06(Japanese player)\u5965\u539f\u5e0c\u671b\u8fd9\u5173\u3002\u4e0b\u534a\u533a\uff0c6\u53f7\u79cd\u5b50\u738b\u4eea\u6db5\u82e5\u60f3\u664b\u7ea7\u51b3\u8d5bsecure position. congratulations.\";\n\t\tAnalyzer analyzer = new SmartChineseAnalyzer();\n        List<String> result = new ArrayList<String>();\n        StringReader sr = new StringReader(testStr);\n\n        try {\n            TokenStream stream  = analyzer.tokenStream(null,sr);\n            CharTermAttribute cattr = stream.addAttribute(CharTermAttribute.class);\n            stream.reset();\n           while (stream.incrementToken()) \n{\n                String token = cattr.toString();\n                result.add(token);\n            }\n            stream.end();\n            stream.close();\n            sr.close();\n            analyzer.close();\n            stream = null;\n            for (String tok: result) \n{\n            \tSystem.out.print(\" \" + tok);\n            }\n            System.out.println();\n        }\n        catch(IOException e) \n{\n            // not thrown b/c we're using a string reader...\n        }\n\t}",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "id": "comment-14696573",
            "author": "Jan H\u00f8ydahl",
            "date": "2015-08-14T06:38:56+0000",
            "content": "What you are seeing is the effect of stemming, which is expected. Please bring questions up on the users list before opening a bug ticket. "
        }
    ]
}