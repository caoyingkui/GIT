{
    "id": "LUCENE-140",
    "title": "docs out of order",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [
            "core/index"
        ],
        "type": "Bug",
        "fix_versions": [
            "2.1"
        ],
        "affect_versions": "None",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "Hello,\n  I can not find out, why (and what) it is happening all the time. I got an\nexception:\njava.lang.IllegalStateException: docs out of order\n        at\norg.apache.lucene.index.SegmentMerger.appendPostings(SegmentMerger.java:219)\n        at\norg.apache.lucene.index.SegmentMerger.mergeTermInfo(SegmentMerger.java:191)\n        at\norg.apache.lucene.index.SegmentMerger.mergeTermInfos(SegmentMerger.java:172)\n        at org.apache.lucene.index.SegmentMerger.mergeTerms(SegmentMerger.java:135)\n        at org.apache.lucene.index.SegmentMerger.merge(SegmentMerger.java:88)\n        at org.apache.lucene.index.IndexWriter.mergeSegments(IndexWriter.java:341)\n        at org.apache.lucene.index.IndexWriter.optimize(IndexWriter.java:250)\n        at Optimize.main(Optimize.java:29)\n\nIt happens either in 1.2 and 1.3rc1 (anyway what happened to it? I can not find\nit neither in download nor in version list in this form). Everything seems OK. I\ncan search through index, but I can not optimize it. Even worse after this\nexception every time I add new documents and close IndexWriter new segments is\ncreated! I think it has all documents added before, because of its size.\n\nMy index is quite big: 500.000 docs, about 5gb of index directory.\n\nIt is repeatable. I drop index, reindex everything. Afterwards I add a few\ndocs, try to optimize and receive above exception.\n\nMy documents' structure is:\n  static Document indexIt(String id_strony, Reader reader, String data_wydania,\nString id_wydania, String id_gazety, String data_wstawienia)\n{\n    Document doc = new Document();\n\n    doc.add(Field.Keyword(\"id\", id_strony ));\n    doc.add(Field.Keyword(\"data_wydania\", data_wydania));\n    doc.add(Field.Keyword(\"id_wydania\", id_wydania));\n    doc.add(Field.Text(\"id_gazety\", id_gazety));\n    doc.add(Field.Keyword(\"data_wstawienia\", data_wstawienia));\n    doc.add(Field.Text(\"tresc\", reader));\n\n    return doc;\n}\n\nSincerely,\nlegez",
    "attachments": {
        "corrupted.part1.rar": "https://issues.apache.org/jira/secure/attachment/12322202/corrupted.part1.rar",
        "corrupted.part2.rar": "https://issues.apache.org/jira/secure/attachment/12322203/corrupted.part2.rar",
        "ASF.LICENSE.NOT.GRANTED--bug23650.txt": "https://issues.apache.org/jira/secure/attachment/12312257/ASF.LICENSE.NOT.GRANTED--bug23650.txt",
        "LUCENE-140-2007-01-09-instrumentation.patch": "https://issues.apache.org/jira/secure/attachment/12348553/LUCENE-140-2007-01-09-instrumentation.patch",
        "indexing-failure.log": "https://issues.apache.org/jira/secure/attachment/12348606/indexing-failure.log"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2003-11-25T19:35:32+0000",
            "content": "Since the bug submitter hasn't followed up to this 'repeatable' issue in almost\ntwo months, I shall assume that this was not a bug in Lucene, but a misuse of\nLucene.\n\nThere is also no self-contained code that demonstrates the bug.\n\nIf this is indeed a Lucene bug, please re-open this bug entry, and provise\nself-sufficient unit test that demonstrates this problem. ",
            "author": "Otis Gospodnetic",
            "id": "comment-12321387"
        },
        {
            "date": "2005-06-14T23:42:25+0000",
            "content": "More Data Integrity Issue: Docs out of Order\n\nHi,\nSeeing similar issue to the one reported in:\nhttp://nagoya.apache.org/bugzilla/show_bug.cgi?id=23650\nOn examining the segments, following inconsistencies were found\n(a) The merging segments had doc number that is greater than maxDoc.\nDon't know how it go in this state, but this occurs using standard lucene\ncode.\n(b) Strangely, some documents had terms with zero frequency.  And when it \noccurred,\nthe zero frequency term has several posting as (docid 0)\nExample.. (docid freq)  \u2013 MaxDoc = 7749 - NO DELETION.\nMerging msgBody; text=it; sz=2  \u2014 The field name is msgBody and term is \"it\"\n                                    and two segments have the term.\n(0 0)(0 0)(0 0)..........(0 0)(4 6)(5 3)(6 1)(9 1)(10 2)(12 1)......\n...(6791 2)(6794 3)(6796 2)(6798 16)(6801 1)(6805 1)(6806 5)\n(6808 1)(6810 1)(6815 2)(6816 3)(6817 1)(6818 1)(6821 4)(6822 1)\n(6824 3)(6826 4)(6828 1)(6829 3)(12549 2)doc exceeds count\n749(13570 1)doc exceeds count 7749(14896 1)doc exceeds count 7749\n(15028 1)doc exceeds count 7749(15357 1)doc exceeds count 7749\n(15427 1)doc exceeds count 7749(15534 1)doc exceeds count 7749\n(15535 1)doc exceeds count 7749(15653 1)doc exceeds count 7749\n(16530 1)doc exceeds count 7749(17108 1).......\n(c) Also the zero frequency was not limited to the 0 document, there was\nanother instance.\n\nOne work around that seemed to resolve the issue was to:\n(a) keep the maxDoc as a member variable in SegmentMergeInfo\nand ignore/throw exception if an inconsistent state is detected.\n\n****ADD To SegmentMerger just before \"docs out of order\" check.\n  if (postings.freq() == 0) \n{\n            continue;\n   }\n   if (doc >= smi.maxDoc) \n{\n      //sbLog.append(\"doc exceeds count \\r\\n \" + smi.maxDoc);\n      continue;\n   }\n****\n\nAtleast putting a check would not corrupt the segments and would\nget us closer to the real problem as to why freq=0 and doc number exceeds\nmaxDoc. Note, the code has had the fix to the other Segment corruption issue\nthat I previously reported (namely, Using a zero length file). ",
            "author": "Arvind Srinivasan",
            "id": "comment-12321388"
        },
        {
            "date": "2005-06-14T23:46:42+0000",
            "content": "Created an attachment (id=15405)\nAnalysis of corrupted segments and suggestions. ",
            "author": "Arvind Srinivasan",
            "id": "comment-12321389"
        },
        {
            "date": "2005-06-22T12:04:49+0000",
            "content": "Arvind, thanks for following up on this issue.  From your report I can see that\nthe index really ends up containing invalid data, but I've never even seen this\nhappen myself.  Could you please put together sample code that gets the index in\nthis state? ",
            "author": "Otis Gospodnetic",
            "id": "comment-12321390"
        },
        {
            "date": "2005-11-10T11:59:30+0000",
            "content": "I've never seen this... can anyone reproduce with Lucene 1.9?\nCCing this to Arvind's email... ",
            "author": "Yonik Seeley",
            "id": "comment-12357178"
        },
        {
            "date": "2005-11-10T12:05:56+0000",
            "content": "2 years later, I still haven't seen this error. ",
            "author": "Otis Gospodnetic",
            "id": "comment-12357180"
        },
        {
            "date": "2006-01-10T16:30:44+0000",
            "content": "First I think that Lucene is great and it manages to do an incredible job. However, this issue is also causing us significant problems. We originally had an AOP interceptor that would update documents in our HTTP threads however when we started to see this issue we were concerned that it was caused by multiple threads accessing the index at the same time. We put extra concurrency controls on the updates using the LuceneIndexAccess API that was posted into bugzilla by another user. This issue still remained after we added the extra concurrency control.\n\nSince then we have abandoned the AOP approach completely and moved the index rebuild to a scheduled thread which collects things that were modified from the database (using datestamp versioning) and then proceeds to update their lucene indexes. We hoped this would solve the problem because only 1 thread in 1 process would be modifying the index at any given time. Alas, we are still getting docs out of order exceptions. It is difficult for us to reproduce as it mainly happens in production and we cannot provide a testcase for it (I wish we could!). \n\nI know that this must be a difficult issue because it is difficult to reproduce. I can't think of anything strange that we are doing with the indexes (one process, one thread modifying). This probably isn't much help but I just wanted to let you know that we are also experiencing the problem.  ",
            "author": "Jarrod Cuzens",
            "id": "comment-12362310"
        },
        {
            "date": "2006-01-11T02:28:02+0000",
            "content": "File corruption could cause this.  Please look in your system logs to see if there are any reports of problems accessing the drive that stores this index. ",
            "author": "Doug Cutting",
            "id": "comment-12362354"
        },
        {
            "date": "2006-01-17T02:45:00+0000",
            "content": "Hi Doug,\n\nThanks for your suggestion (and great work on Lucene!). I looked in the logs and could not find any indication of corruption. In addition we actually have the system running in a cluster where each node in the cluster has its own lucene search index. We had the issue on a different machine before we moved to the cluster and we now see it on both machines in our cluster . Next time it occurs I will get the indexes and try to post them here if you think that would be helpful.\n\nJust some additional info: \n1)  We are running SUSE 10 Linux.\n2)  We run two quartz jobs: One job runs every 2 minutes and updates lucene with changes from the db if necessary. The other job runs at 3:30AM in the morning and does full index rebuilds. We use the LuceneIndexAccess api when working with the IndexReader/IndexWriter. Only one thread should modify the index at any time although it is possible that the full rebuild job and the update job execute concurrently they shouldn't both modify the index due to the LuceneIndexAccess API's synchronization.\n3) Currently when doing searches we create a new IndexSearcher everytime a search is to be performed; We do not use the LuceneIndexAccess API.\n\nWhen I refer to the LuceneIndexAccess API I am referring to the contribution by Mark Schreiber:\nhttp://www.blizzy.de/lucene/lucene-indexaccess-0.1.0.zip\n\nThanks for any help! ",
            "author": "Jarrod Cuzens",
            "id": "comment-12362866"
        },
        {
            "date": "2006-01-19T05:57:46+0000",
            "content": "Hi,\n\nI have recently experienced the same problem on relase 1.4.3. It happended in production(more than once). Filesystem index directory is used. One application is accountable for indexing, another for searching the index(it also uses IndexReader for query rewriting). Access to index directory(which is singleton) is synchronized within each application's scope. These two applications create separate directory instances and access it independently. Unfortunately,  the code doesn't lead to repeatable occurances of this exception. I assume that  these two applications having not synchronized access to the index might couse the problem, but I have received information that it had also occured with the searching application being down.\n\nThanks in advance for any help. ",
            "author": "Rafal Majewski",
            "id": "comment-12363156"
        },
        {
            "date": "2006-01-21T07:41:44+0000",
            "content": "I am posting our corrupted index (I have to do it in two  parts because it is 14.5M). I looked at it in Luke but Luke doesn't really have any tools to help really diagnose corruption issues. At this point we are considering changing our system to do builds on one machine, test them, and then have them distributed to the other machines in our cluster.\n\nIf anybody could look at this it would be greatly appreciated!\nThanks!\nJarrod ",
            "author": "Jarrod Cuzens",
            "id": "comment-12363471"
        },
        {
            "date": "2006-01-21T07:44:02+0000",
            "content": "Second part.  ",
            "author": "Jarrod Cuzens",
            "id": "comment-12363473"
        },
        {
            "date": "2006-04-13T16:13:41+0000",
            "content": "We used Lucene 1.4.3. for a half year now.\nBut just out of the sudden this issue appeared.\n\nWe have synchronized access to index - synchronized singleton handling all write / read operations.\n\nIs there any progress on finding the cause? ",
            "author": "Ales Justin",
            "id": "comment-12374312"
        },
        {
            "date": "2006-04-28T01:49:21+0000",
            "content": "I was having this problem intermittently while indexing over multiple threads and I have found that the following steps can cause this error (with Lucene 1.3 and 1.4.x):\n\n\n\tOpen an IndexReader (#1) over an existing index (this reader is used for searching while updating the index)\n\tUsing this reader (#1) do a search for the document(s) that you would like to update; obtain their document ID numbers\n\tCreate an IndexWriter and add several new documents to the index (for me, this writing is done in other threads) \n\tClose the IndexWriter \n\tOpen another IndexReader (#2) over the index\n\tDelete the previously found documents by their document ID numbers using reader #2\n\tClose the #2 reader\n\tCreate another IndexWriter (#2) and re-add the updated documents\n\tClose the IndexWriter #2\n\tClose the original IndexReader (#1) and open a new reader for general searching\n\n\n\nIf I ensure that the steps marked with an asterisk  do not happen (i.e. using thread synchronization), I never get this error.  Otherwise, it will happen intermittently while closing the second IndexWriter (#2)  (sometimes I get an ArrayIndexOutOfBoundsException during the deletion).  These 'extra' writes cause the initial 'segments' file to be updated after which it is re-read while opening the second IndexReader (#2).\n\nThis can end up deleting documents using possibly non-existent IDs, most likely causing the index corruption that this error signals. ",
            "author": "Jason Lambert",
            "id": "comment-12376780"
        },
        {
            "date": "2006-12-15T04:11:17+0000",
            "content": "We have seen this one as well. We don't have the same usage as above, we only ever delete documents with IndexReader.deleteDocuments(Term)\n\nWe are using Lucene 1.9.1\n\nIt occurs in two places, inside IndexWriter.addDocument():\n\njava.lang.IllegalStateException: docs out of order\n\tat org.apache.lucene.index.SegmentMerger.appendPostings([Lorg/apache/lucene/index/SegmentMergeInfo;I)I(Optimized Method)\n\tat org.apache.lucene.index.SegmentMerger.mergeTermInfo([Lorg/apache/lucene/index/SegmentMergeInfo;I)V(Optimized Method)\n\tat org.apache.lucene.index.SegmentMerger.mergeTermInfos()V(Optimized Method)\n\tat org.apache.lucene.index.SegmentMerger.mergeTerms()V(Optimized Method)\n\tat org.apache.lucene.index.SegmentMerger.merge()I(Optimized Method)\n\tat org.apache.lucene.index.IndexWriter.mergeSegments(II)V(IndexWriter.java:681)\n\tat org.apache.lucene.index.IndexWriter.mergeSegments(I)V(IndexWriter.java:658)\n\tat org.apache.lucene.index.IndexWriter.maybeMergeSegments()V(IndexWriter.java:646)\n\tat org.apache.lucene.index.IndexWriter.addDocument(Lorg/apache/lucene/document/Document;Lorg/apache/lucene/analysis/Analyzer;)V(IndexWriter.java:453)\n\tat org.apache.lucene.index.IndexWriter.addDocument(Lorg/apache/lucene/document/Document;)V(IndexWriter.java:436)\n\nand inside IndexWriter.close():\n\njava.lang.IllegalStateException: docs out of order\n\tat org.apache.lucene.index.SegmentMerger.appendPostings([Lorg/apache/lucene/index/SegmentMergeInfo;I)I(Optimized Method)\n\tat org.apache.lucene.index.SegmentMerger.mergeTermInfo([Lorg/apache/lucene/index/SegmentMergeInfo;I)V(Optimized Method)\n\tat org.apache.lucene.index.SegmentMerger.mergeTermInfos()V(Optimized Method)\n\tat org.apache.lucene.index.SegmentMerger.mergeTerms()V(Optimized Method)\n\tat org.apache.lucene.index.SegmentMerger.merge()I(Optimized Method)\n\tat org.apache.lucene.index.IndexWriter.mergeSegments(II)V(IndexWriter.java:681)\n\tat org.apache.lucene.index.IndexWriter.mergeSegments(I)V(IndexWriter.java:658)\n\tat org.apache.lucene.index.IndexWriter.flushRamSegments()V(IndexWriter.java:628)\n\tat org.apache.lucene.index.IndexWriter.close()V(IndexWriter.java:375)\n\nThe second one exposes a problem in the close() method which is that the index write.lock is not released when exceptions are thrown in close() causing subsequent attempts to open an IndexWriter to fail. ",
            "author": "Jed Wesley-Smith",
            "id": "comment-12458669"
        },
        {
            "date": "2006-12-18T20:57:43+0000",
            "content": "I just resolved LUCENE-603 as a dup of this issue.\n\nIt would be awesome if we could get a test case that shows this happening.  Enough people seem to hit it that it seems likely something is lurking out there so I'd like to get it fixed!! ",
            "author": "Michael McCandless",
            "id": "comment-12459457"
        },
        {
            "date": "2007-01-08T05:42:15+0000",
            "content": "We have now seen this in a number of customer sites since upgrading JIRA to use Lucene 1.9.1. The JIRA report is here: http://jira.atlassian.com/browse/JRA-11861\n\nWe only seem to have seen it since the upgrade from 1.4.3 to 1.9.1, we hadn't seen it before then.\n\nThis is now a major issue for us, it is hitting a number of our customers. I am trying to generate a repeatable test for it as a matter of urgency.\n\nAs a follow-up we sometimes see the old ArrayIndexOutOfBoundsEx in BitVector.get() (BitVector.java:63)\n\nwill post more if I find something worth sharing. ",
            "author": "Jed Wesley-Smith",
            "id": "comment-12462949"
        },
        {
            "date": "2007-01-08T05:44:17+0000",
            "content": "and we also see ArrayIndexOutOfBoundsEx in the SegmentReader.isDeleted() method:\n\njava.lang.ArrayIndexOutOfBoundsException\n        at org.apache.lucene.index.SegmentReader.isDeleted(I)Z(Optimized Method)\n        at org.apache.lucene.index.SegmentMerger.mergeFields()I(Optimized Method)\n        at org.apache.lucene.index.SegmentMerger.merge()I(Optimized Method)\n        at org.apache.lucene.index.IndexWriter.mergeSegments(II)V(IndexWriter.java:681) ",
            "author": "Jed Wesley-Smith",
            "id": "comment-12462950"
        },
        {
            "date": "2007-01-08T13:09:05+0000",
            "content": "OK: I finally found one way that this corruption can occur!  I will\ncreate a unit test & commit a fix.\n\nIf you delete by document number, and, that document number is larger\nthan maxDoc, but only by a little, then the call to\ndeletedDocs.set(num) may in fact succeed (ie, no exception), but will\nhave set bits that are \"out of bounds\" in the BitVector's bits array.\n\nThis is because the bits array is an array of bytes and so you can\nhave up to 7 of these unused bits at the end.  Once this has happened,\nany attempt to merge this segment will hit the \"docs out of order\"\nexception because the BitVector's count() method will count these\n\"illegally set\" bits and thus make the SegmentMerger think too many\ndocs are deleted. \n\nUnfortunately, this case only occurs if you use deleteDocument(int),\nso I can't yet explain how this happens when using only\ndeleteDocument(Term). ",
            "author": "Michael McCandless",
            "id": "comment-12463029"
        },
        {
            "date": "2007-01-08T18:34:10+0000",
            "content": "\nI've committed a fix for this one case to the trunk.\n\nI'm leaving the issue open so folks above can try the fix and confirm\nwhether or not this fixes their cases.\n\nJed (or any other folks who have hit this above and are still\nlistening!), the fix is really trivial and would be easy to back\nport to prior releases: just run \"svn diff -r 494135:494136\" from\na Lucene checkout to see them.\n\nIf you are willing/able to try this in one of the environments where\nyou keep hitting this issue, that would be awesome: if this is in fact\nyour root cause, then you would see an ArrayIndexOutOfBoundsException\nat the point that the delete of a too-large docNum occurred (rather\nthan silent corruption and the above exception much later that you now\nsee); and if it's not your root cause after testing the fix, then we\nwould know for sure to look for another cause here.\n\nAre you sure that you only ever do IndexReader.deleteDocuments(Term)\nand not deleteDocuments(int docNum)?  I still can't explain how this\nerror could happen without using that second method. ",
            "author": "Michael McCandless",
            "id": "comment-12463093"
        },
        {
            "date": "2007-01-09T01:27:24+0000",
            "content": "Amazed by this long lasting bug report I was going similar routes to Mike, and I noticed 3 things - \n\n(1) the sequence of ops brought by Jason is wrong: \n a Open an IndexReader (#1) over an existing index (this reader is used for searching while updating the index)\n b Using this reader (#1) do a search for the document(s) that you would like to update; obtain their document ID numbers\n c Create an IndexWriter and add several new documents to the index (for me, this writing is done in other threads) \n d Close the IndexWriter \n e Open another IndexReader (#2) over the index\n f Delete the previously found documents by their document ID numbers using reader #2\n g Close the #2 reader\n h Create another IndexWriter (#2) and re-add the updated documents\n i Close the IndexWriter #2\n j Close the original IndexReader (#1) and open a new reader for general searching\n\nProblem here is that the docIDs found in (b) may be altered in step (d) and so step (f) would delete the wrong docs. In particular, it might attempt to delete ids that are out of the range. This might expose exactly the BitVector problem, and would explain the whole thing, but I too cannot see how it explains the delete-by-term case.\n\n(2) BitVectort silent ignoring of attempts to delete slightly-out-of-bound docs that fall in the higher byte - this the problem that Mike fixed. I think the fix is okay - though some applications might now get exceptions they did not get in the past - but I believe this is for their own good. \nHowever when I first ran into this I didn't notice that BitVector.size() would become wrong as result of this - nice catch Mike!\n\nI think however that the test Mike added does not expose the docs out of order bug - I tried this test without the fix and it only fail on the \"gotException assert\" - if you comment this assert the test pass. \n\nThe following test would expose the out-of-order bug - it would fail with out-of-order before the fix, and would succeed without it. \n\n  public void testOutOfOrder () throws IOException {\n    String tempDir = System.getProperty(\"java.io.tmpdir\");\n    if (tempDir == null) \n{\n      throw new IOException(\"java.io.tmpdir undefined, cannot run test: \"+getName());\n    }\n\n    File indexDir = new File(tempDir, \"lucenetestindexTemp\");\n    Directory dir = FSDirectory.getDirectory(indexDir, true);\n\n    boolean create = true;\n    int numDocs = 0;\n    int maxDoc = 0;\n    while (numDocs < 100) {\n      IndexWriter iw = new IndexWriter(dir,anlzr,create);\n      create = false;\n      iw.setUseCompoundFile(false);\n      for (int i=0; i<2; i++) \n{\n        Document d = new Document();\n        d.add(new Field(\"body\",\"body\"+i,Store.NO,Index.UN_TOKENIZED));\n        iw.addDocument(d);\n      }\n      iw.optimize();\n      iw.close();\n      IndexReader ir = IndexReader.open(dir);\n      numDocs = ir.numDocs();\n      maxDoc = ir.maxDoc();\n      assertEquals(numDocs,maxDoc);\n      for (int i=7; i >=1; i-) {\n        try \n{\n          ir.deleteDocument(maxDoc+i);\n        }\n catch (ArrayIndexOutOfBoundsException e) {  \n        }\n      }\n      ir.close();\n    }\n  }\n\nMike, do you agree?\n\n(3) maxDoc() computation in SegmentReader is based (on some paths) in RandomAccessFile.length(). IIRC I saw cases (in previous project) where File.length() or RAF.length() (not sure which of the two) did not always reflect real length, if the system was very busy IO wise, unless FD.sync() was called (with performance hit). \n\nThis post seems relevant - RAF.length over 2GB in NFS - http://forum.java.sun.com/thread.jspa?threadID=708670&messageID=4103657 \n\nNot sure if this can be the case here but at least we can discuss whether it is better to always store the length.\n\n ",
            "author": "Doron Cohen",
            "id": "comment-12463176"
        },
        {
            "date": "2007-01-09T06:38:56+0000",
            "content": "Hi Michael,\n\nThis is awesome, I have prepared a patched 1.9.1: http://jira.atlassian.com/secure/attachment/19390/lucene-core-1.9.1-atlassian-patched-2007-01-09.jar\n\nUnfortunately we don't have a repeatable test for this so we will have to distribute to afflicted customers and - well, pray I guess. We have been seeing this sporadically in our main JIRA instance http://jira.atlassian.com so we will hopefully not observe it now.\n\nWe do only use the deleteDocuments(Term) method, so we are not sure whether this will truly fix our problem, but we note that that method calls deleteDocument(int) based on the TermDocs returned for the Term - and maybe they can be incorrect???\n\nOut of interest, apart from changing from 1.4.3 to 1.9.1, in the JIRA 3.7 release we changed our default merge factor to 4 from 10. We hadn't seen this problem before, and suddenly we have had a reasonable number of occurrences.  ",
            "author": "Jed Wesley-Smith",
            "id": "comment-12463202"
        },
        {
            "date": "2007-01-09T06:41:40+0000",
            "content": "Alas, this doesn't appear to be the problem. We are still getting it, but we do at least have a little more info. We added the doc and lastDoc to the IllegalArgEx and we are getting very strange numbers:\n\njava.lang.IllegalStateException: docs out of order (-1764 < 0)\n        at org.apache.lucene.index.SegmentMerger.appendPostings([Lorg/apache/lucene/index/SegmentMergeInfo;I)I(SegmentMerger.java:335)\n        at org.apache.lucene.index.SegmentMerger.mergeTermInfo([Lorg/apache/lucene/index/SegmentMergeInfo;I)V(SegmentMerger.java:298)\n        at org.apache.lucene.index.SegmentMerger.mergeTermInfos()V(SegmentMerger.java:272) \n        at org.apache.lucene.index.SegmentMerger.mergeTerms()V(SegmentMerger.java:236)\n        at org.apache.lucene.index.SegmentMerger.merge()I(SegmentMerger.java:89)\n        at org.apache.lucene.index.IndexWriter.mergeSegments(II)V(IndexWriter.java:681)\n        at org.apache.lucene.index.IndexWriter.mergeSegments(I)V(IndexWriter.java:658)\n        at org.apache.lucene.index.IndexWriter.maybeMergeSegments()V(IndexWriter.java:646)\n        at org.apache.lucene.index.IndexWriter.addDocument(Lorg/apache/lucene/document/Document;Lorg/apache/lucene/analysis/Analyzer;)V(IndexWriter.java:453) \n        at org.apache.lucene.index.IndexWriter.addDocument(Lorg/apache/lucene/document/Document;)V(IndexWriter.java:436)\n\nwhere doc = -1764 and lastDoc is zero ",
            "author": "Jed Wesley-Smith",
            "id": "comment-12463203"
        },
        {
            "date": "2007-01-09T11:18:16+0000",
            "content": "Jed, thanks for testing the fix!\n\n> Alas, this doesn't appear to be the problem. We are still getting\n> it, but we do at least have a little more info. We added the doc and\n> lastDoc to the IllegalArgEx and we are getting very strange numbers:\n>\n> java.lang.IllegalStateException: docs out of order (-1764 < 0)\n> ...\n>\n> where doc = -1764 and lastDoc is zero\n\nOK, so we've definitely got something else at play here (bummer!). That\n(negative doc number) is very strange.  I will keep looking a this.  I\nwill prepare a patch on 1.9.1 that adds some more instrumentation so\nwe can get more details when you hit this ...\n\n> We do only use the deleteDocuments(Term) method, so we are not sure\n> whether this will truly fix our problem, but we note that that\n> method calls deleteDocument(int) based on the TermDocs returned for\n> the Term - and maybe they can be incorrect???\n\nRight, but I had thought the docNum's coming in from this path would\nbe correct.  It sounds like we have another issue at play here that\ncan somehow get even these doc numbers messed up.\n\n> Out of interest, apart from changing from 1.4.3 to 1.9.1, in the\n> JIRA 3.7 release we changed our default merge factor to 4 from\n> 10. We hadn't seen this problem before, and suddenly we have had a\n> reasonable number of occurrences.\n\nInteresting.  Maybe try changing back to 4 and see if it suppresses\nthe bug?  Might give us [desperately needed] more data to cling to\nhere!  On the 1.4.3 -> 1.9.1 change, some of the cases above were even\npre-1.4.x (though they could have been from yet another root cause or\nmaybe filesystem) so it's hard to draw hard conclusions on this\nfront.\n ",
            "author": "Michael McCandless",
            "id": "comment-12463243"
        },
        {
            "date": "2007-01-09T11:32:04+0000",
            "content": "\nDoron,\n\n> (1) the sequence of ops brought by Jason is wrong:\n>   ...\n>\n> Problem here is that the docIDs found in (b) may be altered in step\n> (d) and so step (f) would delete the wrong docs. In particular, it\n> might attempt to delete ids that are out of the range. This might\n> expose exactly the BitVector problem, and would explain the whole\n> thing, but I too cannot see how it explains the delete-by-term case.\n\nRight, the case I fixed only happens when the Lucene\ndeleteDocument(int docNum) is [slightly] mis-used.  Ie if you are\n\"playing by the rules\" you would never have hit this bug.  And this\nparticular use case is indeed incorrect: doc numbers are only valid to\nthe one reader that you got them from.\n\n> I think however that the test Mike added does not expose the docs\n> out of order bug - I tried this test without the fix and it only\n> fail on the \"gotException assert\" - if you comment this assert the\n> test pass.\n\nHuh, I see my test case (in IndexReader) indeed hitting the original\n\"docs out of order\" exception.  If I take the current trunk and\ncomment out the (one line) bounds check in BitVector.set and run that\ntest, it hits the \"docs out of order\" exception.\n\nAre you sure you updated the change (to tighten the check to a <= from\na <) to index/SegmentMerger.java?  Because, I did indeed find that the\ntest failed to fail when I first wrote it (but should have).  So in\ndigging why it didn't fail as expected, I found that the check for\n\"docs out of order\" missed the boundary case of the same doc number\ntwice in a row.  Once I fixed that, the test failed as expected.\n\n> (3) maxDoc() computation in SegmentReader is based (on some paths)\n> in RandomAccessFile.length(). IIRC I saw cases (in previous project)\n> where File.length() or RAF.length() (not sure which of the two) did\n> not always reflect real length, if the system was very busy IO wise,\n> unless FD.sync() was called (with performance hit).\n\nYes I saw this too.  From the follow-on discussion it sounds like we\nhaven't found a specific known JVM bug here.  Still, it does make me\nnervous that we rely on file length to derive maxDoc.\n\nIn general I think we should rely on as little as possible from the\nfile system (there are so many cross platform issues/differences) and\ninstead explicitly store things like maxDoc into the index.  I will\nopen a separate Jira issue to track this.  Also I will record this\npath in the instrumentation patch for 1.9.1 just to see if we are\nactually hitting something here (I think unlikely but possible). ",
            "author": "Michael McCandless",
            "id": "comment-12463247"
        },
        {
            "date": "2007-01-09T11:40:58+0000",
            "content": "OK, I created LUCENE-767 for the \"maxDoc should be explicitly stored in the index\" issue. ",
            "author": "Michael McCandless",
            "id": "comment-12463249"
        },
        {
            "date": "2007-01-09T14:50:21+0000",
            "content": "\nJed, one question: when you tested the fix, you fully rebuilt your\nindex from scratch, right?  Just want to verify that.  You have to\nre-index because once the index is corrupted it will eventually hit\nthe \"docs out of order\" exception even if you fix the original cause.\n\nOK I've prepared a patch off 1.9.1 (just attached it).  The patch\npasses all unit tests on 1.9.1.\n\nIt has the changes I committed to the trunk yesterday, plus\ninstrumentation (messages printed to a PrintStream) to catch places\nwhere doc numbers are not correct.\n\nAll messages I added print to a newly added infoStream static member\nof SegmentMerger.  You can do SegmentMerger.setInfoStream(...) to\nchange it (it defaults to System.err).\n\nJed if you could get the error to re-occur with this patch and then\npost the resulting messages, that would be great.  Hopefully it gives\nus enough information to find the source here or at least to have\nanother iteration with yet more instrumentation.  Thanks!\n ",
            "author": "Michael McCandless",
            "id": "comment-12463294"
        },
        {
            "date": "2007-01-10T00:57:48+0000",
            "content": "Hi Michael,\n\nThanks for the patch, applied and recreated. Attached is the log.\n\nTo be explicit, we are recreating the index via the IndexWriter ctor with the create flag set and then completely rebuilding the index. We are not completely deleting the entire directory. There ARE old index files (_.cfs & _.del) in the directory with updated timestamps that are months old. If I completely recreate the directory the problem does go away. This is a fairly trivial \"fix\", but we are still investigating as we want to know if this is indeed the problem, how we have come to make it prevalent, and what the root cause is.\n\nThanks for all the help everyone. ",
            "author": "Jed Wesley-Smith",
            "id": "comment-12463440"
        },
        {
            "date": "2007-01-10T06:07:58+0000",
            "content": "BTW. We have looked at all the open files referenced by the VM when the indexing errors occur, and there does not seem to be any reference to the old index segment files, so I am not sure how those files are influencing this problem. ",
            "author": "Jed Wesley-Smith",
            "id": "comment-12463470"
        },
        {
            "date": "2007-01-10T07:36:28+0000",
            "content": "Jed, is it possible that when re-creating the index, while IndexWriter is constructed with create=true, FSDirectory is opened with create=false?\nI suspect so, because otherwise, old  .del files would have been deleted. \nIf indeed so, newly created segments, which have same names as segments in previous (bad) runs, when opened, would read the (bad) old .del file. \nThis would possibly expose the bug fixed by Michael. \nI may be over speculating here, but if this is the case, it can also explain why changing the merge factor from 4 to 10 exposed the problem. \n\nIn fact, let me speculate even further - if indeed when creating the index from scratch, the FSDirectory is (mistakenly) opened with create=false, as long as you always repeated the same sequencing of adding and deleting docs, you were likely to almost not suffer from this mistake, because segments created with same names as (old) .del files simply see docs as deleted before the docs are actually deleted by the program. The search behaves wrongly, not finding these docs before they are actually deleted, but no exception is thrown when adding docs. However once the merge factor was changed from 4 to 10, the matching between old .del files and new segments (with same names) was broken, and the out-of-order exception appeared. \n\n...and if this is not the case, we would need to look for something else... ",
            "author": "Doron Cohen",
            "id": "comment-12463483"
        },
        {
            "date": "2007-01-10T10:48:05+0000",
            "content": "OK from that indexing-failure.log (thanks Jed!) I can see that indeed\nthere are segments whose maxDoc() is much smaller than\ndeleteDocs.count().  This then leads to negative doc numbers on\nmerging these segments.\n\nJed when you say \"there are old files (_.cfs & _.del) in this\ndirectory with updated timestamps that are months old\" what do you\nmean by \"with updated timestamps\"?  Which timestamp is months old and\nwhich one is updated?\n\nOK, assuming Jed you are indeed sending \"create=false\" when creating\nthe Directory and then passing that directory to IndexWriter with\ncreate=true, I think we now have this case fully explained (thanks\nDoron): your old _*.del files are being incorrectly opened & re-used\nby Lucene, when they should not be.\n\nLucene (all released versions but not the trunk version, see below)\ndoes a simple fileExists(\"_XXX.del\") call to determine if a segment\nXXX has deletes.\n\nBut when that _XXX.del is a leftover from a previous index, it very\nlikely doesn't \"match\" the newly created _XXX segment.  (Especially if\nmerge factor has changed but also if order of operations has changed,\nwhich I would expect in this use case).\n\nIf that file exists, Lucene assumes it's for this segment and so opens\nit and uses it.  If it happens that this _XXX.del file has more\ndocuments in it than the newly created _XXX.cfs segment, then negative\ndoc numbers will result (and then later cause the \"docs out of order\"\nexception).  If it happens that the _XXX.del file has fewer documents\nthan the newly created _XXX.cfs segment then you'll hit\nArrayIndexOutOfBounds exceptions in calls to isDeleted(...).  If they\nare exactly equal then you'd randomly see some of your docs got\ndeleted.\n\nNote that the trunk version of Lucene has already fixed this bug (as\npart of lockless commits):\n\n\n\tWhether a segment has deletions or not is now explictly stored in\n    the segments file rather than relying on a \"fileExists(...)\" call.\n    So, if an old _XXX.del existed in the filesystem, the newly\n    created _XXX segment would not open it.\n\n\n\n\n\tFurthermore, the trunk version of Lucene uses a new\n    IndexFileDelter class to remove any unreferenced index files.\n    This means it would have removed these old _.cfs and _.del files\n    even in the case where a directory was created with \"create=false\"\n    and the IndexWriter was created with \"create=true\".\n\n\n\nTo summarize:\n\n\n\tThere was one case where if you gave slightly illegal doc numbers\n    (within 7 of the actual maxDoc) Lucene may silently accept the\n    call but would corrupt your index only to be seen later as an\n    \"docs out of order\" IllegalStateException when the segment is\n    merged.  This was just a missing boundary case check.  This case\n    is now fixed in the trunk (you get an\n    ArrayIndexOutOfBoundsException if doc number is too large).\n\n\n\n\n\tThere is also another case, that only happens if you have old\n    _*.del files leftover from a previous index while re-creating a\n    new index.\n\n\n\n    The workaround is simple here: always open the Directory with\n    create=true (or, remove the directory contents yourself before\n    hand).  (IndexWriter does this if you give it a String or File\n    with create=true).\n\n    This is really a bug in Lucene, but given that it's already fixed\n    in the trunk, and the workaround is simple, I'm inclined to not\n    fix it in prior releases and instead publicize the issue (I will\n    do so on java-user).\n\n    But, I will commit two additional IllegalStateException checks to\n    the trunk when a segment is first initialized: 1) check that the\n    two different sources of \"maxDoc\" (fieldsReader.size() and\n    si.docCount) are the same, and 2) check that the number of pending\n    deletions does not exceed maxDoc().  When an index has\n    inconsistency I think the earlier it's detected the better. ",
            "author": "Michael McCandless",
            "id": "comment-12463524"
        },
        {
            "date": "2007-01-10T19:18:57+0000",
            "content": "> BTW. We have looked at all the open files referenced by the VM when\n> the indexing errors occur, and there does not seem to be any reference\n> to the old index segment files, so I am not sure how those files are\n> influencing this problem.\n\nJed just to answer this question: the _XXX.del files are opened very\nbriefly because the contents of this file are loaded / cached in\nmemory, and the the file handle is closed.  I don't think the _XXX.cfs\nfiles are affecting this issue (are not opened). ",
            "author": "Michael McCandless",
            "id": "comment-12463674"
        },
        {
            "date": "2007-01-11T01:18:32+0000",
            "content": "Michael, Doron, you guys are legends!\n\nIndeed the problem is using only the IndexWriter with create true to recreate the directory. Creating a new Directory with create true does fix the problem. The javadoc for this constructor is fairly explicit that it should recreate the index for you (no caveat), so I would consider that a bug, but - given that head fixes it - not one that requires any action.\n\nThanks guys for the prompt attention, excellent and thorough analysis. ",
            "author": "Jed Wesley-Smith",
            "id": "comment-12463781"
        },
        {
            "date": "2007-01-11T11:46:20+0000",
            "content": "Phew!  I'm glad we finally got to the bottom of this one.\n\nThank you for your persistent and fast testing iterations, Jed; this\nissue has been open for far too long!\n\nI will send a summary email to java-user and resolve this issue,\nfinally. ",
            "author": "Michael McCandless",
            "id": "comment-12463872"
        },
        {
            "date": "2007-01-11T12:09:01+0000",
            "content": "\nActually, this reminds me that, as of lockless commits, there is one\nimportant tradeoff on which \"create=true\" to use (the case on windows\nwhere you want to re-create the index but readers are currently using\nit).  I will call out this difference in the javadocs.\n\nAlthough, why do we even have a \"create\" parameter in the directory?\nI think it's confusing (and dangerous, pre-trunk, due to this issue)\nto have two ways of doing the same thing?\n\nLogically, I don't think a Directory should take the responsibility of\ndeleting old files (including old lock files).  It should be a clean\ninterface for doing so, but I think the IndexWriter alone should be\nthe class that deletes files from the directory.\n\nWith lockless commits this has become an important difference, ie, the\nnew IndexFileDeleter class (used by IndexWriter) handles re-trying\nfiles that are in-use (on Windows) whereas FSDirectory will throw an\nexception if create=true and there are index files are in use.\n\nI think we should deprecate the \"create\" argument to\nFSDirectory.getDirectory and leave only the create argument in\nIndexWriter's constructors.  Am I missing something?  Is there are a\nreason not to do this? ",
            "author": "Michael McCandless",
            "id": "comment-12463875"
        },
        {
            "date": "2007-01-11T12:14:18+0000",
            "content": "Resolving this now, finally (I'll move the two \"create\" arguments\ndiscussion to a separate issue if we decide to go forward with that):\n\n\n\tFixed (in the trunk) to catch boundary cases of incorrect docNum's\n    to deleteDocuments.\n\n\n\n\n\tFixed (in the trunk) to do earlier \"IllegalState\" checks to catch\n    index corruption sooner.  Also fixed the existing IllegalState\n    check to catch missing boundary cases.\n\n\n\n\n\tThe re-using of old _XXX.del files is already fixed with lockless\n    commits (in trunk).  This remains open for past releases, but the\n    workaround is simple and I've now publicized this on java-user.\n\n ",
            "author": "Michael McCandless",
            "id": "comment-12463877"
        },
        {
            "date": "2007-02-27T18:10:32+0000",
            "content": "Closing all issues that were resolved for 2.1. ",
            "author": "Michael McCandless",
            "id": "comment-12476252"
        }
    ]
}