{
    "id": "LUCENE-1596",
    "title": "optimize MultiTermEnum/MultiTermDocs",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [
            "core/search"
        ],
        "type": "Improvement",
        "fix_versions": [
            "2.9"
        ],
        "affect_versions": "None",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "Optimize MultiTermEnum and MultiTermDocs to avoid seeks on TermDocs that don't match the term.",
    "attachments": {
        "LUCENE-1596.patch": "https://issues.apache.org/jira/secure/attachment/12405241/LUCENE-1596.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2009-04-11T21:13:09+0000",
            "content": "Attaching optimization patch.  Results up front:\n  random seeks to common terms with term enumerator:  58% improvement\n  full iteration over all docs matching relatively unique terms: 1595% improvement\n\nThe optimizations:\n\n\tMultiTermEnum keeps track of which segments match... if termDocs.seek(termEnum) is used, then MultiTermDocs will only visit segments that matched the term.\n\tMultiTermEnum defers calling next() on sub enumerators until needed.  This allows MultiTermDocs to use the faster seek(enum) since the enumerator is still on the correct term.  This also avoids unnecessary calls to next() that may never be used, as well as unnecessary insertions into the priority queue.  Using seek(enum) in the sub TermDocs also allows cascading of these optimizations (in the event that one has a MultiReader of MultiReaders).\n\n\n\nTest index: this was obviously stacked to show best-case performance for these optimizations.  999,999 documents with maxBufferedDocs=10, resulting in 46 segments.  The full iteration test used relatively unique terms (1 or 2 docs matching each), and the random seeks test used very common terms (if rare terms are used in this test, the initial seek dominates and swamps any improvement from the deferral of calls to next().) ",
            "author": "Yonik Seeley",
            "id": "comment-12698136"
        },
        {
            "date": "2009-04-11T21:30:26+0000",
            "content": "Do I interpret correctly that getting the docIds for terms that are (almost) primary keys on a non optimized index will become a lot faster with this patch? ",
            "author": "Paul Elschot",
            "id": "comment-12698140"
        },
        {
            "date": "2009-04-11T21:46:54+0000",
            "content": "Yes, if you are doing low level stuff directly on the MultiReader, like using TermEnum/TermDocs.  Or calling Filter.getBits(multiReader).  As you probably know, if you pass Filters or Queries to an IndexSearcher, it's now dropping down to the segment level already (a scorer is created per-segment) so it won't hit the MultiTermEnum code.\n ",
            "author": "Yonik Seeley",
            "id": "comment-12698142"
        },
        {
            "date": "2009-04-12T09:40:48+0000",
            "content": "Patch look good Yonik! ",
            "author": "Michael McCandless",
            "id": "comment-12698197"
        },
        {
            "date": "2009-04-12T13:47:41+0000",
            "content": "Hmmm, unfortunately, this patch does nothing for RangeFilter.getDocIdSet(MultiReader), as the term enumerator used there is no longer a MultiTermEnum. ",
            "author": "Yonik Seeley",
            "id": "comment-12698220"
        },
        {
            "date": "2009-04-12T13:56:34+0000",
            "content": "Really? It's just a FilteredTermEnum on top of the TermEnum returned by MultiReader - so even when the filtered enum filters some terms, it should use the MultiTermEnum methods to iterate the terms. ",
            "author": "Uwe Schindler",
            "id": "comment-12698221"
        },
        {
            "date": "2009-04-13T12:31:08+0000",
            "content": "It's just a FilteredTermEnum on top of the TermEnum returned by MultiReader\n\nYes, but the MultiTermEnum has the internal knowledge about what segments matched the term, and actually has the sub-TermEnums positioned on that term. ",
            "author": "Yonik Seeley",
            "id": "comment-12698382"
        },
        {
            "date": "2009-04-13T14:52:45+0000",
            "content": "Yes I understand, the problematic call is TermDocs.seek(TermEnum) which does an instanceof check. If it is a FilteredTermEnum or anything other, which is wrapped, the optimization is not used. ",
            "author": "Uwe Schindler",
            "id": "comment-12698402"
        },
        {
            "date": "2009-05-14T01:56:31+0000",
            "content": "Getting back to this... although this unfortunately won't currently help classes like RangeFilter used directly on a MultiReader because a MultiTermEnum is no longer used, I still think this is worth committing as-is for users of MultiTermEnum.\n\nThoughts/objections? ",
            "author": "Yonik Seeley",
            "id": "comment-12709244"
        },
        {
            "date": "2009-05-14T10:28:53+0000",
            "content": "although this unfortunately won't currently help classes like RangeFilter used directly on a MultiReader because a MultiTermEnum is no longer used, I still think this is worth committing as-is for users of MultiTermEnum.\n\n+1\n\nIt'd be great to somehow have the optimization apply to RangeFilter as well, though since Lucene has now moved to per-segment searching, it's low priority. ",
            "author": "Michael McCandless",
            "id": "comment-12709349"
        },
        {
            "date": "2009-05-14T17:25:10+0000",
            "content": "Committed. ",
            "author": "Yonik Seeley",
            "id": "comment-12709476"
        },
        {
            "date": "2009-05-15T10:00:09+0000",
            "content": "I'm seeing this new AIOOBE when tracking down the intermittent failure\nin TestStressIndexing2:\n\n\n1) testRandomIWReader(org.apache.lucene.index.TestStressIndexing2)\njava.lang.ArrayIndexOutOfBoundsException: 6\n\tat org.apache.lucene.index.MultiSegmentReader$MultiTermDocs.next(MultiSegmentReader.java:672)\n\tat org.apache.lucene.index.TestStressIndexing2.verifyEquals(TestStressIndexing2.java:292)\n\tat org.apache.lucene.index.TestStressIndexing2.verifyEquals(TestStressIndexing2.java:250)\n\tat org.apache.lucene.index.TestStressIndexing2.testRandomIWReader(TestStressIndexing2.java:67)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n\tat java.lang.reflect.Method.invoke(Method.java:585)\n\tat junit.framework.TestCase.runTest(TestCase.java:168)\n\tat org.apache.lucene.util.LuceneTestCase.runTest(LuceneTestCase.java:88)\n\tat junit.framework.TestCase.runBare(TestCase.java:134)\n\tat junit.framework.TestResult$1.protect(TestResult.java:110)\n\tat junit.framework.TestResult.runProtected(TestResult.java:128)\n\tat junit.framework.TestResult.run(TestResult.java:113)\n\tat junit.framework.TestCase.run(TestCase.java:124)\n\tat junit.framework.TestSuite.runTest(TestSuite.java:232)\n\tat junit.framework.TestSuite.run(TestSuite.java:227)\n\tat org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:81)\n\tat org.junit.internal.runners.CompositeRunner.runChildren(CompositeRunner.java:33)\n\tat org.junit.internal.runners.CompositeRunner.run(CompositeRunner.java:28)\n\tat org.junit.runner.JUnitCore.run(JUnitCore.java:130)\n\tat org.junit.runner.JUnitCore.run(JUnitCore.java:109)\n\tat org.junit.runner.JUnitCore.run(JUnitCore.java:100)\n\tat org.junit.runner.JUnitCore.runMain(JUnitCore.java:81)\n\tat org.junit.runner.JUnitCore.main(JUnitCore.java:44)\n\n\n\nI think it's because this optimization isn't admissible in the case\nwhen one calls MultiTermDocs.seek on a MultiTermEnum derived from a\ndifferent MultiSegmentReader.  Ie, I think there needs to be another\ncheck that verifies in fact the MultiTermEnum passed to\nMultiTermDocs.seek share the same MultiSegmentReader?\n\nBefore this optimiztion, this was OK (only the term was used from the\nMultiTermEnum). ",
            "author": "Michael McCandless",
            "id": "comment-12709792"
        },
        {
            "date": "2009-05-15T14:28:20+0000",
            "content": "Gah... I forgot it was permissible (or at least not disallowed) to pass an Enum not derived from the same reader.\nI'll fix. ",
            "author": "Yonik Seeley",
            "id": "comment-12709854"
        },
        {
            "date": "2009-05-15T15:56:15+0000",
            "content": "I just committed the fix (since trunk was broken) and a test that failed w/o the fix, but if anyone has a better idea how to handle/fix, we can certainly still discuss.    I just did the obvious - store the multi-reader in the TermEnum and TermDocs instances and compare in TermDocs.seek(TermEnum) ",
            "author": "Yonik Seeley",
            "id": "comment-12709890"
        }
    ]
}