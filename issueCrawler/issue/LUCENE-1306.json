{
    "id": "LUCENE-1306",
    "title": "CombinedNGramTokenFilter",
    "details": {
        "labels": "",
        "priority": "Trivial",
        "components": [
            "modules/analysis"
        ],
        "type": "New Feature",
        "fix_versions": [],
        "affect_versions": "None",
        "resolution": "Won't Fix",
        "status": "Resolved"
    },
    "description": "Alternative NGram filter that produce tokens with composite prefix and suffix markers.\n\n\nts = new WhitespaceTokenizer(new StringReader(\"hello\"));\nts = new CombinedNGramTokenFilter(ts, 2, 2);\nassertNext(ts, \"^h\");\nassertNext(ts, \"he\");\nassertNext(ts, \"el\");\nassertNext(ts, \"ll\");\nassertNext(ts, \"lo\");\nassertNext(ts, \"o$\");\nassertNull(ts.next());",
    "attachments": {
        "LUCENE-1306.txt": "https://issues.apache.org/jira/secure/attachment/12383946/LUCENE-1306.txt"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2008-06-13T05:57:18+0000",
            "content": "I'm sorry I could not see what it means that, \"combined\" + \"ngram\" from the code above.  Can I ask you to let me know the intension? ",
            "author": "Hiroaki Kawai",
            "id": "comment-12604744"
        },
        {
            "date": "2008-06-13T07:25:20+0000",
            "content": "The current NGram analysis in trunk is split in two, on for edge-grams and one for inner grams. \n\nThis patch combines them both in a single filter that uses ^prefix and suffix$ tokens if they are some sort of edge gram, or both around the complete token if n is great enough. There is also method to extend if you want to add a payload (more boost to edge grams or something) or do something to the gram tokens depending on what part of the original token they contain. ",
            "author": "Karl Wettin",
            "id": "comment-12604756"
        },
        {
            "date": "2008-06-15T03:22:18+0000",
            "content": "Should there be a way for the client of this class to specify the prefix and suffix char?\n\nIs having, for example, \"^h\" as the first bi-gram token really the right thing to do?  Would \"^he\" make more sense?  I know that makes it 3 characters long, but it's 2 chars from the input string.  Not sure, so I'm asking.\n\nIs this primarily to distinguish between the edge and inner n-grams?  If so, would it make more sense to just make use of Token type variable instead? ",
            "author": "Otis Gospodnetic",
            "id": "comment-12605120"
        },
        {
            "date": "2008-06-17T02:56:03+0000",
            "content": "After thinking for a week, I think this idea is nice.\n\nIMHO, this might be renamed to NGramTokenizer simply. A general n-gram tokenizer accepts a sequence that has no gap in it. By the concept, TokenFilter accepts a tokien stream (gapped sequence), and current NGramTokenFilter does not work well in that sense. CombinedNGramTokenFilter filles the gap with prefix(^) and suffix($), and the token stream becomes a simple stream again virtually, n-gram works nice agian.\n\nComments:\n1. prefix and suffix chars should be configurable. Because user must choose a char that is not used in the terms.\n2. prefix and suffix might be a white space. Because most of the users are not interested in whitespace itself.\n3. If you want to do a phrase query (for example, \"This is\"), we have to generate $^ token in the gap to make the positions valid.\n4. n-gram algorithm should be rewritten to make the positions valid. Please see LUCENE-1225\n\nI think \"^h\" is OK, because prefix and suffix are the chars that was introduced as a workaround. ",
            "author": "Hiroaki Kawai",
            "id": "comment-12605483"
        },
        {
            "date": "2008-06-17T20:08:10+0000",
            "content": "Note, also, that one could use the \"flags\" to indicate what the token is.  I know that's a little up in the air just yet, but it does exist.  This would mean that no stripping of special chars is required. ",
            "author": "Grant Ingersoll",
            "id": "comment-12605704"
        },
        {
            "date": "2008-06-17T20:58:03+0000",
            "content": "I'll refine and document this patch soon. Terrible busy though. Hasty responses:\n\nShould there be a way for the client of this class to specify the prefix and suffix char? \n1. prefix and suffix chars should be configurable. Because user must choose a char that is not used in the terms.\n\nThere are getters and setters, but nothing in the constructor.\n\nIs having, for example, \"^h\" as the first bi-gram token really the right thing to do? Would \"^he\" make more sense? I know that makes it 3 characters long, but it's 2 chars from the input string. Not sure, so I'm asking.\n\nI always considered 'start of word' and 'end of word' as a single character and a part of n. I might be wrong though. I'll have to take a look at what other people did. It would not be a very hard thing to include a setting for that.\n\nIs this primarily to distinguish between the edge and inner n-grams? If so, would it make more sense to just make use of Token type variable instead?\none could use the \"flags\" to indicate what the token is. \n\nI might be missing something in your line of questioning. Don't understand what it would help to have the flag or token type as they are not stored in the index.\n\nI don't want separate fields for the prefix, inner and suffix grams, I want to use the same single filter at query time. I typically pass down the gram boost in the payload, evaluated on gram size, how far away it is from the prefix and suffix, et c. \n\n3. If you want to do a phrase query (for example, \"This is\"), we have to generate $^ token in the gap to make the positions valid.\n\nIf you are creating ngrams over multiple words, say a sentence, then I state that there should only be a prefix in the start of the senstance and a suffix in the end of the sentance and that grams will contain whitespace. I never did phrase queries using grams but I'd probably want prefix and suffix around each token. This is another good reason to keep them in the same field with prefix and suffix markers in the token, or? ",
            "author": "Karl Wettin",
            "id": "comment-12605721"
        },
        {
            "date": "2008-06-18T05:06:40+0000",
            "content": "First of all, my comment No.3 was not wrong, sorry. We don't have to insert $^ token in the ngram stream.\n\n\nI don't want separate fields for the prefix, inner and suffix grams, I want to use the same single filter at query time. \n\nI agree with that. \n\nThen, let's consider about the phrase query.\n1. At store time, we want to store a sentence \"This is a pen\"\n2. At query time, we want to query with \"This is\"\n\nAt store time, with WhitespaceTokenizer+CombinedNGramTokenFilter(2,2), we get:\n^T Th hi is s$ ^i is s$ ^a a$ ^p pe en n$\n\nAt query time, with WhitespaceTokenizer+CombinedNGramTokenFilter(2,2), we get:\n^T Th hi is s$ ^i is s$\n\nWe can find that the stored sequence because it contains the query sequence.\n\n\nIf you are creating ngrams over multiple words, say a sentence, then I state that there should only be a prefix in the start of the senstance and a suffix in the end of the sentance and that grams will contain whitespace.\n\nIf so, at query time, with WhitespaceTokenizer+CombinedNGramTokenFilter(2,2), we get:\n\"^T\",\"Th\",\"hi\",\"is\",\"s \",\" i\",\"is\",\"s$\"\n\nWe can't find the stored sequence because it does not contain the query sequence. n-gram query is always phrase query in the micro scope. \n\n+1 for prefix and suffix markers in the token.\n\n\nNote, also, that one could use the \"flags\" to indicate what the token is. I know that's a little up in the air just yet, but it does exist. \n\nYes, there is a flags. Of cource, we can use it. But I can't find the way to use them efficiently in THIS CASE, right now.\n\n\nThis would mean that no stripping of special chars is required.\n\nUnfortunately, stripping is done outside of the ngram filter by WhitespaceTokenizer. ",
            "author": "Hiroaki Kawai",
            "id": "comment-12605836"
        },
        {
            "date": "2008-06-21T21:34:36+0000",
            "content": "New in this patch:\n\n\toffsets as in NGramTokenFilter\n\ttoken type \"^gram\", \"gram$\", \"^gram$\" and \"gram\"\n\ta bit of javadocs\n\n\n\nThere is also a todo I'll have to look in to some other day.\n\n\n//  todo\n//  /**\n//   * if true, prefix and suffix does not count as a part of the ngram size.\n//   * E.g. '^he' has as n of 2 if true and 3 if false\n//   */\n//  private boolean usingBoundaryCharsPartOfN = true;\n\n\n\nThis was not quite as simple to add as I hoped it would be and will try to find some time to fix that before I commit it. ",
            "author": "Karl Wettin",
            "id": "comment-12607040"
        },
        {
            "date": "2008-08-04T11:16:55+0000",
            "content": "The files looks good for me. ",
            "author": "Hiroaki Kawai",
            "id": "comment-12619480"
        },
        {
            "date": "2008-11-12T17:41:51+0000",
            "content": "Could/should this not be folded into the existing Ngram code in contrib? ",
            "author": "Otis Gospodnetic",
            "id": "comment-12646971"
        },
        {
            "date": "2013-03-10T13:32:57+0000",
            "content": "SPRING_CLEANING_2013 We can reopen if necessary.  ",
            "author": "Erick Erickson",
            "id": "comment-13598249"
        }
    ]
}