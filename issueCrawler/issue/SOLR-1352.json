{
    "id": "SOLR-1352",
    "title": "DIH: MultiThreaded",
    "details": {
        "affect_versions": "None",
        "status": "Resolved",
        "fix_versions": [
            "1.5"
        ],
        "components": [
            "contrib - DataImportHandler"
        ],
        "type": "Improvement",
        "priority": "Major",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "It has been a long pending request to make DIH multithreaded. Now that we have implemented most of the features , the next best thing we can aim for is performance. DIH should be able to take advantage of multiple cores in a box .I expect the configuration to be as follows\n\n\n<entity name=\"foo\" threads=\"4\">\n<!--more stuff goes here-->\n</entity>\n\n\n\nat the entity where the threads is specified it should fork into multiple threads. If the threads<2 it executes w/o forking. In debug mode it automatically becomes singlethreaded.",
    "attachments": {
        "SOLR-1352.patch": "https://issues.apache.org/jira/secure/attachment/12424828/SOLR-1352.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Avlesh Singh",
            "id": "comment-12741047",
            "date": "2009-08-09T07:56:17+0000",
            "content": "Thanks, once again , for creating the ticket, Noble.\nHere's the last discussion on the topic, \"Support for batch processing of commands using parallel threads in DIH\" - http://www.lucidimagination.com/search/document/a9b26ade46466ee/queries_regarding_a_paralleldataimporthandler "
        },
        {
            "author": "Noble Paul",
            "id": "comment-12777429",
            "date": "2009-11-13T09:57:24+0000",
            "content": "first cut an ugly patch. a lot of work left before putting it in "
        },
        {
            "author": "Noble Paul",
            "id": "comment-12777430",
            "date": "2009-11-13T09:58:46+0000",
            "content": "'numThreads' becomes' threads' "
        },
        {
            "author": "Noble Paul",
            "id": "comment-12786853",
            "date": "2009-12-07T10:32:15+0000",
            "content": "updated to trunk "
        },
        {
            "author": "Noble Paul",
            "id": "comment-12793988",
            "date": "2009-12-23T09:42:35+0000",
            "content": "More or less final. I plan to commit this soon "
        },
        {
            "author": "Noble Paul",
            "id": "comment-12799113",
            "date": "2010-01-12T07:59:54+0000",
            "content": "committed Revision: 898209 "
        },
        {
            "author": "David Smiley",
            "id": "comment-12862852",
            "date": "2010-04-30T20:42:23+0000",
            "content": "Without having to read the patch, can someone describe in more detail the nature of DIH multi-threading?  I can figure what it would mean to have two threads, one to read from the data provider and one to write to Solr, with a queue in-between.  But it's not clear what's going on here since thread can be > 2. "
        },
        {
            "author": "Noble Paul",
            "id": "comment-12864170",
            "date": "2010-05-05T05:47:11+0000",
            "content": "the read and write are done by the same thread. but if you have 4 threads 4 documents will be processed in parallel "
        },
        {
            "author": "Alexey Serba",
            "id": "comment-12889224",
            "date": "2010-07-16T16:49:28+0000",
            "content": "I've tested this feature in trunk on a quite large data set ( freebase WEX wikipedia extract loaded into Oracle database ). It seems to be working ok. \n\nThe only thing I noticed is that multithreaded implementation produce too verbose logging. Could you please change log level to DEBUG for the following events:\n\n2010-07-16 20:35:50,199 INFO  dataimport.ThreadedEntityProcessorWrapper  - arow : \n{id=12345, body=blahblah, title=Title}\n2010-07-16 20:35:50,201 INFO  dataimport.DocBuilder  - a row on docrootSolrInputDocument[{id=id(1.0)=\n{12345}\n, body=body(1.0)=\n{blahblah}\n, title=title(1.0)={Title}}] "
        },
        {
            "author": "Russell Teabeault",
            "id": "comment-12892919",
            "date": "2010-07-27T20:38:57+0000",
            "content": "I was trying to apply the patch against 1.4 and was unsuccessful.  Has anyone created a patch for this against 1.4 or could give me some advice about creating one.  Thanks. "
        },
        {
            "author": "Noble Paul",
            "id": "comment-12893093",
            "date": "2010-07-28T07:27:27+0000",
            "content": "y do you need to apply  a patch? DIH is a separate .jar file. just take the jar from the latest and replace in your 1.4 release "
        },
        {
            "author": "Russell Teabeault",
            "id": "comment-12893264",
            "date": "2010-07-28T17:21:15+0000",
            "content": "I believe there have been some incompatible changes that have been made and so it is not as easy as just dropping in the DIH jar.  I took the 1.4 war and replaced the DIH jar with a current build of the 1.5 DIH jar.  When accessing the dataimport.jsp file I got the following error:\n\n\norg.apache.solr.handler.RequestHandlerBase.handleRequestBody(Lorg/apache/solr/request/SolrQueryRequest;Lorg/apache/solr/request/SolrQueryResponse;)V\n\njava.lang.AbstractMethodError: org.apache.solr.handler.RequestHandlerBase.handleRequestBody(Lorg/apache/solr/request/SolrQueryRequest;Lorg/apache/solr/request/SolrQueryResponse;)V\n\tat org.apache.solr.handler.RequestHandlerBase.handleRequest(RequestHandlerBase.java:131)\n\tat org.apache.solr.core.SolrCore.execute(SolrCore.java:1316)\n....\n\nAny ideas?  Thanks. "
        },
        {
            "author": "Russell Teabeault",
            "id": "comment-12893693",
            "date": "2010-07-29T16:51:10+0000",
            "content": "Ok.  The package of SolrQueryResponse changed from org.apache.solr.request to org.apache.solr.response.  Because org.apache.solr.response.SolrQueryResponse does not exist in 1.4 I changed the necessary code in the trunk to use org.apache.solr.request.SolrQueryResponse so that I could get everything to compile.  I then replaced the dataimporthandler jar file in the 1.4 version of the solr war. \n\nSo with one thread everything works fine.  I then set the root entity to use 4 threads.  I often get the following exception almost immediately after starting:\n\norg.apache.solr.handler.dataimport.DataImportHandlerException: java.sql.SQLRecoverableException: Closed Connection: next\n        at org.apache.solr.handler.dataimport.DataImportHandlerException.wrapAndThrow(DataImportHandlerException.java:64)\n        at org.apache.solr.handler.dataimport.JdbcDataSource$ResultSetIterator.hasnext(JdbcDataSource.java:337)\n        at org.apache.solr.handler.dataimport.JdbcDataSource$ResultSetIterator.access$600(JdbcDataSource.java:226)\n        at org.apache.solr.handler.dataimport.JdbcDataSource$ResultSetIterator$1.hasNext(JdbcDataSource.java:260)\n        at org.apache.solr.handler.dataimport.EntityProcessorBase.getNext(EntityProcessorBase.java:75)\n        at org.apache.solr.handler.dataimport.SqlEntityProcessor.nextRow(SqlEntityProcessor.java:73)\n...\n\nHowever after 5 to 10 attempts it runs without problem.  This is being run against an Oracle 10g database using the 11g driver.  Also we have 4 sub-entities.  Not sure if I should open a new defect for this or if this has been seen by other people?  Thoughts? "
        },
        {
            "author": "Noble Paul",
            "id": "comment-12896500",
            "date": "2010-08-09T10:58:17+0000",
            "content": "you may open another issue, because this is already closed "
        },
        {
            "author": "cmd",
            "id": "comment-12931442",
            "date": "2010-11-12T16:46:46+0000",
            "content": "Hi Russell Teabeault and  my problem was serious:\n\n<dataConfig>\n\t<dataSource driver=\"oracle.jdbc.driver.OracleDriver\" url=\"jdbc:oracle:thin:@192.168.0.5:1521:orcl\" user=\"TESTSOLR\" password=\"TESTSOLR\" />\n\t<document name=\"doc\">\n\t\t<entity name=\"A\" transformer=\"ClobTransformer\" threads=\"8\" query=\"select * from A \" pk=\"id\">\n                        <field column=\"COL1\" clob=\"true\" name=\"COL1\" />\n\t\t\t<field column=\"COL1\" clob=\"true\" name=\"COL2\" />\n\n                        <entity name=\"B\"  query=\"select * from B WHERE AID='${A.ID}' \" pk=\"id\" processor=\"CachedSqlEntityProcessor\">\n                        <field column=\"COL3\" clob=\"true\" name=\"COL2\" />\n\t\t\t<field column=\"COL4\" clob=\"true\" name=\"COL4\" />\n\t\t\t</entity>\n\t\t</entity>\n\t</document>\n</dataConfig>\n\nTABLE A:10 million rows\nTABLE B:20 million rows\n\nthe dih processor is very unstable.always throws exception \n\"Closed Connection: next\"\nplease provide some information to me .thanks.\n "
        }
    ]
}