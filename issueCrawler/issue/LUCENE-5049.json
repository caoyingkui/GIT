{
    "id": "LUCENE-5049",
    "title": "Native (C++) implementation of \"pure OR\" BooleanQuery",
    "details": {
        "components": [],
        "fix_versions": [],
        "affect_versions": "None",
        "priority": "Major",
        "labels": "",
        "type": "Improvement",
        "resolution": "Unresolved",
        "status": "Open"
    },
    "description": "I've been playing with a C++ implementation of BooleanQuery containing\nonly OR'd (SHOULD) TermQuery clauses, collecting top N hits by score.\n\nThe results are impressive: ~3X speedup for BQ OR over two terms, and\nalso good speedups (~38-78%) for Fuzzy1/2 as well since they rewrite\nto BQ OR over N terms:\n\n\n                    Task    QPS base      StdDev    QPS comp      StdDev                Pct diff\n                 MedTerm       69.47     (15.8%)       68.61     (13.4%)   -1.2% ( -26% -   33%)\n                HighTerm       55.25     (16.2%)       54.63     (13.9%)   -1.1% ( -26% -   34%)\n                 LowTerm      333.10      (9.6%)      329.43      (8.0%)   -1.1% ( -17% -   18%)\n                  IntNRQ        3.37      (2.6%)        3.36      (4.6%)   -0.2% (  -7% -    7%)\n                 Prefix3       18.91      (2.0%)       19.04      (3.5%)    0.7% (  -4% -    6%)\n                Wildcard       29.40      (1.7%)       29.70      (2.8%)    1.0% (  -3% -    5%)\n               MedPhrase      132.69      (6.2%)      134.66      (7.0%)    1.5% ( -11% -   15%)\n        HighSloppyPhrase        0.82      (3.6%)        0.83      (3.5%)    1.9% (  -5% -    9%)\n             AndHighHigh       19.65      (0.6%)       20.02      (0.8%)    1.9% (   0% -    3%)\n              HighPhrase       11.74      (6.6%)       11.96      (7.1%)    1.9% ( -11% -   16%)\n         MedSloppyPhrase       29.09      (1.2%)       29.76      (1.9%)    2.3% (   0% -    5%)\n         LowSloppyPhrase       25.71      (1.4%)       26.98      (1.7%)    4.9% (   1% -    8%)\n                 Respell      173.78      (3.0%)      182.41      (3.7%)    5.0% (  -1% -   12%)\n             MedSpanNear       27.67      (2.5%)       29.07      (2.4%)    5.1% (   0% -   10%)\n            HighSpanNear        2.95      (2.4%)        3.10      (2.8%)    5.4% (   0% -   10%)\n             LowSpanNear        8.29      (3.4%)        8.82      (3.3%)    6.4% (   0% -   13%)\n              AndHighMed       79.32      (1.6%)       84.44      (1.0%)    6.5% (   3% -    9%)\n               LowPhrase       23.20      (2.0%)       25.14      (1.6%)    8.4% (   4% -   12%)\n              AndHighLow      594.17      (3.4%)      660.32      (1.9%)   11.1% (   5% -   16%)\n                  Fuzzy2       88.32      (6.4%)      121.44      (1.7%)   37.5% (  27% -   48%)\n                  Fuzzy1       86.34      (6.0%)      153.49      (1.7%)   77.8% (  66% -   90%)\n              OrHighHigh       16.29      (2.5%)       48.29      (1.3%)  196.5% ( 188% -  205%)\n               OrHighMed       28.98      (2.7%)       87.81      (0.9%)  203.0% ( 194% -  212%)\n               OrHighLow       27.38      (2.6%)       84.94      (1.1%)  210.3% ( 201% -  219%)\n\n\n\nThis is essentially a scaled back attempt at LUCENE-1594 in that it's\n\"hardwired\" to \"just\" the \"OR of TermQuery\" case.",
    "attachments": {
        "LUCENE-5049.patch": "https://issues.apache.org/jira/secure/attachment/12586984/LUCENE-5049.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2013-06-09T21:45:51+0000",
            "content": "Patch.\n\nI use NativeMMapDir (borrowed from LUCENE-3178) to be able to map a\nsingle file without chunking.\n\nNo core changes were needed (it uses reflection to grab all the stuff\nit needs).\n\nThis works with the current default 4.x codec, but it's somewhat\nsub-optimal on x86 since Lucene stores longs big-endian but x86 is\nlittle-endian: I do a long byte-swap for every long at read time\n(though this is a single instruction on x86...).  Also, the longs are\nnot \"aligned\" in memory, but x86 seems not to have much penalty for\nthis (I tried a modified PF that inserts spacer bytes to align each\nblock, but net/net it was slower).\n\nIt's simple to use: there is a single static NativeSearch.search\nmethod, that will use the native code if it can apply to the current\n\"context\", and otherwise falls back to normal IndexSearcher method.\nSo an app can just route all searches through this API, and those that\ncan be optimized, will be.\n\nThere are definite limitations:\n\n\n\tYou must use NativeMMapDir, default codec and sim, all terms must\n    be in one field, and you must sort by score.\n\n\n\n\n\tIt's C code ... so when there are bugs, when you close the\n    IndexSearcher while threads are still searching, etc., you'll get\n    SEGV and the OS will kill the JVM!\n\n\n\n\n\tOnly works on Linux (Unix) little-endian CPUs (only tested on\n    Linux/Intel...) since I always byte swap ...\n\n ",
            "author": "Michael McCandless",
            "id": "comment-13679180"
        },
        {
            "date": "2013-06-09T21:54:11+0000",
            "content": "Okay, I'll be the first to ask it: C++? Really? Is this the beginning of the end for Java for the world of high-performance search?\n\nSeriously, a second question: What about alternative JVM-based languages? I mean, maybe Java does have excess baggage related to its quirky semantics, but could the raw JVM support a lower-level implementation of BQ, without leaving the JVM... \"bubble\"? OTOH, maybe different JVM's could have different performance characteristics.\n\nOh, and what compiler/machine architecture was this for?\n\nAnother question: might there be alternative representations of BQ based on what exactly the clauses are?\n\nOTOH, for us Solr guys, there is somewhat the impression that raw Lucene search is blazing fast already and not the bottleneck for Solr where other things, like caches and facets and highlighting are the concern.\n\nFinally, some of these gains seem... marginal if not outright disappointing considering the raw expectation that bare C++ should be a LOT faster. So, is this maybe more of a \"See, C++ doesn't have THAT big an advantage over Java even for core search operations? ",
            "author": "Jack Krupansky",
            "id": "comment-13679182"
        },
        {
            "date": "2013-06-09T22:40:22+0000",
            "content": "This is an apples vs oranges comparison.\n\nIf you write one huge hairy java method with hardcoded query (OR) + hardcoded Postingsformat (Lucene42) + hardcoded Directory (Mmap) + Hardcoded Similarity (Default) that only works if all terms are against a single field, it would be much faster there too...  ",
            "author": "Robert Muir",
            "id": "comment-13679210"
        },
        {
            "date": "2013-06-09T23:18:19+0000",
            "content": "This is an apples vs oranges comparison.\n\nI agree: all we can conclude from the benchmark is that this hardwired\nC++ impl is ~3X faster (on OR-of-TermQuery) than what we have today in\nJava.\n\nWe can't tell exactly where the gains come from, i.e. how much is due\nto 1) Java vs C and how much from 2) specializing everything to single\ndedicated code.\n\nIf we could build the same specialized code in Java then we could\nseparately test these contributions.  Maybe we could also test which\ncomponents (decoding postings, matching, scoring, collecting) gave\nwhich part of the gains. ",
            "author": "Michael McCandless",
            "id": "comment-13679218"
        },
        {
            "date": "2013-06-09T23:29:17+0000",
            "content": "Okay, I'll be the first to ask it: C++? Really? Is this the beginning of the end for Java for the world of high-performance search?\n\nI don't think so.  This is just an option and it only matches users\ndoing OR BQ over TQ against one field, with default codec/sim, etc.\nI certainly don't think we should switch Lucene to C++.\n\nSeriously, a second question: What about alternative JVM-based languages? I mean, maybe Java does have excess baggage related to its quirky semantics, but could the raw JVM support a lower-level implementation of BQ, without leaving the JVM... \"bubble\"? OTOH, maybe different JVM's could have different performance characteristics.\n\nWe should explore that!  I have no idea.\n\nOh, and what compiler/machine architecture was this for?\n\nLinux / x86 is what I tested on, but I think the code would work fine on other OS's / CPUs.\n\nAnother question: might there be alternative representations of BQ based on what exactly the clauses are?\n\n?\n\nOTOH, for us Solr guys, there is somewhat the impression that raw Lucene search is blazing fast already and not the bottleneck for Solr where other things, like caches and facets and highlighting are the concern.\n\nFaceting/highlighting are definitely costly...\n\nFinally, some of these gains seem... marginal if not outright disappointing considering the raw expectation that bare C++ should be a LOT faster. So, is this maybe more of a \"See, C++ doesn't have THAT big an advantage over Java even for core search operations?\n\nActually I think ~300% gains are unexpectedly high: they were more\nthan I expected.\n\nIt would be nice if most of those gains were from code spec and not\nfrom Java/C++ ... then we could say \"C++ doesn't have that big an\nadvantage over Java\", but it's not clear now where the gains come\nfrom. ",
            "author": "Michael McCandless",
            "id": "comment-13679219"
        },
        {
            "date": "2013-06-10T06:58:50+0000",
            "content": "Hi Mike,\n\nI agree with Robert and Jack - this is like comparing apples and pies. We are back at the same place like 4  years ago when everybody added bulk APIs and you posted a highly optimized special case with all l\u2603\u2603ps-unr\u2603lled\u2122 (LUCENE-1594). This is comparing apples with pies: You use the specialized MMapDirectory which is really a lot faster, so a lot of the improvements also come from there. From most customers I have seen, the \"OR\" case with pure term queries is not the most common one (although it should in reality, but users want \"and\" - maybe because our default scoring is bad - other story?).\n\nI am completely against the idea to have this anywhere in Lucene, same for NativeMMapDirectory (and I am not happy with NativeLinux/WindowsDirectory, too - although they are so special that they have some reason to exist). I would never suggest anybody to actually use this in production, it is too risky. If you want to release this code, its easy: Create a Google Code project and do it outside of Lucene. All interconnection points here are through reflection, so it can be completely separate. I definitely will not post you results anywhere in twitter, because doing this would create another shitstorm against Lucene, Java, Hotspot, and C++ - especially because the results here have nothing to do with Java vs. C++ - its just specialization, nothing more. As Robert said, you can do the same with pure Java (see LUCENE-1594).\n\nThe only possible way to bring C code back into the game is to bring CLucene back to live!\n\nSeriously, a second question: What about alternative JVM-based languages? I mean, maybe Java does have excess baggage related to its quirky semantics, but could the raw JVM support a lower-level implementation of BQ, without leaving the JVM... \"bubble\"? OTOH, maybe different JVM's could have different performance characteristics.\n\nI don't see any change in performance here, as other JVM-based languages produce the same bytecode like javac, just from another source code. Java bytecode is flexible but not too flexible. The optimizations are done by hotspot and those bytecode has not much room for optimization, thats up to the runtime engine.\n\nThe only thing I see is: We use ASM or Javassist to create specialized methods on-the-fly (like a just-in-time compiler). Instead of static Python generated code that is residing in the JAR file, we use a bytecode-generator that creates the packed int classes on the fly and loads them into the JVM using a private child classloader. This can do other code, too. ",
            "author": "Uwe Schindler",
            "id": "comment-13679350"
        },
        {
            "date": "2013-06-22T18:34:37+0000",
            "content": "OK, fair enough Uwe ... I've continued this effort at https://github.com/mikemccand/lucene-c-boost and wrote a blog post about it at http://blog.mikemccandless.com/2013/06/screaming-fast-lucene-searches-using-c.html ",
            "author": "Michael McCandless",
            "id": "comment-13691206"
        }
    ]
}