{
    "id": "LUCENE-2906",
    "title": "Filter to process output of ICUTokenizer and create overlapping bigrams for CJK",
    "details": {
        "labels": "",
        "priority": "Minor",
        "components": [
            "modules/analysis"
        ],
        "type": "New Feature",
        "fix_versions": [
            "3.6",
            "4.0-ALPHA"
        ],
        "affect_versions": "None",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "The ICUTokenizer produces unigrams for CJK. We would like to use the ICUTokenizer but have overlapping bigrams created for CJK as in the CJK Analyzer.  This filter would take the output of the ICUtokenizer, read the ScriptAttribute and for selected scripts (Han, Kana), would produce overlapping bigrams.",
    "attachments": {
        "LUCENE-2906.patch": "https://issues.apache.org/jira/secure/attachment/12470397/LUCENE-2906.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2011-02-04T21:01:00+0000",
            "content": "I'll take it, ive done the unibigram approach already (maybe we can just have it as a separate filter option), so the bigram should be easy.\n\nMy original design, just lets you provide a BitSet of script codes. (this would be simple i think to parse from say a solr factory).\n\nI think its also useful to have an option, for whether the filter should only do this for \"joined\" text or not (based on offsets). For CJK i think it makes sense to enforce this, so that it won't bigram across sentence boundaries. But for say the Tibetan language, where you have a syllable separator, you would want to turn this off.\n\nSeparately, if you want it to work \"just like\" CJKTokenizer, please be aware that by default, the unicode standard tokenizes Katakana to words (only hiragana and han are tokenized to codepoints). So in this case you would have to use a custom ruleset if you wanted katakana to be tokenized to codepoints instead of words, for later bigramming. I'm not sure you want to do this though... (in truth CJKTokenizer bigrams ANYTHING out of ascii, including a lot of things it shouldnt).\n\nFor hangul the same warning applies, but its more debatable, you might want to do this if you don't have a decompounder... but in my opinion this is past tokenization, and its the same problem you have with german, etc... the default tokenization is not \"wrong\".\n\nIn either case, if you decide to do that, it would be a pretty simple ruleset!\n\nLet me know if this makes sense to you. ",
            "author": "Robert Muir",
            "id": "comment-12990739"
        },
        {
            "date": "2011-02-04T23:39:55+0000",
            "content": "Sounds good to me.\n\nThe option to limit to \"joined\" text also sounds very useful.\n\nTom ",
            "author": "Tom Burton-West",
            "id": "comment-12990833"
        },
        {
            "date": "2011-02-06T13:30:12+0000",
            "content": "here's a patch going in a slightly different direction (though we can still add some special icu-only stuff here).\n\ninstead the patch synchronizes the token types of ICUTokenizer with StandardTokenizer, adds the necessarily types to both, and then adds the bigramming logic to standardfilter.\n\nthis way, cjk works easily \"out of box\", for all of unicode (e.g. supplementaries) and plays well with other languages. i deprecated cjktokenizer in the patch and pulled out its special full-width filter into a separate tokenfilter. ",
            "author": "Robert Muir",
            "id": "comment-12991152"
        },
        {
            "date": "2011-02-06T16:19:44+0000",
            "content": "Two questions:\nHow will this differ from the SmartChineseAnalyzer?\nI doubt it but can this be in 3.1? ",
            "author": "DM Smith",
            "id": "comment-12991169"
        },
        {
            "date": "2011-02-06T17:43:23+0000",
            "content": "\nHow will this differ from the SmartChineseAnalyzer?\n\nThe SmartChineseAnalyzer is for Simplified Chinese only... this is about the \nlanguage-independent technique similar to what CJKAnalyzer does today.\n\n\nI doubt it but can this be in 3.1?\n\nWell i hate the way CJKAnalyzer treats things like supplementary characters (wrongly).\nThis is definitely a bug, and fixed here. Part of me wants to fix this as quickly as possible.\n\nAt the same time though, I would prefer 3.2... otherwise I would feel like I am rushing things.\n\nI don't think 3.2 needs to come a year after 3.1... in fact since we have a stable branch I think its\nstupid to make bugfix releases like 3.1.1 when we could just push out a new minor version (3.2) with\nbugfixes instead. The whole branch is intended to be stable changes, so I think this is better use\nof our time. But this is just my opinion, we can discuss it later on the list as one idea to promote \nmore rapid releases. ",
            "author": "Robert Muir",
            "id": "comment-12991186"
        },
        {
            "date": "2011-02-09T17:59:37+0000",
            "content": "the prerequisite subtask is fixed, so we should be able to add this in 3.2 (supporting StandardTokenizer, UAX29URLEmailTokenizer, and ICUTokenizer) without having to change any of the tokenizers.\n\nI'll update the patch. ",
            "author": "Robert Muir",
            "id": "comment-12992622"
        },
        {
            "date": "2011-06-03T16:40:46+0000",
            "content": "bulk move 3.2 -> 3.3 ",
            "author": "Robert Muir",
            "id": "comment-13043556"
        },
        {
            "date": "2011-08-31T21:10:47+0000",
            "content": "Any chance this might get implemented for 3.4? ",
            "author": "Tom Burton-West",
            "id": "comment-13094902"
        },
        {
            "date": "2011-12-16T23:51:12+0000",
            "content": "As much as I would like this to work as the patch does (where its automatic from StandardFilter), I think its bad because its something we then have to commit to/deal with for a while (e.g. backwards compat).\n\nSo another idea is just to call it CJKFilter or something under the CJK package for now. We could still cutover CJKAnalyzer like the patch and then it finally works with supplementary characters too (which I think is really long needed). ",
            "author": "Robert Muir",
            "id": "comment-13171318"
        },
        {
            "date": "2011-12-17T00:24:58+0000",
            "content": "sorry to take so long Tom... ill round this out tonight. ",
            "author": "Robert Muir",
            "id": "comment-13171356"
        },
        {
            "date": "2011-12-17T03:55:51+0000",
            "content": "synced up to trunk... has a couple minor nocommits (mostly just some needed tests) I'll look at tomorrow morning. ",
            "author": "Robert Muir",
            "id": "comment-13171445"
        },
        {
            "date": "2011-12-27T04:06:09+0000",
            "content": "patch removing all nocommits with additional tests.\n\nI think its ready to commit. ",
            "author": "Robert Muir",
            "id": "comment-13176076"
        },
        {
            "date": "2011-12-27T15:04:09+0000",
            "content": "one new test and a tweak: so that this filter never calls input.incrementToken() after it already returned false. ",
            "author": "Robert Muir",
            "id": "comment-13176200"
        },
        {
            "date": "2011-12-29T05:24:36+0000",
            "content": "Committed, maybe in the future we enable this for StandardFilter (for good CJK behavior by default), but for now it seems good enough to have separate filters that handle the corner cases and all of unicode. ",
            "author": "Robert Muir",
            "id": "comment-13176997"
        },
        {
            "date": "2011-12-29T10:02:30+0000",
            "content": "Hi Robert,\n\nI had no time to review before, there is one small thing that should maybe fixed. Currently this finter relies on the fact that TypeAttribute strings are interned, as it compares by identity:\n\n\nString type = typeAtt.type();\nif (type == doHan || type == doHiragana || type == doKatakana || type == doHangul) {\n\n\n\nThis is documented nowhere that Strings in TypeAttribute need to be interned. We should maybe replace that check by a simple equals(). It seems that you already wanted to do that, as you added a sentinel value Object NO = new Object(). With the above check this sentinel value is useless, a simple null would be enough. EDIT: Sentinel value is also useful for not enabling bigramming is a Tokenizer sets \"null\" as TypeAttribute. When using equals() this sentinel makes real sense. The check is not costly. String.equals() already does an identity check for early exit, if the sentinel is used it will also quickly return false (if String.equals(sentinel) is used, it will return false on instanceof Check, if you call sentinel.equals(String) it will even be faster).\n\nSo I would change this check to:\n\n\nString type = typeAtt.type();\nif (doHan.equals(type) || doHiragana.equals(type) || doKatakana.equals(type) || doHangul.equals(type)) {\n\n\n\n(this is the fastest check, if the doXXX is the sentinel, it's default Object.equals() will return false. If its a string, String.equals() will return true on identity very quick, but if it's not interned it will be slower. So we loose nothing but dont require useless interned strings. ",
            "author": "Uwe Schindler",
            "id": "comment-13177097"
        },
        {
            "date": "2011-12-29T10:26:25+0000",
            "content": "...alternatively, we could use a HashSet<String>. If the stringsin it are intered, the lookup is fast, too. The hashCode of Strings is precalculated in the String class. For four if checks it maybe not really different performance wise, but thats just another idea. The ctor would simply check the flags and add the type strings to the Set<String>. ",
            "author": "Uwe Schindler",
            "id": "comment-13177101"
        },
        {
            "date": "2011-12-29T14:09:50+0000",
            "content": "Hi Uwe:\n\nMany filters in lucene currently do things like this, and have forever (including StandardFilter).\nIn my opinion its ok, as its documented this filter works with StandardTokenizer and ICUTokenizer which use\nthe interned types.\n\nSo I would prefer if we discuss this on another issue. ",
            "author": "Robert Muir",
            "id": "comment-13177187"
        },
        {
            "date": "2011-12-29T14:32:35+0000",
            "content": "I created LUCENE-3669 for the broader interned-type issue ",
            "author": "Robert Muir",
            "id": "comment-13177201"
        }
    ]
}