{
    "id": "SOLR-12518",
    "title": "PreAnalyzedField fails to index documents without tokens",
    "details": {
        "labels": "",
        "priority": "Minor",
        "components": [
            "update"
        ],
        "type": "Bug",
        "fix_versions": [],
        "affect_versions": "None",
        "resolution": "Unresolved",
        "status": "Open"
    },
    "description": "Overview\n\nPreAnalyzedField fails to index documents without tokens like the following data:\n\n{\n  \"v\": \"1\",\n  \"str\": \"foo\",\n  \"tokens\": []\n}\n\n\nDetails\n\nPreAnalyzedField consumes field values which have been pre-analyzed in advance. The format of pre-analyzed value is like follows:\n\n{\n  \"v\":\"1\",\n  \"str\":\"test\",\n  \"tokens\": [\n    {\"t\":\"one\",\"s\":123,\"e\":128,\"i\":22,\"p\":\"DQ4KDQsODg8=\",\"y\":\"word\"},\n    {\"t\":\"two\",\"s\":5,\"e\":8,\"i\":1,\"y\":\"word\"},\n    {\"t\":\"three\",\"s\":20,\"e\":22,\"i\":1,\"y\":\"foobar\"}\n  ]\n}\n\n\nAs the document mensions, \"str\" and \"tokens\" are optional, i.e., both an empty value and no key are allowed. However, when \"tokens\" is empty or not defined, PreAnalyzedField throws IOException and fails to index the document.\n\nThis error is related to the behavior of Field#tokenStream. This method tries to create TokenStream by following steps (NOTE: assume indexed=true):\n\n\tIf the field has tokenStream value, returns it.\n\tOtherwise, creates tokenStream by parsing the stored value.\n\n\n\nIf pre-analyzed value doesn't have tokens, the second step will be executed. Unfortunately, since PreAnalyzedField always returns PreAnalyzedAnalyzer as the index analyzer and the stored value (i.e., the value of \"str\") is not the pre-analyzed format, this step will fail due to the pre-analyzed format error (i.e., IOException).\nHow to reproduce\n\n1. Download latest solr package and prepare solr server according to Solr Tutorial.\n 2. Add following fieldType and field to the schema.\n\n    <fieldType name=\"preanalyzed-with-analyzer\" class=\"solr.PreAnalyzedField\">\n      <analyzer>\n        <tokenizer class=\"solr.WhitespaceTokenizerFactory\"/>\n      </analyzer>\n    </fieldType>\n    <field name=\"pre_with_analyzer\" type=\"preanalyzed-with-analyzer\" indexed=\"true\" stored=\"true\" multiValued=\"false\"/>\n\n\n3.\u00a0Index following documents and Solr will throw IOException.\n\n// This is OK\n{\"id\": 1, \"pre_with_analyzer\": \"{\\'v\\':\\'1\\',\\'str\\':\\'document one\\',\\'tokens\\':[{\\'t\\':\\'one\\'},{\\'t\\':\\'two\\'},{\\'t\\':\\'three\\',\\'i\\':100}]}\"}\n\n// Solr throws IOException\n{\"id\": 2, \"pre_with_analyzer\": \"{\\'v\\':\\'1\\',\\'str\\':\\'document two\\', \\'tokens\\':[]}\"}\n\n// Solr throws IOException\n{\"id\": 3, \"pre_with_analyzer\": \"{\\'v\\':\\'1\\',\\'str\\':\\'document three\\'}\"}\n\n\nHow to fix\n\nBecause we don't need to analyze again if \"tokens\" is empty or not set, we can avoid this error by setting EmptyTokenStream as tokenStream instead like the following code:\n\nparse.hasTokenStream() ? parse : new EmptyTokenStream()",
    "attachments": {
        "SOLR-12518.patch": "https://issues.apache.org/jira/secure/attachment/12929163/SOLR-12518.patch"
    },
    "issue_links": {},
    "comments": []
}