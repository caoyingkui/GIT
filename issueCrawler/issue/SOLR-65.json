{
    "id": "SOLR-65",
    "title": "Multithreaded DirectUpdateHandler2",
    "details": {
        "affect_versions": "None",
        "status": "Closed",
        "fix_versions": [
            "1.1.0"
        ],
        "components": [
            "update"
        ],
        "type": "New Feature",
        "priority": "Major",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "Basic implementation of autoCommi functionality, plus overhaul of DUH2 threading to reduce contention",
    "attachments": {
        "autocommit_patch.diff": "https://issues.apache.org/jira/secure/attachment/12344256/autocommit_patch.diff"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Mike Klaas",
            "id": "comment-12446791",
            "date": "2006-11-03T01:32:14+0000",
            "content": "Basic autocommit implementation.\n\nNot complete: this patch still requires a scheduled call to checkCommit() to have the correct semantics--it is something I'm working on.\n\nI posted this patch to get feedback on the thread synchronization strategy.  I eliminated all synchronized blocks, and instead am using a reader/writer lock from java.util.concurrent for synchro.  Virtually everything is serialized using the writer lock (like the old strategy), but document adding degrades its lock to a lowered-contention reader lock before adding hte document to the index. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12447010",
            "date": "2006-11-03T17:00:37+0000",
            "content": "The multithreaded stuff looks very nice!\n\nI like the idea of separating out the autoCommit functionallity into a tracker.\n\nI notice that in closeWriter() you call tracker.didCommit()... but I think of a commit more as making sure everything is on stable storage, and making those changes visible.  closeWriter() is also currently called as an implementation side effect of delete-by-query.\n\nThere are some different uses for commit control that I can think of:\n 1) users don't want to manually send commits, and want to ensure that any changes made to the index will be visible within a certain amount of time.\n 2) in the event of multiple updaters all calling commit often, the index owner wants to limit the commit frequency to avoid search degredation (or OOM errors from too many overlapping on-deck searchers).\n 3) there are infrequent single updates to an index, but when they happen a commit should be done ASAP to lower the latency till visibility.  Subject to limitations in (2)\n\nIt's possible people might even want tuning on the fly.\nFor instance, if you are about to do a compete index rebuild, it would be nice to be able to turn off any autocommitting or commits alltogether to avoid partial indexes being visible.  This could be done with special update commands, or perhaps flags on the <add> command? "
        },
        {
            "author": "Mike Klaas",
            "id": "comment-12447101",
            "date": "2006-11-04T00:18:26+0000",
            "content": "> The multithreaded stuff looks very nice! \n\nThanks \u2013 the new concurrent package is quite cool (it much better fits my mental model of thread synchro).\n\nAbout the closeWriter() -> absolutely correct.  I had totally forgotten about the importance of opening a new searcher as part of the commit.\n\n1) sounds good.  \n2) does this include explicit commits received?  Might this make it tricky to test (both on solr's side and in userland)?  Perhaps the default commit could be an absolute directive, but could accept an optional parameter that allows the commit to be cancelled by the intervalLowerBound parameter.  Something like <commit hint=\"true\"/>.  Or it could be a new command <softcommit/>.  autocommits would also fall into that category.  \n3) would this case be covered by the client sending an <add> followed by <softcommit/>?\n\nThe on-the-fly tuning is possible for maxDocs autocommit but isn't practical for maxTime, since the time-based auto-commit is a system-wide property (whereas maxDocs are only checked within the context of a given request, so it is trivial to turn off checking locally).  It might be better to have some sort of global parameter tuning possible here (jmx??).\n\n-Mike  "
        },
        {
            "author": "Hoss Man",
            "id": "comment-12447104",
            "date": "2006-11-04T01:07:45+0000",
            "content": "Thining about this purely from a configuration standpoint, without any regard to implimentation complexity, the most general pupose options i can think of would be:\n\n   commitFrequencyHardMin (milliseconds)\n   commitFrequencySoftMin (milliseconds greater then commitFrequencyHardMin)\n   commitFrequencyTestDelay (milliseconds)\n   commitFrequencySoftMax (milliseconds greater then commitFrequencySoftMin)\n   commitFrequencyHardMax (milliseconds greater then commitFrequencySoftMax)\n   autoCommitDocs (integer)\n\n...assuming timeSinceLastCommit, timeSinceLastAddOrDelete, and numDocsAddedSinceLastCommit are available to is, these are the situations in which a commit would happen...\n\n   a) commitFrequencyHardMax <= timeSinceLastCommit\n   b) commitFrequencySoftMax <= timeSinceLastCommit < commitFrequencyHardMax\n       && commitFrequencyTestDelay <= timeSinceLastAddOrDelete\n   c) commitFrequencySoftMin <= timeSinceLastCommit < commitFrequencySoftMax\n       && [commit command recieved]\n   d) commitFrequencyHardMin <= timeSinceLastCommit < commitFrequencySoftMin\n       && commitFrequencyTestDelay <= timeSinceLastAddOrDelete \n       && [commit command recieved]\n\nThe situation where autoCommitDocs <= numDocsAddedSinceLastCommit would be generate a commit command (just as if a user had issued it)\n\nI think that various usages of those params (assuming they could be modified on the lfy using JMX or some new command) would cover all of the use cases yonik described, as well as all the ones i can think of.\n\n(implimenting that may be overkill however) "
        },
        {
            "author": "Mike Klaas",
            "id": "comment-12447118",
            "date": "2006-11-04T04:23:02+0000",
            "content": "It certainly appears that there is far more to this functionality than I have put thought into (mostly as the usage patterns are rather different from my usage of solr), and I'm inclined to think that this functionality is better implemented by someone with more time/motivation (especially considering we have a volunteer).\n\nThe important part of this patch for me is the multi-threaded indexing, and a max-doc autocommit would also be nice.  I also think that these two items are the least controversial.  How about I reduce the scope of the patch to those two items, leaving potential for more autocommit constraints? "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12447196",
            "date": "2006-11-04T21:10:07+0000",
            "content": "> How about I reduce the scope of the patch to those two items, leaving potential for more autocommit constraints?\nSounds good. "
        },
        {
            "author": "Mike Klaas",
            "id": "comment-12447609",
            "date": "2006-11-07T02:40:22+0000",
            "content": "New patch.\n\nFirst, the locking semantics actually were wrong.  Since ever addDoc call grabbed the commit lock and downgraded to access lock, subsequent calls would block on the commit.  I tried a few vastly different schemes, and it took a while to figure out something that allowed concurrency but also gave the same protections as before.  I finally settled on using the read/write commit lock as the principal lock, with a touch of synchronization to protect the addDoc calls.\n\nThat finally enabled concurrency, but other bottlenecks emerged.  checkCommit() was grabbing the commit lock, which created a barrier at the end of every addDoc call which  was forced to wait for all pending addDoc calls.  Switched to synchro on the tracker (synchronizing on DUH2 would provoke a potential deadlock).\n\nFinally, there was significant contention on the lock for the logger output stream.  When merging wasn't occuring, the doc rate could reach 200-300 dps, and each docId was being logged.  I modified the bulk add code to log the docid of all documents in a single log statement.  While I was at it, I converted the <result> output for multi-adds to a single xml element.  Was more information going to be added to this?\n\nThe gains of multi-threaded indexing for my application are modest.  The cpu usage is >100% consistently; it drops a bit during medium merges and drops a lot during large merges (merges effectively serialize adding documents).  Still, the throughput gain is about 20-30%.  In retrospect, this isn't terribly surprising, as our analysis is relatively modest.  Applications with heavier analysis needs would see more gains.  "
        },
        {
            "author": "Mike Klaas",
            "id": "comment-12447614",
            "date": "2006-11-07T03:21:51+0000",
            "content": "This is the issue that the patch belongs to. sorry. "
        },
        {
            "author": "Mike Klaas",
            "id": "comment-12447622",
            "date": "2006-11-07T04:19:11+0000",
            "content": "The last patch has a screwup which causes a few tests to fail... this will be fixed in the next version. "
        },
        {
            "author": "Mike Klaas",
            "id": "comment-12448024",
            "date": "2006-11-08T04:16:03+0000",
            "content": "This version removes the attempt at parsing the rest of the xml if an error occurs during document update.  \n\nIt has mostly already been reviewed, but to summarize, this patch:\n\n\timproves concurrency during multi-threaded document update\n\tpotentially optimizes huge commits (may prevent a stall if memory is constrained)\n\teliminates the edge cases of document update (esp. multi-doc update) which causes\n   solr to return xml that couldn't be parsed as a single document (should also solve SOLR-2; SOLR-54)\n\n\n\nIf no-one has objections, I'll commit the patch tomorrow. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12448273",
            "date": "2006-11-08T21:06:20+0000",
            "content": "Everything looks good to me.\n\n> While I was at it, I converted the <result> output for multi-adds to a single xml element. Was more information going to be added to this?\n\nI don't think so.\n\n> Still, the throughput gain is about 20-30%.\n\nNot too bad... is that for a dual CPU machine?  The number of cores per chip and cores per server are going up (quad cores, Sun niagra, etc), so these types of optimizations will grow in importance.\n\nI wonder what kind of gains could be had if Lucene could overlap adding of documents (via buffering) with merging of segments. "
        },
        {
            "author": "Mike Klaas",
            "id": "comment-12448318",
            "date": "2006-11-08T23:32:43+0000",
            "content": "\n   [[ Old comment, sent from unregistered email on Wed, 8 Nov 2006 13:43:59 -0800 ]]\n\n\nYep, that's a 2-cpu machine.\n\n\nA good question--it is definitely possible to test such a scenario by\nmanually creating ram segments and adding them (now that\naddIndicesNoOptimize exists).\n\nIt still might be possible to improve parallelism on the solr end by\nallows doc adds and doDeletions to run concurrently, but if that was a\nmajor bottleneck then the commit frequency could be reduced anyway.\n\nThanks for the review,\n-Mike\n "
        },
        {
            "author": "Mike Klaas",
            "id": "comment-12448332",
            "date": "2006-11-09T00:46:04+0000",
            "content": "Checked in patch r472720 "
        },
        {
            "author": "Hoss Man",
            "id": "comment-12589360",
            "date": "2008-04-15T23:56:45+0000",
            "content": "This bug was modified as part of a bulk update using the criteria...\n\n\n\tMarked (\"Resolved\" or \"Closed\") and \"Fixed\"\n\tHad no \"Fix Version\" versions\n\tWas listed in the CHANGES.txt for 1.1\n\n\n\nThe Fix Version for all 38 issues found was set to 1.1, email notification\nwas suppressed to prevent excessive email.\n\nFor a list of all the issues modified, search jira comments for this\n(hopefully) unique string: 20080415hossman3 "
        }
    ]
}