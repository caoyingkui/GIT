{
    "id": "SOLR-7378",
    "title": "Be more conservative about loading a core when hdfs transaction log could not be recovered",
    "details": {
        "components": [
            "SolrCloud"
        ],
        "type": "Bug",
        "labels": "",
        "fix_versions": [],
        "affect_versions": "5.0",
        "status": "Open",
        "resolution": "Unresolved",
        "priority": "Major"
    },
    "description": "Today, if an HdfsTransactionLog cannot recover its lease, you get the following warning in the log:\n\n\n      log.warn(\"Cannot recoverLease after trying for \" +\n        conf.getInt(\"solr.hdfs.lease.recovery.timeout\", 900000) +\n        \"ms (solr.hdfs.lease.recovery.timeout); continuing, but may be DATALOSS!!!; \" +\n        getLogMessageDetail(nbAttempt, p, startWaiting));\n\n\nfrom: https://github.com/apache/lucene-solr/blob/a8c24b7f02d4e4c172926d04654bcc007f6c29d2/solr/core/src/java/org/apache/solr/util/FSHDFSUtils.java#L145-L148\n\nBut some deployments may not actually want to continue if there is potential data loss, they may want to investigate what the underlying issue is with HDFS first.  And there's no way outside of looking at the logs to figure out what is going on.\n\nThere's a range of possibilties here, but here's a couple of ideas:\n1) config parameter around whether to continue with potential data loss or not\n2) load but require special flag to read potentially incorrect data (similar to  shards.tolerant, data.tolerant or something?)",
    "attachments": {},
    "issue_links": {},
    "comments": []
}