{
    "id": "SOLR-6832",
    "title": "Queries be served locally rather than being forwarded to another replica",
    "details": {
        "components": [
            "SolrCloud"
        ],
        "type": "Bug",
        "labels": "",
        "fix_versions": [
            "5.1",
            "6.0"
        ],
        "affect_versions": "4.10.2",
        "status": "Closed",
        "resolution": "Fixed",
        "priority": "Major"
    },
    "description": "Currently, I see that code flow for a query in SolrCloud is as follows:\n\nFor distributed query:\nSolrCore -> SearchHandler.handleRequestBody() -> HttpShardHandler.submit()\n\nFor non-distributed query:\nSolrCore -> SearchHandler.handleRequestBody() -> QueryComponent.process()\n\n\n\n\n\nFor a distributed query, the request is always sent to all the shards even if the originating SolrCore (handling the original distributed query) is a replica of one of the shards.\nIf the original Solr-Core can check itself before sending http requests for any shard, we can probably save some network hopping and gain some performance.\n\n\n\n\nWe can change SearchHandler.handleRequestBody() or HttpShardHandler.submit() to fix this behavior (most likely the former and not the latter).",
    "attachments": {
        "SOLR-6832.patch": "https://issues.apache.org/jira/secure/attachment/12687662/SOLR-6832.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2014-12-10T17:23:39+0000",
            "author": "Sachin Goyal",
            "content": "The performance gain increases if coresPerMachine is > 1 and a single JVM has cores from 'k' shards. ",
            "id": "comment-14241408"
        },
        {
            "date": "2014-12-11T06:54:33+0000",
            "author": "Shawn Heisey",
            "content": "I have concerns, but I don't want to derail the work.  There are use-cases for which this would be very useful, but many other use-cases where it would cause a single machine to crumble under the load while other machines in the cloud are nearly idle.\n\nDuplicating what I said on the dev@l.a.o thread:\n\nConsider a SolrCloud that is handling 5000 requests per second with a replicationFactor of 20 or 30.  This could be one shard or multiple shards.  Currently, those requests will be load balanced to the entire cluster.  If this option is implemented, suddenly EVERY request will have at least one part handled locally ... and unless the index is very tiny or 99 percent of the queries hit a Solr cache, one index core simply won't be able to handle 5000 queries per second.  Getting a single machine capable of handling that load MIGHT be possible, but it would likely be VERY expensive.\n\nThis would be great as an OPTION that can be enabled when the index composition and query patterns dictate it will be beneficial ... but it definitely should not be default behavior. ",
            "id": "comment-14242231"
        },
        {
            "date": "2014-12-12T21:50:03+0000",
            "author": "Ayon Sinha",
            "content": "Hi Shawn Heisey, I work with Sachin Goyal. The background of this patch is that, we have a cluster of 14 machines actually serving upwards of 5000 qps, and when one machine goes into a multi-second GC pause, it easily brings down the entire cluster. I know this is not the sole cause of the distributed deadlock and we definitely fixed other things like (gc pauses, thread counts etc) to reduce the likelihood of this problem.\n\nIn the scenario that you mention, the load balancer outside SolrCloud is at fault and when that is the case we'd like it to take down only one replica rather than propagate the problem to other replicas.\n\nSo to be clear, when this Option is ON, the only thing you'll \"lose\" is extra load balancing among the shard-queries. And frankly when I have all the shards in the same node, I prefer to NOT go over the network as network is among the most unreliable and taxed resource in cloud environments. When we go over the network to another compute, I have no idea what is carrying me over there and how is that other node doing overall. \nWe will post our results on the benefit of having this option as ON. ",
            "id": "comment-14244844"
        },
        {
            "date": "2014-12-13T21:09:40+0000",
            "author": "Shawn Heisey",
            "content": "That sounds like a perfect use-case for this option.  In your setup, you have an external load balancer and are not relying on SolrCloud itself or the zookeeper-aware Java client (CloudSolrServer) to do the load balancing for you.  For an environment like that, letting SolrCloud forward the request adds a completely unnecessary network hop, along with new Java objects and subsequent garbage that must be collected.\n\nThis is why I said I didn't want to derail the work.  If you have a solution, we should try to get it to a state where it can be committed.  It is very clear that it will be an immense help for many users.  I just don't want it to become the default.\n\nTrying to come up with a useful and descriptive option name that's not horribly long ... that's a challenge.   Something like handleRequestsLocally may be too generic, but it's a lot shorter than handleShardRequestsLocallyIfPossible! ",
            "id": "comment-14245538"
        },
        {
            "date": "2014-12-13T22:02:49+0000",
            "author": "Ayon Sinha",
            "content": "Our clients actually do use CloudSolrServer (LB SolrJ client). Is there something we should be worrying about there? We are under the impression that the Zk aware CloudSolrServer is doing a round-robin load balancing sending query requests.\n\nWe only intend to 'preferLocalShards' on the Solr node side only.\n\nBTW, how is the name 'preferLocalShards' ? ",
            "id": "comment-14245587"
        },
        {
            "date": "2014-12-13T22:56:59+0000",
            "author": "Shawn Heisey",
            "content": "CloudSolrServer does load balance, so you do not need an external load balancer.  Internally, it uses changes in the zookeeper clusterstate to add and remove URLs on an instance of LBHttpSolrServer, which in turn uses HttpSolrServer for each of those URLs.\n\nhttps://lucene.apache.org/solr/4_10_2/solr-solrj/org/apache/solr/client/solrj/impl/LBHttpSolrServer.html\n\nThe name preferLocalShards is perfect ... and I think a good case can be made for CloudSolrServer using this for queries (probably via a query URL parameter) by default. ",
            "id": "comment-14245665"
        },
        {
            "date": "2014-12-13T23:01:38+0000",
            "author": "Shawn Heisey",
            "content": "we might even be able to shorten the parameter name to preferLocal, but that will require some further thought.  I'd hate to have the shorter version be in use when another preferLocalXXX requirement comes up. ",
            "id": "comment-14245667"
        },
        {
            "date": "2014-12-14T21:13:43+0000",
            "author": "Shawn Heisey",
            "content": "A slightly better choice might be preferLocalReplicas ... but Shards is pretty good too. ",
            "id": "comment-14246130"
        },
        {
            "date": "2014-12-17T03:52:29+0000",
            "author": "Sachin Goyal",
            "content": "Attaching a patch for this ticket.\n\nThe patch creates an option preferLocalShards in solrconfig.xml and in the query request params (giving more preference to the one in the query).\n\nIf this option is set, HttpShardHandler.preferCurrentHostForDistributedReq() tries to find a local URL and puts that URL as the first one in the list of URLs sent to LBHttpSolrServer. This ensures that the current host's cores will be given preference for distributed queries.\n\nOther important function is ResponseBuilder.findCurrentHostAddress() which tries to find the current host's URL by searching for current core's name in the list of shards. The URL found by this function is used by the HttpShardHandle's function above.\n\nDefault value of the option is kept as 'false' to ensure normal behavior. ",
            "id": "comment-14249429"
        },
        {
            "date": "2015-02-03T20:34:33+0000",
            "author": "Timothy Potter",
            "content": "Sachin Goyal Thanks for the patch! I'm working to get it to a committable state.\n\nI don't think adding preferLocalShards as a collection-level setting (in SolrConfig) adds much value here. If an operator wants to enforce that query parameter for all requests, they can use the built-in support for defaults or invariants on the appropriate query request handler, e.g. to make this the default on the /select handler, you could do:\n\n\n  <requestHandler name=\"/select\" class=\"solr.SearchHandler\">\n     <lst name=\"defaults\">\n       <str name=\"echoParams\">explicit</str>\n       <int name=\"rows\">10</int>\n       <bool name=\"preferLocalShards\">true</bool>\n       ...\n\n\n\nBoth approaches require some config changes in solrconfig.xml, but the latter (my suggestion) avoids adding new code / config settings. That said, please let me know if you think there's another reason to have this as an explicit setting in solrconfig.xml.\n\nAlso, all the code in findCurrentHostAddress can simply be replaced by ZkController.getBaseUrl() when needed. ",
            "id": "comment-14303922"
        },
        {
            "date": "2015-02-03T21:20:41+0000",
            "author": "Sachin Goyal",
            "content": "Timothy Potter, I do not feel very strongly about the configuration option in solrconfig.xml\nI kept it here only because specifying a global option looked simpler to use.\n\nI will try the ZkController.getBaseUrl() and update the patch shortly with the above suggestions.\n\nThank you for reviewing. ",
            "id": "comment-14304014"
        },
        {
            "date": "2015-02-03T21:28:04+0000",
            "author": "Timothy Potter",
            "content": "Awesome - btw ... in case you haven't seen this before, it's a little cumbersome to get at the ZkController from the req object, something like:\n\n\nreq.getCore().getCoreDescriptor().getCoreContainer().getZkController().getBaseUrl()\n\n ",
            "id": "comment-14304033"
        },
        {
            "date": "2015-02-03T22:25:07+0000",
            "author": "Sachin Goyal",
            "content": "Oh great. Thanks for saving me a search for the ZkController  ",
            "id": "comment-14304149"
        },
        {
            "date": "2015-02-03T23:33:03+0000",
            "author": "Sachin Goyal",
            "content": "Timothy Potter, here is a new patch with the above comments incorporated.\nI have checked that \n\nreq.getCore().getCoreDescriptor().getCoreContainer().getZkController().getBaseUrl()\n\n works well and so \n\nResponseBuilder. findCurrentHostAddress()\n\n is no longer required.\n\nConfiguration change is also done. ",
            "id": "comment-14304309"
        },
        {
            "date": "2015-02-05T16:40:37+0000",
            "author": "Timothy Potter",
            "content": "Thanks for the updated patch. Only thing we need now is a good unit test. I can take a stab at that over the next few days. ",
            "id": "comment-14307520"
        },
        {
            "date": "2015-02-09T21:18:24+0000",
            "author": "Sachin Goyal",
            "content": "Thanks Timothy Potter.\nIf you can point me to some existing test-case from where I can see the creation of multiple nodes' cluster and running updates/queries on the same, then I can help with unit test creation. ",
            "id": "comment-14312895"
        },
        {
            "date": "2015-02-11T00:24:36+0000",
            "author": "Sachin Goyal",
            "content": "Timothy Potter, I have included a unit-test in the new patch.\n\nThis tests that response is received from local cores only when `preferLocalShards` is set to true in the query. ",
            "id": "comment-14315259"
        },
        {
            "date": "2015-02-11T18:16:22+0000",
            "author": "Timothy Potter",
            "content": "Sachin Goyal It seems like your latest patch was created / tested against branch4x vs. trunk? It's better to work against trunk for new features and then we'll back-port the changes as needed. I went ahead and migrated your patch to work with trunk and cleaned up a few places in the code. Overall looking good! ",
            "id": "comment-14316692"
        },
        {
            "date": "2015-02-11T18:17:45+0000",
            "author": "Timothy Potter",
            "content": "Also, I don't think we need to include this parameter in all of the configs, as we're trying to get away from bloated configs. So I changed the patch to just include in the sample techproducts configs. We'll also need to document this parameter in the Solr reference guide. ",
            "id": "comment-14316697"
        },
        {
            "date": "2015-02-11T19:05:04+0000",
            "author": "Sachin Goyal",
            "content": "Thank you Timothy Potter.\nPlease let me know how we can get this committed into the trunk and I can edit the Solr reference guide.\nI would also like to back-port this into the 5x branch. ",
            "id": "comment-14316779"
        },
        {
            "date": "2015-02-13T22:13:01+0000",
            "author": "Timothy Potter",
            "content": "Working on committing this now. ",
            "id": "comment-14320851"
        },
        {
            "date": "2015-02-14T02:40:07+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1659748 from Timothy Potter in branch 'dev/trunk'\n[ https://svn.apache.org/r1659748 ]\n\nSOLR-6832: Queries be served locally rather than being forwarded to another replica ",
            "id": "comment-14321177"
        },
        {
            "date": "2015-02-14T03:06:10+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1659750 from Timothy Potter in branch 'dev/branches/branch_5x'\n[ https://svn.apache.org/r1659750 ]\n\nSOLR-6832: Queries be served locally rather than being forwarded to another replica ",
            "id": "comment-14321192"
        },
        {
            "date": "2015-02-14T05:30:29+0000",
            "author": "Sachin Goyal",
            "content": "Thank you Timothy Potter! ",
            "id": "comment-14321249"
        },
        {
            "date": "2015-02-26T03:14:26+0000",
            "author": "Otis Gospodnetic",
            "content": "The performance gain increases if coresPerMachine is > 1 and a single JVM has cores from 'k' shards.\n\nEver managed to measure how much this feature helps in various scenarios?\n\nFor a distributed query, the request is always sent to all the shards even if the originating SolrCore (handling the original distributed query) is a replica of one of the shards.  If the original Solr-Core can check itself before sending http requests for any shard, we can probably save some network hopping and gain some performance.\n\nThis sounds as like it saves only a N local calls out of M, where M > N, N is the number of local replicas that could be queried locally, and M is the total number of primary shards in the cluster that are to be queries.  Is this correct?\n\nSo say there are 20 shards spread evenly over 20 nodes (i.e., 1 shard per node) and a query request comes in, the node that got the request will query send 19 requests to the remaining 19 nodes and thus save just one network trip by querying a local shard?  I must be missing something... ",
            "id": "comment-14337776"
        },
        {
            "date": "2015-02-26T03:35:33+0000",
            "author": "Ayon Sinha",
            "content": "@Otis, you are correct. This helps only where there is over-sharding. And in our particular scenario where we sharded to get better CPU core utilization and write speeds based on Tim's experiments with over-sharding. Since all queries were send to other nodes, we were getting hit with distributed deadlocks more often when one or more nodes were slow/overloaded.\nSo this patch is a slight optimization and a reduction of likelihood of getting bogged down by other slow nodes when the parent query node has the core. ",
            "id": "comment-14337800"
        },
        {
            "date": "2015-02-26T03:51:49+0000",
            "author": "Otis Gospodnetic",
            "content": "Hmmmm.... didn't examine the patch or tried this functionality, but based on your description... here are some comments.\n\nThis helps only where there is over-sharding.\n\nThat in itself should be avoided whenever possible in my experience. Overhead around memory and communication during querying.  Could be related to your deadlocks.  Or maybe you do a ton more writes so distributing writes across all nodes is worth the query-time overhead of over-sharding?\n\nSince all queries were send to other nodes, we were getting hit with distributed deadlocks more often when one or more nodes were slow/overloaded.\n\nHmmmm... if that is truly happening, then isn't that a separate issue to be fixed?\n\nSo this patch is a slight optimization and a reduction of likelihood of getting bogged down by other slow nodes when the parent query node has the core.\n\nBut VERY slight, right? (hence my Q about whether you've quantified the improvement from this patch)\n\nIntuitively, querying the local data makes sense - why would one not do that if the data is right there.  I just wonder how much you really benefit if you are saving just 1 (or very small) number of network calls in request that ends up dispatching NN requests to NN other nodes in the cluster. ",
            "id": "comment-14337817"
        },
        {
            "date": "2015-02-26T04:48:38+0000",
            "author": "Ayon Sinha",
            "content": "Actually, in our experience, network has been the most flaky piece. So any network hop saved is a big deal.\n\nAnd again you are right that the root cause (first domino) of the distributed deadlock is yet to be identified. What we see is when 1 machine in the cluster goes for a GC pause or traffic spike, it brings down all the other machines be quickly. The slow machine currently does not tell ZK that its struggling and hence all other nodes keep sending it queries. This is being addressed in another JIRA.\n\nThis particular patch buys us some time. ",
            "id": "comment-14337866"
        },
        {
            "date": "2015-04-15T00:30:15+0000",
            "author": "Timothy Potter",
            "content": "Bulk close after 5.1 release ",
            "id": "comment-14495246"
        },
        {
            "date": "2015-06-09T01:54:44+0000",
            "author": "Sachin Goyal",
            "content": "https://issues.apache.org/jira/browse/SOLR-7121 is a patch to address the other part of this problem.\nIt helps nodes become aware of their slowness and tell the ZK that they should be moved out of the network for a while.\nWhen their health has recovered, the nodes automatically request the ZK to be joined back in the cluster.\n\nThese two patches have resulted in making our cluster stable, though we have yet to quantify by how much (Quantification is not really a priority right now given that we will need to compare the cluster with an un-patched cluster and then put load on them to bring them down etc.) ",
            "id": "comment-14578181"
        }
    ]
}