{
    "id": "SOLR-11372",
    "title": "enable refinement testing in TestCloudJSONFacetJoinDomain",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [],
        "type": "Test",
        "fix_versions": [
            "7.1"
        ],
        "affect_versions": "None",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "This test has great random tests that ensure that the count returned for a bucket matches the number of documents returned from an equivalent filter.  We should enable randomly testing smaller limits in conjunction with refinement to ensure we still get accurate counts for buckets that are returned.",
    "attachments": {
        "SOLR-11372.patch": "https://issues.apache.org/jira/secure/attachment/12887984/SOLR-11372.patch",
        "SOLR-11372_fixup.patch": "https://issues.apache.org/jira/secure/attachment/12890195/SOLR-11372_fixup.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2017-09-19T21:14:16+0000",
            "content": "this should be fairly straight forward, but I would suggest doing it in stages.....\n\n1) replace the current FACET_LIMIT = 1 + ... constant with a randomized value that is sometimes more/less then the #unique values, and add the refine param to every generated facet.\n\n2) Assuming that works under beasting for a but and no obvious problems jump out, we can work dowards increase the randomization & edge cases caught by starting with some refactoring...\n\n\n\tadd a variable the facet modeling class to support a unique limit for each facet - default to using the global FACET_LIMIT\n\t\n\t\tupdate the json serialization to add refine:true if and only if the limit specified is < #unique values\n\t\n\t\n\n\n\n3) once that refactoring is vetted, then...\n\n\n\tthe code that generates the randomized facet options can be updated to randomize the limit as well\n\tthe refine param can also be randomized a bit more:\n\t\n\t\tif the limit is > #unique values we can randomly pick any refine value (true, false, or unspecified) and it should still produce valid results\n\t\tif the random limit is < #unique values, we can also randomly pick a refine value \u2013 and if we pick unspecified or false, setting the overrequest param > #unique values should also still make the test pass\n\t\tif (for any reason) we randomize refine=true we should be able to pick a random overrequest param < #unique values w/o causing test failures.\n\t\n\t\n\n ",
            "author": "Hoss Man",
            "id": "comment-16172349"
        },
        {
            "date": "2017-09-19T22:43:03+0000",
            "content": "Here's my current patch.\nrefinement seems to work (and the test fails often when I hardcode refine:false), so it's looking good.  I'm going to beast it a while though and see if anything pops out. ",
            "author": "Yonik Seeley",
            "id": "comment-16172463"
        },
        {
            "date": "2017-09-20T10:22:15+0000",
            "content": "Commit 288a414c756810228eb274a53e64829dc00b1876 in lucene-solr's branch refs/heads/master from Yonik Seeley\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=288a414 ]\n\nSOLR-11372: tests: add refine to TestCloudJSONFacetJoinDomain ",
            "author": "ASF subversion and git services",
            "id": "comment-16172985"
        },
        {
            "date": "2017-09-20T10:23:36+0000",
            "content": "Commit 8c969c5400a45152a6471408a545ebde95ab6959 in lucene-solr's branch refs/heads/branch_7x from Yonik Seeley\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=8c969c5 ]\n\nSOLR-11372: tests: add refine to TestCloudJSONFacetJoinDomain ",
            "author": "ASF subversion and git services",
            "id": "comment-16172986"
        },
        {
            "date": "2017-09-22T17:12:13+0000",
            "content": "Yonik Seeley: I'm sorry i didn't get a chance to review your patch sooner, but i'm -1 for the way you went about this ... you've introduced some scary bobby traps for anyone who might work on this test in the future...\n\n\n\tYou've changed the semantic meaning of \"FACET_LIMIT\" so that it no longer is the \"facet limit\" (or is even an upper bound on the limit because of a *2 you introduced??) w/o renaming the variable or adding any sort of comment to clarify/reduce confusion in the future.\n\t\n\t\teven knowing this test very well, I can't make heads or tails of what your intended purpose of FACET_LIMIT is after your changes \u2013 my best guess is that it should be completley removed and usages should be replaced with UNIQUE_FIELD_VALS?\n\t\n\t\n\tyou've introduced hte new randomized refine/limit/overrequest logic directly into the TermFacet.toJSONFacetParamValue() method \u2013 instead of into the TermFacet constructor along with all othe randomized state.  This means that for a given TermFacet object (or for 2 otherwise identical objects), two calls to toJSONFacetParamValue() will now produce completely different results.\n\t\n\t\tIf nothing else, this means that things like \"testBespoke()\" no longer produce consistent reproducible facets \u2013 whch defeats the entire point, and if any bugs get introduced in refinement in the future, will make them that much harder to track down.\n\t\n\t\n\n ",
            "author": "Hoss Man",
            "id": "comment-16176733"
        },
        {
            "date": "2017-09-22T17:51:31+0000",
            "content": "Yep, I clearly didn't make time to understand the larger test architecture - adding limit/refine/overrequest params to TermFacet makes much more sense (I just searched for the string \"limit:\" and went from there).  It may be a few weeks before I'm able to refactor things (I've been pulled into something else high priority), but feel free to refactor yourself or revert in the meantime. ",
            "author": "Yonik Seeley",
            "id": "comment-16176808"
        },
        {
            "date": "2017-10-03T17:55:57+0000",
            "content": "Yonik Seeley: here's a patch to fix up the test changes \u2013 i'm beasting now, will plan on committing tomorrow unless i find any failures or you see any obvious problems. ",
            "author": "Hoss Man",
            "id": "comment-16190053"
        },
        {
            "date": "2017-10-03T20:50:05+0000",
            "content": "whoops.  updated patch to fix silly mistake: i had \"refactored\" a number into a static constant but then forgot to use that constant in the original code ",
            "author": "Hoss Man",
            "id": "comment-16190331"
        },
        {
            "date": "2017-10-04T16:56:53+0000",
            "content": "Commit 85bd0afaf816e36969f6715805ce2d4e4907f0de in lucene-solr's branch refs/heads/branch_7x from Chris Hostetter\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=85bd0af ]\n\nSOLR-11372: addemdum, refactor refinement randomization to be reproducible when re-using the same TermFacet instance\n\n(cherry picked from commit b10eb1172a76ad877dece87893fec80895562968) ",
            "author": "ASF subversion and git services",
            "id": "comment-16191561"
        },
        {
            "date": "2017-10-04T16:56:55+0000",
            "content": "Commit b10eb1172a76ad877dece87893fec80895562968 in lucene-solr's branch refs/heads/master from Chris Hostetter\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=b10eb11 ]\n\nSOLR-11372: addemdum, refactor refinement randomization to be reproducible when re-using the same TermFacet instance ",
            "author": "ASF subversion and git services",
            "id": "comment-16191562"
        },
        {
            "date": "2017-10-04T17:24:56+0000",
            "content": "Thanks Hoss, I really didn't mean to push the work off on you, but I'm still tied down with something else for the next couple of weeks probably. ",
            "author": "Yonik Seeley",
            "id": "comment-16191614"
        },
        {
            "date": "2017-10-04T17:29:19+0000",
            "content": "no worries, i just didn't want it to slip through the cracks \u2013 especially since the work varun is doing in SOLR-11391 is going to involve more updates to this test.  I wanted to ensure he had a solid foundation to build on. ",
            "author": "Hoss Man",
            "id": "comment-16191626"
        },
        {
            "date": "2017-10-17T11:04:15+0000",
            "content": "Bulk close after 7.1.0 release ",
            "author": "Shalin Shekhar Mangar",
            "id": "comment-16207446"
        }
    ]
}