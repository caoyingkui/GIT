{
    "id": "LUCENE-5357",
    "title": "Upgrade StandardTokenizer & co to latest unicode rules",
    "details": {
        "type": "New Feature",
        "priority": "Major",
        "labels": "",
        "resolution": "Fixed",
        "components": [
            "modules/analysis"
        ],
        "affect_versions": "None",
        "status": "Closed",
        "fix_versions": [
            "4.7",
            "6.0"
        ]
    },
    "description": "besides any change in data, the rules have also changed (regional indicators, better handling for hebrew, etc)",
    "attachments": {
        "LUCENE-5357.patch": "https://issues.apache.org/jira/secure/attachment/12617249/LUCENE-5357.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "id": "comment-13840624",
            "author": "Steve Rowe",
            "content": "Tasks include:\n\n\n\tUpdate the TLDs acceptable in URLs and Emails (for UAX29URLEmailTokenizer) from the latest IANA Root Zone Database, using ant gen-tlds.  Test data files referring to obsolete TLDs will need to be updated to use current TLDs: ((email.addresses,urls).from.)random.text.with.(email.address,urls).txt.\n\tUpdate the icu module's GenerateJFlexSupplementaryMacros.java to include supplementary character additions to JFlex grammars for new character classes [:WordBreak=Single_Quote:], [:WordBreak=Double_Quote:], [:WordBreak=Hebrew_Letter:] and [:WordBreak=Regional_Indicator:].\n\tUpdate the JFlex grammars to Unicode 6.3\n\t\n\t\tChange the version in the %unicode directive in the grammar: %unicode 6.1 -> %unicode 6.3\n\t\tChange all JFlex grammars that use \". | <newline>\" to mean \"any character\" to instead use [^], since JFlex's \".\" now excludes all Unicode newline chars, rather than just n, to comply with Unicode Regular Expressions standard UTS#30.\n\t\tUpgrade the UAX#29-based grammars to the Unicode 6.3 word break rules, in StandardTokenizerImpl.jflex and UAX29URLEmailTokenizer.jflex.\n\t\n\t\n\tRegenerate the JFlex scanners in lucene/analysis/common/ via ant jflex.\n\tTest the new scanners against the Unicode 6.3 word break test data\n\t\n\t\tUpdate generateJavaUnicodeWordBreakTest.pl to handle above-BMP characters in the Unicode character database's ucd/auxiliary/WordBreakTest.txt (previous Unicode versions included only BMP characters in that file).\n\t\tUsing generateJavaUnicodeWordBreakTest.pl, generate WordBreakTestUnicode_6_3_0.java under modules/analysis/common/src/test/org/apache/lucene/analysis/core/.\n\t\tUpdate TestStandardAnalyzer.java and TestUAX29URLEmailTokenizer.java to invoke WordBreakTestUnicode_6_3_0 rather than WordBreakTestUnicode_6_1_0.\n\t\tRemove WordBreakTestUnicode_6_1_0.java.\n\t\n\t\n\n\n\nAdditional task for the 4.x backport:\n\n\n\tVersion the JFlex grammars:\n\t\n\t\tCopy the current implementations to *Impl40 (where 40=>4.0 is the version in which the Unicode 6.1 versions of these scanners were introduced.\n\t\tCause the versioning tokenizer wrappers to instantiate this version when the Version c-tor param is in the range 4.0 to 4.6.\n\t\tChange the specified Unicode version in the non-versioned JFlex grammars from 6.1 to 6.3.\n\t\n\t\n\n ",
            "date": "2013-12-05T22:04:42+0000"
        },
        {
            "id": "comment-13840654",
            "author": "Steve Rowe",
            "content": "Patch against trunk handling all above-described pre-4.x-backport tasks.\n\nAlso, I was able to get rid of the workarounds in lucene/analysis/common/build.xml removing the time stamp and the InputStream constructors from generated JFlex scanners, because JFlex itself has fixed these things. \n\nI think it's ready to go. ",
            "date": "2013-12-05T22:40:36+0000"
        },
        {
            "id": "comment-13840662",
            "author": "Uwe Schindler",
            "content": "because JFlex itself has fixed these things.\n\nHow about a release? It would be so great if it could stay in Maven and could be invoked via ivy-cachepath. ",
            "date": "2013-12-05T22:57:46+0000"
        },
        {
            "id": "comment-13840727",
            "author": "Steve Rowe",
            "content": "How about a release? \n\nI'm working on it, almost done. ",
            "date": "2013-12-06T00:17:32+0000"
        },
        {
            "id": "comment-13841411",
            "author": "ASF subversion and git services",
            "content": "Commit 1548595 from Steve Rowe in branch 'dev/trunk'\n[ https://svn.apache.org/r1548595 ]\n\nLUCENE-5357: Upgrade StandardTokenizer and UAX29URLEmailTokenizer to Unicode 6.3; update UAX29URLEmailTokenizer's recognized top level domains in URLs and Emails from the IANA Root Zone Database. ",
            "date": "2013-12-06T16:51:45+0000"
        },
        {
            "id": "comment-13841857",
            "author": "ASF subversion and git services",
            "content": "Commit 1548746 from Steve Rowe in branch 'dev/trunk'\n[ https://svn.apache.org/r1548746 ]\n\nLUCENE-5357: Sync small change (/Katakana/ => /Katakana [x ExtendNumLet] x Katakana/ in the <ALPHANUM> pattern) from UAX29URLEmailTokenizerImpl.jflex to StandardTokenizerImpl.jflex ",
            "date": "2013-12-06T23:11:14+0000"
        },
        {
            "id": "comment-13841918",
            "author": "ASF subversion and git services",
            "content": "Commit 1548762 from Steve Rowe in branch 'dev/branches/branch_4x'\n[ https://svn.apache.org/r1548762 ]\n\nLUCENE-5357: Upgrade StandardTokenizer and UAX29URLEmailTokenizer to Unicode 6.3; update UAX29URLEmailTokenizer's recognized top level domains in URLs and Emails from the IANA Root Zone Database; add std40/StandardTokenizerImpl40 and std40/UAX29URLEmailTokenizerImpl40, for backcompat from 4.0->4.6.  (merged trunk r1548595 and r1548746) ",
            "date": "2013-12-07T00:05:18+0000"
        },
        {
            "id": "comment-13841923",
            "author": "Steve Rowe",
            "content": "Committed to trunk and backported to branch_4x. ",
            "date": "2013-12-07T00:08:37+0000"
        },
        {
            "id": "comment-13841978",
            "author": "Robert Muir",
            "content": "This patch looks great! Thanks for taking care of this.\n\nI'm sorry I couldnt review it earlier, I had a power surge and had some connection difficulties the last few days. ",
            "date": "2013-12-07T01:14:48+0000"
        },
        {
            "id": "comment-13842206",
            "author": "Steve Rowe",
            "content": "No problem Robert, thanks for taking a look.\n\nAbout back-compat: none of the JFlex-based tokenizers on trunk have version-based behavior at this point, in contrast to branch_4x.  It could be argued that that was because all previous back-compat version were for 3.X, but this issue introduced a 4.0 version, which puts it within the version X-1 window for trunk/5.0.  Should I forward-port the 4.0 back-compat stuff from branch_4x for StandardTokenizer and UAX29URLEmailTokenizer?  There are other analysis components on trunk that do different things based on version, so clearly the practice has not been abandoned on trunk. ",
            "date": "2013-12-07T13:02:29+0000"
        },
        {
            "id": "comment-13842265",
            "author": "Robert Muir",
            "content": "\nAbout back-compat: none of the JFlex-based tokenizers on trunk have version-based behavior at this point, in contrast to branch_4x\n\nI would love if all these constants/parameters were completely removed in trunk. if you look at the mailing lists, its obvious that users dont even understand it at all. I dont know how index back compat got perverted into such a thing that made all the analysis apis ugly and overcomplicated.\n\nThis stuff all hurts the project far more than any benefit it brings to the rare few that understand it. I think it should be removed everywhere. ",
            "date": "2013-12-07T17:06:48+0000"
        }
    ]
}