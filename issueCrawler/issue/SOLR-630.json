{
    "id": "SOLR-630",
    "title": "Spellchecker should not be case-sensitive and should be stopwords-aware",
    "details": {
        "affect_versions": "None",
        "status": "Resolved",
        "fix_versions": [
            "1.5"
        ],
        "components": [
            "spellchecker"
        ],
        "type": "Bug",
        "priority": "Minor",
        "labels": "",
        "resolution": "Invalid"
    },
    "description": "Here are 2 more bugs:\n\n1)\nSearch for:\n  united states of America\nSuggests:\n united states oft America\n\nIt looks like the SC doesn't check stopwords, and \"of\" is a stopword.  Thus, it does not exist in the index,\nbut \"oft\" does, so SC suggests \"oft\" and thinks \"of\" is misspelled.  I think the SC component should check the list of\nstopwords, too, no?\n\n2)\nSearch for:\n united states of America\nSuggests:\n united states oftAmericaa\n\nThe of->oft is described above.  But note how SC suggested America->Americaa, but it didn't do that for \"america\".\nThis looks like case-sensitivity problem.  Shouldn't the SC be case-insensitive?\n\nI can't produce a patch now (no src handy), so I'm hoping Grant or somebody else can do it based on this report.",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "author": "Grant Ingersoll",
            "id": "comment-12620046",
            "date": "2008-08-05T21:19:24+0000",
            "content": "Not major. "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12621814",
            "date": "2008-08-12T13:29:32+0000",
            "content": "Doesn't seem to be anyone taking this up, so marking it as 1.4. "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12674125",
            "date": "2009-02-17T07:29:27+0000",
            "content": "Marked for 1.5 "
        },
        {
            "author": "Alex Baranau",
            "id": "comment-12744860",
            "date": "2009-08-19T03:41:16+0000",
            "content": "I would propose to close this bug.\n\n1) of->oft\n  Whether stop words are omitted or not depends on:\n    a. If \"q\" parameter is used, then \"queryAnalyzerFieldType\" parameter is used to determine the analyzer for the query. If \"queryAnalyzerFieldType\" is not specified, then WhitespaceTokenizer is used.\n    b. If \"spellcheck.q\" parameter is used, then query analyzer of the spellchecker field is used.\n\n2) America->Americaa, america->[none]\n  I couldn't reproduce that. The results are the same as for \"America\" as for \"america\". However, spellchecker is really case-sensitive. For example, if there is \"AmErIcAa\" in the spellchecker index then this suggestion won't appear neither for \"America\" nor for \"america\", but would appear for \"AmErIcA\".\n  The reason, why America->Americaa, america->Americaa lies in the n-gram method which is used in lucene spellchecker: for America and america the same grams are defined, the only difference is \"startN\" gram. Actually there is still might be a difference in the results: the method works so that it boosts the relevance of the suggestion if the first N letters of it are the same as in the word under spellcheck.\n\n  I'm not sure whether case-sensitiveness(is it a word?) is a bug or not. Anyway, finding suggestions as well as creating the index for spellchecker is delegated to the Lucene SpellChecker, so this is Lucene issue, not Solr.\n\nP.S. I believe that one can avoid case-sensitive issue by configuring properly the analyzers (e.g. for the spellchecker field). "
        },
        {
            "author": "Hoss Man",
            "id": "comment-12747724",
            "date": "2009-08-26T00:55:49+0000",
            "content": "P.S. I believe that one can avoid case-sensitive issue by configuring properly the analyzers (e.g. for the spellchecker field).\n\nyeah ... without a concrete example of what kind of config can produce these bugs, my gut assumption is that with some config for spellchecker this problem doesn't exist.\n\nat which point this bug really just becomes an issue if our current example/documentation isn't advocating the best solution.\n\n "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12790676",
            "date": "2009-12-15T11:20:40+0000",
            "content": "I don't think this is a problem. As Alex noted, it is all a matter of configuring your analyzers and spell checker correctly. "
        }
    ]
}