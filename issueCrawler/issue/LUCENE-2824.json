{
    "id": "LUCENE-2824",
    "title": "optimizations for bufferedindexinput",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [],
        "type": "Improvement",
        "fix_versions": [
            "3.1",
            "4.0-ALPHA"
        ],
        "affect_versions": "3.1,                                            4.0-ALPHA",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "along the same lines as LUCENE-2816:\n\n\tthe readVInt/readVLong/readShort/readInt/readLong are not optimal here since they defer to readByte. for example this means checking the buffer's bounds per-byte in readVint instead of per-vint.\n\tits an easy win to speed this up, even for the vint case: its essentially always faster, the only slower case is 1024 single-byte vints in a row, in this case we would do a single extra bounds check (1025 instead of 1024)",
    "attachments": {
        "LUCENE-2824.patch": "https://issues.apache.org/jira/secure/attachment/12466568/LUCENE-2824.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2010-12-19T11:46:21+0000",
            "content": "here's the patch. i reverted my previous backwards break for the no-payloads optimization since this is actually faster overall.\n\nHere's standard codec (trunk). I've run this benchmark about 5 times to be sure.\n\n\n\nQuery\nQPS trunk\nQPS patch\nPct diff\n\n\nuni*\n11.41\n11.36\n-0.5%\n\n\nunit*\n20.57\n20.47\n-0.5%\n\n\nun*d\n31.56\n31.63\n0.2%\n\n\nunited~2.0\n1.66\n1.67\n0.5%\n\n\nunit~1.0\n5.21\n5.23\n0.5%\n\n\nunit~2.0\n5.09\n5.14\n0.9%\n\n\nunited~1.0\n7.61\n7.69\n1.0%\n\n\nunit state\n7.11\n7.21\n1.3%\n\n\nspanNear([unit, state], 10, true)\n2.67\n2.72\n2.0%\n\n\nstate\n25.09\n25.61\n2.1%\n\n\n+nebraska +state\n69.29\n70.84\n2.2%\n\n\nu*d\n8.44\n8.71\n3.2%\n\n\n\"unit state\"\n4.98\n5.17\n3.8%\n\n\n+unit +state\n7.34\n7.70\n4.8%\n\n\nspanFirst(unit, 5)\n10.27\n11.35\n10.5%\n\n\n\n\n\nthe optimization is more important though for the methods like readInt (15% faster in my tests) ",
            "author": "Robert Muir",
            "id": "comment-12972963"
        },
        {
            "date": "2010-12-19T11:52:37+0000",
            "content": "+1, Thats a good idea overall: Always optimize the general case (buffer is large enough), and fallback if not ",
            "author": "Uwe Schindler",
            "id": "comment-12972965"
        },
        {
            "date": "2010-12-19T11:54:25+0000",
            "content": "sorry my math was off, the worst case is 4 extra checks (1028 total?)... but in general the buffer size default (1024)\nis large enough that this helps. ",
            "author": "Robert Muir",
            "id": "comment-12972966"
        },
        {
            "date": "2010-12-19T11:58:11+0000",
            "content": "Did you also try to catch out of bounds exceptions instead of doing the bounds checks in the current patch? ",
            "author": "Paul Elschot",
            "id": "comment-12972967"
        },
        {
            "date": "2010-12-19T12:03:21+0000",
            "content": "Did you also try to catch out of bounds exceptions instead of doing the bounds checks in the current patch?\n\nPaul, how can we do this? In the mmap case we can because the mmap getXXX will throw the bufferunderflow\nand not actually read anything if there isn't enough bytes.\n\nBut in this case I don't see how we can re-arrange the code to safely do this? \nif you know, please let us know as I think this would be better too. ",
            "author": "Robert Muir",
            "id": "comment-12972968"
        },
        {
            "date": "2010-12-19T12:04:37+0000",
            "content": "For the MMap case with veeeery large arrays, the cost of exception instantiation with stack trace is really small. I think for small buffer sizes like 1024 the overhead would be immense. But we should check this \n\nAnother place where the checks were omitted and instead AIOOBE is catched is FieldCacheRangeFilter. This really helps there! But in that case FieldCache is always large  ",
            "author": "Uwe Schindler",
            "id": "comment-12972969"
        },
        {
            "date": "2010-12-19T12:13:17+0000",
            "content": "oh, i think i see your idea Paul... so in the special case when we refill() at the end of the file and we populate\nless than the buffers length, we just have to copy to a shorter array so this will work? ",
            "author": "Robert Muir",
            "id": "comment-12972971"
        },
        {
            "date": "2010-12-19T12:13:31+0000",
            "content": "Using bounds check would be possible when the array size equals the buffered size. But indeed this need not normally be the case.\nI'll take a closer look, it might be worthwhile to use a smaller array object when there is no more data available. ",
            "author": "Paul Elschot",
            "id": "comment-12972972"
        },
        {
            "date": "2010-12-19T12:15:03+0000",
            "content": "You are obviously more familiar with the code than me  ",
            "author": "Paul Elschot",
            "id": "comment-12972973"
        },
        {
            "date": "2010-12-19T12:24:05+0000",
            "content": "well its slightly trickier to do it this way (e.g. slimming down the array in the very special case but restoring the fully sized one later in a future refill(), but potentially worthwhile... we should at least benchmark the exception idea, and see how it goes. ",
            "author": "Robert Muir",
            "id": "comment-12972974"
        },
        {
            "date": "2010-12-19T12:26:18+0000",
            "content": "And as said in my above comment, for buffer sizes like 1024 or in that area (even for 16384 or like that), the overhead of throwing the AIOOBE would be much higher (as the JVM needs to generate stack trace!!!). I would simply don't even think about that g.\n\nFor MMap the idea is fine because we normally have \"buffer\" sizes of 2^31th, where the AIOOBE / BufferUnderflowEx is veeeeeeeeeeeery seldom. ",
            "author": "Uwe Schindler",
            "id": "comment-12972975"
        },
        {
            "date": "2010-12-19T12:42:44+0000",
            "content": "It's too long ago that I had to deal with this tradeoff myself, so I'm taking a look here: http://www.javaspecialists.eu/archive/Issue187.html\n\"Cost of causing exceptions\" (2010-08-31). ",
            "author": "Paul Elschot",
            "id": "comment-12972977"
        },
        {
            "date": "2010-12-19T12:46:15+0000",
            "content": "\nAnd as said in my above comment, for buffer sizes like 1024 or in that area (even for 16384 or like that), the overhead of throwing the AIOOBE would be much higher (as the JVM needs to generate stack trace!!!). I would simply don't even think about that g.\n\nOk, i looked into this and I think I agree with Uwe.\n\nI'm concerned about the JRE-specifics here too (cost of an exception, for example I ran all the tests on IKVM jvm the other day, \nand a wierd one failed due to this:\nhttp://weblog.ikvm.net/CommentView.aspx?guid=062e4506-89c4-488e-9104-59c1ec80007b\n\nSo, I think the optimization here (reducing checks on average) is safe, but I'm worried about going the exception route with\nsuch a small buffer... even if we could tweak it out to perform better on a sun JRE, ",
            "author": "Robert Muir",
            "id": "comment-12972980"
        },
        {
            "date": "2010-12-19T13:07:34+0000",
            "content": "In case I understood the javaspecialists article correctly, it could be faster to use AIOOBE but only when -XX:-OmitStackTraceInFastThrow is not used in the sun/oracle jvm. For the first few hundreds of exceptions from the same piece of code however it would always be slower.\n\nSince this depends on the JVM I'd rather keep the explicit bounds check in the code for now, and may be open a separate issue when it turns out to be faster to use AIOOBE. ",
            "author": "Paul Elschot",
            "id": "comment-12972981"
        },
        {
            "date": "2010-12-20T12:11:33+0000",
            "content": "Paul I agree with your sentiments, for this issue I'd like to stick with this patch as just a small step (reducing bounds checks on average).\n\nIn general, I think its probably the case we can improve our i/o (especially BufferedIndexInput) to be more efficient with\nthe int block codecs, don't hesitate to open more issues if there are ideas, I've definitely been testing a lot of crazy things, but\nthe others didn't pan out \n ",
            "author": "Robert Muir",
            "id": "comment-12973177"
        },
        {
            "date": "2010-12-21T16:20:45+0000",
            "content": "Do these performance comparison tests (posted on 19 December above) have a basic verification that each query returns the same result, for example a CRC on the matching docids and perhaps also a CRC on the score values? ",
            "author": "Paul Elschot",
            "id": "comment-12973735"
        },
        {
            "date": "2010-12-21T17:34:11+0000",
            "content": "\nDo these performance comparison tests (posted on 19 December above) have a basic verification that each query returns the same result, for example a CRC on the matching docids and perhaps also a CRC on the score values?\n\nYes, the performance benchmark I used originally came from Mike, it builds on contrib/benchmark, you can see it here: http://code.google.com/p/luceneutil/\n\nIt verifies as you suggested, and in fact has found bugs before that our tests don't find... which frustrates me about our unit tests! ",
            "author": "Robert Muir",
            "id": "comment-12973783"
        },
        {
            "date": "2011-01-20T18:40:45+0000",
            "content": "I'm seeing excellent gains w/ this patch, on Linux 64bit Java 6 NIOFSDir:\n\n\n\n\nQuery\nQPS clean\nQPS robspec\nPct diff\n\n\nspanFirst(unit, 5)\n16.67\n15.62\n-6.3%\n\n\n\"unit state\"\n8.04\n7.87\n-2.2%\n\n\nspanNear([unit, state], 10, true)\n4.31\n4.25\n-1.2%\n\n\n\"unit state\"~3\n4.85\n5.02\n3.6%\n\n\nunit state\n10.35\n10.94\n5.7%\n\n\nunit~1.0\n9.60\n10.15\n5.7%\n\n\nunit~2.0\n9.35\n9.94\n6.3%\n\n\nunited~2.0\n3.30\n3.51\n6.4%\n\n\n+nebraska +state\n161.71\n174.23\n7.7%\n\n\n+unit +state\n11.20\n12.09\n8.0%\n\n\ndoctitle:.[Uu]nited.\n3.93\n4.25\n8.0%\n\n\nunited~1.0\n15.12\n16.39\n8.4%\n\n\nun*d\n49.33\n56.09\n13.7%\n\n\nu*d\n14.85\n16.97\n14.3%\n\n\nstate\n25.95\n30.12\n16.1%\n\n\nunit*\n22.72\n26.88\n18.3%\n\n\nuni*\n12.64\n15.20\n20.2%\n\n\ndoctimesecnum:[10000 TO 60000]\n8.42\n10.73\n27.4%\n\n\n\n\n\n+1 to commit. ",
            "author": "Michael McCandless",
            "id": "comment-12984326"
        },
        {
            "date": "2011-01-21T04:17:55+0000",
            "content": "Committed revision 1061619, 1061622 ",
            "author": "Robert Muir",
            "id": "comment-12984558"
        },
        {
            "date": "2011-03-30T15:50:15+0000",
            "content": "Bulk close for 3.1 ",
            "author": "Grant Ingersoll",
            "id": "comment-13013415"
        }
    ]
}