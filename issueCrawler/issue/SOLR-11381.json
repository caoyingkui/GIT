{
    "id": "SOLR-11381",
    "title": "HdfsDirectoryFactory throws NPE on cleanup because file system has been closed",
    "details": {
        "labels": "",
        "priority": "Trivial",
        "components": [
            "hdfs"
        ],
        "type": "Bug",
        "fix_versions": [
            "7.6",
            "master (8.0)"
        ],
        "affect_versions": "None",
        "resolution": "Unresolved",
        "status": "Open"
    },
    "description": "I saw this happening on tests related to autoscaling. The old directory clean up is triggered on core close in a separate thread. This can cause a race condition where the filesystem is closed before the cleanup starts running. Then a NPE is thrown and cleanup fails.\n\nFixing the NPE is simple but I think this is a real bug where old directories can be left around on HDFS. I don't know enough about HDFS to investigate further. Leaving it here for interested people to pitch in.\n\n\n105029 ERROR (OldIndexDirectoryCleanupThreadForCore-control_collection_shard1_replica_n1) [n:127.0.0.1:58542_ c:control_collection s:shard1 r:core_node2 x:control_collection_shard1_replica_n1] o.a.s.c.HdfsDirectoryFactory Error checking for old index directories to clean-up.\njava.io.IOException: Filesystem closed\n\tat org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:808)\n\tat org.apache.hadoop.hdfs.DFSClient.listPaths(DFSClient.java:2083)\n\tat org.apache.hadoop.hdfs.DFSClient.listPaths(DFSClient.java:2069)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem.listStatusInternal(DistributedFileSystem.java:791)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem.access$700(DistributedFileSystem.java:106)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem$18.doCall(DistributedFileSystem.java:853)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem$18.doCall(DistributedFileSystem.java:849)\n\tat org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem.listStatus(DistributedFileSystem.java:860)\n\tat org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1517)\n\tat org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1557)\n\tat org.apache.solr.core.HdfsDirectoryFactory.cleanupOldIndexDirectories(HdfsDirectoryFactory.java:540)\n\tat org.apache.solr.core.SolrCore.lambda$cleanupOldIndexDirectories$32(SolrCore.java:3019)\n\tat java.lang.Thread.run(Thread.java:745)\n105030 ERROR (OldIndexDirectoryCleanupThreadForCore-control_collection_shard1_replica_n1) [n:127.0.0.1:58542_ c:control_collection s:shard1 r:core_node2 x:control_collection_shard1_replica_n1] o.a.s.c.SolrCore Failed to cleanup old index directories for core control_collection_shard1_replica_n1\njava.lang.NullPointerException\n\tat org.apache.solr.core.HdfsDirectoryFactory.cleanupOldIndexDirectories(HdfsDirectoryFactory.java:558)\n\tat org.apache.solr.core.SolrCore.lambda$cleanupOldIndexDirectories$32(SolrCore.java:3019)\n\tat java.lang.Thread.run(Thread.java:745)",
    "attachments": {},
    "issue_links": {},
    "comments": []
}