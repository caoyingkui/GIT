{
    "id": "LUCENE-1192",
    "title": "FileNotFound exception on adding a RAMDirectory to an IndexWriter",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [],
        "type": "Bug",
        "fix_versions": [],
        "affect_versions": "2.3.1",
        "resolution": "Invalid",
        "status": "Closed"
    },
    "description": "Hi,\n\nI'm getting FileNotFoundException on adding RAMDirectory to an IndexWriter with following stack trace:\n\njava.io.FileNotFoundException: _8.fnm\n        at org.apache.lucene.store.RAMDirectory.openInput(RAMDirectory.java:234)\n        at org.apache.lucene.index.FieldInfos.<init>(FieldInfos.java:57)\n        at org.apache.lucene.index.SegmentReader.initialize(SegmentReader.java:298)\n        at org.apache.lucene.index.SegmentReader.get(SegmentReader.java:262)\n        at org.apache.lucene.index.SegmentReader.get(SegmentReader.java:221)\n        at org.apache.lucene.index.IndexWriter.mergeMiddle(IndexWriter.java:3099)\n        at org.apache.lucene.index.IndexWriter.merge(IndexWriter.java:2834)\n        at org.apache.lucene.index.IndexWriter.copyExternalSegments(IndexWriter.java:2263)\n        at org.apache.lucene.index.IndexWriter.addIndexesNoOptimize(IndexWriter.java:2238)\n\n\n\nSame code works fine with Lucene 2.2.0. Basically I'm trying to index a huge number of documents (~21mln) having following workflow:\n1. First documents are added to and index which use a RAMDirectory as a storage\n2. Once a given condition occurs RAM based index writer is flushed and his directory is being added to another index writer, which use a FSDirectory as a storage. \n\nSample code:\n\nIndexWriter mainIndexWriter = new IndexWriter(indexDir, new JapaneseAnalyzer(), true);\nIndexWriter ramIndexWriter = new IndexWriter(new RAMDirectory(), new JapaneseAnalyzer(), true);\nmainIndexWriter.setMergeFactor(10);\nmainIndexWriter.setUseCompoundFile(false);\nramIndexWriter.setUseCompoundFile(false);\n\n// Here some code for adding documents to RAM index writer\n...................................................................................................................\n// method where I'm flushing from memory to disk and getting exception\nramIndexWriter.flush();\nmainIndexWriter.addIndexesNoOptimize(new Directory[] {ramIndexWriter.getDirectory()});\nramIndexWriter.close();\nramIndexWriter = new IndexWriter(new RAMDirectory(), new JapaneseAnalyzer(), true);\nramIndexWriter.setUseCompoundFile(false);\nSystem.gc();\n\n\n\nI understand that I should be using new features of IndexWriter like flushing by RAM Usage, but wanna see if there any bugs in my case. Possible I'm facing issue described in LUCENE-1175, but need a confirmation on that.",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "date": "2008-02-26T11:09:42+0000",
            "content": "Updated details on environment ",
            "author": "Alex Falca",
            "id": "comment-12572425"
        },
        {
            "date": "2008-02-26T12:22:47+0000",
            "content": "\nThis actually isn't quite a valid use of Lucene's APIs, because the\nramIndexWriter is actively changing the files in the RAMDirectory.\n\nThis worked in past versions of Lucene because merges were done\nsynchronously.  Now, with background merges by default, a merge can\ncomplete and commit changes to the RAMDirectory while\naddIndexesNoOptimize is running.  The addIndexesNoOptimize method\nrequires a \"static\" Directory, where no writer is actively making\nchanges.\n\nThere are a few ways you could get this to work:\n\n\n\tSync all concurrent merges before calling addIndexesNoOptimize, by\n    calling ((ConcurrentMergeScheduler) ramIndexWriter.getMergeScheduler()).sync()\n\n\n\n\n\tSwitch back to SerialMergeScheduler\n\n\n\n\n\tClose the ramIndexWriter before passing its directory to\n    addIndexesNoOptimize.  In this case you need to separately hold\n    the underlying RAMDirectory since you can't call\n    IndexWriter.getDirectory after close.\n\n\n ",
            "author": "Michael McCandless",
            "id": "comment-12572449"
        },
        {
            "date": "2008-02-26T12:43:23+0000",
            "content": "Thanks for the explanations and proposed ways to solve issue I'll try one of them today. ",
            "author": "Alex Falca",
            "id": "comment-12572457"
        },
        {
            "date": "2008-02-26T14:33:09+0000",
            "content": "You're welcome! ",
            "author": "Michael McCandless",
            "id": "comment-12572495"
        },
        {
            "date": "2008-02-26T16:30:00+0000",
            "content": "Tried last option:\n\n\n\tClose the ramIndexWriter before passing its directory to\n      addIndexesNoOptimize. In this case you need to separately hold\n      the underlying RAMDirectory since you can't call\n      IndexWriter.getDirectory after close.\n\n\n\neverything works fine  Got a 2x increase in speed of indexing.\nThank you again!\nClosing ticket. ",
            "author": "Alex Falca",
            "id": "comment-12572548"
        }
    ]
}