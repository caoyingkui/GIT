{
    "id": "LUCENE-444",
    "title": "StandardTokenizer loses Korean characters",
    "details": {
        "labels": "",
        "priority": "Minor",
        "components": [
            "modules/analysis"
        ],
        "type": "Bug",
        "fix_versions": [
            "1.9"
        ],
        "affect_versions": "None",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "While using StandardAnalyzer, exp. StandardTokenizer with Korean text stream, StandardTokenizer ignores the Korean characters. This is because the definition of CJK token in StandardTokenizer.jj JavaCC file doesn't have enough range covering Korean syllables described in Unicode character map.\nThis patch adds one line of 0xAC00~0xD7AF, the Korean syllables range to the StandardTokenizer.jj code.",
    "attachments": {
        "StandardTokenizer_Korean.patch": "https://issues.apache.org/jira/secure/attachment/12314710/StandardTokenizer_Korean.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2005-10-04T23:28:34+0000",
            "content": "This patch adds one line of 0xAC00~0xD7AF, the Korean syllables range to the StandardTokenizer.jj code. ",
            "author": "Cheolgoo Kang",
            "id": "comment-12331274"
        },
        {
            "date": "2005-10-05T12:54:26+0000",
            "content": "Committed.  Thanks Cheolgoo. ",
            "author": "Otis Gospodnetic",
            "id": "comment-12331345"
        },
        {
            "date": "2005-10-05T19:40:50+0000",
            "content": "I'm closing this issue... but some unit tests would be nice to go along with this too, eventually  ",
            "author": "Erik Hatcher",
            "id": "comment-12331370"
        }
    ]
}