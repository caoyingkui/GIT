{
    "id": "LUCENE-3821",
    "title": "SloppyPhraseScorer sometimes misses documents that ExactPhraseScorer finds.",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [],
        "type": "Bug",
        "fix_versions": [],
        "affect_versions": "3.5,                                            4.0-ALPHA",
        "resolution": "Unresolved",
        "status": "Open"
    },
    "description": "The general bug is a case where a phrase with no slop is found,\nbut if you add slop its not.\n\nI committed a test today (TestSloppyPhraseQuery2) that actually triggers this case,\njenkins just hasn't had enough time to chew on it.\n\nant test -Dtestcase=TestSloppyPhraseQuery2 -Dtests.iter=100 is enough to make it fail on trunk or 3.x",
    "attachments": {
        "LUCENE-3821.patch": "https://issues.apache.org/jira/secure/attachment/12516965/LUCENE-3821.patch",
        "LUCENE-3821_test.patch": "https://issues.apache.org/jira/secure/attachment/12515841/LUCENE-3821_test.patch",
        "schema.xml": "https://issues.apache.org/jira/secure/attachment/12515833/schema.xml",
        "LUCENE-3821-SloppyDecays.patch": "https://issues.apache.org/jira/secure/attachment/12517297/LUCENE-3821-SloppyDecays.patch",
        "solrconfig-test.xml": "https://issues.apache.org/jira/secure/attachment/12515834/solrconfig-test.xml"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2012-02-23T22:52:03+0000",
            "content": "Here's Naomi's original description (moved from description section): including the queries, however I can't \nreproduce with just that phrase of the document (I tried, it passes).\n\nI think its a more complex bug in SloppyPhraseScorer... and I can reproduce similar behavior with another test.\n\n\nIn upgrading from Solr 1.4 to Solr 3.5, the following phrase searches stopped working in dismax:\n\"The Beatles as musicians : Revolver through the Anthology\"\n\"Color-blindness [print/digital]; its dangers and its detection\"\nBoth of these queries have a repeated work, and have many terms. It's not the number of terms or the colon surrounded by spaces, because the following phrase search works in Solr 3.5 (and Solr 1.4):\n\"International encyclopedia of revolution and protest : 1500 to the present\"\n\nWith Robert Muir's help, we have narrowed the problem down to slop (proximity in lucene QueryParser, query slop in dismax). I have included debugQuery details for the Beatles search; I confirmed the same behavior with the color-blindness search.\n\nSolr 3.5: it fails when (query) slop setting isn't 0.\n\nlucene QueryParser with proximity set to 1 (or anything > 0) : no match\nURL: q=all_search:\"The Beatles as musicians : Revolver through the Anthology\"~1\nfinal query: all_search:\"the beatl as musician revolv through the antholog\"~1\n\nlucene QueryParser with proximity set to 0: result!\nURL: q=all_search:\"The Beatles as musicians : Revolver through the Anthology\"\nfinal query: all_search:\"the beatl as musician revolv through the antholog\"\n\n6.0562754 = (MATCH) weight(all_search:\"the beatl as musician revolv through the antholog\" in 1064395), product of:\n<snip>\n48.450203 = idf(all_search: the=3531140 beatl=398 as=645923 musician=11805 revolv=872 through=81366 the=3531140 antholog=11611)\n<snip>\n\ndismax QueryParser with qs=1: no match\nps=0\nURL: qf=all_search&pf=all_search&q=\"The Beatles as musicians : Revolver through the Anthology\"&qs=1&ps=0\nfinal query: +(all_search:\"the beatl as musician revolv through the antholog\"~1)~0.01 (all_search:\"the beatl as musician revolv through the antholog\")~0.01\nps=1\nURL: qf=all_search&pf=all_search&q=\"The Beatles as musicians : Revolver through the Anthology\"&qs=1&ps=1\nfinal query: +(all_search:\"the beatl as musician revolv through the antholog\"~1)~0.01 (all_search:\"the beatl as musician revolv through the antholog\"~1)~0.01\n\ndismax QueryParser with qs=0: result!\nps=0\nURL: qf=all_search&pf=all_search&q=\"The Beatles as musicians : Revolver through the Anthology\"&qs=0&ps=0\nfinal query: +(all_search:\"the beatl as musician revolv through the antholog\")~0.01 (all_search:\"the beatl as musician revolv through the antholog\")~0.01\nps=1\nURL: qf=all_search&pf=all_search&q=\"The Beatles as musicians : Revolver through the Anthology\"&qs=0&ps=1\nfinal query: +(all_search:\"the beatl as musician revolv through the antholog\")~0.01 (all_search:\"the beatl as musician revolv through the antholog\"~1)~0.01\n\n8.564867 = (MATCH) sum of:\n4.2824335 = (MATCH) weight(all_search:\"the beatl as musician revolv through the antholog\" in 1064395), product of:\n<snip>\n48.450203 = idf(all_search: the=3531140 beatl=398 as=645923 musician=11805 revolv=872 through=81366 the=3531140 antholog=11611)\n<snip>\n\nSolr 1.4: it works regardless of slop settings\n\nlucene QueryParser with any proximity value: result!\n~0\nURL: q=all_search:\"The Beatles as musicians : Revolver through the Anthology\"\nfinal query: all_search:\"the beatl as musician revolv through the antholog\"\n~1\nURL: q=all_search:\"The Beatles as musicians : Revolver through the Anthology\"~1\nfinal query: all_search:\"the beatl as musician revolv through the antholog\"~1\n\n5.2672544 = fieldWeight(all_search:\"the beatl as musician revolv through the antholog\" in 3469163), product of:\n<snip>\n48.157753 = idf(all_search: the=3549637 beatl=392 as=751093 musician=11992 revolv=822 through=88522 the=3549637 antholog=11246)\n<snip>\n\ndismax QueryParser with any qs: result!\nqs=0, ps=0\nURL: qf=all_search&pf=all_search&q=\"The Beatles as musicians : Revolver through the Anthology\"&qs=0&ps=0\nfinal query: +(all_search:\"the beatl as musician revolv through the antholog\")~0.01 (all_search:\"the beatl as musician revolv through the antholog\")~0.01\nqs=0, ps=1\nURL: qf=all_search&pf=all_search&q=\"The Beatles as musicians : Revolver through the Anthology\"&qs=0&ps=1\nfinal query: +(all_search:\"the beatl as musician revolv through the antholog\")~0.01 (all_search:\"the beatl as musician revolv through the antholog\"~1)~0.01\ndismax QueryParser with qs=0: result!\nqs=1, ps=0\nURL: qf=all_search&pf=all_search&q=\"The Beatles as musicians : Revolver through the Anthology\"&qs=1&ps=0\nfinal query: +(all_search:\"the beatl as musician revolv through the antholog\"~1)~0.01 (all_search:\"the beatl as musician revolv through the antholog\")~0.01\nqs=1, ps=1\nURL: qf=all_search&pf=all_search&q=\"The Beatles as musicians : Revolver through the Anthology\"&qs=1&ps=1\nfinal query: +(all_search:\"the beatl as musician revolv through the antholog\"~1)~0.01 (all_search:\"the beatl as musician revolv through the antholog\"~1)~0.01\n\n7.4490223 = (MATCH) sum of:\n3.7245111 = weight(all_search:\"the beatl as musician revolv through the antholog\"~1 in 3469163), product of:\n<snip>\n48.157753 = idf(all_search: the=3549637 beatl=392 as=751093 musician=11992 revolv=822 through=88522 the=3549637 antholog=11246)\n<snip>\n\nMore information:\n\nschema.xml:\n<field name=\"all_search\" type=\"text\" indexed=\"true\" stored=\"false\" />\n\nsolr 3.5:\n<fieldtype name=\"text\" class=\"solr.TextField\" positionIncrementGap=\"100\" autoGeneratePhraseQueries=\"true\">\n<analyzer>\n<tokenizer class=\"solr.WhitespaceTokenizerFactory\" />\n<filter class=\"solr.ICUFoldingFilterFactory\"/>\n<filter class=\"solr.WordDelimiterFilterFactory\"\nsplitOnCaseChange=\"1\" generateWordParts=\"1\" catenateWords=\"1\"\nsplitOnNumerics=\"0\" generateNumberParts=\"1\" catenateNumbers=\"1\"\ncatenateAll=\"0\" preserveOriginal=\"0\" stemEnglishPossessive=\"1\" />\n<filter class=\"solr.EnglishPorterFilterFactory\" protected=\"protwords.txt\" />\n<filter class=\"solr.RemoveDuplicatesTokenFilterFactory\" />\n</analyzer>\n</fieldtype>\n\nsolr1.4:\n<fieldtype name=\"text\" class=\"solr.TextField\" positionIncrementGap=\"100\">\n<analyzer>\n<tokenizer class=\"solr.WhitespaceTokenizerFactory\" />\n<filter class=\"schema.UnicodeNormalizationFilterFactory\" version=\"icu4j\" composed=\"false\" remove_diacritics=\"true\" remove_modifiers=\"true\" fold=\"true\" />\n<filter class=\"solr.WordDelimiterFilterFactory\"\nsplitOnCaseChange=\"1\" generateWordParts=\"1\" catenateWords=\"1\"\nsplitOnNumerics=\"0\" generateNumberParts=\"1\" catenateNumbers=\"1\"\ncatenateAll=\"0\" preserveOriginal=\"0\" stemEnglishPossessive=\"1\" />\n<filter class=\"solr.LowerCaseFilterFactory\" />\n<filter class=\"solr.EnglishPorterFilterFactory\" protected=\"protwords.txt\" />\n<filter class=\"solr.RemoveDuplicatesTokenFilterFactory\" />\n</analyzer>\n</fieldtype>\n\nAnd the analysis page shows the same results for Solr 3.5 and 1.4\n\nSolr 3.5:\n\nposition 1 2 3 4 5 6 7 8\nterm text the beatl as musician revolv through the antholog\nkeyword false false false false false false false false\nstartOffset 0 4 12 15 27 36 44 48\nendOffset 3 11 14 24 35 43 47 57\ntype word word word word word word word word\n\nSolr 1.4:\n\nterm position 1 2 3 4 5 6 7 8\nterm text the beatl as musician revolv through the antholog\nterm type word word word word word word word word\nsource start,end 0,3 4,11 12,14 15,24 27,35 36,43 44,47 48,57\n\nFor debug purposes, we can consider the Solr document as:\n\n<doc>\n<str name=\"all_search\">The Beatles as musicians : Revolver through the Anthology</str>\n</doc>\n\nI can't attached the full SolrDoc as all_search is indexed, but not stored, and I use SolrJ to write to the index from java objects ... plus our objects have a zillion fields (I work in a library with very rich metadata and very exacting solr fields). I have attached the Solr 3.5 schema and solrconfig, but they are big and ugly for the same reasons.\n\nFor more details, see the erroneously titled email thread \"result present in Solr 1.4 but missing in Solr 3.5, dismax only\" started on 2012-02-22 on solr-user@lucene.apache.org.\n\n    Naomi\n\n\n ",
            "author": "Robert Muir",
            "id": "comment-13215154"
        },
        {
            "date": "2012-02-23T22:59:05+0000",
            "content": "Moving to comments... ",
            "author": "Robert Muir",
            "id": "comment-13215160"
        },
        {
            "date": "2012-02-23T23:04:56+0000",
            "content": "How's this for a document:\n\n<doc>\n<str name=\"id\">1</str>\n<str name=\"title_245a_display\">The Beatles as musicians</str>\n<str name=\"title_245a_search\">The Beatles as musicians :</str>\n<str name=\"title_245c_display\">Walter Everett</str>\n<str name=\"title_display\">The Beatles as musicians : Revolver through the Anthology</str>\n<str name=\"title_full_display\">The Beatles as musicians : Revolver through the Anthology  / Walter Everett.</str>\n<str name=\"title_245_search\">The Beatles as musicians : Revolver through the Anthology  / Walter Everett.</str>\n<str name=\"title_sort\">Beatles as musicians Revolver through the Anthology</str>\n<str name=\"all_search\">The Beatles as musicians : Revolver through the Anthology</str>\n</doc> ",
            "author": "Naomi Dushay",
            "id": "comment-13215172"
        },
        {
            "date": "2012-02-23T23:06:08+0000",
            "content": "Here's an improved test that fails every time. ",
            "author": "Robert Muir",
            "id": "comment-13215174"
        },
        {
            "date": "2012-02-23T23:21:52+0000",
            "content": "I reviewed the random failures: in all cases it fails, repeated terms are in the query. ",
            "author": "Robert Muir",
            "id": "comment-13215191"
        },
        {
            "date": "2012-02-29T11:44:13+0000",
            "content": "I just @Ignore'd this test... it's creating a lot of Jenkins noise... but we should fix this bug!! ",
            "author": "Michael McCandless",
            "id": "comment-13219123"
        },
        {
            "date": "2012-02-29T12:52:26+0000",
            "content": "Fails here too like this: \n\nant test -Dtestcase=TestSloppyPhraseQuery2 -Dtestmethod=testRandomIncreasingSloppiness -Dtests.seed=-171bbb992c697625:203709d611c854a5:1ca48cb6d33b3f74 -Dargs=\"-Dfile.encoding=UTF-8\"\n\nI'll look into it ",
            "author": "Doron Cohen",
            "id": "comment-13219156"
        },
        {
            "date": "2012-03-03T23:45:54+0000",
            "content": "I understand the problem. \n\nIt all has to do - as Robert mentioned - with the repeating terms in the phrase query. I am working on a patch - it will change the way that repeats are handled. \n\nRepeating PPs require additional computation - and current SloppyPhraseScorer attempts to do that additional work efficiently, but over simplifies in that and fail to cover all cases. \n\nIn the core of things, each time a repeating PP is selected (from the queue) and  propagated, all its sibling repeaters are propagated as well, to prevent a case that two repeating PPs point to the same document position (which was the bug that originally triggered handling repeats in this code). \n\nBut this is wrong, because it propagates all siblings repeaters, and misses some cases.\n\nAlso, the code is hard to read, as Mike noted in LUCENE-2410 (this comment) ).\n\nSo this is a chance to also make the code more maintainable.\n\nI have a working version which is not ready to commit yet, and all the tests pass, except for one which I think is a bug in ExactPhraseScorer, but maybe i am missing something. \n\nThe case that fails is this:\n\n\nAssertionError: Missing in super-set: doc 706\nq1: field:\"(j o s) (i b j) (t d)\"\nq2: field:\"(j o s) (i b j) (t d)\"~1\ntd1: [doc=706 score=7.7783184 shardIndex=-1, doc=175 score=6.222655 shardIndex=-1]\ntd2: [doc=523 score=5.5001016 shardIndex=-1, doc=957 score=5.5001016 shardIndex=-1, doc=228 score=4.400081 shardIndex=-1, doc=357 score=4.400081 shardIndex=-1, doc=390 score=4.400081 shardIndex=-1, doc=503 score=4.400081 shardIndex=-1, doc=602 score=4.400081 shardIndex=-1, doc=757 score=4.400081 shardIndex=-1, doc=758 score=4.400081 shardIndex=-1]\ndoc 706: Document<stored,indexed,tokenized<field:s o b h j t j z o>>\n\n\n\nIt seems that q1 too should not match this document? ",
            "author": "Doron Cohen",
            "id": "comment-13221737"
        },
        {
            "date": "2012-03-04T00:09:07+0000",
            "content": "Doron do you have the seed for that failure?  I can dig on the ExactPhraseScorer... ",
            "author": "Michael McCandless",
            "id": "comment-13221746"
        },
        {
            "date": "2012-03-04T00:17:16+0000",
            "content": "Patch with fix for this problem. I would expect SloppyPhrase scoring performance to degrade, though I did not measure it.\n\nThe single test that still fails (and I think the bug is in ExactPhraseScorer) is testRandomIncreasingSloppiness, and can be recreated like this:\n\nant test -Dtestcase=TestSloppyPhraseQuery2 -Dtestmethod=testRandomIncreasingSloppiness -Dtests.seed=47267613db69f714:-617bb800c4a3c645:-456a673444fdc184 -Dargs=\"-Dfile.encoding=UTF-8\"\n\n ",
            "author": "Doron Cohen",
            "id": "comment-13221747"
        },
        {
            "date": "2012-03-04T00:27:07+0000",
            "content": "Hmm patch has this:\n\n\nimport backport.api.edu.emory.mathcs.backport.java.util.Arrays;\n\n ",
            "author": "Michael McCandless",
            "id": "comment-13221750"
        },
        {
            "date": "2012-03-04T00:32:20+0000",
            "content": "Thanks for digging into the problem Doron!\n\nI'm going to be ecstatic if that crazy test finds bugs both in exact and sloppy phrase scorers  ",
            "author": "Robert Muir",
            "id": "comment-13221755"
        },
        {
            "date": "2012-03-04T07:20:09+0000",
            "content": "Hmm patch has this: ... import backport.api...\n\nOops, here's a fixed patch, also added some comments, and removed the @Ignore from the test\n\nI'm going to be ecstatic if that crazy test finds bugs both in exact and sloppy phrase scorers \n\nIt is a great test! Interestingly one thing it exposed is the dependency of the SloppyPhraseScorer in the order of PPs in PhraseScorer when phraseFreq() is invoked. The way things work in the super class, that order depends on the content of previously processed documents. This fix removes that wrong dependency, of course. The point is that deliberately devising a test that exposes such a bug seems almost impossible: first you need to think about such a case, and if you did, writing a test that would create this specific scenario is buggy by itself. Praise to random testing, and this random test in particular. ",
            "author": "Doron Cohen",
            "id": "comment-13221816"
        },
        {
            "date": "2012-03-04T10:25:38+0000",
            "content": "The remaining failure still happens with the updated patch (same seed), and still seems to me like an ExactPhraseScorer bug. \n\nHowever, it is probably not a simple one I think, because when adding to TestMultiPhraseQuery, it passes, that is, no documents are matched, as expected, although this supposedly created the exact scenario that failed above. \n\nPerhaps ExactPhraseScorer behavior too is influenced by other docs processed so far.\n\nAdd this to TestMultiPhraseQuery\n  public void test_LUCENE_XYZ() throws Exception {\n    Directory indexStore = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, indexStore);\n    add(\"s o b h j t j z o\", \"LUCENE-XYZ\", writer);\n    \n    IndexReader reader = writer.getReader();\n    IndexSearcher searcher = newSearcher(reader);\n    \n    MultiPhraseQuery q = new MultiPhraseQuery();\n    q.add(new Term[] {new Term(\"body\", \"j\"), new Term(\"body\", \"o\"), new Term(\"body\", \"s\")});\n    q.add(new Term[] {new Term(\"body\", \"i\"), new Term(\"body\", \"b\"), new Term(\"body\", \"j\")});\n    q.add(new Term[] {new Term(\"body\", \"t\"), new Term(\"body\", \"d\")});\n    assertEquals(\"Wrong number of hits\", 0,\n        searcher.search(q, null, 1).totalHits);\n    \n    // just make sure no exc:\n    searcher.explain(q, 0);\n    \n    writer.close();\n    searcher.close();\n    reader.close();\n    indexStore.close();\n  }\n\n ",
            "author": "Doron Cohen",
            "id": "comment-13221840"
        },
        {
            "date": "2012-03-04T12:28:44+0000",
            "content": "Update: apparently MultiPhraseQuery.toString does not print its \"holes\".\n\nSo the query that failed was not:\n\nfield:\"(j o s) (i b j) (t d)\"\n\n\nBut rather:\n\n\"(j o s) ? (i b j) ? ? (t d)\"\n\n\nWhich is a different story: this query should match the document\n\ns o b h j t j z o\n\n\nThere is a match for ExactPhraseScorer, but not for Sloppy with slope 1.\nSo there is still work to do on SloppyPhraseScorer...\n\n(I'll fix MFQ.toString() as well) ",
            "author": "Doron Cohen",
            "id": "comment-13221867"
        },
        {
            "date": "2012-03-04T12:32:15+0000",
            "content": "updated patch with fixed MFQ.toString(), which prints the problematic doc and queries in case of failure. ",
            "author": "Doron Cohen",
            "id": "comment-13221870"
        },
        {
            "date": "2012-03-04T12:59:03+0000",
            "content": "I think I understand the cause.\n\nIn current implementation there is an assumption that once we landed on the first candidate document, it is possible to check if there are repeating pps, by just comparing the in-doc-positions of the terms. \n\nTricky as it is, while this is true for plain PhrasePositions, it is not true for MultiPhrasePositions - assume to MPPs: (a m n) and (b x y), and first candidate document that starts with \"a b\". The in-doc-positions of the two pps would be 0,1 respectively (for 'a' and 'b') and we would not even detect the fact that there are repetitions, not to mention not putting them in the same group.\n\nMPPs conflicts with current patch in an additional manner: It is now assumed that each repetition can be assigned a repetition group. \n\nSo assume these PPs (and query positions): \n0:a 1:b 3:a 4:b 7:c\nThere are clearly two repetition groups \n{0:a, 3:a}\n and \n{1:b, 4:b}\n, \nwhile 7:c is not a repetition.\n\nBut assume these PPs (and query positions): \n0:(a b) 1:(b x) 3:a 4:b 7:(c x)\nWe end up with a single large repetition group:\n{0:(a b) 1:(b x) 3:a 4:b 7:(c x)}\n\nI think if the groups are created correctly at the first candidate document, scorer logic would still work, as a collision is decided only when two pps are in the same in-doc-position. The only impact of MPPs would be performance cost: since repetition groups are larger, it would take longer to check if there are repetitions.\n\nJust need to figure out how to detect repetition groups without relying on in-(first-)doc-positions. ",
            "author": "Doron Cohen",
            "id": "comment-13221879"
        },
        {
            "date": "2012-03-05T19:25:35+0000",
            "content": "Attached updated patch. \n\nRepeating PPs with multi-Phrase-query is handled as well.\n\nThis called for more cases in the sloppy phrase scorer and more code, and, although I think the code is cleaner now, I don't know to what extent is it easier to maintain. \n\nIt definitely fixes wrong behavior that exists in current 3x and trunk (patch is for 3x).\n\nHowever, although the random test passes for me even with -Dtests.iter=2000, it is possible to \"break the scorer\" - that is, create a document and a query which should match each other but would not. \n\nThe patch adds just such a case as an @Ignored test case:  TestMultiPhraseQuery.testMultiSloppyWithRepeats(). \n\nI don't see how to solve this specific case in the context of current sloppy phrase scorer. \n\nSo there are 3 options:\n\n\tleave things as they are\n\tcommit this patch and for now document the failing scenario (also keep it in the ignored test case).\n\tdevise a different algorithm for this.\n\n\n\nI would love it to be the 3rd if I just knew how to do it. Otherwise I like the 2nd, just need to keep in mind that the random test might from time to time create this scenario and so there will be noise in the test builds.\n\nPreferences? ",
            "author": "Doron Cohen",
            "id": "comment-13222537"
        },
        {
            "date": "2012-03-06T03:03:37+0000",
            "content": "\nI would love it to be the 3rd if I just knew how to do it. Otherwise I like the 2nd, just need to keep in mind that the random test might from time to time create this scenario and so there will be noise in the test builds.\n\nI think there is no problem in fixing \"some of the bugs\" to improve the behavior, even if its still not perfect.\n\nwe can take our time thinking of how to handle the remaining scenarios... either way I think we should just go\nwith your judgement call on this one, since you obviously understand it better than anyone else. ",
            "author": "Robert Muir",
            "id": "comment-13222958"
        },
        {
            "date": "2012-03-06T08:07:13+0000",
            "content": "Thanks Robert, okay, I'll continue with option 2 then.\n\nIn addition, perhaps should try harder for a sloppy version of current ExactPhraseScorer, for both performance and correctness reasons. \n\nIn ExactPhraseScorer, the increment of count[posIndex] is by 1, each time the conditions for a match (still) holds.  \n\nA sloppy version of this, with N terms and slop=S could increment differently:\n\n1 + N*S        at posIndex\n1 + N*S - 1    at posIndex-1 and posIndex+1\n1 + N*S - 2 at posIndex-2 and posIndex+3\n...\n1 + N*S - S at posIndex-S and posIndex+S\n\n\n\nFor S=0, this falls back to only increment by 1 and only at posIndex, same as the ExactPhraseScorer, which makes sense.\n\nAlso, the success criteria in ExactPhraseScorer, when checking term k, is, before adding up 1 for term k:\n\n\tcount[posIndex] == k-1\nOr, after adding up 1 for term k:\n\tcount[posIndex] == k\n\n\n\nIn the sloppy version the criteria (after adding up term k) would be:\n\n\tcount[posIndex] >= k*(1+N*S)-S\n\n\n\nAgain, for S=0 this falls to the ExactPhraseScorer logic:\n\n\tcount[posIndex] >= k\n\n\n\nMike (and all), correctness wise, what do you think?\n\nIf you are wondering why the increment at the actual position is (1 + N*S) - it allows to match only posIndexes where all terms contributed something.\n\nI drew an example with 5 terms and slop=2 and so far it seems correct.\n\nAlso tried 2 terms and slop=5, this seems correct as well, just that, when there is a match, several posIndexes will contribute to the score of the same match. I think this is not too bad, as for these parameters, same behavior would be in all documents. I would be especially forgiving for this if we this way get some of the performance benefits of the ExactPhraseScorer.\n\nIf we agree on correctness, need to understand how to implement it, and consider the performance effect. The tricky part is to increment at posIndex-n. Say there are 3 terms in the query and one of the terms is found at indexes 10, 15, 18. Assume the slope is 2. Since N=3, the max increment is:\n\n\t1 + N*S = 1 + 3*2 = 7.\n\n\n\nSo the increments for this term would be (pos, incr):\n\nPos   Increment\n---   ---------\n 8  ,  5\n 9  ,  6\n10  ,  7\n11  ,  6\n12  ,  5\n13  ,  5\n14  ,  6\n15  ,  7   =  max(7,5)\n16  ,  6   =  max(6,5)\n17  ,  6   =  max(5,6)\n18  ,  7\n19  ,  6\n20  ,  5\n\n\n\nSo when we get to posIndex 17, we know that posIndex 15 contributes 5, but we do not know yet about the contribution of posIndex 18, which is 6, and should be used instead of 5. So some look-ahead (or some fix-back) is required, which will complicate the code.\n\nIf this seems promising, should probably open a new issue for it, just wanted to get some feedback first. ",
            "author": "Doron Cohen",
            "id": "comment-13223077"
        },
        {
            "date": "2012-03-06T16:48:44+0000",
            "content": "Cool!\n\nI haven't fully thought this out (sloppy phrase matching is hard to think about!), but, tentatively, I think this is correct...? ",
            "author": "Michael McCandless",
            "id": "comment-13223410"
        },
        {
            "date": "2012-03-06T19:07:23+0000",
            "content": "OK great! \n\nIf you did not point a problem with this up front there's a good chance it will work and I'd like to give it a try. \n\nI have a first patch - not working or anything - it opens ExactPhraseScorer a bit for extensions and adds a class (temporary name) - NonExactPhraseScorer. \n\nThe idea is to hide in the ChunkState the details of decaying frequencies due to slops. I will try it over the weekend. If we can make it this way, I'd rather do it in this issue rather than committing the other new code for the fix and then replacing it. If that won't go quick, I'll commit the (other) changes to SloppyPhraseScorer and start a new issue. ",
            "author": "Doron Cohen",
            "id": "comment-13223554"
        },
        {
            "date": "2012-03-06T19:10:57+0000",
            "content": "sounds interesting: ExactPhraseScorer really has a lot of useful recent heuristics and optimizations, \nespecially about when to next() versus advance() and such?\n\nnet/net this idea could possibly improvement the performance overall of SloppyPhraseScorer ",
            "author": "Robert Muir",
            "id": "comment-13223560"
        },
        {
            "date": "2012-03-06T20:23:32+0000",
            "content": "Patch adds NonExactPhraseScorer (temporary name) as discussed above - work in progress, it does not yet do any sloppy matching or scoring. ",
            "author": "Doron Cohen",
            "id": "comment-13223621"
        },
        {
            "date": "2012-03-06T20:28:10+0000",
            "content": "sounds interesting: ExactPhraseScorer really has a lot of useful recent heuristics and optimizations, especially about when to next() versus advance() and such?\n\nnext()/advance() will remain, but it would still be more costly than exact - score cache won't play, because freqs really are float in this case, and also there would be more computations on the way. But let's see it working first... ",
            "author": "Doron Cohen",
            "id": "comment-13223629"
        },
        {
            "date": "2012-03-06T21:55:05+0000",
            "content": "I'm afraid it won't solve the problem.\n\nThe complicity of SloppyPhraseScorer stems firstly from the slop.\nThat part is handled in the scorer for long time.\n\nTwo additional complications are repeating terms, and multi-term phrases.\nEach one of these, separately, is handled as well.\nTheir combination however, is the cause for this discussion.\n\nTo prevent two repeating terms from landing on the same document position, we propagate the smaller of them (smaller in its phrase-position, which takes into account both the doc-position and the offset of that term in the query).\n\nWithout this special treatment, a phrase query \"a b a\"~2 might match a document \"a b\", because both \"a\"'s (query terms) will land on the same document's \"a\". This is illegal and is prevented by such propagation. \n\nBut when one of the repeating terms is a multi-term, it is not possible to know which of the repeating terms to propagate. This is the unsolved bug.\n\nNow, back to current ExactPhraseScorer.\nIt does not have this problem with repeating terms.\nBut not because of the different algorithm - rather because of the different scenario.\nIt does not have this problem because exact phrase scoring does not have it.\nIn exact phrase scoring, a match is declared only when all PPs are in the same phrase position.\nRecall that phrase position = doc-position - query-offset, it is visible that when two PPs with different query offset are in the same phrase-position, their doc-position cannot be the same, and therefore no special handling is needed for repeating terms in exact phrase scorers.\n\nHowever, once we will add that slopy-decaying frequency, we will match in certain posIndex, different phrase-positions. This is because of the slop. So they might land on the same doc-position, and then we start again...\n\nThis is really too bad. Sorry for the lengthy post, hopefully this would help when someone wants to get into this.\n\nBack to option 2. ",
            "author": "Doron Cohen",
            "id": "comment-13223700"
        },
        {
            "date": "2012-03-07T00:04:33+0000",
            "content": "I would be glad to try out a nightly build with the patch as is against our tests - I would be glad to get the 80% solution if it fixes my bug.  I haven't compiled from source yet, though, so am inclined to wait for the patch getting posted to the nightly. ",
            "author": "Naomi Dushay",
            "id": "comment-13223839"
        },
        {
            "date": "2012-03-07T00:22:50+0000",
            "content": "\nTo prevent two repeating terms from landing on the same document position, we propagate the smaller of them (smaller in its phrase-position, which takes into account both the doc-position and the offset of that term in the query).\n\nWithout this special treatment, a phrase query \"a b a\"~2 might match a document \"a b\", because both \"a\"'s (query terms) will land on the same document's \"a\". This is illegal and is prevented by such propagation.\n\nBut when one of the repeating terms is a multi-term, it is not possible to know which of the repeating terms to propagate. This is the unsolved bug.\n\nNot understanding really how SloppyPhraseScorer works now, but not trying to add confusion to the issue, I can't help but think\nthis problem is a variant on LevensteinAutomata... in fact that was the motivation for the new test, i just stole the testing\nmethodology from there and applied it to this!\n\nIt seems many things are the same but with a few twists:\n\n\tfundamentally we are interleaving the streams from the subscorers into the 'index automaton'\n\t'query automaton' is produced from the user-supplied terms\n\tour 'alphabet' is the terms, and holes from position increment are just an additional symbol.\n\tjust like the LevensteinAutomata case, repeats are problematic because they are different characteristic vectors\n\tstacked terms at the same position (index or query) just make the automata more complex (so they arent just strings)\n\n\n\nI'm not suggesting we try to re-use any of that code at all, i don't think it will work. But I wonder if we can re-use even\nsome of the math to redefine the problem more formally to figure out what minimal state/lookahead we need for example... ",
            "author": "Robert Muir",
            "id": "comment-13223856"
        },
        {
            "date": "2012-03-09T21:32:26+0000",
            "content": "\nNot understanding really how SloppyPhraseScorer works now, but not trying to add confusion to the issue, I can't help but think this problem is a variant on LevensteinAutomata... in fact that was the motivation for the new test, i just stole the testing methodology from there and applied it to this!\n\nInteresting! I was not aware of this. I went and read some about this automaton, It is relevant.\n\n\nIt seems many things are the same but with a few twists:\n\n\n\tfundamentally we are interleaving the streams from the subscorers into the 'index automaton'\n'query automaton' is produced from the user-supplied terms\n\n\n\nTrue. In fact, the current code works hard to decide on the \"correct interleaving order\" - while if we had a \"Perfect Levenstein Automaton\" that took care of the computation we could just interleave, in the term position order (forget about phrase position and all that) and let the automaton compute the distance. \n\nThis might capture the difficulty in making the sloppy phrase scorer correct: it started with the algorithm that was optimized for exact matching, and adopted (hacked?) it for approximate matching.\n\nInstead, starting with a model that fits approximate matching, might be easier and cleaner. I like that. \n\n\n\n\tour 'alphabet' is the terms, and holes from position increment are just an additional symbol.\n\tjust like the LevensteinAutomata case, repeats are problematic because they are different characteristic vectors\n\tstacked terms at the same position (index or query) just make the automata more complex (so they arent just strings)\n\n\n\nI'm not suggesting we try to re-use any of that code at all, i don't think it will work. But I wonder if we can re-use even\nsome of the math to redefine the problem more formally to figure out what minimal state/lookahead we need for example...\n\nI agree. I'll think of this.\n\nIn the meantime I'll commit this partial fix. ",
            "author": "Doron Cohen",
            "id": "comment-13226494"
        },
        {
            "date": "2012-03-10T00:14:37+0000",
            "content": "Committed:\n\n\tr1299077  3x\n\tr1299112  trunk\n\n\n\nI would be glad to try out a nightly build with the patch as is against our tests - I would be glad to get the 80% solution if it fixes my bug.\n\nIt's in now...\n\nBut I wonder if we can re-use even some of the math to redefine the problem more formally to figure out what minimal state/lookahead we need for example...\n\nRobert, this gave me an idea... currently, in case of \"collision\" between repeaters, we compare them and advance the \"lesser\" of them (SloppyPhraseScorer.lesser(PhrasePositions, PhrasePositions)) - it should be fairly easy to add lookahead to this logic: if one of the two is multi-term, lesser can also do a lookahead. The amount of lookahead can depend on the slop. I'll give it a try before closing this issue. ",
            "author": "Doron Cohen",
            "id": "comment-13226623"
        },
        {
            "date": "2012-03-10T15:04:20+0000",
            "content": "\nRobert, this gave me an idea... currently, in case of \"collision\" between repeaters, we compare them and advance the \"lesser\" of them (SloppyPhraseScorer.lesser(PhrasePositions, PhrasePositions)) - it should be fairly easy to add lookahead to this logic: if one of the two is multi-term, lesser can also do a lookahead. The amount of lookahead can depend on the slop. I'll give it a try before closing this issue.\n\nInteresting... its hard to think about for me since the edit distance is a little different, but at least in the\nlevAutomata case the maximum 'context' the thing ever needs is 2n+1, where n is the distance/slop. I don't \nknow if it applies here... but seems like it should be at least an upperbound.\n\nSpeaking of which on a related note, I think its possible we can implement a more... exhaustive test for \nSloppyPhraseScorer (rather than relying so much on a random one). The idea would be a twist on \nTestLevenshteinAutomata.assertCharVectors: using an alphabet of terms=\n{0,1}\n the idea is to test all possible\n'automaton structures', for sloppyphrasescorer, the idea would be we have the minimal test method that\ntests all the cases...\n\nI'll think on this one...\n ",
            "author": "Robert Muir",
            "id": "comment-13226873"
        },
        {
            "date": "2012-03-13T01:28:09+0000",
            "content": "The commits from March 10 fix my two failing tests - huzzah!  Thank you so much!   - Naomi ",
            "author": "Naomi Dushay",
            "id": "comment-13228118"
        }
    ]
}