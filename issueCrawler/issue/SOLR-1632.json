{
    "id": "SOLR-1632",
    "title": "Distributed IDF",
    "details": {
        "affect_versions": "1.5",
        "status": "Closed",
        "fix_versions": [
            "5.0",
            "6.0"
        ],
        "components": [
            "search"
        ],
        "type": "New Feature",
        "priority": "Major",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "Distributed IDF is a valuable enhancement for distributed search across non-uniform shards. This issue tracks the proposed implementation of an API to support this functionality in Solr.",
    "attachments": {
        "3x_SOLR-1632_doesntwork.patch": "https://issues.apache.org/jira/secure/attachment/12511710/3x_SOLR-1632_doesntwork.patch",
        "distrib.patch": "https://issues.apache.org/jira/secure/attachment/12427291/distrib.patch",
        "distrib-2.patch": "https://issues.apache.org/jira/secure/attachment/12428840/distrib-2.patch",
        "SOLR-1632.patch": "https://issues.apache.org/jira/secure/attachment/12507206/SOLR-1632.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Andrzej Bialecki",
            "id": "comment-12787300",
            "date": "2009-12-08T04:23:17+0000",
            "content": "Initial implementation. This supports the current global IDF (i.e. none  ), and an exact version of global IDF that requires one additional request per query to obtain per-shard stats.\n\nThe design should be already flexible enough to implement LRU caching of docFreqs, and ultimately to implement other methods for global IDF calculation (e.g. based on estimation or re-ranking). "
        },
        {
            "author": "Otis Gospodnetic",
            "id": "comment-12789120",
            "date": "2009-12-11T05:22:52+0000",
            "content": "What about this approach: http://markmail.org/message/mjfmpzfspguepixx ? "
        },
        {
            "author": "Andrzej Bialecki",
            "id": "comment-12789174",
            "date": "2009-12-11T08:44:40+0000",
            "content": "I'm not sure what approach you are referring to. Following the terminology in that thread, this implementation follows the approach where there is a single merged big idf map at the master, and it's sent out to slaves on each query. However, when exactly this merging and sending happens is implementation-specific - in the ExactDFSource it happens on every query, but I hope the API can support other scenarios as well. "
        },
        {
            "author": "Otis Gospodnetic",
            "id": "comment-12789379",
            "date": "2009-12-11T16:39:34+0000",
            "content": "I didn't look a the patch, but from your comments it looks like you already have that \"1 merged big idf map\", which is really what I was aiming at, so that's good!\n\nI was just thinking that this map (file) would be periodically updated and pushed to slaves, so that slaves can compute the global IDF locally instead of any kind of extra requests. "
        },
        {
            "author": "Andrzej Bialecki",
            "id": "comment-12789607",
            "date": "2009-12-11T23:24:25+0000",
            "content": "I believe the API that I propose would support such implementation as well. Please note that it's usually not feasible to compute and distribute the complete IDF table for all terms - you would have to replicate a union of all term dictionaries across the cluster. In practice, you limit the amount of information by various means, e.g. only distributing data related to the current request (this implementation) or reducing the frequency of updates (e.g. LRU caching), or approximating global DF with a constant for frequent terms (where the contribution of their IDF to the score would be negligible anyway). "
        },
        {
            "author": "Marc Sturlese",
            "id": "comment-12793283",
            "date": "2009-12-21T18:11:40+0000",
            "content": "Wich should be the value of the parameter shard.purpose to enable or disable the exact version of global IDF?  "
        },
        {
            "author": "Andrzej Bialecki",
            "id": "comment-12793295",
            "date": "2009-12-21T18:43:15+0000",
            "content": "Shard.purpose is set by a concrete implementation of the DFSource, so I guess your question is \"how to turn ExactDFSource on/off\"? If that's the case, then put this in your solrconfig.xml:\n\n\n<globalIDF class=\"org.apache.solr.search.ExactDFCache\"/>\n\n "
        },
        {
            "author": "Andrzej Bialecki",
            "id": "comment-12794090",
            "date": "2009-12-23T16:13:44+0000",
            "content": "Updated patch, contains also:\n\n\n\tLRU-based cache that optimizes requests using cached values of docFreq for known terms\n\tunit tests\n\n "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12856220",
            "date": "2010-04-12T23:21:37+0000",
            "content": "Was looking into this a little offline with Mark, who noticed that some queries were not being rewritten, and would thus throw an exception during weighting.\n\nIt looks like the issue is this: rewrite() doesn't work for function queries (there is no propagation mechanism to go through value sources).  This is a problem when real queries are embedded in function queries.\n\nSolr Function queries do have a mechanism to weight (via ValueSource.createWeight()).\nQueryValueSource does \"Weight w = q.weight(searcher);\" and that implementation of weight\ncalls   \"Query query = searcher.rewrite(this);\"\n\nThis patch calls rewrite explicitly (which does nothing for embedded queries), and then when using the DFSource implementation of searcher, rewrite does nothing, and hence the embedded query is never rewritten and the subsequent createWeight() throws an exception. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12856517",
            "date": "2010-04-13T17:53:55+0000",
            "content": "Rewrite not working through function query is not the end of the problems either... there is also stuff like extractTerms.\n\nThere is also the issue of Lucene changing rapidly... and the difficulty of adding new methods to ValueSource and making sure that all implementations correctly propagate them through to sub ValueSources.  Perhaps one idea is to use a visitor pattern to decouple tree traversal with the operations being performed. "
        },
        {
            "author": "LiLi",
            "id": "comment-12892167",
            "date": "2010-07-26T03:13:21+0000",
            "content": "My solr version is 1.4. I patched it but failed.\nSolrCache<String, Integer> cache = perShardCache.get(shard);  it suggests that \"The type SolrCache is not generic; it cannot be parameterized with arguments <String, Integer>\" \n\nThe SolrCache is a interface: public interface SolrCache extends SolrInfoMBean \n\npatching file src/common/org/apache/solr/common/params/ShardParams.java\npatching file src/java/org/apache/solr/core/SolrConfig.java\nHunk #1 succeeded at 30 with fuzz 2 (offset 2 lines).\nHunk #2 FAILED at 197.\n1 out of 2 hunks FAILED \u2013 saving rejects to file src/java/org/apache/solr/core/\nSolrConfig.java.rej\npatching file src/java/org/apache/solr/core/SolrCore.java\nHunk #5 succeeded at 821 (offset 3 lines).\npatching file src/java/org/apache/solr/handler/component/QueryComponent.java\nHunk #1 succeeded at 40 with fuzz 2 (offset -2 lines).\nHunk #6 succeeded at 302 (offset 13 lines).\nHunk #7 succeeded at 324 with fuzz 2 (offset 12 lines).\nHunk #8 succeeded at 343 (offset 21 lines).\nHunk #9 succeeded at 367 (offset 21 lines).\nHunk #10 succeeded at 423 (offset 28 lines).\npatching file src/java/org/apache/solr/handler/component/SearchHandler.java\npatching file src/java/org/apache/solr/handler/component/ShardRequest.java\nHunk #1 FAILED at 37.\n1 out of 1 hunk FAILED \u2013 saving rejects to file src/java/org/apache/solr/handle\nr/component/ShardRequest.java.rej\npatching file src/java/org/apache/solr/search/DFCache.java\npatching file src/java/org/apache/solr/search/DFSource.java\npatching file src/java/org/apache/solr/search/DefaultDFCache.java\npatching file src/java/org/apache/solr/search/ExactDFCache.java\npatching file src/java/org/apache/solr/search/LRUDFCache.java\npatching file src/java/org/apache/solr/search/SolrIndexSearcher.java\nHunk #1 succeeded at 77 (offset 3 lines).\nHunk #2 succeeded at 149 (offset 3 lines).\nHunk #3 succeeded at 699 (offset 46 lines).\nHunk #4 succeeded at 927 (offset 59 lines).\nHunk #5 succeeded at 1041 (offset 59 lines).\nHunk #6 succeeded at 1190 with fuzz 1 (offset 180 lines).\nHunk #7 FAILED at 1276.\nHunk #8 FAILED at 1311.\nHunk #9 succeeded at 1608 (offset 104 lines).\nHunk #10 succeeded at 1716 (offset 113 lines).\nHunk #11 succeeded at 1774 (offset 113 lines).\n2 out of 11 hunks FAILED \u2013 saving rejects to file src/java/org/apache/solr/sear\nch/SolrIndexSearcher.java.rej\npatching file src/java/org/apache/solr/util/SolrPluginUtils.java\ncan't find file to patch at input line 1206\nPerhaps you used the wrong -p or --strip option?\nThe text leading up to this was:\n--------------------------\n\n\n\nIndex: trunk/src/test/org/apache/solr/BaseDistributedSearchTestCase.java\n\n\n===============================================================\n\n\n\u2014 trunk/src/test/org/apache/solr/BaseDistributedSearchTestCase.java  (revisio\nn 893413)\n\n\n+++ trunk/src/test/org/apache/solr/BaseDistributedSearchTestCase.java  (working\n copy)\n--------------------------\nFile to patch:\nSkip this patch? [y] n\nFile to patch:\nSkip this patch? [y]\nSkipping patch.\n4 out of 4 hunks ignored\npatching file src/test/org/apache/solr/search/TestDefaultDFCache.java\npatching file src/test/org/apache/solr/search/TestExactDFCache.java\npatching file src/test/org/apache/solr/search/TestLRUDFCache.java\npatching file src/test/test-files/solr/conf/solrconfig-defaultdfcache.xml\npatching file src/test/test-files/solr/conf/solrconfig-exactdfcache.xml\npatching file src/test/test-files/solr/conf/solrconfig-lrudfcache.xml\n\n\n\n "
        },
        {
            "author": "Thorsten Scherler",
            "id": "comment-12998262",
            "date": "2011-02-23T09:27:09+0000",
            "content": "Regarding the comment \"Perhaps one idea is to use a visitor pattern to decouple tree traversal with the operations being performed.\" can you please explain where to implement the Listener/visitor. I had a quick look at the patch and it seems to me that the main functionality is in trunk/src/java/org/apache/solr/search/SolrIndexSearcher.java and the rest is more caching concerns, right? "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13142603",
            "date": "2011-11-02T21:58:58+0000",
            "content": "Recently I updated this patch to trunk and got rid of the threadlocal usage and Query rewriting that was the reason we had to pull this from trunk long ago - then I attempted to override stats on IndexSearcher with global stats - this is when I realized that had no affect on scoring anymore - this will now be addressed LUCENE-3555. Unfortunately, I didn't pay attention and lost that code. It's unfortunate, because it would have been a nice head start on this issue - I think we may want to make other changes/improvements, but would have been a start with something working. It was a half pain to do since the patch has to be manually applied, but perhaps doing it a second time is faster... "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13142634",
            "date": "2011-11-02T22:34:14+0000",
            "content": "Correction: i got rid of the rewrite that was added for the multi searcher type behavior - I hadn't solved the issue of rewrite to get the terms to retrieve stats for - that patch was not yet going to work with multiterm queries. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13142641",
            "date": "2011-11-02T22:46:24+0000",
            "content": "Although, actually I'm not even sure if that rewrite is really a problem - I almost don't think it will tickle the same issue as the rewrite that was happening before the search. I didn't have a chance to test it or look into it in depth or anything yet though. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13168514",
            "date": "2011-12-13T17:06:56+0000",
            "content": "I found this work hidden away in my eclipse workspace! It still has the thread local stuff - either I had only thought of what I was going to do to remove it, or this was not the latest work, but either way, it starts us from a trunk applyable patch, which is much better. There is still a fair amount to do at minimum to switch to using the new scoring stats. I started some really simple moves towards this (super baby step) and so things dont compile at the moment. Patch should be clean though. "
        },
        {
            "author": "Andrzej Bialecki",
            "id": "comment-13187336",
            "date": "2012-01-17T00:32:31+0000",
            "content": "Patch updated to trunk (rev. 1232110). I refactored the code and changed the names of new classes to better reflect the fact that we work with complex stats and not primitive freqs. Included unit tests are passing. "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-13192357",
            "date": "2012-01-24T18:44:14+0000",
            "content": "Is this something that can be added to branch_3x? With high fuzz and ignore whitespace, the patch applies, but then fails to compile.  It also fails to compile when I set fuzz to zero, pay attention to whitespace, and manually fix the patch rejects.  I couldn't figure out how to fix the problems. "
        },
        {
            "author": "Andrzej Bialecki",
            "id": "comment-13192374",
            "date": "2012-01-24T19:00:24+0000",
            "content": "Is this something that can be added to branch_3x?\n\nNot without porting - Lucene / Solr API-s have changed significantly, and this patch uses some low-level API-s that are different between trunk and 3x. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13192394",
            "date": "2012-01-24T19:18:34+0000",
            "content": "Haven't had time to look this over that closely, but this did jump out at me:\n\n+public class CollectionStats {\n+  public String field;\n+  public int maxDoc;\n+  public int docCount;\n\nShouldn't we be using longs here so we can support more than 2B docs? "
        },
        {
            "author": "Andrzej Bialecki",
            "id": "comment-13192407",
            "date": "2012-01-24T19:22:37+0000",
            "content": "Yeah, I was curious about this too. However, this is how CollectionStatistics is defined in Lucene, so it's something that we have to change in Lucene too. "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-13192416",
            "date": "2012-01-24T19:27:28+0000",
            "content": "This is a diff from my best approximation of applying the trunk patch to 3x.  It doesn't compile, but it will probably save someone some time. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13192438",
            "date": "2012-01-24T19:43:42+0000",
            "content": "\nHowever, this is how CollectionStatistics is defined in Lucene, so it's something that we have to change in Lucene too.\n\nTermStatistics too. Lets open a separate issue for this. "
        },
        {
            "author": "Andrzej Bialecki",
            "id": "comment-13194796",
            "date": "2012-01-27T14:38:41+0000",
            "content": "Patch updated to use long types, and properly handle -1's in freqs. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13194814",
            "date": "2012-01-27T14:54:08+0000",
            "content": "Thanks Andrzej: I think it will be nice that all of lucene's scoring algorithms can work in distributed mode.\n\nJust one question about the patch: in StatsUtil I can't tell if termFromString matches termToString?\ntermToString seems to base64 encode the term text (a good idea, since terms can be binary), but I don't\nsee the corresponding decode in termFromString (there is an XXX: comment though).\n "
        },
        {
            "author": "Andrzej Bialecki",
            "id": "comment-13194842",
            "date": "2012-01-27T15:19:06+0000",
            "content": "Hmm, indeed...  I must have switched to toString() for debugging (its easier to eyeball an ascii string than a base64 string  ). This should use base64 throughout. I'll prepare a patch shortly.\n\n(BTW, I'm aware that passing around blobs of base64 inside SolrParams is ugly. I'm open to suggestions how to handle this better). "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13194860",
            "date": "2012-01-27T15:45:26+0000",
            "content": "(BTW, I'm aware that passing around blobs of base64 inside SolrParams is ugly. I'm open to suggestions how to handle this better).\n\nI'd prefer non-base64 at the Solr transport level (e.g. termStats=how,now,brown,cow).  It will be both smaller, and much easier to debug other things.\n\nAlthough Lucene can technically index arbitrary binary now, Solr does not use that anywhere (and won't for 4.0).  It would take a good amount of infrastructure work all over to truly allow that.  If/when we allow arbitrary binary terms, it should be relatively easy to extend the syntax we pick today to allow selectively base64 encoded terms.\n\nThere are already a number of places in Solr where we use StrUtil.join (a comma separated list of strings) to specify a list of terms (both in distrib faceting and distrib search for example).\n "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13194878",
            "date": "2012-01-27T16:05:31+0000",
            "content": "\nAlthough Lucene can technically index arbitrary binary now, Solr does not use that anywhere (and won't for 4.0).\n\nThats not actually true. Collation uses it already. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13194893",
            "date": "2012-01-27T16:29:53+0000",
            "content": "Thats not actually true. Collation uses it already.\n\nHmmm, that's normally just for sorting though.  I wonder if that works with distributed search today?\n\nAnyway, we have a schema - that can allow us to do what makes sense depending on the field (i.e. only use base64 or \\x?? for fields where there will be non-character terms) "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13194899",
            "date": "2012-01-27T16:34:41+0000",
            "content": "Its also used for locale-sensitive range queries (and of course termquery etc works too, but thats not interesting). "
        },
        {
            "author": "Andrzej Bialecki",
            "id": "comment-13194907",
            "date": "2012-01-27T16:47:26+0000",
            "content": "\\x or %xx escaping could be ok, I guess - it's safe, and in most cases it's still readable, unlike base64. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13194910",
            "date": "2012-01-27T16:51:51+0000",
            "content": "Its also used for locale-sensitive range queries\n\nGiven that range queries (and other multi-term queries) are constant scoring and may contain many terms, hopefully we avoid requesting term stats for these? "
        },
        {
            "author": "Andrzej Bialecki",
            "id": "comment-13194915",
            "date": "2012-01-27T16:58:15+0000",
            "content": "hopefully we avoid requesting term stats for these?\nThere is no provision for this yet in the current patch. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13194921",
            "date": "2012-01-27T17:15:22+0000",
            "content": "\nThere is no provision for this yet in the current patch.\n\nThere is nothing different from a MTQ generated BQ than a huge BQ a solr user submits.\nIn my opinion instead of saying \"screw scoring certain types of queries\", this stuff should\nbe done by InExact implementations (and maybe that should be the default, fine). e.g. a nice\nheuristic could look at the local stats and say: sure there are 100 terms but 50 are low-freq,\nlets assume additive constant C for those, batch the other terms into e.g. 5 ranges and only request\nstats on 5 \"surrogate\" terms representative of those groups.\n\nJust make sure any heuristic is always added to what is surely present locally, e.g. distributed\ndocfreq is always >= local docfreq. Then no scoring algorithms will break. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13195619",
            "date": "2012-01-28T20:34:38+0000",
            "content": "There is nothing different from a MTQ generated BQ than a huge BQ a solr user submits.\n\nMulti-term queries like range query, prefix query, etc, do not depend on term stats, and can consist of millions of terms.  It's a waste to attempt to return term stats for them (estimated or not).\n\nIt would also be a shame to use estimates rather than exact numbers for what will be the common case (i.e. when there's really only a couple of terms you need stats for):\n +title:\"blue whale\"  +title_whole:[a TO g}\n  or\n +title:\"blue whale\"  +date:[2001-01-01 TO 2010-01-01}\n\nIdeally, we wouldn't even do a rewrite in order to collect terms - rewrite itself has gotten much more expensive in some circumstances (i.e. iterating the first 350 terms to determine what style of rewrite should be used) "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13195632",
            "date": "2012-01-28T21:36:54+0000",
            "content": "\nMulti-term queries like range query, prefix query, etc, do not depend on term stats, and can consist of millions of terms. \nNo, they cannot.\n\nit can't be millions of terms because a million exceeds the\nboolean max clause count, in which it will always use a filter.\n\n\nIdeally, we wouldn't even do a rewrite in order to collect terms\n\nYou don't have to, Lucene's test case (ShardSearchingTestBase) doesn't do an extra rewrite to collect terms.\n\n@Override\npublic Query rewrite(Query original) throws IOException {\n  final Query rewritten = super.rewrite(original);\n  final Set<Term> terms = new HashSet<Term>();\n  rewritten.extractTerms(terms);\n\n  // Make a single request to remote nodes for term\n  // stats:\n  ...\n  return rewritten;\n}\n\n\n\n\n\n\trewrite itself has gotten much more expensive in some circumstances (i.e. iterating the first 350 terms to determine what style of rewrite should be used)\n\n\nGot any benchmarks to back this up with?\n\nIts incorrect to say rewrite has gotten more expensive? More expensive than what? \nIts the opposite: its actually much faster when rewriting to boolean queries in 4.0 because it always works per-segment. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13195635",
            "date": "2012-01-28T22:36:09+0000",
            "content": "it can't be millions of terms because a million exceeds the boolean max clause count, in which it will always use a filter.\n\nSo depending on exactly how many terms the range query covers, extractTerms may or may not return any.\nSo extractTerms() may return 300 terms the first time, and then after someone adds some docs to the index it may suddenly return 0.\nThis just strengthens the case that we should be consistent and just always ignore the terms from these MTQs.\n\nIts incorrect to say rewrite has gotten more expensive? More expensive than what?\n\nSorry, I wasn't specific enough. I meant compared to back when Solr had it's own RangeFilter and PrefixFilter that it would wrap in a ConstantScoreQuery.  There never was any rewrite-to-boolean-query or consulting the index, so it's obviously a faster rewrite().\n\nBut back to the original question - I still see no reason to request/return/cache terms/stats from these multi-term queries when by definition they should not change the results of the request. "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-13195637",
            "date": "2012-01-28T22:54:41+0000",
            "content": "Sorry, I wasn't specific enough. I meant compared to back when Solr had it's own RangeFilter and PrefixFilter that it would wrap in a ConstantScoreQuery. There never was any rewrite-to-boolean-query or consulting the index, so it's obviously a faster rewrite().\n\nJust set in Solr the rewrite mode of MTQ to CONSTANT_SCORE_FILTER_REWRITE - done. There is no discussion needed and no custom RangeQuery in Solr. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13195638",
            "date": "2012-01-28T23:05:33+0000",
            "content": "Just set in Solr the rewrite mode of MTQ to CONSTANT_SCORE_FILTER_REWRITE - done.\n\nRight - I was considering the best way to do this (passing that info around solr about when to use what method).\nIt solves both issues - relatively expensive rewrites that are not needed, and  ignoring the MTQ terms. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13195644",
            "date": "2012-01-28T23:35:15+0000",
            "content": "\nBut back to the original question - I still see no reason to request/return/cache terms/stats from these multi-term queries when by definition they should not change the results of the request.\n\nMy original point (forgetting about the specifics of MTQ, how things are being scored, or anything) is still that its a general case of Query that can have lots of Terms.\n\nSo if there are concerns about \"lots of terms\", I still think its worth considering having some \nlimits on how many Terms would be exchanged. Maybe BooleanQuery's max clause count is already good\nenough, but another way to do it would be to have an approximate implementation that approximates \nwhen the term count for a query gets too high. "
        },
        {
            "author": "Markus Jelsma",
            "id": "comment-13543008",
            "date": "2013-01-03T15:51:16+0000",
            "content": "Any progress to report or does anyone have a patch that is updated for trunk? "
        },
        {
            "author": "Markus Jelsma",
            "id": "comment-13581387",
            "date": "2013-02-19T15:53:28+0000",
            "content": "Updated patch to build for rev: 1447516 (Mon, 18 Feb 2013)\n\nAll tests seem to pass. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13581945",
            "date": "2013-02-20T04:50:00+0000",
            "content": "Nice. I mentioned this to AB not too long ago, but I'm of the mind to simply commit this. It will default to off, and we can continue to work on it.\n\nSo unless someone steps in, I'll commit what Markus has put up.\n\nMarkus, have you tried this out at all beyond the unit tests - eg on a cluster? "
        },
        {
            "author": "Markus Jelsma",
            "id": "comment-13582022",
            "date": "2013-02-20T08:08:35+0000",
            "content": "No, not yet. Please let me do some real tests, there must be issues, the patch is over a year old!  "
        },
        {
            "author": "Markus Jelsma",
            "id": "comment-13582142",
            "date": "2013-02-20T12:33:25+0000",
            "content": "It doesn't really seem to work, we're seeing lots of NPE's and if a response comes through IDF is not consistent for all terms. Most request return one of the NPE's below. Sometimes it works, and then the second request just fails.\n\n\njava.lang.NullPointerException\n\tat org.apache.solr.search.stats.ExactStatsCache.sendGlobalStats(LRUStatsCache.java:202)\n\tat org.apache.solr.handler.component.QueryComponent.createMainQuery(QueryComponent.java:783)\n\tat org.apache.solr.handler.component.QueryComponent.regularDistributedProcess(QueryComponent.java:618)\n\tat...\n\n\n\n\njava.lang.NullPointerException\n\tat org.apache.solr.search.stats.LRUStatsCache.sendGlobalStats(LRUStatsCache.java:228)\n\tat org.apache.solr.handler.component.QueryComponent.createMainQuery(QueryComponent.java:783)\n\tat org.apache.solr.handler.component.QueryComponent.regularDistributedProcess(QueryComponent.java:618)\n\tat...\n\n\n\nWe also see this one from time to time, it looks like this is thrown is there are `no servers hosting shard`:\n\njava.lang.NullPointerException\n\tat org.apache.solr.search.stats.LRUStatsCache.mergeToGlobalStats(LRUStatsCache.java:112)\n\tat org.apache.solr.handler.component.QueryComponent.updateStats(QueryComponent.java:743)\n\tat org.apache.solr.handler.component.QueryComponent.handleRegularResponses(QueryComponent.java:659)\n\tat org.apache.solr.handler.component.QueryComponent.handleResponses(QueryComponent.java:634)\n\tat ..\n\n\n\nIt's also imposes a huge performance penalty with both LRUStatsCache and ExactStatsCache, if you're used to 40ms response times you'll see the average jump to 2 seconds with very frequent 5 second spikes. Performance stays poor if logging is disabled.\n\nThe logs are also swamped with logs like:\n\n2013-02-20 11:54:48,091 WARN [search.stats.LRUStatsCache] - [http-8080-exec-5] - : ## Missing global colStats info: <FIELD>, using local\n2013-02-20 11:54:48,091 WARN [search.stats.LRUStatsCache] - [http-8080-exec-5] - : ## Missing global termStats info: <FIELD>:<TERM>, using local\n\n\n\nBoth StatsCacheImpls behave like this. Each query logs lines like above. Maybe performance is poor because it tries to look up terms everytime but i'm not sure yet.\n\n\nFinally something crazy i'd like to share \n\n-Infinity = (MATCH) sum of:\n  -Infinity = (MATCH) max plus 0.35 times others of:\n    -Infinity = (MATCH) weight(content_nl:amsterdam^1.6 in 449) [], result of:\n      -Infinity = score(doc=449,freq=1.0 = termFreq=1.0\n), product of:\n        1.6 = boost\n        -Infinity = idf(docFreq=29800090, docCount=-1)\n        1.0 = tfNorm, computed from:\n          1.0 = termFreq=1.0\n          1.2 = parameter k1\n          0.0 = parameter b (norms omitted for field)\n\n\n\nIf someone happens to recognize the issues above, i'm all ears  "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13582178",
            "date": "2013-02-20T13:46:16+0000",
            "content": "Hmm, that makes it look like the current tests for this must be pretty weak then. "
        },
        {
            "author": "Markus Jelsma",
            "id": "comment-13582188",
            "date": "2013-02-20T13:59:47+0000",
            "content": "Things have changed a lot in the past 13 months and i haven't figured it all out yet. I'll try to make sense out of it but some expert opinion and trial on the patch and all would be more than helpful. Is Andrzej not around?  "
        },
        {
            "author": "Markus Jelsma",
            "id": "comment-13673099",
            "date": "2013-06-03T13:29:00+0000",
            "content": "Updated patch for trunk:\nLast Changed Rev: 1488431\nLast Changed Date: 2013-06-01 01:42:51 +0200 (Sat, 01 Jun 2013) "
        },
        {
            "author": "David Boychuck",
            "id": "comment-13803043",
            "date": "2013-10-23T17:31:37+0000",
            "content": "is this patch currently working in 5.0? "
        },
        {
            "author": "Markus Jelsma",
            "id": "comment-13803064",
            "date": "2013-10-23T17:48:16+0000",
            "content": "No, it does not work at all. I did spend some time on it but had other things to do. In the end i removed my (not working) changes and uploaded a patch that at least compiles against the revision of that time.\n "
        },
        {
            "author": "Markus Jelsma",
            "id": "comment-13831398",
            "date": "2013-11-25T12:10:06+0000",
            "content": "Ok, i updated the patch for today's trunk and it actually works now with ExactStatsCache. We now have correct DF for distributed queries.\n\nI removed the perReaderTermContext in ExactStatsCache, this cached the TermContext for new terms. This was a problem because caching it this way meant that any second term got the same DF as the first.\n\nI also added a local boolean to SolrIndexSearcher's collectionStatistics() and termStatistics() to force it to return only local scores. This is a nasty hack to prevent it from returning the other shard's DF. Without this, DF will increase for every other request, in the end it will crash the systems because the number gets too high.\n\nAlso, the warning ## Missing global termStats info: \" + term + \", using local should perhaps not be a warning at all. This gets emitted also for fields not having those terms. The check in returnLocalStats doesn't add terms for docFreq == 0.\n\nAdd <globalStats class=\"org.apache.solr.search.stats.ExactStatsCache\"/> to your solrconfig in the config section to make it work.\n\nPlease check my patch and let's fix this issue so we hopefully can get distributed IDF in Solr 4.7.\n "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13833392",
            "date": "2013-11-27T02:57:03+0000",
            "content": "I'm looking at a couple of the test fails before I go to bed tonight:\n\n\n   [junit4] Tests with failures:\n   [junit4]   - org.apache.solr.handler.component.QueryElevationComponentTest.testGroupedQuery\n   [junit4]   - org.apache.solr.TestDistributedSearch.testDistribSearch\n   [junit4]   - org.apache.solr.search.stats.TestLRUStatsCache.testDistribSearch\n   [junit4]   - org.apache.solr.TestGroupingSearch.testGroupingGroupSortingScore_basicWithGroupSortEqualToSort\n   [junit4]   - org.apache.solr.TestGroupingSearch.testGroupingGroupSortingScore_withTotalGroupCount\n   [junit4]   - org.apache.solr.TestGroupingSearch.testGroupingGroupSortingScore_basic\n   [junit4]   - org.apache.solr.search.stats.TestExactStatsCache.testDistribSearch\n   [junit4]   - org.apache.solr.update.AddBlockUpdateTest.testXML\n   [junit4]   - org.apache.solr.update.AddBlockUpdateTest.testSolrJXML "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13833439",
            "date": "2013-11-27T04:26:38+0000",
            "content": "I did not do a thorough review or anything, but here is a patch...\n\n\n\tI cleaned up a lot of things.\n\tI fixed the things that needed to be fixed for the tests to pass.\n\tI got precommit passing (though I may have added back in a nocommit after).\n\n\n\nAnyway, tests seem to pass for me. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13833476",
            "date": "2013-11-27T05:29:52+0000",
            "content": "More cleanup in this patch. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13833478",
            "date": "2013-11-27T05:31:42+0000",
            "content": "The config you need to use to turn this on is now:\n\n<statsCache class=\"org.apache.solr.search.stats.ExactStatsCache\"/>\n\nIt needs to go in the top level config section. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13833483",
            "date": "2013-11-27T05:34:17+0000",
            "content": "The thread local still scares me ... need to look closer at that. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13842077",
            "date": "2013-12-07T05:00:33+0000",
            "content": "I've got two main concerns - the thread local and it looks like the statscache is not thread safe but shared across threads.\n\nThe threadlocal is concerning because you can have thousands of threads and each will cache how many stats? I wish we could do something better. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13842270",
            "date": "2013-12-07T17:22:17+0000",
            "content": "This patch remove the new thread local by piggy backing on the existing thread local Solr uses for a request (which is already nicely cleaned up per request).\n\nI also attempted to make ExactStatsCache thread safe, but the whole design there needs a review I think.\n\nLRUStatsCache is certainly still not thread safe and needs to be fixed. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13842271",
            "date": "2013-12-07T17:28:46+0000",
            "content": "Markus Jelsma, how was performance with your most recent patch compared to what you first reported? "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13842306",
            "date": "2013-12-07T19:41:31+0000",
            "content": "Whoops - attached the wrong patch this morning. Anyway, here is a new one.\n\n\n\tAttempted to make LRUStatsCache thread safe.\n\n\n\n\n\tLot's of little clean up / little improvements\n\n "
        },
        {
            "author": "Markus Jelsma",
            "id": "comment-13843025",
            "date": "2013-12-09T09:55:41+0000",
            "content": "It is much faster now, even usable. But i haven't tried it in a larger cluster yet. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13844454",
            "date": "2013-12-10T17:39:47+0000",
            "content": "Last patch was doubled - pasted twice I guess. Here is a clean one. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13846728",
            "date": "2013-12-12T20:52:17+0000",
            "content": "Here is my latest work I was playing around with the other night. A lot more cleanup, removed a bunch of dupe code, etc.\n\nI think things are fairly reasonable now given the current design.\n\nI do think we want to look at the design to make sure it's going to work well with the caching impls that we will want to add. "
        },
        {
            "author": "Vitaliy Zhovtyuk",
            "id": "comment-13925341",
            "date": "2014-03-09T22:05:55+0000",
            "content": "Updated to latest trunk.\nCleaned code duplicates. Fixed org.apache.solr.search.stats.TestLRUStatsCache, added test for org.apache.solr.search.stats.ExactSharedStatsCache.\nFixed javadocs. "
        },
        {
            "author": "Markus Jelsma",
            "id": "comment-13925596",
            "date": "2014-03-10T09:35:37+0000",
            "content": "Hi Vitaly, are you sure it still works? I tried your and few older patches again but docCounts are no longer the sum of the cluster size. The GET_STATS query is executed though.\n\nTwo node test cluster:\n\n\n 384841 [qtp1175813699-17] INFO  org.apache.solr.core.SolrCore  \u2013 [collection1] webapp=/solr path=/select params={distrib=false&debug=track&wt=javabin&requestPurpose=GET_TERM_STATS&version=2&rows=10&debugQuery=false&shard.url=http://127.0.1.1:8983/solr/collection1/&NOW=1394444039677&rid=-collection1-1394444039677-12&shards.purpose=2&q=wiki&isShard=true} status=0 QTime=1 \n384848 [qtp1175813699-17] INFO  org.apache.solr.core.SolrCore  \u2013 [collection1] webapp=/solr path=/select params={distrib=false&debug=track&wt=javabin&requestPurpose=GET_TOP_IDS,GET_STATS,GET_TERMS,GET_MLT_RESULTS,SET_TERM_STATS&version=2&rows=10&org.apache.solr.stats.colStats=content_nl,121630,115956,16436279,11372267&org.apache.solr.stats.terms=content_nl:wiki&NOW=1394444039677&shard.url=http://127.0.1.1:8983/solr/collection1/&debugQuery=false&fl=id,score&shards.purpose=5636&rid=-collection1-1394444039677-12&start=0&q=wiki&org.apache.solr.stats.termStats=content_nl:wiki,284,645&isShard=true&fsv=true} hits=138 status=0 QTime=1 \n384863 [qtp1175813699-17] INFO  org.apache.solr.core.SolrCore  \u2013 [collection1] webapp=/solr path=/select params={ids=http://nl.wikipedia.org/wiki/Overleg_sjabloon:Infobox_film,http://nl.wikipedia.org/wiki/Overleg_sjabloon:Navigatie_Bijbel,http://nl.wikipedia.org/wiki/Overleg_help:Gebruik_van_sjablonen,http://nl.wikipedia.org/wiki/Overleg_sjabloon:Citeer_boek,http://nl.wikipedia.org/wiki/Overleg_sjabloon:Wikt&distrib=false&debug=track&wt=javabin&requestPurpose=GET_FIELDS,GET_DEBUG&version=2&rows=10&debugQuery=true&shard.url=http://127.0.1.1:8983/solr/collection1/&NOW=1394444039677&rid=-collection1-1394444039677-12&shards.purpose=320&q=wiki&isShard=true} status=0 QTime=7 \n384870 [qtp1175813699-13] INFO  org.apache.solr.core.SolrCore  \u2013 [collection1] webapp=/solr path=/select params={debugQuery=true&q=wiki} rid=-collection1-1394444039677-12 hits=284 status=0 QTime=33 \n\n\n\n\n\n380242 [qtp1175813699-16] INFO  org.apache.solr.core.SolrCore  \u2013 [collection1] webapp=/solr path=/select params={distrib=false&debug=track&wt=javabin&requestPurpose=GET_TERM_STATS&version=2&rows=10&debugQuery=false&shard.url=http://127.0.1.1:7574/solr/collection1/&NOW=1394444039677&rid=-collection1-1394444039677-12&shards.purpose=2&q=wiki&isShard=true} status=0 QTime=0 \n380249 [qtp1175813699-16] INFO  org.apache.solr.core.SolrCore  \u2013 [collection1] webapp=/solr path=/select params={distrib=false&debug=track&wt=javabin&requestPurpose=GET_TOP_IDS,GET_STATS,GET_TERMS,GET_MLT_RESULTS,SET_TERM_STATS&version=2&rows=10&org.apache.solr.stats.colStats=content_nl,121630,115956,16436279,11372267&org.apache.solr.stats.terms=content_nl:wiki&NOW=1394444039677&shard.url=http://127.0.1.1:7574/solr/collection1/&debugQuery=false&fl=id,score&shards.purpose=5636&rid=-collection1-1394444039677-12&start=0&q=wiki&org.apache.solr.stats.termStats=content_nl:wiki,284,645&isShard=true&fsv=true} hits=146 status=0 QTime=2 \n380263 [qtp1175813699-16] INFO  org.apache.solr.core.SolrCore  \u2013 [collection1] webapp=/solr path=/select params={ids=http://nl.wikipedia.org/wiki/Overleg_sjabloon:Navigatie,http://nl.wikipedia.org/wiki/Overleg_help:Waarom_staat_mijn_bestand_op_de_beoordelingslijst,http://nl.wikipedia.org/wiki/Overleg_help:Wikipediachat,http://nl.wikipedia.org/wiki/Overleg_sjabloon:Co\u00f6rdinaten,http://nl.wikipedia.org/wiki/Overleg_sjabloon:Sjabdoc/doc&distrib=false&debug=track&wt=javabin&requestPurpose=GET_FIELDS,GET_DEBUG&version=2&rows=10&debugQuery=true&shard.url=http://127.0.1.1:7574/solr/collection1/&NOW=1394444039677&rid=-collection1-1394444039677-12&shards.purpose=320&q=wiki&isShard=true} status=0 QTime=6 \n\n\n\nBut i get these scores:\n\n\n12.8123455 = (MATCH) weight(content_nl:wiki in 18636) [], result of:\n  12.8123455 = score(doc=18636,freq=33.0 = termFreq=33.0\n), product of:\n    6.0355678 = idf(docFreq=138, docCount=57897)\n    2.122807 = tfNorm, computed from:\n      33.0 = termFreq=33.0\n      1.2 = parameter k1\n      0.0 = parameter b (norms omitted for field)\n\n\n\n\n12.558066 = (MATCH) weight(content_nl:wiki in 60634) [], result of:\n  12.558066 = score(doc=60634,freq=25.0 = termFreq=25.0\n), product of:\n    5.982207 = idf(docFreq=146, docCount=58059)\n    2.0992365 = tfNorm, computed from:\n      25.0 = termFreq=25.0\n      1.2 = parameter k1\n      0.0 = parameter b (norms omitted for field)\n\n\n\nDid it work for you? "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13925920",
            "date": "2014-03-10T17:25:44+0000",
            "content": "I tried your and few older patches again but docCounts are no longer the sum of the cluster size. \n\nDo you see what is missing in the tests to catch this? "
        },
        {
            "author": "Markus Jelsma",
            "id": "comment-13930406",
            "date": "2014-03-11T14:39:53+0000",
            "content": "No, but i think this happened when the QueryCommand code\n\n    public StatsSource getStatsSource() { return statsSource; }\n    public QueryCommand setStatsSource(StatsSource dfSource) {\n      this.statsSource = dfSource;\n      return this;\n    }\n\n\n\ngot removed. "
        },
        {
            "author": "Vitaliy Zhovtyuk",
            "id": "comment-13956321",
            "date": "2014-04-01T09:53:26+0000",
            "content": "\n\tFixed global stats distribution\n\tAdded assert on query explain (docNum, weight and idf should be the same in distributed tests), this assert is valid on 2nd query only since global stats merged in the end of 1st query.\n\n "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-13971037",
            "date": "2014-04-16T12:56:57+0000",
            "content": "Move issue to Solr 4.9. "
        },
        {
            "author": "Anshum Gupta",
            "id": "comment-14142964",
            "date": "2014-09-22T07:06:34+0000",
            "content": "I'd created a reviewboard request to look and compare the last few patches. Thought I'd share that here.\nhttps://reviews.apache.org/r/25855/ "
        },
        {
            "author": "Anshum Gupta",
            "id": "comment-14149902",
            "date": "2014-09-26T20:02:18+0000",
            "content": "I've uploaded and updated patch that applies to current trunk but has a failing TestLRUStatsCache at the review board.\nI'm trying to get it to work but Vitaliy Zhovtyuk, can you have a look at it too if you have time?\n\nTest Failure\njava.lang.AssertionError: \nExpected :0.7176591\nActual   :0.10904001\n <Click to see difference>\n\tat __randomizedtesting.SeedInfo.seed([C08012850AFBE274:41669C9D7DA48248]:0)\n\tat org.junit.Assert.fail(Assert.java:93)\n\tat org.junit.Assert.failNotEquals(Assert.java:647)\n\tat org.junit.Assert.assertEquals(Assert.java:128)\n\tat org.junit.Assert.assertEquals(Assert.java:147)\n\tat org.apache.solr.search.stats.TestLRUStatsCache.checkResponse(TestLRUStatsCache.java:55)\n\tat org.apache.solr.search.stats.TestDefaultStatsCache.dfQuery(TestDefaultStatsCache.java:102)\n\tat org.apache.solr.search.stats.TestDefaultStatsCache.doTest(TestDefaultStatsCache.java:67)\n\tat org.apache.solr.BaseDistributedSearchTestCase.testDistribSearch(BaseDistributedSearchTestCase.java:875)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\n "
        },
        {
            "author": "Vitaliy Zhovtyuk",
            "id": "comment-14151149",
            "date": "2014-09-28T17:34:54+0000",
            "content": "Wrong patch was attached on 1.04.2014.\nUpdated previous changes to current trunk.\nTestDefaultStatsCache, TestExactSharedStatsCache, TestExactStatsCache, TestLRUStatsCache are passing. "
        },
        {
            "author": "Anshum Gupta",
            "id": "comment-14152329",
            "date": "2014-09-29T21:32:29+0000",
            "content": "Thanks for updating the patch Vitaliy Zhovtyuk.\nThe tests pass now. I'm looking at the updated patch. "
        },
        {
            "author": "Anshum Gupta",
            "id": "comment-14207089",
            "date": "2014-11-11T21:21:11+0000",
            "content": "Updated patch. "
        },
        {
            "author": "Anshum Gupta",
            "id": "comment-14237511",
            "date": "2014-12-08T06:34:26+0000",
            "content": "Updated patch with minor changes. I've also benchmarked this test on my machine with 150k Jeopardy questions dataset over 2 shards with a replication factor of 1. The times aren't off on that one.\n\nIt'd be good if someone else can also look at it else I'd like to brush it a little more, document it and commit. "
        },
        {
            "author": "Anshum Gupta",
            "id": "comment-14246473",
            "date": "2014-12-15T09:07:55+0000",
            "content": "Unless there are objections in the next few days, I think we should get this in now. This would not be enabled by default i.e. LocalStatsCache impl would be used anyways. "
        },
        {
            "author": "Anshum Gupta",
            "id": "comment-14250963",
            "date": "2014-12-18T01:31:28+0000",
            "content": "I plan on committing this sometime over the weekend. "
        },
        {
            "author": "Anshum Gupta",
            "id": "comment-14255085",
            "date": "2014-12-21T07:35:33+0000",
            "content": "Final patch. Nothing really changed form the last one but just updated it to be from the latest version of trunk. Will commit this tomorrow morning. "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14255502",
            "date": "2014-12-22T07:05:36+0000",
            "content": "Commit 1647253 from Anshum Gupta in branch 'dev/trunk'\n[ https://svn.apache.org/r1647253 ]\n\nSOLR-1632: Distributed IDF, finally. "
        },
        {
            "author": "Anshum Gupta",
            "id": "comment-14255504",
            "date": "2014-12-22T07:07:36+0000",
            "content": "Thanks to everyone who's contributed on this one! The list is long \nI've committed this to trunk, if all stays well, will commit it into 5x later in the (coming) week. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-14255813",
            "date": "2014-12-22T15:08:35+0000",
            "content": "WhoooHooooo! "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-14256107",
            "date": "2014-12-22T19:47:24+0000",
            "content": "The commit is too large to digest easily.  I assume this is on by default?  Can it be enabled and disabled?\n\nI will likely be using this once it's available, but do we have any idea what the performance impact is? "
        },
        {
            "author": "Anshum Gupta",
            "id": "comment-14256121",
            "date": "2014-12-22T19:56:59+0000",
            "content": "This isn't switched on by default as it certainly comes at some cost (there are no free lunches, remember?) \n\nIt can be switched on by specifying what implementation you want via top-level solrconfig setting or System property e.g. here is how you can set it to use ExactStatsCache implementation (non-cached):\n\n <statsCache class=\"org.apache.solr.search.stats.ExactStatsCache\"/>\n\n\n\nAbout the performance impact, I tested it on my machine (which is not really a great thing to do as there's barely any possibility of network issues here) for about 6mn (real and mocked up Jeopardy questions dataset) docs and regular queries and the performance impact was barely noticeable.\n\nI still need to document this (which I'll add to the ref guide once this makes it into 5x) and I suppose things would be easier to understand for the end user then. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-14256378",
            "date": "2014-12-23T00:51:49+0000",
            "content": "We should get some results across real machines, but I also turned my micro bench work onto this. I didn't confirm that the settings are actually taking affect, or review the latest work, but I ran the benchmark twice, once with LocalStatsCache and once with ExactStatsCache. \n\n<statsCache class=\"org.apache.solr.search.stats.ExactStatsCache\"/>\n<statsCache class=\"org.apache.solr.search.stats.LocalStatsCache\"/>\n\nThe test uses two machines, one to create and send the docs/queries, another to run the Solr JVMs. I ran a query test using a ton of wikipedia data across 6 jvm instances, 6 shards, no replication. I indexed a ton of docs, and then used a bunch of threads and bunch of CloudSolrServer's to pound in some queries. Performance appeared nearly identical. "
        },
        {
            "author": "Anshum Gupta",
            "id": "comment-14256394",
            "date": "2014-12-23T01:03:11+0000",
            "content": "Right, I saw similar behavior on my tests. I think the impact really would be when there's a ton of query terms across multiple shards that actually use the network. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-14259225",
            "date": "2014-12-26T21:49:19+0000",
            "content": "This isn't switched on by default as it certainly comes at some cost\n\nWhat would be really nice is to enable this on a per-request basis.  Perhaps via \"globalStats=true\"\nWe can open up a new issue if it's difficult enough... "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14260436",
            "date": "2014-12-29T20:57:04+0000",
            "content": "Commit 1648428 from Anshum Gupta in branch 'dev/branches/branch_5x'\n[ https://svn.apache.org/r1648428 ]\n\nSOLR-1632: Distributed IDF, finally. (merge from trunk) "
        },
        {
            "author": "Anshum Gupta",
            "id": "comment-14282225",
            "date": "2015-01-19T07:44:15+0000",
            "content": "Yonik Seeley: I did give it a thought but it would be tricky to support something like  stats=<implementation> for each request. We could however have something like  'stats=local' or 'stats=global' where in the later case, it uses the implementation specified in the config. But yes, we could evaluate that more. "
        },
        {
            "author": "Anshum Gupta",
            "id": "comment-14360983",
            "date": "2015-03-13T19:33:35+0000",
            "content": "Marking as resolved. "
        },
        {
            "author": "Anshum Gupta",
            "id": "comment-14360984",
            "date": "2015-03-13T19:33:50+0000",
            "content": "Closing the issue. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-14737856",
            "date": "2015-09-10T00:16:20+0000",
            "content": "LUCENE-6758 removed part of the test of this issue:\n\n\n--- lucene/dev/trunk/solr/core/src/test/org/apache/solr/search/stats/TestDefaultStatsCache.java\t2015/09/09 03:13:44\t1701894\n+++ lucene/dev/trunk/solr/core/src/test/org/apache/solr/search/stats/TestDefaultStatsCache.java\t2015/09/09 03:16:15\t1701895\n@@ -79,10 +79,6 @@\n     if (clients.size() == 1) {\n       // only one shard\n       assertEquals(controlScore, shardScore);\n-    } else {\n-      assertTrue(\"control:\" + controlScore.floatValue() + \" shard:\"\n-          + shardScore.floatValue(),\n-          controlScore.floatValue() > shardScore.floatValue());\n     }\n   }\n\n\n\nhttp://svn.apache.org/viewvc?view=revision&revision=1701895\n\nWas it testing something important, and can it be replaced with something else? "
        },
        {
            "author": "Varun Thacker",
            "id": "comment-14805205",
            "date": "2015-09-18T08:24:20+0000",
            "content": "I think the check should be modified from ontrolScore.floatValue() > shardScore.floatValue()) to controlScore.floatValue() >= shardScore.floatValue()) .\n\nI understand the motivation here that once a term starts getting 'rare'  the score will be higher as the stats are just from the individual shards. \n\nThe first part of the test doesn't seem to be triggering this though:\n\n\ndel(\"*:*\");\nfor (int i = 0; i < clients.size(); i++) {\n      int shard = i + 1;\n      for (int j = 0; j <= i; j++) {\n        index_specific(i, id, docId++, \"a_t\", \"one two three\",\n            \"shard_i\", shard);\n      }\n    }\n\n\n "
        },
        {
            "author": "blackwing",
            "id": "comment-15635553",
            "date": "2016-11-04T07:37:21+0000",
            "content": "I've activated distrubted idf. I've two shards for my collection, shard1 contains 1000 docs and shard2 contains 800 doc.\n\nSo maxDoc to calculate idf for a particular doc score is 1000+800? "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-15636656",
            "date": "2016-11-04T15:18:21+0000",
            "content": "Please ask usage questions on the user's list, see \"mailing lists\" here: http://lucene.apache.org/solr/resources.html\n\n\nYou'll get a lot more eyeballs on the question and likely a much faster answer. "
        }
    ]
}