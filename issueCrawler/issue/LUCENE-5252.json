{
    "id": "LUCENE-5252",
    "title": "add NGramSynonymTokenizer",
    "details": {
        "components": [
            "modules/analysis"
        ],
        "fix_versions": [],
        "affect_versions": "None",
        "priority": "Minor",
        "labels": "",
        "type": "New Feature",
        "resolution": "Unresolved",
        "status": "Open"
    },
    "description": "I'd like to propose that we have another n-gram tokenizer which can process synonyms. That is NGramSynonymTokenizer. Note that in this ticket, the gram size is fixed, i.e. minGramSize = maxGramSize.\n\nToday, I think we have the following problems when using SynonymFilter with NGramTokenizer. \nFor purpose of illustration, we have a synonym setting \"ABC, DEFG\" w/ expand=true and N = 2 (2-gram).\n\n\n\tThere is no consensus (I think  how we assign offsets to generated synonym tokens DE, EF and FG when expanding source token AB and BC.\n\tIf the query pattern looks like ABCY, it cannot be matched even if there is a document \"\u2026ABCY\u2026\" in index when autoGeneratePhraseQueries set to true, because there is no \"CY\" token (but \"GY\" is there) in the index.\n\n\n\nNGramSynonymTokenizer can solve these problems by providing the following methods.\n\n\n\tNGramSynonymTokenizer reads synonym settings (synonyms.txt) and it doesn't tokenize registered words. e.g.\n\n\n\n\n\n\nsource text\nNGramTokenizer+SynonymFilter\nNGramSynonymTokenizer\n\n\nABC\nAB/DE/BC/EF/FG\nABC/DEFG\n\n\n\n\n\n\n\tThe back and forth of the registered words, NGramSynonymTokenizer generates extra tokens w/ posInc=0. e.g.\n\n\n\n\n\n\nsource text\nNGramTokenizer+SynonymFilter\nNGramSynonymTokenizer\n\n\nXYZABC123\nXY/YZ/ZA/AB/DE/BC/EF/C1/FG/12/23\nXY/YZ/Z/ABC/DEFG/1/12/23\n\n\n\n\n\nIn the above sample, \"Z\" and \"1\" are the extra tokens.",
    "attachments": {
        "LUCENE-5252_4x.patch": "https://issues.apache.org/jira/secure/attachment/12606270/LUCENE-5252_4x.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2013-10-02T09:09:53+0000",
            "content": "The draft patch without tests. As I don't have Java 7 environment for now, the patch is based on 4x branch.\n\nWhen NGramSynonymTokenizer was developed in RONDHUIT, it used double array trie for the synonym dictionary.\n\nI've tried to convert the code to Lucene's FST. As this is the first experience of FST for me, any inefficient code may exist. Comments are welcome! ",
            "author": "Koji Sekiguchi",
            "id": "comment-13783754"
        },
        {
            "date": "2013-10-03T07:28:11+0000",
            "content": "New patch that has tests.\n\nBecause the original test was developed in RONDHUIT and it includes test codes for not only NGramSynonymTokenizer but also synonym dictionary, the attached tests may be redundant in terms of SynonymMap. ",
            "author": "Koji Sekiguchi",
            "id": "comment-13784888"
        },
        {
            "date": "2013-10-11T13:27:59+0000",
            "content": "Fix a bug regarding ignoreCase in the attached patch. ",
            "author": "Koji Sekiguchi",
            "id": "comment-13792612"
        },
        {
            "date": "2013-10-15T09:12:27+0000",
            "content": "Fix code regarding one-way synonym (aaa=>bbb). ",
            "author": "Koji Sekiguchi",
            "id": "comment-13795021"
        },
        {
            "date": "2013-10-18T13:55:37+0000",
            "content": "New patch. As for some reason, I give up to support one-way synonym in NGramSynonymTokenizer, I removed indexMode parameter in this patch. ",
            "author": "Koji Sekiguchi",
            "id": "comment-13799109"
        },
        {
            "date": "2013-10-18T13:59:48+0000",
            "content": "Oops, replace the previous funny name by this patch. Sorry for the noise. ",
            "author": "Koji Sekiguchi",
            "id": "comment-13799113"
        }
    ]
}