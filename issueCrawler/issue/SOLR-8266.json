{
    "id": "SOLR-8266",
    "title": "Remove Java Serialization from the Streaming API",
    "details": {
        "components": [],
        "type": "Improvement",
        "labels": "",
        "fix_versions": [],
        "affect_versions": "None",
        "status": "Closed",
        "resolution": "Implemented",
        "priority": "Major"
    },
    "description": "This is being done mainly for security reasons but it's also architecturally the right thing to do.\n\nGoing forward only Streaming Expressions will be used to serialize Streaming API Objects.",
    "attachments": {
        "SOLR-8266.patch": "https://issues.apache.org/jira/secure/attachment/12776034/SOLR-8266.patch",
        "SOLR-8266-comment-out-testParallelEOF.patch": "https://issues.apache.org/jira/secure/attachment/12776168/SOLR-8266-comment-out-testParallelEOF.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2015-11-10T13:20:22+0000",
            "author": "Jason Gerlowski",
            "content": "I can write a patch to try and get the ball rolling on this, unless you've started on it Joel? ",
            "id": "comment-14998545"
        },
        {
            "date": "2015-11-10T13:39:29+0000",
            "author": "Joel Bernstein",
            "content": "I haven't started. Feel free to start working on a patch. Here are the places that will need to be changed:\n\n1) StreamHandler: Remove code that handles Java de-serialization. Always use Streaming Expressions.\n2) ParallelStream: Remove code that handles Java serialization. Always use Streaming Expressions.\n3) StreamingTest: Change all parallels tests so that the StreamFactory is properly configured and added to the StreamContext. Then set the StreamContext on to the TupleStream before calling the getTuples() method. The StreamHandler does this logic so you can copy the behavior from there.\n\nI'll be happy to review your work. ",
            "id": "comment-14998582"
        },
        {
            "date": "2015-11-17T02:29:38+0000",
            "author": "Jason Gerlowski",
            "content": "Quick update- I haven't had time to get around to this yet.  I'm still happy to take a look, but I won't be able to pick it up in the next few days, and I don't want to deter anyone else from working on it in the meantime.\n\nI'll comment again if I'm able to start on it. ",
            "id": "comment-15007877"
        },
        {
            "date": "2015-12-06T15:04:05+0000",
            "author": "Jason Gerlowski",
            "content": "After having some time to read up on the Streaming API/Expression stuff, I've now got enough context to pick this up again.  Should have a patch up later this morning. ",
            "id": "comment-15043915"
        },
        {
            "date": "2015-12-07T05:18:54+0000",
            "author": "Jason Gerlowski",
            "content": "Making the first two changes Joel laid out (StreamHandler and ParallelStream) seemed easy.\n\nI'm having a little more trouble with the third piece of this patch- tweaking StreamingTest's use of parallel streams to use a properly configured StreamFactory/StreamContext.\n\nThe current patch gets through several of the parallel-stream tests, before hitting testParallelEOF and failing with the follow stack trace:\n\n\njava.io.IOException: java.util.concurrent.ExecutionException: java.io.IOException: --> https://127.0.0.1:35540/collection1/:Invalid stream expression count(merge(search(collection1,q=\"id:(4 1 8 7 9)\",fl=\"id,a_s,a_i\",sort=\"a_i asc\",partitionKeys=a_i,zkHost=\"127.0.0.1:36053/solr\"),search(collection1,q=\"id:(0 2 3 6)\",fl=\"id,a_s,a_i\",sort=\"a_i asc\",partitionKeys=a_i,zkHost=\"127.0.0.1:36053/solr\"),on=\"a_i asc\")) - function 'count' is unknown (not mapped to a valid TupleStream)\n\tat __randomizedtesting.SeedInfo.seed([19FC8C86B647325A:E5A7AB021C6ECB2F]:0)\n\tat org.apache.solr.client.solrj.io.stream.CloudSolrStream.openStreams(CloudSolrStream.java:353)\n\tat org.apache.solr.client.solrj.io.stream.CloudSolrStream.open(CloudSolrStream.java:234)\n\tat org.apache.solr.client.solrj.io.stream.StreamingTest.getTuples(StreamingTest.java:1821)\n\tat org.apache.solr.client.solrj.io.stream.StreamingTest.testParallelEOF(StreamingTest.java:1697)\n\tat org.apache.solr.client.solrj.io.stream.StreamingTest.streamTests(StreamingTest.java:1795)\n\n\n\n\nI've still got some investigation to do here; probably just overlooking something simple.  But it's late here, and I'd like to upload my progress so I can continue from a different computer in the morning.  (And if anyone chimes in with thoughts/advice, all the better). ",
            "id": "comment-15044389"
        },
        {
            "date": "2015-12-07T12:34:59+0000",
            "author": "Joel Bernstein",
            "content": "Jason,\n\nThe key part of the error message is: \" function 'count' is unknown (not mapped to a valid TupleStream)\"\n\nThe StreamFactory has to have each function mapped.  ",
            "id": "comment-15044847"
        },
        {
            "date": "2015-12-07T13:09:03+0000",
            "author": "Jason Gerlowski",
            "content": "Yeah, I'd keyed in to that part of the error message too.  Looking at StreamingTest, it looks like the StreamFactory does have a \"count\" mapping specified already: .withFunctionName(\"count\", RecordCountStream.class).\n\nSo either that line doesn't do what I thought it did, or something else is up here.\n\nBut in any case this is a good excuse to dig a little deeper into the streaming code.  Will be taking another pass this afternoon. ",
            "id": "comment-15044882"
        },
        {
            "date": "2015-12-07T13:16:26+0000",
            "author": "Dennis Gove",
            "content": "While that mapping is setup in the test you've got to remember that in a parallel situation the expression is passed off to a different process which doesn't use the factory created in the test. Instead it uses a factory created in StreamHandler. That one has some defaults set and also reads solrconfig.xml to get any new mappings. Check that factory to make sure count is mapped there. I've tried to keep the default up to date with all default stream classes but may have missed some. \n\nThis setup is there so that people can add their own implementation of both streams and expressions (and really anything else that is in the Expressible hierarchy).  ",
            "id": "comment-15044899"
        },
        {
            "date": "2015-12-07T15:08:32+0000",
            "author": "Joel Bernstein",
            "content": "Just checked and the StreamHandler is using the CountMetric. It may be that this test is incompatible with the current StreamHandler setup.\n\nProbably best to just comment it out for now. If you run into other test errors dealing with count comment them out as well.\n\nI'll take a look a those tests when I review the patch.\n ",
            "id": "comment-15045055"
        },
        {
            "date": "2015-12-07T20:21:06+0000",
            "author": "Jason Gerlowski",
            "content": "Thanks for the early look/help guys.  I've updated the patch to align with your suggestions.  The tests all pass now, with the caveat that I had to comment out the testParallelEOF call in testStreams().  Everything else seems to work fine.\n\nWhile I'm confident in the code I wrote, I do have some questions about how this code is working:\n\n1.) I just wanted to double-check my understanding of the StreamFactory configuration discrepancies causing the stack trace I mentioned above.\n\nStreamFactory is used to convert between TupleStreams and StreamExpressionParameters and are used in both SolrJ ( ParallelStream for example) and SOLR (StreamHandler).  These factories need to be in sync.  If not, SolrJ can end up sending serialized values to Solr that it doesn't know what to do with (as in the conflicting \"count\" types from a few comments ago).\n\nJust trying to make sure I understand the big picture, so I can make edits with more confidence next time.\n\n2.) I noticed that StreamFactory.withFunctionName() takes any Class as it's second argument.  Is there any value in narrowing the type of that parameter, so that it's harder to misconfigure StreamFactory?  (i.e. withFunctionName(String name, Class<? extends Expressible> clazz)).\n\n3.) StreamingTest has a single test that triggers 20ish independent sub-tests (e.g. testParallelEOF, testStatsStream).  Updating these tests to use the StreamFactory was a bit more painful that it probably could've been.  With the sub-tests all bundled together, the process for fixing them looked like: (a) run them all, (b) wait for a failure, (c) scroll back through the output to see which clause failed, (d) fix and repeat.  Had the sub-tests been separate JUnit tests, identifying the failing pieces and fixing them would've been easier.  Is there a historical reason theses tests have all been grouped together (performance/overhead for example)?  If not, do you think there would be any pushback on splitting these test clauses apart (as a part of a separate JIRA). ",
            "id": "comment-15045641"
        },
        {
            "date": "2015-12-07T20:58:19+0000",
            "author": "Joel Bernstein",
            "content": "#1:  You've got the big picture right.\n\n#2: Probably a good idea.\n\n#3: The rather unwieldy StreamingTest will eventually be split into smaller test cases, one for each stream. Same with the StreamingExpressions tests. We should probably add a ticket for this.  ",
            "id": "comment-15045715"
        },
        {
            "date": "2015-12-07T21:04:41+0000",
            "author": "Joel Bernstein",
            "content": "Jason Gerlowski, thanks for patch!\n\nI'll will review it in the next day or two. You didn't mention but I'm assuming this is a trunk patch?\n\nAlso typically you would update the same patch file name (SOLR-8266.patch) and jira will display them all. I would then pick your latest patch to apply. Don't worry about it in this case, I'll just take your latest patch file.\n ",
            "id": "comment-15045725"
        },
        {
            "date": "2015-12-08T02:33:06+0000",
            "author": "Jason Gerlowski",
            "content": "No problem; hopefully you're still as thankful after giving it a review :-p\n\nI did write it against trunk, though I can put it on top of another branch if you'd prefer.\n\nI was aware of the patch naming convention.  I broke it in an effort to call out that this patch contains a commented out test, and (probably? maybe?) shouldn't be committed as-is.  If that break from convention isn't worthwhile though, I'll stop doing that sort of thing.  Still learning the ropes here a bit.\n\nAs for the questions/change-suggestions in my earlier comment, I'll throw together JIRAs for those and toss up a starter patch on them. ",
            "id": "comment-15046221"
        },
        {
            "date": "2015-12-08T02:55:43+0000",
            "author": "Mike Drob",
            "content": "I was aware of the patch naming convention. I broke it in an effort to call out that this patch contains a commented out test, and (probably? maybe?) shouldn't be committed as-is. If that break from convention isn't worthwhile though, I'll stop doing that sort of thing. Still learning the ropes here a bit.\n\nI've seen folks put a //nocommit tag to intentionally fail the validation check in cases like these. ",
            "id": "comment-15046241"
        },
        {
            "date": "2015-12-09T18:32:05+0000",
            "author": "Joel Bernstein",
            "content": "The patch looks great. I changed the testParallelEOF method to not test for count. Now it just tests that an EOF Tuple is collected from each worker. No current streams actually use the EOF Tuples from the workers so this is really only a place holder until we have real functionality.\n\nRunning all tests and precommit and then I plan to commit.\n ",
            "id": "comment-15049144"
        },
        {
            "date": "2015-12-09T19:42:55+0000",
            "author": "Joel Bernstein",
            "content": "As this ticket also removes the security risk associated with Object serialization, I plan to also uncomment the /stream handler in the sample solrconfig.xml so the SQL interface etc... will be operational out of the box.\n\nThe /stream handler now only excepts a Streaming Expression query and returns json. ",
            "id": "comment-15049265"
        },
        {
            "date": "2015-12-09T19:52:29+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1718947 from Joel Bernstein in branch 'dev/trunk'\n[ https://svn.apache.org/r1718947 ]\n\nSOLR-8266: Remove Java Serialization from the Streaming API ",
            "id": "comment-15049290"
        },
        {
            "date": "2015-12-09T19:55:51+0000",
            "author": "Joel Bernstein",
            "content": "Thanks Jason Gerlowski! ",
            "id": "comment-15049293"
        },
        {
            "date": "2015-12-17T12:31:36+0000",
            "author": "Jason Gerlowski",
            "content": "I've added a patch addressing #2 in SOLR-8385.\n\nI've added a patch addressing #3 in SOLR-8432. ",
            "id": "comment-15061984"
        }
    ]
}