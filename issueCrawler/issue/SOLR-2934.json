{
    "id": "SOLR-2934",
    "title": "Problem with Solr Hunspell with French Dictionary",
    "details": {
        "affect_versions": "3.5",
        "status": "Closed",
        "fix_versions": [
            "4.8",
            "6.0"
        ],
        "components": [
            "Schema and Analysis"
        ],
        "type": "Bug",
        "priority": "Major",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "I'm trying to add the HunspellStemFilterFactory to my Solr project. \nI'm trying this on a fresh new download of Solr 3.5.\nI downloaded french dictionary here (found it from here): http://www.dicollecte.org/download/fr/hunspell-fr-moderne-v4.3.zip\n\nBut when I start Solr and go to the Solr Analysis, an error occurs in Solr.\n\nIs there the trace : \njava.lang.RuntimeException: Unable to load hunspell data! [dictionary=en_GB.dic,affix=fr-moderne.aff]\n\tat org.apache.solr.analysis.HunspellStemFilterFactory.inform(HunspellStemFilterFactory.java:82)\n\tat org.apache.solr.core.SolrResourceLoader.inform(SolrResourceLoader.java:546)\n\tat org.apache.solr.schema.IndexSchema.<init>(IndexSchema.java:126)\n\tat org.apache.solr.core.CoreContainer.create(CoreContainer.java:461)\n\tat org.apache.solr.core.CoreContainer.load(CoreContainer.java:316)\n\tat org.apache.solr.core.CoreContainer.load(CoreContainer.java:207)\n\tat org.apache.solr.core.CoreContainer$Initializer.initialize(CoreContainer.java:130)\n\tat org.apache.solr.servlet.SolrDispatchFilter.init(SolrDispatchFilter.java:94)\n\tat org.mortbay.jetty.servlet.FilterHolder.doStart(FilterHolder.java:97)\n\tat org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)\n\tat org.mortbay.jetty.servlet.ServletHandler.initialize(ServletHandler.java:713)\n\tat org.mortbay.jetty.servlet.Context.startContext(Context.java:140)\n\tat org.mortbay.jetty.webapp.WebAppContext.startContext(WebAppContext.java:1282)\n\tat org.mortbay.jetty.handler.ContextHandler.doStart(ContextHandler.java:518)\n\tat org.mortbay.jetty.webapp.WebAppContext.doStart(WebAppContext.java:499)\n\tat org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)\n\tat org.mortbay.jetty.handler.HandlerCollection.doStart(HandlerCollection.java:152)\n\tat org.mortbay.jetty.handler.ContextHandlerCollection.doStart(ContextHandlerCollection.java:156)\n\tat org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)\n\tat org.mortbay.jetty.handler.HandlerCollection.doStart(HandlerCollection.java:152)\n\tat org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)\n\tat org.mortbay.jetty.handler.HandlerWrapper.doStart(HandlerWrapper.java:130)\n\tat org.mortbay.jetty.Server.doStart(Server.java:224)\n\tat org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)\n\tat org.mortbay.xml.XmlConfiguration.main(XmlConfiguration.java:985)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n\tat java.lang.reflect.Method.invoke(Unknown Source)\n\tat org.mortbay.start.Main.invokeMain(Main.java:194)\n\tat org.mortbay.start.Main.start(Main.java:534)\n\tat org.mortbay.start.Main.start(Main.java:441)\n\tat org.mortbay.start.Main.main(Main.java:119)\n\nCaused by: java.lang.StringIndexOutOfBoundsException: String index out of range: 3\n\tat java.lang.String.charAt(Unknown Source)\n\tat org.apache.lucene.analysis.hunspell.HunspellDictionary$DoubleASCIIFlagParsingStrategy.parseFlags(HunspellDictionary.java:382)\n\tat org.apache.lucene.analysis.hunspell.HunspellDictionary.parseAffix(HunspellDictionary.java:165)\n\tat org.apache.lucene.analysis.hunspell.HunspellDictionary.readAffixFile(HunspellDictionary.java:121)\n\tat org.apache.lucene.analysis.hunspell.HunspellDictionary.<init>(HunspellDictionary.java:64)\n\tat org.apache.solr.analysis.HunspellStemFilterFactory.inform(HunspellStemFilterFactory.java:46)\n\n\nI can't find where the problem is. It seems like my dictionary isn't well written for hunspell, but I tried with two different dictionaries, and I had the same problem.\nI also tried with an english dictionary, and ... it works !\nSo I think that my french dictionary is wrong for hunspell, but I don't know why ...\n\nCan you help me ?",
    "attachments": {
        "en_GB.aff": "https://issues.apache.org/jira/secure/attachment/12511682/en_GB.aff",
        "en_GB.dic": "https://issues.apache.org/jira/secure/attachment/12511683/en_GB.dic"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Erick Erickson",
            "id": "comment-13160886",
            "date": "2011-12-01T12:55:29+0000",
            "content": "Please raise issues like this on the solr user's list (solr-user@lucene.apache.org) first rather than raising a JIRA, JIRAs are for bugs/improvements rather than this kind of issue. If the users list results indicate a problem (rather than a user/data error) exists, then feel free to rais a JIRA. "
        },
        {
            "author": "Chris Male",
            "id": "comment-13160887",
            "date": "2011-12-01T12:58:13+0000",
            "content": "Hey Erick,\n\nI asked Nathan to open this issue as he reported it on the mailing list.  I want to evaluate whether the problem is in our codebase. "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13160888",
            "date": "2011-12-01T13:00:02+0000",
            "content": "Yep, I just saw that and tried to re-open the issue but you beat me to it! I should probably read the user's list before the dev list each morning!\n\nMy mistake. "
        },
        {
            "author": "Chris Male",
            "id": "comment-13160889",
            "date": "2011-12-01T13:01:19+0000",
            "content": "No worries  "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13160900",
            "date": "2011-12-01T13:17:55+0000",
            "content": "Might also be a good idea to document somewhere that not all languages' encodings work correctly at the moment.\n\nSome of these are crazy-complicated (e.g. hungarian).  "
        },
        {
            "author": "Chris Male",
            "id": "comment-13160902",
            "date": "2011-12-01T13:20:26+0000",
            "content": "Great idea "
        },
        {
            "author": "Markus Jelsma",
            "id": "comment-13192162",
            "date": "2012-01-24T14:04:15+0000",
            "content": "We've seen issues with quite a few dic files as well but the stacktrace makes it difficult to find the error. NumberFormatExceptions (da_DK) are easy as they print the bad number but ArrayOutOfBoundExceptions (nl_NL) are almost impossible to debug. We also see ParseExceptions such as (en_GB):\n\nCaused by: java.text.ParseException: The first non-comment line in the affix file must be a 'SET charset', was: 'FLAG num'\n        at org.apache.lucene.analysis.hunspell.HunspellDictionary.getDictionaryEncoding(HunspellDictionary.java:262)\n        at org.apache.lucene.analysis.hunspell.HunspellDictionary.<init>(HunspellDictionary.java:101)\n        at org.apache.solr.analysis.HunspellStemFilterFactory.inform(HunspellStemFilterFactory.java:80)\n        ... 31 more\n\nand UnsupportedCharsetException (th_TH):\n\nCaused by: java.nio.charset.UnsupportedCharsetException: TIS620-2533\n        at java.nio.charset.Charset.forName(Charset.java:505)\n        at org.apache.lucene.analysis.hunspell.HunspellDictionary.getJavaEncoding(HunspellDictionary.java:275)\n        at org.apache.lucene.analysis.hunspell.HunspellDictionary.<init>(HunspellDictionary.java:102)\n        at org.apache.solr.analysis.HunspellStemFilterFactory.inform(HunspellStemFilterFactory.java:80)\n        ... 31 more\n\nIt seems there are many different issues with the provided dic and aff files and some seem to work and some don't seem to work at all.  "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13192194",
            "date": "2012-01-24T14:53:18+0000",
            "content": "\nIt seems there are many different issues with the provided dic and aff files and some seem to work and some don't seem to work at all.\n\nWhat does this mean? We don't provide any dic and aff files! "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13192210",
            "date": "2012-01-24T15:26:22+0000",
            "content": "Where did you get your en_GB dictionary? The one from openoffice has as first line 'SET ISO8859-1'.\nSo if you want bugs fixed with dictionaries, which anyone can make and can be buggy, you must upload \nthem to this issue (don't check the box), because otherwise we have nothing to work with.\n\nThere is no point in worrying about adding aliases/matching up charset naming for Thai.\nThe thai spell dictionary is just a list of words (nothing in the .aff except 4 replacement rules\nfor spellchecking), so this whole filter will be a no-op with that dictionary.\n\n\nSET TIS620-2533\n\nREP 4\nREP \u0e17\u0e23 \u0e0b\nREP \u0e0b \u0e17\u0e23\nREP \u0e2a \u0e0b\nREP \u0e0b \u0e2a\n\n "
        },
        {
            "author": "Markus Jelsma",
            "id": "comment-13192211",
            "date": "2012-01-24T15:26:57+0000",
            "content": "I'm sorry, it means the packages available at OpenOffice. "
        },
        {
            "author": "Markus Jelsma",
            "id": "comment-13192214",
            "date": "2012-01-24T15:30:02+0000",
            "content": "\nCaused by: java.text.ParseException: The first non-comment line in the affix file must be a 'SET charset', was: 'FLAG num'\n        at org.apache.lucene.analysis.hunspell.HunspellDictionary.getDictionaryEncoding(HunspellDictionary.java:262)\n        at org.apache.lucene.analysis.hunspell.HunspellDictionary.<init>(HunspellDictionary.java:101)\n        at org.apache.solr.analysis.HunspellStemFilterFactory.inform(HunspellStemFilterFactory.java:80)\n        ... 31 more\n\n\n\nThis is thrown by the en_GB available at OpenOffice. \nhttp://extensions.services.openoffice.org/en/project/dict-en-fixed "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13192216",
            "date": "2012-01-24T15:33:37+0000",
            "content": "That page doesnt work for me.\n\n\nSo if you want bugs fixed with dictionaries, which anyone can make and can be buggy, you must upload\nthem to this issue (don't check the box), because otherwise we have nothing to work with. "
        },
        {
            "author": "Markus Jelsma",
            "id": "comment-13192221",
            "date": "2012-01-24T15:42:45+0000",
            "content": "Indeed! Strange. If you go there via:\nhttp://extensions.services.openoffice.org/en/dictionaries\n\nand this anchor:\nEnglish dictionaries with fixed dash handling and new ligature and phonetic suggestion support\n\nyou'll end up on the same page without error. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13192231",
            "date": "2012-01-24T16:05:04+0000",
            "content": "When I click that page it just links to http://extensions.services.openoffice.org/en/project/dict-en-fixed and gives the same error.\n\nCan you upload your copy? "
        },
        {
            "author": "Markus Jelsma",
            "id": "comment-13192240",
            "date": "2012-01-24T16:11:31+0000",
            "content": "en_GB.aff and en_GB.dic files from openoffice.org. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13192246",
            "date": "2012-01-24T16:16:30+0000",
            "content": "I see, indeed this has no CHARSET line.\n\nI think the only solution is to allow the user to manually provide this as a parameter in such cases. "
        },
        {
            "author": "Br\u00e1ulio Bhavamitra",
            "id": "comment-13207685",
            "date": "2012-02-14T12:59:48+0000",
            "content": "the same is happening with pt_BR dict http://artfiles.org/openoffice.org/contrib/dictionaries/pt_BR.zip "
        },
        {
            "author": "Ludovic Boutros",
            "id": "comment-13284322",
            "date": "2012-05-28T08:33:20+0000",
            "content": "For the french dictionary for instance, if I understand the mechanism well, \nit seems that there are some aliases, i.e. \"AF ...\", \"AM ...\".\nThese dictionaries are somehow compressed.\n\nAnd in the C++ code there is this part of code :\n\n\n    dash = strchr(piece, '/');\n    if (dash) {\n        ...\n        if (pHMgr->is_aliasf()) {\n          int index = atoi(dash + 1);\n          nptr->contclasslen = pHMgr->get_aliasf(index, &(nptr->contclass));\n        } else {\n            nptr->contclasslen = pHMgr->decode_flags(&(nptr->contclass), dash + 1);\n            flag_qsort(nptr->contclass, 0, nptr->contclasslen);\n        }\n\n\n\nBut I did not find anything similar in the Java Class, the aliases are not loaded I think.\nCorrect me if I'm wrong but it seems not possible to load compressed affix dictionaries currently.\n\nHope this can help. "
        },
        {
            "author": "Chris Male",
            "id": "comment-13284329",
            "date": "2012-05-28T08:57:11+0000",
            "content": "Correct me if I'm wrong but it seems not possible to load compressed affix dictionaries currently.\n\nThat is correct.  Our Java code isn't a direct port from the C++ code, rather it's an implementation designed to suit our needs.  It could definitely do with some love in regards to compressed dictionaries.  Would you like to open an issue and throw together a patch? "
        },
        {
            "author": "Ludovic Boutros",
            "id": "comment-13284334",
            "date": "2012-05-28T09:06:25+0000",
            "content": "And just for information, the ubuntu french hunspell dictionary is not compressed and works perfectly. "
        },
        {
            "author": "Ludovic Boutros",
            "id": "comment-13284337",
            "date": "2012-05-28T09:11:39+0000",
            "content": "done : SOLR-3494. "
        },
        {
            "author": "Ludovic Boutros",
            "id": "comment-13284361",
            "date": "2012-05-28T10:18:22+0000",
            "content": "I've attached a little patch in the other issue which allows me to load latest French dictionaries of OpenOffice. "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13412133",
            "date": "2012-07-11T22:26:06+0000",
            "content": "bulk fixing the version info for 4.0-ALPHA and 4.0 all affected issues have \"hoss20120711-bulk-40-change\" in comment "
        },
        {
            "author": "Stephan Meisinger",
            "id": "comment-13414942",
            "date": "2012-07-16T09:05:21+0000",
            "content": "Please consider look at this again:\nI can reproduce the original StringOutOfBoundException in DoubleASCIIFlagParsingStrategy\n\nI think this is caused by \n\n for (int i = 0; i < rawFlags.length(); i+=2) {\nchar cookedFlag = (char) ((int) rawFlags.charAt + (int) rawFlags.charAt(i + 1)); // <<< i +1 here!!!\n\nwe have used the dictonary with solr 3.3 (+patched with files from LUCENE-3414/SOLR-2769) changed this given line to \n\n for (int i = 0; i < rawFlags.length()-1; i+=2) { // <<< reduce size by 1 because of .charAt(i+1)\nchar cookedFlag = (char) ((int) rawFlags.charAt + (int) rawFlags.charAt(i + 1));\n\nthis worked flawless for us.  "
        },
        {
            "author": "Chris Male",
            "id": "comment-13414943",
            "date": "2012-07-16T09:07:24+0000",
            "content": "I will take a look Stephan. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13429761",
            "date": "2012-08-07T03:42:46+0000",
            "content": "rmuir20120906-bulk-40-change "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13452218",
            "date": "2012-09-10T17:41:58+0000",
            "content": "moving all 4.0 issues not touched in a month to 4.1 "
        },
        {
            "author": "Steve Rowe",
            "id": "comment-13717418",
            "date": "2013-07-23T18:48:11+0000",
            "content": "Bulk move 4.4 issues to 4.5 and 5.0 "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-13919695",
            "date": "2014-03-04T17:51:21+0000",
            "content": "Commit 1574158 from Robert Muir in branch 'dev/trunk'\n[ https://svn.apache.org/r1574158 ]\n\nSOLR-2934: increase buffer size for recent dictionaries with large amounts of AF/AM lines before charset "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-13919696",
            "date": "2014-03-04T17:51:58+0000",
            "content": "Commit 1574159 from Robert Muir in branch 'dev/branches/branch_4x'\n[ https://svn.apache.org/r1574159 ]\n\nSOLR-2934: increase buffer size for recent dictionaries with large amounts of AF/AM lines before charset "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13919712",
            "date": "2014-03-04T18:02:09+0000",
            "content": "Currently we can load all the openoffice dictionaries (at least from the old link).\n\nI will test newer dictionaries (thunderbird has a link) later today, especially since it has many that arent in the openoffice list. This might reveal some issues to fix.\n\nAs far as EN_GB.aff,.dic, i committed a fix for this (we use mark/reset to go back once we find the encoding, for now, and i ensured it has a large enough buffer size).\n\nAs far as the original exception reported by the user (mixing EN_GB.dic with french affix file, this is not supported. Affix files must \"go with\" the dictionary as they contain information such as how characters and flags are encoded).\n\nAs far as Stephen's issue: with long flags, there should never be an odd number of flags. So something is wrong with the dictionary you are using. I haven't seen it yet in the wild with published dictionaries. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13924932",
            "date": "2014-03-08T17:12:22+0000",
            "content": "\nStephan Meisinger added a comment - 16/Jul/12 05:05\n\nPlease consider look at this again:\nI can reproduce the original StringOutOfBoundException in DoubleASCIIFlagParsingStrategy\n\nJust a followup about that issue with long flags, I found this in a thunderbird dictionary. The bug is not the flag parsing (again it should always be an even number of characters, i added an explicit check for that too!). Instead the bug was that escaping wasnt handled properly. So if the word itself contains a slash, some parts of the word would be bogusly parsed as flags. The escaping was fixed in LUCENE-5497. "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-13982631",
            "date": "2014-04-27T23:26:01+0000",
            "content": "Close issue after release of 4.8.0 "
        }
    ]
}