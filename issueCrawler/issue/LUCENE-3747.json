{
    "id": "LUCENE-3747",
    "title": "Support Unicode 6.1.0",
    "details": {
        "labels": "",
        "priority": "Minor",
        "components": [
            "modules/analysis"
        ],
        "type": "Improvement",
        "fix_versions": [
            "4.0-BETA",
            "6.0"
        ],
        "affect_versions": "3.5,                                            4.0-ALPHA",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "Now that Unicode 6.1.0 has been released, Lucene/Solr should support it.\n\nJFlex trunk now supports Unicode 6.1.0.\n\nTasks include:\n\n\n\tUpgrade ICU4J to v49 (after it's released, on 2012-03-21, according to http://icu-project.org).\n\tUse icu module tools to regenerate the supplementary character additions to JFlex grammars.\n\tVersion the JFlex grammars: copy the current implementations to *Impl3<X>; cause the versioning tokenizer wrappers to instantiate this version when the Version c-tor param is in the range 3.1 to the version in which these changes are released (excluding the range endpoints); then change the specified Unicode version in the non-versioned JFlex grammars from 6.0 to 6.1.\n\tRegenerate JFlex scanners, including StandardTokenizerImpl, UAX29URLEmailTokenizerImpl, and HTMLStripCharFilter.\n\tUsing generateJavaUnicodeWordBreakTest.pl, generate and then run WordBreakTestUnicode_6_1_0.java  under modules/analysis/common/src/test/org/apache/lucene/analysis/core/",
    "attachments": {
        "LUCENE-3747-remainders.patch": "https://issues.apache.org/jira/secure/attachment/12545819/LUCENE-3747-remainders.patch",
        "LUCENE-3747.patch": "https://issues.apache.org/jira/secure/attachment/12536814/LUCENE-3747.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2012-02-02T18:13:54+0000",
            "content": "+1 as soon as the icu release comes out we should start working on the update.\n\nadditional things for updating icu:\n\n\tcheck for any uax#29 differences (i think we are unaffected)\n\tupdate files in icu/src/data/utr30 (i really need to make a script to automate this, but it does document what has to happen)\n\ttry again to remove the java7-workaround-hack in LuceneTestCase for http://bugs.icu-project.org/trac/ticket/8734\n\n ",
            "author": "Robert Muir",
            "id": "comment-13199047"
        },
        {
            "date": "2012-02-02T18:18:36+0000",
            "content": "check for any uax#29 differences (i think we are unaffected)\n\nRight, I'm not sure about this - I plan on upgrading the JFlex test cases that implement the uax#29 rules and test against the data Unicode.org provides.  I should know more once that's done. ",
            "author": "Steve Rowe",
            "id": "comment-13199051"
        },
        {
            "date": "2012-02-02T18:25:56+0000",
            "content": "the \"changes.txt\" is here http://www.unicode.org/versions/Unicode6.1.0/ along with the log here:\nhttp://www.unicode.org/reports/tr29/tr29-19.html#Modifications ",
            "author": "Robert Muir",
            "id": "comment-13199064"
        },
        {
            "date": "2012-02-03T19:48:25+0000",
            "content": "\ncheck for any uax#29 differences (i think we are unaffected)\n\nRight, I'm not sure about this - I plan on upgrading the JFlex test cases that implement the uax#29 rules and test against the data Unicode.org provides. I should know more once that's done.\n\nI've finished adding Unicode 6.1 versions to JFlex's UAX#29 test cases, including the word break rules test case, and the only change I noticed that could conceivably affect Lucene's UAX#29 tokenizers is the new Section 8, which discusses Korean syllables.  Since the rules listed in that section are not part of the word break rules, but rather are a tailoring, and since that section says \"All standard Korean syllable blocks used in modern Korean are of the form <L V T> or <L V> and have equivalent, single-character precomposed forms.\", I don't think we need to support this (right now anyway).\n\n(By contrast, the UAX#14 line break rules changed significantly between Unicode v6.0 and v6.1, and I'm still working to include a Unicode 6.1 version to JFlex's corresponding test case.) ",
            "author": "Steve Rowe",
            "id": "comment-13199985"
        },
        {
            "date": "2012-03-06T14:58:07+0000",
            "content": "A release candidate is available. ",
            "author": "DM Smith",
            "id": "comment-13223298"
        },
        {
            "date": "2012-07-17T12:57:28+0000",
            "content": "First stab at trunk patch. ",
            "author": "Steve Rowe",
            "id": "comment-13416151"
        },
        {
            "date": "2012-07-17T13:04:23+0000",
            "content": "Subversion script for trunk:\n\n\nsvn rm lucene/test-framework/src/java/org/apache/lucene/util/TestRuleIcuHack.java\nsvn rm lucene/analysis/icu/lib/icu4j-4.8.1.1.jar.sha1\nsvn rm solr/contrib/extraction/lib/icu4j-4.8.1.1.jar.sha1\nsvn rm solr/contrib/analysis-extras/lib/icu4j-4.8.1.1.jar.sha1\n\n\n\nbranch_4x will need more svn moves and version checks for the versioned grammars.\n\n\nlucene/analysis/common/\n\n\n\tI ran ant gen-tlds\n\tI ran ant jflex\n\n\n\nlucene/analysis/icu/\n\nuax29\n\n\n\tI don't fully understand the syntax used in the .rbbi files, so I didn't check whether they need algorithm updates.  (However, since I didn't need to make any changes for the JFlex version, probably no algorithm changes needed.)\n\tI ran ant genrbbi.\n\n\n\nutr30\nBasicFoldings.txt: \n\n\tFor those things that are \"additions to kd\" - how to extend?\n\tFor dashes folding, I added some non-included ranges.  Q: should wave dash be folded to swung dash? (They look the same.)\n\tI don't know how to extend underline folding - is there a property?\n\tI don't know how to extend punctuation folding - is there a property?\n\n\n\nDiacriticFolding.txt: \n\n\tIn the [:Diacritic:] section, I'm not sure how to proceed, as I can see several missing Latin-1 code points that were almost certainly part of Unicode 6.0.0, so the selection mechanism is non-transparent.\n\tIn the [:Mark:]&[:Lm:] section, I'm not sure how to make selections, so I didn't try.\n\tIn the \"Additional Arabic/Hebrew decompositions\" section, I don't know how to extend.\n\tOther sections were based either on AsciiFoldingFilter or UTR#30, neither of which has changed\n\n\n\nDigbatFolding.txt:\n\n\tbased on AsciiFoldingFilter, which hasn't changed\n\n\n\nHanRadicalFolding.txt: \n\n\tbased on UTR#30, which hasn't changed\n\n\n\nNativeDigitFolding.txt:\n\n\n\tI wrote a shell/perl script, embedded in the text file, to update.\n\tShould [:No:] DIGIT chars be included?  One currently is: 19DA;NEW TAI LUE THAM DIGIT ONE;No;0;L;;;1;1;N;;;;;, but others are not (other ranges listed in the patch).\n\n\n\nnfkc.txt: \n\n\n\tNew version copied directly from icu-project.org\n\tThere is a problem: the following from TestICUFoldingFilter fails:\n\n\n\n\n46:  assertAnalyzesTo(a, \"\u039c\u03ac\u03ca\u03bf\u03c2\", new String[] { \"\u03bc\u03b1\u03b9\u03bf\u03c3\" });\n\n\n\n AFAICT, this is because the accent decomposition mappings are no longer present in nfkc.txt.  This makes no sense; Robert, do you know what's happening here?\n\nnfkc_cf.txt: \n\n\n\tNew version copied directly from icu-project.org\n\n ",
            "author": "Steve Rowe",
            "id": "comment-13416154"
        },
        {
            "date": "2012-07-17T13:06:45+0000",
            "content": "try again to remove the java7-workaround-hack in LuceneTestCase for http://bugs.icu-project.org/trac/ticket/8734\n\nI ran your little program with ICU4J 49.1, and the Error is no longer raised.  I've removed the workaround class. ",
            "author": "Steve Rowe",
            "id": "comment-13416156"
        },
        {
            "date": "2012-07-17T13:11:48+0000",
            "content": "Thanks so much for tackling this! Give me some time to check out what you did... ",
            "author": "Robert Muir",
            "id": "comment-13416158"
        },
        {
            "date": "2012-07-17T13:19:20+0000",
            "content": "Ill comment on the other things, but just to answer this:\n\n\nAFAICT, this is because the accent decomposition mappings are no longer present in nfkc.txt. This makes no sense; Robert, do you know what's happening here?\n\nYou need to bring in nfc.txt too now.\n\nhttp://bugs.icu-project.org/trac/ticket/9023 ",
            "author": "Robert Muir",
            "id": "comment-13416163"
        },
        {
            "date": "2012-07-17T13:23:44+0000",
            "content": "You need to bring in nfc.txt too now. http://bugs.icu-project.org/trac/ticket/9023\n\nWhew, cool! ",
            "author": "Steve Rowe",
            "id": "comment-13416166"
        },
        {
            "date": "2012-07-17T13:53:12+0000",
            "content": "\nFor those things that are \"additions to kd\" - how to extend?\n\nWhat this means is that its the mappings in utr30 minus what nfkc does.\nSo i dont think we need to really worry about this much?\nif we wanted we could check the sets present for some, defined by the below link:\nhttp://www.unicode.org/reports/tr30/tr30-4.html#_Toc42\nSo thats sorta the rule for this whole file?\n\nExample:\n\n## Space Folding\n# [:Zs:] > U+0020\n1680>0020\n180E>0020\n\n\n\nSo that is basically iterating this UnicodeSet (can be done in code with ICU) and generating mappings to 0020: \n\n[[:Zs:]-[\\u0020]-[:Changes_When_NFKC_Casefolded=Yes:]]\n\n\n\nDoes that make sense?\n\n\nShould [:No:] DIGIT chars be included? One currently is: 19DA;NEW TAI LUE THAM DIGIT ONE;No;0;L;;;1;1;N;;;;;, but others are not (other ranges listed in the patch).\n\nI dont see any problems including [:Numeric_Type=Digit:]. But i wouldnt use [:No:].\nSo something like [[:Numeric_Type=Digit:][:Nd:]] ?\n\n\nIn the [:Diacritic:] section, I'm not sure how to proceed, as I can see several missing Latin-1 code points that were almost certainly part of Unicode 6.0.0, so the selection mechanism is non-transparent.\n\nIts definitely a subset. Some stuff in here like viramas should not be folded away.\nSorry i dont have a well-defined set or criteria, it was just common-sense.\nFor the last update, i basically only reviewed the 'new' ones and made a decision: e.g. \n\n[[:Diacritic:]-[:Age=6.0:]]\n\n\n\nSo this will be the trickiest part of the file to automate i think, as it was originally\ndefined as a list for the most part: http://www.unicode.org/reports/tr30/datafiles/DiacriticFolding.txt ",
            "author": "Robert Muir",
            "id": "comment-13416196"
        },
        {
            "date": "2012-07-17T14:08:26+0000",
            "content": "Basically Steve, my opinion is if we have a good way to script this thing, we should just try to come\nup with some appropriate Sets for this stuff and automate it. It doesn't need to be perfect.\n\nAnd then go forward from there with fine tuning the script... but I think automation should be \nthe priority! ",
            "author": "Robert Muir",
            "id": "comment-13416227"
        },
        {
            "date": "2012-07-24T05:42:44+0000",
            "content": "\n\tI ran perl generateJavaUnicodeWordBreakTest.pl and deleted the previously-generated WordBreakTestUnicode_6_0_0.java in favor of the new WordBreakTestUnicode_6_1_0.java. The new full svn script is:\n\nsvn rm lucene/test-framework/src/java/org/apache/lucene/util/TestRuleIcuHack.java\nsvn rm lucene/analysis/icu/lib/icu4j-4.8.1.1.jar.sha1\nsvn rm solr/contrib/extraction/lib/icu4j-4.8.1.1.jar.sha1\nsvn rm solr/contrib/analysis-extras/lib/icu4j-4.8.1.1.jar.sha1\nsvn rm lucene/analysis/common/src/test/org/apache/lucene/analysis/core/WordBreakTestUnicode_6_0_0.java\n\n\n\tUpdated to automate the following via a new ant target gen-utr30-data-files, which gennorm2 now depends on:\n\n\n\n\n\tDownload nfc.txt, nfkc.txt and nfkc_cf.txt from Unicode.org\n\tConvert round-trip mappings in nfc.txt to one-way mappings if the right-hand side contains [:Diacritic:]\n\tExpand UnicodeSet rules in the other norm2 files.\n\n\n\n Where I couldn't figure out a rule, I put in an annotation (\"# Rule: verbatim\") to leave the following mappings as-is.\n\n Robert, I couldn't discern any logic to the exceptions you made to the \"[:Diacritic:]>\" mappings, so I left it at the full [:Diacritic:] set; feel free to amend the rule.\n\n After these changes, I ran ant gennorm2.\n\n All tests pass.  I think this is ready to go.\n\n(More work to be done on branch_4x, where the current Unicode 6.0 JFlex-based implementations need to be acessible via LUCENE_36.) ",
            "author": "Steve Rowe",
            "id": "comment-13421197"
        },
        {
            "date": "2012-07-24T05:50:09+0000",
            "content": "If its automated then I'm +1. We can refine with other issues (keeping with the automated approach)\n\nI took a glance at the patch and it looks nice and very thorough... thank you!!!!! ",
            "author": "Robert Muir",
            "id": "comment-13421199"
        },
        {
            "date": "2012-07-26T13:03:11+0000",
            "content": "Committed to trunk: r1365971.\n\nBackporting to branch_4x now. ",
            "author": "Steve Rowe",
            "id": "comment-13423040"
        },
        {
            "date": "2012-07-26T23:19:36+0000",
            "content": "There was a source generation problem: \"Picked up JAVA_TOOL_OPTIONS: -Dfile.encoding=UTF-8\" got embedded in two of the intermediate generated .jflex-macro files.  If JAVA_TOOLS_OPTIONS env. var is set, it gets picked up as if it were cmdline options by JVM, then the JVM outputs that string, apparently into the same stream that gets captured by one of the source generation processes.\n\nI committed a fix to trunk: r1366231. ",
            "author": "Steve Rowe",
            "id": "comment-13423551"
        },
        {
            "date": "2012-07-27T07:19:33+0000",
            "content": "Committed to branch_4x: r1366298. ",
            "author": "Steve Rowe",
            "id": "comment-13423713"
        },
        {
            "date": "2012-09-19T22:34:19+0000",
            "content": "I missed a couple of Unicode 6.0 mentions.  Patch in a moment. ",
            "author": "Steve Rowe",
            "id": "comment-13459171"
        },
        {
            "date": "2012-09-19T22:43:52+0000",
            "content": "HTMLStripCharFilter.jflex needed to be upgraded (%unicode 6.0 -> %unicode 6.1) and regenerated, but the rest is just documentation, though this patch does include all regenerated .java files.\n\nCommitting shortly. ",
            "author": "Steve Rowe",
            "id": "comment-13459179"
        },
        {
            "date": "2012-09-20T01:28:47+0000",
            "content": "Committed:\n\n\n\ttrunk r1387813\n\tbranch_4x r1387837\n\n ",
            "author": "Steve Rowe",
            "id": "comment-13459277"
        },
        {
            "date": "2013-03-22T16:35:53+0000",
            "content": "[branch_4x commit] Steven Rowe\nhttp://svn.apache.org/viewvc?view=revision&revision=1387837\n\nLUCENE-3747: finish upgrading to Unicode 6.1 (merge trunk r1387813) ",
            "author": "Commit Tag Bot",
            "id": "comment-13610795"
        }
    ]
}