{
    "id": "LUCENE-6077",
    "title": "Add a filter cache",
    "details": {
        "resolution": "Fixed",
        "affect_versions": "None",
        "components": [],
        "labels": "",
        "fix_versions": [
            "5.0"
        ],
        "priority": "Minor",
        "status": "Closed",
        "type": "Improvement"
    },
    "description": "Lucene already has filter caching abilities through CachingWrapperFilter, but CachingWrapperFilter requires you to know which filters you want to cache up-front.\n\nCaching filters is not trivial. If you cache too aggressively, then you slow things down since you need to iterate over all documents that match the filter in order to load it into an in-memory cacheable DocIdSet. On the other hand, if you don't cache at all, you are potentially missing interesting speed-ups on frequently-used filters.\n\nSomething that would be nice would be to have a generic filter cache that would track usage for individual filters and make the decision to cache or not a filter on a given segments based on usage statistics and various heuristics, such as:\n\n\tthe overhead to cache the filter (for instance some filters produce DocIdSets that are already cacheable)\n\tthe cost to build the DocIdSet (the getDocIdSet method is very expensive on some filters such as MultiTermQueryWrapperFilter that potentially need to merge lots of postings lists)\n\tthe segment we are searching on (flush segments will likely be merged right away so it's probably not worth building a cache on such segments)",
    "attachments": {
        "LUCENE-6077.patch": "https://issues.apache.org/jira/secure/attachment/12683845/LUCENE-6077.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "id": "comment-14226209",
            "author": "Adrien Grand",
            "date": "2014-11-26T14:14:35+0000",
            "content": "Here is a patch. It divides the work into 2 pieces:\n\n\tFilterCache whose responsibility is to act as a per-segment cache for filters but doesn't make any decision about which filters should be cached\n\tFilterCachingPolicy, whose responsibility is to decide about whether a filter is worth caching given the filter itself, the current segment and the produced (uncached) DocIdSet.\n\n\n\nFilterCache has an implementation called LRUFilterCache that accepts a maximum size (number of cached filters) and ram usage and is going to evict least-recently-used filters first. It has some protected methods that allow to configure which impl should be used to cache DocIdSets (RoaringDocIdSet by default), and how to measure ram usage of filters (the default impl uses Accountable#ramBytesUsed if the filter implements Accountable, and falls back to an arbitrary constant (1024) otherwise).\n\nFilterCachingPolicy has an implementation called UsageTrackingFilterCachingPolicy that tries to provide sensible defaults:\n\n\tit tracks the 256 most recently used filters (through their hash codes) globally (not per segment)\n\tit only caches on segments whose source is a merge or addIndexes (not flushes)\n\tit uses some heuristics to decide how many times a filter should appear in the history of 256 filters in order to be cached.\n\n\n\nThe filter caching policy can be configured on a per-filter basis, so that even if there are filters that you want to cache more aggressively than others, it is possible to cache them all in a single FilterCache instance. "
        },
        {
            "id": "comment-14226284",
            "author": "Robert Muir",
            "date": "2014-11-26T15:10:19+0000",
            "content": "This looks great!\n\nDo we really need to default CachingWrapperFilter to a \"stupid\" policy?\nIs there a better name for FilterCache.cache() method? it can be a noun or a verb, so its kind of confusing. Maybe doCache would be better?\nCachingWrapperFilter's new ctor: can we fix the typo?\nFilterCachingPolicy.onCache, can we correct the param name? "
        },
        {
            "id": "comment-14226443",
            "author": "Adrien Grand",
            "date": "2014-11-26T16:51:09+0000",
            "content": "Updated patch:\n\n\tCachingWrapperFilter now uses a policy that only caches on merged segments by default (instead of all segments)\n\tapplied other suggestions about typos/naming\n\n "
        },
        {
            "id": "comment-14227412",
            "author": "Adrien Grand",
            "date": "2014-11-27T09:07:25+0000",
            "content": "Updated patch:\n\n\tfixed LRUFilterCache.getChildResources to not make a copy of the cache (since Accountables.namedAccountables already takes care of taking a snapshot)\n\treplaced the heuristics based on the segment source in the diagnostics by a heuristic on the segment size compared to the size of the top-level context. This should give better results since merged segments are not necessarily large and flushed segments can be large if you have large IW buffers.\n\n\n\nI think it's ready? "
        },
        {
            "id": "comment-14227687",
            "author": "Robert Muir",
            "date": "2014-11-27T14:20:35+0000",
            "content": "+1 "
        },
        {
            "id": "comment-14227803",
            "author": "ASF subversion and git services",
            "date": "2014-11-27T16:23:50+0000",
            "content": "Commit 1642183 from Adrien Grand in branch 'dev/trunk'\n[ https://svn.apache.org/r1642183 ]\n\nLUCENE-6077: Add a filter cache. "
        },
        {
            "id": "comment-14227818",
            "author": "ASF subversion and git services",
            "date": "2014-11-27T16:34:12+0000",
            "content": "Commit 1642185 from Adrien Grand in branch 'dev/branches/branch_5x'\n[ https://svn.apache.org/r1642185 ]\n\nLUCENE-6077: Add a filter cache. "
        },
        {
            "id": "comment-14332864",
            "author": "Anshum Gupta",
            "date": "2015-02-23T05:02:19+0000",
            "content": "Bulk close after 5.0 release. "
        }
    ]
}