{
    "id": "LUCENE-6177",
    "title": "Add CustomAnalyzer - a builder that creates Analyzers from the factory classes",
    "details": {
        "resolution": "Fixed",
        "affect_versions": "None",
        "components": [
            "modules/analysis"
        ],
        "labels": "",
        "fix_versions": [
            "5.0",
            "6.0"
        ],
        "priority": "Major",
        "status": "Closed",
        "type": "New Feature"
    },
    "description": "I prepared some \"generic Analyzer class CustomAnalyzer, that makes it easy to build analyzers like in Solr or Elasticsearch. Under the hood it uses the factory classes. The class is made like a builder:\n\n\nAnalyzer ana = CustomAnalyzer.builder(Path.get(\"/path/to/config/dir\"))\n  .withTokenizer(\"standard\")\n  .addTokenFilter(\"standard\")\n  .addTokenFilter(\"lowercase\")\n  .addTokenFilter(\"stop\", \"ignoreCase\", \"false\", \"words\", \"stopwords.txt\", \"format\", \"wordset\")\n  .build();\n\n\n\nIt is possible to give the resource loader (used by stopwords and similar). By default it tries to load stuff from context classloader (without any class as reference so paths must be absolute - this is the behaviour ClasspathResourseLoader defaults to).\n\nIn addition you can give a Lucene MatchVersion, by default it would use Version.LATEST (once LUCENE-5900 is completely fixed).",
    "attachments": {
        "LUCENE-6177.patch": "https://issues.apache.org/jira/secure/attachment/12691669/LUCENE-6177.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "id": "comment-14273761",
            "author": "Uwe Schindler",
            "date": "2015-01-12T16:46:28+0000",
            "content": "First patch.\n\nI have to add tests for it. This patch should just show how it looks like. It may still contain bugs, it was just quickly hacked together. "
        },
        {
            "id": "comment-14273769",
            "author": "Robert Muir",
            "date": "2015-01-12T16:54:01+0000",
            "content": "+1 Uwe, looks nice. "
        },
        {
            "id": "comment-14275594",
            "author": "Uwe Schindler",
            "date": "2015-01-13T17:46:35+0000",
            "content": "Here is a patch with tests. I will look into Solr's TokenizerChain and see how this could be replaced by the generic approach (it is just code duplication).\n\nBut this is something for later, I would like to just provide this with Lucene 5.0, because the number of people who complain about how to make analyzer is quite big on java-user.\n\nRobert Muir also suggested, that we might implement all current analyzers using this class, because its much easier to read than createComponents() methods. "
        },
        {
            "id": "comment-14275858",
            "author": "Robert Muir",
            "date": "2015-01-13T20:17:32+0000",
            "content": "+1 to the patch! "
        },
        {
            "id": "comment-14276816",
            "author": "Uwe Schindler",
            "date": "2015-01-14T11:39:42+0000",
            "content": "New patch:\n\n\tallows to set positionIncrement\n\tallows to set offsetIncrement\n\tallows to get the config back as lists\n\n "
        },
        {
            "id": "comment-14276941",
            "author": "Uwe Schindler",
            "date": "2015-01-14T14:23:20+0000",
            "content": "Patch with a small bugfix (found by new test) and many documentation improvements. I also linked this analyzer in the documentation about Lucene Analysis.\n\nI will commit this now to 5.0, 5.1 and Trunk. "
        },
        {
            "id": "comment-14276947",
            "author": "ASF subversion and git services",
            "date": "2015-01-14T14:32:34+0000",
            "content": "Commit 1651681 from Uwe Schindler in branch 'dev/trunk'\n[ https://svn.apache.org/r1651681 ]\n\nLUCENE-6177: Add CustomAnalyzer that allows to configure analyzers like you do in Solr's index schema. This class has a builder API to configure Tokenizers, TokenFilters, and CharFilters based on their SPI names and parameters as documented by the corresponding factories. "
        },
        {
            "id": "comment-14276973",
            "author": "ASF subversion and git services",
            "date": "2015-01-14T14:42:12+0000",
            "content": "Commit 1651687 from Uwe Schindler in branch 'dev/branches/branch_5x'\n[ https://svn.apache.org/r1651687 ]\n\nMerged revision(s) 1651681 from lucene/dev/trunk:\nLUCENE-6177: Add CustomAnalyzer that allows to configure analyzers like you do in Solr's index schema. This class has a builder API to configure Tokenizers, TokenFilters, and CharFilters based on their SPI names and parameters as documented by the corresponding factories. "
        },
        {
            "id": "comment-14276983",
            "author": "ASF subversion and git services",
            "date": "2015-01-14T14:46:59+0000",
            "content": "Commit 1651688 from Uwe Schindler in branch 'dev/branches/lucene_solr_5_0'\n[ https://svn.apache.org/r1651688 ]\n\nMerged revision(s) 1651681 from lucene/dev/trunk:\nLUCENE-6177: Add CustomAnalyzer that allows to configure analyzers like you do in Solr's index schema. This class has a builder API to configure Tokenizers, TokenFilters, and CharFilters based on their SPI names and parameters as documented by the corresponding factories. "
        },
        {
            "id": "comment-14276990",
            "author": "Uwe Schindler",
            "date": "2015-01-14T14:51:17+0000",
            "content": "I committed this now to get it into the coming Lucene 5.0. This is a really new \"feature\" so it should get its major version. It is also quite \"separate\", so there is no risk.\n\nIn the future we should use this in Solr (replace TokenizerChain / SolrAnalyzer class). We may alo define our default Analyzers throughout the analysis-common package with this class. I will open separate issues for that. "
        },
        {
            "id": "comment-14277927",
            "author": "ASF subversion and git services",
            "date": "2015-01-14T23:52:19+0000",
            "content": "Commit 1651901 from Uwe Schindler in branch 'dev/trunk'\n[ https://svn.apache.org/r1651901 ]\n\nLUCENE-6177: fix typo "
        },
        {
            "id": "comment-14277928",
            "author": "ASF subversion and git services",
            "date": "2015-01-14T23:53:15+0000",
            "content": "Commit 1651902 from Uwe Schindler in branch 'dev/branches/branch_5x'\n[ https://svn.apache.org/r1651902 ]\n\nMerged revision(s) 1651901 from lucene/dev/trunk:\nLUCENE-6177: fix typo "
        },
        {
            "id": "comment-14277930",
            "author": "ASF subversion and git services",
            "date": "2015-01-14T23:54:12+0000",
            "content": "Commit 1651903 from Uwe Schindler in branch 'dev/branches/lucene_solr_5_0'\n[ https://svn.apache.org/r1651903 ]\n\nMerged revision(s) 1651901 from lucene/dev/trunk:\nLUCENE-6177: fix typo "
        },
        {
            "id": "comment-14332931",
            "author": "Anshum Gupta",
            "date": "2015-02-23T05:02:40+0000",
            "content": "Bulk close after 5.0 release. "
        }
    ]
}