{
    "id": "LUCENE-5048",
    "title": "NegativeArraySizeException caused by  ff.addFields",
    "details": {
        "components": [
            "modules/facet"
        ],
        "fix_versions": [
            "4.4",
            "6.0"
        ],
        "affect_versions": "4.2,                                            4.3",
        "priority": "Major",
        "labels": "",
        "type": "Bug",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "I have a Server/Client software that I have created which has a server process that accepts connections from clients that transmit data about local connection information. This data is than buffered and a ThreadPoolExecutor runs to take the data and put it into a lucene index as well as a facet index. This works perfect for the lucene index, but the facet index randomly generates a NegativeArraySizeException. I cannot find any reason why the exception would be caused because lines with the same type of data do not throw it, then all of a sudden the exception is thrown, typically 4 of them in a row. I talked with mikemccand on IRC and he requested I submit this issue.\n\nAfter some discussion, he seems to think it's because some of the values I am using are rather large.\n\nHere is the exception...\njava.lang.NegativeArraySizeException\n        at java.lang.AbstractStringBuilder.<init>(AbstractStringBuilder.java:64)\n        at java.lang.StringBuilder.<init>(StringBuilder.java:97)\n        at org.apache.lucene.facet.taxonomy.writercache.cl2o.CharBlockArray.subSequence(CharBlockArray.java:164)\n        at org.apache.lucene.facet.taxonomy.writercache.cl2o.CategoryPathUtils.hashCodeOfSerialized(CategoryPathUtils.java:50)\n        at org.apache.lucene.facet.taxonomy.writercache.cl2o.CompactLabelToOrdinal.stringHashCode(CompactLabelToOrdinal.java:294)\n        at org.apache.lucene.facet.taxonomy.writercache.cl2o.CompactLabelToOrdinal.grow(CompactLabelToOrdinal.java:184)\n        at org.apache.lucene.facet.taxonomy.writercache.cl2o.CompactLabelToOrdinal.addLabel(CompactLabelToOrdinal.java:116)\n        at org.apache.lucene.facet.taxonomy.writercache.cl2o.Cl2oTaxonomyWriterCache.put(Cl2oTaxonomyWriterCache.java:84)\n        at org.apache.lucene.facet.taxonomy.directory.DirectoryTaxonomyWriter.addToCache(DirectoryTaxonomyWriter.java:592)\n        at org.apache.lucene.facet.taxonomy.directory.DirectoryTaxonomyWriter.addCategoryDocument(DirectoryTaxonomyWriter.java:551)\n        at org.apache.lucene.facet.taxonomy.directory.DirectoryTaxonomyWriter.internalAddCategory(DirectoryTaxonomyWriter.java:501)\n        at org.apache.lucene.facet.taxonomy.directory.DirectoryTaxonomyWriter.internalAddCategory(DirectoryTaxonomyWriter.java:494)\n        at org.apache.lucene.facet.taxonomy.directory.DirectoryTaxonomyWriter.addCategory(DirectoryTaxonomyWriter.java:468)\n        at org.apache.lucene.facet.index.FacetFields.addFields(FacetFields.java:175)\n        at net.domain.NetstatIndexer.IndexJob.run(IndexJob.java:73)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:722)\n\nHere is an example data entry which appears when the exception occurs...\nLocation: nj\nLocalIP: 10.1.200.187\nRemoteIP: 41.161.197.166\nLocalPorts: [443]\nConnections: 1\nTimes: [120]\nTimestamp: 2013-06-09T12:51:00.000-07:00\nStates: [\"Established\"]\n\nAnd here is the the code stripped down to provide an example of how I am handling the facet/doc code.\n\ndoc.add(new TextField(\"Location\", ehost[0], Field.Store.YES));\ncats.add(new CategoryPath(\"Location\", doc.get(\"Location\")));\ndoc.add(new TextField(\"LocalIP\", (String) stat.get(\"LocalIP\"), Field.Store.YES));\ncats.add(new CategoryPath(\"LocalIP\", doc.get(\"LocalIP\")));\ndoc.add(new TextField(\"RemoteIP\", (String) stat.get(\"RemoteIP\"), Field.Store.YES));\ncats.add(new CategoryPath(\"RemoteIP\", doc.get(\"RemoteIP\")));\ndoc.add(new TextField(\"LocalPorts\", StringUtils.join(stat.get(\"LocalPorts\"), \",\"), Field.Store.YES));\ncats.add(new CategoryPath(\"LocalPorts\", doc.get(\"LocalPorts\")));\ndoc.add(new TextField(\"RemotePorts\", StringUtils.join(stat.get(\"RemotePorts\"), \",\"), Field.Store.YES));\ncats.add(new CategoryPath(\"RemotePorts\", doc.get(\"RemotePorts\")));\ndoc.add(new LongField(\"Connections\", (Long) stat.get(\"Connections\"), Field.Store.YES));\ncats.add(new CategoryPath(\"Connections\", doc.get(\"Connections\")));\ndoc.add(new TextField(\"Times\", StringUtils.join(stat.get(\"Times\"), \",\"), Field.Store.YES));\ncats.add(new CategoryPath(\"Times\", doc.get(\"Times\")));\ndoc.add(new TextField(\"Timestamp\", (String) stat.get(\"Timestamp\"), Field.Store.YES));\ncats.add(new CategoryPath(\"Timestamp\", doc.get(\"Timestamp\")));\ndoc.add(new TextField(\"States\", StringUtils.join(stat.get(\"States\"), \",\"), Field.Store.YES));\ncats.add(new CategoryPath(\"States\", doc.get(\"States\")));\nSystem.out.println(\"Location: \"doc.get(\"Location\")\" LocalIP: \"doc.get(\"LocalIP\")\" RemoteIP: \"doc.get(\"RemoteIP\")\" LocalPorts: \"doc.get(\"LocalPorts\")\" Connections: \"doc.get(\"Connections\")\" Times: \"doc.get(\"Times\")\" Timestamp: \"doc.get(\"Timestamp\")\" States: \"+doc.get(\"States\"));\nif (cats.size()!=0) {\n        FacetFields ff = new FacetFields(Main.twriter);\n        ff.addFields(doc, cats); // <-- Exception occurs here randomly\n}",
    "attachments": {
        "LUCENE-5048.patch": "https://issues.apache.org/jira/secure/attachment/12586978/LUCENE-5048.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2013-06-09T21:32:42+0000",
            "content": "Here's a test showing the issue.\n\nWhat makes it tricky is it's not until CompactLabelToOrdinal goes to rehash that the previously successfully indexed too-large value causes the exception, even though the current doc being indexed is fine.\n\nThe problem is the casts to (short) in CategoryPathUtils, e.g.:\n\n\n    int length = (short) charBlockArray.charAt(offset++);\n\n\n\nI think those should be cast to (int) instead?  (Test passes if I fix all 3).  Does anyone know why they are using (short) now?\n\nBut, separately, indexing such immense (> 32 KB) facet labels really doesn't make much sense?  Ie, most likely it's an accident in the app ... I think somewhere \"higher up\" we should catch this and throw IllegalArgumentException. ",
            "author": "Michael McCandless",
            "id": "comment-13679172"
        },
        {
            "date": "2013-06-09T22:05:45+0000",
            "content": "I modified my code so that it declared the categorypaths separately instead of as a string joined together, which makes sense to do anyway...\n\nJSONArray states = (JSONArray) stat.get(\"States\");\nfor (Object state : states) {\n\tcats.add(new CategoryPath(\"States\", (String) state));\n}\n\nSince doing this I have not see the issue, so it does appear Michael was correct, this was caused by having categorypaths with values to large. Thanks! ",
            "author": "Colton Jamieson",
            "id": "comment-13679193"
        },
        {
            "date": "2013-06-10T07:25:57+0000",
            "content": "Good catch. The test doesn't always reproduce though, it repro with this seed: -Dtests.seed=5229F4C07527089D.\nI modified it to fail on even less categories, just had to initialize a Cl2oTaxoWriterCache with smaller initial capacity.\n\nAnyway, the problem is the cast to short. In Java, short (and int) are signed. So what happens is:\n\n\tThe test generates a random unicode string of length 32767, but its length() is 65534 which is 0xFFFE.\n\tCast that to short, you get -2.\n\tCast it to char, you get 0xFFFE (since char is the only primitive that's unsigned)\n\tAnd of course casting to int is unnecessary.\n\n\n\nThe code serializes the length of each component in a char[], as a char. During serialization, it casts to char, since it appends it to a char[]. During deserialization, it wrongly casts to short (should cast to char, which you then get a warning on unnecessary cast). I guess this never showed up since nobody yet tried to index components of length 16K+ .\n\nSo to fix this we indeed need to remove the cast to short. But also, there's a bigger bug here \u2013 since the length is assumed to be less than 65536, if you index a very large category twice (or a substring of it), I think there will be an issue. So I added to test adding same category again, after re-hash, and voila, it was added again, with a different ordinal. Therefore I added a check in CategoryPath which prevents the creation of CPs with very large components (> 65535 chars). I'll post a modified patch soon. ",
            "author": "Shai Erera",
            "id": "comment-13679362"
        },
        {
            "date": "2013-06-10T07:29:09+0000",
            "content": "Patch addresses the issues mentioned in the previous comment. ",
            "author": "Shai Erera",
            "id": "comment-13679363"
        },
        {
            "date": "2013-06-10T11:01:43+0000",
            "content": "Thanks Shai!\n\nMaybe we should set the limit to match indexer's limit (slightly less than 32 KB I think)?  Both limits are insanely large .... I wonder if they should be much smaller e.g. 256 bytes.\n\nSecond, can you fix testHugeLabel to actually index exactly the max length label? ",
            "author": "Michael McCandless",
            "id": "comment-13679429"
        },
        {
            "date": "2013-06-10T13:19:36+0000",
            "content": "Thanks Mike. Patch indexes the facets, but has a troubling nocommit. If you run the test with -Dtests.seed=919CD019C8A94C60, it fails to DD on the term. I print the $facet terms and it's not there!\n\nI played with the length of the term (exhaustive binary search ) and figured that if it's set to 10,920 (something) it passes but 10,921 (something) it fails. Tracked it down to TermsHashPerField which silently (!?) drops long terms (exceeding 32766 bytes).\n\nThe problem is, I don't know what limit is safe to use. Following the code, seems that 32766/4? The test passes with different seeds and different lengths... But that's not documented anywhere (not the limit, nor the silent dropping of terms), at least no documentation that I found.\n\nNow, notice how I wrote 10921 (something) above \u2013 that's another trick _TestUtil.randomRealistic plays on me. Sometimes if you ask it to generate a 100 'length' string, the result String.length() says 100 and sometimes 200 . I'll repro that and discuss separately.\n\nSo what's the best course of action? Expose the DWPT.MAX_TERM_LENGTH_UTF8 and then limit a CP component to X/4? But that doesn't solve the other problem, that a DD-term can still be silently dropped. So seems like we should limit a CP total encoded length (w/ the separator) to MAX/4? \n\nUnlike document content terms, I think it's bad if we silently drop DD terms. I prefer that we fail fast on that. We can do that in DrillDownStream - if the termAttribute.length is > MAX/4, refused to add that category? ",
            "author": "Shai Erera",
            "id": "comment-13679488"
        },
        {
            "date": "2013-06-10T13:33:36+0000",
            "content": "We can do that in DrillDownStream - if the termAttribute.length is > MAX/4, refused to add that category?\n\n+1 ",
            "author": "Michael McCandless",
            "id": "comment-13679497"
        },
        {
            "date": "2013-06-10T14:08:09+0000",
            "content": "I added CP.MAX_CATEGORY_PATH_LENGTH = (BYTE_BLOCK_SIZE - 2) / 4 - so now you cannot create such a long CP at all (ctors verify that).\n\nI also added _TestUtil.randomSimpleString(r,min,max) and modified the test to use it instead of randomRealistic \u2013 since we limit by characters, not codepoints, using randomRealisticUnicodeString sometimes failed on too large components, which is not what the test checks.\n\nI think now it's ready! ",
            "author": "Shai Erera",
            "id": "comment-13679519"
        },
        {
            "date": "2013-06-10T17:03:18+0000",
            "content": "+1\n\nOne minor thing: you no longer have to check for \\u001f: randomSimpleString never returns that char. ",
            "author": "Michael McCandless",
            "id": "comment-13679627"
        },
        {
            "date": "2013-06-10T18:33:47+0000",
            "content": "I agree. Technically it's even wrong to use that char specifically - if at all we should use the constant from FacetIndexingParams. But I'll remove. ",
            "author": "Shai Erera",
            "id": "comment-13679747"
        },
        {
            "date": "2013-06-10T18:41:16+0000",
            "content": "[trunk commit] shaie\nhttp://svn.apache.org/viewvc?view=revision&revision=1491562\n\nLUCENE-5048: limit CategoryPath total length ",
            "author": "Commit Tag Bot",
            "id": "comment-13679758"
        },
        {
            "date": "2013-06-10T18:54:10+0000",
            "content": "Committed to trunk and 4x. Thanks Colton for reporting! ",
            "author": "Shai Erera",
            "id": "comment-13679771"
        },
        {
            "date": "2013-06-27T07:15:03+0000",
            "content": "Wow. Thanks  I happened to trigger this bug yesterday, and found it very hard to reproduce.  (I do have a testset which triggers this bug in about 4 seconds; if it has value I'll attach it to this issue).  ",
            "author": "Rob Audenaerde",
            "id": "comment-13694540"
        },
        {
            "date": "2013-06-27T07:19:23+0000",
            "content": "Thanks Rob. The bug is already fixed (will be released in 4.4) and I was able to create a very short testcase (which adds only few categories) to reproduce it. ",
            "author": "Shai Erera",
            "id": "comment-13694541"
        },
        {
            "date": "2013-07-23T18:37:09+0000",
            "content": "Bulk close resolved 4.4 issues ",
            "author": "Steve Rowe",
            "id": "comment-13716763"
        }
    ]
}