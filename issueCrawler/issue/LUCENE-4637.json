{
    "id": "LUCENE-4637",
    "title": "Using StringField for while storing becomes a regular Field when the document is retrieved - Due to this the next search cannot find the document because the value of the Field got tokenized which was not desired when it was added",
    "details": {
        "components": [
            "core/index"
        ],
        "fix_versions": [
            "6.0"
        ],
        "affect_versions": "4.0",
        "priority": "Major",
        "labels": "",
        "type": "Bug",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "In this case, I don't want Lucene to tokenize the value for a field that is being added to the document in the index and hence StringField is used. Once we do a search using one of the field values, we get the Document object from the searcher but the type of the field becomes Field instead of the StringField. So when I try to update the value of one of the fields in the document and then do another seacrh using the same term, the 2nd search fails to find this document.\n\nIn order to reproduce the case, please use the code below.\n\n\nSample class:\n/////////////\n\n\npackage com.thegoldensource.demo;\n\nimport java.io.IOException;\nimport java.util.List;\n\nimport org.apache.lucene.analysis.Analyzer;\nimport org.apache.lucene.analysis.core.WhitespaceAnalyzer;\nimport org.apache.lucene.document.Document;\nimport org.apache.lucene.document.Field.Store;\nimport org.apache.lucene.document.StringField;\nimport org.apache.lucene.index.DirectoryReader;\nimport org.apache.lucene.index.IndexWriter;\nimport org.apache.lucene.index.IndexWriterConfig;\nimport org.apache.lucene.index.IndexableField;\nimport org.apache.lucene.index.Term;\nimport org.apache.lucene.search.IndexSearcher;\nimport org.apache.lucene.search.ScoreDoc;\nimport org.apache.lucene.search.TermQuery;\nimport org.apache.lucene.search.TopDocs;\nimport org.apache.lucene.store.Directory;\nimport org.apache.lucene.store.RAMDirectory;\nimport org.apache.lucene.util.Version;\n\n/**\n *\n\n\t@author rparekh\n *\n */\npublic class SimpleTest {\n\n\n\n\t/**\n\n\t@param args\n\t */\n\tpublic static void main(String[] args) {\n\n\n\n\t\ttry\n\t\t{\n\n\t\t\tAnalyzer analyzer = new WhitespaceAnalyzer(Version.LUCENE_40);\n\n\t\t    // Store the index in memory:\n\t\t    Directory directory = new RAMDirectory();\n\t\t    // To store an index on disk, use this instead:\n\t\t    //Directory directory = FSDirectory.open(\"/tmp/testindex\");\n\t\t    IndexWriterConfig config = new IndexWriterConfig(Version.LUCENE_30, analyzer);\n\t\t    IndexWriter iwriter = new IndexWriter(directory, config);\n\t\t    Document doc = new Document();\n\t\t    String text = \"This is the text\";\n\n\t\t    doc.add(new StringField(\"id\", \"a\", Store.NO));\n\t\t    doc.add(new StringField(\"content\", text, Store.YES));\n\n\t\t    iwriter.addDocument(doc);\n\t\t    iwriter.commit();\n\n\n\t\t    // Now search the index:\n\t\t    DirectoryReader ireader = DirectoryReader.open(directory);\n\t\t    IndexSearcher isearcher = new IndexSearcher(ireader);\n\n\t\t    Term myTerm = new Term(\"id\", \"a\");\n\t\t    TermQuery query = new TermQuery(myTerm); \n\t\t    TopDocs docs = isearcher.search(query, 1);\n\t\t    int hits = docs.totalHits;\n\t\t    System.out.println(\"Hits : \" + hits);\n\t\t    ScoreDoc[] documents = docs.scoreDocs;\n\t\t    Document d = null;\n\t\t    for(int i=0; i < documents.length; i++)\n\t\t    {\n\t\t    \td = isearcher.doc(documents[i].doc);\n\t\t    \tIndexableField contentField = d.getField(\"content\");\n\n\t\t    \tif(contentField != null)\n\t\t    \t{\n\t\t    \t\tSystem.out.println(\"Content from doc : [\" + contentField.stringValue() + \"]\");\t\n\t\t    \t}\n\t\t    }\n\n\t\t    // For updating the value of a field, remove the field and add it again.\n\t\t    d.removeField(\"content\");\n\t\t    d.add(new StringField(\"content\", \"new content\",Store.YES));\n\t    \tList<IndexableField> fields = d.getFields();\n\n\t\t    iwriter.updateDocument(myTerm, fields);\n\n\t\t    iwriter.commit();\n\t\t    iwriter.close();\n\n\t\t    // Search the document again\n\t\t    DirectoryReader newReader = DirectoryReader.open(directory);\n\t\t    IndexSearcher newSeracher = new IndexSearcher(newReader);\n\n\t\t    TermQuery newTermQuery = new TermQuery(myTerm);\n\t\t    TopDocs newTopDocs = newSeracher.search(newTermQuery, 10);\n\t\t    int hits1 = newTopDocs.totalHits;\n\n\t\t    // Number of hits should be 1 but it is 0 (zero) - This is because the type of \n\t\t    // Fields in the document that was retrieved changes from the original StringField to Field which is not correct\n\t\t    System.out.println(\"Hits again : \" + hits1 );\n\n\t\t    if(hits1 > 0)\n\t\t    {\n\t\t\t    ScoreDoc[] documents1 = newTopDocs.scoreDocs;\n\n\t\t\t    Document d1 = newSeracher.doc(documents1[0].doc);\n\n\t\t\t    IndexableField newContent = d1.getField(\"content\");\n\t\t\t    if(newContent != null)\n\t\t\t    {\n\t\t\t    \tSystem.out.println(\"New Content : [\" + newContent.stringValue() + \"]\");\n\t\t\t    }\n\t\t    }\n\n\t\t    ireader.close();\n\t\t    directory.close();\n\t\t}\n\t\tcatch(IOException e)\n\t\t{\n\t\t\tSystem.err.print(e);\n\t\t}\n\n\t}\n\n}\n\n/////////////\n\n\nOutput:\nHits : 1\nContent from doc : [This is the text]\nHits again : 0",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "date": "2012-12-19T13:53:14+0000",
            "content": "Lucene 5.0 will no longer return o.a.l.Document instances from IndexReader/IndexSearcher so it is no longer possible to index them using IndexWriter.\nIt is a bug in your application to use stored documents as source for reindexing without taking extra care. This was always problematic since the beginning of Lucene and always created problems. This lead to the fix in LUCENE-3312 to be fixed in Lucene 5.0 by returning a different instance type. ",
            "author": "Uwe Schindler",
            "id": "comment-13535963"
        }
    ]
}