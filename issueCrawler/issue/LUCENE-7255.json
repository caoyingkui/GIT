{
    "id": "LUCENE-7255",
    "title": "Paging with SortingMergePolicy and EarlyTerminatingSortingCollector",
    "details": {
        "resolution": "Unresolved",
        "affect_versions": "5.3,                                            5.4,                                            5.5,                                            6.0",
        "components": [],
        "labels": "",
        "fix_versions": [],
        "priority": "Major",
        "status": "Open",
        "type": "Bug"
    },
    "description": "EarlyTerminatingSortingCollector seems to don't work when used with a TopDocsCollector searching for documents after a certain FieldDoc. That is, it can't be used for paging. The following code allows to reproduce the problem:\n\n// Sort to be used both with merge policy and queries\nSort sort = new Sort(new SortedNumericSortField(FIELD_NAME, SortField.Type.INT));\n\n// Create directory\nRAMDirectory directory = new RAMDirectory();\n\n// Setup merge policy\nTieredMergePolicy tieredMergePolicy = new TieredMergePolicy();\nSortingMergePolicy sortingMergePolicy = new SortingMergePolicy(tieredMergePolicy, sort);\n\n// Setup index writer\nIndexWriterConfig indexWriterConfig = new IndexWriterConfig(new SimpleAnalyzer());\nindexWriterConfig.setOpenMode(IndexWriterConfig.OpenMode.CREATE_OR_APPEND);\nindexWriterConfig.setMergePolicy(sortingMergePolicy);\nIndexWriter indexWriter = new IndexWriter(directory, indexWriterConfig);\n\n// Index values\nfor (int i = 1; i <= 1000; i++) {\n    Document document = new Document();\n    document.add(new NumericDocValuesField(FIELD_NAME, i));\n    indexWriter.addDocument(document);\n}\n\n// Force index merge to ensure early termination\nindexWriter.forceMerge(1, true);\nindexWriter.commit();\n\n// Create index searcher\nIndexReader reader = DirectoryReader.open(directory);\nIndexSearcher searcher = new IndexSearcher(reader);\n\n// Paginated read\nint pageSize = 10;\nFieldDoc pageStart = null;\nwhile (true) {\n\n    logger.info(\"Collecting page starting at: {}\", pageStart);\n\n    Query query = new MatchAllDocsQuery();\n\n    TopDocsCollector tfc = TopFieldCollector.create(sort, pageSize, pageStart, true, false, false);\n    EarlyTerminatingSortingCollector collector = new EarlyTerminatingSortingCollector(tfc, sort, pageSize, sort);\n    searcher.search(query, collector);\n    ScoreDoc[] scoreDocs = tfc.topDocs().scoreDocs;\n    for (ScoreDoc scoreDoc : scoreDocs) {\n        pageStart = (FieldDoc) scoreDoc;\n        logger.info(\"FOUND {}\", scoreDoc);\n    }\n\n    logger.info(\"Terminated early: {}\", collector.terminatedEarly());\n\n    if (scoreDocs.length < pageSize) break;\n}\n\n// Close\nreader.close();\nindexWriter.close();\ndirectory.close();\n\n\nThe query for the second page doesn't return any results. However, it gets the expected results when if we don't wrap the TopFieldCollector with the EarlyTerminatingSortingCollector.",
    "attachments": {
        "LUCENE-7255_v0.diff": "https://issues.apache.org/jira/secure/attachment/12801244/LUCENE-7255_v0.diff"
    },
    "issue_links": {},
    "comments": [
        {
            "id": "comment-15257870",
            "author": "Christine Poerschke",
            "date": "2016-04-26T10:30:06+0000",
            "content": "Hi Andr\u00e9s de la Pe\u00f1a -  thanks for the report and code to reproduce.\n\nI haven't yet tried to add your code to the existing TestEarlyTerminatingSortingCollector tests but from just reading the code think that a higher numDocsToCollect argument might need to be passed to the EarlyTerminatingSortingCollector constructor i.e.\n\n\n- EarlyTerminatingSortingCollector collector = new EarlyTerminatingSortingCollector(tfc, sort, pageSize, sort);\n+ EarlyTerminatingSortingCollector collector = new EarlyTerminatingSortingCollector(tfc, sort, numToSkip+pageSize, sort);\n\n\n\nIs that something you could try out when you have a few minutes? This could make a good additional TestEarlyTerminatingSortingCollector test I think.\n\n "
        },
        {
            "id": "comment-15257918",
            "author": "Andr\u00e9s de la Pe\u00f1a",
            "date": "2016-04-26T11:21:36+0000",
            "content": "Hi Christine Poerschke,\n\nYou are totally right, the test works perfectly passing the total number of hits:\n\n// Sort to be used both with merge policy and queries\nSort sort = new Sort(new SortedNumericSortField(FIELD_NAME, SortField.Type.INT));\n\n// Create directory\nRAMDirectory directory = new RAMDirectory();\n\n// Setup merge policy\nTieredMergePolicy tieredMergePolicy = new TieredMergePolicy();\nSortingMergePolicy sortingMergePolicy = new SortingMergePolicy(tieredMergePolicy, sort);\n\n// Setup index writer\nIndexWriterConfig indexWriterConfig = new IndexWriterConfig(new SimpleAnalyzer());\nindexWriterConfig.setOpenMode(IndexWriterConfig.OpenMode.CREATE_OR_APPEND);\nindexWriterConfig.setMergePolicy(sortingMergePolicy);\nIndexWriter indexWriter = new IndexWriter(directory, indexWriterConfig);\n\n// Index values\nfor (int i = 1; i <= 1000; i++) {\n    Document document = new Document();\n    document.add(new NumericDocValuesField(FIELD_NAME, i));\n    indexWriter.addDocument(document);\n}\n\n// Force index merge to ensure early termination\nindexWriter.forceMerge(1, true);\nindexWriter.commit();\n\n// Create index searcher\nIndexReader reader = DirectoryReader.open(directory);\nIndexSearcher searcher = new IndexSearcher(reader);\n\n// Initialize paging state\nint numFound = 0;\nFieldDoc pageStart = null;\n\n// Paginated read\nwhile (true) {\n\n    logger.info(\"Collecting page starting at: {}\", pageStart);\n\n    Query query = new MatchAllDocsQuery();\n\n    TopDocsCollector tfc = TopFieldCollector.create(sort, PAGE_SIZE, pageStart, true, false, false);\n    Collector collector = new EarlyTerminatingSortingCollector(tfc, sort, numFound + PAGE_SIZE, sort);\n    searcher.search(query, collector);\n    ScoreDoc[] scoreDocs = tfc.topDocs().scoreDocs;\n    for (ScoreDoc scoreDoc : scoreDocs) {\n\n        logger.info(\"FOUND {}\", scoreDoc);\n\n        // Update paging state\n        pageStart = (FieldDoc) scoreDoc;\n        numFound++;\n    }\n\n    if (scoreDocs.length < PAGE_SIZE) break;\n}\n\n// Close\nreader.close();\nindexWriter.close();\ndirectory.close();\n\n\nHi totally misunderstood the argument numDocsToCollect in EarlyTerminatingSortingCollector constructor \n\nSo the deep paging state of applications using a sorted index must be composed not only by the last FieldDoc but also by the number of already read documents. I guess that it is something to be taken into account by LUCENE-6766, probably IndexSearcher.searchAfter(ScoreDoc after, Query query, int n, Sort sort) should become IndexSearcher.searchAfter(ScoreDoc after, int numToSkip, Query query, int n, Sort sort), or something similar, don't you think so? Do you think it would be possible to directly pass the page size to the EarlyTerminatingSortingCollector instead of the number of documents to collect?\n\nI will be happy adding the paging test to TestEarlyTerminatingSortingCollector, if you want.\n\nThanks for your help. "
        },
        {
            "id": "comment-15257952",
            "author": "Christine Poerschke",
            "date": "2016-04-26T11:59:52+0000",
            "content": "Do you think it would be possible to directly pass the page size to the EarlyTerminatingSortingCollector instead of the number of documents to collect?\n\nDo you mean something like this i.e. a sort of convenience additional constructor?\n\n\n- public EarlyTerminatingSortingCollector(Collector in, Sort sort, int numDocsToCollect, Sort mergePolicySort) {\n-   ...\n- }\n\n+ public EarlyTerminatingSortingCollector(Collector in, Sort sort, int numDocsToCollect, Sort mergePolicySort) {\n+   this(in, sort, 0, numDocsToCollect, mergePolicy);\n+ }\n+\n+ public EarlyTerminatingSortingCollector(Collector in, Sort sort, int numToSkip, int numWanted, Sort mergePolicySort) {\n+   ...\n+ }\n\n\n\nThat sounds good to me. Shai Erera, Robert Muir, Adrien Grand - what do you think?\n\nI will be happy adding the paging test to TestEarlyTerminatingSortingCollector, if you want.\n\n+1 for a paging test. "
        },
        {
            "id": "comment-15258025",
            "author": "Andr\u00e9s de la Pe\u00f1a",
            "date": "2016-04-26T12:54:41+0000",
            "content": "I was thinking in being able to build a EarlyTerminatingSortingCollector just with the number of wanted documents, either changing the meaning of the argument:\n\n- public EarlyTerminatingSortingCollector(Collector in, Sort sort, int numDocsToCollect, Sort mergePolicySort) {\n-   ...\n- }\n\n+ public EarlyTerminatingSortingCollector(Collector in, Sort sort, int numWanted, Sort mergePolicySort) {\n+   ...\n+ }\n\n\nor maybe adding a new method:\n\n+ public EarlyTerminatingSortingCollector buildWithWanted(Collector in, Sort sort, int numWanted, Sort mergePolicySort) {\n+   ...\n+ }\n\n\nThis way, if it is possible, the paging state managed by users would be composed only by the last FieldDoc, as it is done by other collectors. Otherwise, if I'm right, the paging state managed by users using sorted indexes should be composed by both the last FieldDoc and also the number of already collected documents, and an hypothetical IndexSearcher aware of index sorting such as the proposed by LUCENE-6766 should modify its searchAfter method to require the number of documents to skip. \n "
        },
        {
            "id": "comment-15258054",
            "author": "Adrien Grand",
            "date": "2016-04-26T13:11:36+0000",
            "content": "I like the API better as it is today since it is more explicit about how it is working. I suspect there might be some confusion about how searchAfter works in the non-sorted case: even though the last competitive document is provided, the query needs to visit all matches. The collector will just ignore documents that compare better than after since they were already returned on a previous page. Compared to regular pagination, this is better since we can use a priority queue of size size rather than from+size, but in both cases, all matching documents are collected.\n\nWe could make pagination work better in the case of sorted segments by tracking the last competitive document per segment rather than at the index level. This way, on each sorted segment, we could directly jump to the next competitive document, so the collector would actually only collect numWanted documents rather than numToSkip+numWanted. This would require a custom collector however. "
        },
        {
            "id": "comment-15262224",
            "author": "Andr\u00e9s de la Pe\u00f1a",
            "date": "2016-04-28T14:26:03+0000",
            "content": "Ok, I see. It would be great for deep pagination to take advantage of index sorting without requiring the number of documents to skip. (LUCENE-6766|https://issues.apache.org/jira/browse/LUCENE-6766) is really promising \n\nI'm attaching a patch adding the aforementioned pagination test to TestEarlyTerminatingSortingCollector. It's my first patch for Lucene so please be indulgent. "
        },
        {
            "id": "comment-15262327",
            "author": "Robert Muir",
            "date": "2016-04-28T15:24:25+0000",
            "content": "\nOk, I see. It would be great for deep pagination to take advantage of index sorting without requiring the number of documents to skip. (LUCENE-6766|https://issues.apache.org/jira/browse/LUCENE-6766) is really promising \n\nI agree, I think its crucial to not require the user to do a bunch of tracking. Otherwise it defeats the point of the searchAfter method, which is to make it easy for things to be more efficient if you want to page.\n\n\nWe could make pagination work better in the case of sorted segments by tracking the last competitive document per segment rather than at the index level. This way, on each sorted segment, we could directly jump to the next competitive document, so the collector would actually only collect numWanted documents rather than numToSkip+numWanted. This would require a custom collector however.\n\nWe should not let \"would require a custom collector\" prevent exploring this. I see it as, a custom collector is currently already required, and to boot: paging does not work with it \n\nOf course, it is important that long-term this stuff can work with searchAfter automatically. But I don't see any proposals for how this can work now, and I'm pretty sure to support it, we need to \"track more stuff\" on behalf of the user.\n\nThere are a lot of ways that could work for this collector, a number like Christine's `numToSkip` combined with `topValue`, or Adrien's per-segment set of docIDs, or a per-segment set of docIDs combined with `topValue` (to keep priority queues constant size on the unsorted segments), and so on.\n\nBut I don't think we should worry about this right now. I think the searchAfter api will need some change regardless if we want it to work transparently, and that should be thought out carefully. "
        }
    ]
}