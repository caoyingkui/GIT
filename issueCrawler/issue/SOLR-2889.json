{
    "id": "SOLR-2889",
    "title": "Implement Adaptive Replacement Cache",
    "details": {
        "affect_versions": "3.4",
        "status": "Closed",
        "fix_versions": [],
        "components": [
            "search"
        ],
        "type": "New Feature",
        "priority": "Minor",
        "labels": "",
        "resolution": "Won't Fix"
    },
    "description": "Currently Solr's caches are LRU, which doesn't look at hitcount to decide which entries are most important.  There is a method that takes both frequency and time of cache hits into account:\n\nhttp://en.wikipedia.org/wiki/Adaptive_Replacement_Cache\n\nIf it's feasible, this could be a good addition to Solr/Lucene.",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "author": "Simon Willnauer",
            "id": "comment-13147937",
            "date": "2011-11-10T19:17:34+0000",
            "content": "having a more diverse caching infrastructure is certainly something solr & lucene could make use of. I'd like to see this kind of stuff in lucene too so lucene users can make use of this too. Maybe we can factor out the solr caches into a caching module by makeing them more generic? "
        },
        {
            "author": "Jason Rutherglen",
            "id": "comment-13148003",
            "date": "2011-11-10T20:56:59+0000",
            "content": "+1 - Put it in Lucene and NOT Solr.  thanks.  \n\nWhen this is implemented, using Google collections should be developed as well (which appropriately jettisons the cache values before OOM), ala the previously created though not committed SOLR-1513. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13148014",
            "date": "2011-11-10T21:14:44+0000",
            "content": "Put it in Lucene and NOT Solr. thanks.\n\nWe've been over this - improvements to Solr should not be blocked just because someone else desires the functionality in lucene.\nIt's up to the person doing the work, what their objectives are, how much time they have, etc. "
        },
        {
            "author": "Jason Rutherglen",
            "id": "comment-13148065",
            "date": "2011-11-10T22:36:27+0000",
            "content": "Yonik, Take a step back.  No analyzers are in Solr, and the caching and other 'parts' will be moved out.  It's reasonable to expect that process to happen on new additions to what is a singular project. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13148078",
            "date": "2011-11-10T22:45:59+0000",
            "content": "It's reasonable to expect that process to happen on new additions to what is a singular project.\n\nSorry, no. It's completely unrelated.  Adding conditional numHits per entry to FastLRUCache would be a small simple change.  Trying to figure out what/how to refactor Solr's current caching into a module is at least an order of magnitude (or two) harder.  You can tackle that anytime you feel like it, but don't force it on anyone else. "
        },
        {
            "author": "Simon Willnauer",
            "id": "comment-13148082",
            "date": "2011-11-10T22:52:41+0000",
            "content": "@yonik: I agree progress over perfection... this can happen afterwards\n\n@shawn: please go ahead and hack on what you wanted to do, your contribution is more than welcome! You should start where and with what you feel comfortable and we gonna work towards improving our codebase. My idea I mentioned above with adding a module is a long term goal, lets concentrate on what this issue tries to achieve.\n\n@jason: I agree with yonik, we have been there and we should not express our strong feelings loud in every issue possible. We'll get there its open source!  "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-13148124",
            "date": "2011-11-10T23:48:30+0000",
            "content": "@simon: I will certainly take a look, and I am encouraged by yonik's assessment that it's a simple change, but I have to say that I'm a Java newbie.  I hope that I can do it, but I'm not super optimistic. "
        },
        {
            "author": "Simon Willnauer",
            "id": "comment-13148133",
            "date": "2011-11-11T00:02:43+0000",
            "content": "Shawn, don't worry we can iterate over you patches! I am optimistic! Welcome to solr & lucene  "
        },
        {
            "author": "Jason Rutherglen",
            "id": "comment-13148269",
            "date": "2011-11-11T05:09:02+0000",
            "content": "Simon and Yonik, re-read what you wrote, have fun. "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-13148529",
            "date": "2011-11-11T15:19:35+0000",
            "content": "Two things:\n\n1) After some thought, I have concluded that a straight LFU cache might fit my needs perfectly, and it's a baby step towards ARC.\n\n2) I took a quick look at some of the code.  The code for cache trimming and warming is in ConcurrentLRUCache.java, but the hits seem to be tracked in \n{Fast}\nLRUCache.java.  I think this means that the first step would be to refactor things so that we have one or more base classes with common functionality, which are then extended or imported by smaller classes that implement LRU, LFU, and ARC.\n\nAm I on the right track?  Does this need another issue? "
        },
        {
            "author": "Lance Norskog",
            "id": "comment-13148725",
            "date": "2011-11-11T20:50:31+0000",
            "content": "If you are working on the caches, better instrumentation would be a good feature. I would like to know how much 'churn' is happening: if I have 90% semi-permanent members and 10% constantly changing, that means my cache needs tuning. "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-13148880",
            "date": "2011-11-12T00:11:56+0000",
            "content": "@lance: To say I'm working on it is very much an overstatement.  I have taken a quick look, enough to know that I may be in over my head, requiring a lot of learning before diving in.  I will give it a try, but Yoda probably would not be impressed by the results. "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-13149179",
            "date": "2011-11-12T23:05:38+0000",
            "content": "FastLRUCache uses ConcurrentLRUCache, which includes a full class for a cache entry.  A new member could be added to CacheEntry pretty easily to track usage, but the rest of the code would have to me modified to use it.  Making sure it's all thread-safe would probably be the hard part.\n\nLRUCache relies on the alternate sort order on LinkedHashMap, so it would not be as simple to add usage tracking.\n\nSomething I noticed along the way: The solrj tree seems like an odd place for ConcurrentLRUCache, because nothing else in that section uses it (directly at least). "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13149208",
            "date": "2011-11-13T02:37:23+0000",
            "content": "LRUCache relies on the alternate sort order on LinkedHashMap, so it would not be as simple to add usage tracking.\n\nA single cache that tracks hits per entry would be enough I think - no need to add the capability to all existing cache types.\n\nThe solrj tree seems like an odd place for ConcurrentLRUCache, because nothing else in that section uses it (directly at least).\n\nHmmm, never realized that.  Perhaps just due to the fact that it was in the util package? "
        },
        {
            "author": "Chris Male",
            "id": "comment-13149215",
            "date": "2011-11-13T04:38:29+0000",
            "content": "ConcurrentLRUCache has been moved out of SolrJ and into Solr Core in trunk and 3x in SOLR-2758.  Which source code checkout are you looking at? "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-13149236",
            "date": "2011-11-13T06:57:28+0000",
            "content": "ConcurrentLRUCache has been moved out of SolrJ and into Solr Core in trunk and 3x in SOLR-2758. Which source code checkout are you looking at?\n\nI'm looking at 3.4.0, the version I'm running. "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-13149949",
            "date": "2011-11-14T21:33:23+0000",
            "content": "After a close look, I find overall understanding elusive, and I have been told by my employer not to spend a lot of time on it.  It must be relegated to my spare time, which is pretty scarce. "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-13152641",
            "date": "2011-11-18T04:34:16+0000",
            "content": "My original approach wasn't working well, which is why I said I wasn't going to be able to do it.  Today I took a different approach, and the changes were pretty easy.  I just made copies of ConcurrentLRUCache.java and FastLRUCache.java, then renamed and massaged them into LFU versions.  The heart of what I did was remove lastAccessed and turned it into an AtomicLong named hits.\n\nIt does work as a cache for some simple hand-entered queries, but I need to do some more extensive testing to see if evictions and warming are working as expected before I upload it.  I think I'll temporarily stick in some println statements to watch what it's doing.\n\nSome other things that need to be done that I'm not sure I'm qualified for (but I will attempt):\n\n\n\tTest code.\n\tAbstracting out the common parts into parent classes.\n\n "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-13254671",
            "date": "2012-04-16T13:12:57+0000",
            "content": "After thinking about what ended up being the final code for SOLR-2906, I know that I won't be able to tackle this, but I am wondering whether this is really necessary any more.  The timeDecay option on the LFU cache implementation could be viewed as an LRU tweak to the LFU cache, which I think fulfills my original goals even if it's not a true ARC cache.  Does that mean this issue should be closed?  I can't say.\n\nI hope someone really smart is able to provide some serious speed optimization for the new LFU cache. "
        },
        {
            "author": "austin collins",
            "id": "comment-13255108",
            "date": "2012-04-16T22:00:00+0000",
            "content": "@Shawn I have been reading though your comments. Well done for taking on this project, it sounds like a good achievement and addition to the open-s-c. \n\nYou set out with a goal, and I guess this was to make performance gains. However you don't sound confident you have achieved this when you ask for someone to provide some speed optimization. \n\nWould you mind posting some information about the results of your work and how much performance gain you made. If you have benchmark results this would be ideal. Did you notice any increase/decrease in memory and CPU demand? "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-13255727",
            "date": "2012-04-17T17:01:17+0000",
            "content": "Would you mind posting some information about the results of your work and how much performance gain you made. If you have benchmark results this would be ideal. Did you notice any increase/decrease in memory and CPU demand?\n\nI haven't done any extensive testing.  The testing that I did do for SOLR-2906 suggested that the LFU cache did not offer any performance benefit over LRU, but that it didn't really cause a performance detriment either.  I think this means that the idea was sound, but any speedups gained from the different methodology were lost because of the basic and non-optimized implementation.\n\nIt was not a definitive test - I have two copies of my production distributed index for redundancy purposes, with haproxy doing load balancing between the two.  I can set one set of servers to LFU and the other to LRU, but it's production, so the two sets of servers never receive the same queries and I don't really want to try any isolation tests on production equipment.  My testbed is too small for a doing tests with all production data - one server with all resources smaller than production.  I could do some tests with smaller data sets that will fit entirely in RAM, but that will take a lot of planning that I currently don't have time to do.\n\nThe LRU cache is highly optimized for speed, but I didn't really understand the optimizations and they don't apply to LFU as far as I can tell.  At this time I am still using LRU cache because I don't dare change the production configuration without authorization and I can't leave production servers in test mode for very long. "
        },
        {
            "author": "Shawn Heisey",
            "id": "comment-13636590",
            "date": "2013-04-19T16:50:22+0000",
            "content": "Although I think an ARC would be really cool, the work on SOLR-3393 is probably good enough.  Closing this issue.\n\nThis is part of an effort to close old issues that I have reported.  Search tag: elyograg2013springclean "
        }
    ]
}