{
    "id": "LUCENE-5197",
    "title": "Add a method to SegmentReader to get the current index heap memory size",
    "details": {
        "components": [
            "core/codecs",
            "core/index"
        ],
        "fix_versions": [
            "4.5",
            "6.0"
        ],
        "affect_versions": "None",
        "priority": "Major",
        "labels": "",
        "type": "Improvement",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "It would be useful to at least estimate the index heap size being used by Lucene. Ideally a method exposing this information at the SegmentReader level.",
    "attachments": {
        "LUCENE-5197.patch": "https://issues.apache.org/jira/secure/attachment/12601092/LUCENE-5197.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2013-09-02T23:40:49+0000",
            "content": "Initial patch file that only takes into account classes in the codecs package to estimate the index heap memory usage for a SegmentReader ",
            "author": "Areek Zillur",
            "id": "comment-13756268"
        },
        {
            "date": "2013-09-03T08:31:35+0000",
            "content": "Very nice work, I agree it would be nice to be able to have a better overview of Lucene's memory usage! Regarding the patch, it looks to me that some null checks are unnecessary, eg. AssertingFieldsConsumer.in. ",
            "author": "Adrien Grand",
            "id": "comment-13756450"
        },
        {
            "date": "2013-09-03T08:39:02+0000",
            "content": "I can foresee how all this calculations go out of sync with changing implementations  Wouldn't RamUsageEstimator (or its modification) be a better choice to do it dynamically somehow?\n\nI realize there is an overhead involved, but it should be more portable/ accurate/ easier to maintain if it's not implemented separately in all of these classes.\n\nJust a thought. ",
            "author": "Dawid Weiss",
            "id": "comment-13756452"
        },
        {
            "date": "2013-09-03T08:44:30+0000",
            "content": "I was thinking about RamUsageEstimator but it has some pitfalls too I think. For example, RAMInputStream has a link to RAMFile which in turns has a link to the RAMDirectory. So every time you would run RamUsageEstimator on a format producer, you would take into account the whole directory size? ",
            "author": "Adrien Grand",
            "id": "comment-13756456"
        },
        {
            "date": "2013-09-03T08:45:20+0000",
            "content": "Wouldn't RamUsageEstimator (or its modification) be a better choice to do it dynamically somehow?\n\nI agree and had exactly that thought in mind. This is not the type of API that needs to be blazing fast and the overhead in RamUsageEstimator is totally accepted IMO. I can see how this gets incorrect very quickly... ",
            "author": "Shai Erera",
            "id": "comment-13756457"
        },
        {
            "date": "2013-09-03T08:48:41+0000",
            "content": "I guess you'd have to modify RamUsageEstimator to allow a tree-visitor pattern, then you'd be able to only account for the nodes that matter (or ignore those you know shouldn't be counted).\n\nThis also has some caveats \u2013 like references to things that shouldn't be counted (thread locals reaching out to thread instances, loggers reaching out to pretty much everything...). Having said that, I can see how such an implementation can be tested to detect things like this early, which with the manual counting may be a problem.\n\nAgain \u2013 I'm not saying \"no\", I'm just expressing concern about the size and complexity of the patch. If there's a simpler way to do it that is performance-acceptable we should probably follow Occam's razor... ",
            "author": "Dawid Weiss",
            "id": "comment-13756458"
        },
        {
            "date": "2013-09-03T08:53:32+0000",
            "content": "Again \u2013 I'm not saying \"no\", I'm just expressing concern about the size and complexity of the patch.\n\nSure, I'm concerned about this too and I think the tree-visitor pattern for RamUsageEstimator is a nice idea! ",
            "author": "Adrien Grand",
            "id": "comment-13756461"
        },
        {
            "date": "2013-09-03T09:07:33+0000",
            "content": "It'd be cool to have it for other reasons as well (excluding certain fields from being counted, etc.). The minor glitch is that RamUsageEstimator's implementation is stack-based, not recursive (to prevents stack overflows) but it shouldn't be a biggie. ",
            "author": "Dawid Weiss",
            "id": "comment-13756470"
        },
        {
            "date": "2013-09-03T12:19:05+0000",
            "content": "This would be a great addition!  And I agree if we can somehow do this with RUE, being able to restrict where it's allowed to \"crawl\", that would be nice.\n\nSeparately, I wonder if we could get a breakdown of the RAM usage ... sort of like Explanation, which returns both the value and a String (English) description of how the value was computed.  But this can come later ... just a ramBytesUsed returning long is a great start. ",
            "author": "Michael McCandless",
            "id": "comment-13756552"
        },
        {
            "date": "2013-09-03T12:23:33+0000",
            "content": "This can be done with the same implementation \u2013 a tree visitor could collect partial sums and aggregate them for the object hierarchy in the form of a tree rather than sum it all up. \n\nThis is sort-of implemented here (although I kept the same implementation of RamUsageEstimator; a visitor pattern would be more elegant I think).\nhttps://github.com/dweiss/java-sizeof/blob/master/src/main/java/com/carrotsearch/sizeof/ObjectTree.java ",
            "author": "Dawid Weiss",
            "id": "comment-13756556"
        },
        {
            "date": "2013-09-03T13:10:38+0000",
            "content": "From my perspective: Usage of RAMUsageEstimator is to be preferred, everything else gets outdated very fast (especially we have no idea about caches like FieldCache used). In production RAMDirectory is not used, and things like MMap or NIOFSDir have no heap usage and default codec is also not much, so I see no reason to don't trust offical RAM usage as reported by RAMUsageEstimator.\nThe memory usage counting of IndexWriter is way different to what we have on the IndexReader side. The accounting done on IndexWriter side are much more under control of the Lucene code and are very fine granular, but stuff like proposed changes in FixedBitSet are just nonsense to me. RAMUsageEstimator can estimate FixedBitSet very correct (that's just easy and in my opinion 100% correct). ",
            "author": "Uwe Schindler",
            "id": "comment-13756595"
        },
        {
            "date": "2013-09-03T14:55:11+0000",
            "content": "RAMUsageEstimator is quite slow when you need to run it on lots of objects (e.g. the codec tree here).\n\nAlso it totally breaks down if it hits certain objects like a ThreadLocal. ",
            "author": "Robert Muir",
            "id": "comment-13756676"
        },
        {
            "date": "2013-09-03T18:35:09+0000",
            "content": "> Also it totally breaks down if it hits certain objects like a ThreadLocal.\n\nThat's why I suggested a visitor pattern, you could tune it not to enter such variables. Also note that if there are lots of objects then the object representation overhead itself will be significant and will vary depending on each VM, its settings, etc; a specific snippet of code to estimate each object's memory use may be faster but it'll be either a nightmare to maintain or it'll be a very rough approximate.\n\nI think it'd be better to try to make RUE faster/ more flexible. Like Shai mentioned \u2013 if it's not a performance-critical API then the difference will not be at all significant. ",
            "author": "Dawid Weiss",
            "id": "comment-13756885"
        },
        {
            "date": "2013-09-03T18:48:14+0000",
            "content": "Attached a patch removing redundant null checks as Adrien suggested.\n\nFirst of all wanted to thank everybody for their valuable inputs.\n\nThe reasons why I choose to have an explicit method to calculate the heap size rather than using the RAMUsageEstimator already has surfaced in the discussion above (slow for many objects, incorrect for some type of objects).\nIt would be nice to have an API to call from (solr Admin for example) to estimate the current index heap size.\n\nI do understand the concern regarding the \"out of sync with implementation changes\" concern, I mainly took into account the codecs for the size estimation only such that higher level APIs need not to implement the method.\n\nThe suggested modified RAMUsageEstimator sounds nice, but as far as I understand would not the logic in implementing the \"excluded objects\" change just as much? while being more implicit than the proposed solution above?  ",
            "author": "Areek Zillur",
            "id": "comment-13756905"
        },
        {
            "date": "2013-09-03T19:03:18+0000",
            "content": "> incorrect for some type of objects\n\nCan you elaborate on this? Where was it incorrect?\n\n> would not the logic in implementing the \"excluded objects\" change just as much?\n\nI think it'd be much simpler to exclude the type of objects we know spin out of control - loggers, thread locals, thread references and leave the remaining stuff accounted. After all if it's referenced it does take space on the heap so the figure is correct. What you're doing is actually a skewed view \u2013 it measures certain fields selectively.\n\nI was also thinking in terms of tests \u2013 one can create a sanity test which will create a small index, measure its RAM usage and then fail if it seems \"too large\" (because a thread local or some other field was accounted for). I don't see a way to do such a sanity check for per-class handcrafted code (unless you want to test against RamUsageEstimator, which would duplicate the effort anyway).\n\nLet me stress again that I'm not against your patch, I just have a gut feeling it'll be a recurring theme of new issues in Jira.\n\nYet another idea sprang to my mind \u2013 perhaps if speed is an issue and certain types of objects can efficiently calculate their RAM usage (FSTs), we could make RamUsageEstimator \"aware\" of such objects by introducing an interface like:\n\ninterface IKnowMySize {\n  public long /* super. :) */ sizeMe();\n}\n\n\n\nJokes aside, this could be implemented for classes which indeed have a complex structure and the rest (arrays, etc.) could be counted efficiently by walking the reference graph. Just a thought. ",
            "author": "Dawid Weiss",
            "id": "comment-13756924"
        },
        {
            "date": "2013-09-03T20:11:47+0000",
            "content": "\nWhat you're doing is actually a skewed view \u2013 it measures certain fields selectively.\n\nAnd from a big O perspective, this might be just fine.\n\nThe way i see it, this would be a way to see how much RAM the lucene segment needs for someone's content.\nThings like the terms index and docvalues fields grow according to the content in different ways: e.g. how large/how many terms you have, how they share prefixes, how many documents you have, and so on.\n\nThe \"skew\" is just boring constants pulled out of the equation, even if its 2KB or so, its not interesting at all since its just a constant cost independent of the content. ",
            "author": "Robert Muir",
            "id": "comment-13757009"
        },
        {
            "date": "2013-09-03T20:18:42+0000",
            "content": ">Can you elaborate on this? Where was it incorrect?\n\n\tby incorrect I meant walking up undesirable member variables in a an object. In hindsight, I would say that was a bad choice of wording. I think the correct word would be inflexible.\n\n\n\nI do like the RamUsageEstimator \"aware\"-ness idea. I think that along with some kind of filtering mechanism in RamUsageEstimator would be perfect. ",
            "author": "Areek Zillur",
            "id": "comment-13757021"
        },
        {
            "date": "2013-09-03T21:35:28+0000",
            "content": "> And from a big O perspective, this might be just fine.\n\nHe, he. From a big-O perspective the cost of RUE vs. custom code is negligible \n\nAnyway, fine \u2013 I still think it'd be a nice addition to RUE to allow selective counting (to exclude certain fields from the equation) and it'd be a perfect use case to apply here. But it can be used in other places (like in tests to count static memory usage held by a class, etc.). ",
            "author": "Dawid Weiss",
            "id": "comment-13757109"
        },
        {
            "date": "2013-09-04T11:16:22+0000",
            "content": "+1 to current patch, except SimpleTextFieldsReader does in fact use RAM (it has a termsCache, and it sneakily pre-loads all terms for each field into an FST!).\n\nI think we should go with this current approach, and then later, if/when we improve RUE to easily restrict where it crawls / speed it up / etc., then we can cutover. ",
            "author": "Michael McCandless",
            "id": "comment-13757665"
        },
        {
            "date": "2013-09-04T15:48:07+0000",
            "content": "Can we rename FixedGapTermsIndexReader.getSizeInBytes to FixedGapTermsIndexReader.ramBytesUsed?\n\nOtherwise, the patch consistently uses the same name (ramBytesUsed) throughout, its just this one that is inconsistent. ",
            "author": "Robert Muir",
            "id": "comment-13757889"
        },
        {
            "date": "2013-09-04T17:50:13+0000",
            "content": "Changed getSizeInbytes to ramBytesUsed as Robert suggested ",
            "author": "Areek Zillur",
            "id": "comment-13758040"
        },
        {
            "date": "2013-09-04T18:06:09+0000",
            "content": "Michael McCandless\nI can add a ramBytesUsed method to the SimpleTextTerms class to account for it. But only under the assumption that SimpleTextTerms implementation will be used for the SimpleTextFieldsReader (it uses the abstract Terms class in the termsCache). comments? ",
            "author": "Areek Zillur",
            "id": "comment-13758082"
        },
        {
            "date": "2013-09-04T19:23:01+0000",
            "content": "But only under the assumption that SimpleTextTerms implementation will be used for the SimpleTextFieldsReader (it uses the abstract Terms class in the termsCache). comments?\n\nI think it's fine to change its termsCache to be SimpleTextTerms.  Thanks! ",
            "author": "Michael McCandless",
            "id": "comment-13758234"
        },
        {
            "date": "2013-09-04T20:01:43+0000",
            "content": "Took into account termsCache in SimpleTextFieldReader as discussed with Michael. ",
            "author": "Areek Zillur",
            "id": "comment-13758273"
        },
        {
            "date": "2013-09-06T17:03:43+0000",
            "content": "Some minor cleanups / improvements:\n\nFixed calculations for all-in-ram DV impls: for the esoteric/deprecated ones, it just uses RUE rather than making the code complicated. Facet42 is easy though and accounts correctly now.\n\nAdded missing null check for VariableGapReader's FST (it can happen when there are no terms). ",
            "author": "Robert Muir",
            "id": "comment-13760355"
        },
        {
            "date": "2013-09-09T19:59:09+0000",
            "content": "Commit 1521267 from Robert Muir in branch 'dev/trunk'\n[ https://svn.apache.org/r1521267 ]\n\nLUCENE-5197: Added SegmentReader.ramBytesUsed ",
            "author": "ASF subversion and git services",
            "id": "comment-13762213"
        },
        {
            "date": "2013-09-09T20:33:35+0000",
            "content": "Commit 1521284 from Robert Muir in branch 'dev/branches/branch_4x'\n[ https://svn.apache.org/r1521284 ]\n\nLUCENE-5197: Added SegmentReader.ramBytesUsed ",
            "author": "ASF subversion and git services",
            "id": "comment-13762249"
        },
        {
            "date": "2013-09-09T20:46:47+0000",
            "content": "Thanks Areek! ",
            "author": "Robert Muir",
            "id": "comment-13762264"
        },
        {
            "date": "2013-10-05T10:19:09+0000",
            "content": "4.5 release -> bulk close ",
            "author": "Adrien Grand",
            "id": "comment-13787090"
        }
    ]
}