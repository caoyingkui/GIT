{
    "id": "SOLR-9120",
    "title": "LukeRequestHandler logs WARN \"Error getting file length for [segments_NNN]\" for inconsequential NoSuchFileException situations -- looks scary but is not a problem, logging should be reduced",
    "details": {
        "components": [],
        "type": "Improvement",
        "labels": "",
        "fix_versions": [
            "7.2",
            "master (8.0)"
        ],
        "affect_versions": "5.5,                                            6.0",
        "status": "Closed",
        "resolution": "Fixed",
        "priority": "Major"
    },
    "description": "Begining with Solr 5.5, the LukeRequestHandler started attempting to report the name and file size of the segments file for the current Searcher+IndexReader in use by Solr \u2013 however the filesize information is not always available from the Directory in cases where \"on disk\" commits have caused that file to be removed, for example...\n\n\n\tyou perform index updates & commits w/o \"newSearcher\" being opened\n\tyou \"concurrently\" make requests to the LukeRequestHandler or the CoreAdminHandler requesting \"STATUS\" (ie: after the commit, before any newSearcher)\n\t\n\t\tthese requests can come from the Admin UI passively if it's open in a browser\n\t\n\t\n\n\n\nIn situations like this, a decision was made in SOLR-8587 to log a WARNing in the event that the segments file size could not be determined \u2013 but these WARNing messages look scary and have lead (many) users to assume something is wrong with their solr index.\n\nWe should reduce the severity of these log messages, and improve the wording to make it more clear that this is not a fundemental problem with the index.\n\n\n\n\nHere's some trivial steps to reproduce the WARN message...\n\n\n$ bin/solr -e techproducts\n...\n$ tail -f example/techproducts/logs/solr.log\n...\n\n\n\nIn another terminal...\n\n\n$ curl -H 'Content-Type: application/json' 'http://localhost:8983/solr/techproducts/update?commit=true&openSearcher=false' --data-binary '[{\"id\":\"HOSS\"}]'\n...\n$ curl 'http://localhost:8983/solr/techproducts/admin/luke'\n...\n\n\n\nWhen the \"/admin/luke\" URL is hit, this will show up in the logs \u2013 but the luke request will finish correctly...\n\n\nWARN  - 2017-11-08 17:23:44.574; [   x:techproducts] org.apache.solr.handler.admin.LukeRequestHandler; Error getting file length for [segments_2]\njava.nio.file.NoSuchFileException: /home/hossman/lucene/dev/solr/example/techproducts/solr/techproducts/data/index/segments_2\n\tat sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)\n\tat sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)\n\tat sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)\n\tat sun.nio.fs.UnixFileAttributeViews$Basic.readAttributes(UnixFileAttributeViews.java:55)\n\tat sun.nio.fs.UnixFileSystemProvider.readAttributes(UnixFileSystemProvider.java:144)\n\tat sun.nio.fs.LinuxFileSystemProvider.readAttributes(LinuxFileSystemProvider.java:99)\n\tat java.nio.file.Files.readAttributes(Files.java:1737)\n\tat java.nio.file.Files.size(Files.java:2332)\n\tat org.apache.lucene.store.FSDirectory.fileLength(FSDirectory.java:243)\n\tat org.apache.lucene.store.NRTCachingDirectory.fileLength(NRTCachingDirectory.java:128)\n\tat org.apache.solr.handler.admin.LukeRequestHandler.getFileLength(LukeRequestHandler.java:611)\n\tat org.apache.solr.handler.admin.LukeRequestHandler.getIndexInfo(LukeRequestHandler.java:584)\n\tat org.apache.solr.handler.admin.LukeRequestHandler.handleRequestBody(LukeRequestHandler.java:136)\n\tat org.apache.solr.handler.RequestHandlerBase.handleRequest(RequestHandlerBase.java:177)\n...\nINFO  - 2017-11-08 17:23:44.587; [   x:techproducts] org.apache.solr.core.SolrCore; [techproducts]  webapp=/solr path=/admin/luke params={} status=0 QTime=15",
    "attachments": {
        "SOLR-9120.patch": "https://issues.apache.org/jira/secure/attachment/12864579/SOLR-9120.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2016-06-02T17:31:12+0000",
            "author": "Thomas Kurz",
            "content": "Same here. This does not seem to break other parts but produces a lot of log noise and seems also to block the admin cores interface. Any ideas how to fix or workaround this? ",
            "id": "comment-15312724"
        },
        {
            "date": "2016-06-02T17:31:55+0000",
            "author": "Thomas Kurz",
            "content": "We are running Solr 5.5.0, so it would be great to also put the fix on this. ",
            "id": "comment-15312726"
        },
        {
            "date": "2016-07-24T17:16:25+0000",
            "author": "Michael Braun",
            "content": "Seeing this as well, Solr 6.1.0. ",
            "id": "comment-15391112"
        },
        {
            "date": "2016-07-26T16:44:18+0000",
            "author": "Tomasz Oliwa",
            "content": "I also see this on Solr 6.1.0 ",
            "id": "comment-15394063"
        },
        {
            "date": "2016-09-28T10:40:04+0000",
            "author": "Henry Cleland",
            "content": "Same is on Solr 6.2.1, it blocks the admin interface and then logs =>\nWARN  (qtp110456297-15) [   ] o.a.s.h.a.LukeRequestHandler Error getting file length for [segments_4g]\njava.nio.file.NoSuchFileException: /home/solr/var/solr/data/cs/data/index/segments_4g\n....\n ",
            "id": "comment-15529228"
        },
        {
            "date": "2016-10-25T02:55:36+0000",
            "author": "Gopalakrishnan B",
            "content": "Team - Do we have an update on when this will be fixed and what version ?\n\nCurrently, as a workaround we are restarting our entire solr cluster to resolve the luke call failure. ",
            "id": "comment-15603980"
        },
        {
            "date": "2016-10-25T15:07:40+0000",
            "author": "Erick Erickson",
            "content": "There's no \"official\" roadmap. Submitting a patch makes it much more likely it'll be addressed though.... ",
            "id": "comment-15605563"
        },
        {
            "date": "2016-10-26T16:00:54+0000",
            "author": "Gopalakrishnan B",
            "content": "Can we get a patch to resolve this issue on PDN? OR If there is a workaround to resolve this issue please provide us the same. ",
            "id": "comment-15608859"
        },
        {
            "date": "2016-10-26T18:06:59+0000",
            "author": "Hrishikesh Gadre",
            "content": "I just added a comment related to this issue in SOLR-8587. I will submit a patch if this suggestion make sense. ",
            "id": "comment-15609207"
        },
        {
            "date": "2016-11-03T19:13:27+0000",
            "author": "Gopalakrishnan B",
            "content": "Can you please confirm if the patch is rolled out to fix this issue? ",
            "id": "comment-15633900"
        },
        {
            "date": "2016-11-03T20:00:40+0000",
            "author": "Erick Erickson",
            "content": "Anything with a \"resloution\" of \"fixed\" is in some release, the \"fixed version\" field will tell you which ones.\n\nThis JIRA has not been added to any version as it's still \"unresolved\"\n\nSOLR-8587 is in Solr 5.5 and 6.0 (and of course trunk the future 7.0) ",
            "id": "comment-15634057"
        },
        {
            "date": "2016-11-07T01:04:42+0000",
            "author": "Gopalakrishnan B",
            "content": "SOLR-8587 seems to be in closed state from Feb/23/2016 where as the comment from Hrishikesh Gadre is added around Oct/27/2016 so little confused whether the latest fix/patch mentioned will be available in Solr 5.5/6.0/7.0 or not.\n\nAlso, since this ticket SOLR-9120 is opened on the version 6.0, hence I am afraid whether the fix made on SOLR-8587 resolves this issue.\n\nIf SOLR-8587 is in progress by someone to verify the patch suggested by Hrishikesh Gadre, can we have that ticket reopened to update its status? ",
            "id": "comment-15642747"
        },
        {
            "date": "2016-12-17T06:39:00+0000",
            "author": "Gopalakrishnan B",
            "content": "Hi Team,\n\ndo we have any update on this?\n\nThanks. ",
            "id": "comment-15756478"
        },
        {
            "date": "2017-02-12T13:20:50+0000",
            "author": "Gopalakrishnan B",
            "content": "Hi Team,\n\nPlease let us know if we have any update on this ticket.\n\nThanks,. ",
            "id": "comment-15862784"
        },
        {
            "date": "2017-02-16T16:00:12+0000",
            "author": "Shawn Heisey",
            "content": "Confirmed that this is still happening in the wild on 6.4. Doesn't seem to cause any actual issues other than a surplus of log messages.\n\nHere's the full transcript of what can be found in the log on 6.3.0:\n\n\n2017-02-16 15:56:00.122 WARN  (qtp895947612-44262) [   x:inclive] o.a.s.h.a.LukeRequestHandler Error getting file length\nfor [segments_cr3]\njava.nio.file.NoSuchFileException: /index/solr6/data/data/inc_1/index/segments_cr3\n        at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)\n        at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)\n        at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)\n        at sun.nio.fs.UnixFileAttributeViews$Basic.readAttributes(UnixFileAttributeViews.java:55)\n        at sun.nio.fs.UnixFileSystemProvider.readAttributes(UnixFileSystemProvider.java:144)\n        at sun.nio.fs.LinuxFileSystemProvider.readAttributes(LinuxFileSystemProvider.java:99)\n        at java.nio.file.Files.readAttributes(Files.java:1737)\n        at java.nio.file.Files.size(Files.java:2332)\n        at org.apache.lucene.store.FSDirectory.fileLength(FSDirectory.java:243)\n        at org.apache.lucene.store.NRTCachingDirectory.fileLength(NRTCachingDirectory.java:128)\n        at org.apache.solr.handler.admin.LukeRequestHandler.getFileLength(LukeRequestHandler.java:598)\n        at org.apache.solr.handler.admin.LukeRequestHandler.getIndexInfo(LukeRequestHandler.java:586)\n        at org.apache.solr.handler.admin.LukeRequestHandler.handleRequestBody(LukeRequestHandler.java:137)\n        at org.apache.solr.handler.RequestHandlerBase.handleRequest(RequestHandlerBase.java:153)\n        at org.apache.solr.core.SolrCore.execute(SolrCore.java:2213)\n        at org.apache.solr.servlet.HttpSolrCall.execute(HttpSolrCall.java:654)\n        at org.apache.solr.servlet.HttpSolrCall.call(HttpSolrCall.java:460)\n        at org.apache.solr.servlet.SolrDispatchFilter.doFilter(SolrDispatchFilter.java:303)\n        at org.apache.solr.servlet.SolrDispatchFilter.doFilter(SolrDispatchFilter.java:254)\n        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1668)\n        at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:581)\n        at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)\n        at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)\n        at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)\n        at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1160)\n        at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:511)\n        at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)\n        at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1092)\n        at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n        at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)\n        at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)\n        at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)\n        at org.eclipse.jetty.server.Server.handle(Server.java:518)\n        at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:308)\n        at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:244)\n        at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:273)\n        at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:95)\n        at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)\n        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceAndRun(ExecuteProduceConsume.java:246)\n        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:156)\n        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:654)\n        at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:572)\n        at java.lang.Thread.run(Thread.java:745)\n\n ",
            "id": "comment-15870176"
        },
        {
            "date": "2017-03-17T03:01:37+0000",
            "author": "Rohit Kanchan",
            "content": "Do we have any patch for this? We are also facing the same issue on 6.1 version. ",
            "id": "comment-15929372"
        },
        {
            "date": "2017-04-04T19:30:59+0000",
            "author": "Rondel Ward",
            "content": "I'm seeing this same issue on Solr 6.4.2.  ",
            "id": "comment-15955665"
        },
        {
            "date": "2017-04-14T20:51:34+0000",
            "author": "Shawn Heisey",
            "content": "This issue seems to have fallen out of notice.  I suspect that something changed in Lucene so that Solr is looking at outdated information, and Solr just needs to be updated so it looks in a new place for data, or so that it keeps a previous commit point around for a moment while it gathers information.  If somebody has any idea what I can look for, I am willing to put time into finding a fix, but I have no idea where to begin right now.\n\nThe message can be eliminated from the logs by setting the log level for LukeRequestHandler (full class name org.apache.solr.handler.admin.LukeRequestHandler) to ERROR, which can be done either in the Logging UI or in log4j.properties. ",
            "id": "comment-15969513"
        },
        {
            "date": "2017-04-21T16:35:22+0000",
            "author": "Stephen Weiss",
            "content": "I think this does have a real impact - we get these errors when doing backups and it causes the backups to fail, so then we have to repeat.  Sometimes it takes a few hours before we get a clean backup as a result. ",
            "id": "comment-15979029"
        },
        {
            "date": "2017-04-21T17:00:42+0000",
            "author": "Hrishikesh Gadre",
            "content": "I added following comments to SOLR-8587 long time ago. \n\n----------------------------------------\nI ran into a similar problem (NoSuchFileException for the segments file) while working on Solr backup/restore. This problem can be avoided by using the following trick implemented in ReplicationHandler.\nhttps://github.com/apache/lucene-solr/blob/7794fbd13f1a0edfff8f121fb1c6a01075eeef6a/solr/core/src/java/org/apache/solr/handler/ReplicationHandler.java#L537-L542\nI see that LukeRequestHandler is not implementing similar strategy. \nhttps://github.com/apache/lucene-solr/blob/7794fbd13f1a0edfff8f121fb1c6a01075eeef6a/solr/core/src/java/org/apache/solr/handler/admin/LukeRequestHandler.java#L583\nMy guess is that if we change LukeRequestHandler to implement a strategy similar to ReplicationHandler, it should fix the problem. Although I don't fully understand why is that the case. Yonik Seeley Uwe Schindler you have any idea?\n----------------------------------------\n\n----------------------------------------\nOk I confirmed that the above mentioned approach fixes the NoSuchFileException for the segments file. Please refer to this quick patch,\nhttps://github.com/hgadre/lucene-solr/commit/e780f63d4ce79b30f3379df3eb59021394080cc8\n\nOne open question at this point,\nIf we fetch the IndexCommit via solrCore.getDeletionPoplicy().getLatestCommit() API, then should we be using the corresponding IndexReader instance (instead of IndexSearcher.getIndexReader()) ?. Otherwise we may get inconsistent results. But after reviewing the code, it looks like IndexCommit.getReader() method may return null value. So I am not sure if we can rely on it. Any thoughts on this?\n----------------------------------------\n\nMay be we can just use this as the fix? Shawn Heisey any thoughts? ",
            "id": "comment-15979075"
        },
        {
            "date": "2017-04-21T20:19:35+0000",
            "author": "Shawn Heisey",
            "content": "I do not know the code well enough to say whether your fix is 100% correct.\n\nIs there any way to get that github commit as a diff that I can apply? ",
            "id": "comment-15979311"
        },
        {
            "date": "2017-04-21T20:20:24+0000",
            "author": "Shawn Heisey",
            "content": "If you can build a test that reproduces the problem, which then passes with your patch, that would be VERY helpful. ",
            "id": "comment-15979316"
        },
        {
            "date": "2017-04-21T21:36:14+0000",
            "author": "Shawn Heisey",
            "content": "Attaching a new patch based on the patch suggested by Hrishikesh Gadre.\n\nInstead of just changing the LukeRequestHandler#getIndexInfo method signature, I have deprecated the original signature.  If this is committed, the method should be removed in the commit to master.  I have no idea whether user plugin code will be using this method, but since it is public, I think we have to assume that somebody's going to depend on it.\n\nIf one of you who has had a failure with the backup feature can invent a test for the backup feature that fails without the patch and passes with it, that would be the best way to ensure that the fix is good.\n\nThe patch passes precommit.  Still working on the default Solr test suite. ",
            "id": "comment-15979430"
        },
        {
            "date": "2017-05-03T10:49:44+0000",
            "author": "Ere Maijala",
            "content": "We also encounter this often when trying to create backups, but I don't have a consistently reproducible test case. It's more like \"index enough stuff and then try to create a backup\". This is with a SolrCloud with three nodes and a collection with 1 shard, 3 replicas. ",
            "id": "comment-15994650"
        },
        {
            "date": "2017-09-25T21:11:30+0000",
            "author": "Shawn Heisey",
            "content": "With the patch for SOLR-11297 applied, I was still running into this issue on branch_6_6.\n\nAfter manually applying the patch included here (because it would not apply to branch_6_6 automatically), this problem seems to be resolved.\n\nThis is an updated patch, against branch_6_6.  I have not yet tried it against 7x or master. ",
            "id": "comment-16179798"
        },
        {
            "date": "2017-09-25T21:23:47+0000",
            "author": "Shawn Heisey",
            "content": "By resolved, I mean that the error message no longer shows up in my log.  The error never did cause me any actual problems, but I do not use the backup feature. ",
            "id": "comment-16179817"
        },
        {
            "date": "2017-09-26T17:08:08+0000",
            "author": "Shawn Heisey",
            "content": "Looks like I just didn't wait long enough.  Still getting the NoSuchFileException even with the patch applied.  Version is 6.6.2-SNAPSHOT, with the patch for SOLR-11297 and the patch for this issue applied. ",
            "id": "comment-16181153"
        },
        {
            "date": "2017-11-03T08:12:20+0000",
            "author": "Pascal Schwaller",
            "content": "I can confirm the same NoSuchFileException on both versions 6.6.2 and 7.1.0 ",
            "id": "comment-16237252"
        },
        {
            "date": "2017-11-07T16:08:16+0000",
            "author": "Cassandra Targett",
            "content": "I think there are two different scenarios covered by this one issue:\n\n\n\tA real error that blocks backups.\n\tA seemingly harmless error that fills up logs.\n\n\n\nPascal Schwaller, you were the most recent person to say you have seen this in 6.6.2 and 7.1 - was it when trying to do a backup that failed? Or did you notice the errors in the log without Solr being disrupted? ",
            "id": "comment-16242273"
        },
        {
            "date": "2017-11-07T18:20:07+0000",
            "author": "Varun Thacker",
            "content": "Hi Shawn Heisey\n\nYou confirmed that this patch works and LukeRequestHandler no longer gives the NoSuchFileException ? Any reason for it not to be committed?\n\nI dug deeper into backups failing because of NoSuchFileException and can confirm that this patch won't address it. However the same solution can be used there. Essentially we need to take the same fix and apply it here https://github.com/apache/lucene-solr/blob/master/solr/core/src/java/org/apache/solr/handler/SnapShooter.java#L165 . I will create a separate issue for tracking this  ",
            "id": "comment-16242565"
        },
        {
            "date": "2017-11-07T18:24:40+0000",
            "author": "Varun Thacker",
            "content": "I create SOLR-11616 to track backup failures with the same message ",
            "id": "comment-16242576"
        },
        {
            "date": "2017-11-07T18:24:53+0000",
            "author": "Hrishikesh Gadre",
            "content": "Varun Thacker\n\n>>Essentially we need to take the same fix and apply it here\n\nIt may be a good idea to actually figure out what is the root cause of this behavior. Seems quite weird to me. There may be some fundamental issue at the lucene level ? ",
            "id": "comment-16242577"
        },
        {
            "date": "2017-11-07T19:36:17+0000",
            "author": "Shawn Heisey",
            "content": "You confirmed that this patch works and LukeRequestHandler no longer gives the NoSuchFileException \n\nNo.  I thought it was solved, but apparently I just didn't wait long enough after the Solr restart.  The message continued to appear in the logs even with the patch.  I have no idea whether the patch solved the backup problem that other people have encountered \u2013 I don't use the backup feature. ",
            "id": "comment-16242731"
        },
        {
            "date": "2017-11-07T19:45:11+0000",
            "author": "Varun Thacker",
            "content": "The patch won't solve the backup problem for sure. Whatever solution we have for this can be borrowed to fix SOLR-11616 ",
            "id": "comment-16242748"
        },
        {
            "date": "2017-11-07T21:35:28+0000",
            "author": "Hoss Man",
            "content": "I'm very confused by some of the back and forth comments here \u2013 beyond the fact that in some cases people seem to be talking about different bugs (SOLR-11616) that are completely unrelated to the LukeRequestHandler problem here (similar only because they both involve NoSuchFileException on segments files, even though the code is completley different) \n\nin particular...\n\nIt may be a good idea to actually figure out what is the root cause of this behavior. Seems quite weird to me. There may be some fundamental issue at the lucene level ?\n\n...i don't understand this confusion about the \"root cause\" of where/why the NoSuchFileException exception comes from ... that was very clearely spelled out in the discussion in SOLR-8793, which lead to the creation of SOLR-8587 \u2013 both of which are linked to this jira...\n\nFrom: SOLR-8793\nLucene deletes the files no longer referenced by an index (through any commit) so they disappear on the directory listing. IndexReaders still having them open on older index state are not affected (\"delete on last close\" POSIX semantics) - the inode is still existing, just the directory entry is gone. The inode is deleted if nothing refers to it anymore. This is different on Windows under some circumstances (MMapDirectory).\nOK yea you're right, I was confused. The file can be read by the open IR, but won't appear in directory listing. I opened SOLR-8793 to fix this, sorry for that!\n\nAt which point, in SOLR-8587, Shai Erera fixed the code so that instead of propgating the NoSuchFileException up out and failing the LukeRequestHandler request, the code would simply warn about the Exception, and the request would succeed, ala this code...\n\n\n  private static long getFileLength(Directory dir, String filename) {\n    try {\n      return dir.fileLength(filename);\n    } catch (IOException e) {\n      // Whatever the error is, only log it and return -1.\n      log.warn(\"Error getting file length for [{}]\", filename, e);\n      return -1;\n    }\n  }\n\n\n\n\n...which is why in comments above, people report seeing exceptions like this in their logs (including the \"Error getting file length\" info from getFileLength)...\n\n\n2017-02-16 15:56:00.122 WARN  (qtp895947612-44262) [   x:inclive] o.a.s.h.a.LukeRequestHandler Error getting file length\nfor [segments_cr3]\njava.nio.file.NoSuchFileException: /index/solr6/data/data/inc_1/index/segments_cr3\n        at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)\n        at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)\n        at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)\n        at sun.nio.fs.UnixFileAttributeViews$Basic.readAttributes(UnixFileAttributeViews.java:55)\n        at sun.nio.fs.UnixFileSystemProvider.readAttributes(UnixFileSystemProvider.java:144)\n        at sun.nio.fs.LinuxFileSystemProvider.readAttributes(LinuxFileSystemProvider.java:99)\n        at java.nio.file.Files.readAttributes(Files.java:1737)\n        at java.nio.file.Files.size(Files.java:2332)\n        at org.apache.lucene.store.FSDirectory.fileLength(FSDirectory.java:243)\n        at org.apache.lucene.store.NRTCachingDirectory.fileLength(NRTCachingDirectory.java:128)\n        at org.apache.solr.handler.admin.LukeRequestHandler.getFileLength(LukeRequestHandler.java:598)\n\n\n\n...but the /luke requests themselves don't actually fail.\n\n\n\nAs things stand now, the code is doing exactly what it was designed to do:\n\n\tmake an attempt at reporting the on disk size of the segments file currently in use by the reader\n\tif the size of the segments file can't be determined due to any IO Exception, return -1 log a WARN about the IO Exception\n\n\n\nThe question becomes: do we want to change that logging?\n\nLukeRequestHandler is currently making no assumptions about wether or not any IO Exception it encounters is \"bad\" or not \u2013 from the perspective of that class the sitation is non fatal so it's not logging as an ERROR, just a WARNing ... we could remove this logging, or change it to INFO or DEBUG \u2013 but then LukeRequestHandler would be making some explicit assumptions that this type of exception is \"OK\" ... and in many cases it is, but what if in some cases it isn't?\n\nI suspect this is why Shai used WARN in the first place \u2013 to avoid making any explicit assumptions about how sever the IOException is \u2013 we could easily change this to be less noisy, but should we?\n\nMy vote would be \"yes\": log it only at a DEBUG level and update the message to something like \"Ignoring exception attempting to check (optional) fileSize stat for: <filename>\"\n\n\n\nAs for the attached patch: I don't understand the nuances of why getting the last commit from the DeletionPolicy ma/may-not be better then getting it from the IndexReader, but it doesn't change the fundemental root of the issue: a commit point may be refering to a (segments) file that is still usable by already open file handles, but no longer has an entry in the directory listing so it does not exist if you try to ask the Directory for it's size. changing which commit we ask doesn't change the underlying filesystem semantics.\n\nin other words: \n\n\tthe patch as is can never fx the underlying source of the NoSuchFileException\n\tif the patch is a good idea for other reasons, thne that should be spelled out in a distinct issue explaining why exactly LukeRequestHandler should _in general, for all aspects of index info) be using core.getDeletionPolicy().getLatestCommit() instead of reader.getIndexCommit()\n\n ",
            "id": "comment-16242927"
        },
        {
            "date": "2017-11-07T21:46:04+0000",
            "author": "Hoss Man",
            "content": "And FWIW: The more i read up on all of these issues: No one has ever actually posted any explicit logs, or steps to reproduce, of any failures with backup (or ReplicationHandler) to this (SOLR-9120) issue (or for that matter: to SOLR-8587, or to SOLR-8793, OR to SOLR-11616) ... AFAICT there is only anecdotal information claiming that these exceptions (logged by LukeRequestHandler) are also a \"similar problem\" to doing backups/replication.\n\nIf anyone has can provide Actual logs from an error occuring during backup/replication \u2013 along with configs / steps to reproduce: SOLR-11616 is the place to post them.\n\nAFAIK there is NO code in LukeRequestHandler that is used by any backup/replication based code \u2013 it is purely for status purposes. ",
            "id": "comment-16242968"
        },
        {
            "date": "2017-11-08T06:08:32+0000",
            "author": "Pascal Schwaller",
            "content": "Cassandra Targett We created two clones from a version 6.3, then updated one clone to 6.6.2, the other to 7.1.0. I replaced the deprecated field types in the schema.xml and updated solrconfig.xml on both newer versions (individually and according to the changes of each version separately) and re-indexed. \n\nWhile I'm still running the re-indexing job I get the warning \"Error getting file length for [segments_NNN]\" with NoSuchFileException in the detail of the warning. The job will run just fine without having any exceptions and my data in the index seem to be complete.\n\nWe don't have this warning appearing on version 6.3 though. ",
            "id": "comment-16243426"
        },
        {
            "date": "2017-11-08T16:59:38+0000",
            "author": "Hoss Man",
            "content": "We don't have this warning appearing on version 6.3 though.\n\nYou should be able to reproduce these warnings in any situation where:\n\n\tyou have an instance of Solr 5.5 or newer\n\tyou perform index updates & commits w/o \"newSearcher\" being opened\n\tyou \"concurrently\" make requests to the LukeRequestHandler or the CoreAdminHandler requesting \"STATUS\" (ie: after the commit, before any newSearcher)\n\t\n\t\tthese requests can come from the Admin UI passively if it's open in a browser\n\t\n\t\n\n\n\nIf you are not seeing these in your 6.3 solr instance, it's probably because you are not doing any indexing against that instance (you mentioned re-indexing with the 6.6 and 7.1 \"clones\" of your original 6.3 instance \u2013 but you didn't mention anything about running any indexing on the 6.3 instance.\n\nThe job will run just fine without having any exceptions and my data in the index seem to be complete.\n\ncorrect \u2013 the WARNing messages from LukeRequestHandler come from purely \"informative\" code paths that are returning status information about the current version of the index being searched \u2013 this code path is in no way involved in anyting indexing related \n\n\n\nMy vote would be \"yes\": log it only at a DEBUG level and update the message to something like \"Ignoring exception attempting to check (optional) fileSize stat for: <filename>\"\n\nHere's a more concrete straw man proposal that i'll prep a patch for..\n\n\n\trefactor the existing (private) getFileLength method to be very specifically named for getting the segments file length (since that's the only current usage of this method)\n\tchange the semantics of the method so it explicitly attempts to catch NoSuchFileException and in that case logs it at a DEBUG only level with a very explicit msg\n\t\n\t\tsomething along the lines of \"Unable to read the current reader's segments file length from the index Directory, this can happen if there are new 'on disk' commits since the reader was opened\"\n\t\n\t\n\tif any other IOException is caught, continue to log a WARN with a msg that makes it clear this is being ignored and has not caused any problems for luke\n\t\n\t\tie: \"Ignoring exception attempting to check (optional) fileSize stat for segments file\"\n\t\n\t\n\n\n\nthoughts?\n ",
            "id": "comment-16244314"
        },
        {
            "date": "2017-11-08T19:04:03+0000",
            "author": "Hoss Man",
            "content": "\nHere's some trivial steps to reproduce the WARN message...\n\n\n$ bin/solr -e techproducts\n...\n$ tail -f example/techproducts/logs/solr.log\n...\n\n\n\n\nIn another terminal...\n\n\n$ curl -H 'Content-Type: application/json' 'http://localhost:8983/solr/techproducts/update?commit=true&openSearcher=false' --data-binary '[{\"id\":\"HOSS\"}]'\n...\n$ curl 'http://localhost:8983/solr/techproducts/admin/luke'\n...\n\n\n\nWhen the \"/admin/luke\" URL is hit, this will show up in the logs \u2013 but the luke request will finish correctly...\n\n\nWARN  - 2017-11-08 17:23:44.574; [   x:techproducts] org.apache.solr.handler.admin.LukeRequestHandler; Error getting file length for [segments_2]\njava.nio.file.NoSuchFileException: /home/hossman/lucene/dev/solr/example/techproducts/solr/techproducts/data/index/segments_2\n\tat sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)\n\tat sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)\n\tat sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)\n\tat sun.nio.fs.UnixFileAttributeViews$Basic.readAttributes(UnixFileAttributeViews.java:55)\n\tat sun.nio.fs.UnixFileSystemProvider.readAttributes(UnixFileSystemProvider.java:144)\n\tat sun.nio.fs.LinuxFileSystemProvider.readAttributes(LinuxFileSystemProvider.java:99)\n\tat java.nio.file.Files.readAttributes(Files.java:1737)\n\tat java.nio.file.Files.size(Files.java:2332)\n\tat org.apache.lucene.store.FSDirectory.fileLength(FSDirectory.java:243)\n\tat org.apache.lucene.store.NRTCachingDirectory.fileLength(NRTCachingDirectory.java:128)\n\tat org.apache.solr.handler.admin.LukeRequestHandler.getFileLength(LukeRequestHandler.java:611)\n\tat org.apache.solr.handler.admin.LukeRequestHandler.getIndexInfo(LukeRequestHandler.java:584)\n\tat org.apache.solr.handler.admin.LukeRequestHandler.handleRequestBody(LukeRequestHandler.java:136)\n\tat org.apache.solr.handler.RequestHandlerBase.handleRequest(RequestHandlerBase.java:177)\n...\nINFO  - 2017-11-08 17:23:44.587; [   x:techproducts] org.apache.solr.core.SolrCore; [techproducts]  webapp=/solr path=/admin/luke params={} status=0 QTime=15\n\n\n\n\nAny subsequent hits to the \"/admin/luke\" request handler \u2013 which can also happen automatically & asynchronously in the backgrond if you have \"http://localhost:8983/solr/#/techproducts\" (or some of it's sub-pages) loaded in your browser \u2013 will also produce that same log message, unless until a commit that opens a new searcher.\n\n\n\n\nWith the attached patch, and solr's default logging levels, the same steps produce no messages from LukeRequestHandler.\n\nany concerns? ",
            "id": "comment-16244556"
        },
        {
            "date": "2017-11-09T09:02:40+0000",
            "author": "Pascal Schwaller",
            "content": "Hoss Man Thanks for your comment. I re-checked and you are right, these warnings also appear on solr version 6.3.0. \n\nWhen I read your comment, that warnings could show up being on the Admin GUI while indexing, I checked it because that was the only difference I had when testing the previous indexing of all 3 versions. \n\nI wasn't on the admin GUI while I was indexing 6.3.0 (with the result of not having warnings in the log) but I was when indexing 6.6.2 and 7.1.0, checking the number of documents indexed on the core and back to the log. \n\nI did the opposite today, not having the admin GUI open on 6.6.2 and 7.1.0 (which showed no warnings) but did on 6.3.0, where I got a warning every time I checked the number of indexed documents in the core and back to the logs.\n\nYour proposed solution sounds good to me! ",
            "id": "comment-16245397"
        },
        {
            "date": "2017-11-09T16:54:07+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 15fe53e10be74a0c953c4e0fac6815798cf66772 in lucene-solr's branch refs/heads/master from Chris Hostetter\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=15fe53e ]\n\nSOLR-9120: Reduce log level for inconsequential NoSuchFileException that LukeRequestHandler may encounter ",
            "id": "comment-16246012"
        },
        {
            "date": "2017-11-09T17:48:42+0000",
            "author": "ASF subversion and git services",
            "content": "Commit e0455440fe241477f9a269926a7a710e538074e2 in lucene-solr's branch refs/heads/branch_7x from Chris Hostetter\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=e045544 ]\n\nSOLR-9120: Reduce log level for inconsequential NoSuchFileException that LukeRequestHandler may encounter\n\n(cherry picked from commit 15fe53e10be74a0c953c4e0fac6815798cf66772) ",
            "id": "comment-16246139"
        },
        {
            "date": "2018-11-13T09:28:05+0000",
            "author": "Franck Perrin",
            "content": "Hello, Is there any chance this patch will be backported to v6.6 please ? thank you. ",
            "id": "comment-16684932"
        },
        {
            "date": "2018-11-13T16:26:25+0000",
            "author": "Erick Erickson",
            "content": "In a word, \"no\". The only\u00a0issues that would stand a chance of being backported to 6x at this point would be serious security vulnerabilities. This is actually harmless, even if it's annoying.\n\nIf it's really a problem for you, you can easily get/compile the source and\u00a0build Solr yourself. Whether the patch would apply cleanly to 6x is an open question. ",
            "id": "comment-16685443"
        },
        {
            "date": "2018-11-14T09:29:07+0000",
            "author": "Franck Perrin",
            "content": "Thank you, I understand your position. I understand this is supposed to be harmless but we've been encountering issues where solr jumps in memory usage until it goes OOM (in a matter of seconds) and the only thing noticeable in the logs are errors mentioned in this ticket. this happens twice a month or so. Is there somewhere where I could seek further assistance like a public slack or forum ? Thank you. ",
            "id": "comment-16686248"
        },
        {
            "date": "2018-11-14T15:47:46+0000",
            "author": "Erick Erickson",
            "content": "It's highly unlikely this is related to your OOMs, \n\nSupport: sure, see the Solr user's list from here: http://lucene.apache.org/solr/community.html\n\nMy guess would be you're sorting or grouping or faceting on a field that does not have docValues enabled, but lets move the rest of the discussion over to the user's list. ",
            "id": "comment-16686744"
        },
        {
            "date": "2018-11-14T16:43:47+0000",
            "author": "Franck Perrin",
            "content": "Thank you, I'll go on to the user's list then. ",
            "id": "comment-16686845"
        }
    ]
}