{
    "id": "SOLR-8697",
    "title": "Fix LeaderElector issues",
    "details": {
        "components": [
            "SolrCloud"
        ],
        "type": "Bug",
        "labels": "",
        "fix_versions": [
            "5.5.1",
            "6.0"
        ],
        "affect_versions": "5.4.1",
        "status": "Resolved",
        "resolution": "Fixed",
        "priority": "Major"
    },
    "description": "This patch is still somewhat WIP for a couple of reasons:\n\n1) Still debugging test failures.\n2) This will more scrutiny from knowledgable folks!\n\nThere are some subtle bugs with the current implementation of LeaderElector, best demonstrated by the following test:\n\n1) Start up a small single-node solrcloud.  it should be become Overseer.\n2) kill -9 the solrcloud process and immediately start a new one.\n3) The new process won't become overseer.  The old process's ZK leader elect node has not yet disappeared, and the new process fails to set appropriate watches.\n\nNOTE: this is only reproducible if the new node is able to start up and join the election quickly.",
    "attachments": {
        "SOLR-8697-followup.patch": "https://issues.apache.org/jira/secure/attachment/12789305/SOLR-8697-followup.patch",
        "SOLR-8697.patch": "https://issues.apache.org/jira/secure/attachment/12788725/SOLR-8697.patch",
        "OverseerTestFail.log": "https://issues.apache.org/jira/secure/attachment/12789290/OverseerTestFail.log"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2016-02-18T20:06:54+0000",
            "author": "Scott Blum",
            "content": "Shalin Shekhar Mangar Erick Erickson Mark Miller ",
            "id": "comment-15152995"
        },
        {
            "date": "2016-02-18T20:17:39+0000",
            "author": "Mark Miller",
            "content": "The old process's ZK leader elect node has not yet disappeared, and the new process fails to set appropriate watches.\n\nI thought we waited for a while for the old one to go away...is that missing in the Overseer election code and just in the shard election code? ",
            "id": "comment-15153011"
        },
        {
            "date": "2016-02-18T20:41:08+0000",
            "author": "Scott Blum",
            "content": "TBH, the code is pretty hard to follow in its existing form, and a lot of the theory of operation and design is difficult to distill.  There is code that looks like it's trying to do what you're talking about, but it's buggy.\n\nTake this analysis with like 70% confidence: The existing code has a very hazy definition of \"myself\" and \"previous registration\", from what I can tell.  The previous elect node from a different process qualifies as \"myself\" in some cases, so the new process thinks it's already registered when it's not. ",
            "id": "comment-15153048"
        },
        {
            "date": "2016-02-18T22:52:46+0000",
            "author": "Scott Blum",
            "content": "Mark Miller Erick Erickson\n\nI think there is a potential problem with how OverseerTest is constructed, that perhaps caused us to write some code into LeaderElector in the past that doesn't make any sense for live code.\n\nI'm looking at the implementation of MockZkController.publishState() (it's kind of a beast) and I notice that when it creates an ElectionContext, it never actually adds it to the map, checks whether one already exists, etc.  As a result, MockZkController does something the real ZkController never does \u2013 it tries to register two different election contexts for the same core on the same ZK session.\n\nMy question is, what's the right fix?  I can either make MockZkController not setup a new electionContext on subsequent invocations, or I could make it simply cancel the previous election context before creating a new one. ",
            "id": "comment-15153294"
        },
        {
            "date": "2016-02-19T00:16:37+0000",
            "author": "Scott Blum",
            "content": "Found another bug in ShardLeaderElectionContextBase.\n\ncancelElection() and runLeaderProcess() can race with each other.  If the local process is trying to cancel right as it becomes leader, cancelElection() won't see a leaderZkNodeParentVersion yet, so it won't try to delete the leader registration.  Meanwhile, runLeaderProcess() still succeeds in creating the leader registration.  The call to super.cancelElection() does remove us from the queue, but the dead leader registration is left there.\n\nI think moving the call to super.cancelElection() to the start of ShardLeaderElectionContextBase.cancelElection() should resolve the race, because actually removing the election node will cause the multi to fail with a NoNode rather than a NodeExists, and it won't get stuck in a retry loop. ",
            "id": "comment-15153418"
        },
        {
            "date": "2016-02-19T18:37:11+0000",
            "author": "Scott Blum",
            "content": "Okay, all the tests are passing now, I think this is ready for review. ",
            "id": "comment-15154618"
        },
        {
            "date": "2016-02-19T19:44:17+0000",
            "author": "Mark Miller",
            "content": "TBH, the code is pretty hard to follow in its existing form\n\nYup. It was mildly hairy in its first form (copying the ZK recipe as described) and took a while to harden. Then some contributions came that just made it insane to follow. I've brought it up before, instead of trying to avoid thundering herd issues with what will be a reasonably low number of replicas trying to be leader, we probably should just have very simple leader elections. All of the original logic, and the logic that was added that made it really hard for me to follow, would be really simple if we gave up the cool elegant approach we used to avoid a mostly non existent thundering herd issue. That thicket is just a ripe breeding ground for random bugs our tests just don't easily expose.\n\nAt this point, the effort to change reliably is probably really high though. ",
            "id": "comment-15154740"
        },
        {
            "date": "2016-02-19T20:30:14+0000",
            "author": "Scott Blum",
            "content": "I think part of the general problem with a lot of the ZK-interacting code is a lack of clean separation of concerns.  The relationships between LeaderElector and the various ElectionContext subclasses are pretty gnarly and incestuous.  DistributedQueue had a similar kind of design problem before I extracted the app specific gnarly parts into OverseerTaskQueue.\n\nHave we considered trying to migrate to, say, Apache Curator (full disclosure: I'm a committer)?  There are a lot of advantages to using third party libs for some of these common patterns like distributed queue, leader election, or even observing changes in a tree.  Those components tend to be reusable, better documented, with cleaner APIs, and have a natural resistance to spaghetti invasion.  (Examples: OverseerNodePrioritizer and RebalanceLeaders are intricately tied to implementation details of LeaderElector.)\n\nA clean, reusable leader election component (with its own tests) that could simply be used in a few different contexts seems like a good place to be longer term.\n\nThat said, I hope this patch can simply clean up some up the existing bugs without being too disruptive. ",
            "id": "comment-15154817"
        },
        {
            "date": "2016-02-19T20:42:04+0000",
            "author": "Mark Miller",
            "content": "Curator has come up before. Personally, I have not wanted to try and mimic what we have or go through a protracted hardening process again. This stuff is all very touchy, and our tests def do not catch everything, so a rip and replace at that low level would be both very difficult and sure to introduce a lot of issues.\n\nI think a lot of the problem is that devs like to favor just tossing crap on top of what exists, rather than trying to wholistically move the design forward or make it right for what they want to add (Examples: OverseerNodePrioritizer and RebalanceLeaders - which also made the election code much more dense). I feel a lot of \"let's just make this work\". I can't tell you how surprised I've been that some devs have come and built so much on some of the prototype code I initially laid out. I've always thought, how do you build so much on this without finding/fixing more core bugs and seeing other necessary improvements more things as you go? Not that it doesn't happen, but the scale has historically been way below what I think makes sense. Easy for me to say I guess. Anyway, it's great that you have already filed a bunch of issues \n\nI'd rather focus on some refactoring than bringing in curator though. The implications of that would be pretty large and we have plenty of other more pressing issues I think. ",
            "id": "comment-15154833"
        },
        {
            "date": "2016-02-19T20:55:38+0000",
            "author": "Mark Miller",
            "content": "full disclosure: I'm a committer\n\nAnd you worked on GWT! Awesome. Have not used it in years, still madly in love with GWT.\n\nusing third party libs \n\nWe may have started with curator but when we started (query side of SolrCloud was 2009 or 2010?) it was not around or we did not know about it back then if it was. ",
            "id": "comment-15154853"
        },
        {
            "date": "2016-02-19T21:22:44+0000",
            "author": "Scott Blum",
            "content": "Yeah, totally agreed on refactoring and trying to fix core bugs!  Bringing in Curator at some point would be something I'd only advocate for incrementally and in pieces, like replace our DQ with Curator's, etc.  Moving everything over at in a short period of time would be a pipe dream anyway.\n\nBack on the topic of LeaderElector, I think this patch is in a pretty good state now.  The only thing I want to consider doing in the short term (after this patch) is that, in addition to watching the node ahead of you, I think we should also be watching our own node, whether or not we're leader.  If an outside party forcibly deletes our node, we should put ourselves at the back of the line.  If you think about it, if we could trust that behavior, something like RebalanceLeaders wouldn't even need to be a distributed request; overseer could just delete the current leader elect node and trust the owner to do the right thing. ",
            "id": "comment-15154888"
        },
        {
            "date": "2016-02-19T21:44:27+0000",
            "author": "Mark Miller",
            "content": "You can leave the old patches by the way. We tend to leave the history and just pull the latest patch with the same file name. ",
            "id": "comment-15154919"
        },
        {
            "date": "2016-02-19T21:54:50+0000",
            "author": "Mark Miller",
            "content": "Bringing in Curator at some point would be something I'd only advocate for incrementally and in pieces, like replace our DQ with Curator's, etc.\n\nYeah, I suppose if we had some consensus to push it forward over time, that's a viable option.\n\nIf an outside party forcibly deletes our node, we should put ourselves at the back of the line.\n\nYeah, that sounds like an interesting improvement. Much nicer than making a bunch of distrib calls. ",
            "id": "comment-15154939"
        },
        {
            "date": "2016-02-19T22:02:01+0000",
            "author": "Mark Miller",
            "content": "FYI, we are in a special little place where we can break back compat and don't have to consider rolling upgrades because the next release is 6.0. We don't have much time before 6.0 branches though I think.\n\nPatch looks good to me. Others should take a look as well, but I'll commit to get Jenkins cranking on it. ",
            "id": "comment-15154950"
        },
        {
            "date": "2016-02-19T22:07:05+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 9418369b46586818467109e482b70ba41e90d4ed in lucene-solr's branch refs/heads/master from markrmiller\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=9418369 ]\n\nSOLR-8697: Scope ZK election nodes by session to prevent elections from interfering with each other and other small LeaderElector improvements. ",
            "id": "comment-15154965"
        },
        {
            "date": "2016-02-19T22:11:55+0000",
            "author": "Mark Miller",
            "content": "cancelElection() and runLeaderProcess() can race with each other. If the local process is trying to cancel right as it becomes leader, cancelElection() won't see a leaderZkNodeParentVersion yet, so it won't try to delete the leader registration. Meanwhile, runLeaderProcess() still succeeds in creating the leader registration. The call to super.cancelElection() does remove us from the queue, but the dead leader registration is left there.\n\nAny thoughts on why the existing stress tests for leader election can't catch this? Can we beef something up? ",
            "id": "comment-15154976"
        },
        {
            "date": "2016-02-19T22:22:24+0000",
            "author": "Scott Blum",
            "content": "Actually OverseerTest.testShardLeaderChange() DID catch this race for me.  But only rarely.  Debugging that flake is how I uncovered the race. ",
            "id": "comment-15154993"
        },
        {
            "date": "2016-02-19T22:25:07+0000",
            "author": "Mark Miller",
            "content": "Okay, good, but then was it after your changes? I don't recall seeing that test fail in a long, long time on our Jenkins 'cluster', and that's a bunch of machines running the tests continuously. I also don't recall it locally. ",
            "id": "comment-15154996"
        },
        {
            "date": "2016-02-20T00:22:00+0000",
            "author": "Scott Blum",
            "content": "I think it's such a subtle race, that it would only generally show up with code changes-- but as little as changing logging could trigger it / not trigger it.  So it might have been beaten into a state where it happened to work unless you breathed on it.  Drove me nuts for the longest time debugging it until I stumbled on the race.  ",
            "id": "comment-15155203"
        },
        {
            "date": "2016-02-23T19:46:49+0000",
            "author": "Mark Miller",
            "content": "Note: Have not seen any fails like this in this test in a long, long time so may be related to this change. Perhaps just a test issue, because this retries for like 60 seconds or something.\n\n\n   [junit4] ERROR   66.3s J4  | OverseerTest.testShardLeaderChange <<<\n   [junit4]    > Throwable #1: org.apache.solr.common.SolrException: Could not register as the leader because creating the ephemeral registration node in ZooKeeper failed\n   [junit4]    > \tat __randomizedtesting.SeedInfo.seed([C4618609907C7E14:1A3201FE8AE48BE5]:0)\n   [junit4]    > \tat org.apache.solr.cloud.ShardLeaderElectionContextBase.runLeaderProcess(ElectionContext.java:212)\n   [junit4]    > \tat org.apache.solr.cloud.LeaderElector.runIamLeaderProcess(LeaderElector.java:173)\n   [junit4]    > \tat org.apache.solr.cloud.LeaderElector.checkIfIamLeader(LeaderElector.java:138)\n   [junit4]    > \tat org.apache.solr.cloud.LeaderElector.joinElection(LeaderElector.java:310)\n   [junit4]    > \tat org.apache.solr.cloud.LeaderElector.joinElection(LeaderElector.java:219)\n   [junit4]    > \tat org.apache.solr.cloud.OverseerTest$MockZKController.publishState(OverseerTest.java:181)\n   [junit4]    > \tat org.apache.solr.cloud.OverseerTest.testShardLeaderChange(OverseerTest.java:841)\n   [junit4]    > \tat java.lang.Thread.run(Thread.java:745)\n   [junit4]    > Caused by: org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists\n   [junit4]    > \tat org.apache.zookeeper.KeeperException.create(KeeperException.java:119)\n   [junit4]    > \tat org.apache.zookeeper.ZooKeeper.multiInternal(ZooKeeper.java:949)\n   [junit4]    > \tat org.apache.zookeeper.ZooKeeper.multi(ZooKeeper.java:915)\n   [junit4]    > \tat org.apache.solr.common.cloud.SolrZkClient$11.execute(SolrZkClient.java:577)\n   [junit4]    > \tat org.apache.solr.common.cloud.SolrZkClient$11.execute(SolrZkClient.java:574)\n   [junit4]    > \tat org.apache.solr.common.cloud.ZkCmdExecutor.retryOperation(ZkCmdExecutor.java:60)\n   [junit4]    > \tat org.apache.solr.common.cloud.SolrZkClient.multi(SolrZkClient.java:574)\n   [junit4]    > \tat org.apache.solr.cloud.ShardLeaderElectionContextBase$1.execute(ElectionContext.java:195)\n   [junit4]    > \tat org.apache.solr.common.util.RetryUtil.retryOnThrowable(RetryUtil.java:49)\n   [junit4]    > \tat org.apache.solr.common.util.RetryUtil.retryOnThrowable(RetryUtil.java:42)\n   [junit4]    > \tat org.apache.solr.cloud.ShardLeaderElectionContextBase.runLeaderProcess(ElectionContext.java:178)\n   [junit4]    > \t... 45 more\n\n ",
            "id": "comment-15159525"
        },
        {
            "date": "2016-02-23T19:52:50+0000",
            "author": "Scott Blum",
            "content": "I'll take a look.  I ran into this before on account of the test code doing a couple of questionable things.\n\n1) Re-using the same ZK session for multiple election contexts on the same election.  I fixed that one in my patch.\n\n2) Not deleting the registration on cancel.  I didn't bother fixing this one, since I figured eventually the session timeout would kill all the ephemeral nodes, making for a more thorough test.  But explicitly deleting the registration would speed the test up and make it more reliable, probably.\n\nThoughts? ",
            "id": "comment-15159537"
        },
        {
            "date": "2016-02-23T20:00:50+0000",
            "author": "Mark Miller",
            "content": "Here is the log file just in case. ",
            "id": "comment-15159554"
        },
        {
            "date": "2016-02-23T20:05:57+0000",
            "author": "Mark Miller",
            "content": "deleting the registration on cancel.\n\n+1. ",
            "id": "comment-15159562"
        },
        {
            "date": "2016-02-23T20:29:28+0000",
            "author": "Scott Blum",
            "content": "Attached a followup patch that cancels previous elections when the MockZkController is closed.  I haven't actually been able to get OverseerTest.testShardLeaderChange() to flake on my machine, with or without the change, even running like 100 iterations.  But  ",
            "id": "comment-15159589"
        },
        {
            "date": "2016-02-23T20:34:00+0000",
            "author": "Mark Miller",
            "content": ", even running like 100 iterations.\n\nUnfortunately, that is common. The tests are run in a wicked diverse set of envs. We see stuff from the jenkins cluster no dev ever seems to hit. \n\nA lot of fails only pop when running with other tests to also bog down the system, and you won't see the issue with that test in isolation, and then you can configure different numbers of tests to run at the same time (I do 10 on my 6 core machine), and the different levels of hardware...\n\nSome things are pretty hard to replicate locally. ",
            "id": "comment-15159597"
        },
        {
            "date": "2016-02-23T20:42:49+0000",
            "author": "Scott Blum",
            "content": "Actually, I'm stupid.  The flaky problem is that I still didn't fix the race regarding leaderZkNodeParentVersion.  I just made it harder to repro.\n\nThe smoking gun is this line:\n\n\n      log.info(\"No version found for ephemeral leader parent node, won't remove previous leader registration.\");\n\n\n\nYou can repro this pretty easily with the following change:\n\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n -- a/solr/core/src/java/org/apache/solr/cloud/ElectionContext.java\n ++ b/solr/core/src/java/org/apache/solr/cloud/ElectionContext.java\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n@@ -193,7 +193,7 @@ class ShardLeaderElectionContextBase extends ElectionContext {\n           List<OpResult> results;\n           \n           results = zkClient.multi(ops, true);\n           \n           Thread.sleep(10000);\n           for (OpResult result : results) {\n             if (result.getType() == ZooDefs.OpCode.setData) {\n               SetDataResult dresult = (SetDataResult) result;\n\n\n\nWe need a harder synchronization around becoming leader vs. canceling. ",
            "id": "comment-15159610"
        },
        {
            "date": "2016-02-23T20:54:36+0000",
            "author": "Scott Blum",
            "content": "Attached a patch with real synchronization.  99% sure this will fix the observed flake.\nI also included the MockZKController.close() election cancel change, I think it's a good cleanup but not related to the flake. ",
            "id": "comment-15159632"
        },
        {
            "date": "2016-02-24T19:05:12+0000",
            "author": "Scott Blum",
            "content": "Mark Miller should I open a separate jira for the follow on patch? ",
            "id": "comment-15163535"
        },
        {
            "date": "2016-02-24T19:47:04+0000",
            "author": "Mark Miller",
            "content": "No, we only open a new issue if this one has gone out in a release, otherwise we can keep iterating as needed in the same issue. A bit busy, but I'll get to this soon. ",
            "id": "comment-15163597"
        },
        {
            "date": "2016-02-26T17:32:26+0000",
            "author": "ASF subversion and git services",
            "content": "Commit efb7bb171b22a3c6a00d30eefe935a0024df0c71 in lucene-solr's branch refs/heads/master from markrmiller\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=efb7bb1 ]\n\nSOLR-8697: Add synchronization around registering as leader and canceling. ",
            "id": "comment-15169379"
        },
        {
            "date": "2016-02-27T07:06:28+0000",
            "author": "ASF subversion and git services",
            "content": "Commit c2bc93822d73b66c74ed998ea6c57a3cce05af44 in lucene-solr's branch refs/heads/master from Shalin Shekhar Mangar\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=c2bc938 ]\n\nSOLR-8697: Fix precommit failure ",
            "id": "comment-15170408"
        },
        {
            "date": "2016-04-21T17:47:54+0000",
            "author": "Anshum Gupta",
            "content": "Reopening to back port for 5.5.1 ",
            "id": "comment-15252315"
        },
        {
            "date": "2016-04-21T20:39:36+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 0dabbadb4dbdabbad4da06a49e2eebd908a4cd62 in lucene-solr's branch refs/heads/branch_5x from markrmiller\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=0dabbad ]\n\nSOLR-8697: Scope ZK election nodes by session to prevent elections from interfering with each other and other small LeaderElector improvements. ",
            "id": "comment-15252648"
        },
        {
            "date": "2016-04-21T20:39:38+0000",
            "author": "ASF subversion and git services",
            "content": "Commit d08169e6f6355d9023779cac1303ab48fe2c86e0 in lucene-solr's branch refs/heads/branch_5x from markrmiller\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=d08169e ]\n\nSOLR-8697: Add synchronization around registering as leader and canceling. ",
            "id": "comment-15252649"
        },
        {
            "date": "2016-04-21T20:39:39+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 4b42c77ac6b045dce914d2244298cd0fea5300e4 in lucene-solr's branch refs/heads/branch_5x from Shalin Shekhar Mangar\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=4b42c77 ]\n\nSOLR-8697: Fix precommit failure ",
            "id": "comment-15252650"
        },
        {
            "date": "2016-04-21T21:11:42+0000",
            "author": "ASF subversion and git services",
            "content": "Commit f8dd98f93b75ff774fd81c3a44d551d204676b94 in lucene-solr's branch refs/heads/branch_5_5 from markrmiller\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=f8dd98f ]\n\nSOLR-8697: Scope ZK election nodes by session to prevent elections from interfering with each other and other small LeaderElector improvements. ",
            "id": "comment-15252750"
        },
        {
            "date": "2016-04-21T21:11:44+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 78bed536984dbfd4ba2f802deb58b29979d59329 in lucene-solr's branch refs/heads/branch_5_5 from markrmiller\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=78bed53 ]\n\nSOLR-8697: Add synchronization around registering as leader and canceling. ",
            "id": "comment-15252751"
        },
        {
            "date": "2016-04-21T21:11:45+0000",
            "author": "ASF subversion and git services",
            "content": "Commit f6fca6901665cab4bea078baa4350ddc8964a2cf in lucene-solr's branch refs/heads/branch_5_5 from Shalin Shekhar Mangar\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=f6fca69 ]\n\nSOLR-8697: Fix precommit failure ",
            "id": "comment-15252752"
        },
        {
            "date": "2016-05-13T18:23:46+0000",
            "author": "Jeff Wartes",
            "content": "Does this fix SOLR-6498? ",
            "id": "comment-15282958"
        },
        {
            "date": "2016-05-13T18:37:42+0000",
            "author": "Scott Blum",
            "content": "Probably so.  I think we should close that one and assume it's fixed. ",
            "id": "comment-15282985"
        }
    ]
}