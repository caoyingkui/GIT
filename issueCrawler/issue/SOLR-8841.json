{
    "id": "SOLR-8841",
    "title": "edismax: minimum match and compound words",
    "details": {
        "components": [
            "search"
        ],
        "type": "Bug",
        "labels": "",
        "fix_versions": [],
        "affect_versions": "5.5,                                            6.0",
        "status": "Open",
        "resolution": "Unresolved",
        "priority": "Major"
    },
    "description": "Hi,\n\nwhen searching for a single word which is split by a compound word splitter (very common in German), minimum match is not handled correctly. It is always set to 1 (only a single search term), but as the word is split into several single parts, one matching part is enough\n\nThis also happens if mm is set to 100%.\n\nProbably mm should be set after the split has been performed. Similar problems might arise with synonymization at search time.\n\nRegards\nChristian",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "date": "2016-03-14T22:17:42+0000",
            "author": "Tom Burton-West",
            "content": "This looks very similar to the bug that was fixed in Solr 4.1 for  SOLR-3589\nhttps://issues.apache.org/jira/browse/SOLR-3589\nI wonder if the fix somehow got lost in the move to Solr 5.5?  \nDoes the test labeled \"SOLR-3589: Edismax parser does not honor mm parameter if analyzer splits a token\"  in https://github.com/apache/lucene-solr/blob/branch_5_5/solr/core/src/test/org/apache/solr/search/TestExtendedDismaxParser.java run ok?\n\nTom\n\n ",
            "id": "comment-15194276"
        },
        {
            "date": "2016-03-14T22:27:40+0000",
            "author": "Christian Winkler",
            "content": "Maybe it's a bit different as this is not a tokenizer but a filter (like DictionaryCompoundWordTokenFilter).\n\nRegards\nChristian ",
            "id": "comment-15194292"
        }
    ]
}