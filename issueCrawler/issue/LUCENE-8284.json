{
    "id": "LUCENE-8284",
    "title": "Add MultiTermsIntervalsSource",
    "details": {
        "components": [],
        "status": "Patch Available",
        "resolution": "Unresolved",
        "fix_versions": [],
        "affect_versions": "None",
        "labels": "",
        "priority": "Minor",
        "type": "Improvement"
    },
    "description": "Add support for creating an IntervalsSource from multi-term expansions such as wildcards, regular expressions, etc.",
    "attachments": {
        "LUCENE-8284.patch": "https://issues.apache.org/jira/secure/attachment/12921266/LUCENE-8284.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "id": "comment-16458668",
            "author": "Matt Weber",
            "content": "Initial patch adding WildcardIntervalsSource, PrefixIntervalsSource, and RegexpIntervalsSource.   ",
            "date": "2018-04-30T15:39:45+0000"
        },
        {
            "id": "comment-16458673",
            "author": "Matt Weber",
            "content": "Alan Woodward Jim Ferenczi\n\nSince these expand terms per-segment the terms are not available when creating the IntervalWeight and thus result in a null simScorer if these are the only sources.  I currently picked using a constant 1.0f in this case.  Not sure if this is the best approach or not. ",
            "date": "2018-04-30T15:45:36+0000"
        },
        {
            "id": "comment-16460767",
            "author": "Adrien Grand",
            "content": "I don't think we should expose intervals on multi-term queries: it doesn't scale. I know spans have SpanMultiTermQuery which does the same, but I've seen users having issue with it as soon as they weren't working on a tiny dataset anymore. Intervals on prefixes or infixes should be doable by indexing (edge) ngrams, maybe there are things we could do in order to make it easier to use? This might be just documentation. ",
            "date": "2018-05-02T09:23:14+0000"
        },
        {
            "id": "comment-16460819",
            "author": "Jim Ferenczi",
            "content": "I agree with Adrien, just exposing multi term queries without limitations is not going to scale and will certainly produce OOME or very slow query.\n(edge) ngrams indexing should be used for prefixes and infixes matching but it won't work for fuzzy or regex queries so another option would be to accept multi term queries but only if they use top terms rewriting.\nSo it would only select the top terms (and we can limit the number to Boolean.MAX_CLAUSE_COUNT) and translate them into term intervals ? maxExpansions should be a mandatory parameter for this kind of source in order to make sure that users are aware that only a subset of the matching terms are considered. ",
            "date": "2018-05-02T10:12:27+0000"
        },
        {
            "id": "comment-16461092",
            "author": "Matt Weber",
            "content": "Adrien Grand Jim Ferenczi\n\nI disagree.  There are many cases where they are not expensive and/or I, as a user, understand the consequences and am willing to live with it.  Indexing techniques (ngrams, etc) will only go so far and there are many cases where they might actually introduce issues once your not working on a tiny dataset.  I feel the type of restriction or optimizations you talk about should be added at the usage level, ie. Solr or Elasticsearch.\n\nIs there anything I can do to move this forward?  Add an expansion limit?  Rewrite support? ",
            "date": "2018-05-02T14:23:56+0000"
        },
        {
            "id": "comment-16461126",
            "author": "Jim Ferenczi",
            "content": "Is there anything I can do to move this forward? Add an expansion limit? Rewrite support?\n\nYes, as I said in my previous comment we should have a way to limit the expansion through top terms rewrite.\n I discussed with Adrien Grand and Alan Woodward and we agreed that the limit should be explicit (a parameter of the source) and that we should never create a disjunction that is bigger than BooleanQuery#MAX_CLAUSE_COUNT (hard limit for the max expansion). If these restrictions are added then we have no objections to add these kind of sources to intervals . ",
            "date": "2018-05-02T14:53:51+0000"
        },
        {
            "id": "comment-16461601",
            "author": "David Smiley",
            "content": "LUCENE-6513 is related to more intelligently calculate the top-terms using DF,\u00a0TTF. \u00a0I have some WIP refreshing of an existing patch on that ticket. ",
            "date": "2018-05-02T20:41:59+0000"
        },
        {
            "id": "comment-16461774",
            "author": "Matt Weber",
            "content": "Attached a patch that adds an expansion limit per-segment and just gathers the first terms we come across.  Not sure I like this, I am going to try a version that adds a rewrite method to IntervalsSource so we can use the existing rewrite methods including the one David Smiley mentioned. ",
            "date": "2018-05-03T00:25:22+0000"
        }
    ]
}