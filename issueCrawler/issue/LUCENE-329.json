{
    "id": "LUCENE-329",
    "title": "Fuzzy query scoring issues",
    "details": {
        "labels": "",
        "priority": "Minor",
        "components": [
            "core/search"
        ],
        "type": "Bug",
        "fix_versions": [
            "5.3",
            "6.0"
        ],
        "affect_versions": "1.2",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "Queries which automatically produce multiple terms (wildcard, range, prefix, \nfuzzy etc)currently suffer from two problems:\n\n1) Scores for matching documents are significantly smaller than term queries \nbecause of the volume of terms introduced (A match on query Foo~ is 0.1 \nwhereas a match on query Foo is 1).\n2) The rarer forms of expanded terms are favoured over those of more common \nforms because of the IDF. When using Fuzzy queries for example, rare mis-\nspellings typically appear in results before the more common correct spellings.\n\n\nI will attach a patch that corrects the issues identified above by \n1) Overriding Similarity.coord to counteract the downplaying of scores \nintroduced by expanding terms.\n2) Taking the IDF factor of the most common form of expanded terms as the \nbasis of scoring all other expanded terms.",
    "attachments": {
        "ASF.LICENSE.NOT.GRANTED--patch.txt": "https://issues.apache.org/jira/secure/attachment/12312489/ASF.LICENSE.NOT.GRANTED--patch.txt",
        "LUCENE-329.patch": "https://issues.apache.org/jira/secure/attachment/12730488/LUCENE-329.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2005-01-05T06:39:35+0000",
            "content": "Created an attachment (id=13887)\nFix for issues identified in this bug\n\nFix for the fuzzy scoring issues. Introduced new subclasses for BooleanQuery\nand TermQuery - ExpandedTermsQuery and ExpandedTermQuery respectively.\n\"Fuzzy\" queries (range, multiterm and fuzzy) now use these subclasses to make\nuse of their new Similarity implementations. ",
            "author": "Mark Harwood",
            "id": "comment-12322124"
        },
        {
            "date": "2005-09-23T04:45:14+0000",
            "content": "This has been partially addressed. \n\nIssue 1, the coord factor has been rectified with the introduction of new constructor BooleanQuery(boolean disableCoord).\n\nIssue 2 (idf ranking) has not been addressed.  ",
            "author": "Mark Harwood",
            "id": "comment-12330222"
        },
        {
            "date": "2006-10-05T15:41:49+0000",
            "content": "Why isn't the patch implemented? My users are finding the current result of fuzzy searched not correct (as stated in the sample provided by Mark)\n ",
            "author": "Marco Dissel",
            "id": "comment-12440168"
        },
        {
            "date": "2006-10-05T18:50:30+0000",
            "content": "I'm not very familiar with this issue, but a quick review of the patch and the existing comments lead me to believe that commiting it as is wouldn't be the cleanest way to deal with this problem:\n\n1) As Mark mentioned, a \"disableCoord\" option has been added to BooleanQuery which makes the ExpandedTermsQuery class in this patch unneccessary.  furthermore, the ExpandedTermsQuery class is (in my opinion) broken because it ignores any user specific Similarity completely (instead of just ignoring the coord factor)\n\n2) This patch does not include any test cases.\n\n\nFurthermore, this patch (assuming it does what it says it does) would fundementally alter the scoring of a FuzzyQuery \u2013 the new scoring may seem like the right thing to do for you and for Mark, but without a larger concensus I'm a little worried that perhaps there are just as many FuzzyQuery users out there who are happy with the current behavior and would consider this change a bug.  So any \"fix\" for this should either be configurable, or have an overwelming amount of support that the change is the \"right\" thing to do.\n\n(The main issue seems to be that terms with low idf have a larger impact, and that results in rare mis-spellings getting higher scores \u2013 but assuming \"clean data\" with no mis-spellings, scoring \"rare\" terms higher seems like the ideal behavior, correct?)\n ",
            "author": "Hoss Man",
            "id": "comment-12440213"
        },
        {
            "date": "2006-10-05T19:10:12+0000",
            "content": ">> but assuming \"clean data\" with no mis-spellings, scoring \"rare\" terms higher seems like the ideal behavior\n\nExact matched of a term should have a higher ranking then fuzzy matched terms.. at least that's the expected behaviour in my situation although i think it seems the most common behaviour.. We could also make this optionally, so that we don't affect the current scoring algorithm..\n\nps. i'm using the Lucene.NET port, so by changing/extending this behaviour in Java we (or George) can implement this at the .NET version as well. ",
            "author": "Marco Dissel",
            "id": "comment-12440219"
        },
        {
            "date": "2008-11-13T02:37:50+0000",
            "content": "Any consensus on this? We have the disableCoord and now the option to use a constant score mode for all the mult-term queries. Is that enough? What do you think Mark H? Does this patch still make sense? ",
            "author": "Mark Miller",
            "id": "comment-12647168"
        },
        {
            "date": "2008-11-13T03:51:56+0000",
            "content": "I've been using DisjunctionMaxQuery for term expansion. It seems to be a much more natural fit for this kind of problem. BooleanQuery never worked for me even with disableCoord. ",
            "author": "Alexey Lef",
            "id": "comment-12647175"
        },
        {
            "date": "2008-11-13T09:54:36+0000",
            "content": "This patch goes back a while.\nContrib's FuzzyLikeThisQuery contains my current \"best practice\" for fuzzy matching but the logic is mixed in with code that also does \"LikeThis\" optimisations ie working out which input terms are the best to search on rather than using all input terms. This could usefully be lifted out and used elsewhere.\n\nThe fuzzy scoring logic takes the IDF of the input term and uses that as the IDF for scoring all expanded variants. If the input term does not exist then all variants are rewarded with their averaged IDF. Coord is disabled.\n\nUsing some form of IDF is typically desirable to balance a fuzzy query with other (potentially non fuzzy) clauses in the overall user query. Within a fuzzy query (or wildcard or other auto-expanding queries) however I see no reason to differentiate between the auto-expanded terms with different IDF values. In my view these auto-expand queries should generally use the same IDF for all variants and only reward them differently based on edit distance or what other distance metric is meaningful to that form of expansion (e.g. age range query on age 40 +/- 10 years could reward based on closeness to input term 40).\n\nCheers\nMark ",
            "author": "Mark Harwood",
            "id": "comment-12647243"
        },
        {
            "date": "2010-02-15T14:42:02+0000",
            "content": "in my opinion this is now fixable in a very nice way.\n\nwe can make an alternative rewrite method for fuzzy that does just like TopTermsRewrite, except it creates a BooleanQuery of ConstantScore queries instead. this way the score will be equal to the boost.\n\nthen users could choose which one they want to use. ",
            "author": "Robert Muir",
            "id": "comment-12833812"
        },
        {
            "date": "2010-02-15T14:54:37+0000",
            "content": "The problem with ignoring IDF completely is that it doesn't help balance partial matches where there is >1 fuzzy element in the query e.g.in a query  for John~ Patitucci~ I'm probably more interested in a partial match on the rarer surname than a partial match on the common forename. Obliterating IDF completely as a factor would lose this feature (available in FuzzyLikeThisQuery) ",
            "author": "Mark Harwood",
            "id": "comment-12833822"
        },
        {
            "date": "2010-02-15T15:00:11+0000",
            "content": "The problem with ignoring IDF completely is that it doesn't help balance partial matches where there is >1 fuzzy element in the query e.g.in a query for John~ Patitucci~ I'm probably more interested in a partial match on the rarer surname than a partial match on the common forename. Obliterating IDF completely as a factor would lose this feature (available in FuzzyLikeThisQuery)\n\nMark, it wouldn't lose any features. we simply provide another option, just like we do for other MultiTermQuery rewrites for other queries, so users can choose what they want to use. its just an additional choice. ",
            "author": "Robert Muir",
            "id": "comment-12833828"
        },
        {
            "date": "2010-02-15T15:01:37+0000",
            "content": "here is a rough patch ",
            "author": "Robert Muir",
            "id": "comment-12833829"
        },
        {
            "date": "2010-02-15T15:19:21+0000",
            "content": "I'm probably more interested in a partial match on the rarer surname than a partial match on the common forename. Obliterating IDF completely as a factor would lose this feature (available in FuzzyLikeThisQuery)\n\noh I see, this issue is really different from LUCENE-124 (they arent technically duplicates). I can move my patch there. You can still create a 'smarter' method here, it won't get in the way as now FuzzyQuery does not have a hardcoded rewrite method. ",
            "author": "Robert Muir",
            "id": "comment-12833835"
        },
        {
            "date": "2010-02-15T15:24:23+0000",
            "content": "My \"best-practice\" suggestion isn't as simple as offering a choice between preserving IDF for all terms or not.\n\nInstead, it is a proposal that we should use the input term's IDF for scoring all variants of the same root term (or taking an average of variants where the root term does not exist).\n\nThis I feel preserves the benefits of keeping IDF as a factor (as in my John~ Patitucci~ balancing example) but also eliminating the side effects we see where a rare mis-spelling beats exact matches. ",
            "author": "Mark Harwood",
            "id": "comment-12833840"
        },
        {
            "date": "2010-02-15T15:27:50+0000",
            "content": "My \"best-practice\" suggestion isn't as simple as offering a choice between preserving IDF for all terms or not. \n\nMark, right, my mistake. I will move this patch to LUCENE-124 so there is a simple alternative, you can proceed here with a smarter method... sorry i got confused amongst the different issues  ",
            "author": "Robert Muir",
            "id": "comment-12833841"
        },
        {
            "date": "2010-02-15T15:54:39+0000",
            "content": "\nquery for John~ Patitucci~ I'm probably more interested in a partial match on the rarer surname than a partial match on the common forename. \n\n\nas a matter of fact, we have not only one frequency  to consider, rather two Term frequencies!\n\nconsider simpler case\nQuery term: \"Johan\" //would be High frequency term\ngives:\nFuzzy Expanded term1 \"Johana\" // High frequency\nFuzzy Expanded term2 \"Joahn\" // Low Freq\n\nI guess you would like to score the second term higher, meaning Lower frequency (higher IDF)... So far so good. \n\nNow turn it upside down and search for LF typo \"Joahn\"... in that case you would preffer HF Term \"Johan\" from expanded list to score higher...\n\nPoint being, this situation here is just not \"complete\" without taking both frequencies into consideration (Query Term and Expanded term). In my experience, some simple nonlinear hints based on these two freqs bring some easy precision points (HF-LF Pairs are much more likely to be typos that two HF-HF...  ).  ",
            "author": "Eks Dev",
            "id": "comment-12833860"
        },
        {
            "date": "2010-02-15T16:27:14+0000",
            "content": "consider simpler case\n\nOK - but we need to remember that it is important to achieve balance across different fuzzy queries as well as terms within the same fuzzy query.\nLet's stick to the terms within a single fuzzy query for now:\n\nI guess you would like to score the second term higher, meaning Lower frequency\n\nNo, variant's frequency is not a deciding factor - only edit distance. \"Johana\" is similarity 0.6 while \"Joahn\" is 0.2 so I would favour result one  (although the this difference seems a little off in this case)\nThe basic assumption is that user's input is valid and not a typo (deriving spelling suggestions etc are a different topic and one we shouldnt try cover here). \nFuzzy matching can drag in all sorts of unqualified variants with massively different frequencies. Because we cannot control these discrepancies we should reward all these alternatives using the known factors we have to hand - the IDF of the user's supposedly valid input and the similarity measure of each variant compared to the input.\nWe could get fancy about probability of variants given the other input terms in the query but that feels like its straying into spell checker territory and ngrams etc. ",
            "author": "Mark Harwood",
            "id": "comment-12833876"
        },
        {
            "date": "2011-01-27T10:30:18+0000",
            "content": "Recent 3.x versions contain a new FuzzyQuery rewrite method (MultiTermQuery.TopTermsBoostOnlyBooleanQueryRewrite)  that uses a BooleanQuery with clauses of ConstantScoreQuery(TermQuery) usig the fuzzy boost. So term's idf is not used at all.\n\nThis should solve this problem. ",
            "author": "Uwe Schindler",
            "id": "comment-12987483"
        },
        {
            "date": "2011-01-27T14:38:44+0000",
            "content": "So term's idf is not used at all. This should solve this problem\n\nA sub-optimal  for the reasons I outlined earlier:\n\nThe problem with ignoring IDF completely is that it doesn't help balance partial matches where there is >1 fuzzy element in the query e.g.in a query for John~ Patitucci~ I'm probably more interested in a partial match on the rarer surname than a partial match on the common forename. Obliterating IDF completely as a factor would lose this feature (available in FuzzyLikeThisQuery) ",
            "author": "Mark Harwood",
            "id": "comment-12987585"
        },
        {
            "date": "2011-01-27T15:21:48+0000",
            "content": "I agree with your complaints, but this issue was more about MTQ queries at all and strange scoring. So FuzzyQuery behaves now more as one would expect. We already have different variants of this query like FuzzyLikeThis that also solve this issue.\n\nThis is why I closed the issue. ",
            "author": "Uwe Schindler",
            "id": "comment-12987598"
        },
        {
            "date": "2011-01-27T15:22:20+0000",
            "content": "Mark, I tend to agree, but at the same time I think you can safely implement\na RewriteMethod to do whatever you want? (e.g. apply the logic of FuzzyLikeThis)\n\nDoing something special with IDF is really specific to certain Similarities, for example\nyour Similarity might not use the traditional IDF at all, but something involving\ntotalTermFreq and sumOfTotalTermFreq (like language modelling).\n\nSo I am concerned about doing tricky things with the scoring system by default \nfor this query... we provide the simple options in core (Scoring, BoostOnly, etc) though.\n\nAn idea would be to factor the logic out of FuzzyLikeThisQuery into a FuzzyLikeThisRewriteMethod,\nso you could just call .setRewriteMethod on your fuzzy query and use it. ",
            "author": "Robert Muir",
            "id": "comment-12987600"
        },
        {
            "date": "2011-01-27T17:02:21+0000",
            "content": "I think you can safely implement a RewriteMethod to do whatever you want?\n\nYep, I've got workarounds using FuzzyLikeThis that work for me but have long had a general unease about the \"out of the box\" experience for others.\n\nHowever things are certainly better than they were when this issue was first raised and the main concerns have been addressed.\n\nSo FuzzyQuery behaves now more as one would expect\n\nIs it worth explicitly stating those expectations? Mine would be based on these principles:\n1) IDF is commonly accepted as useful when ranking partial matches of queries with multiple optional clauses\n2) IDF doesn't stop being useful if one of those clauses just  happens to be a term flagged as \"fuzzy\".\n\nSo given a query:    rareWord~ OR commonWord~ \nI would expect an exact match on \"rareWord\" to rank higher than an exact match on \"commonWord\".\nI don't think the current implementation respects this.\n\n\n\n\n\n ",
            "author": "Mark Harwood",
            "id": "comment-12987650"
        },
        {
            "date": "2011-03-30T15:50:29+0000",
            "content": "Bulk close for 3.1 ",
            "author": "Grant Ingersoll",
            "id": "comment-13013497"
        },
        {
            "date": "2012-03-09T13:35:10+0000",
            "content": "Why has this been closed ? ",
            "author": "Paul taylor",
            "id": "comment-13226066"
        },
        {
            "date": "2015-05-05T12:39:27+0000",
            "content": "New patch addressing this long-standing bug.\nAddresses the all-or-nothing choices of today where the default is a (poor) use of all IDF factors or a sub-optimal alternative of using a rewrite method with no IDF.\nThe patch includes:\n1) A new default FuzzyQuery rewrite method that balances IDF better\n2) Unit tests for single and multi-query behaviours\n\nAdditionally, this document offers more analysis based on quality tests on a slightly larger set of data not included here: https://docs.google.com/document/d/1KXhbUpD5GFyzNqfk3nocODOo7Upgpd5tmUQp4-OPwiM/edit#heading=h.2e8gdmdqf2m5 ",
            "author": "Mark Harwood",
            "id": "comment-14528373"
        },
        {
            "date": "2015-05-07T20:11:43+0000",
            "content": "I like the patch. Maybe we should blend the total term freq just like we blend the doc freq so that it works too with a similarity that uses the ttf instead of the df?\n\nAlso it is the 2nd query (the other one is FuzzyLikeThis) where we need to hack a bit TermContext in order to decouple the computation of statistics from the registration of the term states. I'm wondering if we should improve TermContext to make it easier, eg.\n\n\nIndex: lucene/core/src/java/org/apache/lucene/index/TermContext.java\n===================================================================\n--- lucene/core/src/java/org/apache/lucene/index/TermContext.java\t(revision 1678141)\n+++ lucene/core/src/java/org/apache/lucene/index/TermContext.java\t(working copy)\n@@ -117,16 +117,31 @@\n    * should be derived from a {@link IndexReaderContext}'s leaf ord.\n    */\n   public void register(TermState state, final int ord, final int docFreq, final long totalTermFreq) {\n+    register(state, ord);\n+    accumulateStatistics(docFreq, totalTermFreq);\n+  }\n+\n+  /**\n+   * Expert: Registers and associates a {@link TermState} with an leaf ordinal. The\n+   * leaf ordinal should be derived from a {@link IndexReaderContext}'s leaf ord.\n+   * On the contrary to {@link #register(TermState, int, int, long)} this method\n+   * does NOT update term statistics.\n+   */\n+  public void register(TermState state, final int ord) {\n     assert state != null : \"state must not be null\";\n     assert ord >= 0 && ord < states.length;\n     assert states[ord] == null : \"state for ord: \" + ord\n         + \" already registered\";\n+    states[ord] = state;\n+  }\n+\n+  /** Expert: Accumulate term statistics. */\n+  public void accumulateStatistics(final int docFreq, final long totalTermFreq) {\n     this.docFreq += docFreq;\n     if (this.totalTermFreq >= 0 && totalTermFreq >= 0)\n       this.totalTermFreq += totalTermFreq;\n     else\n       this.totalTermFreq = -1;\n-    states[ord] = state;\n   }\n \n   /**\n\n ",
            "author": "Adrien Grand",
            "id": "comment-14533301"
        },
        {
            "date": "2015-05-12T10:33:34+0000",
            "content": "Switched to the TermContext.accumulateStatistics() method Adrien suggested for tweaking stats. ",
            "author": "Mark Harwood",
            "id": "comment-14539629"
        },
        {
            "date": "2015-05-12T15:43:55+0000",
            "content": "It's not correct to do maxTtf = Math.max(ttf, maxTtf) because the ttf can sometimes be -1, so it would rather need to be something like maxTtf = ttf == -1 || maxTtf == -1 ? -1 : Math.max(ttf, maxTtf).\n\nAlso I liked it better in the previous patch how you built a new TermContext instance instead of modifying the current one in place. Maybe you could add it back? ",
            "author": "Adrien Grand",
            "id": "comment-14540069"
        },
        {
            "date": "2015-05-19T10:21:03+0000",
            "content": "Updated following review comments (thanks, Adrien).\nAll tests passing on trunk. ",
            "author": "Mark Harwood",
            "id": "comment-14550191"
        },
        {
            "date": "2015-05-19T11:13:05+0000",
            "content": "Last edits to remove unnecessary Math.max() tests. Added assertion around maxTTf expectations ",
            "author": "Mark Harwood",
            "id": "comment-14550242"
        },
        {
            "date": "2015-05-19T11:52:08+0000",
            "content": "Cut-and-paste error in last patch set df=0 and effects were undetected by unit tests.\nEnhanced unit test to detect error then fixed ",
            "author": "Mark Harwood",
            "id": "comment-14550291"
        },
        {
            "date": "2015-05-19T12:12:54+0000",
            "content": "+1 to this patch! ",
            "author": "Adrien Grand",
            "id": "comment-14550334"
        },
        {
            "date": "2015-05-19T12:48:52+0000",
            "content": "Thanks, I'll commit tomorrow if there's no objections. ",
            "author": "Mark Harwood",
            "id": "comment-14550376"
        },
        {
            "date": "2015-05-19T12:49:00+0000",
            "content": "+1 to this patch. I like this approach and it seems scoring-system agnostic, which was my major issue with IDF-specific stuff. When committing, maybe rename adjustDF() since actually it adjusts all term-level stats? ",
            "author": "Robert Muir",
            "id": "comment-14550377"
        },
        {
            "date": "2015-05-20T11:08:34+0000",
            "content": "Commit 1680522 from mharwood@apache.org in branch 'dev/trunk'\n[ https://svn.apache.org/r1680522 ]\n\nLUCENE-329: Fix FuzzyQuery defaults to rank exact matches highest ",
            "author": "ASF subversion and git services",
            "id": "comment-14552134"
        },
        {
            "date": "2015-05-20T12:51:24+0000",
            "content": "Commit 1680548 from mharwood@apache.org in branch 'dev/branches/branch_5x'\n[ https://svn.apache.org/r1680548 ]\n\nLUCENE-329: Fix FuzzyQuery defaults to rank exact matches highest ",
            "author": "ASF subversion and git services",
            "id": "comment-14552260"
        },
        {
            "date": "2015-05-20T12:54:01+0000",
            "content": "Committed to 5.x branch and trunk ",
            "author": "Mark Harwood",
            "id": "comment-14552265"
        },
        {
            "date": "2015-08-26T13:06:04+0000",
            "content": "Bulk close for 5.3.0 release ",
            "author": "Shalin Shekhar Mangar",
            "id": "comment-14713204"
        }
    ]
}