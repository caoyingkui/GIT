{
    "id": "SOLR-7712",
    "title": "TestCloudPivotFacet failure",
    "details": {
        "components": [],
        "type": "Bug",
        "labels": "",
        "fix_versions": [
            "5.3",
            "6.0"
        ],
        "affect_versions": "5.3",
        "status": "Closed",
        "resolution": "Fixed",
        "priority": "Major"
    },
    "description": "java8, branch_5x & trunk, r1686892\n\nOriginal failure here (Linux): <http://jenkins.sarowe.net/job/Lucene-Solr-tests-5.x-Java8/144/>\n\nReproduces for me on OS X 10.10 on branch_5x, but on trunk failed to reproduce the one time I tried it.\n\n\n   [junit4]   2> NOTE: reproduce with: ant test  -Dtestcase=TestCloudPivotFacet -Dtests.method=test -Dtests.seed=2701C0115CD1BF95 -Dtests.slow=true -Dtests.locale=ja_JP -Dtests.timezone=America/Scoresbysund -Dtests.asserts=true -Dtests.file.encoding=ISO-8859-1\n   [junit4] FAILURE 42.6s | TestCloudPivotFacet.test <<<\n   [junit4]    > Throwable #1: java.lang.AssertionError: {main(facet=true&facet.pivot=%7B%21stats%3Dst1%7Dpivot_y_s1%2Cdense_pivot_y_s%2Cdense_pivot_ti1&facet.limit=9&facet.sort=index),extra(rows=0&q=id%3A%5B*+TO+304%5D&stats=true&stats.field=%7B%21key%3Dsk1+tag%3Dst1%2Cst2%7Dpivot_tf1&stats.field=%7B%21key%3Dsk2+tag%3Dst2%2Cst3%7Dpivot_x_s&stats.field=%7B%21key%3Dsk3+tag%3Dst3%2Cst4%7Ddense_pivot_ti1&_test_sort=index)} ==> Mean of sk1 => pivot_y_s1,dense_pivot_y_s,dense_pivot_ti1: {params(rows=0),defaults({main(rows=0&q=id%3A%5B*+TO+304%5D&stats=true&stats.field=%7B%21key%3Dsk1+tag%3Dst1%2Cst2%7Dpivot_tf1&stats.field=%7B%21key%3Dsk2+tag%3Dst2%2Cst3%7Dpivot_x_s&stats.field=%7B%21key%3Dsk3+tag%3Dst3%2Cst4%7Ddense_pivot_ti1&_test_sort=index),extra(fq=%7B%21term+f%3Dpivot_y_s1%7Dh)})} expected:<-1.4136202738271603E8> but was:<-1.4136202738271606E8>\n   [junit4]    > \tat __randomizedtesting.SeedInfo.seed([2701C0115CD1BF95:AF55FFCBF22DD26D]:0)\n   [junit4]    > \tat org.apache.solr.cloud.TestCloudPivotFacet.assertPivotCountsAreCorrect(TestCloudPivotFacet.java:281)\n   [junit4]    > \tat org.apache.solr.cloud.TestCloudPivotFacet.test(TestCloudPivotFacet.java:228)\n   [junit4]    > \tat org.apache.solr.BaseDistributedSearchTestCase$ShardsRepeatRule$ShardsFixedStatement.callStatement(BaseDistributedSearchTestCase.java:960)\n   [junit4]    > \tat org.apache.solr.BaseDistributedSearchTestCase$ShardsRepeatRule$ShardsStatement.evaluate(BaseDistributedSearchTestCase.java:935)\n   [junit4]    > \tat java.lang.Thread.run(Thread.java:745)\n   [junit4]    > Caused by: java.lang.AssertionError: Mean of sk1 => pivot_y_s1,dense_pivot_y_s,dense_pivot_ti1: {params(rows=0),defaults({main(rows=0&q=id%3A%5B*+TO+304%5D&stats=true&stats.field=%7B%21key%3Dsk1+tag%3Dst1%2Cst2%7Dpivot_tf1&stats.field=%7B%21key%3Dsk2+tag%3Dst2%2Cst3%7Dpivot_x_s&stats.field=%7B%21key%3Dsk3+tag%3Dst3%2Cst4%7Ddense_pivot_ti1&_test_sort=index),extra(fq=%7B%21term+f%3Dpivot_y_s1%7Dh)})} expected:<-1.4136202738271603E8> but was:<-1.4136202738271606E8>\n   [junit4]    > \tat org.apache.solr.cloud.TestCloudPivotFacet.assertPivotStats(TestCloudPivotFacet.java:383)\n   [junit4]    > \tat org.apache.solr.cloud.TestCloudPivotFacet.assertPivotData(TestCloudPivotFacet.java:339)\n   [junit4]    > \tat org.apache.solr.cloud.TestCloudPivotFacet.assertPivotCountsAreCorrect(TestCloudPivotFacet.java:302)\n   [junit4]    > \tat org.apache.solr.cloud.TestCloudPivotFacet.assertPivotCountsAreCorrect(TestCloudPivotFacet.java:271)\n   [junit4]    > \t... 42 more",
    "attachments": {
        "SOLR-7712.patch": "https://issues.apache.org/jira/secure/attachment/12742265/SOLR-7712.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2015-06-22T22:52:41+0000",
            "author": "Hoss Man",
            "content": "TL;DR: I think this test needs some some small deltas when doing float/double comparisons \u2013 but i want to think about it a bit more.\n\n\n\nFYI: I couldn't immediately reproduce that seed at r1686892 on 5x, the first time i to beast it made it 5 iterations before it failed with the exact same numeric values.\n\nWhat this test is doing is executing a pivot fact request with stats enabled, then executing a \"drill down\" queries on each pivot field value (by adding an fq) and confirming the numResults matches the previously returned pivot count, and that the top level stats of the drill down query equal the previously returned per-pivot stats.\n\nI remember when writing this test that i expected i would need to do some 3 arg asserts on the floating point stat values to account for a small epsilon that might be introduced in the floating point match because of the different order of computation \u2013 but when i ran the initial straw man test i never got any errors.\n\nI also remember working through the problem in my head for a few minutes to try and figure out why it wasn't failing \u2013 and figuring that regardless of whether it was top level stats or pivot stats, the same code was going to accumulate the (per-index) values in the same order  (the test doesn't do any index updates concurrent to searching for obvious reasons) and i just left it alone.\n\nlooking at these failures now, and adding some extra logging and thinking about it a bit more, i think we've just been getting lucky that this hasn't failed yet.\n\nI can think of 2 ways for this type of validation to fail on exact floating point comparison:\n\n\n\tif different replicas get hit by the top level diff queries, or a diff replica was used to refine a pivot then is used by the verification query, and if those diff replicas have slightly diff segments (due ot recovery, or retry or whatever so the accumulation of the \"sum\" of a field for all the matching docs adds the numbers up in a diff order.\n\tif there are more then 2 shards, and the 2 top level queries (or the refinement of a pivot query) gets responses from the shards in a diff order) then the sum of the aggregate \"sum\" involves adding numbers in a diff order.\n\n\n\nif the \"sum\" is diff, then the \"mean\" might be diff as well (depending on precision loss due to dividing by the count)\n\nBut most times, we deal with numeric values that either don't lose precision when added up, or lose precision the same amount in both ways.\n ",
            "id": "comment-14596792"
        },
        {
            "date": "2015-06-26T23:52:24+0000",
            "author": "Hoss Man",
            "content": "here's a patch i'm currently beasting on both branches. ",
            "id": "comment-14603798"
        },
        {
            "date": "2015-06-26T23:55:31+0000",
            "author": "Hoss Man",
            "content": "bah .. ignore that patch.  i totally forgot we support stats on dates and the handful of manual runs i did with that patch never triggered date stats.  new patch soon. ",
            "id": "comment-14603800"
        },
        {
            "date": "2015-06-28T02:55:59+0000",
            "author": "Hoss Man",
            "content": "beasted this new patch 1500 x2 times last night (trunk + 5x)\n\nI'll keep beasting and plan on committing monday. ",
            "id": "comment-14604477"
        },
        {
            "date": "2015-06-29T17:06:29+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1688266 from hossman@apache.org in branch 'dev/trunk'\n[ https://svn.apache.org/r1688266 ]\n\nSOLR-7712: fixed test to account for aggregate floating point precision loss ",
            "id": "comment-14605907"
        },
        {
            "date": "2015-06-29T17:26:53+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1688267 from hossman@apache.org in branch 'dev/branches/branch_5x'\n[ https://svn.apache.org/r1688267 ]\n\nSOLR-7712: fixed test to account for aggregate floating point precision loss (merge r1688266) ",
            "id": "comment-14605935"
        },
        {
            "date": "2015-06-29T17:33:19+0000",
            "author": "Hoss Man",
            "content": "thanks steve ",
            "id": "comment-14605947"
        },
        {
            "date": "2015-08-26T13:06:07+0000",
            "author": "Shalin Shekhar Mangar",
            "content": "Bulk close for 5.3.0 release ",
            "id": "comment-14713223"
        }
    ]
}