{
    "id": "SOLR-7681",
    "title": "HttpSolrClient fails with a confusing error when a GET request is too big",
    "details": {
        "components": [],
        "type": "Bug",
        "labels": "",
        "fix_versions": [],
        "affect_versions": "None",
        "status": "Open",
        "resolution": "Unresolved",
        "priority": "Minor"
    },
    "description": "If a request is sent with too long an URL for GET, the Solr server responds as follows:\n\n\nHTTP/1.1 413 FULL head\n\nContent-Length: 0\nConnection: close\nServer: Jetty(8.1.10.v20130312)\n\n\n\noascsi.HttpSolrServer.executeMethod currently in such a situation, goes ahead and tries to parse a Content-Type header in such a case and ends up with a SolrServerException: Error executing query caused by org.apache.http.ParseException: Invalid content type.",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "date": "2015-06-16T00:08:43+0000",
            "author": "Hoss Man",
            "content": "FYI: SOLR-7664 already tracks fixing the solrj client to provide the 413 specifics instead of throwing a ParseException.  \n\nwe should keep this issue (SOLR-7681)  focused on trying reduce/eliminate the situations where a 413 will be thrown, and/or improving the returned by the server in such a a situation. so the client knows what to do to try and fix it. ",
            "id": "comment-14587189"
        },
        {
            "date": "2015-06-16T06:21:14+0000",
            "author": "Ramkumar Aiyengar",
            "content": "Is there any situation in which GETs are preferable? This might be a simple matter of adjusting defaults to use POST. Currently SolrJ defaults to GET.. ",
            "id": "comment-14587533"
        },
        {
            "date": "2015-06-16T22:15:21+0000",
            "author": "Hoss Man",
            "content": "HTTP Proxies can cache GET requests more easily to reduce load on the solr servers when clients frequently execute the same queries.  it's also a lot easier to make sense of what's going on in log files.\n\nI think the best \"solution\" is:\n\n\tfigure out how to increase this limit in the jetty stack\n\tfigure out how to improve the HTTP Status error message returned when the limit is exceeded anyway to make it clear what the problem is (and suggest using POST).\n\tmake sure all of the various HTTP based SolrClient imples make it easy to use POST on any/all request so that people who don't care about caching can use it. (and make sure we have a test that POST is in fact used in this case.\n\n ",
            "id": "comment-14588894"
        },
        {
            "date": "2015-06-16T23:34:01+0000",
            "author": "Ramkumar Aiyengar",
            "content": "Do you think these justify GET being the default? Solr can already do caching (better than proxies since it can invalidate), and our logs can show the parameters on POST really if needed. I am not arguing against having GET altogether, just that if we should encourage people to use it..\n\nNote that increasing the buffer might have perf implications, most HTTP parsers are optimised to deal with short headers, with large amounts of data following it if necessary \u2013 I don't know about jetty impl though.\n\nAlternative (more complicated) might be for us to somehow know what the limit is (might be possible now that we know we use Jetty), have that available through clusterstate and switch between GET and POST based on payload size. I am not convinced myself though that this complexity is worth it.. ",
            "id": "comment-14589011"
        },
        {
            "date": "2015-06-16T23:48:25+0000",
            "author": "Ramkumar Aiyengar",
            "content": "Actually thinking through this further, with 5x Jetty is an implementation detail, so we know the GET size limit, forget about figuring out or storing in clusterstate. The simplest solution might be to just always switch to POST if that limit is reached, and we don't break compatibility since it wouldn't have worked before. For the power user, we can always provide a way to tweak the GET to POST cutoff limit. ",
            "id": "comment-14589032"
        },
        {
            "date": "2015-06-17T00:00:54+0000",
            "author": "Hoss Man",
            "content": "i don't have a strong opinion about wether SolrJ defaults to GET or POST, i was just pointing out the advantages of GET in response to your question (aside: Solr's caching is great, and helps at a micro level, but in my experience HTTP caching is still very valuable at a macro level - particularly in the case of DoS type situations)\n\nI don't disagree with any of the points you've made, but those all address changes in the client \u2013 of which we only control 1 (solrj)\n\nIt doesn't change the fact that on the server side (which is what this issue is about) we should make the error message more useful when someone triggers this problem from python/curl/ruby/haskell/whatever \u2013 and i would argue it's worth while to at least investigate increasing the limit in jetty to see if there are any downsides, or at least figuring out a way to expose it as a tunable server configuration knob even if we decide not to increase it by default. ",
            "id": "comment-14589046"
        },
        {
            "date": "2015-06-17T00:08:47+0000",
            "author": "Ramkumar Aiyengar",
            "content": "+1, I agree we need to fix at least the server side error, these suggestions are only to make it less possible to hit the error if the client is using SolrJ. ",
            "id": "comment-14589060"
        },
        {
            "date": "2015-06-17T23:21:34+0000",
            "author": "Hrishikesh Gadre",
            "content": "Ramkumar Aiyengar Ideally we should be selecting the HTTP verb based on semantics of the functionality. e.g.\n\nread_only functionality -> Get\nidempotent updates -> put\nnon idempotent updates (or adds) -> post etc.\n\nIs there a reason why we don't care about it? ",
            "id": "comment-14590833"
        },
        {
            "date": "2015-06-18T07:10:17+0000",
            "author": "Ramkumar Aiyengar",
            "content": "Ideally yes, and there's no particular reason I know of why we don't always use it. I think there's still an issue out there to prevent all updates through GET (or may be that was resolved, I don't remember)..\n\nThe only real concern here is that the size restrictions on GET are much more restrictive than POST, and queries can sometimes be as big as updates. If Jetty can safely be modified to accept GETs of any size without perf concerns, then probably this is lesser of a problem. ",
            "id": "comment-14591374"
        },
        {
            "date": "2015-06-18T15:59:45+0000",
            "author": "Hrishikesh Gadre",
            "content": "Yes sure. I was just curious. ",
            "id": "comment-14592025"
        }
    ]
}