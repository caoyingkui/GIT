{
    "id": "LUCENE-2905",
    "title": "Sep codec writes insane amounts of skip data",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [],
        "type": "Bug",
        "fix_versions": [
            "6.0"
        ],
        "affect_versions": "None",
        "resolution": "Unresolved",
        "status": "Open"
    },
    "description": "Currently, even if we use better compression algorithms via Fixed or Variable Intblock\nencodings, we have problems with both performance and index size versus StandardCodec.\n\nConsider the following numbers:\n\n\nstandard:\nfrq: 1,862,174,204 bytes\nprx: 1,146,898,936 bytes\ntib: 541,128,354 bytes\ncomplete index: 4,321,032,720 bytes\n\nbulkvint:\ndoc: 1,297,215,588 bytes\nfrq: 725,060,776 bytes\npos: 1,163,335,609 bytes\ntib: 729,019,637 bytes\ncomplete index: 5,180,088,695 bytes\n\nsimple64:\ndoc: 1,260,869,240 bytes\nfrq: 234,491,576 bytes\npos: 1,055,024,224 bytes\nskp: 473,293,042 bytes\ntib: 725,928,817 bytes\ncomplete index: 4,520,488,986 bytes\n\n\n\nI think there are several reasons for this:\n\n\tSplitting into separate files (e.g. postings into .doc + .freq).\n\tHaving to store both a relative delta to the block start, and an offset into the block.\n\tIn a lot of cases various numbers involved are larger than they should be: e.g. they are file pointer deltas, but blocksize is fixed...\n\n\n\nHere are some ideas (some are probably stupid) of things we could do to try to fix this:\n\nIs Sep really necessary? Instead should we make an alternative to Sep, Interleaved? that interleaves doc and freq blocks (doc,freq,doc,freq) into one file? the concrete impl could implement skipBlock() for when they only want docdeltas: e.g. for Simple64 blocks on disk are fixed size so it could just skip N bytes. Fixed Int Block codecs like PFOR and BulkVint just read their single numBytes header they already have today, and skip numBytes.\n\nIsn't our skipInterval too low? Most of our codecs are using block sizes such as 64 or 128, so a skipInterval of 16 seems a little overkill.\n\nShouldn't skipInterval not even be a final constant in SegmentWriteState, but instead completely private to the codec?\n\nFor block codecs, doesn't it make sense for them to only support skipping to the start of a block? Then, their skip pointers dont need to be a combination of delta + upto, because upto is always zero. What would we have to modify in the bulkpostings api for jump() to work with this?\n\nFor block codecs, shouldn't skipInterval then be some sort of divisor, based on block size (maybe by default its 1, meaning we can skip to the start of a every block)\n\nFor codecs like Simple64 that encode fixed length frames, shouldnt we use 'blockid' instead of file pointer so that we get smaller numbers? e.g. simple64 can do blockid * 8 to get to the file pointer.\n\nGoing along with the blockid concept, couldnt pointers in the terms dict be blockid deltas from the index term, instead of fp deltas? This would be smaller numbers and we could compress this metadata better.",
    "attachments": {
        "LUCENE-2905_interleaved.patch": "https://issues.apache.org/jira/secure/attachment/12470971/LUCENE-2905_interleaved.patch",
        "LUCENE-2905_skipIntervalMin.patch": "https://issues.apache.org/jira/secure/attachment/12470800/LUCENE-2905_skipIntervalMin.patch",
        "LUCENE-2905_simple64.patch": "https://issues.apache.org/jira/secure/attachment/12470832/LUCENE-2905_simple64.patch",
        "LUCENE-2905_intblock.patch": "https://issues.apache.org/jira/secure/attachment/12470885/LUCENE-2905_intblock.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2011-02-04T17:29:23+0000",
            "content": "As a quick experiment, i compared simple64-varint with the default skipInterval (16) against one with a higher interval (32).\n\nTotal index size decreased from 4,520,488,986 bytes to 4,269,022,166 bytes.\n\nMMapDirectory:\n\n\n\nQuery\nQPS base\nQPS patch\nPct diff\n\n\nunit~0.7\n29.83\n28.84\n-3.3%\n\n\nstates\n36.26\n35.49\n-2.1%\n\n\n+united +states\n12.02\n11.80\n-1.9%\n\n\nun*d\n17.37\n17.24\n-0.7%\n\n\nuni*\n16.46\n16.36\n-0.6%\n\n\nu*d\n9.27\n9.22\n-0.5%\n\n\nunit*\n28.43\n28.49\n0.2%\n\n\n\"united states\"\n8.19\n8.25\n0.8%\n\n\ndoctitle:.[Uu]nited.\n4.00\n4.04\n1.0%\n\n\ndoctimesecnum:[10000 TO 60000]\n10.10\n10.25\n1.5%\n\n\nunit~0.5\n17.52\n17.82\n1.7%\n\n\nspanNear([unit, state], 10, true)\n31.77\n32.33\n1.7%\n\n\nunited~0.6\n7.96\n8.20\n3.0%\n\n\nunited~0.75\n10.94\n11.49\n5.0%\n\n\n\"united states\"~3\n4.14\n4.40\n6.2%\n\n\nunited states\n11.21\n12.07\n7.7%\n\n\nspanFirst(unit, 5)\n107.66\n116.32\n8.0%\n\n\n+nebraska +states\n111.04\n120.41\n8.4%\n\n\n\n ",
            "author": "Robert Muir",
            "id": "comment-12990638"
        },
        {
            "date": "2011-02-04T17:37:38+0000",
            "content": "Here's SimpleFSDirectory:\n\n\n\n\nQuery\nQPS base\nQPS patch\nPct diff\n\n\ndoctimesecnum:[10000 TO 60000]\n8.93\n8.80\n-1.4%\n\n\nstates\n31.27\n31.19\n-0.3%\n\n\nspanNear([unit, state], 10, true)\n23.34\n23.34\n-0.0%\n\n\nunit*\n25.77\n25.84\n0.3%\n\n\nunit~0.7\n14.18\n14.31\n0.9%\n\n\nuni*\n14.21\n14.38\n1.3%\n\n\n\"united states\"\n6.53\n6.64\n1.6%\n\n\nunit~0.5\n8.19\n8.37\n2.2%\n\n\nun*d\n13.12\n13.44\n2.4%\n\n\nunited~0.6\n4.34\n4.46\n2.8%\n\n\nu*d\n5.88\n6.05\n2.9%\n\n\n+united +states\n10.17\n10.47\n2.9%\n\n\n\"united states\"~3\n3.77\n3.89\n3.1%\n\n\nunited~0.75\n6.95\n7.23\n4.0%\n\n\ndoctitle:.[Uu]nited.\n2.33\n2.47\n6.0%\n\n\nspanFirst(unit, 5)\n91.85\n98.12\n6.8%\n\n\nunited states\n9.91\n10.61\n7.0%\n\n\n+nebraska +states\n63.09\n72.34\n14.7%\n\n\n\n ",
            "author": "Robert Muir",
            "id": "comment-12990642"
        },
        {
            "date": "2011-02-04T17:52:42+0000",
            "content": "Hi Robert,\n\nit is good to see we are going in the same direction ;o). Here is a short paper about an extension of skip list for block based inverted file [1] which was accepted at the European Conference of Information Retrieval. I shared this paper in a previous discussion with Michael. Maybe you will find some ideas inside that are worth keeping in mind.\n\nAlso, the main problem of the current skip list implementation when it is applied on Sep codec is in my opinion the fact that we have to store for each skip list entry the fp of each of the sep file. And more you have files (in the SIREn case, we had 5 files), more the skip list data structure get bigger.\nHowever, if you think of it, the main goal of the skip list is to skip doc id, not freq or pos. We are storing the fps of the freq and pos files only because we need to synchronise the position of the \"inverted file pointer\" on each file. \nAlso, this occurs some overhead when you only need to answer\n\n\tpure boolean query: we only need to scan the doc file, but we are still reading and decoding the fp pointers of the freq and pos file;\n\textended boolean query: we only need to scan the doc and freq file, but we are still reading and decoding the fp pointers of the pos file;\n\n\n\nAn idea I had a few months ago (but never found the time to implement it and test it) was to change the way the skip list data structure is created. The idea was to store the pointer to the doc file in the skip entry, and nothing else. The other pointers (to the freq file and position file) are in fact stored into the block header.\nWhen using the skip list, you will traverse the skip list until you find the skip point of interest, then decode the associated skip entry and get the doc file pointer. The doc file pointer indicates the beginning of the block that contains the identifiers that you are looking for.\nAfter reading the block from the disk and load it into memory, you can decode its header, which contains a pointer to the associated block into the frequency file. Similarly, into the block header of the frequency file, you have a pointer to the associated block into the pos file. In fact, you can picture this by a linked list of block. The skip list provides only the first pointer to the block doc file, then pointers to subsequent blocks are included into the block headers.\nOn one hand, this considerably reduce the size of the skip list, since most of the information are \"exported\" and encoded into block headers. On the other hand, I am not sure if it reduces the size of the index, as it just move the data from the skip list to the inverted file. In addition, I think it makes impossible the delta-encoding of the fp for the freq and pos file. But they might be other optimisation possible with this data model.\n\n[1] http://dl.dropbox.com/u/1278798/ecir2011-skipblock.pdf ",
            "author": "Renaud Delbru",
            "id": "comment-12990649"
        },
        {
            "date": "2011-02-04T18:00:29+0000",
            "content": "These are all great ideas!\n\nInterleaving frq/doc makes tons of sense, not only for better\ncompression, but because for large (can't-be-hot) indexes the need to\nseek to 2 files during search is costly.\n\nIf we are REALLY sure keeping int alignment in these intblock\nencoded files is not important (ie, we really do get best perf by\nslurping in byte[] and then decoding from there), then we should also\nstore eg skip data into the frq/doc file (this is what Standard\ndoes).\n\nMaybe similarly interleave payload/positions packets?\n\nI think our skipInterval is too low for the block codecs (and, should\nbe private) Separately, I think we should break out \"when skip is even\nstored\" vs \"how frequently we index skip data\".  EG maybe we should\nonly store skip data if dF >= 1024 (say), and then separately index\nskip data every N docs.\n\nSkip only to start-of-block is tempting, but, tricky for the varint\ncase since the blocks don't \"line up\" across frq/doc.  For fixed\nblock, it's silly to store separate seek points since they are always\n\"aligned\".\n\nBlockID for Simple64 (and more generally any varint codec whose blocks\nare fixed number of bytes) makes great sense.\n\nFor low DF terms w/in a block I think we shouldn't store their\npointers into the posting; instead, you should load an earlier term's\npostings and scan over its postings.  This should save tons of space\nin the tib file. ",
            "author": "Michael McCandless",
            "id": "comment-12990654"
        },
        {
            "date": "2011-02-04T18:16:53+0000",
            "content": "Renaud thanks for the paper... I will spend some time trying to digest it!\nBut I think its always an option to try to reduce the number of files, too.\nThis is important also for # of open files and other practical reasons.\n\nMike a few questions:\n\nIf we are REALLY sure keeping int alignment in these intblock\nencoded files is not important (ie, we really do get best perf by\nslurping in byte[] and then decoding from there), then we should also\nstore eg skip data into the frq/doc file (this is what Standard\ndoes).\n\nWell, I measured this a lot, but why box ourselves out? As a first step \nwe can still keep the .skp file as-is, but it only needs point to \nthe start of the doc block in the frq/doc file.\n\n\nMaybe similarly interleave payload/positions packets?\n\nI think we should do something here. But when i started trying to draw\nthis up, I came to the conclusion that payload byte[]s should themselves\nbe actual terms (e.g. deduplicated), and we store some sort of ord to get\nto them instead of bytes and length, etc. if they were themselves terms,\nthen they could also store forward postings back to their docs, and you \ncould query on payloads (attributes) efficiently too... but I know this\nwould be a fairly large change.\n\n\nSeparately, I think we should break out \"when skip is even\nstored\" vs \"how frequently we index skip data\".\n\nI agree, another reason to pull skipInterval completely codec-private.\nThen a codec could itself have a separate \"skipMinimum\" too.\n\n\nFor low DF terms w/in a block I think we shouldn't store their\npointers into the posting; instead, you should load an earlier term's\npostings and scan over its postings. This should save tons of space\nin the tib file.\n\nHow would this work? Isnt everything right now in the .tib delta-encoded\nagainst the index term? What if there are 'large' terms in between?\nAnd for some queries like rangequery, wouldnt this create a little O(n^2)\nof sorts? I don't think this is a big deal, most people should be using\ne.g. NumericRangeQuery, and maybe we could still prevent it...? ",
            "author": "Robert Muir",
            "id": "comment-12990662"
        },
        {
            "date": "2011-02-10T20:22:49+0000",
            "content": "here's a patch with what Mike suggested, moving the skipping stuff private to the codecs, and separating the interval from the minimum df necessary to index skip data.\n\ni also added the 'dont skip when close' opto to Sep and Preflex codecs (since i neglected to do this and only did Standard).\n\nI kept all parameters the same (I think we should benchmark etc before changing) but I did some experiments with a fairly large skipMinimum and it looked promising. I think we later (after we have good benchmarks) set this reasonable, and maybe bump skipInterval for Sep codec too, especially if we improve its 'pendingPositions' consuming to balance it out.\n\nSo, I think we should apply this little patch as-is as a small step. ",
            "author": "Robert Muir",
            "id": "comment-12993205"
        },
        {
            "date": "2011-02-11T05:05:42+0000",
            "content": "here's a patch solving a lot of the issue for the skiplists and doc/freq/prox etc pointers for Simple64.\n\nas discussed above, because its size on disk is fixed, we encode blockID and blockID deltas instead of file pointers. \n\nwith the saved bits, we steal one for the case where the delta is within-block, in this case this delta is really the upto delta.\n\nthis puts my simple64 indexes smaller than standardcodec (and speeds up the queries too) ",
            "author": "Robert Muir",
            "id": "comment-12993345"
        },
        {
            "date": "2011-02-11T12:03:11+0000",
            "content": "I edited my comment above, because the new version of jira works differently somehow with newlines/pasting and it screwed up the quoting.\n\nTo add insult to injury, when you edit there is no longer a way to comment on what you changed...  ",
            "author": "Robert Muir",
            "id": "comment-12993463"
        },
        {
            "date": "2011-02-11T13:02:49+0000",
            "content": "Both patches look great!  Bit by bit... ",
            "author": "Michael McCandless",
            "id": "comment-12993478"
        },
        {
            "date": "2011-02-11T18:59:12+0000",
            "content": "here's a patch for the regular FixedIntBlock and VariableIntBlock cases: they write upto first, if a bit is set then its within block and upto is the upto delta. otherwise they then read the vlong for the fp delta.\n\nthis saves about 5% total bulkvint index size. ",
            "author": "Robert Muir",
            "id": "comment-12993639"
        },
        {
            "date": "2011-02-14T00:12:18+0000",
            "content": "attached is an initial stab at an interleaved block layout for fixed int block coders.\n\nits limited, and optimized for the case where doc,freq,pos have the same blocksize...\n\nthe existing fixed int block api is not really changed, only extended. so you can implement this api and easily choose between Sep or Fixed index layout.\n\nthe docs and freq blocks are interleaved (doc block, freq block) in such a way that its generally transparent to bulk enum consumers. So they work in lock-step, on the same actual underlying index input (sharing io buffer, etc).\n\npointers in the term dictionary and skipdata are reduced, because they only point to the block/offset in the single .doc file, and the freq is implied and parallel following it.\n\ni added skipBlock() which for these fixed encoders, means they only read their header (typically a single vint) and skip their compressed payload. Because of this, i increased skip interval (to blocksize actually) in the patch. \n\nThis might seem scary, but its not so bad, because without using any skip data, we can skip over the blocks themselves... e.g. skipping over 16,384 pending positions is only 128 vint reads.\n\nfor now, i only cutover BulkVInt for testing, here's what i have so far:\nThe total index size for the wikipedia benchmark index decreased from to 4,936,834,246 to 4,568,172,525 bytes (note this was already recently reduced from 5,180,088,695 bytes).\n\nHere is the perf results:\n\n\n\nQuery\nQPS branch\nQPS patch\nPct diff\n\n\nunit~0.7\n29.17\n28.34\n-2.9%\n\n\nunit*\n30.28\n29.65\n-2.1%\n\n\nuni*\n17.56\n17.20\n-2.0%\n\n\nunit~0.5\n17.89\n17.54\n-1.9%\n\n\ndoctitle:.[Uu]nited.\n4.02\n3.97\n-1.3%\n\n\nun*d\n17.43\n17.28\n-0.9%\n\n\nu*d\n8.97\n8.92\n-0.5%\n\n\ndoctimesecnum:[10000 TO 60000]\n10.88\n10.92\n0.3%\n\n\n+united +states\n13.98\n14.04\n0.5%\n\n\nunited~0.6\n8.19\n8.24\n0.6%\n\n\n\"united states\"\n9.00\n9.13\n1.4%\n\n\nstates\n37.75\n38.72\n2.6%\n\n\nunited~0.75\n11.45\n11.75\n2.6%\n\n\n+nebraska +states\n88.60\n92.81\n4.7%\n\n\nunited states\n11.71\n12.80\n9.3%\n\n\n\"united states\"~3\n4.88\n5.41\n10.7%\n\n\nspanFirst(unit, 5)\n166.83\n198.12\n18.8%\n\n\nspanNear([unit, state], 10, true)\n36.10\n47.48\n31.5%\n\n\n\n\n\nthe patch is really ugly, the whole thing is basically a nocommit, but in general the tests pass (i have at least one long-tail random fail to hunt down), but i think it has some promise.\n\ni mostly only added the capabilities to the old docsEnums and docsAndPositionsEnums, so we dont see all the benefits i think... ideally we can tweak the bulkpostings apis (especially positions) to take advantage of some of this stuff.\n\n ",
            "author": "Robert Muir",
            "id": "comment-12994175"
        },
        {
            "date": "2011-02-14T14:10:34+0000",
            "content": "seems hudson just hit the \"long-tail random fail\" i was talking about, in trunk.\n\nso i don't think its a problem with this codec: https://hudson.apache.org/hudson/job/Lucene-Solr-tests-only-trunk/4884/ ",
            "author": "Robert Muir",
            "id": "comment-12994304"
        },
        {
            "date": "2011-02-14T17:16:56+0000",
            "content": "OK I committed this for now to the branch (r1070580), we can always revert it.\n\nI cutover FOR, PFOR, and PFOR2 to use this, and all tests pass with all these codecs. ",
            "author": "Robert Muir",
            "id": "comment-12994370"
        }
    ]
}