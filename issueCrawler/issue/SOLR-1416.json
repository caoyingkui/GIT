{
    "id": "SOLR-1416",
    "title": "reduce contention in CoreContainer#getCore()",
    "details": {
        "affect_versions": "None",
        "status": "Reopened",
        "fix_versions": [],
        "components": [
            "multicore"
        ],
        "type": "Improvement",
        "priority": "Minor",
        "labels": "",
        "resolution": "Unresolved"
    },
    "description": "every call to CoreContainer#getCore() is synchronized . We should reduce the contention . The writes are very infrequent and reads are frequent . How about using a ReadWriterLock?",
    "attachments": {
        "SOLR-1416.patch": "https://issues.apache.org/jira/secure/attachment/12418831/SOLR-1416.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "David Smiley",
            "id": "comment-12997644",
            "date": "2011-02-22T05:28:14+0000",
            "content": "I don't think ReadWriterLock makes sense when the operation that you're doing is cheap (e.g. simple hashtable lookups). I argue you've actually slowed things down! I think ConcurrentHashMap makes the most sense.\n\nJust curious, did you have trepidation about this making you stop short of committing it? You were a committer when you posted it. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-12997650",
            "date": "2011-02-22T06:26:49+0000",
            "content": "Agreed - without some credible data, this seems like the wrong change. The synch'd operation would appear to be too cheap to benefit from a reader/writer lock.\n\nNot sure if a ConcurrentHashMap could be used though...I think we would lose a slightly higher sync level we need?  "
        },
        {
            "author": "Erick Erickson",
            "id": "comment-13631329",
            "date": "2013-04-14T15:18:19+0000",
            "content": "SPRING_CLEANING_2013 JIRA.\nWe haven't really seen any evidence that this is a problem. As it happens once per search request I'm going to defer. "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-13631334",
            "date": "2013-04-14T15:53:36+0000",
            "content": "Noble and I worked on LotsOfCores for AOL which had more than 20K cores per Solr instance. The top three factors slowing down solr for such use-cases were:\n\n\tOpening IndexSearcher (our use-case had a 10:1 write/read ratio) - solved by opening searcher lazily\n\tLoading/parsing IndexSchema and SolrConfig objects - solved by caching these objects\n\tContention in CoreContainer#getCore - solved by the attached patch\n\n\n\nAt this later date, I don't have the data to support this change but it is worth benchmarking if someone is up for it. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13631359",
            "date": "2013-04-14T17:29:37+0000",
            "content": "I reopened. This remains a good issue. "
        }
    ]
}