{
    "id": "SOLR-5122",
    "title": "spellcheck.collateMaxCollectDocs estimates seem to be meaninless -- can lead to \"ArithmeticException: / by zero\"",
    "details": {
        "affect_versions": "4.4",
        "status": "Closed",
        "fix_versions": [
            "4.5",
            "6.0"
        ],
        "components": [],
        "type": "Bug",
        "priority": "Major",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "As part of SOLR-4952 SpellCheckCollatorTest started using RandomMergePolicy, and this (aparently) led to a failure in testEstimatedHitCounts.\n\nAs far as i can tell: the test assumes that specific values would be returned as the estimated \"hits\" for a colleation, and it appears that the change in MergePolicy however resulted in different segments with different term stats, causing the estimation code to produce different values then what is expected.\n\nI made a quick attempt to improve the test to:\n\n\texpect explicit exact values only when spellcheck.collateMaxCollectDocs is set such that the \"estimate' should actually be exact (ie: collateMaxCollectDocs  == 0 or collateMaxCollectDocs greater then the num docs in the index\n\trandomize the values used for collateMaxCollectDocs and confirm that the estimates are never more then the num docs in the index\n\n\n\nThis lead to an odd \"ArithmeticException: / by zero\" error in the test, which seems to suggest that there is a genuine bug in the code for estimating the hits that only gets tickled in certain mergepolicy/segment/collateMaxCollectDocs combinations.\n\nUpdate: This appears to be a general problem with collecting docs out of order and the estimation of hits \u2013 i believe even if there is no divide by zero error, the estimates are largely meaningless since the docs are collected out of order.",
    "attachments": {
        "SOLR-5122.patch": "https://issues.apache.org/jira/secure/attachment/12596688/SOLR-5122.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Hoss Man",
            "id": "comment-13732584",
            "date": "2013-08-07T19:01:16+0000",
            "content": "Attached patch applied to trunk r1511141 produces the following error...\n\n\n   [junit4]   2> 6500 T10 C1 oasc.SolrCore.execute [collection1] webapp=null path=null params={spellcheck=true&spellcheck.dictionary=direct&spellcheck.count=1&spellcheck.collate=true&spellcheck.maxCollationTries=1&spellcheck.maxCollations=1&spellcheck.collateExtendedResults=true&qt=spellCheckCompRH&q=teststop%3Ametnoia&spellcheck.collateMaxCollectDocs=5} hits=0 status=500 QTime=25 \n   [junit4]   2> 6501 T10 oasc.SolrException.log ERROR REQUEST FAILED: spellcheck=true&spellcheck.dictionary=direct&spellcheck.count=1&spellcheck.collate=true&spellcheck.maxCollationTries=1&spellcheck.maxCollations=1&spellcheck.collateExtendedResults=true&qt=spellCheckCompRH&q=teststop%3Ametnoia&spellcheck.collateMaxCollectDocs=5:java.lang.ArithmeticException: / by zero\n   [junit4]   2> \t\tat org.apache.solr.spelling.SpellCheckCollator.collate(SpellCheckCollator.java:153)\n   [junit4]   2> \t\tat org.apache.solr.handler.component.SpellCheckComponent.addCollationsToResponse(SpellCheckComponent.java:229)\n   [junit4]   2> \t\tat org.apache.solr.handler.component.SpellCheckComponent.process(SpellCheckComponent.java:196)\n   [junit4]   2> \t\tat org.apache.solr.handler.component.SearchHandler.handleRequestBody(SearchHandler.java:208)\n   [junit4]   2> \t\tat org.apache.solr.handler.RequestHandlerBase.handleRequest(RequestHandlerBase.java:135)\n   [junit4]   2> \t\tat org.apache.solr.core.SolrCore.execute(SolrCore.java:1845)\n   [junit4]   2> \t\tat org.apache.solr.util.TestHarness.query(TestHarness.java:292)\n   [junit4]   2> \t\tat org.apache.solr.util.TestHarness.query(TestHarness.java:274)\n   [junit4]   2> \t\tat org.apache.solr.SolrTestCaseJ4.assertQ(SolrTestCaseJ4.java:609)\n   [junit4]   2> \t\tat org.apache.solr.SolrTestCaseJ4.assertQ(SolrTestCaseJ4.java:602)\n   [junit4]   2> \t\tat org.apache.solr.spelling.SpellCheckCollatorTest.testEstimatedHitCounts(SpellCheckCollatorTest.java:475)\n...\n   [junit4]   2> 6501 T10 oas.SolrTestCaseJ4.tearDown ###Ending testEstimatedHitCounts\n   [junit4]   2> NOTE: reproduce with: ant test  -Dtestcase=SpellCheckCollatorTest -Dtests.method=testEstimatedHitCounts -Dtests.seed=16B4D8F74E59EE10 -Dtests.multiplier=2 -Dtests.nightly=true -Dtests.slow=true -Dtests.locale=nl -Dtests.timezone=America/Dawson -Dtests.file.encoding=US-ASCII\n   [junit4] ERROR   0.35s | SpellCheckCollatorTest.testEstimatedHitCounts <<<\n   [junit4]    > Throwable #1: java.lang.RuntimeException: Exception during query\n   [junit4]    > \tat __randomizedtesting.SeedInfo.seed([16B4D8F74E59EE10:270F66C2EB66FEC0]:0)\n   [junit4]    > \tat org.apache.solr.SolrTestCaseJ4.assertQ(SolrTestCaseJ4.java:635)\n   [junit4]    > \tat org.apache.solr.SolrTestCaseJ4.assertQ(SolrTestCaseJ4.java:602)\n   [junit4]    > \tat org.apache.solr.spelling.SpellCheckCollatorTest.testEstimatedHitCounts(SpellCheckCollatorTest.java:475)\n   [junit4]    > \tat java.lang.Thread.run(Thread.java:724)\n   [junit4]    > Caused by: java.lang.ArithmeticException: / by zero\n   [junit4]    > \tat org.apache.solr.spelling.SpellCheckCollator.collate(SpellCheckCollator.java:153)\n   [junit4]    > \tat org.apache.solr.handler.component.SpellCheckComponent.addCollationsToResponse(SpellCheckComponent.java:229)\n   [junit4]    > \tat org.apache.solr.handler.component.SpellCheckComponent.process(SpellCheckComponent.java:196)\n   [junit4]    > \tat org.apache.solr.handler.component.SearchHandler.handleRequestBody(SearchHandler.java:208)\n   [junit4]    > \tat org.apache.solr.handler.RequestHandlerBase.handleRequest(RequestHandlerBase.java:135)\n   [junit4]    > \tat org.apache.solr.core.SolrCore.execute(SolrCore.java:1845)\n   [junit4]    > \tat org.apache.solr.util.TestHarness.query(TestHarness.java:292)\n   [junit4]    > \tat org.apache.solr.util.TestHarness.query(TestHarness.java:274)\n   [junit4]    > \tat org.apache.solr.SolrTestCaseJ4.assertQ(SolrTestCaseJ4.java:609)\n   [junit4]    > \t... 42 more\n\n "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13732654",
            "date": "2013-08-07T19:53:16+0000",
            "content": "The problematic line is when catching the EarlyTerminatingCollectorException exception and computing the estimate based on the last doc id collected...\n\n\nhits = maxDocId / ((etce.getLastDocId() + 1) / docCollectionLimit);\n\n\n\nUnless i'm mising something, the problem comes up when (etce.getLastDocId() + 1) < docCollectionLimit because then the integer division results in 0, which then becomes the demoninator under maxDocId\n\nIt would be trivial to toss another \"1+\" in there to eliminate the divide by zero, but i'm confused about the basic assumption taking place here \u2013 it smells fishy \u2013 making any estimation based on getLastDocId() seems to only be useful if we know docs are being collected in order, and when the collateMaxCollectDocs option was added in r1479638, it did force in order collection when using hte early termination...\n\nhttps://svn.apache.org/viewvc/lucene/dev/trunk/solr/core/src/java/org/apache/solr/spelling/SpellCheckCollator.java?r1=1479638&r2=1479637&pathrev=1479638\n\n...but in r1479645 that use of FORCE_INORDER_COLLECTION was eliminate with the msg \"removing dead code\" ...\n\nhttps://svn.apache.org/viewvc/lucene/dev/trunk/solr/core/src/java/org/apache/solr/spelling/SpellCheckCollator.java?r1=1479645&r2=1479644&pathrev=1479645\n\nBut w/o FORCE_INORDER_COLLECTION I don't see how any estimation based on the lastDocId can ever be meaningful?\n\n\nJames Dyer can you take a look at this? "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13732659",
            "date": "2013-08-07T19:57:49+0000",
            "content": "Reviewing the comments in SOLR-3240 i think i just figured out hte \"remove dead code\" comment...\n\nI'm also thinking I can safely get rid of the \"forceInorderCollection\" flag because requesting docs sorted by doc-id would enforce the same thing, right?\n\n...i don't think this assumption is valid.  I don't think using the docid sort option affects the order that collectors recieve docs, it's just used to register a SortField using SortField.Type.DOC, which isn't used until after the collector collects \"all\" of the docs.\n\nSo i think we need to add back in the FORCE_INORDER_COLLECTION "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13732865",
            "date": "2013-08-07T22:41:06+0000",
            "content": "FYI: I attempted ot do a simple revert of r1479645 and the test still fails \u2013 but reviewing hte diff i think that's because there doesn't seem to be anything paying attention to the FORCE_INORDER_COLLECTION flag at collection time, so it's effectively useless.\n\nI'm at a loss to really understand what the correct fix should be at this point "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-13732951",
            "date": "2013-08-07T23:48:21+0000",
            "content": "Commit 1511539 from hossman@apache.org in branch 'dev/trunk'\n[ https://svn.apache.org/r1511539 ]\n\nSOLR-5122: disble testEstimatedHitCounts until issue with inordered collection can be dealt with "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-13732953",
            "date": "2013-08-07T23:49:43+0000",
            "content": "Commit 1511540 from hossman@apache.org in branch 'dev/branches/branch_4x'\n[ https://svn.apache.org/r1511540 ]\n\nSOLR-5122: disble testEstimatedHitCounts until issue with inordered collection can be dealt with (merge r1511539) "
        },
        {
            "author": "James Dyer",
            "id": "comment-13738311",
            "date": "2013-08-13T14:55:28+0000",
            "content": "Hoss,\n\nI appreciate your reporting this & taking care of this as much as possible.  Do you know offhand a failing seed for this test?  (I've been away for awhile and might not have the jenkins log easily available.)  I will look at this.  Likely, I need to require docs to be collected in order and mistakenly thought this was unnecessary. "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13738395",
            "date": "2013-08-13T15:51:50+0000",
            "content": "The initial jenkins failure i saw was \"At revision 1511278\"...\n\nhttps://builds.apache.org/job/Lucene-Solr-NightlyTests-trunk/343/\nhttps://mail-archives.apache.org/mod_mbox/lucene-dev/201308.mbox/%3Calpine.DEB.2.02.1308070919170.13959@frisbee%3E\n\n\nI can reproduce this \u2013 it's probably related to the MP randomization i \nput in ... looks like it's doing exact numeric comparisons based on term \nstats.  I'll take a look later today...\n\nant test  -Dtestcase=SpellCheckCollatorTest -Dtests.method=testEstimatedHitCounts -Dtests.seed=16B4D8F74E59EE10 -Dtests.multiplier=2 -Dtests.nightly=true -Dtests.slow=true   -Dtests.locale=nl -Dtests.timezone=America/Dawson -Dtests.file.encoding=US-ASCII\n\n...regardless of he initial failure though, if you try out the patch i attached to try and improve the test coverage, then the \"reproduce\" line from the failure i posted along iwth that patch still reproduces on trunk (but you do have to manually uncomment the @Ignore...\n\n\nant test  -Dtestcase=SpellCheckCollatorTest -Dtests.method=testEstimatedHitCounts -Dtests.seed=16B4D8F74E59EE10 -Dtests.multiplier=2 -Dtests.nightly=true -Dtests.slow=true -Dtests.locale=nl -Dtests.timezone=America/Dawson -Dtests.file.encoding=US-ASCII\n\n "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13738397",
            "date": "2013-08-13T15:52:45+0000",
            "content": "updated patch to trunk and included the commenting out of the @Ignore so all ou need to do is apply this patch to reproduce with the previously mentioned seed. "
        },
        {
            "author": "James Dyer",
            "id": "comment-13738708",
            "date": "2013-08-13T19:28:36+0000",
            "content": "The scenarios tested in testEstimatedHitCounts() seem to always pick a collector that does not accept docs out-of-order (\"TopFieldCollector$OneComparatorNonScoringCollector\").  The problem looks like when a new segment/scorer is set, we get a new set of doc id's.  So prior to random merges, the test naively assummed everything was on 1 segment.  Now with multiple, all bets are off and I don't think we can be estimating hits.\n\nI think the best fix is to dial back the functionality here and not offer hit estimates at all.  The functionality still would be beneficial in cases the user did not require hit-counts to be returned at all (for instance, ~rmuir mentioned using this feature with suggesters).  \n\nAnother option is to add together the doc ids for the various scorers that are looked at and pretend this is your max doc id.  I'm torn here because I'd hate to remove functionality that has been released but on the other hand if it is always going to give lousy estimates then why fool people?\n\nThoughts? "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13739893",
            "date": "2013-08-14T17:14:15+0000",
            "content": "So prior to random merges, the test naively assummed everything was on 1 segment. Now with multiple, all bets are off and I don't think we can be estimating hits.\n\nI'm not following you here \u2013 why don't you think the basic approach to estimation can still work?\n\nthe only missing pieces seem to be that when an estimation is requested:\n\n\tdocs must be collected in order \u2013 a property that forces this behavior from EarlyTerminatingCollector.acceptsDocsOutOfOrder regardless of what the delegate cares about should do the trick.\n\tlastDocId needs to be absolute, not per-segment \u2013 which could be done by tracking the reader offsets in EarlyTerminatingCollector.setNextReader and using that offset when assigning lastDocId in EarlyTerminatingCollector.collect\n\n\n\n...and that should make it work as you previously designed it ... right? "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13740492",
            "date": "2013-08-15T00:35:28+0000",
            "content": "here's a patch that improves EarlyTerminatingCollector to keep track of the size of each reader it collects against so that it can derive some meaning from the docIds it collects.  As part of this patch i eliminated the use of the \"lastDocId\" to try and discourage people from trying to find specific \u2013 instead the EarlyTerminatingCollectorException now just reports the number of docs \"collected\" out of the total number of docs \"scanned\" ... the result is that the collector doesn't really care which order it gets the AtomicReaderContexts in, however it still has to force documents to be collected in order, so that they will be in-order within a single reader so that the stats for that reader can be meaningful.\n\npatch includes the previous tests, plus a new test loop that we get a reasonably accurate estimate from a term that is in every other doc in the index.\n\nJames Dyer - does this look right to you? does it address your concerns about keeping hte estimation code in place? "
        },
        {
            "author": "James Dyer",
            "id": "comment-13740999",
            "date": "2013-08-15T14:32:02+0000",
            "content": "Hoss,\n\nThis looks reasonable to me.  The test is more forgiving to variations caused by random merges, no more integer division, etc.  I appreciate your working on this as I wouldn't have much more time until next week.  I think your method of estimating the hits would be at least as good of what I attempted to do before. "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-13741262",
            "date": "2013-08-15T17:50:32+0000",
            "content": "Commit 1514402 from hossman@apache.org in branch 'dev/trunk'\n[ https://svn.apache.org/r1514402 ]\n\nSOLR-5122: Fixed bug in spellcheck.collateMaxCollectDocs.  Eliminates risk of divide by zero, and makes estimated hit counts meaningful in non-optimized indexes. "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-13741270",
            "date": "2013-08-15T17:53:53+0000",
            "content": "Commit 1514408 from hossman@apache.org in branch 'dev/branches/branch_4x'\n[ https://svn.apache.org/r1514408 ]\n\nSOLR-5122: Fixed bug in spellcheck.collateMaxCollectDocs.  Eliminates risk of divide by zero, and makes estimated hit counts meaningful in non-optimized indexes. (merge r1514402) "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13741273",
            "date": "2013-08-15T17:55:08+0000",
            "content": "Committed revision 1514402.\nCommitted revision 1514408. "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-13741477",
            "date": "2013-08-15T21:07:17+0000",
            "content": "Commit 1514494 from hossman@apache.org in branch 'dev/trunk'\n[ https://svn.apache.org/r1514494 ]\n\nSOLR-5122: fix javadocs "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-13741506",
            "date": "2013-08-15T21:27:23+0000",
            "content": "Commit 1514504 from hossman@apache.org in branch 'dev/branches/branch_4x'\n[ https://svn.apache.org/r1514504 ]\n\nSOLR-5122: fix javadocs (merge r1514494) "
        },
        {
            "author": "Adrien Grand",
            "id": "comment-13787131",
            "date": "2013-10-05T10:19:23+0000",
            "content": "4.5 release -> bulk close "
        }
    ]
}