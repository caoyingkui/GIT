{
    "id": "SOLR-14",
    "title": "Add the ability to preserve the original term when using WordDelimiterFilter",
    "details": {
        "affect_versions": "None",
        "status": "Closed",
        "fix_versions": [
            "1.3"
        ],
        "components": [
            "search"
        ],
        "type": "Improvement",
        "priority": "Major",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "When doing prefix searching, you need to hang on to the original term othewise you'll miss many matches you should be making.\n\nData: ABC-12345\nWordDelimiterFitler may change this into\nABC 12345 ABC12345\n\nA user may enter a search such as \n ABC-123*\nWhich will fail to find a match given the above scenario.\n\nThe attached patch will allow the use of the \"preserveOriginal\" option to WordDelimiterFilter and will analyse as\nABC 12345 ABC12345  ABC-12345 \nin which case we will get a postive match.",
    "attachments": {
        "SOLR-14.patch": "https://issues.apache.org/jira/secure/attachment/12384146/SOLR-14.patch",
        "TokenizerFactory.java": "https://issues.apache.org/jira/secure/attachment/12326118/TokenizerFactory.java",
        "WordDelimiterFilter.patch": "https://issues.apache.org/jira/secure/attachment/12326117/WordDelimiterFilter.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Yonik Seeley",
            "id": "comment-12377415",
            "date": "2006-05-02T22:35:28+0000",
            "content": "Thanks for the patch Trey!\n\nCan you give an example with the resulting token positions (or positionIncrements?)\n\nAlso, is there an easy way to prevent duplicate tokens from being produced (the preserveOriginal version will often be identical to catenateWords or catenateNumbers, right?) "
        },
        {
            "author": "Richard \"Trey\" Hyde",
            "id": "comment-12377426",
            "date": "2006-05-02T23:43:00+0000",
            "content": "IMO, it does the wrong thing with position.  I think it should have the position of the original term, I'll see if I can't figure out how to do that.  It also doesn't work properly in the \"single token\" optimized case, another easy fix.  As far as preventing duplicate tokens, an iteration though the token queue with equals should do the trick, no? "
        },
        {
            "author": "Hoss Man",
            "id": "comment-12377440",
            "date": "2006-05-03T00:54:56+0000",
            "content": "It would probably be good to make sure we have some UnitTests of the existing WDF behavior prior to applying this patch, and then some tests that use this new feature just so it's clera how it works in various situations.\n\nAs for duplicates: my initial thought was that this could be handled by the proposed Filter in SOLR-11... but then i realized yonik has a point: the common case is probably going to be no intra-word delimiters, so a short circut check that doesn't crete two of every token would probably be better "
        },
        {
            "author": "Richard \"Trey\" Hyde",
            "id": "comment-12377851",
            "date": "2006-05-05T00:42:24+0000",
            "content": "Ok, this one actually works in a few more cases.    \n\nThere is still term duping if numotk > 1 and there are no intraword delimiters in the original string.\n "
        },
        {
            "author": "Geoffrey Young",
            "id": "comment-12605063",
            "date": "2008-06-14T11:55:50+0000",
            "content": "this is fairly important for our ongoing implementation - can someone with appropriate karma take steps to get this into 1.3?\n\nthanks "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12605080",
            "date": "2008-06-14T15:28:00+0000",
            "content": "Someone would need to make an up-to-date patch that works (pref w/ some tests). "
        },
        {
            "author": "Mike Klaas",
            "id": "comment-12605403",
            "date": "2008-06-16T20:29:51+0000",
            "content": "Note that it is very easy to use an external TokenFilter, so you could just c&p WDF into your own class and make the changes.\n\n(Though I'm not saying that this shouldn't make it in for 1.3) "
        },
        {
            "author": "Mike Klaas",
            "id": "comment-12605410",
            "date": "2008-06-16T21:03:42+0000",
            "content": "Also, voting for an issue is a good way to increase its visibility "
        },
        {
            "author": "Geoffrey Young",
            "id": "comment-12605678",
            "date": "2008-06-17T17:50:50+0000",
            "content": "ok, I've given this a shot.  I'm an an open-source guy, even an ASF guy, but not a java guy, so forgive my code \n\nthe patch should apply cleanly to current trunk.  the last patch before mine still had some issues that needed to be worked through wrt term duplication.  this patch should work a bit better.\n\nall current tests pass when adjusted to 'preserveOriginal=0' (default behavior, same as 1.2).  I looked at augmenting the current tests for WDF and 'preserveOriginal=1' but it's beyond my current java abilities.\n\ninstalling the patch and running the analyzer yields stuff like this:\n\n  foo => foo\n  foo-bar => foo-bar foo bar foobar\n  foo-bar baz => foo-bar foo bar foobar baz\n  foo! => foo foo!\n\nwhich seems reasonable to me.\n\na little shepherding would be awesome.\n\nthanks\n\n--Geoff "
        },
        {
            "author": "Ankur Madnani",
            "id": "comment-12608159",
            "date": "2008-06-25T19:19:26+0000",
            "content": "The junit test for preserveOriginal=1 is added to this patch. \nThis patch contains the new schema.xml for test and changed TestWordDelimiterFilter.\n\nThe patch given earlier by Geoff. changes the signature of the public constructors in the WordDelimiterFilter by adding preserveOriginal as parameter.\nMay be we should create separate constructor which accepts preserveOriginal, to \npreserve Backwards Compatibility.\n\n\n\n "
        },
        {
            "author": "Geoffrey Young",
            "id": "comment-12609241",
            "date": "2008-06-30T14:36:17+0000",
            "content": "this new patch addresses three additional cases\n\n  o words prefixed with delimiters\n  o words postfixed with delimiters\n  o words that are all delimiters\n\nthere's a special place for people who name themselves  !!! and expect to be found.\n\nthe input string\n\n\n  test 404-123 $foo bar& beer !!! *foo baz's biff\n\n\n\nproduces\n\n\ntest 404-123 404 123 404123 foo $foo bar bar& beer !!! foo *foo baz baz's biff\n\n\n\nusing options\n\n\norg.apache.solr.analysis.WordDelimiterFilterFactory {preserveOriginal=1, generateNumberParts=1, catenateWords=1, generateWordParts=1, catenateAll=1, catenateNumbers=1}\n\n\n "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12610000",
            "date": "2008-07-02T18:31:47+0000",
            "content": "Attaching new version of patch.\n\nThe previous version had position issues, and also had issues with certain flag combos.\nI changed the strategy by handling \"preserveOriginal\" outside of the main loop (anywhere there is a \"break\" that falls through) and then just returning the original token first and adjusting the offset of the next token to overlap.\n\nThis should also be faster as it avoids token copying in the common case. "
        },
        {
            "author": "Geoffrey Young",
            "id": "comment-12610229",
            "date": "2008-07-03T13:36:31+0000",
            "content": "looks good from a functional pov.  the ordering of the tokens looks funny (to me) in analysis.jsp, but all the right ones are there.\n\nit still takes my full load roughly twice as long to index (3.5 minutes versus 1.75 minutes for a 120MB file) but the functionality is important enough to incur the cost.\n\nthanks muchly. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12610232",
            "date": "2008-07-03T14:04:23+0000",
            "content": "the ordering of the tokens looks funny (to me) in analysis.jsp\n\nCurrently xxx-yyy is expanded to xxx yyy/xxxyyy  (xxx is in the first position,  yyy and xxxyyy are in the second position).\nIf we also want to index the original xxx-yyy, it's a bit arbitrary if it goes in the same position as the xxx or the yyy.\nIn this case I put it with xxx since the original token can then just be returned first (and retain everything about the original token such as it's payload, w/o having to clone it).\n "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12610262",
            "date": "2008-07-03T15:46:18+0000",
            "content": "I committed after adding a performance test to verify that performance doesn't noticeably degrade for preserveOriginal=false.\nThanks everyone!  "
        }
    ]
}