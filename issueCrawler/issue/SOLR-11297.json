{
    "id": "SOLR-11297",
    "title": "Message \"Lock held by this virtual machine\" during startup.  Solr is trying to start some cores twice",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [],
        "type": "Bug",
        "fix_versions": [
            "6.6.2",
            "7.0.1",
            "7.1"
        ],
        "affect_versions": "6.6",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "Sometimes when Solr is restarted, I get some \"lock held by this virtual machine\" messages in the log, and the admin UI has messages about a failure to open a new searcher.  It doesn't happen on all cores, and the list of cores that have the problem changes on subsequent restarts.  The cores that exhibit the problems are working just fine \u2013 the first core load is successful, the failure to open a new searcher is on a second core load attempt, which fails.\n\nNone of the cores in the system are sharing an instanceDir or dataDir.  This has been verified several times.\n\nThe index is sharded manually, and the servers are not running in cloud mode.\n\nOne critical detail to this issue: The cores are all perfectly functional.  If somebody is seeing an error message that results in a core not working at all, then it is likely a different issue.",
    "attachments": {
        "SOLR-11297.sh": "https://issues.apache.org/jira/secure/attachment/12887946/SOLR-11297.sh",
        "SOLR-11297.patch": "https://issues.apache.org/jira/secure/attachment/12887945/SOLR-11297.patch",
        "solr6_6-startup.log": "https://issues.apache.org/jira/secure/attachment/12884353/solr6_6-startup.log"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2017-08-29T22:29:45+0000",
            "content": "Attaching a solr logfile showing the most recent startup.  The \"s1live\" and \"spark5live\" cores have logged the problem message. ",
            "author": "Shawn Heisey",
            "id": "comment-16146255"
        },
        {
            "date": "2017-08-29T23:45:29+0000",
            "content": "I have some anecdotal evidence that specifying\n<writeLockTimeout>5000</writeLockTimeout>\nin solrconfig.xml (the time is an estimate) will make this problem go away. That's not a proper fix, but if anyone interested in this JIRA could test it and report it'd help track this down.\n ",
            "author": "Erick Erickson",
            "id": "comment-16146353"
        },
        {
            "date": "2017-08-30T16:15:10+0000",
            "content": "With the writeLockTimeout setting inside indexConfig, problem still happened.  Just in case that was the wrong place, I also added it to the top level of solrconfig.xml, still no change. ",
            "author": "Shawn Heisey",
            "id": "comment-16147529"
        },
        {
            "date": "2017-08-30T16:28:55+0000",
            "content": "I found LUCENE-6525, and so far I haven't found any evidence to indicate that the writeLockTimeout value actually gets used for anything (currently have branch_7_0 checked out). ",
            "author": "Shawn Heisey",
            "id": "comment-16147549"
        },
        {
            "date": "2017-08-30T17:14:03+0000",
            "content": "Hmmmm, on a quick look I don't see it either. I was looking at this in 6x. I'll look further. There's a hint in the test where there's something about: getters.add(\"getWriteLockTimeout\");\n\nAnyone have a clue?\n\nErick ",
            "author": "Erick Erickson",
            "id": "comment-16147624"
        },
        {
            "date": "2017-09-01T19:23:33+0000",
            "content": "I poked around a little more and https://issues.apache.org/jira/browse/LUCENE-6525 started the deprecation process for writeLockTimeout.  Most of the references to it were removed in 7x and even 6x doesn't use it for all it can be set. In master there's still a single reference in a test... I've pinged the dev list about whether we should remove them all.\n\nBut the net-net is that changing that in any 7x version and even 6x doesn't use it (didn't check early 6 versions, just current 6x). I was looking at 5x code when I saw it had an effect.\n\nSo it's no surprise that it didn't have any effect for you Shawn Heisey.\n\nAnyway, that was just to see if you were seeing something I was looking at in 5x to see how pervasive this was as I was starting to dig as to why it is happening. The JIRA talks about using SleepingLockWrapper, but that's not exposed in Solr at this point and I don't see any point in exposing it for this problem since it's a band-aid not a proper fix.\n\nSorry for the misdirection\n\nErick ",
            "author": "Erick Erickson",
            "id": "comment-16151045"
        },
        {
            "date": "2017-09-01T20:45:35+0000",
            "content": "Repeating something I said on the mailing list, and expanding on it:\n\nI have never seen messages for this problem on my \"build\" cores or my \"broker\" cores, only on \"live\" cores.  The build cores are used for full index rebuilds and then swapped with live cores.  They do not receive any requests unless a (rare) full index rebuild is underway.  Because full index rebuilds involve DIH, the build cores are almost never getting requests (other than DIH status requests) after a Solr restart. The broker cores have the shards parameter in the request handler \"defaults\" section, so clients do not need to know that they are accessing a distributed index.\n\nI think there may be a race condition.  Best idea is that it starts when the core opens its searcher (or possibly slightly offset from that moment), and ends when the core is fully functional.  If requests are received for the index during that timeframe, it appears to cause Solr to try to create the core again.  The second creation fails because the first is already underway and has opened a searcher.  In my case, it only seems to affect shard requests, but this might simply be a result of the fact that requests to the broker cores don't involve the local index in that core (which is empty), only indexes on the shard cores.\n\nI typically see \"Lock held\" messages in the log for more cores than are shown in the admin UI as having failed to start, and sometimes the message appears MANY times for one core.  I think there is an example of that in the log that I attached to the issue. ",
            "author": "Shawn Heisey",
            "id": "comment-16151118"
        },
        {
            "date": "2017-09-01T20:48:51+0000",
            "content": "If you would like me to build a special 6.6 version with extra logging to try and pinpoint the problem, give me a patch and I can do that.  The system with the problem is my dev server, I can fiddle with it. ",
            "author": "Shawn Heisey",
            "id": "comment-16151125"
        },
        {
            "date": "2017-09-17T16:43:06+0000",
            "content": "I think my issue ( https://issues.apache.org/jira/browse/SOLR-11361 ) is basically a duplicate of this reported issue.  In my testing I can shut my Solr/Core down (I only have one) and then bring it up on a new port number and there are no locking errors.  If I close Solr/Core again and go to the original port number the lock error is back.  Lastly, I think if I just close Solr/Core and wait a fair amount of time, the lock error goes away.\n\nI updated from 6.2.1 to 6.6.1 last night (and long ago on 4.10 before that).  I then moved down to 6.6.0 and while I get the lock error, the core is operational (6.6.1 is will not even show in the drop down for cores once the lock error kicks in). ",
            "author": "Richard Rominger",
            "id": "comment-16169349"
        },
        {
            "date": "2017-09-18T17:03:14+0000",
            "content": "Shawn Heisey Erick Erickson\nI am curious about how frequently this behavior is reproducible. Is rest of the world running 6.6.1 totally fine and only 4 of us seeing this issue?\nI see LUCENE-7959 was fixed to give a better error, however in my case the file is actually getting created so I am not hitting the permission issue. One way to debug will be to downgrade to an earlier version and try to reproduce the error. Can someone suggest which version should I start with?  ",
            "author": "Nawab Zada Asad iqbal",
            "id": "comment-16170301"
        },
        {
            "date": "2017-09-18T17:23:03+0000",
            "content": "I can say for my test bed using 6.6.0 / 6.6.1 it's pretty reproducible.  I am running Windows 10 1703 for my testing.  I go back to 6.2.1 and it stable as a rock.\n\nWhen the problem kicks in, all I have to do is shutdown Solr and restart it on a different port and it loads up fine.  Then I shutdown for a bit of time and I can then restart on the port that I really want Solr running on. ",
            "author": "Richard Rominger",
            "id": "comment-16170333"
        },
        {
            "date": "2017-09-18T17:26:54+0000",
            "content": "Nawab Zada Asad iqbal, Every time I restart 6.6.0, I see the problem described in this issue.\n\nVersion 6.6.1 may have a separate issue in addition to this issue, described in SOLR-11361.  I saw a similar message in the logs with 6.6.2-SNAPSHOT, and in that version, some of my cores that do not work at all.  For the problem I have described here, every core actually works, I just get annoying notifications in the admin UI and errors in the log. ",
            "author": "Shawn Heisey",
            "id": "comment-16170355"
        },
        {
            "date": "2017-09-18T18:01:18+0000",
            "content": "Erick Erickson, the release notes for 6.6.1 indicate a bunch of changes in that version on the creation, loading, and reloading of cores.  Those changes look like yours.  With all the current and past work you've done on core loading, I think you're in the best position to understand the code.\n\nThe problem I have reported on this issue isn't a \"real\" problem, because it doesn't affect usability at all, just logging ... but 6.6.1 seems to have a separate (and very real) problem. ",
            "author": "Shawn Heisey",
            "id": "comment-16170402"
        },
        {
            "date": "2017-09-18T18:10:37+0000",
            "content": "Minor correction to that last statement: 6.6.1 seems to have a \"real\" problem, which may or may not be related to this problem. ",
            "author": "Shawn Heisey",
            "id": "comment-16170411"
        },
        {
            "date": "2017-09-18T18:18:08+0000",
            "content": "agreed.  6.6.0 seems to load my core okay - even though WebGUI has [Red] Fault errors for me.  Which that is enough for me not to use 6.6.0 as a Production candidate. ",
            "author": "Richard Rominger",
            "id": "comment-16170429"
        },
        {
            "date": "2017-09-18T20:20:56+0000",
            "content": "Possibly related, we need to check when we address this. ",
            "author": "Erick Erickson",
            "id": "comment-16170618"
        },
        {
            "date": "2017-09-19T18:37:22+0000",
            "content": "I've been working on this issue for a few days now. The problem occurs when you start making requests (e.g. ping) before the cores are completely loaded. In this scenario two threads try to load the same core at the same time, one executing `CoreContainer#load` as part of Solr init process and another executing `CoreContainer#getCore` to respond the HTTP request.\n\nThe `getCore` method uses the `waitAddPendingCoreOps` method to wait pending core operations before trying to create the core if it isn't loaded. That's OK. But the `load` method doesn't put an entry in pending core ops before it tries to create the core.\n\nThe solution is to surround the call to the method `createFromDescriptor` with `waitAddPendingCoreOps` and `removeFromPendingOps`.\n\nI've attached a shell script showing how to reproduce this issue and a draft patch adding the missing methods calls. I tried to write an unit test but I couldn't figure out how to handle the execution of two or more threads to make sure the test is deterministic. ",
            "author": "Luiz Armesto",
            "id": "comment-16172145"
        },
        {
            "date": "2017-09-19T18:43:09+0000",
            "content": "So it's possible my SOLR-11361 is a real issue?  That Jan fellow made me feel a little dumb, though to be honest I likely did not write up my issue properly (as it was my 1st one here on this site). ",
            "author": "Richard Rominger",
            "id": "comment-16172156"
        },
        {
            "date": "2017-09-19T19:45:28+0000",
            "content": "Luiz Armesto, I don't see the code that you've patched in CoreContainer.java in the 6.6.0 release tag checkout.  I can't figure out in that branch where to apply your changes.\n\nRichard Rominger, if any of your cores will not function once Solr has finished its startup work, but did work before the restart, then I do not think the problem is this issue.  On my server where I have this problem, every single core works, even though the admin UI and the log claim that some of the cores didn't initialize correctly. ",
            "author": "Shawn Heisey",
            "id": "comment-16172236"
        },
        {
            "date": "2017-09-19T19:50:28+0000",
            "content": "By switching to master briefly, finding the code, and then switching back to the 6.6.0 tag, I was able to figure out where to put the extra lines.  Now I need to build and install it, see if it solves the issue. ",
            "author": "Shawn Heisey",
            "id": "comment-16172243"
        },
        {
            "date": "2017-09-19T20:06:56+0000",
            "content": "With the patch in place on the 6.6.0 code, the errors in the admin UI appear while startup is finishing, but then eventually disappear.  The logfile still contains many instances of the error message. ",
            "author": "Shawn Heisey",
            "id": "comment-16172265"
        },
        {
            "date": "2017-09-19T20:31:20+0000",
            "content": "Luiz:\n\nNice sleuthing! This looks quite promising, I can see where this would be a problem. I looked through the code and I think I see some other places this could happen, so I'm going to put up some changes.\n\nI want particularly to look at other createCoreFromDescriptor calls and see if we can move the locking via waitAddPendingCoreOps could be moved there, although on a quick glance I'm not sure.\n\nMore soon.\n ",
            "author": "Erick Erickson",
            "id": "comment-16172292"
        },
        {
            "date": "2017-09-19T20:34:56+0000",
            "content": "Erick Erickson\n\nLuiz Armesto's repro is very similar to mine. I had run solr6.6.1 in a standalone environment without any issue. I stumbled on this issue while trying to start cores on a server which was constantly being pinged by haproxy, even before it had loaded the (empty) cores. ",
            "author": "Nawab Zada Asad iqbal",
            "id": "comment-16172298"
        },
        {
            "date": "2017-09-19T20:42:04+0000",
            "content": "My dev server is also pinged frequently by haproxy.  I also have a status servlet that provides a bunch of information from my Solr installs, including the dev server.  If that servlet is open in a browser, it will refresh once a minute. ",
            "author": "Shawn Heisey",
            "id": "comment-16172310"
        },
        {
            "date": "2017-09-20T11:06:15+0000",
            "content": "Richard Rominger, it was certainly not intentional to make you feel dumb  we tend to close issues that look like a user question rather than a new bug, and the bar should always be low to re-open. In this case I may have jumped the trigger prematurely, but it is always a good idea to run your problem with the user-list to determine if others also believe it to be a new issue. In this case we can hope that this one will solve your case too...\n\nIf you later re-open SOLR-11361 then please shorten down the issue description to just a few paragraphs. Long stack traces are best shared by enclosing in noformat tags or sharing via a Gist url. Feel free to ask any question on the users list! ",
            "author": "Jan H\u00f8ydahl",
            "id": "comment-16173022"
        },
        {
            "date": "2017-09-20T17:42:19+0000",
            "content": "OK, I poked at this yesterday and my bright idea of moving things to createCoreFromDescriptor doesn't work. getCore is the problem, it depends on getting the core back from waitAddPendingCoreOps if some other thread is opening the core. If we put some kind of test in getCore instead (say isCoreInPending() or something), then later in that method called createCoreFromDescriptor (assuming the core wasn't in pending ops), it'd be possible that another process would open the core between the calls.\n\nThere are three places in CoreContainer that call createCoreFromDescriptor without being surrounded by a waitAddPendingCoreOps/removeFromPendingOps, I'm working up a patch for the other two.\n\nWe'll see if it fixes Shawn's problem too, vetting it a bit more now and will put up a patch later today if all goes well. ",
            "author": "Erick Erickson",
            "id": "comment-16173562"
        },
        {
            "date": "2017-09-21T15:02:25+0000",
            "content": "This passes the shell script test (Thanks Luiz!) All tests pass.\n\nThis surrounds all the instances of createFromDescriptor with a call to waitAddPendingCoreOps/removeFromPendingOps. I think there were several more potential problems, create, load and reload all were unprotected.\n\nAlso added a fairly detailed comment on why moving this to createFromDescriptor won't work.\n\nShawn: \nCan you give this a spin? If you still see the errors let me know, plus a little more detail about your setup. Or is it just you have a bunch of cores and are pinging when starting Solr? ",
            "author": "Erick Erickson",
            "id": "comment-16174896"
        },
        {
            "date": "2017-09-21T15:06:35+0000",
            "content": "P.S. I spent probably more time than I should have trying to make an automated test for this too, but failed miserably. It seems like a pair of threads that queried/pinged/reloaded should have tripped this but somehow it didn't work for me. ",
            "author": "Erick Erickson",
            "id": "comment-16174900"
        },
        {
            "date": "2017-09-21T17:05:27+0000",
            "content": "FWIW, on my cluster with constant haproxy pings, i was hitting this issue 9/10 times. And the core was not even usable. So my issue was slightly different from Shawn, but I hope that your fix will cover for all the issues. Looking forward for the fix.  ",
            "author": "Nawab Zada Asad iqbal",
            "id": "comment-16175113"
        },
        {
            "date": "2017-09-21T21:45:28+0000",
            "content": "Well, the patch should apply pretty cleanly to the 6.6 branch, although I admit I created it against Master. Is there any way you can apply it and give it a try?\n ",
            "author": "Erick Erickson",
            "id": "comment-16175513"
        },
        {
            "date": "2017-09-22T17:00:43+0000",
            "content": "Erick Erickson i would have loved to test it, but my test cluster which naturally hit this issue has been reclaimed and i will not have access to another for another week. I am looking forward to solr 7.0; as we haven't rolled solr 6 to production yet. \nLocally, I can mock the repeated pings by Luiz's script but if you have already tested with it, then that is not much useful.  ",
            "author": "Nawab Zada Asad iqbal",
            "id": "comment-16176719"
        },
        {
            "date": "2017-09-22T18:11:13+0000",
            "content": "so, all this stuff about patching is this in a Solr 6.1.x download? ",
            "author": "Richard Rominger",
            "id": "comment-16176841"
        },
        {
            "date": "2017-09-25T17:58:22+0000",
            "content": "With the latest patch applied to branch_6_6 and installing from solr-6.6.2-SNAPSHOT.tgz, everything works as expected.  There are no errors in the admin UI, and the \"Lock held by this virtual machine\" message is not in the log.  The only errors I see in the log are those generated by accessing cores while they are loading.\n\n\n<title>Error 503 {metadata={error-class=org.apache.solr.common.SolrException,root-error-class=org.apache.solr.common.SolrException},msg=SolrCore is loading,code=503}</title>\n\n ",
            "author": "Shawn Heisey",
            "id": "comment-16179443"
        },
        {
            "date": "2017-09-25T18:08:25+0000",
            "content": "so, all this stuff about patching is this in a Solr 6.1.x download?\n\nIt's just a patch attached to a Jira issue right now.   To be seen in a downloaded version, a change must be committed to one or more code branches, and then somebody must volunteer to be the release manager for a new version built from a branch with the fix.\n\nAt this time, I think the earliest release that might get this issue resolved will be 7.1.0.  The problems seen in SOLR-11361 (which I think Erick's patch also fixes) might be severe enough to justify a 6.6.2 release, but that's not something I would count on.\n\nSide note: Just like a user on IRC, I was having a problem accessing /solr/admin/metrics with 6.6.0 and a 6.6.2-SNAPSHOT version that I had built previously, but that problem seems to be fixed now.  I do not know if Erick's patch is what made that work, or if it was another change made to the 6.6 branch. ",
            "author": "Shawn Heisey",
            "id": "comment-16179465"
        },
        {
            "date": "2017-09-25T19:13:59+0000",
            "content": "Final patch, just the last patch I uploaded with CHANGES.txt ",
            "author": "Erick Erickson",
            "id": "comment-16179603"
        },
        {
            "date": "2017-09-25T19:14:22+0000",
            "content": "Commit 6391a75a50ecc05db0d7a5ed9adc9fe187a4f57e in lucene-solr's branch refs/heads/master from Erick Erickson\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=6391a75 ]\n\nSOLR-11297: Message 'Lock held by this virtual machine' during startup.  Solr is trying to start some cores twice ",
            "author": "ASF subversion and git services",
            "id": "comment-16179604"
        },
        {
            "date": "2017-09-25T19:25:01+0000",
            "content": "Commit 2e0529532896c966ad11b55575de119fd8f2be3b in lucene-solr's branch refs/heads/branch_7x from Erick Erickson\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=2e05295 ]\n\nSOLR-11297: Message 'Lock held by this virtual machine' during startup.  Solr is trying to start some cores twice\n\n(cherry picked from commit 6391a75) ",
            "author": "ASF subversion and git services",
            "id": "comment-16179623"
        },
        {
            "date": "2017-09-25T20:05:09+0000",
            "content": "Many thanks Luiz and Shawn!\n\nRichard:\nThis will never be back-ported to 6.1, did you mean 6.6.1? And its not there either. If there's ever  a 6.6.2 (and there are no plans for one) then we could backport it.\n\nI did try applying the patch to 6.6.1 and compiling and running Luiz's test and it works like a champ so that's an option. ",
            "author": "Erick Erickson",
            "id": "comment-16179689"
        },
        {
            "date": "2017-09-25T20:20:07+0000",
            "content": "I meant in 6.6.1 (which would spawn 6.6.2?) - which was the next version I wanted to test and where I ran into problems.  ",
            "author": "Richard Rominger",
            "id": "comment-16179704"
        },
        {
            "date": "2017-09-25T21:42:51+0000",
            "content": "It seems that this error is difficult to reproduce. I tried Luiz's script on my Mac laptop and wasn't able to reproduce this issue even after decreasing the 'sleep' between iteration to `0.005`. I tried it on a production like machine (which is similar to what I had done last month although using an haproxy instead of a command line script) and I was able to hit the above error however my cores were still loaded by the 'Core' thread and were functional. Last month when initially I hit this issue, my server was giving the above 'Lock held by this virtual machine' error and also they were *not* usable. Unfortunately, I don't have access to those specific machines anymore. \n ",
            "author": "Nawab Zada Asad iqbal",
            "id": "comment-16179831"
        },
        {
            "date": "2017-09-28T18:05:26+0000",
            "content": "Commit 614b807fc29685696ecfd09f92f312fd92a01c54 in lucene-solr's branch refs/heads/branch_7_0 from Erick Erickson\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=614b807 ]\n\nSOLR-11297: Message 'Lock held by this virtual machine' during startup.  Solr is trying to start some cores twice\n\n(cherry picked from commit 6391a75a50ecc05db0d7a5ed9adc9fe187a4f57e) ",
            "author": "ASF subversion and git services",
            "id": "comment-16184570"
        },
        {
            "date": "2017-10-06T21:56:45+0000",
            "content": "Closing after 7.0.1 release. ",
            "author": "Steve Rowe",
            "id": "comment-16195298"
        },
        {
            "date": "2017-10-14T00:55:24+0000",
            "content": "Commit d8e587e227a414d2c991f6fd740073112b9a1cf5 in lucene-solr's branch refs/heads/branch_6x from Erick\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=d8e587e ]\n\nSOLR-11297: Message 'Lock held by this virtual machine' during startup. Solr is trying to start some cores twice ",
            "author": "ASF subversion and git services",
            "id": "comment-16204397"
        },
        {
            "date": "2017-10-14T15:20:41+0000",
            "content": "Commit 51e0959eaea9dd07ffd0cf6919d99c6b8eca7fa4 in lucene-solr's branch refs/heads/branch_6_6 from Erick Erickson\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=51e0959 ]\n\nSOLR-11297: Message 'Lock held by this virtual machine' during startup.  Solr is trying to start some cores twice ",
            "author": "ASF subversion and git services",
            "id": "comment-16204663"
        }
    ]
}