{
    "id": "SOLR-3544",
    "title": "Under heavy load json response is cut at some arbitrary position",
    "details": {
        "affect_versions": "3.1",
        "status": "Closed",
        "fix_versions": [],
        "components": [
            "search"
        ],
        "type": "Bug",
        "priority": "Major",
        "labels": "",
        "resolution": "Not A Bug"
    },
    "description": "We query solr for 30K documents using json as the response format. Normally this works perfectly fine. But when the machine comes under heavy load (all cores utilized) the response got interrupted at arbitrary position. We circumvented the problem by switching to xml response format.\n\nI've written the full description here: http://restreaming.wordpress.com/2012/06/14/the-curious-case-of-solr-malfunction/",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "author": "Hoss Man",
            "id": "comment-13295307",
            "date": "2012-06-14T20:50:41+0000",
            "content": "can you provide some more details please...\n\n1) what servlet container are you using?\n2) how big (in bytes) are the responses when they work? how big are they when \"cut off\"?\n3) does the \"cut off\" always happen on/around a specific piece of markup? (ie: when closing a list or an object) or in the middle of arbitrary string values?  is it possible there are certain byte sequences that always occur just before/at/after the cutoff happens?\n4) your blog post mentions...\n\nUnfortunately, there was no indication of any malfunction in Solr except for the \u201cBroken Pipe\u201d notification that the client has closed the connection.\n\n...where are you seeing this? in packet sniffing tool? in the solr logs? ... what exactly is the full message? \n "
        },
        {
            "author": "Du\u0161an Omer\u010devi\u0107",
            "id": "comment-13295913",
            "date": "2012-06-15T20:35:42+0000",
            "content": "Ad 1) We're using Tomcat.\n\nAd 2) We fetch up to 40K documents with each document being a few KB in size. Total response is some 100MB in size. The cut off really happened at arbitrary position, from a few KB into the response up to several MB into the response.\n\nAd 3) I've checked it thoroughly and I couldn't find any pattern. It really seems that the problem is independent of the data.\n\nAd 4) The full message is:\n2012-06-11 12:23:34 ERROR: ClientAbortException:  java.net.SocketException: Broken pipe\n        at org.apache.catalina.connector.OutputBuffer.realWriteBytes(OutputBuffer.java:370)\n        at org.apache.tomcat.util.buf.ByteChunk.append(ByteChunk.java:323)\n        at org.apache.catalina.connector.OutputBuffer.writeBytes(OutputBuffer.java:396)\n        at org.apache.catalina.connector.OutputBuffer.write(OutputBuffer.java:385)\n        at org.apache.catalina.connector.CoyoteOutputStream.write(CoyoteOutputStream.java:89)\n        at sun.nio.cs.StreamEncoder.writeBytes(StreamEncoder.java:202)\n        at sun.nio.cs.StreamEncoder.implWrite(StreamEncoder.java:263)\n        at sun.nio.cs.StreamEncoder.write(StreamEncoder.java:106)\n        at java.io.OutputStreamWriter.write(OutputStreamWriter.java:190)\n        at org.apache.solr.common.util.FastWriter.flush(FastWriter.java:113)\n        at org.apache.solr.servlet.SolrDispatchFilter.writeResponse(SolrDispatchFilter.java:344)\n        at org.apache.solr.servlet.SolrDispatchFilter.doFilter(SolrDispatchFilter.java:265)\n        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:215)\n        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:188)\n        at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:213)\n        at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:172)\n        at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:127)\n        at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:117)\n        at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:108)\n        at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:174)\n        at org.apache.coyote.http11.Http11Processor.process(Http11Processor.java:873)\n        at org.apache.coyote.http11.Http11BaseProtocol$Http11ConnectionHandler.processConnection(Http11BaseProtocol.java:665)\n        at org.apache.tomcat.util.net.PoolTcpEndpoint.processSocket(PoolTcpEndpoint.java:528)\n        at org.apache.tomcat.util.net.LeaderFollowerWorkerThread.runIt(LeaderFollowerWorkerThread.java:81)\n        at org.apache.tomcat.util.threads.ThreadPool$ControlRunnable.run(ThreadPool.java:689)\n        at java.lang.Thread.run(Thread.java:662)\nCaused by: java.net.SocketException: Broken pipe\n        at java.net.SocketOutputStream.socketWrite0(Native Method)\n        at java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:92)\n        at java.net.SocketOutputStream.write(SocketOutputStream.java:136)\n        at org.apache.coyote.http11.InternalOutputBuffer.realWriteBytes(InternalOutputBuffer.java:750)\n        at org.apache.tomcat.util.buf.ByteChunk.flushBuffer(ByteChunk.java:432)\n        at org.apache.tomcat.util.buf.ByteChunk.append(ByteChunk.java:347)\n        at org.apache.coyote.http11.InternalOutputBuffer$OutputStreamOutputBuffer.doWrite(InternalOutputBuffer.java:773)\n        at org.apache.coyote.http11.filters.IdentityOutputFilter.doWrite(IdentityOutputFilter.java:127)\n        at org.apache.coyote.http11.InternalOutputBuffer.doWrite(InternalOutputBuffer.java:583)\n        at org.apache.coyote.Response.doWrite(Response.java:560)\n        at org.apache.catalina.connector.OutputBuffer.realWriteBytes(OutputBuffer.java:365)\n        ... 25 more\n\n2012-06-11 12:23:34 ERROR: Servlet.service() for servlet default threw exception\njava.lang.IllegalStateException\n        at org.apache.catalina.connector.ResponseFacade.sendError(ResponseFacade.java:405)\n        at org.apache.solr.servlet.SolrDispatchFilter.sendError(SolrDispatchFilter.java:380)\n        at org.apache.solr.servlet.SolrDispatchFilter.doFilter(SolrDispatchFilter.java:283)\n        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:215)\n        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:188)\n        at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:213)\n        at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:172)\n        at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:127)\n        at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:117)\n        at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:108)\n        at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:174)\n        at org.apache.coyote.http11.Http11Processor.process(Http11Processor.java:873)\n        at org.apache.coyote.http11.Http11BaseProtocol$Http11ConnectionHandler.processConnection(Http11BaseProtocol.java:665)\n        at org.apache.tomcat.util.net.PoolTcpEndpoint.processSocket(PoolTcpEndpoint.java:528)\n        at org.apache.tomcat.util.net.LeaderFollowerWorkerThread.runIt(LeaderFollowerWorkerThread.java:81)\n        at org.apache.tomcat.util.threads.ThreadPool$ControlRunnable.run(ThreadPool.java:689)\n        at java.lang.Thread.run(Thread.java:662)\n\nBut I believe that this is just a secondary effect of client closing the connection. It seems that the client is closing the connection because he doesn't have anything left to read. And it seems that it doesn't have anything to read because server abruptly stops sending data. In catalina.out there were no other error messages that would indicate why the server stopped sending data.\n\n\nI hope this helps at least a bit. I didn't post this bug report because I expected it to be resolved (it's quite weird indeed), but mostly as reference point if somebody else is experiencing similar problems. But if it would get resolved that would be even better, of course \n\nDu\u0161an "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-15575025",
            "date": "2016-10-14T11:14:45+0000",
            "content": "Not a bug. If you want to spool 30k docs, please use /export handler, cursorMark or streaming! "
        }
    ]
}