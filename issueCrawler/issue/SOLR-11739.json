{
    "id": "SOLR-11739",
    "title": "Solr can accept duplicated async IDs",
    "details": {
        "labels": "",
        "priority": "Minor",
        "components": [
            "SolrCloud"
        ],
        "type": "Bug",
        "fix_versions": [
            "7.3",
            "master (8.0)"
        ],
        "affect_versions": "None",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "Solr is supposed to reject duplicated async IDs, however, if the repeated IDs are sent fast enough, a race condition in Solr will let the repeated IDs through. The duplicated task is ran and and then silently fails to report as completed because the same async ID is already in the completed map.",
    "attachments": {
        "SOLR-11739.patch": "https://issues.apache.org/jira/secure/attachment/12901295/SOLR-11739.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2017-12-08T19:37:39+0000",
            "content": "Patch with failing test ",
            "author": "Tom\u00e1s Fern\u00e1ndez L\u00f6bbe",
            "id": "comment-16284098"
        },
        {
            "date": "2017-12-08T20:09:28+0000",
            "content": "I thought about three options\n1. Fix the actual race condition, don't let duplicate async IDs at all.\n2. Fix the Overseer so that it checks before running each task if one with the same ID was completed before.\n3. Let the Overseer re-run the tasks (leave it as it is now). Maybe just add logging, or a way to show the error (failed tasks)\n\n#3 can be dangerous, since the task could be something like a DELETEREPLICA. If the duplicate ID was caused by some broken retry logic on the client side, Solr could be deleting many replicas with what the client thought was a single command. \n\n#2 may be OK, the problem I see with that is that it gives an inconsistent behavior to the user (sometimes the duplicate IDs are rejected, and sometimes not). Also, this would make the Overseer silently drop tasks (yes, we can add some sort of failure in the logs but we can\u2019t assume anyone is going to notice). \n\n#1 is the correct fix from the functional stand point, however I can\u2019t think of a way to really fix the race condition without adding an extra write to ZooKeeper, which we\u2019d have to do for every collection request with an asyncID. And this is to cover from a client misuse edge case. \n\nI think (and I discussed this offline with Anshum Gupta, he thinks this too) #1 is the way to go. I\u2019ll put up a patch. ",
            "author": "Tom\u00e1s Fern\u00e1ndez L\u00f6bbe",
            "id": "comment-16284147"
        },
        {
            "date": "2017-12-11T17:52:06+0000",
            "content": "My off the cuff, uneducated, impression w/o knowing much about the internals or the history of how the existing code go to the state it's currently in is that...\n\nEither:\n\n\tSolr should assign the asyncIds and guarantee that they are unique\n\tThe user should assign the asyncIds, and Solr should make no assumptions about them, nor use them for anything other then reporting status.\n\n\n\n#1 seems a lot harder since it's essentially a distributed unique key generation problem, which IIUC is why asyncId wasn't implemented that way in the first place.\n\nFor #2, from my perspective, It sounds like tomas is saying that there is existing code in solr that tries to reject duplicate asyncIds \u2013 and I would argue (as a straw man) that Solr making any attempt at doing that is where the real bug lies ... Solr should happily let you specify the same asyncId multiple times, and that should have no affect at all on the reliability of the commands being executed in the order recieved.  the only thing it should affect is that requesting status info on the commands may give unexpected results (depending on what the client is expecting) ... i would expect that requesting status for the id would return the status of the \"1st\" instance, until the \"2nd\" instance finishes at which point the status info is overridden.\n\nthat way if a user wants to re-use the exact same asyncId for every request, they are welcome to put that bullet in their foot as many times as they want \u2013 it keeps things simpler for us internally, and we're not trying to coddle them for doing something (very advanced) in a silly way.\n\n\n\nIf we're going to coddle them, then we should coddle them all the way \u2013 isn't the amount of work / zk writes needed to generate a universally unique asyncId on the server side essentially the same as the amount needed to tell the client that the asyncId they specified isn't unique? ",
            "author": "Hoss Man",
            "id": "comment-16286346"
        },
        {
            "date": "2017-12-11T18:58:26+0000",
            "content": "Solr should assign the asyncIds and guarantee that they are unique\nWe now do something like this when async IDs are not provided, but on the client side. See https://github.com/apache/lucene-solr/blob/41644bdcdcc0734115ce08ec24d6b408e1f8cf28/solr/solrj/src/java/org/apache/solr/client/solrj/request/CollectionAdminRequest.java#L150-L152\nIt sounds like tomas is saying that there is existing code in solr that tries to reject duplicate asyncIds\nYes, here: https://github.com/apache/lucene-solr/blob/41644bdcdcc0734115ce08ec24d6b408e1f8cf28/solr/core/src/java/org/apache/solr/handler/admin/CollectionsHandler.java#L282-L286\nSolr should happily let you specify the same asyncId multiple times\nhmm I'm not sure. I think the fact that Solr won't re-execute the same request twice makes it much easier to write workflows that do collection operations. \nisn't the amount of work / zk writes needed to generate a universally unique asyncId on the server side essentially the same as the amount needed to tell the client that the asyncId they specified isn't unique?\nWe now do a bunch of reads to check if the async IDs are in any of the current queues/maps (see the code I linked above). I was considering either writing to some ZooKeeper path the async ID  as part of a lock, before checking the existing queues and then deleting the lock, or moving completely the async IDs to it's own path, and starting using this as the source of truth of asyncIDs. The later would then make it easier to check if an async ID is currently in use, however it's a much bigger change and we'll need to consider back compatibility ",
            "author": "Tom\u00e1s Fern\u00e1ndez L\u00f6bbe",
            "id": "comment-16286410"
        },
        {
            "date": "2017-12-20T01:35:58+0000",
            "content": "Here is a patch with what I said, it keeps the async IDs in a separate map, and every time a new async request comes in we try to create the key on this new map, failing if it already exists.\nAny other thoughts Hoss Man, given my previous reply and the patch? Anshum Gupta? ",
            "author": "Tom\u00e1s Fern\u00e1ndez L\u00f6bbe",
            "id": "comment-16297762"
        },
        {
            "date": "2017-12-20T05:02:07+0000",
            "content": "i have no strong opinions ... at a high level i think the approach you describe (i didn't review the patch) is fine from a stability/reliability and back compat standpoint, but I have no idea how it affects performance (although it should go w/o saying that i favor stability/reliability over performance when discussing \"admin\" actions)\n\nTo clarify one comment where i suspect we may have been misscommunicating...\n\n\nSolr should happily let you specify the same asyncId multiple times\n\nhmm I'm not sure. I think the fact that Solr won't re-execute the same request twice makes it much easier to write workflows that do collection operations. \n\nI feel like my suggestion was orthoginal to to the concern you suggested in response.  What i was suggesting is that, in theory: Solr could be agnostic to the asyncId and only use them for  tracking results.  Example: if these 4 commands come in...\n\n\n\tasyncId=222&cmd=CREATESOMETHING\n\tasyncId=1&cmd=DOSOMETHINGELSE\n\tasyncId=222&cmd=DOWHATEVER\n\n\n\n...then Solr could in fact execute those 3 commands, in that sequence, reliably, and w/o any risk of any of them being executed more or less then exactly 1 time.  The fact that 2 of them have the same asyncId should in no way impact Solr's execution of those commands.  The only impact that the duplicated asyncId should have is that once the DOWHATEVER cmd is executed, it will no longer be possible for a client to ever check the status of the CREATESOMETHING, because the results of the DOWHATEVER command should overwrite the results of the CREATESOMETHING ... that could be solr's sole internal use of the asyncId\n\n(ie: only track all commands to process in an ordered queue, use the asyncId only in a map we don't care about internally, other then if a user asks for status info)\n\nthat was the crux of my suggestion ... assuming we want a policy of solr being \"agnostic\" to duplicate asyncIds in order to reduce the zk overhead of tracking/rejecting dups.  (BUt i don't feel strongly about it) ",
            "author": "Hoss Man",
            "id": "comment-16297890"
        },
        {
            "date": "2017-12-20T18:39:43+0000",
            "content": "feel like my suggestion was orthognal to to the concern you suggested in response. \nNo, I meant \"Solr won't re-execute the same request twice\" even if it receives it twice. What I say is that, by Solr rejecting the duplicate async ID it makes the admin request idempotent, you could do something like:\n\nwhile (!success) {\n    try {\n        performRequest(asyncId=1&cmd=CREATESOMETHING)\n        success = true\n    } catch (e) {\n        //backoff\n    }\n }\n\n\n\nIf there is some error back from performRequest, you don\u2019t know if the request was scheduled or not, but you don\u2019t care if you know Solr won\u2019t re-schedule it, you can just send it again. Another use case could be workers watching a queue and executing actions, if the queue delivers a message more than once, you don\u2019t have to worry about sending the command to Solr multiple times, and can assume a \u201crequest already exists\u201d response from Solr to be a success. ",
            "author": "Tom\u00e1s Fern\u00e1ndez L\u00f6bbe",
            "id": "comment-16298901"
        },
        {
            "date": "2018-01-06T00:16:10+0000",
            "content": "Thanks for taking this up Tom\u00e1s Fern\u00e1ndez L\u00f6bbe! This looks good and not super invasive. \n\nHere's some feedback:\n\n\tCollectionsHandler.java\n\t\n\t\tWe should add back the check in old places instead of leaving that as a TODO\n\t\tL296: It would be good to log the reason for the failure to offer the request to the OverseerCollectionQueue\n\t\n\t\n\tAre the log4j.properties changes intentional ?\n\tSizeLimitedDistributedMap.OnChildDeleteObserver interface doesn\u2019t need the keyword static also can you add some javadoc there?\n\tAs I understand, you would also want to override clear() and call onDeleteObserver.onChildDelete in those cases too.\n\tJavadocs for claim/clearAsyncId. It\u2019d be good to mention that it returns false when it tries to clear an ID that doesn\u2019t exist any more.\n\n ",
            "author": "Anshum Gupta",
            "id": "comment-16314192"
        },
        {
            "date": "2018-02-01T04:48:09+0000",
            "content": "Hoss Man, To me it seems that with your 3 command example things are a little worse than you say... There would be a window where id 222\u00a0could be seen as the success of CREATESOMETHING, and someone checking on DOWHATEVER might think DOWHATEVER had been done successfully (yay, go home, throw a party...\u00a0) but then DOWHATEVER fails (Monday's gonna be less fun...), and then some automated process\u00a0checks on 222 to verify that it did actually CREATESOMETHING, but sees a failure... (drat, do it again...\u00a0and again and again.. continually failing because SOMETHING now exists).....\u00a0\n\nSure, it's their fault for not coordinating their ID's but... why\u00a0help them make that mistake?\n\nI think any ID that is not unique is more or less useless. I haven't used async requests and haven't previously\u00a0paid much attention to\u00a0it, don't know the history, and I might be missing something, but I find it shocking that\u00a0Solr\u00a0is not generating the id and ensuring it's uniqueness. How about when the Overseer is elected, it establishes a source of entropy (Random initialized from time) and uses that to issue UUID's. There's only one overseer at a time, and the cases where 2 or more overseers are started at exactly the same time and coexist is a bug, right? If there's no overseer, commands can't be run anyway... ",
            "author": "Gus Heck",
            "id": "comment-16348004"
        },
        {
            "date": "2018-02-04T02:12:11+0000",
            "content": "Thanks for the thorough review Anshum.\nWe should add back the check in old places instead of leaving that as a TODO\nYes, that was my plan. I'll upload a patch now with the back compat support.\nL296: It would be good to log the reason for the failure to offer the request to the OverseerCollectionQueue\nNote that the exception will be thrown in this case\nAre the log4j.properties changes intentional ?\nFor my testing, I'll revert before committing\nSizeLimitedDistributedMap.OnChildDeleteObserver interface doesn\u2019t need the keyword static also can you add some javadoc there?\nGood catch. Changed.\nAs I understand, you would also want to override clear() and call onDeleteObserver.onChildDelete in those cases too.\nReally, I was thinking on the observer to be called only in the case of overflow, not for a regular delete (it's also not called on remove). I modified the name to OnOverflowObserver of the observer to be clearer about this.\nJavadocs for claim/clearAsyncId. It\u2019d be good to mention that it returns false when it tries to clear an ID that doesn\u2019t exist any more.\nAdded\n\nAlso added some more tests to the new code and to DistributedMap since I couldn't find any.\n...How about when the Overseer is elected, it establishes a source of entropy (Random initialized from time) and uses that to issue UUID's...\nThat is another option. Although note that there is a client option to call with an auto-generated asyncId, which should prevent collisions. We could also switch to a model in which we don't accept client-provided async IDs, but I guess that should be another Jira, there would be much more changes for that, including an API change ",
            "author": "Tom\u00e1s Fern\u00e1ndez L\u00f6bbe",
            "id": "comment-16351606"
        },
        {
            "date": "2018-02-16T00:18:01+0000",
            "content": "Commit 61ea8f60b1c69ba9ed753fe533d571fcbb452887 in lucene-solr's branch refs/heads/master from Tom\u00e1s Fern\u00e1ndez L\u00f6bbe\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=61ea8f6 ]\n\nSOLR-11739: Don't accept duplicate async IDs in collection API operations ",
            "author": "ASF subversion and git services",
            "id": "comment-16366446"
        },
        {
            "date": "2018-02-16T00:22:46+0000",
            "content": "Commit 250e5b2aba2c25540f597f4436c619fd97febd0d in lucene-solr's branch refs/heads/master from Tom\u00e1s Fern\u00e1ndez L\u00f6bbe\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=250e5b2 ]\n\nSOLR-11739: Remove cast no longer needed ",
            "author": "ASF subversion and git services",
            "id": "comment-16366450"
        },
        {
            "date": "2018-02-16T00:23:28+0000",
            "content": "Commit f6b6f5070270c93fa7d8604ed456c9df041e7454 in lucene-solr's branch refs/heads/branch_7x from Tom\u00e1s Fern\u00e1ndez L\u00f6bbe\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=f6b6f50 ]\n\nSOLR-11739: Don't accept duplicate async IDs in collection API operations ",
            "author": "ASF subversion and git services",
            "id": "comment-16366451"
        },
        {
            "date": "2018-02-16T00:23:30+0000",
            "content": "Commit dfb0803bbb972d730627fbdcd4df66558d06f13a in lucene-solr's branch refs/heads/branch_7x from Tom\u00e1s Fern\u00e1ndez L\u00f6bbe\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=dfb0803 ]\n\nSOLR-11739: Remove cast no longer needed ",
            "author": "ASF subversion and git services",
            "id": "comment-16366452"
        }
    ]
}