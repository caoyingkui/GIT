{
    "id": "SOLR-5285",
    "title": "Solr response format should support child Docs",
    "details": {
        "affect_versions": "None",
        "status": "Resolved",
        "fix_versions": [
            "4.9",
            "6.0"
        ],
        "components": [],
        "type": "New Feature",
        "priority": "Major",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "Solr has added support for taking childDocs as input ( only XML till now ). It's currently used for BlockJoinQuery. \n\nI feel that if a user indexes a document with child docs, even if he isn't using the BJQ features and is just searching which results in a hit on the parentDoc, it's childDocs should be returned in the response format.\n\nChris Hostetter (Unused) on IRC suggested that the DocTransformers would be the place to add childDocs to the response.\n\nNow given a docId one needs to find out all the childDoc id's. A couple of approaches which I could think of are \n1. Maintain the relation between a parentDoc and it's childDocs during indexing time in maybe a separate index?\n2. Somehow emulate what happens in ToParentBlockJoinQuery.nextDoc() - Given a parentDoc it finds out all the childDocs but this requires a childScorer.\n\nAm I missing something obvious on how to find the relation between a parentDoc and it's childDocs because none of the above solutions for this look right.",
    "attachments": {
        "SOLR-5285.patch": "https://issues.apache.org/jira/secure/attachment/12606800/SOLR-5285.patch",
        "javabin_backcompat_child_docs.bin": "https://issues.apache.org/jira/secure/attachment/12644635/javabin_backcompat_child_docs.bin"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Mikhail Khludnev",
            "id": "comment-13780919",
            "date": "2013-09-28T18:35:23+0000",
            "content": "giving you search with !{parent qparser, which children you want to return, all children belong to a parent or only those which passed by the child level query? \n\nnote: approach no 1. seems never fitting, because the relation is already present in the index; approach no.2 seems like over-optimization, if we are talking about enriching only 'rows' parent.   "
        },
        {
            "author": "Varun Thacker",
            "id": "comment-13782943",
            "date": "2013-10-01T13:46:40+0000",
            "content": "I don't think I have been to able to explain the problem accurately in the Jira description. Let me try again..\n\n1. Index docs with childDocs. So let's take the example on https://cwiki.apache.org/confluence/display/solr/Other+Parsers#OtherParsers-BlockJoinQueryParsers\n\n2. Now I query http://localhost:8983/solr/collection1/select?q=*:*&fq=content_type:%22parentDocument%22\n\n3. This is the response\n\n\n<response>\n    <lst name=\"responseHeader\">\n        <int name=\"status\">0</int>\n        <int name=\"QTime\">2</int>\n        <lst name=\"params\">\n            <str name=\"q\">*:*</str>\n            <str name=\"fq\">content_type:\"parentDocument\"</str>\n        </lst>\n    </lst>\n<result name=\"response\" numFound=\"2\" start=\"0\">\n    <doc>\n        <str name=\"id\">1</str>\n        <arr name=\"title\">\n        <str>Solr adds block join support</str>\n        </arr>\n        <arr name=\"content_type\">\n            <str>parentDocument</str>\n        </arr>\n        <long name=\"_version_\">1447311301175934976</long>\n    </doc>\n    <doc>\n        <str name=\"id\">3</str>\n        <arr name=\"title\">\n            <str>Lucene and Solr 4.5 is out</str>\n        </arr>\n        <arr name=\"content_type\">\n            <str>parentDocument</str>\n        </arr>\n        <long name=\"_version_\">1447311327665061888</long>\n    </doc>\n</result>\n</response>\n\n\n\n4. Ideally I would want this as my response:\n\n<response>\n    <lst name=\"responseHeader\">\n        <int name=\"status\">0</int>\n        <int name=\"QTime\">2</int>\n        <lst name=\"params\">\n            <str name=\"q\">*:*</str>\n        </lst>\n    </lst>\n<result name=\"response\" numFound=\"4\" start=\"0\">\n<doc>\n    <str name=\"id\">1</str>\n    <arr name=\"title\">\n        <str>Solr adds block join support</str>\n    </arr>\n    <arr name=\"content_type\">\n        <str>parentDocument</str>\n    </arr>\n    <long name=\"_version_\">1447311301175934976</long>\n    <doc>\n        <str name=\"id\">2</str>\n        <str name=\"comments\">SolrCloud supports it too!</str>\n    </doc>\n</doc>\n\n<doc>\n    <str name=\"id\">3</str>\n    <arr name=\"title\">\n        <str>Lucene and Solr 4.5 is out</str>\n    </arr>\n    <arr name=\"content_type\">\n        <str>parentDocument</str>\n    </arr>\n    <long name=\"_version_\">1447311327665061888</long>\n    <doc>\n        <str name=\"id\">4</str>\n        <str name=\"comments\">Lots of new features</str>\n    </doc>\n</doc>\n</result>\n</response>\n\n\n\n\nAlso Mikhail Khludnev ,\napproach no 1. seems never fitting, because the relation is already present in the index\n how is the relation already present in the index? From what I understand each child doc has a root field which points to the parent doc. But we do not have the opposite relation. To implement this feature we would need the relation b/w each parent and all it's child doc right? Am I missing anything? "
        },
        {
            "author": "Mikhail Khludnev",
            "id": "comment-13783101",
            "date": "2013-10-01T16:22:12+0000",
            "content": "Hello Varun,\n\nYou can experiment with the following code:\n\n\n@Override\npublic void transform(SolrDocument doc, int docid) throws IOException{\n  parentid = doc.getField(\"id\");\n  children = searcher.getDocList(\n      QParser.getParser(\"{!child of=content_type:parentDocument}id:\"+parentid).getQuery(),...);\n  doc.put(\"children\", children);\n}\n\n\n\n "
        },
        {
            "author": "Varun Thacker",
            "id": "comment-13786195",
            "date": "2013-10-04T14:36:48+0000",
            "content": "Syntax: [children parentFilter=\"content_type:parentDocument\"]\n\nThis patch adds support for nested docs for wt=xml. I will add for other writers soon.\n\nThere is no way to specify return fields for a childDoc. Should there be an option?\n\nI added ChildDocTransformerFactory#toSolrDocument which is the same as TextResponseWriter#toSolrDocument. It's not the best thing to do.\n\nMikhail Khludnev thanks for your suggestion  "
        },
        {
            "author": "Varun Thacker",
            "id": "comment-13881853",
            "date": "2014-01-25T12:58:27+0000",
            "content": "\n\tNested chidDoc support in both XML and JSON response formats\n\tIt's implemented as a DocTransformer and the syntax for calling using it is:\n\n[child parentFilter=\"fieldName:fieldValue\"]\n\n\n\tAdded response format tests for XML And JSON\n\n "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13959412",
            "date": "2014-04-03T23:15:56+0000",
            "content": "Hey Varun, thanks for working on this \u2013 great idea.\n\nI haven't reviewed your implementation details in depth, but here's my comments/concerns/questions based on an initial skim of your patch...\n\n\n\t\"There is no way to specify return fields for a childDoc. Should there be an option?\"\n\t\n\t\tI think so, probably an \"fl\" option on the [child] transformer, but if that's non-trivial to add right now, we should at least clearly document/test that all of the child fields come back \u2013 ie: make sure it's not inadvertently affected by the top level 'fl' param)\n\t\n\t\n\t\"I added ChildDocTransformerFactory#toSolrDocument which is the same as TextResponseWriter#toSolrDocument. It's not the best thing to do.\"\n\t\n\t\tno .. we should just refactor this into a static utility method somewhere.\n\t\n\t\n\tit's not clear to me from the API what to expect will happen if i have more then one level of parent-child relationships in my index \u2013 will children & grandchildren be returned?  whatever is expected needs to be documented/tested\n\tThis should ideally work (and be tested) when using SolrJ and JavaBin \u2013 but at a minimum we must ensure it doesn't cause requests to explode with weird errors \u2013 particularly since i notice your patch modifies o.a.s.common.SolrDocument but i don't see any updates to the javabin codec.\n\t\n\t\twe should also ensure/test that the codec is updated in such a way that people who don't use this feature won't get weird errors when using old_solrj+new_solr or new_solrj+old_solr (ie: don't include an empty list of children in the binary data if the transformer isn't used at all)\n\t\n\t\n\tthe way you create the index in TestChildDocTransformer is pretty confusing and seems overly convoluted \u2013 it would be a lot more straight forward to use real, nested, SolrInputDocuments and something like SolrTestCaseJ4.addAndGetVersion\n\tin ChildDocTransformer.transform, the use of String.format & \"{!child..}\" seems like unneccessary overhead \u2013 we should just use new ToChildBlockJoinQuery(...)\n\t\n\t\tno need to build up a string just to parse it, and as things stand now i'm pretty sure you'll get weird errors if parentFilter contains quotes\n\t\n\t\n\tIt looks like there is an NPE waiting to happen in SolrDocument.clear()\n\n "
        },
        {
            "author": "Varun Thacker",
            "id": "comment-13969358",
            "date": "2014-04-15T09:12:27+0000",
            "content": "1. After having a quick glance at the code I don't think it's trivial to add return fields for child docs. I could create a follow up Jira for it. But I added more tests to verify the the top level fl param does not affect the fields coming back in the child document.\n\n2. Moved TextResponseWriter.toSolrDocument to ResponseWriterUtil.toSolrDocument\n\n3. I tested with adding grandchildren document, and the behaviour is that the grandchildren docs gets returned along with the child docs by ToChildBlockJoinQuery. I'll go through ToChildBlockJoinQuery to see if thats the expected behaviour.\n\n4. Updated JavaBinCodec to handle child documents. Added a test TestChildDocTransformer.testJavaBinCodec. Also TestJavaBinCodec passes so it should have any backward or forward compatibility issues.\n\n5. Simplified TestChildDocTransformer.createIndex\n\n6. Fixed ChildDocTransformer.transform to directly create ToChildBlockJoinQuery\n\n7. Added null check in SolrDocument.clear() "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-13971137",
            "date": "2014-04-16T12:57:15+0000",
            "content": "Move issue to Solr 4.9. "
        },
        {
            "author": "Varun Thacker",
            "id": "comment-13987850",
            "date": "2014-05-02T16:08:06+0000",
            "content": "Updated patch with trunk.\n\nit's not clear to me from the API what to expect will happen if i have more then one level of parent-child relationships in my index \u2013 will children & grandchildren be returned? whatever is expected needs to be documented/tested\n\nTested with grandchildren. In Lucene all grandchildren and all siblings  are treated as simply children to the parent document. A parent document and all it's child documents are indexed in a block. Hence we should document for only support one level of nesting. "
        },
        {
            "author": "Varun Thacker",
            "id": "comment-13987853",
            "date": "2014-05-02T16:08:59+0000",
            "content": "Correct patch. Please ignore the previous patch. "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13992454",
            "date": "2014-05-08T02:52:51+0000",
            "content": "\nHey Varun, I made some small changes to your patch as i was reviewing it...\n\n\n\tremoved unneeded new import of SolrCmdDistributor in TextResponseWriter\n\tTextResponseWriter.toSolrDocument is public, so we can't just remove it competley \u2013 i added it back as a stub wrapper arround your new ResponseWriterUtil.toSolrDocument\n\tadd some javadocs to ResponseWriterUtil.toSolrDocument\n\tI think I missed this in your last patch: we can't change the signature of the public static String SolrTestCaseJ4.json(SolrInputDocument) method \u2013 i fixed this to be a refactoring that delegates to a new public static void SolrTestCaseJ4.json(SolrInputDocument,CharArr) method (which is recursive like in your patch)\n\tMoved your new TestChildDocTransformer.testJavaBinCodec method into TestJavaBinCodec.testResponseChildDocuments since it doesn't actually test anything about the transformer. just the codec.  I also beefed it up with some additional children, and assertions about hasChildDocuments() and if/when getChildDocuments() should be null.\n\n\n\n\n\nSome responses to your previous comments...\n\nFixed ChildDocTransformer.transform to directly create ToChildBlockJoinQuery\nAdded null check in SolrDocument.clear()\n\n+1, +1 ... those look great\n\n... I don't think it's trivial to add return fields for child docs. I could create a follow up Jira for it. But I added more tests to verify the the top level fl param does not affect the fields coming back in the child document.\n\nI think the way to do it would be to have ChildDocTransformer maintain it's own private ReturnField instace (based on an 'fl' local param) which it would use in the transform(...) method to remove fields from the child {{SolrDocument}}s if they weren't wanted.\n\nBut you're right \u2013 that can be done as a later feature enhancement. (I added a TODO for now)\n\nTestJavaBinCodec passes so it should have any backward or forward compatibility issues.\n\n(I realize you were the main author of SOLR-5265 and you know a lot of this, but i'm going to go into depth for clarity for anyone else reading this issue)\n\nMost of the existing tests using the codec don't give any assurances that the patch hasn't broken codec compatibility \u2013 because the tests run with the current marshall and unmarshal methods, both of which the patch changes.  The only tests thats help assure the patch doesn't break backcompatibility are TestJavaBinCodec.testBackCompat and TestJavaBinCodec.testForwardCompat because they compare the results of the current codec with a binary file produced with an older version of the codec stored in svn.  They ensure that the current codec (in a client) can still read the binary data from an older codec (on a server), and that the current codec (on a server) still produces an identical response to what an older codec would (so we know that a client running an older version should be able to parse it).  But these tests only verify this for documents w/o any children (because that's all that existed prior to this patch).  So they don't give us any future protection against breaking backcompat with the new additions of child docs in the response.\n\nWe need to add new tests, using a new *.bin file in SVN containing nested SolrDocuments, to help verify forward compatibility (and future backcompatibility).\n\n(as a general rule we shouldn't modify \"javabin_backcompat.bin\", or any other *.bin files we add over time, because that would make it very easy to some backcompat breakages to slip in with whatever commit modifies them)\n\nSimplified TestChildDocTransformer.createIndex\n\nThanks \u2013 with the simplified and cleaner index creation, it's a lot easier to see what's going on.  One key issue that jumps out at me is that there's no verification that things work properly if you use the transformer on a result set where some docs have children and others do not.  we should definitely account for that.\n\nI think ideally what we should have (in addition to your existing static test) is a new randomized test that builds up a Map (keyed on id) of {{SolrInputDocument}}s with a random number of children (etc... up to a random depth) then after adding all of those documents executes some random queries using this transformer and asserts that each {{SolrDocument}}s in the response has the expected children same number of children as the original docs.\n\n(The best place for this to live would be SolrExampleTests because then it would help vet both the XML and binary response formats, using the actual example configs)\n\n\nTested with grandchildren. In Lucene all grandchildren and all siblings are treated as simply children to the parent document. A parent document and all it's child documents are indexed in a block. Hence we should document for only support one level of nesting.\n\nWell, looking at your test, a more specific way to put it is that the new \"child\" transformer actually returns all descendents of the return documents in a flat list.  Which is fine if we document it that way \u2013 but it has me thinking: we should really add a \"childFilter\" option to the transformer to constrain the results.  This would not only help with the grand child situation, but would also make it easy for people to constrain the types of children they want to get back. (and getDocList can already take in a Query filter)\n\n\n\n\nSome new misc questions/comments about the current patch...\n\n\n\tWhy is the tag name in the JSON format \"childDocs\" but in the XML format it's \"childDoc\" (no plural) ? ... seems like those should be consistent.\n\tthe \"10\" hardcoded in the getDocList call is garunteed to burn someone ... it can definitely default to 10, but we need to have a local param for it in the tnrasformer\n\n\n "
        },
        {
            "author": "Varun Thacker",
            "id": "comment-13996169",
            "date": "2014-05-13T07:38:39+0000",
            "content": "I think we should fix the back compat tests before resolving this. "
        },
        {
            "author": "Varun Thacker",
            "id": "comment-13996523",
            "date": "2014-05-13T15:58:09+0000",
            "content": "1. Added JavaDocs to ChildDocTransformerFactory\n2. Created a new binary file for backcompatibility and forwardcompatibility.\n\nWhy is the tag name in the JSON format \"childDocs\" but in the XML format it's \"childDoc\" (no plural) ? ... seems like those should be consistent.\n\nI guess because in JSON the input is a JSON array hence \"childDocs\", while in XML we use multiple \"childDoc\" tags to represent nested documents.\n\nthe \"10\" hardcoded in the getDocList call is garunteed to burn someone ... it can definitely default to 10, but we need to have a local param for it in the tnrasformer\n\nAdded a non mandatory parameter called \"numChildDocs\" which makes it configurable. Although I'm not sure if the name is correct.\n\nWell, looking at your test, a more specific way to put it is that the new \"child\" transformer actually returns all descendents of the return documents in a flat list. Which is fine if we document it that way \u2013 but it has me thinking: we should really add a \"childFilter\" option to the transformer to constrain the results. This would not only help with the grand child situation, but would also make it easy for people to constrain the types of children they want to get back. (and getDocList can already take in a Query filter)\n\nAdded a non mandatory parameter called \"childFilter\" which could be used to filter out which child documents to be nested in the parent documents to be returned.\n\nTODO - I will work on adding randomized testing "
        },
        {
            "author": "Varun Thacker",
            "id": "comment-13996527",
            "date": "2014-05-13T16:01:52+0000",
            "content": "Updated patch with the binary file is attached separately.\n\nStill need to add the randomized tests. "
        },
        {
            "author": "Raveendra Yerraguntl",
            "id": "comment-13998844",
            "date": "2014-05-15T15:27:35+0000",
            "content": "Thanks Varun and all.\n\nJust in time. Is it possible to get into 4.8.* versions . It reduces lot of UI work. \n\nIf not when is the 4.9 scheduled for a stable release?  "
        },
        {
            "author": "Varun Thacker",
            "id": "comment-13999612",
            "date": "2014-05-16T05:41:09+0000",
            "content": "Updated patch.\n\n\n\tAdds a random test in SolrExampleTests\n\tAdds missing support for child documents in XMLRepsonseParser\n\n\n\njavabin_backcompat_child_docs.bin remains the same and is attached separately. "
        },
        {
            "author": "Varun Thacker",
            "id": "comment-13999615",
            "date": "2014-05-16T05:43:16+0000",
            "content": "Raveendra Yerraguntl It won't be part of the 4.8.* releases.\n\nThere is no particular timeline for the 4.9 release but it could be out within a month. "
        },
        {
            "author": "Arcadius Ahouansou",
            "id": "comment-14004850",
            "date": "2014-05-21T16:15:26+0000",
            "content": "Thanks Varun Thacker  and all for the great work.\n Hoss Man Any chance this will get into 4.9?\n\nThanks. "
        },
        {
            "author": "Hoss Man",
            "id": "comment-14005064",
            "date": "2014-05-21T18:36:21+0000",
            "content": "Hey Varun,\n\nI didn't get very far digging into your patch, because i started by looking at your new randomized test in SolrExampleTests and encountered some problems...\n\n1) the first time i tried running your new randomized test, i got an NPE \u2013 it didn't reproduce reliable though, because your test called \"new Random()\" instead of leveraging the test-framework (\"ant precommit\" will warn you about stuff like this)\n\n2) Side note: there's no need to randomize which response parser is used when you add test methods to \"SolrExampleTests\" \u2013 every method there gets picked up automatically by the subclasses which ensure they are all run with every writer/parser.\n\n3) When started looking into fixing the use of random() in your test, I realized that the assertions in the test weren't very strong.  What i was refering to in my earlier comment was having a test that attempted to use the transformer on a result set that included docs with children, and docs w/o children; and asserting that every child returned really was a decendent of the specified doc by comparing with what we know for a fact we indexed \u2013 your test wasn't really doing any of that.\n\nIn the attached patch, i've overhauled SolrExampleTests.testChildDoctransformer() along the lines of what i was describing, but this has exposed a ClassCastException in the transformer.  I haven't had a chance to dig into what's happening, but for some odd reason it only seems to manifest itself when the XML Response Writer is used...\n\n\nhossman@frisbee:~/lucene/dev/solr/solrj$ ant test -Dtests.method=testChildDoctransformer -Dtests.seed=720251997BEC4F70 -Dtests.slow=true -Dtests.locale=sk -Dtests.timezone=Pacific/Fiji -Dtests.file.encoding=UTF-8\n\n...\n\n   [junit4]   2> 11768 T20 C1 oasc.SolrException.log ERROR null:java.lang.ClassCastException: org.apache.lucene.document.Field cannot be cast to java.lang.String\n   [junit4]   2> \t\tat org.apache.solr.response.transform.ChildDocTransformer.transform(ChildDocTransformerFactory.java:142)\n   [junit4]   2> \t\tat org.apache.solr.response.TextResponseWriter.writeDocuments(TextResponseWriter.java:254)\n   [junit4]   2> \t\tat org.apache.solr.response.TextResponseWriter.writeVal(TextResponseWriter.java:172)\n   [junit4]   2> \t\tat org.apache.solr.response.XMLWriter.writeResponse(XMLWriter.java:111)\n   [junit4]   2> \t\tat org.apache.solr.response.XMLResponseWriter.write(XMLResponseWriter.java:40)\n   [junit4]   2> \t\tat org.apache.solr.servlet.SolrDispatchFilter.writeResponse(SolrDispatchFilter.java:760)\n   [junit4]   2> \t\tat org.apache.solr.servlet.SolrDispatchFilter.doFilter(SolrDispatchFilter.java:428)\n   [junit4]   2> \t\tat org.apache.solr.servlet.SolrDispatchFilter.doFilter(SolrDispatchFilter.java:208)\n   [junit4]   2> \t\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1419)\n   [junit4]   2> \t\tat org.apache.solr.client.solrj.embedded.JettySolrRunner$DebugFilter.doFilter(JettySolrRunner.java:136)\n   [junit4]   2> \t\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1419)\n   [junit4]   2> \t\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:455)\n   [junit4]   2> \t\tat org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:229)\n   [junit4]   2> \t\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:137)\n   [junit4]   2> \t\tat org.eclipse.jetty.server.handler.GzipHandler.handle(GzipHandler.java:301)\n   [junit4]   2> \t\tat org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1077)\n   [junit4]   2> \t\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:384)\n   [junit4]   2> \t\tat org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:193)\n   [junit4]   2> \t\tat org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1009)\n   [junit4]   2> \t\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:135)\n   [junit4]   2> \t\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:116)\n   [junit4]   2> \t\tat org.eclipse.jetty.server.Server.handle(Server.java:368)\n   [junit4]   2> \t\tat org.eclipse.jetty.server.AbstractHttpConnection.handleRequest(AbstractHttpConnection.java:489)\n   [junit4]   2> \t\tat org.eclipse.jetty.server.AbstractHttpConnection.headerComplete(AbstractHttpConnection.java:942)\n   [junit4]   2> \t\tat org.eclipse.jetty.server.AbstractHttpConnection$RequestHandler.headerComplete(AbstractHttpConnection.java:1004)\n   [junit4]   2> \t\tat org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:640)\n   [junit4]   2> \t\tat org.eclipse.jetty.http.HttpParser.parseAvailable(HttpParser.java:235)\n   [junit4]   2> \t\tat org.eclipse.jetty.server.AsyncHttpConnection.handle(AsyncHttpConnection.java:82)\n   [junit4]   2> \t\tat org.eclipse.jetty.io.nio.SelectChannelEndPoint.handle(SelectChannelEndPoint.java:628)\n   [junit4]   2> \t\tat org.eclipse.jetty.io.nio.SelectChannelEndPoint$1.run(SelectChannelEndPoint.java:52)\n   [junit4]   2> \t\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:608)\n   [junit4]   2> \t\tat org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:543)\n   [junit4]   2> \t\tat java.lang.Thread.run(Thread.java:744)\n   [junit4]   2> \t\n   [junit4]   2> 11774 T12 oas.SolrTestCaseJ4.tearDown ###Ending testChildDoctransformer\n   [junit4]   2> NOTE: reproduce with: ant test  -Dtestcase=SolrExampleStreamingTest -Dtests.method=testChildDoctransformer -Dtests.seed=720251997BEC4F70 -Dtests.slow=true -Dtests.locale=sk -Dtests.timezone=Pacific/Fiji -Dtests.file.encoding=UTF-8\n   [junit4] ERROR   5.76s J2 | SolrExampleStreamingTest.testChildDoctransformer <<<\n\n...\n\n   [junit4]   2> 16262 T39 C1 oasc.SolrException.log ERROR null:java.lang.ClassCastException: org.apache.lucene.document.Field cannot be cast to java.lang.String\n   [junit4]   2> \t\tat org.apache.solr.response.transform.ChildDocTransformer.transform(ChildDocTransformerFactory.java:142)\n   [junit4]   2> \t\tat org.apache.solr.response.TextResponseWriter.writeDocuments(TextResponseWriter.java:254)\n   [junit4]   2> \t\tat org.apache.solr.response.TextResponseWriter.writeVal(TextResponseWriter.java:172)\n   [junit4]   2> \t\tat org.apache.solr.response.XMLWriter.writeResponse(XMLWriter.java:111)\n   [junit4]   2> \t\tat org.apache.solr.response.XMLResponseWriter.write(XMLResponseWriter.java:40)\n   [junit4]   2> \t\tat org.apache.solr.servlet.SolrDispatchFilter.writeResponse(SolrDispatchFilter.java:760)\n   [junit4]   2> \t\tat org.apache.solr.servlet.SolrDispatchFilter.doFilter(SolrDispatchFilter.java:428)\n   [junit4]   2> \t\tat org.apache.solr.servlet.SolrDispatchFilter.doFilter(SolrDispatchFilter.java:208)\n   [junit4]   2> \t\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1419)\n   [junit4]   2> \t\tat org.apache.solr.client.solrj.embedded.JettySolrRunner$DebugFilter.doFilter(JettySolrRunner.java:136)\n   [junit4]   2> \t\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1419)\n   [junit4]   2> \t\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:455)\n   [junit4]   2> \t\tat org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:229)\n   [junit4]   2> \t\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:137)\n   [junit4]   2> \t\tat org.eclipse.jetty.server.handler.GzipHandler.handle(GzipHandler.java:301)\n   [junit4]   2> \t\tat org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1077)\n   [junit4]   2> \t\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:384)\n   [junit4]   2> \t\tat org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:193)\n   [junit4]   2> \t\tat org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1009)\n   [junit4]   2> \t\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:135)\n   [junit4]   2> \t\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:116)\n   [junit4]   2> \t\tat org.eclipse.jetty.server.Server.handle(Server.java:368)\n   [junit4]   2> \t\tat org.eclipse.jetty.server.AbstractHttpConnection.handleRequest(AbstractHttpConnection.java:489)\n   [junit4]   2> \t\tat org.eclipse.jetty.server.AbstractHttpConnection.headerComplete(AbstractHttpConnection.java:942)\n   [junit4]   2> \t\tat org.eclipse.jetty.server.AbstractHttpConnection$RequestHandler.headerComplete(AbstractHttpConnection.java:1004)\n   [junit4]   2> \t\tat org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:640)\n   [junit4]   2> \t\tat org.eclipse.jetty.http.HttpParser.parseAvailable(HttpParser.java:235)\n   [junit4]   2> \t\tat org.eclipse.jetty.server.AsyncHttpConnection.handle(AsyncHttpConnection.java:82)\n   [junit4]   2> \t\tat org.eclipse.jetty.io.nio.SelectChannelEndPoint.handle(SelectChannelEndPoint.java:628)\n   [junit4]   2> \t\tat org.eclipse.jetty.io.nio.SelectChannelEndPoint$1.run(SelectChannelEndPoint.java:52)\n   [junit4]   2> \t\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:608)\n   [junit4]   2> \t\tat org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:543)\n   [junit4]   2> \t\tat java.lang.Thread.run(Thread.java:744)\n   [junit4]   2> \t\n   [junit4]   2> 16264 T30 oas.SolrTestCaseJ4.tearDown ###Ending testChildDoctransformer\n   [junit4]   2> NOTE: reproduce with: ant test  -Dtestcase=SolrExampleXMLTest -Dtests.method=testChildDoctransformer -Dtests.seed=720251997BEC4F70 -Dtests.slow=true -Dtests.locale=sk -Dtests.timezone=Pacific/Fiji -Dtests.file.encoding=UTF-8\n   [junit4] ERROR   0.96s J1 | SolrExampleXMLTest.testChildDoctransformer <<<\n\n...\n\n   [junit4] Tests with failures:\n   [junit4]   - org.apache.solr.client.solrj.embedded.SolrExampleStreamingTest.testChildDoctransformer\n   [junit4]   - org.apache.solr.client.solrj.SolrExampleXMLTest.testChildDoctransformer\n\n\n "
        },
        {
            "author": "Varun Thacker",
            "id": "comment-14005151",
            "date": "2014-05-21T19:54:41+0000",
            "content": "Fixed the class cast exception.\n\nThis passes for me now -\n\n \nant test -Dtests.method=testChildDoctransformer -Dtests.seed=720251997BEC4F70 -Dtests.slow=true -Dtests.locale=sk -Dtests.timezone=Pacific/Fiji -Dtests.file.encoding=UTF-8\n\n\n\nAlso ran it over 20 times and it is passing. "
        },
        {
            "author": "Hoss Man",
            "id": "comment-14005273",
            "date": "2014-05-21T21:38:48+0000",
            "content": "Hey Varun,\n\nI'd started looking ~ChildDocTransformerFactory.java:142 before i saw your new patch \u2013 comparing the old code with the new code it still seems like this is more brittle than it needs to be (particularly in cases where the uniqueKey field type isn't a string \u2013 ie: a TrieIntField)\n\nI've attached an update that eliminates (most) of that brittle casting code to rely on the FieldType methods instead ... i still want to review the rest of the patch in more depth, but i wanted to go ahead and attach this update ASAP so you could take a look (and because i'm not sure how much more patch reviewing time i'll get in before i leave town tomorrow)\n\n\n "
        },
        {
            "author": "Hoss Man",
            "id": "comment-14005349",
            "date": "2014-05-21T22:48:43+0000",
            "content": "\nWhy is the tag name in the JSON format \"childDocs\" but in the XML format it's \"childDoc\" (no plural) ? ... seems like those should be consistent.\n\nI guess because in JSON the input is a JSON array hence \"childDocs\", while in XML we use multiple \"childDoc\" tags to represent nested documents.\n\nThat makes sense \u2013 but now has me thinking back to the proposed usage in your earliest comment on this issue: why create a new <childDoc> element in the XML at all? why not just re-use <doc> (nested inside the existing <doc>) ... that seems like the most straight forward solution, and from what i can tell, that would probably simplify the changes to XMLResponseParser.java as well wouldn't it?\n\nspeaking of which \u2013 i don't understand the need for changing the method sig for XMLResponseParser.readDocument ... why can't the method construct the SolrDocument objects itself?\n\nAdded a non mandatory parameter called \"numChildDocs\" which makes it configurable. Although I'm not sure if the name is correct.\n\nhmmm, yeah ... for consistency with the top level query we could use something like \"rows\" but the risk for confusion there seems like it outweighs the consistency factor.\n\nhow about \"limit\" ?\n\nAdded a non mandatory parameter called \"childFilter\" ...\n\nlook good ... in general ChildDocTransformerFactory looks pretty good to me now \u2013 although I just noticed a typo in the SolrException msg if parentFilter is null ... it refers to \"which\" \u2013 but that doesn't apply here.\n\n2. Created a new binary file for backcompatibility and forwardcompatibility.\n\nI might be missing something, buti don't think testBackCompatForSolrDocumentWithChildDocs is actually asserting anything related to the child docs \u2013 because it uses assertSolrDocumentEquals, but that method hasn't been updated to know about child docs, has it?\n\n\n\nTo sum up:\n\n\n\tIn general, i think the current patch looks great\n\tremaining concerns about implementation:\n\t\n\t\ttestBackCompatForSolrDocumentWithChildDocs doesn't seem valid to me w/o changes to assertSolrDocumentEquals\n\t\terr msg typo in ChildDocTransformerFactory needs fixed\n\t\tmethod sig change in XMLResponseParser.readDocument seems unneccesasary\n\t\n\t\n\tremaining questions about the API:\n\t\n\t\tbetter name for numChildDocs ? ... how about limit ?\n\t\twhy use <childDoc> in XML instead of <doc> ?\n\t\n\t\n\n "
        },
        {
            "author": "Varun Thacker",
            "id": "comment-14005648",
            "date": "2014-05-22T06:05:38+0000",
            "content": "testBackCompatForSolrDocumentWithChildDocs doesn't seem valid to me w/o changes to assertSolrDocumentEquals\n\nFixed assertSolrDocumentEquals. I had overlooked it. Thanks\n\nerr msg typo in ChildDocTransformerFactory needs fixed\nFixed\n\nmethod sig change in XMLResponseParser.readDocument seems unneccesasary\n\nFixed. I was experimenting with some other way but with the current implementation the method signature doesn't need to be changed.\n\nbetter name for numChildDocs ? ... how about limit ?\n\n+1 to limit. I never liked numChildDocs. Changed it to limit.\n\nwhy use <childDoc> in XML instead of <doc> ?\n\nAgreed. We should use  <doc>. Even when a user inputs the nested documents in XML no special <childDoc> is used. Fixed XMLWriter and XMLResponseParser.\n\nAlso I changed the JSON ouput array key from \n\nchildDocs\n\n to \n\n_childDocuments_ \n\n This keeps it consistent with the input JSON with child documents. "
        },
        {
            "author": "Arcadius Ahouansou",
            "id": "comment-14005678",
            "date": "2014-05-22T07:04:42+0000",
            "content": "Hi Varun Thacker\nI am experimenting with this patch and I have a quick question:\nI have applied the patch https://issues.apache.org/jira/secure/attachment/12646085/SOLR-5285.patch to  trunk.\n\nI have indexed the json file \n\n[\n   {\n      \"id\":\"0\",\n      \"content_type\":\"level-0\",\n      \"_childDocuments_\":[\n         {\n            \"id\":\"1\",\n            \"content_type\":\"level-1\",\n            \"_childDocuments_\":[\n               {\n                  \"id\":\"2\",\n                  \"content_type\":\"level-2\",\n                  \"_childDocuments_\":[\n                     {\n                        \"id\":\"3\",\n                        \"content_type\":\"level-3\"\n                     }\n                  ]\n               }\n            ]\n         }\n      ]\n   }\n]\n\n\n\nwhen I query through\nhttp://localhost:8983/solr/collection1/select?q=*:*&wt=json&indent=true&fl=*,[child%20parentFilter=%22content_type:level-0%22]&fq=content_type:level-0\n\nI get back\n\n{\n   \"responseHeader\":{\n      \"status\":0,\n      \"QTime\":1,\n      \"params\":{\n         \"fl\":\"*,[child parentFilter=\\\"content_type:level-0\\\"]\",\n         \"indent\":\"true\",\n         \"q\":\"*:*\",\n         \"wt\":\"json\",\n         \"fq\":\"content_type:level-0\"\n      }\n   },\n   \"response\":{\n      \"numFound\":1,\n      \"start\":0,\n      \"docs\":[\n         {\n            \"id\":\"0\",\n            \"content_type\":[\n               \"level-0\"\n            ],\n            \"_version_\":1468783944507850752,\n            \"childDocs\":[\n               {\n                  \"id\":\"3\",\n                  \"content_type\":[\n                     \"level-3\"\n                  ]\n               },\n               {\n                  \"id\":\"2\",\n                  \"content_type\":[\n                     \"level-2\"\n                  ]\n               },\n               {\n                  \"id\":\"1\",\n                  \"content_type\":[\n                     \"level-1\"\n                  ]\n               }\n            ]\n         }\n      ]\n   }\n}\n\n\n\nIs this the expected output or a bug or am I doing something wrong?\nI would have thought that the hierarchy would be preserved.\n\nThanks. "
        },
        {
            "author": "Varun Thacker",
            "id": "comment-14005689",
            "date": "2014-05-22T07:26:57+0000",
            "content": "Hi Arcadius Ahouansou,\n\nThanks for trying out the patch.\n\nYes this is expected behaviour. Although one can index an entire hierarchy the final result will be a flat list. This has been discussed in the comments on the issue. \n\nThe reason for this is in lucene stored the parent document and all its child document in one 'block' and uses this property of storing to do fast joins. Here is a good blog post which explains the mechanism better - http://blog.mikemccandless.com/2012/01/searching-relational-content-with.html\n\nWere you just testing or is there a particular use case which needs this hierarchy to be maintained. "
        },
        {
            "author": "Varun Thacker",
            "id": "comment-14005690",
            "date": "2014-05-22T07:27:53+0000",
            "content": "Correct patch with all the changes. "
        },
        {
            "author": "Arcadius Ahouansou",
            "id": "comment-14005716",
            "date": "2014-05-22T08:22:17+0000",
            "content": "Hi Varun Thacker\nYes, in my use case, we need to preserve the hierarchy.\n\nI  believe it is a good idea to preserve the structure of the hierarchy in the response, or at least, provide the option to preserve it.\n\nIt makes more sense IMHO.\n\nIs it an expensive operation?\n "
        },
        {
            "author": "Varun Thacker",
            "id": "comment-14008366",
            "date": "2014-05-25T16:00:21+0000",
            "content": "Hi Arcadius Ahouansou,\n\nIn Lucene the documents are stored in one 'block' which consists of the parent document and the child documents. It's just 1 level and thus the hierarchy will not get preserved.\n\nYou could create a Lucene Jira for it and patches are always welcome  "
        },
        {
            "author": "Arcadius Ahouansou",
            "id": "comment-14011030",
            "date": "2014-05-28T11:38:05+0000",
            "content": "Hi Varun Thacker,\nI tried \n\nfacet=true&facet.field=content_type\n\n \nThe facet count for children was always 0.\nIs this a feature?\nThanks. "
        },
        {
            "author": "Mikhail Khludnev",
            "id": "comment-14011414",
            "date": "2014-05-28T18:23:37+0000",
            "content": "Arcadius Ahouansou it's SOLR-5743 . Not much progress so far. I'm expecting some movement during this year. "
        },
        {
            "author": "Hoss Man",
            "id": "comment-14020371",
            "date": "2014-06-06T21:04:17+0000",
            "content": "Correct patch with all the changes.\n\nThis looks solid to me ... running tests now "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14020487",
            "date": "2014-06-06T22:44:03+0000",
            "content": "Commit 1601028 from hossman@apache.org in branch 'dev/trunk'\n[ https://svn.apache.org/r1601028 ]\n\nSOLR-5285: Added a new [child ...] DocTransformer for optionally including Block-Join decendent documents inline in the results of a search "
        },
        {
            "author": "Hoss Man",
            "id": "comment-14020521",
            "date": "2014-06-06T23:19:40+0000",
            "content": "I've backported to 4x and am running the tests now \u2013 but while backporting i noticed something i overlooked when reviewing the patch: the ChildDocTransformerFactory usage of FieldType.toExternal & FieldType.getFieldQuery from my May 21th patch some how got lost along the way, so this is still brittle in how it deals with the primaryKey field.\n\nonce i've finished backporting the current trunk state to 4x, i'll try to fix that before resolving this issue. "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14020542",
            "date": "2014-06-06T23:42:58+0000",
            "content": "Commit 1601037 from hossman@apache.org in branch 'dev/branches/branch_4x'\n[ https://svn.apache.org/r1601037 ]\n\nSOLR-5285: Added a new [child ...] DocTransformer for optionally including Block-Join decendent documents inline in the results of a search (merge r1601028) "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14020596",
            "date": "2014-06-07T00:48:49+0000",
            "content": "Commit 1601044 from hossman@apache.org in branch 'dev/trunk'\n[ https://svn.apache.org/r1601044 ]\n\nSOLR-5285: use FieldType methods to be less brittle "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14020638",
            "date": "2014-06-07T01:45:25+0000",
            "content": "Commit 1601052 from hossman@apache.org in branch 'dev/branches/branch_4x'\n[ https://svn.apache.org/r1601052 ]\n\nSOLR-5285: use FieldType methods to be less brittle (merge r1601044) "
        },
        {
            "author": "Varun Thacker",
            "id": "comment-14020948",
            "date": "2014-06-07T20:08:51+0000",
            "content": "Documentation we should add to the ref guide under - https://cwiki.apache.org/confluence/display/solr/Common+Query+Parameters\n\n\n[child]\n\nDocTransformer for optionally including Block-Join decendent documents inline in the results of a search. This transformer returns all descendants of each parent document in a flat list nested inside the parent document. This is useful when you have indexed nested child documents and want to retrieve the child documents for the relavant parent documents for any type of search query. Supported response formats are -  xml, json, and javabin\n\nUsage example -\n\n[child parentFilter=\"fieldName:fieldValue\"]\n\n\n\n[child parentFilter=\"fieldName:fieldValue\" childFilter=\"fieldName:fieldValue\"]\n\n\n\n[child parentFilter=\"fieldName:fieldValue\" childFilter=\"fieldName:fieldValue\" limit=20]\n\n\n\nMandatory -\n\n\tThe \"parentFilter\" parameter is mandatory. This condition should identify only child documents.\n\n\n\nOptional -\n\n\tThe \"childFilter\" parameter is used to filter out which child documents should be returned.\n\tThe \"limit\" parameter which provides an option to specify the number of child documents to be returned per parent document. By default it's set to 10.\n\n "
        },
        {
            "author": "Hoss Man",
            "id": "comment-14034635",
            "date": "2014-06-18T00:10:47+0000",
            "content": "I documented on the newly created page for doc transformers...\n\nhttps://cwiki.apache.org/confluence/display/solr/Transforming+Result+Documents "
        }
    ]
}