{
    "id": "SOLR-7291",
    "title": "ChaosMonkey should create more mayhem with ZK availability",
    "details": {
        "components": [],
        "type": "Improvement",
        "labels": "",
        "fix_versions": [
            "5.1",
            "6.0"
        ],
        "affect_versions": "None",
        "status": "Closed",
        "resolution": "Fixed",
        "priority": "Minor"
    },
    "description": "Some things ChaosMonkey and it's users can do:\n\n\n\tIt should stop, pause and restart ZK once in a while\n\tTests using CM should check with indexing stalling when this happens",
    "attachments": {
        "SOLR-7291.patch": "https://issues.apache.org/jira/secure/attachment/12706707/SOLR-7291.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2015-03-23T20:10:26+0000",
            "author": "Ramkumar Aiyengar",
            "content": "Initial patch, this adds a ZK stop/pause/restart, while restricting so timeout for the cloudClient to a value less than the pause. If indexing stalls, this should trigger soTimeout's and fail indexing.. (or so I think..)\n\nIdeally I would like to move this to chaosMonkey.. I am for some reason not able to reuse the zkServer object to stop/restart ZK, which will make this a lot simpler. Not sure why just\n\n\nzkServer.shutdown();\nzkServer.run()\n\n\n\ndoesn't work..\n\nAlso, did s/Stopable/Stoppable/ for a few classes.. ",
            "id": "comment-14376541"
        },
        {
            "date": "2015-03-23T23:07:17+0000",
            "author": "Ramkumar Aiyengar",
            "content": "Does anyone know the intended difference between the ChaosMonkeyNothingIsSafeTest and ChaosMonkeySafeLeaderTest? Is it just that in one case the leaders can be killed while the leaders are safe in the other? If that's the case, the tests seem to be subtly diverged. In any case, given that leaders are only randomly killed, wouldn't the first be a superset of the other? ",
            "id": "comment-14376868"
        },
        {
            "date": "2015-03-24T12:56:17+0000",
            "author": "Mark Miller",
            "content": "There are various differences between them. I think only one of them uses ConcurrentSolrClient for example.\n\nThe basic idea is that one will never kill leaders and one will. It's not really intended that they stay in sync.\n\nOne is focused on finding and highlighting issues with recovery that should not involve leader election.\n\nThe other one is for more full, anything goes stuff. ",
            "id": "comment-14377796"
        },
        {
            "date": "2015-03-24T13:01:57+0000",
            "author": "Mark Miller",
            "content": "In any case, given that leaders are only randomly killed, wouldn't the first be a superset of the other?\n\nOne super set test makes it very hard to debug and fix issues. I actually run variations of both of these tests on my jenkins when hunting down failures so that I can narrow down what behavior things fail under. I'd have a lot more of them focused on more subsets, but even these 2 get so little time that it's just not worth it yet. Trying to separate out leader election at the high level has proved very helpful so far though.\n\nAnyway, when the safe leader test fails and the leader kill test is not failing, you can bet you get to just focus on the recovery from leader path. When leaders go down in these tests, it's also many times hard to catch an issue as the leader sync sequence can repair and hide problems.\n\nThe fails can be so infrequent, to hunt them you need either / or a test beasting script and jenkins running just the chaosmonkey tests. I run them in a few variations, nightly and regular. When my local jenkins machine is up and running that is. ",
            "id": "comment-14377806"
        },
        {
            "date": "2015-03-24T21:27:36+0000",
            "author": "Ramkumar Aiyengar",
            "content": "Thanks Mark, that explains why the two tests should run in the same test run. What that also means is that it should be possible to reuse the parts which should be the same.. From what you describe, there are two aspects to this test:\n\n\n\tWhat gets done (indexing, searching, \"full throttle\" operations using cuss)\n\tWhat gets monkeyed with (slaves, leaders, ZK..)\n\n\n\nYou need to pick a subset of stuff from each line and run the test. Currently we do two configurations, but there could be more if we need them..\n\nI will see if I can change the code to reflect that. Currently there are differences in how the tests are set up outside these params, which seems unintended. ",
            "id": "comment-14378665"
        },
        {
            "date": "2015-03-25T00:03:35+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1669026 from Ramkumar Aiyengar in branch 'dev/trunk'\n[ https://svn.apache.org/r1669026 ]\n\nSOLR-7291: Test indexing on ZK disconnect with ChaosMonkey tests ",
            "id": "comment-14378965"
        },
        {
            "date": "2015-03-27T21:01:57+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1669687 from Ramkumar Aiyengar in branch 'dev/branches/branch_5x'\n[ https://svn.apache.org/r1669687 ]\n\nSOLR-7291: Test indexing on ZK disconnect with ChaosMonkey tests ",
            "id": "comment-14384647"
        },
        {
            "date": "2015-04-12T04:43:58+0000",
            "author": "Shalin Shekhar Mangar",
            "content": "This went into 5.1 right? Can we close this? Also, is this also the reason why we're seeing more chaos monkey failures these days? ",
            "id": "comment-14491326"
        },
        {
            "date": "2015-04-12T07:45:05+0000",
            "author": "Ramkumar Aiyengar",
            "content": "I think so. I was looking to push the zk disconnect into ChaosMonkey class itself as a part of its loop after the current failures had reduced, but that can go in as a separate issue.\n.\nAnd no, I don't think this is the reason because the ZK disconnect happens outside the chaos loop after the 'we expect some failures' check is done. I did have to reduce the socket timeout and that could impact things, but again, the frequency of failures actually hasn't increased much as far as I can see after the change. The main increase was before.. ",
            "id": "comment-14491364"
        },
        {
            "date": "2015-04-15T00:30:51+0000",
            "author": "Timothy Potter",
            "content": "Bulk close after 5.1 release ",
            "id": "comment-14495375"
        }
    ]
}