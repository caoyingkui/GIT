{
    "id": "LUCENE-949",
    "title": "AnalyzingQueryParser can't work with leading wildcards.",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [
            "core/queryparser"
        ],
        "type": "Bug",
        "fix_versions": [
            "4.4",
            "6.0"
        ],
        "affect_versions": "2.2",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "The getWildcardQuery mehtod in AnalyzingQueryParser.java need the following changes to accept leading wildcards:\n\n\tprotected Query getWildcardQuery(String field, String termStr) throws ParseException\n\t{\n\t\tString useTermStr = termStr;\n\t\tString leadingWildcard = null;\n\t\tif (\"*\".equals(field))\n\t\t{\n\t\t\tif (\"*\".equals(useTermStr))\n\t\t\t\treturn new MatchAllDocsQuery();\n\t\t}\n\t\tboolean hasLeadingWildcard = (useTermStr.startsWith(\"*\") || useTermStr.startsWith(\"?\")) ? true : false;\n\n\t\tif (!getAllowLeadingWildcard() && hasLeadingWildcard)\n\t\t\tthrow new ParseException(\"'*' or '?' not allowed as first character in WildcardQuery\");\n\n\t\tif (getLowercaseExpandedTerms())\n\t\t{\n\t\t\tuseTermStr = useTermStr.toLowerCase();\n\t\t}\n\n\t\tif (hasLeadingWildcard)\n\t\t{\n\t\t\tleadingWildcard = useTermStr.substring(0, 1);\n\t\t\tuseTermStr = useTermStr.substring(1);\n\t\t}\n\n\t\tList tlist = new ArrayList();\n\t\tList wlist = new ArrayList();\n\t\t/*\n\n\tsomewhat a hack: find/store wildcard chars in order to put them back\n\tafter analyzing\n\t\t */\n\t\tboolean isWithinToken = (!useTermStr.startsWith(\"?\") && !useTermStr.startsWith(\"*\"));\n\t\tisWithinToken = true;\n\t\tStringBuffer tmpBuffer = new StringBuffer();\n\t\tchar[] chars = useTermStr.toCharArray();\n\t\tfor (int i = 0; i < useTermStr.length(); i++)\n\t\t{\n\t\t\tif (chars[i] == '?' || chars[i] == '*')\n\t\t\tUnknown macro: {\t\t\t\tif (isWithinToken)\t\t\t\t{\n\t\t\t\t\ttlist.add(tmpBuffer.toString());\n\t\t\t\t\ttmpBuffer.setLength(0);\n\t\t\t\t}\t\t\t\tisWithinToken = false;\t\t\t} \n\t\t\telse\n\t\t\tUnknown macro: {\t\t\t\tif (!isWithinToken)\t\t\t\t{\n\t\t\t\t\twlist.add(tmpBuffer.toString());\n\t\t\t\t\ttmpBuffer.setLength(0);\n\t\t\t\t}\t\t\t\tisWithinToken = true;\t\t\t} \n\t\t\ttmpBuffer.append(chars[i]);\n\t\t}\n\t\tif (isWithinToken)\n\t\t{\n\t\t\ttlist.add(tmpBuffer.toString());\n\t\t}\n\t\telse\n\t\t{\n\t\t\twlist.add(tmpBuffer.toString());\n\t\t}\n\n\n\n\t\t// get Analyzer from superclass and tokenize the term\n\t\tTokenStream source = getAnalyzer().tokenStream(field, new StringReader(useTermStr));\n\t\torg.apache.lucene.analysis.Token t;\n\n\t\tint countTokens = 0;\n\t\twhile (true)\n\t\t{\n\t\t\ttry\n\t\t\t{\n\t\t\t\tt = source.next();\n\t\t\t}\n\t\t\tcatch (IOException e)\n\t\t\t{\n\t\t\t\tt = null;\n\t\t\t}\n\t\t\tif (t == null)\n\t\t\t{\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (!\"\".equals(t.termText()))\n\t\t\t{\n\t\t\t\ttry\n\t\t\t\t{\n\t\t\t\t\ttlist.set(countTokens++, t.termText());\n\t\t\t\t}\n\t\t\t\tcatch (IndexOutOfBoundsException ioobe)\n\t\t\t\t{\n\t\t\t\t\tcountTokens = -1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\ttry\n\t\t{\n\t\t\tsource.close();\n\t\t}\n\t\tcatch (IOException e)\n\t\t{\n\t\t\t// ignore\n\t\t}\n\n\t\tif (countTokens != tlist.size())\n\t\t{\n\t\t\t/*\n\t\t\t * this means that the analyzer used either added or consumed\n\t\t\t * (common for a stemmer) tokens, and we can't build a WildcardQuery\n\t\t\t */\n\t\t\tthrow new ParseException(\"Cannot build WildcardQuery with analyzer \" + getAnalyzer().getClass()\n\t\t\t\t\t+ \" - tokens added or lost\");\n\t\t}\n\n\t\tif (tlist.size() == 0)\n\t\t{\n\t\t\treturn null;\n\t\t}\n\t\telse if (tlist.size() == 1)\n\t\t{\n\t\t\tif (wlist.size() == 1)\n\t\t\t{\n\t\t\t\t/*\n\n\tif wlist contains one wildcard, it must be at the end,\n\tbecause: 1) wildcards at 1st position of a term by\n\tQueryParser where truncated 2) if wildcard was not in end,\n\tthere would be two or more tokens\n\t\t\t\t */\n\t\t\t\tStringBuffer sb = new StringBuffer();\n\t\t\t\tif (hasLeadingWildcard)\n\t\t\t\t{\n\t\t\t\t\t// adding leadingWildcard\n\t\t\t\t\tsb.append(leadingWildcard);\n\t\t\t\t}\n\t\t\t\tsb.append((String) tlist.get(0));\n\t\t\t\tsb.append(wlist.get(0).toString());\n\t\t\t\treturn super.getWildcardQuery(field, sb.toString());\n\t\t\t}\n\t\t\telse if (wlist.size() == 0 && hasLeadingWildcard)\n\t\t\t{\n\t\t\t\t/*\n\t\t\t\t * if wlist contains no wildcard, it must be at 1st position\n\t\t\t\t */\n\t\t\t\tStringBuffer sb = new StringBuffer();\n\t\t\t\tif (hasLeadingWildcard)\n\t\t\t\t{\t\t\t\t\t// adding leadingWildcard\t\t\t\t\tsb.append(leadingWildcard);\t\t\t\t}\n\t\t\t\tsb.append((String) tlist.get(0));\n\t\t\t\tsb.append(wlist.get(0).toString());\n\t\t\t\treturn super.getWildcardQuery(field, sb.toString());\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\t/*\n\t\t\t\t * we should never get here! if so, this method was called with\n\t\t\t\t * a termStr containing no wildcard ...\n\t\t\t\t */\n\t\t\t\tthrow new IllegalArgumentException(\"getWildcardQuery called without wildcard\");\n\t\t\t}\n\t\t}\n\t\telse\n\t\t{\n\t\t\t/*\n\tthe term was tokenized, let's rebuild to one token with wildcards\n\tput back in postion\n\t\t\t */\n\t\t\tStringBuffer sb = new StringBuffer();\n\t\t\tif (hasLeadingWildcard)\n\t\t\t{\n\t\t\t\t// adding leadingWildcard\n\t\t\t\tsb.append(leadingWildcard);\n\t\t\t}\n\t\t\tfor (int i = 0; i < tlist.size(); i++)\n\t\t\tUnknown macro: {\t\t\t\tsb.append((String) tlist.get(i));\t\t\t\tif (wlist != null && wlist.size() > i)\t\t\t\t{\n\t\t\t\t\tsb.append((String) wlist.get(i));\n\t\t\t\t}\t\t\t} \n\t\t\treturn super.getWildcardQuery(field, sb.toString());\n\t\t}\n\t}",
    "attachments": {
        "LUCENE-949.patch": "https://issues.apache.org/jira/secure/attachment/12579378/LUCENE-949.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2011-01-26T09:13:41+0000",
            "content": "Way outdated code and it's not really clear what needs to be done. If this is still a problem, I suggest reopening and post a proper patch. ",
            "author": "Shai Erera",
            "id": "comment-12986910"
        },
        {
            "date": "2011-09-20T07:18:04+0000",
            "content": "Hi.\n\nIs there some way to re-open and fix this behavior/bug in AnalyzingQueryParser?\nI have discover this opened (and closed 4 years later) bug. We are working with Lucene 3.2 and we use AnalyzingQueryParser because we need to parse with analyzer every query, even wildcard queries. \n\nThis works great with most queries, and with the ones that don't work (for example in cases analyzer add/remove words and query have wildcards) we use QueryParser although it doesn't analyze wildcard queries.\n\nIn our application there are some cases when we need to allow leading wildcard queries, and AnalyzingQueryParser fails although I set to true 'AllowLeadingWildcard' flag. Strings like 'ucene' is converted into WildcardQuery like this 'ucene'. This is another strange behavior, the ending wildcard.\n\nI know QueryParser doesn't have this leading wildcard bug, but I need to parse query (I am Spanish and we have special characters (\u00f1, \u00fc, vocals with accent on them) and we parse indexed data, and to search we need to parse query too.\n\n\n\nThanks in advance. Regards!\n ",
            "author": "David Herrera",
            "id": "comment-13108413"
        },
        {
            "date": "2011-09-20T07:22:04+0000",
            "content": "Sorry, is my first post here and I didn't know special characters like \n\n*\n\n is bold. For that mistake, in my previous comment there one bold line that I didn't want to be bold. This is what I want to put:\n\n\n'*ucene' is converted into WildcardQuery like this 'ucene*'\n ",
            "author": "David Herrera",
            "id": "comment-13108415"
        },
        {
            "date": "2013-04-02T17:36:16+0000",
            "content": "Reopening at the request of [~tallison@mitre.org] who intends to attach a patch.  Regular users can't re-open JIRA issues, apparently. ",
            "author": "David Smiley",
            "id": "comment-13620032"
        },
        {
            "date": "2013-04-02T17:40:15+0000",
            "content": "This allows for leading wildcards in the AnalyzingQueryParser if setAllowLeadingWildcard is set to true.   ",
            "author": "Tim Allison",
            "id": "comment-13620036"
        },
        {
            "date": "2013-04-09T13:33:00+0000",
            "content": "Hello Timothy, can you turn these changes into a patch?\n\nSee http://wiki.apache.org/lucene-java/HowToContribute#Creating_a_patch\n\nThanks! ",
            "author": "Robert Muir",
            "id": "comment-13626606"
        },
        {
            "date": "2013-04-11T20:42:43+0000",
            "content": "First patch.  Let me know if this actually works. ",
            "author": "Tim Allison",
            "id": "comment-13629337"
        },
        {
            "date": "2013-04-12T16:03:17+0000",
            "content": "Thank you Timothy. the patch looks very good to me, thanks also for adding tests!\n\nA few questions:\n\n\tThe regex simplification looks good to me, but I'm not a regex expert. Maybe someone that is better with regex like Steve Rowe can have a look. If nobody objects after a few days I'm inclined to move forward though.\n\tWhat about the case where someone has escaped wildcards? I'm not sure whats even happening today in this case... perhaps it already has surprising behavior and should really be a separate bug, or maybe its working and I just dont see it. I doubt its tested though... but it seems the regex would need to accomodate that?\n\tThe String.format() invocations should probably pass getLocale() from the superclass as the first argument, rather than depending on the default locale. Since they are locale sensitive I think its best to use the one that someone configured on the queryparser (e.g. via setLocale)\n\n ",
            "author": "Robert Muir",
            "id": "comment-13630226"
        },
        {
            "date": "2013-04-12T17:15:52+0000",
            "content": "Hi Timothy, I agree with Robert, the patch reduces line count while improving clarity and adding functionality - sweet!\n\nA few nitpicks (+1 otherwise):\n\n\n\tYou don't handle escaped metachars ? and * in the query, though the original doesn't either, so this shouldn't stop the patch from being committed.\n\tThe (?s) has no effect in \"(?s)([^\\\\?\\\\*]+)\", since it only affects the expansion of the dot metachar, which isn't present (see http://docs.oracle.com/javase/6/docs/api/java/util/regex/Pattern.html#DOTALL): an inverted charset will always include newlines unless the charset to be inverted explicitly includes them.  Of course, this is all moot, since the query parser will already have split on whitespace before sending termStr to getWildcardQuery() \n\tYou can drop the following line in normalizeMustBeSingleTerm(): nonWildcardMatcher.reset(termStr);, since nonWildcardMatcher is never reused.\n\tThe presence of term breaking chars is not the only condition under which analysis of a single term can produce multiple terms (e.g. synonyms, multiple readings), so the following exception message should be generalized: \"There is a term breaking character between %s and %s\".\n\tIn your new test, the following assertion message seems to have too many words? \"Testing wildcard with wildcard with initial wildcard not allowed\"\n\n ",
            "author": "Steve Rowe",
            "id": "comment-13630354"
        },
        {
            "date": "2013-04-12T17:25:42+0000",
            "content": "One more minor thing: the javadoc on getWildcardQuery() needs fixing - probably previously should have been \"but not for <code>user*</code>\" to illustrate not being called for prefix queries, but with your patch it's just plain wrong:\n\n\n* Example: will be called for <code>H?user</code> or for <code>H*user</code> \n* but not for <code>*user</code>.\n\n ",
            "author": "Steve Rowe",
            "id": "comment-13630370"
        },
        {
            "date": "2013-04-18T17:49:40+0000",
            "content": "Thank you very much for the feedback. I refactored a bit and added escaped wildcard handling.  Let me know how this looks. ",
            "author": "Tim Allison",
            "id": "comment-13635415"
        },
        {
            "date": "2013-04-18T17:54:29+0000",
            "content": "Tim, thanks, I'll take a look at your new patch later today.\n\nFYI, you shouldn't remove old patches - when you upload a file with the same name, the older versions still appear, but their names appear in grey, and you can see the date/time each was uploaded.  See e.g. SOLR-3251, where I've uploaded the same-named patch multiple times. ",
            "author": "Steve Rowe",
            "id": "comment-13635425"
        },
        {
            "date": "2013-04-26T00:59:37+0000",
            "content": "Refactored a bit and added a few more tests. ",
            "author": "Tim Allison",
            "id": "comment-13642457"
        },
        {
            "date": "2013-05-06T07:11:39+0000",
            "content": "Hi [~tallison@mitre.org],\n\nSorry it took so long, I've attached a patch based on your patch with some fixes:\n\n\n\tRemoved tabs.\n\tRestored license header and class javadoc to AnalyzingQueryParser.java (your patch removed them for some reason?).\n\tConverted all code indentation to 2 spaces per level (you had a lot of 3 space per level indentation).\n\tConverted the wildcardPattern to allow anything to be escaped, not just backslashes and wildcard chars '?' and '*'.  Also removed the optional backslashes from group 2 (the actual wildcards) - when iterating over wildcardPattern matches, your patch would throw away any number of real wildcards following an escaped wildcard.  I added a test for this.\n\tWhen multiple output tokens are produced (and there should only be one), now reporting all of them in the exception message instead of just the first two.\n\tRemoved all references to \"chunklet\" in favor of \"output token\" - this non-standard terminology made the code harder to read.\n\tChanged descriptions of multiple output tokens to not necessarily be as the result of splitting (e.g. synonyms).\n\tIn analyzeSingleChunk(), moved exception throwing to the source of problems.\n\n\n\nI also added a CHANGES.txt entry.  \n\nTim, let me know if you think my changes are okay - if so, I think it's ready to commit. ",
            "author": "Steve Rowe",
            "id": "comment-13649555"
        },
        {
            "date": "2013-05-06T07:20:08+0000",
            "content": "One other change I forgot to mention, Tim: I substituted MockAnalyzer where you used StandardAnalyzer in the test code - this allowed me to remove the analyzers-common dependency you introduced (and also the memory dependency, which didn't seem to be used for anything in your patch). ",
            "author": "Steve Rowe",
            "id": "comment-13649560"
        },
        {
            "date": "2013-05-06T11:40:14+0000",
            "content": "Steve, no problem on the delay.  Thank you for your help!  Changes sound great.  Thank you.\n ",
            "author": "Tim Allison",
            "id": "comment-13649670"
        },
        {
            "date": "2013-05-06T23:03:19+0000",
            "content": "Committed to trunk and branch_4x.\n\nThanks Tim! ",
            "author": "Steve Rowe",
            "id": "comment-13650208"
        },
        {
            "date": "2013-05-10T22:57:23+0000",
            "content": "Although this is labelled as a Major Bug, it feels more like a new feature to me, so I'm not motivated to backport this to 4.3.1. ",
            "author": "Steve Rowe",
            "id": "comment-13654988"
        },
        {
            "date": "2013-07-23T18:36:59+0000",
            "content": "Bulk close resolved 4.4 issues ",
            "author": "Steve Rowe",
            "id": "comment-13716708"
        }
    ]
}