{
    "id": "SOLR-5234",
    "title": "Allow SolrResourceLoader to load resources from URLs",
    "details": {
        "affect_versions": "None",
        "status": "Resolved",
        "fix_versions": [],
        "components": [],
        "type": "Improvement",
        "priority": "Minor",
        "labels": "",
        "resolution": "Won't Fix"
    },
    "description": "This would allow multiple solr instance to share large configuration files.  It would also help resolve problems caused by attempting to store >1Mb files in zookeeper.",
    "attachments": {
        "SOLR-5234.patch": "https://issues.apache.org/jira/secure/attachment/12602560/SOLR-5234.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Alan Woodward",
            "id": "comment-13764186",
            "date": "2013-09-11T10:23:00+0000",
            "content": "Quick n dirty patch.  It doesn't appear to break anything...\n\nUnresolved questions:\n\n\tI'm not sure how best to test the new functionality.  Do the Jenkins boxes even allow access to the internet?\n\tInteractions with SOLR-4882.  Maybe I should just disallow URLs that begin with \"file://\"?\n\n "
        },
        {
            "author": "Alan Woodward",
            "id": "comment-13767515",
            "date": "2013-09-14T16:02:18+0000",
            "content": "Anyone have any comments on this?  Chris Hostetter (Unused) or Mark Miller? "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13767532",
            "date": "2013-09-14T17:27:05+0000",
            "content": "Have not looked at the patch yet, but the feature sounds okay to me. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-13767533",
            "date": "2013-09-14T17:27:45+0000",
            "content": "I'm not sure how best to test the new functionality. \n\nJust an embedded jetty instance? "
        },
        {
            "author": "Alan Woodward",
            "id": "comment-13767883",
            "date": "2013-09-15T19:21:27+0000",
            "content": "New patch, with test for local URLs (thanks for the suggestion, Mark!) "
        },
        {
            "author": "Markus Jelsma",
            "id": "comment-13768616",
            "date": "2013-09-16T18:51:59+0000",
            "content": "So i assume this will provide a similar functionallity as SOLR-5234 when in cloud mode? "
        },
        {
            "author": "Alan Woodward",
            "id": "comment-13769289",
            "date": "2013-09-17T07:32:40+0000",
            "content": "Hi Markus, do you mean SOLR-5115?  It provides a superset of that functionality - absolute file:// URLs will work, but so will more general http:// URLs.  In our case, the latter is more useful as it allows us to store large files in one place, and not have to duplicate them across all nodes in the SolrCloud cluster (we also want to share some custom stemming dictionaries with other lucene-based services). "
        },
        {
            "author": "Noble Paul",
            "id": "comment-13769343",
            "date": "2013-09-17T09:01:07+0000",
            "content": "Is it always going to be loaded again and again when requested ?\nAny caching involved? If yes, how do you manage the TTL "
        },
        {
            "author": "Alan Woodward",
            "id": "comment-13769345",
            "date": "2013-09-17T09:05:49+0000",
            "content": "It doesn't do any caching in the code itself, it's just a call to URL.openStream().  If you want to cache resources you can put them behind Varnish or something similar. "
        },
        {
            "author": "Noble Paul",
            "id": "comment-13769370",
            "date": "2013-09-17T09:45:29+0000",
            "content": "Loading resources from urls can be expensive if there are too many calls\n\nWhat about consistency?\n\nSay, a core is loaded and the version of a resource is 'x' . after sometime a core is loaded and the version is x+1 . Is there a way for the user to know which is the version being loaded ? The point is , now I can take a look at the solrconfig.xml and see what is the current config. If I load it from a url, I have no way to see it "
        },
        {
            "author": "Markus Jelsma",
            "id": "comment-13769591",
            "date": "2013-09-17T15:12:21+0000",
            "content": "Yeah i meant 5115, silly me, i linked it myself! Thanks, will try to check it out later. "
        },
        {
            "author": "Alan Woodward",
            "id": "comment-13769866",
            "date": "2013-09-17T20:05:34+0000",
            "content": "I had more in mind things like resources specified in solrconfig.xml, files used to configure lemmatizers or whatever, rather than the whole solrconfig.xml itself.  Although I suppose it would work for that too.  But generally, you'd only be fetching things on core reload, which is an expensive operation anyway. "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13771032",
            "date": "2013-09-18T18:14:12+0000",
            "content": "Anyone have any comments on this?\n\nI'm not sure i really see a burning need for this, but i'm not opposed to it either.\n\njust do me one favor and update the docs about it to make it very clear how the remote URL is read ({@link} to URL.openStream and all that) so that people aren't asking questions about trying ot use credentials, or proxies or whatever.\n\nWhat about consistency?\n\nI'm not sure how that's any bigger of an issue with this patch then it is with local files \u2013 someone can always edit a file on disk after the core is laoded and you knave no way of being sure if the one in use is hte same as the one you see on disk. "
        },
        {
            "author": "Markus Jelsma",
            "id": "comment-13897813",
            "date": "2014-02-11T12:39:57+0000",
            "content": "Anything new on this one? We'd like to have http:// and file:// schema support in SolrResourceLoader. "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-13897988",
            "date": "2014-02-11T16:29:05+0000",
            "content": "Sorry, if we would allow to load arbitrary files from outside the instance directory by SolrResourceLoader, we would re-add the CVE security issues closed recently - so this is a no-go, see SOLR-4882.\n\nThe only possibility to add this would to restrict this feature strictly to an URL-prefix via config. "
        },
        {
            "author": "Alan Woodward",
            "id": "comment-13897993",
            "date": "2014-02-11T16:36:47+0000",
            "content": "Yeah, the reason I'd not committed it was due to SOLR-4882.\n\nMaybe there's a workaround with the allow.unsafe.resourceloading environment variable?  Or we could add a parameter to SolrResourceLoader.openResource() that says we allow unsafe loading for this call?  That way the various stemmers and other analysis components that are just loading text files can load from anywhere, but XSLT or anything else that loads and then runs executable code is suitably sandboxed. "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-13898000",
            "date": "2014-02-11T16:44:00+0000",
            "content": "This might be a possibility, but /etc/passwd is also a text file  ! We have to differentiate here between the two factors: \"who\" calls openResource for \"what\". If \"who\" is not coming from the network (e.g. it' triggered by a filename received via REST API), it is fine to load text files. But not if a velocity template tries to load /etc/passwd and send it to the client or if a input file xincludes some content.\nAlso the \"what\" should be restricted: Don't load XML files (unless you disable xinclude and external entities in XML) or other active contents from anywhere. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13898019",
            "date": "2014-02-11T16:57:12+0000",
            "content": "It doesn't seem like this would be a security issue since it's at a lower level (i.e. if an attacker can add something to ZK that points to /etc/passwd, then they can already do any number of bad things to the cluster).  It's like saying \"vi\" is a security risk because it can read your files. "
        },
        {
            "author": "Alan Woodward",
            "id": "comment-13898027",
            "date": "2014-02-11T17:00:47+0000",
            "content": "The problem comes when it's loading something like XML.  The CVE issue Uwe linked above is very clear (and slightly terrifying) about how you can break into a system running Solr if you can upload some XML somewhere onto the system - I had no idea that you could run arbitrary Java code within an XML parser, but it turns out you can! "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13898051",
            "date": "2014-02-11T17:29:46+0000",
            "content": "Let's take a more specific example and see if that represents a security risk:\nA field type in schema.xml containing a SynonymFilter loading a large synonym file from a shared NFS mount.\nIf that use case does not have any security issues, then we should figure out how to support it (and things like it). "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-13898968",
            "date": "2014-02-12T10:04:38+0000",
            "content": "It doesn't seem like this would be a security issue since it's at a lower level (i.e. if an attacker can add something to ZK that points to /etc/passwd, then they can already do any number of bad things to the cluster). It's like saying \"vi\" is a security risk because it can read your files.\n\nI agree, the example here was a little bit captious. The general problem is just parts of solr that allow to use absolute URIs coming from the network to load stuff via SolrResourceLoader. It is for sure no problem, if you might place an absolute URI inside solrconfig.xml, if that file is not modifiable through the REST API via network, which might be possible already or via new APIs that might be added later.\n\nThe idea of Alan Woodward is a great one. If we extend openResource API by adding the \"unsafe\" parameter to it (the proposed semantics are just not ideal) would help a lot. Stuff like Velocity or XSL's should not be allowed to escape the instance directory. But it is still risky to allow to load resources from anywhere. Before adding a feature like this, we should check every CVE, if it is really not possible to do the stuff. It should be possible to use the SolrResourceLoader in usafe wayy if you are really sure that nothing from the public REST APIs can access stuff like this without checks.\n\nThe important thing here is: We should not make Solr a wide-open gateway allowing to load resources from the outside without restrictions. The example you gave with loading a very large resource file from a NFS resource is different from the ability to load any resource from anywhere. We should be as safe as possible.\n\nUnless we have the ability to have access control to our network-accesible APIs, we should not open more holes like loading stuff from arbitrary URIs. "
        },
        {
            "author": "Alan Woodward",
            "id": "comment-13899293",
            "date": "2014-02-12T17:16:17+0000",
            "content": "This patch adds an ExternalResourceLoader class that checks to see if a resource name is a URL.  If it is, it opens it and returns that, otherwise it just passes things on to a delegate resource loader.\n\nIt also adds an argument 'allowExternalResources' to AbstractAnalysisFactory, which if set to true will wrap loaders passed to getLines() and friends in an ExternalResourceLoader.  This makes whether or not to allow URLs configurable on each entry in the schema.\n\nNeeds moar tests, of course.\n\nSeparately, should getWordSet and getSnowballWordSet be moved somewhere else?  They seem a bit specialized to be in AbstractAnalysisFactory. "
        },
        {
            "author": "Alan Woodward",
            "id": "comment-13912805",
            "date": "2014-02-26T12:00:23+0000",
            "content": "A more thoroughly tested patch\n\n\tadds a protected openResource(loader, resourcename) method to AbstractAnalysisFactory that wraps the loader in an ExternalResourceLoader if external resource loading is allowed\n\tSynonymFilterFactory uses this method to load it's resources now\n\n\n\nIt's probably worth going through the other FilterFactories and changing them to also use this base method as well. "
        },
        {
            "author": "Alan Woodward",
            "id": "comment-13912812",
            "date": "2014-02-26T12:18:01+0000",
            "content": "And this patch updates the four remaining ResourceLoaderAware factories that were directly calling loader.openResource().\n\nIs it possible to set up forbidden-APIs to say 'everything that extends AbstractAnalysisFactory should not use ResourceLoader.openResource()'?  That way we can ensure that all the filter factories use the base method instead. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13912815",
            "date": "2014-02-26T12:23:43+0000",
            "content": "I don't think we should forbid like that. Instead this is just a sign that the APIs are not quite right!\n "
        },
        {
            "author": "Alan Woodward",
            "id": "comment-13912865",
            "date": "2014-02-26T13:16:17+0000",
            "content": "I agree that it's clunky.\n\nHm, maybe we make TokenFilterFactory itself implement ResourceLoaderAware, and make inform() final there?  Which does the allowExternalResource checks, and then delegates the loader, wrapped or not, to an abstract doInform() class.  It's a back-compat breaking change though. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13912869",
            "date": "2014-02-26T13:17:50+0000",
            "content": "Just as a general thing, from my perspective I'd rather us backwards break and have a clean API, if thats what we need to do. "
        },
        {
            "author": "Alan Woodward",
            "id": "comment-13913144",
            "date": "2014-02-26T16:54:20+0000",
            "content": "I'd like to commit this for now, and open another JIRA to look at the TokenFilterFactory API; I really don't like backwards breaks in point releases, especially on something like this where client extensions are explicitly encouraged.  Does that seem reasonable? "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13913152",
            "date": "2014-02-26T16:58:01+0000",
            "content": "But its still a backwards break in that now factories are \"buggy\" if they dont call this superclass method, just a different type of API break.\n\nPersonally I'd really rather us have a clean API, but I won't block the change. "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-16607096",
            "date": "2018-09-07T12:59:46+0000",
            "content": "Are you still planning to do this Alan Woodward?\n\nI feel that perhaps BLOB store in .system collection would be a better place to upload large configs than having each Solr node reach out to an external system over the network, with all stability and security concerns that raises. Besides, the ZkResourceLoader supports fallback to local file system, so if you avoid uploading a large file to ZK but place it locally in SOLR_HOME instead, it would work. "
        },
        {
            "author": "Alan Woodward",
            "id": "comment-16607131",
            "date": "2018-09-07T13:37:27+0000",
            "content": "I think you're right Jan, I'll resolve as Won't Fix. "
        }
    ]
}