{
    "id": "SOLR-1395",
    "title": "Integrate Katta",
    "details": {
        "affect_versions": "1.4",
        "status": "Closed",
        "fix_versions": [
            "4.4"
        ],
        "components": [],
        "type": "New Feature",
        "priority": "Minor",
        "labels": "",
        "resolution": "Won't Fix"
    },
    "description": "We'll integrate Katta into Solr so that:\n\n\n\tDistributed search uses Hadoop RPC\n\n\n\n\n\tShard/SolrCore distribution and management\n\n\n\n\n\tZookeeper based failover\n\n\n\n\n\tIndexes may be built using Hadoop",
    "attachments": {
        "solr-1395-katta-0.6.3-6.patch": "https://issues.apache.org/jira/secure/attachment/12505075/solr-1395-katta-0.6.3-6.patch",
        "solr-1395-katta-0.6.2.patch": "https://issues.apache.org/jira/secure/attachment/12456924/solr-1395-katta-0.6.2.patch",
        "solr-1395-1431-4.patch": "https://issues.apache.org/jira/secure/attachment/12421144/solr-1395-1431-4.patch",
        "katta.node.properties": "https://issues.apache.org/jira/secure/attachment/12420837/katta.node.properties",
        "front-end.log": "https://issues.apache.org/jira/secure/attachment/12452378/front-end.log",
        "log4j-1.2.13.jar": "https://issues.apache.org/jira/secure/attachment/12419321/log4j-1.2.13.jar",
        "solr-1395-katta-0.6.3-5.patch": "https://issues.apache.org/jira/secure/attachment/12498997/solr-1395-katta-0.6.3-5.patch",
        "SOLR-1395.patch": "https://issues.apache.org/jira/secure/attachment/12418533/SOLR-1395.patch",
        "katta-core-0.6-dev.jar": "https://issues.apache.org/jira/secure/attachment/12420337/katta-core-0.6-dev.jar",
        "solr-1395-katta-0.6.3-4.patch": "https://issues.apache.org/jira/secure/attachment/12494591/solr-1395-katta-0.6.3-4.patch",
        "test-katta-core-0.6-dev.jar": "https://issues.apache.org/jira/secure/attachment/12420336/test-katta-core-0.6-dev.jar",
        "solr-1395-1431.patch": "https://issues.apache.org/jira/secure/attachment/12420800/solr-1395-1431.patch",
        "solr-1395-katta-0.6.2-3.patch": "https://issues.apache.org/jira/secure/attachment/12459219/solr-1395-katta-0.6.2-3.patch",
        "hadoop-core-0.19.0.jar": "https://issues.apache.org/jira/secure/attachment/12419322/hadoop-core-0.19.0.jar",
        "solr-1395-1431-3.patch": "https://issues.apache.org/jira/secure/attachment/12420836/solr-1395-1431-3.patch",
        "solr-1395-katta-0.6.3-7.patch": "https://issues.apache.org/jira/secure/attachment/12505440/solr-1395-katta-0.6.3-7.patch",
        "solr-1395-katta-0.6.2-2.patch": "https://issues.apache.org/jira/secure/attachment/12458718/solr-1395-katta-0.6.2-2.patch",
        "katta-solrcores.jpg": "https://issues.apache.org/jira/secure/attachment/12465203/katta-solrcores.jpg",
        "zookeeper-3.2.1.jar": "https://issues.apache.org/jira/secure/attachment/12419320/zookeeper-3.2.1.jar",
        "katta.zk.properties": "https://issues.apache.org/jira/secure/attachment/12420838/katta.zk.properties",
        "solr-1395-1431-katta0.6.patch": "https://issues.apache.org/jira/secure/attachment/12436343/solr-1395-1431-katta0.6.patch",
        "solr1395.jpg": "https://issues.apache.org/jira/secure/attachment/12480614/solr1395.jpg",
        "solr-1395-katta-0.6.2-1.patch": "https://issues.apache.org/jira/secure/attachment/12457647/solr-1395-katta-0.6.2-1.patch",
        "back-end.log": "https://issues.apache.org/jira/secure/attachment/12452379/back-end.log",
        "zkclient-0.1-dev.jar": "https://issues.apache.org/jira/secure/attachment/12420338/zkclient-0.1-dev.jar"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Noble Paul",
            "id": "comment-12749389",
            "date": "2009-08-31T05:57:58+0000",
            "content": "Why should this be a Solr issue? What is missing in Solr which prevents you from integrating katta into Solr as a some kind of plugin? "
        },
        {
            "author": "Jason Rutherglen",
            "id": "comment-12751145",
            "date": "2009-09-03T20:36:53+0000",
            "content": "This is our first cut at integrating Katta with Solr. The\nKattaClientTest test case shows a Katta cluster being created\nlocally, a couple of cores/shards being placed into the cluster,\nthen a query being executed that returns the correct number of\nresults. It takes about 30s - 1.5min to run (hopefully that can\nbe reduced?). \n\nToday Solr shards map to Solr servers. Here we map shards to\ncores, where there can be multiple shards per server or in Katta\nparlance a node. We assume the shards exist in Hadoop HDFS.\nKatta copies the shards to a local Solr server to make them\nsearchable (and incrementally updateable).\n\nInstructions for Installation\n\n\n\tDownload Katta trunk \"svn co\nhttps://katta.svn.sourceforge.net/svnroot/katta/trunk\nkattatrunk\". Download the KATTA-SOLR.patch to kattatrunk. run \"patch\n-p 0 -i KATTA-SOLR.patch\", \"ant -jar\", \"ant jar-test\".\n\n\n\n\n\tDownload a Solr trunk \"svn co\nhttp://svn.apache.org/repos/asf/lucene/solr/trunk solrtrunk\".\nCopy from kattatrunk: lib/log4j-1.2.13.jar\nlib/zookeeper-3.1.1.jar lib/hadoop-core-0.19.0.jar\nbuild/katta-core-0.6-dev.jar build/test-katta-core-0.6-dev.jar\nto solrtrunk/lib\n\n\n\n\n\tDownload SOLR-1395.patch to solrtrunk. Run \"patch -p 0 -i\nSOLR-1395.patch\". \n\n\n\n\n\tRun a test while in solrtrunk \"ant test-core\n-Dtestcase=KattaClientTest\"\n\n\n\nGeneral Notes\n\n\n\tSearchHandler's HttpCommComponent has been abstracted out.\nThere's a CommComponent interface, AbstractCommComponent\nimplements the generic multithreading ShardRequest ->\nShardResponse logic. EmbeddedSearchHandler executes requests on\na set of local cores. HttpCommComponent implements requests over\nHTTP. KattaCommComponent distributes requests using Katta's\nHadoop RPC mechanism.\n\n\n\n\n\tThe patch enables all of Solr's distributed request types. All\ncurrent distributed requests should work as is with no\nmodifications.\n\n\n\n\n\tShards/Solr cores may be managed dynamically and remotely\nadministered from a centralized location (whereas today Solr\ntypically requires SSHing and manually editing files etc)\n\n\n\n\n\tSolr Katta has built in failover, this is tested in\nKattaClientFailoverTest\n\n\n\n\n\tWhen a shard is deployed to a Solr server, the schema and\nsolrconfig are deployed with it. This begs the question of how\nupdates to the solrconfig and schema are deployed. Redeploying\nsolrconfig is fairly simple, whereas a schema change implies\nrecreating the entire shard.\n\n\n\n\n\tMaybe there's an easy way to interface with Hadoop index\ncreation (i.e. as easy as Solr's HTTP based update command)\n\n\n\nThe patch was created by Jason Venner and Jason Rutherglen\n "
        },
        {
            "author": "Stefan Groschupf",
            "id": "comment-12751980",
            "date": "2009-09-07T00:13:42+0000",
            "content": "Jason please note that the latest katta code is actually in sourceforges git repo not in svn. "
        },
        {
            "author": "Jason Rutherglen",
            "id": "comment-12754241",
            "date": "2009-09-11T17:34:40+0000",
            "content": "I added a wiki page at: http://wiki.apache.org/solr/KattaIntegration "
        },
        {
            "author": "Jason Rutherglen",
            "id": "comment-12754256",
            "date": "2009-09-11T18:06:12+0000",
            "content": "These are the external libraries necessary to run the test "
        },
        {
            "author": "Jason Venner (www.prohadoop.com)",
            "id": "comment-12754662",
            "date": "2009-09-13T04:52:01+0000",
            "content": "Jason and I have a couple of small changes that make this simpler to use, and a first faq entry.\nIf you get a NullPointerException in mergeId's a likely cause is a schema missmatch on the unique id field between an index served by a shard, and the top level solr instance performing the search. "
        },
        {
            "author": "Noble Paul",
            "id": "comment-12754700",
            "date": "2009-09-13T14:33:13+0000",
            "content": "Jason , why don't you separate issue for the CommComponent.It is useful for Solr even w/o Katta "
        },
        {
            "author": "Jason Rutherglen",
            "id": "comment-12755228",
            "date": "2009-09-14T22:32:14+0000",
            "content": "Noble, great idea!  I opened an issue at SOLR-1431. "
        },
        {
            "author": "Jason Rutherglen",
            "id": "comment-12758526",
            "date": "2009-09-23T01:16:45+0000",
            "content": "New patch updated to Katta's latest from Git.  It's slimmed down a bit, removing the various extraneous config files etc. "
        },
        {
            "author": "Jason Rutherglen",
            "id": "comment-12758530",
            "date": "2009-09-23T01:18:44+0000",
            "content": "Copy these libraries into lib/ before executing the test.  The Katta jars are somewhat custom.  I'll post a patch there shortly. "
        },
        {
            "author": "Jason Rutherglen",
            "id": "comment-12759283",
            "date": "2009-09-24T21:59:09+0000",
            "content": "Updated the KattaRequest class to properly serialize the SolrParams. "
        },
        {
            "author": "Jason Venner (www.prohadoop.com)",
            "id": "comment-12760635",
            "date": "2009-09-29T16:07:06+0000",
            "content": "the file /tmp/solr-1395-1431.patch is a combined patch of 1431 and 1395.\nA small api change in the query string creator required a small code change.\nClientUtils.toQueryString, now prefixes the returned query string with a '?' character "
        },
        {
            "author": "Jason Venner (www.prohadoop.com)",
            "id": "comment-12760726",
            "date": "2009-09-29T21:41:13+0000",
            "content": "/tmp/solr-1395-1431-3.patch contains an additional unit test for the query string serialization code, and two additional classes that allow for deployment to katta.\n\nWIth this jar, a katta client node may be started via\nkatta-daemon.sh start katta\\ startNode org.apache.solr.katta.DeployableSolrKattaServer\nThe system properties that control the node startup are\n\nsolr.server.name - the property to look for the server name, default proxy\nsolr.home - the property to look for the server root, default solrHome\nsolr.config.file - the property to look for the server config file name, default solr.xml\n\nThese will be used to find a solr configuration to run the embedded server which will search the deployed shards.\n\nIndex shards may be deployed via the standard katta mechanism of katta addIndex index-name shared-path-to-index\nI use the zip files produced by SOLR-1301 and deploy from hdfs.\n\nFor searching, create a solr configuration with a handler:\n\n  <requestHandler name=\"standard\" class=\"solr.KattaRequestHandler\" default=\"true\">\n    <!-- default values for query parameters -->\n     <lst name=\"defaults\">\n       <str name=\"echoParams\">explicit</str>\n       <!--\n       <int name=\"rows\">10</int>\n       <str name=\"fl\">*</str>\n       <str name=\"version\">2.1</str>\n        -->\n\t   <str name=\"shards\">*</str>\n     </lst>\n  </requestHandler>\n\nThis will search all deployed shards, replace the shards parameter with an explicit shard list if you only wish to query an explicit subset with this query handler.\n\nThe solr instance for search will need the zookeeper information.\n\nconf/katta.node.properties\nconf/katta.zk.properties, replace the zookeeper nodes with your clusters nodes\n\nI tend to run java -d64 -Xmx2g -Dkatta.request.timeout=100000 start.jar\nfor my testing work as my cluster is on the far side of a couple of firewallss\n\nI also have to store my katta.zk.properties file in the start.jar for some reason\n "
        },
        {
            "author": "Jason Rutherglen",
            "id": "comment-12760955",
            "date": "2009-09-30T16:57:46+0000",
            "content": "Jason, Can you upload a SOLR-1395 only patch?  That will help in seeing the SOLR-1395 specific changes.\n\nI think the next step is to remove the dependency on separate property files, as I find these hard to manage (they are too numerous). "
        },
        {
            "author": "Jason Venner (www.prohadoop.com)",
            "id": "comment-12760968",
            "date": "2009-09-30T18:04:24+0000",
            "content": "I was unable to separate them cleanly, so no.\n\n\n "
        },
        {
            "author": "Jason Venner (www.prohadoop.com)",
            "id": "comment-12761682",
            "date": "2009-10-02T19:33:00+0000",
            "content": "solr-1395-1431-4.patch contains a number of repairs, and now facet count aggregation works.\nThe one down side, is that this patch REQUIRES that the shards paramter explicitly list the shards to be queried, using a wild card does not work.\n\nI have this up and running nicely over 9 katta nodes and 65million documents. "
        },
        {
            "author": "pravin karne",
            "id": "comment-12765983",
            "date": "2009-10-15T09:30:14+0000",
            "content": "from where i can download KATTA-SOLR.patch  "
        },
        {
            "author": "Jason Venner (www.prohadoop.com)",
            "id": "comment-12766054",
            "date": "2009-10-15T13:21:33+0000",
            "content": "It should all be attached to the jira.\n\n\n\n "
        },
        {
            "author": "pravin karne",
            "id": "comment-12766066",
            "date": "2009-10-15T14:07:40+0000",
            "content": "hi\nFor solr patch i used following command:\n\npatch -p 0 -i solr-1395-1431-4.patch    //  this is for solrt trunk and its working\n\nbut for katt trunk i have to use KATTA-SOLR.patch\n\n\"KATTA-SOLR.patch\" is not on jira .Shall i use same above patch i.e. solr-1395-1431-4.patch \ncan plz tell me name of that patch file?\n\n\n\n\n\n\n "
        },
        {
            "author": "Jason Venner (www.prohadoop.com)",
            "id": "comment-12766077",
            "date": "2009-10-15T14:41:33+0000",
            "content": "My apologies, I think it is in the katta tree,\nKatta-80?\nhttp://oss.101tec.com/jira/browse/KATTA-80\n\n\u2013\nJason Venner\nAuthor: Pro Hadoop A howto guide to learning and using hadoop and map/reduce\nhttp://www.prohadoopbook.com/ a Ning network for Hadoop using Professionals\n\n\n\n\n\n "
        },
        {
            "author": "Jason Venner (www.prohadoop.com)",
            "id": "comment-12766081",
            "date": "2009-10-15T14:57:32+0000",
            "content": "AFIK this was committed also, so it is in katta trunk now.\n\n\n\u2013\nJason Venner\nAuthor: Pro Hadoop A howto guide to learning and using hadoop and map/reduce\nhttp://www.prohadoopbook.com/ a Ning network for Hadoop using Professionals\n\n Stefan Groschupf  \n<http://oss.101tec.com/jira/secure/ViewProfile.jspa?name=sg>  added a\ncomment  - 13/Oct/09 09:15 PM\n\nJust committed that, thanks Jason.\n\n\n\n\n "
        },
        {
            "author": "pravin karne",
            "id": "comment-12769917",
            "date": "2009-10-26T06:55:40+0000",
            "content": "Hi,\ni have integrate above path successfully.But when i tried to run \"ant test-core-Dtestcase=KattaClientTest\" test ,its failed.\nIs there any katta configuration required?\nAs this path uses katta internally  How to deploy indexes on solr with above patch ?\n\ncan i run katta and solr run on different machine ? how to configure this?\n\ncan you please provide details configurations steps for  katta/solr integrations \n\nThanks\n\n\n "
        },
        {
            "author": "Jason Rutherglen",
            "id": "comment-12771704",
            "date": "2009-10-29T23:52:44+0000",
            "content": "Pravin,\n\nI'll review the test case when I can.  Did you download and apply the latest patch?   "
        },
        {
            "author": "shyjuThomas",
            "id": "comment-12832465",
            "date": "2010-02-11T12:27:56+0000",
            "content": "Now Katta 0.6 version has been released, and there are many changes present in the katta-core-0.6.0.jar compared to the katta-core-0.6-dev.jar  present along with this. The patch provided for this issue will not work with this latest katta release version.  "
        },
        {
            "author": "Jason Rutherglen",
            "id": "comment-12832587",
            "date": "2010-02-11T17:30:23+0000",
            "content": "shyjuThomas,\n\nIt'd be good to update this patch to the latest Katta... You're welcome to do so... For my project I only need what'll be in SOLR-1724...  "
        },
        {
            "author": "Thomas Koch",
            "id": "comment-12834273",
            "date": "2010-02-16T15:54:44+0000",
            "content": "I'd also need katta integration at least for search, since my frontend is PHP (sorry...) and so I can't communicate as easily from PHP to Java as from PHP to SOLR.\nHas anybody already done an updated patch or could help me to do it? "
        },
        {
            "author": "Jason Venner (www.prohadoop.com)",
            "id": "comment-12834292",
            "date": "2010-02-16T16:23:37+0000",
            "content": "I run this by having a set of front end solr instances with jetty (1 or more), then you can speak http to these solr instances, which will allow you to query via php.\n\nWhat I typically do, is just hack the solrconfig.xml in the solr/examples/solr/conf directory and drop in my schema.xml into the same directory.\nThen run java ..... -jar start.jar from the examples directory.\n\nTweek this out for your production requirements ... "
        },
        {
            "author": "Tatsuya Hayashi",
            "id": "comment-12834935",
            "date": "2010-02-17T19:11:10+0000",
            "content": "I downloaded a Solr trunk and copied necessary jar files to solrtrunk/lib.\nAnd tried to apply the SOLR-1395.patch (patch -p 0 -i SOLR-1395.patch)\nBut I saw a failure message on the console.\n\npatching file src/java/org/apache/solr/handler/component/SearchHandler.java\nHunk #1 FAILED at 17.\n1 out of 4 hunks FAILED \u2013 saving rejects to file src/java/org/apache/solr/handler/component/SearchHandler.java.rej\npatching file src/solrj/org/apache/solr/client/solrj/request/QueryRequest.java\n\nCould anyone give me any suggestion to solve it? "
        },
        {
            "author": "Thomas Koch",
            "id": "comment-12835852",
            "date": "2010-02-19T17:52:40+0000",
            "content": "I've updated the patch for katta 0.6 however I deleted the SolrIndexer class since I don't need it and it relies on the indexer contribution to katta which seems to be deprecated.\nI still need to work on this patch, because I need the functionality to search all registered indexes. I'd appreciate any help! "
        },
        {
            "author": "Thomas Koch",
            "id": "comment-12850136",
            "date": "2010-03-26T13:43:58+0000",
            "content": "This patch implements searching over a set of indices specified by a regular expression (in the shards= parameter of the query). For this patch to work, you also need to patch katta: http://oss.101tec.com/jira/browse/KATTA-91 "
        },
        {
            "author": "Sumit",
            "id": "comment-12855955",
            "date": "2010-04-12T13:06:55+0000",
            "content": "1. Is this integration works with latest katta and solr source code? while following steps for katta no test-katta-core-0.6-dev.jar formed. Any idea why?  Also 2 test cases got failed i,e; ShardManagerTest.java and LoadTestMasterOperationTest.java. So i removed these two test cases and proceeds.\n\n2. Now when i am trying to use ant test-core in solr after following all other steps i am getting compilation error. To me it seems errors are coming due to old lucene jars as like error is coming as \"cannot find symbol symbol: variable TOKENIZED location: ckass org.apache.document.Field.Index\". Some errors are coming in compiling KattaClientFailoverTest.java when it is trying to find AbstractKattaTest. \n\nCan some one help me in resolving these types of issues?\n\nThanks,\nSumit "
        },
        {
            "author": "Hoss Man",
            "id": "comment-12872545",
            "date": "2010-05-27T22:07:34+0000",
            "content": "Bulk updating 240 Solr issues to set the Fix Version to \"next\" per the process outlined in this email...\n\nhttp://mail-archives.apache.org/mod_mbox/lucene-dev/201005.mbox/%3Calpine.DEB.1.10.1005251052040.24672@radix.cryptio.net%3E\n\nSelection criteria was \"Unresolved\" with a Fix Version of 1.5, 1.6, 3.1, or 4.0.  email notifications were suppressed.\n\nA unique token for finding these 240 issues in the future: hossversioncleanup20100527 "
        },
        {
            "author": "Mathias Walter",
            "id": "comment-12899788",
            "date": "2010-08-18T08:56:11+0000",
            "content": "I ported the patch to Solr 3.1 and Katta 0.6.2, except the Katta test. I also fixed some bugs. The updated patch will be added soon.\n\nIn the meanwhile I discovered a big issue. Often, a SolrKattaNode (back-end server) hosts many shards. If now a Solr front-end server starts a new query, it sent as many queries in parallel to the back-end servers as shards the have. In contrast, a Katta/Lucene search sends just one query to each back-end server which queries all shards a back-end server hosts.\nThe problem is now that the Solr front-end server often did not receive all KattaResponse's from the back-end servers and hence timeout some queries and raises an exception. Sometimes a NullPointerException in org.apache.solr.handler.component.QueryComponent.mergeIds (usually at startup of the front-end server) and sometimes a NullPointerException in org.apache.solr.handler.component.QueryComponent.returnFields:\n\n\nTRACE 2010-08-18 10:32:25,729 [pool-3-thread-4] net.sf.katta.client.WorkQueue - Done waiting, results = ClientResult: 0 results, 0 errors, 0/1 shards (id=6:0)\nTRACE 2010-08-18 10:32:25,729 [pool-3-thread-4] net.sf.katta.client.WorkQueue - Shutting down work queue, results = ClientResult: 0 results, 0 errors, 0/1 shards (id=6:0)\nTRACE 2010-08-18 10:32:25,729 [pool-3-thread-4] net.sf.katta.client.ClientResult - close() called.\nTRACE 2010-08-18 10:32:25,729 [pool-3-thread-4] net.sf.katta.client.ClientResult - Notifying closed listener.\nTRACE 2010-08-18 10:32:25,729 [pool-3-thread-4] net.sf.katta.client.WorkQueue - Shut down via ClientRequest.close()\nTRACE 2010-08-18 10:32:25,729 [pool-3-thread-4] net.sf.katta.client.WorkQueue - Shutdown() called (id=6)\nTRACE 2010-08-18 10:32:25,729 [pool-3-thread-4] net.sf.katta.client.WorkQueue - Returning results = ClientResult: 0 results, 0 errors, 0/1 shards (closed), took 9989 ms (id=6:0)\nDEBUG 2010-08-18 10:32:25,730 [pool-3-thread-4] net.sf.katta.client.Client - broadcast(request([null, org.apache.solr.katta.KattaRequest@180a1d7b]),\n {ibis46.gsf.de:20001=[sen-00000#sen-00000]}) took 10001 msec for ClientResult: 0 results, 0 errors, 0/1 shards (closed)\nDEBUG 2010-08-18 10:32:25,730 [pool-3-thread-4] org.apache.solr.katta.KattaSearchHandler - KattaCommComponent shard: sen-00000 results.size: 0\n WARN 2010-08-18 10:32:25,730 [pool-3-thread-4] org.apache.solr.katta.KattaSearchHandler - Received 0 responses for query [], not 1\nERROR 2010-08-18 10:32:25,731 [pool-1-thread-1] org.apache.solr.core.SolrCore - java.lang.NullPointerException\n\tat org.apache.solr.handler.component.QueryComponent.mergeIds(QueryComponent.java:411)\n\tat org.apache.solr.handler.component.QueryComponent.handleResponses(QueryComponent.java:308)\n\tat org.apache.solr.handler.component.SearchHandler.handleRequestBody(SearchHandler.java:284)\n\tat org.apache.solr.handler.RequestHandlerBase.handleRequest(RequestHandlerBase.java:131)\n\tat org.apache.solr.core.SolrCore.execute(SolrCore.java:1322)\n\tat org.apache.solr.core.QuerySenderListener.newSearcher(QuerySenderListener.java:52)\n\tat org.apache.solr.core.SolrCore$3.call(SolrCore.java:1144)\n\tat java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:138)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)\n\tat java.lang.Thread.run(Thread.java:619)\n\n\nDEBUG 2010-08-18 10:37:55,295 [pool-3-thread-9] net.sf.katta.client.Client - broadcast(request([null, org.apache.solr.katta.KattaRequest@71ce5e7a]),\n {ibis46.gsf.de:20001=[sen-00003#sen-00003]}) took 10001 msec for ClientResult: 0 results, 0 errors, 0/1 shards (closed)\nDEBUG 2010-08-18 10:37:55,295 [pool-3-thread-9] org.apache.solr.katta.KattaSearchHandler - KattaCommComponent shard: sen-00003 results.size: 0\n WARN 2010-08-18 10:37:55,295 [pool-3-thread-9] org.apache.solr.katta.KattaSearchHandler - Received 0 responses for query [], not 1\nERROR 2010-08-18 10:37:55,296 [918077175@qtp-87740549-8] org.apache.solr.core.SolrCore - java.lang.NullPointerException\n\tat org.apache.solr.handler.component.QueryComponent.returnFields(QueryComponent.java:574)\n\tat org.apache.solr.handler.component.QueryComponent.handleResponses(QueryComponent.java:312)\n\tat org.apache.solr.handler.component.SearchHandler.handleRequestBody(SearchHandler.java:284)\n\tat org.apache.solr.handler.RequestHandlerBase.handleRequest(RequestHandlerBase.java:131)\n\tat org.apache.solr.core.SolrCore.execute(SolrCore.java:1322)\n\tat org.apache.solr.servlet.SolrDispatchFilter.execute(SolrDispatchFilter.java:341)\n\tat org.apache.solr.servlet.SolrDispatchFilter.doFilter(SolrDispatchFilter.java:244)\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1157)\n\tat org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:388)\n\tat org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)\n\tat org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)\n\tat org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:765)\n\tat org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:440)\n\tat org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:230)\n\tat org.mortbay.jetty.handler.HandlerCollection.handle(HandlerCollection.java:114)\n\tat org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)\n\tat org.mortbay.jetty.Server.handle(Server.java:326)\n\tat org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542)\n\tat org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:926)\n\tat org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:549)\n\tat org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212)\n\tat org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)\n\tat org.mortbay.jetty.bio.SocketConnector$Connection.run(SocketConnector.java:228)\n\tat org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582)\n\n\n\nInterestingly, the back-end servers processing the queries immediately and send the results to the front-end server:\n\n\n INFO 2010-08-18 10:37:45,325 [pool-13-thread-9] org.apache.solr.core.SolrCore - [sen-00003#sen-00003] webapp=null path=/select params={start=0&\nids=pubmed%3A1567687%3A1%3A0%2Cpubmed%3A17140099%3A8%3A0%2Cpubmed%3A12807258%3A6%3A0%2Cpubmed%3A11701068%3A3%3A0&\nids=pubmed%3A1567687%3A1%3A0%2Cpubmed%3A17140099%3A8%3A0%2Cpubmed%3A12807258%3A6%3A0%2Cpubmed%3A11701068%3A3%3A0&q=Human&isShard=true&rows=10} status=0 QTime=7 \nDEBUG 2010-08-18 10:37:45,326 [IPC Server handler 17 on 20001] org.apache.solr.katta.SolrKattaServer - SolrServer.request: ibis46.gsf.de:20001 shards: [sen-00003#sen-00003]\n request params: start=0&ids=pubmed%3A1567687%3A1%3A0%2Cpubmed%3A17140099%3A8%3A0%2Cpubmed%3A12807258%3A6%3A0%2Cpubmed%3A11701068%3A3%3A0&q=Human&isShard=true&rows=10&shards=sen-00003%23sen-00003\n rsp: {response={numFound=4,start=0,docs=[SolrDocument[{id=pubmed:1567687:1:0, type=sentence, lang=en, pubdate=Fri Dec 15 11:39:20 CET 2006}],\n SolrDocument[{id=pubmed:17140099:8:0, type=sentence, lang=en, pubdate=Thu Mar 01 11:40:18 CET 2007}],\n SolrDocument[{id=pubmed:12807258:6:0, type=sentence, lang=en, pubdate=Thu Jun 11 11:37:14 CEST 2009}],\n SolrDocument[{id=pubmed:11701068:3:0, type=sentence, lang=en, pubdate=Fri Apr 28 11:36:26 CEST 2006}]]},\n QueriedShards=[Ljava.lang.String;@791ef9f6}\nDEBUG 2010-08-18 10:37:45,326 [IPC Server handler 17 on 20001] org.apache.hadoop.ipc.Server - Served: request queueTime= 8 procesingTime= 17\nDEBUG 2010-08-18 10:37:45,326 [IPC Server handler 17 on 20001] org.apache.hadoop.ipc.Server - IPC Server Responder: responding to #30 from 146.107.217.46:58679\nDEBUG 2010-08-18 10:37:45,326 [IPC Server handler 17 on 20001] org.apache.hadoop.ipc.Server - IPC Server Responder: responding to #30 from 146.107.217.46:58679 Wrote 386 bytes.\n\n\n\nBut if the front-end server cancels the query in case of a timout, always the last sent KattaResponse was not recognized by the front-end server. I've attached a full communication log of one failed query for both the front-end (front-end.log) and the back-end ([^backend-end.log]) server.\n\nDid anyone run into the same issue? I hope because the error occurs quit often. I assume this bug is related to Hadoop RPC, but I could not find a Hadoop JIRA. I also tried the latest release candidate 0.21.0 of Hadoop.\n\nMy idea is now to combine the parallel queries to one back-end server into one single query, similar to the Lucene queries implemented in Katta. "
        },
        {
            "author": "jianfeng zheng",
            "id": "comment-12904548",
            "date": "2010-08-31T07:48:52+0000",
            "content": "Hey Mathias,\n\n     I also come into this problem, have you deal with it? And btw, how you get these beautiful logs? "
        },
        {
            "author": "Mathias Walter",
            "id": "comment-12906456",
            "date": "2010-09-06T08:33:48+0000",
            "content": "\nI also come into this problem, have you deal with it?\n\nYeah, I got it working by using the Katta Distribution Policy instead of the MultiShard Distributed Search of Solr. That does not solve the RPC problem, but avoid it completely. Personally, I think it is better to keep Katta choosing how to distribute the queries to the different Katta nodes instead of letting Solr to do this.\n\nI'll provide my changes soon.\n\n\nAnd btw, how you get these beautiful logs?\n\nI got the logs by configuring the log4j.properties like follows:\n\n\nkatta.root.logger=TRACE,console\nlog4j.logger.org.apache.zookeeper=WARN\n#log4j.logger.org.apache.hadoop=WARN\nlog4j.logger.org.I0Itec.zkclient=WARN\nlog4j.logger.org.mortbay.log=WARN\nkatta.log.dir=./logs\nkatta.log.file=katta.log\n\n# Define the root logger to the system property \"katta.root.logger\".\nlog4j.rootLogger=${katta.root.logger}\n\n#\n# console\n# Add \"console\" to rootlogger above if you want to use this \n#\nlog4j.appender.console=org.apache.log4j.ConsoleAppender\nlog4j.appender.console.target=System.out\nlog4j.appender.console.layout=org.apache.log4j.PatternLayout\nlog4j.appender.console.layout.ConversionPattern=%5p %d{ISO8601} [%t] %c - %m%n\n\n "
        },
        {
            "author": "jianfeng zheng",
            "id": "comment-12909654",
            "date": "2010-09-15T08:54:32+0000",
            "content": "You are so nice, Mathias\n\n      I am using the MultiShard Distributed Search of Solr, and also let Katta chose a node for a shard. I found there is only one proxy object in KattaClient for each Katta node, lock it will solve the problem you post on 18/Aug. but it will lead to each node works as single thread. \n\n "
        },
        {
            "author": "tom liu",
            "id": "comment-12919478",
            "date": "2010-10-09T10:14:24+0000",
            "content": "i use solr-4.0 newest code trunk, and katta 0.6.2, hadoop-0.20.2, zookeeper-3.3.1, after fixed some bugs , i run it.\n\nthe bugs is :\n1. solr's ShardDoc.java, ShardFieldSortedHitQueue line 210 :\n\n        final float f1 = e1.score==null?0.00f:e1.score;\n        final float f2 = e2.score==null?0.00f:e2.score;\n\n\n2. KattaSearchHandler.java, KattaMultiShardHandler may be return more results, so must include any results:\n\n\t\t\tif (results.isEmpty()) {\n\t\t\t\tssr.setResponse(new NamedList<Object>());\n\t\t\t\treturn;\n\t\t\t}\n+\n+\t\t\tNamedList<Object> nl = new NamedList<Object>();\n+\t\t\tNamedListCollection nlc = new NamedListCollection(nl);\n+\t\t\tfor(KattaResponse kr : results){\n+\t\t\t\tnl = nlc.add(kr.getRsp().getResponse());\n+\t\t\t}\n\t\t\tssr.setResponse(nl);\n                }\n+\t\tprivate class NamedListCollection {\n+\t\t\tprivate NamedList<Object> _nl;\n+\t\t\tNamedListCollection(NamedList<Object> nl){\n+\t\t\t\t_nl = nl;\n+\t\t\t}\n+\t\t\tNamedList<Object> add(NamedList<Object> nl){\n+\t\t\t\tIterator<Entry<String,Object>> it = nl.iterator();\n+\t\t\t\twhile (it.hasNext()){\n+\t\t\t\t\tEntry<String,Object> entry = it.next();\n+\t\t\t\t\tString key = entry.getKey();\n+\t\t\t\t\tObject obj = entry.getValue();\n+\t\t\t\t\tObject old = _nl.remove(key);\n+\t\t\t\t\tif(old != null){\n+\t\t\t\t\t\tadd(key, obj , old );\n+\t\t\t\t\t}else{\n+\t\t\t\t\t\t_nl.add(key, obj);\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t\treturn _nl;\n+\t\t\t}\n+\t\t\tvoid add(String key,Object obj,Object old){\n+\t\t\t\tif(key.equals(\"response\")){\n+\t\t\t\t\tSolrDocumentList doca = (SolrDocumentList)obj;\n+\t\t\t\t\tSolrDocumentList docb = (SolrDocumentList)old;\n+\t\t\t\t\tSolrDocumentList docs = new SolrDocumentList();\n+\t\t\t\t\tdocs.setNumFound(doca.getNumFound()+docb.getNumFound());\n+\t\t\t\t\t//doca.setStart(doca.getStart()+docb.getStart());\n+\t\t\t\t\tdocs.setMaxScore(Math.max(doca.getMaxScore(), docb.getMaxScore()));\n+\t\t\t\t\tdocs.addAll(doca);\n+\t\t\t\t\tdocs.addAll(docb);\n+\t\t\t\t\t_nl.add(key,docs);\n+\t\t\t\t}else if(key.equals(\"QueriedShards\")){\n+\t\t\t\t\tCollection<String> qsa = (ArrayList<String>)obj;\n+\t\t\t\t\tCollection<String> qsb = (ArrayList<String>)old;\n+\t\t\t\t\tCollection<String> qs = new ArrayList<String>();\n+\t\t\t\t\tqs.addAll(qsa);\n+\t\t\t\t\tqs.addAll(qsb);\n+\t\t\t\t\t_nl.add(key, qs);\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n\n "
        },
        {
            "author": "tom liu",
            "id": "comment-12919581",
            "date": "2010-10-10T08:39:19+0000",
            "content": "My deployment is:\n\n\tone Master\n\ttwo Slaves:\n\t\n\t\tsolr01\n\t\tsolr02\n\t\n\t\n\ttwo Indexes:\n\t\n\t\tsolrhome01(.zip)\n\t\tsolrhome02(.zip)\n\t\n\t\n\n\n\nAnd, i use:\n\n# bin/katta addIndex solrhome01 hdfs://localhost:9000/solr/solrhome01.zip\n# bin/katta addIndex solrhome02 hdfs://localhost:9000/solr/solrhome02.zip\n\n\n\nso, my shard-Node is:\n\n\tsolrhome01#solrhome01\n\t\n\t\t--solr01\n\t\t--solr02\n\t\n\t\n\tsolrhome02#solrhome02\n\t\n\t\t--solr01\n\t\t--solr02\n\t\n\t\n\n\n\nWhen i searched in master, i found that, in any slave, the search ran twice, such as:\n\nSolrServer.request: solr01:20000 shards:[solrhome01#solrhome01, solrhome02#solrhome02] \nrequest params:fl=id%2Cscore&start=0&q=solr&isShard=true&fsv=true&rows=10&shards=solrhome01%23solrhome01%2Csolrhome02%23solrhome02\n2010-10-10 16:17:04 org.apache.solr.core.SolrCore execute\n\u4fe1\u606f: [solrhome02#solrhome02] webapp=null path=/select params={fl=id%2Cscore&start=0&q=solr&isShard=true&fsv=true&rows=10} hits=1 status=0 QTime=16 \n2010-10-10 16:17:04 org.apache.solr.core.SolrCore execute\n\u4fe1\u606f: [solrhome01#solrhome01] webapp=null path=/select params={fl=id%2Cscore&start=0&q=solr&isShard=true&fsv=true&rows=10} hits=1 status=0 QTime=16 \n2010-10-10 16:17:04 org.apache.solr.core.SolrCore execute\n\u4fe1\u606f: [solrhome02#solrhome02] webapp=null path=/select params={fl=id%2Cscore%2Cid&start=0&q=solr&isShard=true&rows=10&ids=SOLR1000} status=0 QTime=0 \nSolrServer.SolrResponse:{response={numFound=1,start=00.5747526,docs=[SolrDocument[{id=SOLR1000, score=0.5747526}]]},QueriedShards=[Ljava.lang.String;@175ace6}\n\n\n\nSolrServer.request: solr02:20000 shards:[solrhome01#solrhome01, solrhome02#solrhome02] \nrequest params:start=0&ids=SOLR1000&q=solr&isShard=true&rows=10&shards=solrhome01%23solrhome01%2Csolrhome02%23solrhome02\n2010-10-10 16:17:04 org.apache.solr.core.SolrCore execute\n\u4fe1\u606f: [solrhome02#solrhome02] webapp=null path=/select params={start=0&ids=SOLR1000&q=solr&isShard=true&rows=10&fsv=true&fl=id%2Cscore} status=0 QTime=16\n2010-10-10 16:17:04 org.apache.solr.core.SolrCore execute\n\u4fe1\u606f: [solrhome01#solrhome01] webapp=null path=/select params={start=0&ids=SOLR1000&q=solr&isShard=true&rows=10&fsv=true&fl=id%2Cscore} status=0 QTime=16\n2010-10-10 16:17:04 org.apache.solr.core.SolrCore execute\n\u4fe1\u606f: [solrhome01#solrhome01] webapp=null path=/select params={start=0&ids=SOLR1000&ids=SOLR1000&q=solr&isShard=true&rows=10} status=0 QTime=0\nSolrServer.SolrResponse:{response={numFound=1,start=0,docs=[SolrDocument[{id=SOLR1000, ...]]},QueriedShards=[Ljava.lang.String;@1d590d}\n\n\n\ni think, in slaves, IS_SHARD=true, so, it would prevent this happens. "
        },
        {
            "author": "Mathias Walter",
            "id": "comment-12919757",
            "date": "2010-10-11T08:55:24+0000",
            "content": "The two queries are not identical! In a distributed environment the first query asks each shard for the n document Ids with the top scorces. The master merges them to the final top n ranking documents. Then a second query to each shard is sent which requestes the solr documents by its IDs. That's why you can see \"ids=SOLR1000\" in the second query. "
        },
        {
            "author": "tom liu",
            "id": "comment-12919784",
            "date": "2010-10-11T10:22:26+0000",
            "content": "No, that's four queries:\n\n\ton solr01, url is /select?fl=id,score&...\n\t\n\t\tShard=solrhome02#solrhome02\n\t\tShard=solrhome01#solrhome01\n\t\n\t\n\ton solr01, url is /select?ids=SOLR1000&fl=id,score,id&...\n\t\n\t\tShard=solrhome02#solrhome02\n\t\n\t\n\ton solr02, url is /select?ids=SOLR1000&fl=id,score&...\n\t\n\t\tShard=solrhome02#solrhome02\n\t\tShard=solrhome01#solrhome01\n\t\n\t\n\ton solr02, url is /select?ids=SOLR1000&ids=SOLR1000&...\n\t\n\t\tShard=solrhome01#solrhome01\n\t\n\t\n\n\n\nIf the orient query includes shards=*, then master solr would send * to kattaclient.\nAnd then, kattaclient or katta.Client would select node such as solr01, and send shards=solrhome01#solrhome01,solrhome02#solrhome02\nin middle-shard, searchHandler and queryComponent would invoke distributed process, such as createMainQuery and createRetrieveDocs.\nSo, in any node, the query would be distributed into two queries:\n\n\tfirst is selecting id and score\n\tsecond is selecting docs\n\n\n\ni have changed the queryComponent class. that is:\ndistributedProcess\n\t// Added by tom liu\n\t// do or not need distributed process\n\tboolean isShard = rb.req.getParams().getBool(ShardParams.IS_SHARD, false);\n\t// if in sub shards, do not need distributed process\n\tif (isShard) {\n\t\tif (rb.stage < ResponseBuilder.STAGE_PARSE_QUERY)\n\t\t\treturn ResponseBuilder.STAGE_PARSE_QUERY;\n\t\tif (rb.stage == ResponseBuilder.STAGE_PARSE_QUERY) {\n\t\t\tcreateDistributedIdf(rb);\n\t\t\treturn ResponseBuilder.STAGE_EXECUTE_QUERY;\n\t\t}\n\t\tif (rb.stage < ResponseBuilder.STAGE_EXECUTE_QUERY)\n\t\t\treturn ResponseBuilder.STAGE_EXECUTE_QUERY;\n\t\tif (rb.stage == ResponseBuilder.STAGE_EXECUTE_QUERY) {\n\t\t\tcreateMainQuery(rb);\n\t\t\treturn ResponseBuilder.STAGE_GET_FIELDS;\n\t\t}\n\t\tif (rb.stage < ResponseBuilder.STAGE_GET_FIELDS)\n\t\t\treturn ResponseBuilder.STAGE_GET_FIELDS;\n\t\tif (rb.stage == ResponseBuilder.STAGE_GET_FIELDS) {\n\t\t\treturn ResponseBuilder.STAGE_DONE;\n\t\t}\n\t\treturn ResponseBuilder.STAGE_DONE;\n\t}\n\t// add end\n        ...\n\n \n\nhandleResponses\n  if ((sreq.purpose & ShardRequest.PURPOSE_GET_TOP_IDS) != 0) {\n      mergeIds(rb, sreq);\n  \t  // Added by tom liu\n  \t  // do or not need distributed process\n  \t  boolean isShard = rb.req.getParams().getBool(ShardParams.IS_SHARD, false);\n      if(isShard){\n      \tsreq.purpose = ShardRequest.PURPOSE_GET_FIELDS;\n      }\n   \t  // add end\n    }\n\n    if ((sreq.purpose & ShardRequest.PURPOSE_GET_FIELDS) != 0) {\n      returnFields(rb, sreq);\n      return;\n    }\n\n \n\ncreateMainQuery\n    sreq.params = new ModifiableSolrParams(rb.req.getParams());\n    // TODO: base on current params or original params?\n\n\t// Added by tom liu\n\t// do or not need distributed process\n\tboolean isShard = rb.req.getParams().getBool(ShardParams.IS_SHARD, false);\n    if(isShard){\n        // isShard=true, then do not change params\n    }else{\n    \t// add end\n\t    // don't pass through any shards param\n\t    sreq.params.remove(ShardParams.SHARDS);\n    ...\n\n \n\nreturnFields\n      boolean returnScores = (rb.getFieldFlags() & SolrIndexSearcher.GET_SCORES) != 0;\n\n      // changed by tom liu\n      // add for loop\n      //assert(sreq.responses.size() == 1);\n      //ShardResponse srsp = sreq.responses.get(0);\n      for(ShardResponse srsp : sreq.responses){\n\t      SolrDocumentList docs = (SolrDocumentList)srsp.getSolrResponse().getResponse().get(\"response\");\n\n\t      String keyFieldName = rb.req.getSchema().getUniqueKeyField().getName();\n      ...\n\n  "
        },
        {
            "author": "tom liu",
            "id": "comment-12920067",
            "date": "2010-10-12T02:58:31+0000",
            "content": "fixed some bugs:\n\n\tNPE throws in QueryComponent's mergeIds method\n\t\n\t\tadd: shardDoc.score = 0f;\n\t\n\t\n\tDups query in sub shards\n\t\n\t\tchanges queryComponent's distributedProcess\n\t\tchanges queryComponent's handleResponses\n\t\tchanges queryComponent's createMainQuery\n\t\tchanges queryComponent's returnFields\n\t\n\t\n\tNo results when start!=0\n\t\n\t\tchanges queryComponent's createRetrieveDocs\n\t\n\t\n\tmore results returned in KattaMultiShardHandler\n\t\n\t\tchanges KattaMultiShardHandler's execute\n\t\n\t\n\n "
        },
        {
            "author": "Dhruv Bansal",
            "id": "comment-12920373",
            "date": "2010-10-12T22:05:54+0000",
            "content": "tom liu,\n\ni'm unable to run the last patch file you uploaded, solr-1395-katta-0.6.2.patch on 2010-10-11, using apache-solr-1.4.1.\n\npatching_solr-1.4.1\n$ wget http://mirror.cloudera.com/apache//lucene/solr/1.4.1/apache-solr-1.4.1.tgz\n...\n$ tar -xzf apache-solr-1.4.1.tgz\n$ cd apache-solr-1.4.1/src\napache-solr-1.4.1/src$ wget https://issues.apache.org/jira/secure/attachment/12456924/solr-1395-katta-0.6.2.patch\n...\napache-solr-1.4.1/src$ patch -p0 -i solr-1395-katta-0.6.2.patch\n\npatching file java/org/apache/solr/katta/ISolrDocumentFactory.java\npatching file java/org/apache/solr/katta/ISolrServer.java\npatching file java/org/apache/solr/katta/KattaClient.java\npatching file java/org/apache/solr/katta/KattaResponse.java\npatching file java/org/apache/solr/katta/ZipService.java\npatching file java/org/apache/solr/katta/KattaMultiServer.java\npatching file java/org/apache/solr/katta/KattaComponent.java\npatching file java/org/apache/solr/katta/DocumentWritable.java\nPatching file java/org/apache/solr/katta/KattaSearchHandler.java\npatching file java/org/apache/solr/katta/SolrKattaServer.java\npatching file java/org/apache/solr/katta/DeployableSolrKattaServer.java\npatching file java/org/apache/solr/katta/KattaRequest.java\npatching file java/org/apache/solr/katta/SolrIndexer.java\npatching file java/org/apache/solr/handler/KattaRequestHandler.java\npatching file java/org/apache/solr/handler/component/SearchHandler.java\nHunk #1 succeeded at 216 (offset -14 lines).\nHunk #2 succeeded at 243 (offset -14 lines).\nHunk #3 succeeded at 301 (offset -14 lines).\nHunk #4 FAILED at 357.\n1 out of 4 hunks FAILED -- saving rejects to file java/org/apache/solr/handler/component/SearchHandler.java.rej\npatching file java/org/apache/solr/handler/component/SimpleSolrResponse.java\npatching file java/org/apache/solr/handler/component/MultiShardHandler.java\npatching file java/org/apache/solr/handler/component/HttpMultiShardHandler.java\npatching file java/org/apache/solr/handler/component/EmbeddedMultiShardHandler.java\npatching file java/org/apache/solr/handler/component/QueryComponent.java\nHunk #1 succeeded at 42 with fuzz 2 (offset 6 lines).\nHunk #2 succeeded at 174 (offset -2 lines).\nHunk #3 succeeded at 274 (offset -110 lines).\nHunk #4 FAILED at 432.\nHunk #5 succeeded at 361 (offset -109 lines).\nHunk #6 succeeded at 474 (offset -110 lines).\nHunk #7 succeeded at 525 (offset -110 lines).\nHunk #8 succeeded at 576 (offset -115 lines).\nHunk #9 FAILED at 711.\n2 out of 9 hunks FAILED -- saving rejects to file java/org/apache/solr/handler/component/QueryComponent.java.rej\npatching file java/org/apache/solr/handler/component/MultiEmbeddedSearchHandler.java\npatching file java/org/apache/solr/handler/component/AbstractMultiShardHandler.java\npatching file solrj/org/apache/solr/client/solrj/request/QueryRequest.java\npatching file webapp/web/WEB-INF/web.xml\n\n\n\nDid I do something incorrectly? "
        },
        {
            "author": "tom liu",
            "id": "comment-12920471",
            "date": "2010-10-13T08:33:49+0000",
            "content": "I am sorry,\nThe solr-1395-katta-0.6.2.patch based on:\n\n\tsolr's newest trunk\n\t\n\t\tsvn co http://svn.apache.org/repos/asf/lucene/dev/trunk lucene\n\t\n\t\n\thadoop-0.20.2\n\tkatta-0.6.2\n\tzookeeper-3.3.1\n\n "
        },
        {
            "author": "tom liu",
            "id": "comment-12922014",
            "date": "2010-10-18T08:43:09+0000",
            "content": "When i use debugQuery=true to query solr, NPE throws.\nI found all subclass of SearchComponent have defects, Because i changed QueryComponent that do not query twice in middle solrs, but any component depends on twice query.\n\nSo, i would change SearchComponent's subclass, such as DebugComponent. "
        },
        {
            "author": "Mathias Walter",
            "id": "comment-12922026",
            "date": "2010-10-18T09:23:09+0000",
            "content": "You should not include your modified web.xml into the patch. "
        },
        {
            "author": "Mathias Walter",
            "id": "comment-12922039",
            "date": "2010-10-18T10:23:00+0000",
            "content": "Why did you include SolrIndexer.java, ZipService.java, DocumentWritable.java, KattaComponent.java and ISolrDocumentFactory.java? Did you merged in another patch? Please keep them separated.\n\nBTW: SolrIndexer uses IndexConfiguration from Katta, which is no longer available. "
        },
        {
            "author": "tom liu",
            "id": "comment-12922866",
            "date": "2010-10-20T06:19:18+0000",
            "content": "fixed some bugs:\n\n\n\tNPE throws in QueryComponent's mergeIds method\n\t\n\t\tadd: shardDoc.score = 0f;\n\t\n\t\n\tDups query in sub shards\n\t\n\t\tchanges queryComponent's distributedProcess\n\t\tchanges queryComponent's handleResponses\n\t\tchanges queryComponent's createMainQuery\n\t\tchanges queryComponent's returnFields\n\t\n\t\n\tNo results when start!=0\n\t\n\t\tchanges queryComponent's createRetrieveDocs\n\t\n\t\n\tmore results returned in KattaMultiShardHandler\n\t\n\t\tchanges KattaMultiShardHandler's execute\n\t\n\t\n\tIndexConfiguration\n\tComponents throw NPE\n\t\n\t\tDebugComponent\n\t\tFacetComponent\n\t\tHighlightComponent\n\t\tStatsComponent\n\t\n\t\n\n\n\nMy patch is based on solr-1395-1431-4.patch:\n\n\tsvn co http://svn.apache.org/repos/asf/lucene/dev/trunk lucene\n\tpatch solr-1395-1431-4.patch\n\t...... (do some changes, such as fixed above bugs)\n\tsvn di > solr-1395-katta-0.6.2-1.patch\n\n "
        },
        {
            "author": "tom liu",
            "id": "comment-12924911",
            "date": "2010-10-26T09:55:31+0000",
            "content": "Concurrency request would be thrown NPE.\nSuch as:\n\nab -n 10000 -c 5 http://solr01:8080/solr/select?q=solr&...\n\n\n\nit would be thrown NPE:\n\n10/10/26 17:36:03 TRACE client.WorkQueue:261 - Done waiting, results = ClientResult: 0 results, 0 errors, 0/2 shards (id=2359:0)\n10/10/26 17:36:03 TRACE client.WorkQueue:270 - Shutting down work queue, results = ClientResult: 0 results, 0 errors, 0/2 shards (id=2359:0)\n10/10/26 17:36:03 TRACE client.ClientResult:286 - close() called.\n10/10/26 17:36:03 TRACE client.ClientResult:290 - Notifying closed listener.\n10/10/26 17:36:03 TRACE client.WorkQueue:136 - Shut down via ClientRequest.close()\n10/10/26 17:36:03 TRACE client.WorkQueue:188 - Shutdown() called (id=2359)\n10/10/26 17:36:03 TRACE client.WorkQueue:277 - Returning results = ClientResult: 0 results, 0 errors, 0/2 shards (closed), took 10003 ms (id=2359:0)\n10/10/26 17:36:03 DEBUG client.Client:427 - broadcast(request([Ljava.lang.Object;@7cf02bee), {solr03:20000=[solrhome01#solrhome01, solrhome02#solrhome02]}) took 10004 msec for ClientResult: 0 results, 0 errors, 0/2 shards (closed)\n10/10/26 17:36:03 INFO component.SearchHandler:89 - KattaCommComponent results.size: 0\n10/10/26 17:36:03 WARN component.SearchHandler:93 - Received 0 responses for query [], not 1\n10/10/26 17:36:03 ERROR core.SolrCore:151 - java.lang.NullPointerException\n        at org.apache.solr.handler.component.QueryComponent.mergeIds(QueryComponent.java:553)\n        at org.apache.solr.handler.component.QueryComponent.handleResponses(QueryComponent.java:435)\n        at org.apache.solr.handler.component.SearchHandler.handleRequestBody(SearchHandler.java:304)\n        at org.apache.solr.handler.RequestHandlerBase.handleRequest(RequestHandlerBase.java:131)\n\n\n\nBut use \n\nab -n 10000 -c 1 http://solr01:8080/solr/select?q=solr&... \n\n\ndo not thrown\n\nBTW::\nNPE would stop RPC communication in request method of SolrKattaServer.java "
        },
        {
            "author": "Mathias Walter",
            "id": "comment-12924942",
            "date": "2010-10-26T12:32:32+0000",
            "content": "Tom, thats what I reported on 18th of August and why I switched to the Katta distribution system. "
        },
        {
            "author": "tom liu",
            "id": "comment-12925765",
            "date": "2010-10-28T09:39:17+0000",
            "content": "Walter, thanks.\ni review codes, found that org.apache.hadoop.ipc.Client class holds connection to ShardNode, but for each node, only one socket/connection.\nso, if large requests are sent, the connection would be wait synchronized.\n\ni think, for each node, it would have some connections. "
        },
        {
            "author": "JohnWu",
            "id": "comment-12927352",
            "date": "2010-11-02T10:30:24+0000",
            "content": "Tom Liu:\n\n\n     I trunk the code from the http://svn.apache.org/repos/asf/lucene/dev/trunk lucene\n     when patch it with solr-1395-1431-4.patch, there are something wrong as follows:     \n\n    Hunk # FAILED \n\n\n    Did I patch the code with solr-1395-1431.patch firstly?\n\n    If I patch the code with solr-1395-katta-0.6.2.patch and katta(also patched), ant build sucessful!\n\n    but you give a solr-1395-katta-0.6.2-1.patch now! How to keep the code syn as yours?\n   please tell us the whole patch process. We work together to solve this problem\uff01\n\n  Thanks! \n\n "
        },
        {
            "author": "tom liu",
            "id": "comment-12927767",
            "date": "2010-11-03T07:52:17+0000",
            "content": "i fixed below bugs:\n\n\tRPC Server stopping\n\tRpc client receive null docs\n\tRpc Client request timeout, that solr would receive null docs\n\n\n\nBTW::\nWalter, i found if change server and client communications that like client send request to server, the NPE would not throw.\nsee: https://issues.apache.org/jira/browse/HADOOP-7017 "
        },
        {
            "author": "tom liu",
            "id": "comment-12927774",
            "date": "2010-11-03T07:58:09+0000",
            "content": "JohnWu:\n\npls use solr-1395-katta-0.6.2.patch.\n\ni did not know how to make a patch from solr-1395-1431.patch.\nsolr-1395-katta-0.6.2*.patch included solr-1395-1431.patch "
        },
        {
            "author": "JohnWu",
            "id": "comment-12927779",
            "date": "2010-11-03T08:24:26+0000",
            "content": "Tomliu:\n\nthanks your answer:\"solr-1395-katta-0.6.2*.patch included solr-1395-1431.patch\"\n\n\nI trunk the code form http://svn.apache.org/repos/asf/lucene/dev/trunk\n\nthe folder now is:\n\n[hadoop@pc-master solrNewTrunkForPatch-solr-1395-katta-0.6.2-1patch]$ ls\nbuild.xml  lucene  modules  solr\n\n\ncd solr/src/java\n\npatch -p0 -i solr-1395-katta-0.6.2-2.patch \n\npatching file net/sf/katta/util/IndexConfiguration.java\npatching file org/apache/solr/katta/ISolrDocumentFactory.java\npatching file org/apache/solr/katta/ISolrServer.java\npatching file org/apache/solr/katta/KattaClient.java\npatching file org/apache/solr/katta/KattaResponse.java\npatching file org/apache/solr/katta/ZipService.java\npatching file org/apache/solr/katta/KattaMultiServer.java\npatching file org/apache/solr/katta/KattaComponent.java\npatching file org/apache/solr/katta/DocumentWritable.java\npatching file org/apache/solr/katta/KattaSearchHandler.java\npatching file org/apache/solr/katta/SolrKattaServer.java\npatching file org/apache/solr/katta/DeployableSolrKattaServer.java\npatching file org/apache/solr/katta/KattaRequest.java\npatching file org/apache/solr/katta/SolrIndexer.java\npatching file org/apache/solr/handler/KattaRequestHandler.java\npatching file org/apache/solr/handler/component/SearchHandler.java\nHunk #1 succeeded at 251 (offset 21 lines).\nHunk #3 succeeded at 337 (offset 22 lines).\nHunk #4 FAILED at 379.\n1 out of 4 hunks FAILED \u2013 saving rejects to file org/apache/solr/handler/component/SearchHandler.java.rej\npatching file org/apache/solr/handler/component/FacetComponent.java\nHunk #2 succeeded at 203 (offset 19 lines).\npatching file org/apache/solr/handler/component/SimpleSolrResponse.java\npatching file org/apache/solr/handler/component/DebugComponent.java\npatching file org/apache/solr/handler/component/MultiShardHandler.java\npatching file org/apache/solr/handler/component/HttpMultiShardHandler.java\npatching file org/apache/solr/handler/component/StatsComponent.java\npatching file org/apache/solr/handler/component/EmbeddedMultiShardHandler.java\npatching file org/apache/solr/handler/component/QueryComponent.java\nHunk #1 succeeded at 287 (offset 112 lines).\nHunk #2 succeeded at 387 (offset 4 lines).\nHunk #3 succeeded at 543 (offset 112 lines).\nHunk #4 succeeded at 480 (offset 4 lines).\nHunk #5 succeeded at 702 (offset 112 lines).\nHunk #6 succeeded at 644 (offset 4 lines).\nHunk #7 succeeded at 808 (offset 112 lines).\nHunk #8 succeeded at 720 (offset 4 lines).\npatching file org/apache/solr/handler/component/MultiEmbeddedSearchHandler.java\npatching file org/apache/solr/handler/component/HighlightComponent.java\npatching file org/apache/solr/handler/component/AbstractMultiShardHandler.java\n\n\nhow to solve the problem as above showed?\n\"Hunk #4 FAILED at 379.\n1 out of 4 hunks FAILED \u2013 saving rejects to file org/apache/solr/handler/component/SearchHandler.java.rej\n\"\n\n\n\nwe just lack such a step, the only one step to run the cluster as you!\n\nwaiting for your reply! online!\n\n "
        },
        {
            "author": "Mathias Walter",
            "id": "comment-12927780",
            "date": "2010-11-03T08:30:45+0000",
            "content": "Hi John,\n\nwhy don't you just compare SearchHandler.java.rej with SearchHandler.java and merge them manually? It should be very easy. "
        },
        {
            "author": "wilson huang",
            "id": "comment-12927800",
            "date": "2010-11-03T09:17:58+0000",
            "content": "Tom:\n   I have some questions:\n1. How to configure the patched solr ?\n2. How to start up Katta after solr patched?\n    a) start the master and the nodes of Katta from the commond line or the Katta as a component in solr\n\n3. How to use indices whitch created on Katta in your solr cluster?\n\nThanks! "
        },
        {
            "author": "JohnWu",
            "id": "comment-12928160",
            "date": "2010-11-04T08:31:13+0000",
            "content": "TomLiu:\n        I correct the code ater patched:\ncorrect the code\uff1a\n1)package org.apache.solr.client.solrj.request-> QueryRequest ->query (filed):\nprotected SolrParams query;\n\n2)package org.apache.solr.handler.component->SearchHandler->Submit (method):\n  void submit(final ShardRequest sreq, final String shard, final ModifiableSolrParams params) {\n\n\t       Callable<ShardResponse> task = new Callable<ShardResponse>() {\n\t         public ShardResponse call() throws Exception {\n\n\t           ShardResponse srsp = new ShardResponse();\n\t           srsp.setShardRequest(sreq);\n\t           srsp.setShard(shard);\n\t           SimpleSolrResponse ssr = new SimpleSolrResponse();\n\t           srsp.setSolrResponse(ssr);\n\t           long startTime = System.currentTimeMillis();\n\n\t           try \n{\n\t             // String url = \"http://\" + shard + \"/select\";\n\t             String url = SearchHandler.scheme + shard;\n\t   \n\t            params.remove(CommonParams.WT); // use default (currently javabin)\n\t             params.remove(CommonParams.VERSION);\n\t   \n\t             SolrServer server = new CommonsHttpSolrServer(url, client);\n\t             // SolrRequest req = new QueryRequest(SolrRequest.METHOD.POST, \"/select\");\n\t             // use generic request to avoid extra processing of queries\n\t             QueryRequest req = new QueryRequest(params);\n\t             req.setMethod(SolrRequest.METHOD.POST);\n\t   \n\t             // no need to set the response parser as binary is the default\n\t             // req.setResponseParser(new BinaryResponseParser());\n\t             // srsp.rsp = server.request(req);\n\t            // srsp.rsp = server.query(sreq.params);\n\t   \n\t             ssr.nl = server.request(req);\n\n  }\n catch (Throwable th) {\n          srsp.setException(th);\n          if (th instanceof SolrException) \n{\n            srsp.setResponseCode(((SolrException)th).code());\n          }\n else \n{\n            srsp.setResponseCode(-1);\n          }\n        }\n\n        ssr.elapsedTime = System.currentTimeMillis() - startTime;\n\n        return srsp;\n      }\n    };\n\n    pending.add( completionService.submit(task) );\n  }\n\nAfter \nant compile\nin Solr/dist:\napache-solr-4.0-SNAPSHOT.war                  apache-solr-dataimporthandler-4.0-SNAPSHOT.jar\napache-solr-analysis-extras-4.0-SNAPSHOT.jar  apache-solr-dataimporthandler-extras-4.0-SNAPSHOT.jar\napache-solr-cell-4.0-SNAPSHOT.jar             apache-solr-solrj-4.0-SNAPSHOT.jar\napache-solr-clustering-4.0-SNAPSHOT.jar       solrj-lib\napache-solr-core-4.0-SNAPSHOT.jar\n\n\n\n\nnow I forget the which patch crate a katta and katta proxy folder in example:\n\n\ndrwxrwxr-x 3 hadoop hadoop  4096 Nov  3 22:53 kattaproxy\ndrwxrwxr-x 3 hadoop hadoop  4096 Nov  3 22:53 katta\ndrwxrwxr-x 3 hadoop hadoop  4096 Oct 16 03:28 exampledocs\ndrwxrwxr-x 5 hadoop hadoop  4096 Oct 16 03:31 example-DIH\n\nwhich folder for katta ? how to set the SolrKattaServer in core container? \nThere are some test program, which can to refer? \n\nThanks for your help!\n\n "
        },
        {
            "author": "tom liu",
            "id": "comment-12928464",
            "date": "2010-11-05T03:44:28+0000",
            "content": "JohnWu\uff0cHuang \uff1a\n\nin katta integrations, the solr core has three roles:\n\n\tproxy, that is query dispatches or front server.\nall query would be sent to this proxy, and then dispatch to subproxy on katta cluster node.\nin this proxy, QueryComponent's distributedProcess would be executed. but the param isShard=false.\n\tsubproxy, that is proxy on katta cluster node.\nbecause each node maybe has more than one cores, so subproxy would receive query from proxy, and send query to any core.\nin this subproxy, QueryComponent's distributedProcess would be executed. but the param isShard=true.\n\tqueryCore, that is real query solr core.\nany query would be sent to querycore, and the querycore execute QueryComponent's process method.\n\n\n\nso, when run solr cluster or distribution, we would setup three envs.\n\n\tproxy's solrconfig.xml\n\n<requestHandler name=\"standard\" class=\"solr.KattaRequestHandler\" default=\"true\">\n    <lst name=\"defaults\">\n        <str name=\"echoParams\">explicit</str>\n        <str name=\"shards\">*</str>\n     </lst>\n</requestHandler>\n\n\n\tsubproxy's solrconfig.xml\n<requestHandler name=\"standard\" class=\"solr.SearchHandler\" default=\"true\">...</requestHandler>\n\tquerycore's solrconfig.xml\n<requestHandler name=\"standard\" class=\"solr.MultiEmbeddedSearchHandler\" default=\"true\">...</requestHandler>\n\n\n\nin katta's katta.node.properties::\nnode.server.class=org.apache.solr.katta.DeployableSolrKattaServer\n\nand in classes dirs of proxy's solr webapps\npls add two files:\n\n\tkatta.zk.properties\n\tkatta.node.properties\n\n "
        },
        {
            "author": "tom liu",
            "id": "comment-12930442",
            "date": "2010-11-10T02:12:47+0000",
            "content": "fixed some bugs:\n\n\tselect?qt=qtname do not supported in SolrKattaServer of subproxy\nin SolrKattaServer, any queryHanlder must be MultiEmbeddedSearchHandler.\nso in solrconfig.xml, we must change solr.SearchHandler to MultiEmbeddedSearchHandler\nfor example:\n\n  <searchComponent name=\"tvComponent\" class=\"solr.TermVectorComponent\"/>\n  <!-- A Req Handler for working with the tvComponent.  This is purely as an example.\n  You will likely want to add the component to your already specified request handlers. -->\n  <requestHandler name=\"tvrh\" class=\"solr.MultiEmbeddedSearchHandler\">\n    <lst name=\"defaults\">\n      <bool name=\"tv\">true</bool>\n    </lst>\n    <arr name=\"last-components\">\n      <str>tvComponent</str>\n    </arr>\n  </requestHandler>\n\n\n\tTermVectorComponent do not return results\nsee https://issues.apache.org/jira/browse/SOLR-2224\n\n "
        },
        {
            "author": "JohnWu",
            "id": "comment-12933413",
            "date": "2010-11-18T12:47:20+0000",
            "content": "tom liu\uff1a\n\n    in proxy's solrconfig.xml \n         Can we need add a \"saerch\" segment of handler as follows?\n\n<requestHandler name=\"search\" class=\"solr.KattaRequestHandler\" default=\"true\">\n\n<lst name=\"defaults\">\n<!-- <str name=\"shards\">0,1,2,3,4,5,6,7,8</str> -->\n\n<str name=\"shards\">\nn-12-0,n-12-1,n-12-2,n-12-3,n-12-4,n-12-5,n-12-6,n-12-7,n-12-8,n-12-9,n-12-10,n-12-11\n</str>\n...\n</requestHandler>\n\nit's old configuration of frontend solr, use this configure fileand the zookeeper is unembeded, but the zkclient of 1395patched solr can not find the index deployed by the outter katta!\n\nwithin old configure file:\nin zoo.cfg\nclientPort=2181\n\nbut the katta.zk.properties\nzookeeper.clientPort=2182\nIt's the reason why our client can not connect with the index of unembeded zookeeper ?\n\ncan you give us a reply?\n\nThanks!\nJohnWu "
        },
        {
            "author": "tom liu",
            "id": "comment-12935709",
            "date": "2010-11-25T10:08:24+0000",
            "content": "JohnWu:\n\nmy conf is:\nproxy/solrconfig.xml\n<requestHandler name=\"standard\" class=\"solr.KattaRequestHandler\" default=\"true\">\n\t<lst name=\"defaults\">\n\t<str name=\"echoParams\">explicit</str>\n\t<str name=\"shards\">*</str>\n\t</lst>\n  </requestHandler>\n\n \n\nsubproxy/solrconfig.xml\n<requestHandler name=\"standard\" class=\"solr.SearchHandler\" default=\"true\">\n    <!-- default values for query parameters -->\n     <lst name=\"defaults\">\n       <str name=\"echoParams\">explicit</str>\n     </lst>\n  </requestHandler>\n\n \n\nquerycore(shards)/solrconfig.xml\n<requestHandler name=\"standard\" class=\"solr.MultiEmbeddedSearchHandler\" default=\"true\">\n    <!-- default values for query parameters -->\n     <lst name=\"defaults\">\n       <str name=\"echoParams\">explicit</str>\n     </lst>\n  </requestHandler>\n\n \n\nzoo.cfg\nclientPort=2181\n...\n\n \n\nin Katta/conf and Shards/WEB-INF/classes\nkatta.zk.properties\nzookeeper.embedded=false\nzookeeper.servers=localhost:2181\n...\n\n  "
        },
        {
            "author": "JohnWu",
            "id": "comment-12964710",
            "date": "2010-11-29T11:49:56+0000",
            "content": "TomLiu:\n\n         oh, Thanks!\n         for this patch, we overcome some obstacles and share with everyone focus on this feature:\n\n         1) if you want debug the program with katta code, please do not use the katta code from SVN, which lib is so old (lucene is 2.4, hadoop is 0.19, zookeeper is 3.1.1), you need use Git trunk the code and build a eclipse project.\n         2) build a WTP project with the TomLiu patched solr in eclipse, and reference above katta project.\n         3) copy the zkclient-0.2.dev.jar of katta project to solr project lib (It's so terrible, the exception report less IOItech, that means 101tech)\n\ndebug run!\n        ok!\n\nTom:\n       Can you tell me the conf of solrHome?\n       we want to know the solr core deploy in build the proxy process?(if that, the process likes the 1301 patch) or the solr core already exists there, waiting for query?\n\nThanks! "
        },
        {
            "author": "tom liu",
            "id": "comment-12966040",
            "date": "2010-12-02T09:47:00+0000",
            "content": "solrHome is set :\n\n\twebapps/yourapp/web.xml\nthis is conf of frontserver or proxy.\n\tkatta script\nthis is conf of subproxy. such as:\n\n...\nKATTA_OPTS=\"$KATTA_OPTS -Dsolr.home=/var/data/solr/kattaproxy\"\n...\n\n\n\tsolrcore\nthis conf would be set by Katta/Solr automatic.\n\n\n\nin katta integration, tomcat (or jetty) is the trigger point, which connected to zkserver and katta nodes.\nkatta nodes that deployed solrcores are waiting for querys from tomcat. "
        },
        {
            "author": "JohnWu",
            "id": "comment-12966090",
            "date": "2010-12-02T12:42:52+0000",
            "content": "TomLiu:\n         yeah, today I use the katta Git code (Maybe katta0.6.3) add the lib: solr-1395-katta-0.6.2-3patch.jar then \n        bin/katta startNode org.apache.solr.katta.DeployableSolrKattaServer\n\nbut back the error as follows:\n\n       INFO: Solr home set to '/home/hadoop/workspace/kattaNoZK/solrHome/'\n       ERROR: could not create instance of class 'org.apache.solr.katta.DeployableSolrKattaServer': defaultCore:proxy could not be found\n\nI ask an question:\n       DeployableSolrKattaServer is for dispatch kattaRequest to subproxy, is right? which will use the in \n        T result = (T) _method.invoke(proxy, _args); to reflect kattaRequests to nodes?\n\nin proxy, Myquery is :\n       http://localhost:8080/solr-1395-katta-0.6.2-3patch/select?q=lovealice&version=2.2&start=0&rows=10&indent=on&isShard=false&distrib=true\n       is that right?\n\nThank you for your patience to answer me.\n\ntoday, I receive a email form aladeck, he let me introduce the whole process step by step, but I meet so many problem, I recommend you to answer this question for him.\n\nIf you are so busy, please help gets some key advices to me, I would first send an report to you, your reviewed, then I send it to them.\n\nThanks!\n\nJohnWu\n\n "
        },
        {
            "author": "JohnWu",
            "id": "comment-12966118",
            "date": "2010-12-02T13:32:02+0000",
            "content": "TomLiu:\n        Do you means that the patched solr with three cores?\n\n<solr persistent=\"false\">\n\n  <cores adminPath=\"/admin/cores\">\n\t<core name=\"proxy\" instanceDir=\"proxy\"/>\n\t<core name=\"subproxy\" instanceDir=\"subproxy\"/>\n\t<core name=\"queryCore\" instanceDir=\"queryCore\"/>\n  </cores>\n</solr>\n\n    is that right? "
        },
        {
            "author": "tom liu",
            "id": "comment-12966402",
            "date": "2010-12-03T03:44:27+0000",
            "content": "pls see the katta-solrcores picture.\n\nproxy and subproxy are different process, and sometimes are in different nodes.\n\nthe process with query is :\n\n\tproxy that is solrapp on tomcat, receive query that you send from IE or Firefox\n\tthen proxy dispatch query to subproxy\n\tsubproxy is katta nodes that holds DeployableSolrKattaServer\n\tso, with spliting shards, subproxy redispatch query to shard\n\tevery shard is a EmbeddedSolrServer, that holds one solrcore\n\n\n\nsolrhome in proxy, be set from web.xml or java -DsolrHome=......\nbut in subproxy, must be set in katta script\nin EmbeddedSolrServer, solrhome set automaticly. "
        },
        {
            "author": "JohnWu",
            "id": "comment-12967086",
            "date": "2010-12-06T05:11:53+0000",
            "content": "TomLiu:\n\n        I still jam in the query dipatch  to subproxy!\n\nSEVERE: Error calling public abstract org.apache.solr.katta.KattaResponse org.apache.solr.katta.ISolrServer.request(java.lang.String[],org.apache.solr.katta.KattaRequest) throws java.lang.Exception on pc-slave02:20000 (try # 1 of 3) (id=0)\njava.lang.reflect.InvocationTargetException\n\n       so, I give you my config in proxy, please review them:\n\n       in proxy \n\n           1)\n            solrHome-> solrconfig.xml\n                     <config>\n\n                             <requestHandler name=\"standard\" class=\"solr.KattaRequestHandler\" default=\"true\">\n\n                            <lst name=\"defaults\">\n                            <str name=\"echoParams\">explicit</str>\n                            <str name=\"shards\">*</str>\n                            </lst>\n                           </requestHandler>\n                    </config>\n\n                  ok, all the shard is watched and hold in Zookeeper, through zookeeper zkCli.sh\n\n                 [zk: pc-master(CONNECTED) 11] ls /katta/shard-to-nodes\n                 SPIndex05#1287138886138-99384445, SPIndex04#1287138886138-99384445\n\n                2)\n                 In proxy \n                 katta.node.properties:\n                 node.server.class=net.sf.katta.lib.lucene.LuceneServer\n\n\n               3)\n                query:  http://localhost:8080/solr-1395-katta-0.6.2-2patch/select/?q=lovealice&version=2.2&start=0&rows=10&indent=on&isShard=false&distrib=true\n\n                is that right?\n               especial in this step 2,\n\nThanks!\n\nJohnWu\n "
        },
        {
            "author": "tom liu",
            "id": "comment-12967118",
            "date": "2010-12-06T07:49:37+0000",
            "content": "in proxy:\nkatta.node.properties:\n#node.server.class=net.sf.katta.lib.lucene.LuceneServer\nnode.server.class=org.apache.solr.katta.DeployableSolrKattaServer\n\nyou must put apache-solr-core-XXX.jar to katta's lib, and some relative jars. "
        },
        {
            "author": "JohnWu",
            "id": "comment-12967125",
            "date": "2010-12-06T08:56:42+0000",
            "content": "Tomliu:\n        so in proxy , not in sub-proxy, katta startNode need add the class org.apache.solr.katta.DeployableSolrKattaServer ?\n\n        in katta's lib, there are too many differents: solr, lucene, zookeeper, the worst is lucene!\n\ncan you give me a mailbox? I can contect you directly (mine is panglaohu@gmail.com).\n\n       now, in workqueue of katta, NodeInteraction 135 row:\n       T result = (T) _method.invoke(proxy, _args);\n\n       proxy is a IPC of hadoop, it can not find the pc-slavo2:20000,\n       I lose some config in hadoop? or I need patch Hadoop with your https://issues.apache.org/jira/browse/HADOOP-7017?\n\n       please reply, thanks!\n\nJohnWu "
        },
        {
            "author": "Eric Pugh",
            "id": "comment-12967184",
            "date": "2010-12-06T13:32:32+0000",
            "content": "Tom, John,\n\nJust wanted to comment that having your conversation on this ticket in public has been great!  I am a couple steps behind you, having started up Katta, and started Solr with the patch, but not having success on searching.\n\nMy current error is that Solr can't find the katta.zk.properties file, where did you put it so it would be found on the class path?\n\nEric "
        },
        {
            "author": "JohnWu",
            "id": "comment-12969639",
            "date": "2010-12-09T06:42:16+0000",
            "content": "Eric:\nif you use eclipse to debug the project\nkatta.zk.properties in the src folder\n\nJohnWu "
        },
        {
            "author": "tom liu",
            "id": "comment-12970069",
            "date": "2010-12-10T05:00:33+0000",
            "content": "Eric\uff1a\nplease put katta.zk.properties and katta.node.properties into your webapp's WEB-INF/lib.\n\nJohnWu:\nin katta's lib, there were so many jars, but some jars must be there. you know, Solr must include Luence's jar .\n\nwith your problem, that can't find pc-slavo2:20000, katta must connect to pc-slavo2:20000 through tcp socket.\nhow about that you ping pc-slavo2 and telnet pc-slavo2 20000?\nyou can try adding pc-slavo2 with ip address to hosts files. "
        },
        {
            "author": "tom liu",
            "id": "comment-12970111",
            "date": "2010-12-10T09:50:01+0000",
            "content": "Eric\uff1a\nplease put katta.zk.properties and katta.node.properties into your webapp's WEB-INF/classes  "
        },
        {
            "author": "JohnWu",
            "id": "comment-12979502",
            "date": "2011-01-10T08:16:13+0000",
            "content": "TomLiu:\n\nin slave node the katta.node.properties also set as follows?\n\n#node.server.class=net.sf.katta.lib.lucene.LuceneServer\nnode.server.class=org.apache.solr.katta.DeployableSolrKattaServer "
        },
        {
            "author": "JohnWu",
            "id": "comment-12981179",
            "date": "2011-01-13T08:42:49+0000",
            "content": "TomLiu:\n\nin katta's lib, there were so many jars, but some jars must be there. you know, Solr must include Luence's jar .\n\nI add some libs to katta,\n\nDo you mean the solr embeded in katta?\n\nNow the request can form the master to slave, but how the subproxy send the query to query core?\n\nI configure the subproxy (katta with solr 1395 patch):\n\nnode.server.class=org.apache.solr.katta.DeployableSolrKattaServer\n\nand solr home is in katta sh, in solr home:\n\nsolr.config is solr.SearchHandler\n\nbut I do not know the katta can dispatch the query to query core, the solr.jar of katta will search the query in it's data directory, how about the shard confiure in subproxy?\n\ncan you give me a detailed reply?\n\nThanks alot! "
        },
        {
            "author": "tom liu",
            "id": "comment-12981204",
            "date": "2011-01-13T10:37:14+0000",
            "content": "In katta intergrated envs, solr is embeded.\n\nKatta does as distributed compute manager, which manages:\n\n\tnode startup/shutdown\n\tshard deploy/undeploy\n\trpc invoke to application/Solr\n\n\n\nand Solr does as application on distributed compute envs.\n\nin Master Box, QueryHandler must be solr.KattaSearchHandler in solrconfig.xml\nso that, kattaclient will be invoked by solrapp, and then invoked rpc to slave.\n\nin Slave Box, Katta will startup embeded solr, which is the subproxy.\n\nthe shard, that is the query solrcore, will be deployed by katta's script: \nbin/katta addIndex <indexName> <indexPath> "
        },
        {
            "author": "JohnWu",
            "id": "comment-12981260",
            "date": "2011-01-13T14:28:02+0000",
            "content": "Tomliu:\n      Maybe the last step for me, but it's so long!\nkatta use the lucene version is 3.0, but the solr-1395 use lucene is 4.0 snapshot, I package the solr-1395 to jar and put it in the katta class path, but the lucene version is different, \n\nso if I use the katta search SPIndex02 content:lovealice 1\n\nslave return the lucene exception.\n\n     how you make the lucene is same? add the keywordAnalyzer.class in lucene-40.-snapshot.jar?\n\nThanks!\n\nJohnWu "
        },
        {
            "author": "JohnWu",
            "id": "comment-12982499",
            "date": "2011-01-17T06:48:01+0000",
            "content": "TomLiu\uff1a\n     Now in query Core, the exception is org.apache.solr.search.DocSlice cannot be cast to org.apache.solr.common.SolrDocumentList\n\n    the exception is throw by :\n\n   // Added by tom liu\n\t\tSolrDocumentList sdl = (SolrDocumentList)nl.get(\"response\");\n\n\n     which is in public KattaResponse request(String[] shards, KattaRequest request) method of SolrKattaServer.java\n\n   nl is a NamedList,response will back a DocSlice, DocSlice extends DocSetBase implements DocList, but class SolrDocumentList extends ArrayList<SolrDocument>, that's can not cast reason!!!\n\n    what can I do? "
        },
        {
            "author": "tom liu",
            "id": "comment-12983076",
            "date": "2011-01-18T08:43:44+0000",
            "content": "sorry, the above comments have errors:\nin querycore(shards)/solrconfig.xml, requestHandler must be solr.MultiEmbeddedSearchHandler.\nquerycore(shards)/solrconfig.xml\n  <requestHandler name=\"standard\" class=\"solr.MultiEmbeddedSearchHandler\" default=\"true\">\n    <!-- default values for query parameters -->\n     <lst name=\"defaults\">\n       <str name=\"echoParams\">explicit</str>\n    </lst>\n  </requestHandler>\n\n \n\nQueryComponent returns DocSlice, but XMLWrite or EmbeddedServer returns SolrDocumentList from DocList. "
        },
        {
            "author": "JohnWu",
            "id": "comment-12983586",
            "date": "2011-01-19T07:37:28+0000",
            "content": "oh, TomLiu:\n\nI use the MultiEmbeddedSearchHandler in query core, but the request also can not through the code:\n\n// add end\n\t\tNamedList nl = resp.getValues();\n\t\tnl.add(\"QueriedShards\", shards);\t\t\n\n// Added by tom liu\n\t\tSolrDocumentList sdl = (SolrDocumentList)nl.get(\"response\");\n\t\tif( sdl == null )\n{\n\t\t\tnl.add(\"response\", new SolrDocumentList());\n\t\t\tif( log.isWarnEnabled() )\n\t\t\t\tlog.warn(\"SolrServer.SolrResponse: no response\");\n\t\t}\n\nif you use the katta start the embedded solr, the queryComponent is the necessary component for solr, so the above code will throw the exception of cast DocSlice to SolrDocumentList.\nDoes I miss some step?\n\nwhat means but XMLWrite or EmbeddedServer returns SolrDocumentList from DocList.?\n "
        },
        {
            "author": "JohnWu",
            "id": "comment-12984038",
            "date": "2011-01-20T06:31:14+0000",
            "content": "do you mean if we not use the queryComponent , we can not throw the cast exception?\nso we need correct the solr.config with \n\n<queryResponseWriter name=\"xml\" class=\"org.apache.solr.request.XMLResponseWriter\" default=\"true\"/>\n\nuse the XMLResponseWriter to write the response?\n\n\n "
        },
        {
            "author": "Jerry Mindek",
            "id": "comment-12985743",
            "date": "2011-01-24T15:44:03+0000",
            "content": "Hello! I am very interested in integrating Katta into Solr.\n\nUnfortunately, I have been unsuccessful at compiling or build Katta into Solr.\nI have tried to integrate Katta into both branch-1.4 and the current Solr trunk. \n\nCould someone please post an up-to-date integration guide?  "
        },
        {
            "author": "JohnWu",
            "id": "comment-12991279",
            "date": "2011-02-07T05:51:30+0000",
            "content": "TomLiu:\n\nas you said:QueryComponent returns DocSlice, but XMLWrite or EmbeddedServer returns SolrDocumentList from DocList.\n\nI set the requestHandler to solr.MultiEmbeddedSearchHandler but the queryComponent still return the DocSlice.\n\nCan you give me some advices?\n\nThanks!\n\nJohnWu "
        },
        {
            "author": "tom liu",
            "id": "comment-12993799",
            "date": "2011-02-12T02:02:07+0000",
            "content": "JohnWu:\n the request and response are transfered between those commponents:\n\n\tone tomcat webapp, which is the frontserver before Katta-Integrated-Solr\n\tkattaclient, which runs on tomcat webapp, and dispatch requestes to KattaCluster with RPC\n\tKattaCluster Node, which handles contentserver(ISolrServer), and RPC server\n\tISolrServer, which recv request, and dispatch request to SolrCore\n\tSolrCore, which is EmbeddedSolrServer, and returns response from request\n\n\n\n so, queryComponent return the DocSlice, but with EmbeddedSolrServer, the DocSlice is casted to SolrDocumentList.\n\n i attached one JPG file, which shows some commponents deployed.\n\n with katta, there are two deployments:\n\n\tapp deployment: deploy commponents, and startup\n\tdata deployment: use katta script to deploy data, for example, addIndex/removeIndex/redeployIndex\n\n "
        },
        {
            "author": "JohnWu",
            "id": "comment-12994224",
            "date": "2011-02-14T08:04:44+0000",
            "content": "TomLiu:\n   how to configure the  ISolrServer, let it dispatch request to SolrCore? only in solrconfig.xml(searchHandler) and properties(DeployableSOlrKattaServer)?\n\nJohnWu "
        },
        {
            "author": "tom liu",
            "id": "comment-12994255",
            "date": "2011-02-14T10:08:02+0000",
            "content": "the ISolrServer is handled by Katta-Node, configures be:\n\n\tsolrconfig.xml: which is used by ISolrServer's Default SolrCore\n\tkatta script: which is used to tell iSolrServer's SolrHome.\n\n\n\nKatta's Script:[On katta node, but not on katta master]\n\nKATTA_OPTS=\"$KATTA_OPTS -Dsolr.home=/var/data/solr -Dsolr.directoryFactory=solr.MMapDirectoryFactory\"\n\n\n\nKatta startup node, the IsolrServer will be got solr.home and solr.directoryFactory\nand then, ISolrServer's Default SolrCore will use those env to hold solrcore. "
        },
        {
            "author": "JohnWu",
            "id": "comment-12994642",
            "date": "2011-02-15T03:17:17+0000",
            "content": "Tomliu:\n   Do you mean ISolrServer use katta script to direct the query core home and indexDirectory?\n\n   now I use a katta with solr patched jar to start the subproxy, the solr home is set in katta script:\n\n   -Dsolr.home=/home/hadoop/workspace/kattaNoZK/solrHome\n\n   in conf folder of solrHome the solrconfig.xml is:\n\n   <requestHandler name=\"standard\" class=\"solr.SearchHandler\" default=\"true\">\n    <!-- default values for query parameters -->\n     <lst name=\"defaults\">\n       <str name=\"echoParams\">explicit</str>\n       <!--<str name=\"shards.qt\">tvrh</str>  --> \n     </lst>\n   </requestHandler>\n\n   so the solr send the query to this core of solrHome with searchHanler (which use query component and return the Doclice)\n\nAs you yesterday said, I need correct the solrHome of katta script (slave node) direct it to query core? but how to configure the sub-proxy solr home with solr.searchHandler?\n\nThanks!\n\nJohnWu\n\n "
        },
        {
            "author": "tom liu",
            "id": "comment-12994688",
            "date": "2011-02-15T08:23:16+0000",
            "content": "ISolrServer's config is set by katta script. QueryCore's config will be set autolly.\n\nSub-proxy solr is just proxy, which do not process any request.\nso, sub-proxy dispatch request to querycore. and querycore process request, return solrdoclists.\n\nbut, you get the exception which do not cast object type. i think that querycore would be wrong. "
        },
        {
            "author": "JohnWu",
            "id": "comment-12994757",
            "date": "2011-02-15T11:13:17+0000",
            "content": "tomliu:\n   so the solrhome of ISolrServer need configure to multi-core style?\n   in solr.xml\n<solr persistent=\"false\">\n  <cores adminPath=\"/admin/cores\">\n\n\t<core name=\"queryCore\" instanceDir=\"queryCore\"/>\n\n  </cores>\n</solr>\n   but how to set the handler to each role of katta slave?\n\n   can you show the solr home folder hierarchy and config content of katta slave node? "
        },
        {
            "author": "tom liu",
            "id": "comment-12995212",
            "date": "2011-02-16T08:20:28+0000",
            "content": "On Katta slave node, my folder hierarchy is:\n\n\n\n/var/data\nroot\n\n\n/var/data/hadoop\nstore hadoop data\n\n\n/var/data/hdfszips\nstore zip tmp data, which get from hdfs,then move to katta's shardes\n\n\n/var/data/solr\nroot store solr core configures\n\n\n/var/data/solr/seoproxy\nstore seoproxy's solr config,which is used by sub-proxy\n\n\n/var/data/katta/shards/nodename_20000/seo0#seo0\nstore seo0 shard,which is deployed from master node\n\n\n/var/data/zkdata\nstore zkserver data,which is zk logs and snapshotes\n\n\n\n\n\nOn Katta master node, my folder hierarchy is:\n\n\n\n/var/data\nroot\n\n\n/var/data/hadoop\nstore hadoop data\n\n\n/var/data/hdfsfile\nstore solr tmp data, which get from solr dataimporter,then zip && put to hdfs\n\n\n/var/data/solr\nroot store solr core configures\n\n\n/var/data/solr/seo\nstore seo's solr config,which is used by tomcat's webapp\n\n\n/var/data/zkdata\nstore zkserver data,which is zk logs and snapshotes\n\n\n\n\n\nso, my config is from five folderes:\n\n\n\nMaster\n/var/data/solr/seo\ntomcat webapp's solrcore config\n\n\nSlave\n/var/data/solr/seoproxy\nsub-proxy's solrcore config\n\n\nMaster\n/var/data/hdfsfile\nquery-core's config,which is config template\n\n\nHDFS\nhttp://hdfsname:9000/seo/seo0.zip\nquery-core seo0's zip file,which is hold conf\n\n\nSlave\n/var/data/katta/shards/nodename_20000/seo0#seo0/conf\nquery-core seo0's config,which is unzipped from seo0.zip of HDFS\n\n\n\n\n\nand, /var/data/hdfsfile structure is:\n\nseo@seo-solr1:/var/data/hdfsfile$ ll\ntotal 28\ndrwxr-xr-x 6 seo seo 4096 Oct 21 15:21 ./\ndrwxr-xr-x 4 seo seo 4096 Feb 16 15:49 ../\ndrwxr-xr-x 2 seo seo 4096 Oct  8 09:17 bin/\ndrwxr-xr-x 4 seo seo 4096 Jan 21 18:22 conf/\ndrwxr-xr-x 3 seo seo 4096 Oct 21 15:21 data/\ndrwxr-xr-x 2 seo seo 4096 Sep 29 14:01 lib/\n-rw-r--r-- 1 seo seo 1320 Oct  8 09:20 solr.xml\n\n "
        },
        {
            "author": "JohnWu",
            "id": "comment-12995792",
            "date": "2011-02-17T12:48:19+0000",
            "content": "TomLiu:\n  you means use the katta addindex seo.zip to deploy the querycore to katta slave node?\n  seo.zip is patched solr? or use the normal solr?\nJohnWu "
        },
        {
            "author": "Sanjay",
            "id": "comment-12996193",
            "date": "2011-02-18T01:39:13+0000",
            "content": "Hi John,\n\nI'am facing problem patching solr trunk with solr-1395-katta-0.6.2-3.patch. I'am sure missing something, should I patch katta trunk with same patch first?\nThe install instructions above are old and looks like they no longer apply. \n\nHere are the steps I followed:\n\n1. svn co http://svn.apache.org/repos/asf/lucene/dev/trunk lucene\n2. cd lucene/solr/src/java\n3. wget http://xyz.com/solr-1395-katta-0.6.2-3.patch\n4. patch -p0 -i solr-1395-katta-0.6.2-3.patch\n\npatching file java/org/apache/solr/katta/SolrIndexer.java\npatching file java/org/apache/solr/handler/KattaRequestHandler.java\ncan't find file to patch at input line 1663\nPerhaps you used the wrong -p or --strip option?\nThe text leading up to this was:\n--------------------------\n\n\n\n\n\nProperty changes on: java/org/apache/solr/handler/KattaRequestHandler.java\n\n\n___________________________________________________________________\n\n\nAdded: svn:mime-type\n\n\n   + text/plain\n\n\n\n\nIndex: java/org/apache/solr/handler/component/SearchHandler.java\n\n\n===================================================================\n\n\n\u2014 java/org/apache/solr/handler/component/SearchHandler.java  (revision 1003107)\n\n\n+++ java/org/apache/solr/handler/component/SearchHandler.java  (working copy)\n\n\n\n\n\nThanks!,\nSanjay "
        },
        {
            "author": "tom liu",
            "id": "comment-12996307",
            "date": "2011-02-18T09:27:10+0000",
            "content": "use the katta addindex seo.zip to deploy the querycore to katta slave node.\n\nseo.zip is patched solr. "
        },
        {
            "author": "JohnWu",
            "id": "comment-12997298",
            "date": "2011-02-21T08:23:27+0000",
            "content": "TomLiu:\n   can you tell me the seo.zip contains folder hierarchy?\n   I use katta addindex only deploy the index in katta cluster, so the core is pre load in each node, and the MultiEmbeddedSearchHandler return the DocSlice,\n   so tell me why or I try to zip a patched solr with conf as you said, please tell me your seo.zip contents, Thanks!\nJohnWu\n\nSanjay:\n   patch -p0 -i solr-1395-katta-0.6.3.patch is right.\n   Maybe you trunk code is the newest? Tom can reply this issue.\nJohnWu "
        },
        {
            "author": "tom liu",
            "id": "comment-12997387",
            "date": "2011-02-21T13:06:35+0000",
            "content": "i just zip /var/data/hdfsfile to seo.zip:\nzip -r /var/data/hdfsfile seo "
        },
        {
            "author": "JohnWu",
            "id": "comment-12997684",
            "date": "2011-02-22T08:30:29+0000",
            "content": "Tomliu: \nhow to katta addIndex hdfs://***.zip to queryCore /data folder? \nyou know the katta addindex target folder is a tmp folder\uff1f \nDo you set the folder with the -Dsolr.directoryFactory=solr.MMapDirectoryFactory? \nhow to set the config for MMapDirectoryFactory? \nThanks! JohnWu "
        },
        {
            "author": "tom liu",
            "id": "comment-12998773",
            "date": "2011-02-24T09:15:58+0000",
            "content": "please see conf file katta.node.properties.\nthe node.shard.folder property defined the folder of queryCore "
        },
        {
            "author": "JohnWu",
            "id": "comment-13000086",
            "date": "2011-02-28T02:21:24+0000",
            "content": "TomLiu:\n   ok, as you said, I use the katta addindex the querycore to katta(in node properties).\n   Now I ask you another question about:\n   how the sub-proxy dispatch the query to queryCore? (set shard in solrconfig.xml?)\n   we know the query in sub-proxy param is isShard=true, (only the query can select the queryCore to seo0#seo0)?\nJohnWu "
        },
        {
            "author": "JohnWu",
            "id": "comment-13000736",
            "date": "2011-03-01T06:18:37+0000",
            "content": "TomLiu:\n   just one question, how the subproxy dispatch the query to queryCore?\nJohnWu "
        },
        {
            "author": "tom liu",
            "id": "comment-13000786",
            "date": "2011-03-01T09:09:57+0000",
            "content": "you can debug or trace the process:\n\n\twebapp's param: shards=*\n\tkattaclient's process: shards=seo0,seo1,...\n\tsub-proxy's param: shards=seo0 [maybe many requestes,so param is not same]\n\tsub-proxy then dispatch request to seo0 queryCore\n\n\n\nother process, iff you put shards=seo0::\n\n\twebapp's param: shards=seo0\n\tkattaclient's process: shards=seo0\n\tsub-proxy's param: shards=seo0 [one request]\n\tsub-proxy then dispatch request to seo0 queryCore\n\n "
        },
        {
            "author": "JohnWu",
            "id": "comment-13000871",
            "date": "2011-03-01T13:37:28+0000",
            "content": "Tomliu:\n   yeah, I trace the process,\n1) proxy: shard=*;\n2) subproxy receive the request, param: shards=seo0;\n\nbut I don't know how to set the subproxy to dispatch the query to seo0, you know the solr is not start as a service in Tomcat(subproxy is start by katta), so slorconfig.xml of subproxy can not set the shard as the http://localhost:8080/seo0.\n\n   we trace the code, find out the query in proxy param: isdistribute=true, can call the distributeprocess, but the query in subproxy, the param: isdistribute=false,\n\n   so can you tell me the how to set the shard info in subproxy?\nJohnWu "
        },
        {
            "author": "JohnWu",
            "id": "comment-13001314",
            "date": "2011-03-02T07:05:43+0000",
            "content": "Tomliu:\n   DeployableSolrKattaServer start a embeddedSOlrServer, we think the query need to shard, but the core descriptor shows the core is subproxy, so how we set the config of subproxy to find the seo0 shard? if distribute=false, the shard query score process can not trigger. "
        },
        {
            "author": "JohnWu",
            "id": "comment-13002432",
            "date": "2011-03-04T03:08:55+0000",
            "content": "ok,ALL\n\nwe have the correct result back \uff08form slave02 to master\uff09:\n<result name=\"response\" numFound=\"1\" start=\"0\">\n\\u2212\n<doc>\n<str name=\"id\">MA147LL/A</str>\n<str name=\"name\">Apple 60 GB iPod with Video Playback Black</str>\n<str name=\"manu\">Apple Computer Inc.</str>\n\\u2212\n...\n\nnote:\n  if you use the Tomliu's patch please correct the code of queryComponent:\n\n    //JohnWu correct the && to ||, need decide the shards is null\n    if (shards == null)\n{\n    \thasShardURL = false;\n    }\nelse\n{\n    \thasShardURL = shards != null || shards.indexOf('/') > 0;\n    }\n\nso the queryCore can enter the distribute process and get the hits, the DocSlice cast to DocumentList\n\nIf you have any problem, please ask me, we discuss it together\n\nThanks!\n\n\njohnWu "
        },
        {
            "author": "Jamie Johnson",
            "id": "comment-13034887",
            "date": "2011-05-17T17:09:17+0000",
            "content": "I think I have most of this running, but I still have a disconnect.  I've done the following:\n1. Patched\n2. Compiled\n3. Run web application with additional request handler added to solrconfig.mxl\n4. Started katta\n5. Started DeployableSolrKattaServer\n\nNow if I execute a query (http://localhost:8983/solr/select/?q=*%3A*&version=2.2&start=0&rows=10&indent=on&distrib=true) I get net.sf.katta.util.KattaException: No shards for indices: [*], which makes perfect sense since I have no indices deployed.  As a simple test I deployed an index that comes stock with katta (bin/katta addIndex testIndex src/test/testIndexA 2), and execute my query again and I get no results (which also makes sense since that index does not match my solr config).\n\nAll of that being said what is the process for publishing a core to katta?  Is there a way to use the standard http methods to add to the index (using something like java -jar post.jar *.xml)?  If not how is it done?  Any insight into this would be greatly appreciated. "
        },
        {
            "author": "Pulkit Agrawal",
            "id": "comment-13038118",
            "date": "2011-05-23T18:27:13+0000",
            "content": "Hi All,\n\nI am new to solr and katta.\nI really want to integrate both. But didn't find a guided path.\nCan you guys please help me how I can integrate the both\n\nThanks in advancd. "
        },
        {
            "author": "Pulkit Agrawal",
            "id": "comment-13039186",
            "date": "2011-05-25T16:21:01+0000",
            "content": "I am pretty close to get it done.\nJust need little help.\n\nI am setup whole thing on localhost.\ncan you please guide me where should i put my configuration file.\n\nI have two separate directories for solr and katta.\nWhere is proxy and where to putvariousconfihguration file?\n\nPlease help\n\nThanks in Advance  "
        },
        {
            "author": "Pulkit Agrawal",
            "id": "comment-13039313",
            "date": "2011-05-25T20:15:19+0000",
            "content": "I am able to run the proxy but still stuck with \n\nsubproxy:\nkatta startNode -c org.apache.solr.katta.DeployableSolrKattaServer -s\n\nI got folloeing error \n\nNFO: New CoreContainer 26210109\nMay 25, 2011 8:10:28 PM org.apache.solr.core.SolrResourceLoader <init>\nINFO: Solr home set to '/home/ec2-user/pulkit/example/solr/'\nMay 25, 2011 8:10:28 PM org.apache.solr.core.SolrResourceLoader <init>\nINFO: Solr home set to '/home/ec2-user/pulkit/example/solr/./'\nMay 25, 2011 8:10:28 PM org.apache.solr.core.SolrConfig initLibs\nINFO: Adding specified lib dirs to ClassLoader\nMay 25, 2011 8:10:28 PM org.apache.solr.common.SolrException log\nSEVERE: org.apache.solr.common.SolrException: Invalid luceneMatchVersion 'LUCENE_40', valid values are: [LUCENE_20, LUCENE_21, LUCENE_22, LUCENE_23, LUCENE_24, LUCENE_29, LUCENE_30, LUCENE_CURRENT] or a string in format 'V.V'\n        at org.apache.solr.core.Config.parseLuceneVersionString(Config.java:306)\n        at org.apache.solr.core.Config.getLuceneVersion(Config.java:286)\n        at org.apache.solr.core.SolrConfig.<init>(SolrConfig.java:132)\n        at org.apache.solr.core.CoreContainer.create(CoreContainer.java:578)\n        at org.apache.solr.core.CoreContainer.load(CoreContainer.java:406)\n        at org.apache.solr.core.CoreContainer.load(CoreContainer.java:291)\n        at org.apache.solr.core.CoreContainer.<init>(CoreContainer.java:109)\n        at org.apache.solr.katta.DeployableSolrKattaServer.<init>(DeployableSolrKattaServer.java:62)\n        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)\n        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)\n        at java.lang.reflect.Constructor.newInstance(Constructor.java:513)\n        at java.lang.Class.newInstance0(Class.java:355)\n        at java.lang.Class.newInstance(Class.java:308)\n        at net.sf.katta.util.ClassUtil.newInstance(ClassUtil.java:51)\n        at net.sf.katta.Katta$3.parseArguments(Katta.java:303)\n        at net.sf.katta.Katta$Command.parseArguments(Katta.java:958)\n        at net.sf.katta.Katta.main(Katta.java:95)\nCaused by: java.lang.IllegalArgumentException: No enum const class org.apache.lucene.util.Version.LUCENE_40\n        at java.lang.Enum.valueOf(Enum.java:196)\n        at org.apache.lucene.util.Version.valueOf(Version.java:30)\n        at org.apache.solr.core.Config.parseLuceneVersionString(Config.java:304)\n        ... 17 more\n\nERROR: could not instantiate class org.apache.solr.katta.DeployableSolrKattaServer\njava.lang.RuntimeException: could not instantiate class org.apache.solr.katta.DeployableSolrKattaServer\n        at net.sf.katta.util.ClassUtil.newInstance(ClassUtil.java:53)\n        at net.sf.katta.Katta$3.parseArguments(Katta.java:303)\n        at net.sf.katta.Katta$Command.parseArguments(Katta.java:958)\n        at net.sf.katta.Katta.main(Katta.java:95)\nCaused by: org.apache.solr.common.SolrException: defaultCore:proxy could not be found\n        at org.apache.solr.katta.SolrKattaServer.<init>(SolrKattaServer.java:54)\n        at org.apache.solr.katta.DeployableSolrKattaServer.<init>(DeployableSolrKattaServer.java:62)\n        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)\n        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)\n        at java.lang.reflect.Constructor.newInstance(Constructor.java:513)\n        at java.lang.Class.newInstance0(Class.java:355)\n        at java.lang.Class.newInstance(Class.java:308)\n        at net.sf.katta.util.ClassUtil.newInstance(ClassUtil.java:51)\n        ... 3 more\nUsage:\n  startNode [-c <serverClass>] [-p <port number>]              Starts a local node\n\n\n\n\n\nInvalid luceneMatchVersion 'LUCENE_40'  ----------- What does that mean?\n\nAny pointer?\nThanks "
        },
        {
            "author": "JohnWu",
            "id": "comment-13039585",
            "date": "2011-05-26T08:23:27+0000",
            "content": "Pulkit Agrawal\uff1a\n\n      start the katta with embeded solr, you config the class(DeployableSolrKattaServer) in katta config file is ok.\n\n      now,  I think your lucene version is not suitable for this solr after patched. Lucene 4.0 means the 1395 solr use lucene-4.0-snapshot. It is a develop version of lucene, The index of lucene 3.0 and solr1.4.0 is matched for it.\n\n      I think you have a long term for it, you doen't build the code of lucene from the cvs of solr(as TomLiu said), so you the dispatch query to proxy, but the proxy can not parse it.\n      Pay attention to the config and query core, the solr home and config file need same as each other.\nThanks!\n\n\n "
        },
        {
            "author": "Stefan Groschupf",
            "id": "comment-13039860",
            "date": "2011-05-26T18:50:10+0000",
            "content": "Hey People,\nI would love to make sure everybody understands it is technically possible to embed Solr into Katta but it does not make sense. \nThere is zero value add in this! In fact you just slow down your searches.\n\nStefan  "
        },
        {
            "author": "Eric Pugh",
            "id": "comment-13039864",
            "date": "2011-05-26T19:03:25+0000",
            "content": "I wanted to somewhat second Stefan's comment.   There are some advantages to using Katta, but what we found is that this patch is very NOT ready for use.  If you want to integrate Solr into a Katta type world, you are going to be writing some serious code, so don't just budget a week to hook Katta into Solr!\n\nWe ended up going down the Solr Cloud route on a recent project, and hooking in some distributed support for durable indexes.  Inspired by this patch, but certainly not using this patch!    "
        },
        {
            "author": "Stefan Groschupf",
            "id": "comment-13039887",
            "date": "2011-05-26T19:54:23+0000",
            "content": "Thanks Eric, \nI would argue you don't need Solr if you want to do a serious distributed indexing and searching platform the advantages of Solr's HTTP API and it's overhead are just in your way.\nBut take that with salt, since I'm the guy that founded Katta.  "
        },
        {
            "author": "JohnWu",
            "id": "comment-13040014",
            "date": "2011-05-27T01:00:59+0000",
            "content": "why we use this patch "
        },
        {
            "author": "JohnWu",
            "id": "comment-13040037",
            "date": "2011-05-27T02:29:07+0000",
            "content": "Stefan Groschupf,Eric Pugh,Pulkit Agrawal and other peoples:\n\ntoday, I upload a figure for 1395 patch, and describe why we use this patch.  (solr1395.jpg                 27/May/11 01:00 226 kB)\n\nthe whole ARCH contains 3 levels:\n1) Solr level\n2) katta slave node level\n3) Hadoop level\n\nall the frameworks give web app server, distribute search, data store and MapReduce features to lucene.\n\nI will give you a detail document about how to use this patch, now, just say the process of a coarse-grained \n\na) build the environment\n\n   1)install Hadoop (ensure you can browse your files in HDFS)\n   2)install Zookeeper (ensure you can zkCli.sh connect the server)\n   3)install katta (ensure masternode and datanode can run, use \"katta check\" the shard and \"start Master -ne\" means you use unembeded style to  satrt the katta master)\n\nb) patch the solr\n\n   1) trunk the code form http://svn.apache.org/repos/asf/lucene/dev/trunk \n   (tom liu added a comment - 20/Oct/10 06:19)\n\n   2) add the patch, manual patch some code if reject  \n   (solr-1395-katta-0.6.2-3.patch       10/Nov/10 02:12 108 kB)\n\n   3) correct the code of queryComponent(solr)\n\n   //JohnWu correct the && to ||, need decide the shards is null\n   if (shards == null)\n{ hasShardURL = false; }\nelse\n{ hasShardURL = shards != null || shards.indexOf('/') > 0; }\n\n\nc) query and config the system (katta-solrcores.jpg    03/Dec/10 03:44    94 kB)\n\n    1) web container (tomcat) start the solr server as the figure showed the proxy, you need correct the solrconfig.xml\n\n       <requestHandler name=\"standard\" class=\"solr.KattaRequestHandler\" default=\"true\">\n          <lst name=\"defaults\">\n            <str name=\"echoParams\">explicit</str>\n            <str name=\"shards\">*</str>\n          </lst>\n       </requestHandler>\n\n     the solr will use the kattaclient to dispatch the query to subproxy nodes (katta datanodes)\n\n    2) katta datanode start with embeded solr\n\n    correct the katta sh script as follows:\n    KATTA_OPTS=\"$KATTA_OPTS -Dsolr.home=/var/data/solr -Dsolr.directoryFactory=solr.MMapDirectoryFactory\"\n\n    add the \"zookeeper.servers=localhost:2181\" and \"zookeeper.embedded=false\" in katta.zk.properties, put this file in your class path\n\n    the proxy solr config, you need correct the solrconfig.xml as follows:\n    <requestHandler name=\"standard\" class=\"solr.SearchHandler\" default=\"true\">...</requestHandler>\n\n    3) deploy your queryCore.zip(the folder hieracy, please look TomLiu comments) with \"katta addIndex queryCore*.zip hdfs://*****\"\n    deployed queryCore has the solrconfig.xml as follows:\n    <requestHandler name=\"standard\" class=\"solr.MultiEmbeddedSearchHandler\" default=\"true\">...</requestHandler>\n\n    4)use the follows query\n    http://localhost:8080/solr-1395-katta-0.6.2-2patch/select/?q=apple&version=2.2&start=0&rows=10&indent=on&isShard=false&distrib=true\n\n    the index you can use the example of solr1.4.\n\n    ok, the hits return :\n\n    <result name=\"response\" numFound=\"1\" start=\"0\">\n    \\u2212\n     <doc>\n         <str name=\"id\">MA147LL/A</str>\n        <str name=\"name\">Apple 60 GB iPod with Video Playback Black</str>\n        <str name=\"manu\">Apple Computer Inc.</str>\n    \\u2212\n\nd) some amazing things\n\nIf one node crashed, the other nodes will still run.The system will redeploy a set of index to a new node, keep the system stable on fly and replicate number is a fixed number.\n\nSummary\n\nIf you use the patch, you need read all the comments as the order of Date.\nIf you want a flexible structure, please use this patch.\nIf you want use the solr multicore, please use this patch.\n\nThanks to TomLiu, Jason Rutherglen and Jason Venner.\n\nThanks alot!\n\nJohnWu "
        },
        {
            "author": "JohnWu",
            "id": "comment-13040042",
            "date": "2011-05-27T02:57:06+0000",
            "content": "Stefan Groschupf:\n\n    Thanks to your contribution in katta, but do you think the lucene can supply some functions like facet and multi-core in solr?\n\n\u3000\u3000\u3000We all know the patch use Hadoop rpc connect the slave nodes like katta your built.We want build a cloud protoype with Web APP server features. But we didn't need your advertisement in Katta.Is there zero value for this patch? cost in Network transmission\uff1fIf you select distribute search, all the issues you can not avoid.\n\n    so plase give us some valuable suggestions or code\uff53, do not promote your katta, Despise you so advertisement in\u3000Katta\uff0e\n\nJohnWu "
        },
        {
            "author": "JohnWu",
            "id": "comment-13040043",
            "date": "2011-05-27T03:11:49+0000",
            "content": "Eric Pugh\uff1a\n\u3000\u3000\u3000TomLiu\u3000patch the code form the svn, but code is changed. so I think you need find the old code about 2010 octmeber, the system can work.\n\n     the code is just add some class of katta to solr and correct the queryComponent of solr. But the lucene code is the biggest problem for us, it is a devleopment version.\n\n     the whole config process, I have a comment for it. Please tell us your problem.\nJohnWu "
        },
        {
            "author": "Jason Rutherglen",
            "id": "comment-13041026",
            "date": "2011-05-30T07:38:28+0000",
            "content": "I think John Wu brings up excellent points. I don't think Solr Cloud\noffers the same thing as this issue, and/or it's not articulated well on\nthe wiki. Lucene out of the box doesn't offer facets and other search\ncomponent features. These are things Solr provides but could/should be\nmodularized out as already proposed. Solr is currently too tightly\ninterwoven, this is perhaps why this patch is challenging to operate.\nIntegrating alternative systems into Solr seems to be political from my\npoint of view, eg, <political>Solr + Katta</political> "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13043687",
            "date": "2011-06-03T16:46:32+0000",
            "content": "Bulk move 3.2 -> 3.3 "
        },
        {
            "author": "tom liu",
            "id": "comment-13100161",
            "date": "2011-09-08T08:50:08+0000",
            "content": "i upload one patch, that based on current trunk version.\nmy env:\nhadoop:  0.20.2\nzookeep: 3.3.3\nkatta:   0.6.3 "
        },
        {
            "author": "JohnWu",
            "id": "comment-13105770",
            "date": "2011-09-15T23:34:53+0000",
            "content": "Tom:\n   Thanks!\n   do you test the patch with facet and highlight? if you tested them, please tell us.\nThanks again.\nJohnWu "
        },
        {
            "author": "tom liu",
            "id": "comment-13105812",
            "date": "2011-09-16T01:58:38+0000",
            "content": "Johnwu:\n   surely, i do test the patch with:\n   stats,terms,termvector,hl,facet,debug\n\n   PS: i changed katta code for managing shards of updating.\n   iff you do not need this, pls comment the following code including client.broadcastToNodes(...) :\nKattaClient.java\n\tpublic ClientResult<KattaResponse> request(long timeout,\n\t\t\tString[] indexNames, KattaRequest request) throws KattaException {\n\t\tClientResult<KattaResponse> results = null;\n\t\tString path = request.getParams().get(CommonParams.QT);\n\t\tif (path!=null && path.equals(\"update\")) {\n\t\t\t// only for qt=update\n\t\t\tresults = client.broadcastToNodes(\n\t\t\t\t\ttimeout, true, REQUEST_METHOD, 0, indexNames, null, request);\n\t\t} else {\n\t\t\tresults = client.broadcastToIndices(\n\t\t\t\t    timeout, true, REQUEST_METHOD, 0, indexNames, null, request);\n\t\t}\n\t\treturn results;\n\t}\n\n  "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13106473",
            "date": "2011-09-16T14:51:14+0000",
            "content": "3.4 -> 3.5 "
        },
        {
            "author": "JohnWu",
            "id": "comment-13107053",
            "date": "2011-09-17T07:37:11+0000",
            "content": "Tom:\n  1) yes, the code is update the index with segment style, that's great,but it can not sync index when one node crash down. So I create index with renew the whole index.\n\n  2) still for the facet issue, can you give me a case about facet? tell me the detail steps, someone told me the facet data is stored in the front end, so it can not get the global info for our distributed system.\n\nthanks!\nJohnWu "
        },
        {
            "author": "laigood",
            "id": "comment-13108423",
            "date": "2011-09-20T07:53:49+0000",
            "content": "Hello everyone,I'm very interested in integrate solr with katta,But i have some question.\n1.Is it only affect in solr1.4? Does anyone successful integrate with solr3.X?\n2.Efficiency,after 2times proxy,will it slow down query times,How slow is it?\n3.figture solr1395.jpg show that clusters have a master,is this mean if i index\nor search throught solr, must throught this master? how to make loadbalance?\nthanks "
        },
        {
            "author": "JohnWu",
            "id": "comment-13113121",
            "date": "2011-09-23T03:02:16+0000",
            "content": "Tom:\n   yes, you add modifyRequest method in \n1)DebugComponent\n2)FacetComponent\n3)HighlightComponent\n4)SearchComponent\n5)SpellCheckComponent\n6)TermVectorComponent\n\nthey all called by \"component.modifyRequest(this, me, sreq)\" of the ResponseBuilder, so above components can work.\n\nThanks!\n\nJohnWu "
        },
        {
            "author": "JohnWu",
            "id": "comment-13127311",
            "date": "2011-10-14T06:47:55+0000",
            "content": "Tom\uff1a\n   does the subproxy support multi-core?\n   I have different schema index, like \"book\" and \"address\"\n   now I create 2 cores name them \"book\" and \"address\"\n   I can dispatch the query to the sub-proxy, but only the proxy with book schema can facet the result,\n\n   so can you tell me how to setup multi-core in subproxy,which is a embedded solr server. I trace the code, it find the subproxy conf folder means the subproxy is a single core server.\n\n   Thanks!\n   or anther solution for me, the subproxy keep a minimized schema, the schema can fit for every katta node?\n\nJohnWu\n\n "
        },
        {
            "author": "tom liu",
            "id": "comment-13127354",
            "date": "2011-10-14T08:09:14+0000",
            "content": "JohnWu\uff1a\ni use the solr's regex rule to point which core would be use.\nFirst, in sub-proxy and top-solr, i merge two schema into one schema, eg. merge book and address schemas into bookaddress, then put bookaddress schema into top-solr and sub-proxy, so that solr would find every field in them.\nThen, on top-solr machine, i install one nginx proxy, it will act on a cache and proxy.\nLast, setup nginx, let's direct to correct cores. for example:\n1. in solr parameters, i add one such as: target=book[ or address]\n2. in nginx, i setup:\n\n    if ($args ~* ^(.*)target%3a(\\\\w*)(.*)$){\n          set $shard $2;\n          rewrite (.*) $1?shards=$shard\\\\\\\\w* break;\n    }\n    if ($args ~* ^(.*)target:(\\\\w*)(.*)$){\n          set $shard $2;\n          rewrite (.*) $1?shards=$shard\\\\\\\\w* break;\n    }\n\n\n3. then, the reqest url would be changed to URL&shards=book\\w* "
        },
        {
            "author": "tom liu",
            "id": "comment-13127359",
            "date": "2011-10-14T08:21:35+0000",
            "content": "fix bug on grouping\nand do not support update on cores "
        },
        {
            "author": "JohnWu",
            "id": "comment-13139997",
            "date": "2011-10-31T08:26:21+0000",
            "content": "tom\uff1a\n   For multi-schema case, I try to add multi-core in proxy and sub-proxy, but I meet the connection close issue.\n   please help me and analyze the case.\n\n   now in proxy, I set the solr home with proxymulticore folder, which contains structure as follows:\n   -proxymulticore\n   --customer\n   ----conf\n   ----data\n   --part\n   ----conf\n   ----data\n   --solr.xml\n\n  solr.xml as follows:\n  <cores adminPath=\"/admin/cores\">\n\t<core name=\"part\" instanceDir=\"part\">\t\t\n\t</core>\n\t<core name=\"customer\" instanceDir=\"customer\">\t\t\n\t</core>\n  </cores>\n\n  in part folder the solrcong.xml set as \n----------------\n  <requestHandler name=\"standard\" class=\"solr.KattaRequestHandler\" default=\"true\">\n    <lst name=\"defaults\">\n        <str name=\"echoParams\">explicit</str>\n        <str name=\"shards\">part-00000,part-00001,part-00002</str>\n     </lst>\n  </requestHandler>\n----------------\n\n  so in the proxy, we can use the request:\nhttp://localhost:8080/solr-1395-katta-0.6.2-2patch/part/select/?q=a*&version=2.2&start=0&rows=10&indent=on&isShard=false&distrib=true&core=part\n\n  the proxy will use the kattaRequest dispatch the query to katta datanodes(subproxy).\n\n  in subproxy, when we start the embedded solr with subproxymulticore folder, which structure as follows:\n   -subproxymulticore\n   --customer\n   ----conf\n   ----data\n   --part\n   ----conf\n   ----data\n   --solr.xml\n\n   exlusive the solrconfig.xml in part folder as follows, the others are same.\n----------------\n  <requestHandler name=\"standard\" class=\"solr.SearchHandler\" default=\"true\">\n    <!-- default values for query parameters -->\n     <lst name=\"defaults\">\n       <str name=\"echoParams\">explicit</str>\n     </lst>\n  </requestHandler>\n------------------ \n  now, I correct some code of DeployableSolrKattaServer.java in patched solr as follows:\n--------------------\n\tpublic DeployableSolrKattaServer() throws ParserConfigurationException,\n\t\t\tIOException, SAXException \n{\n//\t\tsuper(getServerName(), new CoreContainer(getSolrHome()\n//\t\t\t\t.getAbsolutePath(), getConfigFile()));\n\t\t//super(getServerName(), new CoreContainer());\n\n//By JohnWu, we do not direct find the conf folder of a core, we find the solr.xml to add cores.\n\n\t\tsuper(getServerName(),new CoreContainer.Initializer().initialize());\n\t\t\n\n\t}\n\n-------------------\n\nadd correct some code in SolrKattaServer.java\n\n-------------------\n\tpublic SolrKattaServer(String defaultCoreName, CoreContainer coreContainer) {\n\t\tthis.coreContainer = coreContainer;\n\t\thandler = new MultiEmbeddedSearchHandler(coreContainer);\n\t\thandler.init(new NamedList());\n\t\t//defaultCore = coreContainer.getCore(defaultCoreName);\n\t\tdefaultCores = coreContainer.getCores();\n//\t\tif (defaultCore == null)\n//\t\t\tthrow new SolrException(ErrorCode.UNKNOWN, \"defaultCore:\"\n//\t\t\t\t\t+ defaultCoreName + \" could not be found\");\n\t\tif (defaultCores == null)\n\t\t\tthrow new SolrException(ErrorCode.UNKNOWN, \"defaultCore:\"\n\t\t\t\t\t+ defaultCoreName + \" could not be found\");\n\t\t//JohnWu add for multi-cores\n\t\tIterator it = defaultCores.iterator();\n\t\twhile(it.hasNext())\n{\n\t\t\thandler.inform((SolrCore)it.next());\n\t\t}\n\t\t//handler.inform(defaultCore);\n\t}\n\n\n\t/**\n\n\tThe main method that executes requests from a KattaClient\n\t */\n\t@Override\n\tpublic KattaResponse request(String[] shards, KattaRequest request)\n\t\t\tthrows Exception {\n\n\n\n\t\t//JohnWu add it for multi cores, we need get the suitable core according to the shard\n\t    SolrParams params = request.getParams();\n\t    SolrParams required = params.required();\n\t    String cname = required.get(CoreAdminParams.CORE);\n\t    SolrCore core = coreContainer.getCore(cname);\n\n\t    //need add some code to void the socre is null\n\t    if (core != null) {\n\t\t\tModifiableSolrParams sp = new ModifiableSolrParams(request.getParams());\n\t\t\tString shardsStr = StringUtils.arrayToString(shards);\n\t\t\tsp.set(ShardParams.SHARDS, shardsStr);\n\n\t\t\tif (log.isDebugEnabled())\n{\n\t\t\t\tlog.debug(\"SolrServer.request: \" + nodeName + \" shards:\"\n\t\t\t\t\t\t+ Arrays.asList(shards) + \" request params:\" + sp );\n\t\t\t}\n\n\t\t\t//remove by John\n\t\t\t//SolrQueryRequestBase req = new LocalSolrQueryRequest(defaultCore, sp);\n\n\n\t\t\t\tSolrQueryRequestBase req = new LocalSolrQueryRequest(core, sp);\n\t\t\t\tSolrQueryResponse resp = new SolrQueryResponse();\n\t\t\t\t// Added by tom liu\n\t\t\t\t// because exception would stop RPC\n\t\t\t\t// so, must handle exception\n\t\t\t\ttry\n{\n\t\t\t\t// add end\n\t\t\t\t\tgetRequestHandler(req).handleRequest(req, resp);\n\t\t\t\t// Added by tom liu\n\t\t\t\t}\ncatch(SolrException ex)\n{\n\t\t\t\t\tlog.error(ex.getMessage(), ex);\n\t\t\t\t}\n\t\t\t\t// add end\n\t\t\t\tNamedList nl = resp.getValues();\n\t\t\t\tnl.add(\"QueriedShards\", shards);\n\t\t\t\t// Added by tom liu\n\t\t\t\tSolrDocumentList sdl = (SolrDocumentList)nl.get(\"response\");\n\t\t\t\tif( sdl == null )\n{\n\t\t\t\t\tnl.add(\"response\", new SolrDocumentList());\n\t\t\t\t\tif( log.isWarnEnabled() )\n\t\t\t\t\t\tlog.warn(\"SolrServer.SolrResponse: no response\");\n\t\t\t\t}\n\t\t\t\t// add end\n\t\t\t\tSolrResponse rsp = new SolrResponseBase();\n\t\t\t\trsp.setResponse(nl);\n\t\t\t\tif (log.isDebugEnabled()){\n\t\t\t\t\tif( null != sdl )\n{\n\t\t\t\t\t\tlog.debug(\"SolrServer.SolrResponse: numFound=\" + sdl.getNumFound() \n\t\t\t\t\t\t\t\t+ \",start=\" + sdl.getStart() + \",docs=\" + sdl.size());\n\t\t\t\t\t}\n\t\t\t\t\tlog.debug(\"termVectors=\" + nl.get(\"termVectors\"));\n\t\t\t\t}\n// By using shards[0] we guarantee that this response is tied to a known\n// shard in the orignator, so that the results can be merged.\n// The name and only 1 is allowed has to be one of the original query\n// shards.\n\n\t\t\t\treturn new KattaResponse(shards[0], \"\", 0, rsp);\n\t    }else\n{\n\t    \t//maybe null is bad!\n\t    \tSystem.out.println(\"------the core is null!!!!!!\");\n\t    \treturn null;\n\t    }\n\t\t\t\t\t\n\n\n\n\t}\n\n\t// Added by tom liu\n\t// for supporting qt=...\n\tprivate MultiEmbeddedSearchHandler getRequestHandler(SolrQueryRequest request) {\n\t    SolrParams params = request.getParams();\n\t    if( params == null ) \n{\n\t      params = new ModifiableSolrParams();\n\t    }\n\n\t    String qt = params.get( CommonParams.QT );\n\t    if (qt != null) {\t\n\t    \t//JohnWu remove follow for multi-core\n//\t    \tMultiEmbeddedSearchHandler myhandler = (MultiEmbeddedSearchHandler)defaultCore.getRequestHandler( qt );\n//\t        if( myhandler == null ) \n{\n//\t          throw new SolrException( SolrException.ErrorCode.BAD_REQUEST, \"unknown handler: \"+qt);\n//\t        }\n//\t        myhandler.setCoreContainer(coreContainer);\n//\t        return myhandler;\n\n\n\t    \t//JohnWu add for multi-core\n\n\t\t\tIterator it = defaultCores.iterator();\n\t\t\twhile(it.hasNext()){\n\t\t    \tMultiEmbeddedSearchHandler myhandler = (MultiEmbeddedSearchHandler)((SolrCore)it.next()).getRequestHandler( qt );\n\t\t        if( myhandler == null ) \n{\n\t\t          throw new SolrException( SolrException.ErrorCode.BAD_REQUEST, \"unknown handler: \"+qt);\n\t\t        }\n\t\t        myhandler.setCoreContainer(coreContainer);\n\t\t        return myhandler;\n\t\t\t}\n\n\t    }\n\t\treturn handler;\n\t}\n\n------------------\n\nbut now when the katta send the second query with ids to data node, the connection is closed.\n\nINFO: pSearch-00000#pSearch-00000 webapp=null path=/select params=\n{start=0&ids=28aaa%2Caaa%2Cbbb&q=a*&core=part&isShard=true&rows=10}\n hits=3 status=0 QTime=12\n\nplease help me, and tell me why the process can not go through the whole process.\n\nThanks!\n\nJohnWu\n\n\n\n "
        },
        {
            "author": "JohnWu",
            "id": "comment-13139999",
            "date": "2011-10-31T08:29:18+0000",
            "content": "for the formats error, we re submit the code of DeployableSolrKattaServer\n\n\tpublic DeployableSolrKattaServer() throws ParserConfigurationException,\n\t\t\tIOException, SAXException \n{\n//\t\tsuper(getServerName(), new CoreContainer(getSolrHome()\n//\t\t\t\t.getAbsolutePath(), getConfigFile()));\n\t\t//super(getServerName(), new CoreContainer());\n\n\t\tsuper(getServerName(),new CoreContainer.Initializer().initialize());\n\t\t\n\n\t} "
        },
        {
            "author": "JohnWu",
            "id": "comment-13141576",
            "date": "2011-11-01T20:56:40+0000",
            "content": "Tom:\n   now I need confirm one thing about the global score in 1395 patch, we know the first query carry the response is <id,score>, so now if a big document set create 3 part index and distribute in 3 shards, the score is only a part score in shard?\n   we can not get the total score of 3 shard like the katta first time get the docf, second time get the total score?\nThanks!\nJohnWu "
        },
        {
            "author": "tom liu",
            "id": "comment-13157012",
            "date": "2011-11-25T07:48:33+0000",
            "content": "JohnWu:\n   you can add order of score. "
        },
        {
            "author": "tom liu",
            "id": "comment-13157019",
            "date": "2011-11-25T08:01:15+0000",
            "content": "Based on current trunk version, and impove some features:\n\n\tcreate one class that reopen IndexWriter for override solr indexes\n\tcreate one component class that only for udpate/reopenIndexWriter, so we do not use all other components of query\n\tmerger other result of shard\n\n\n\nsample config:\n\n\ttop-level solr\n\n  <searchComponent name=\"kattaUpdate\" class=\"solr.KattaUpdateTransferComponent\" />\n  <requestHandler name=\"update\" class=\"solr.KattaRequestHandler\" >\n    <lst name=\"defaults\">\n      <str name=\"shards\">*</str>\n      <str name=\"shards.qt\">update</str>\n    </lst>\n    <arr name=\"components\">\n      <str>kattaUpdate</str>\n    </arr>\n  </requestHandler>\n  <requestHandler name=\"kattaUpdate\" class=\"solr.KattaRequestHandler\" >\n    <lst name=\"defaults\">\n      <str name=\"shards\">*</str>\n      <str name=\"shards.qt\">kattaUpdate</str>\n    </lst>\n    <arr name=\"components\">\n      <str>kattaUpdate</str>\n    </arr>\n  </requestHandler>\n\n \n\tmiddle-level solrconfig\n\n  <searchComponent name=\"kattaUpdate\" class=\"solr.KattaUpdateTransferComponent\" />\n  <requestHandler name=\"update\" class=\"solr.MultiEmbeddedSearchHandler\">\n    <arr name=\"components\">\n      <str>kattaUpdate</str>\n    </arr>\n  </requestHandler>\n  <requestHandler name=\"kattaUpdate\" class=\"solr.MultiEmbeddedSearchHandler\">\n    <arr name=\"components\">\n      <str>kattaUpdate</str>\n    </arr>\n  </requestHandler>\n\n\n\tlower-level solrconfig\n\n  <requestHandler name=\"update\" class=\"solr.XmlUpdateRequestHandler\" >\n    <arr name=\"components\" />\n  </requestHandler>\n  <requestHandler name=\"kattaUpdate\" class=\"solr.KattaUpdateHandler\" >\n    <arr name=\"components\" />\n  </requestHandler>\n\n\n\n "
        },
        {
            "author": "tom liu",
            "id": "comment-13158461",
            "date": "2011-11-28T14:07:25+0000",
            "content": "I find one bug in shardSize of SolrKattaServer.java:\nwhen use coreContainer.getCore(name), the core's refcount has added by one. so that, core.close do not close the core. "
        },
        {
            "author": "tom liu",
            "id": "comment-13159061",
            "date": "2011-11-29T03:22:03+0000",
            "content": "fix the bug that SolrCore do not closed. "
        },
        {
            "author": "JohnWu",
            "id": "comment-13177588",
            "date": "2011-12-30T08:12:51+0000",
            "content": "tom:\n\n  can you merge the code of my comment - 31/Oct/11 08:2 in yours, and supply the multi-core function for the sub-proxy?\n  so if the proxy and sub-proxy contains many schemas and support muli-core query, and all the schema are independent, we can add different query and business logic, and the hot deployment will give the solr real features which is katta can not be achieved.\n  multi-core need change the code of your patch\n\tpublic SolrKattaServer(String defaultCoreName, CoreContainer coreContainer) {\n\t\tthis.coreContainer = coreContainer;\n\t\thandler = new MultiEmbeddedSearchHandler(coreContainer);\n\t\tdefaultCore = coreContainer.getCore(defaultCoreName);\n\n  that's only load one solr conf folder in, so it only load one solr core\nThanks!\n\nJohnWu "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13234693",
            "date": "2012-03-21T18:08:54+0000",
            "content": "Bulk of fixVersion=3.6 -> fixVersion=4.0 for issues that have no assignee and have not been updated recently.\n\nemail notification suppressed to prevent mass-spam\npsuedo-unique token identifying these issues: hoss20120321nofix36 "
        },
        {
            "author": "Otis Gospodnetic",
            "id": "comment-13482950",
            "date": "2012-10-24T04:30:21+0000",
            "content": "Does anyone really need this?  If so, I'm curious why?\nOr should we close this? "
        },
        {
            "author": "Otis Gospodnetic",
            "id": "comment-13697445",
            "date": "2013-07-02T02:58:51+0000",
            "content": "No response to my Q from N months ago. With Cloudera Search and Blur being available, plus SolrCloud, I think we can't close this as Won't Fix. "
        },
        {
            "author": "Steve Rowe",
            "id": "comment-13716883",
            "date": "2013-07-23T18:38:52+0000",
            "content": "Bulk close resolved 4.4 issues "
        }
    ]
}