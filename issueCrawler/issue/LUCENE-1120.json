{
    "id": "LUCENE-1120",
    "title": "Use bulk-byte-copy when merging term vectors",
    "details": {
        "labels": "",
        "priority": "Minor",
        "components": [
            "core/index"
        ],
        "type": "Improvement",
        "fix_versions": [
            "2.4"
        ],
        "affect_versions": "None",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "Indexing all of Wikipedia, with term vectors on, under the YourKit\nprofiler, shows that 26% of the time (!!) was spent merging the\nvectors.  This was without offsets & positions, which would make\nmatters even worse.\n\nDepressingly, merging, even with ConcurrentMergeScheduler, cannot in\nfact keep up with the flushing of new segments in this test, and this\nis on a strong IO system (Mac Pro with 4 drive RAID 0 array, 4 CPU\ncores).\n\nSo, just like Robert's idea to merge stored fields with bulk copying\nwhenever the field name->number mapping is \"congruent\" (LUCENE-1043),\nwe can do the same with term vectors.\n\nIt's a little trickier because the term vectors format doesn't quite\nmake it easy to bulk-copy because it doesn't directly encode the\noffset into the tvf file.\n\nI worked out a patch that changes the tvx format slightly, by storing\nthe absolute position in the tvf file for the start of each document\ninto the tvx file, just like it does for tvd now.  This adds an extra\n8 bytes (long) in the tvx file, per document.\n\nThen, I removed a vLong (the first \"position\" stored inside the tvd\nfile), which makes tvd contents fully position independent (so you can\njust copy the bytes).\n\nThis adds up to 7 bytes per document (less for larger indices) that\nhave term vectors enabled, but I think this small increase in index\nsize is acceptable for the gains in indexing performance?\n\nWith this change, the time spent merging term vectors dropped from 26%\nto 3%.  Of course, this only applies if your documents are \"regular\".\nI think in the future we could have Lucene try hard to assign the same\nfield number for a given field name, if it had been seen before in the\nindex...\n\nMerging terms now dominates the merge cost (~20% over overall time\nbuilding the Wikipedia index).\n\nI also beefed up TestBackwardsCompatibility unit test: test a non-CFS\nand a CFS of versions 1.9, 2.0, 2.1, 2.2 index formats, and added some\nterm vector fields to these indices.",
    "attachments": {
        "LUCENE-1120.take2.patch": "https://issues.apache.org/jira/secure/attachment/12373647/LUCENE-1120.take2.patch",
        "LUCENE-1120.patch": "https://issues.apache.org/jira/secure/attachment/12372624/LUCENE-1120.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2008-01-07T14:55:42+0000",
            "content": "Attached patch.  All tests pass.\n\n(Note that the TestBackwardsCompatibility test will fail if you apply the patch because the new *.zip files I added aren't in the patch).\n\nI think we should commit this for 2.3?  It's a sizable gain in merging\nperformance. ",
            "author": "Michael McCandless",
            "id": "comment-12556576"
        },
        {
            "date": "2008-01-07T15:21:40+0000",
            "content": "\nI think we should commit this for 2.3? It's a sizable gain in merging\n\nHI Mike,\n\nI'm planning to branch the trunk today. Considering the file format changes, it might be a bit risky to apply this patch last minute. I think we should commit this for 2.4. What do you think?\n\n-Michael ",
            "author": "Michael Busch",
            "id": "comment-12556586"
        },
        {
            "date": "2008-01-07T15:36:26+0000",
            "content": "\nConsidering the file format changes, it might be a bit risky to apply this patch last minute. I think we should commit this for 2.4. What do you think?\n\nOK, I agree, it is somewhat risky, so let's wait.  (Though it is a sizable gain in performance!). ",
            "author": "Michael McCandless",
            "id": "comment-12556589"
        },
        {
            "date": "2008-01-07T15:36:57+0000",
            "content": "\nIndexing all of Wikipedia, with term vectors on, under the YourKit\nprofiler, shows that 26% of the time (!!) was spent merging the\nvectors. \n\nI wonder how accurate these profiling numbers are? Java profiling slows\ndown (non-native) method calls, but not I/O operations. Did you measure\nthe merge time before and after applying this patch without a profiling\ntool?\n\n-Michael ",
            "author": "Michael Busch",
            "id": "comment-12556590"
        },
        {
            "date": "2008-01-07T15:39:47+0000",
            "content": "\nI wonder how accurate these profiling numbers are? Java profiling slows\ndown (non-native) method calls, but not I/O operations. Did you measure\nthe merge time before and after applying this patch without a profiling\ntool?\nGood point \u2013 I haven't measured outside of profiling.  I plan to build a full Wiki index with and without this change to test.... ",
            "author": "Michael McCandless",
            "id": "comment-12556593"
        },
        {
            "date": "2008-01-21T02:51:50+0000",
            "content": "Attached patch updated to current trunk.  All tests pass.  I plan to\ncommit after 2.3 is out...\n\nOK I ran a performance test with this patch, indexing the first 200K\ndocs of Wikipedia using this alg:\n\n  analyzer=org.apache.lucene.analysis.standard.StandardAnalyzer\n  doc.maker=org.apache.lucene.benchmark.byTask.feeds.LineDocMaker\n\n  doc.stored = true\n  doc.term.vector = true\n  doc.term.vector.positions = true\n  doc.term.vector.offsets = true\n\n  docs.file=/Volumes/External/lucene/wiki.txt\n\n  directory=FSDirectory\n\n  merge.scheduler=org.apache.lucene.index.SerialMergeScheduler\n\n  { \"Rounds\"\n    ResetSystemErase\n    { \"BuildIndex\"\n      CreateIndex\n      { \"AddDocs\" AddDoc > : 200000\n      CloseIndex\n    }\n    NewRound\n  } : 3\n\n  RepSumByPrefRound BuildIndex\n\nI used SerialMergeScheduler so that I could measure time saved due to\nfaster merging.\n\nWithout the patch, best of 3 was 509.0 sec; with patch, best of 3 was\n448.8 sec = 11.8% overall speedup. ",
            "author": "Michael McCandless",
            "id": "comment-12560916"
        },
        {
            "date": "2008-01-21T02:53:18+0000",
            "content": "Attaching the right patch this time... ",
            "author": "Michael McCandless",
            "id": "comment-12560917"
        },
        {
            "date": "2008-01-25T11:33:34+0000",
            "content": "I just committed this.  Note that this is a [small] change to the index format, so if you use trunk to build an index, 2.3 won't be able to read it! ",
            "author": "Michael McCandless",
            "id": "comment-12562448"
        }
    ]
}