{
    "id": "LUCENE-626",
    "title": "Extended spell checker with phrase support and adaptive user session analysis.",
    "details": {
        "labels": "",
        "priority": "Minor",
        "components": [
            "core/search"
        ],
        "type": "Improvement",
        "fix_versions": [],
        "affect_versions": "None",
        "resolution": "Unresolved",
        "status": "Open"
    },
    "description": "Extensive javadocs available in patch, but I also try to keep it compiled here: http://ginandtonique.org/~kalle/javadocs/didyoumean/org/apache/lucene/search/didyoumean/package-summary.html#package_description\n\nA semi-retarded reinforcement learning thingy backed by algorithmic second level suggestion schemes that learns from and adapts to user behavior as queries change, suggestions are accepted or declined, etc.\n\nExcept for detecting spelling errors it considers context, composition/decomposition and a few other things.\n\nheroes of light and magik -> heroes of might and magic\nvinci da code -> da vinci code\njava docs -> javadocs\nblacksabbath -> black sabbath\n\nDepends on LUCENE-550",
    "attachments": {
        "LUCENE-626_20071023.txt": "https://issues.apache.org/jira/secure/attachment/12368239/LUCENE-626_20071023.txt"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2007-02-03T02:19:04+0000",
            "content": "All of the old comments was obsolete, so I re-initialized the whole issue. ",
            "author": "Karl Wettin",
            "id": "comment-12469933"
        },
        {
            "date": "2007-02-03T02:21:55+0000",
            "content": "NgramPhraseSuggester is now decoupled from the adaptive layer, but I would like to refactor it even more so it is easy to replace the SpellChecker with any other single token suggester. ",
            "author": "Karl Wettin",
            "id": "comment-12469934"
        },
        {
            "date": "2007-02-17T07:54:53+0000",
            "content": "Patch in this issue have no dependencies to anything out of the ordinary.\n\nHowever, a large refactor and well documented version dependent to LUCENE-550 is available. ",
            "author": "Karl Wettin",
            "id": "comment-12473889"
        },
        {
            "date": "2007-03-03T19:59:38+0000",
            "content": "Patch depends on LUCENE-550. ",
            "author": "Karl Wettin",
            "id": "comment-12477674"
        },
        {
            "date": "2007-03-03T21:04:24+0000",
            "content": "This feature looks interesting, but why should it depend on LUCENE-550 ? ",
            "author": "Nicolas Lalev\u00e9e",
            "id": "comment-12477685"
        },
        {
            "date": "2007-03-03T21:13:14+0000",
            "content": "Nicolas Lalev\u00e9e [03/Mar/07 01:04 PM]\n> This feature looks interesting, but why should it depend on LUCENE-550 ? \n\nIt use the Index (notification, unison index factory methods, et c.) and IndexFacade (cache, fresh reader/searcher et c.) available in that patch. And by doing that, it also enables me to use InstantiatedIndex for the a priori corpus and ngram index to speed up the response time even more. ",
            "author": "Karl Wettin",
            "id": "comment-12477688"
        },
        {
            "date": "2007-08-17T00:10:40+0000",
            "content": "As the phrase-suggestion layer on top of contrib/spell in this patch was noted in a bunch of forums the last weeks, I've removed the 550-dependency and brought it up to date with the trunk. \n\nSecond level suggesting (ngram token, phrase) can run stand alone. See TestTokenPhraseSuggester. However, I recommend the adaptive dictonary as it will act as a cache on top of second level suggestions. (See docs.)\n\nOutput from using adaptive layer only, i.e. suggestions based on how users previously behaved. About half a million user queries analyed to build the dictionary (takes 30 seconds to build on my dual core):\n\n3ms\t pirates ofthe caribbean -> pirates of the caribbean\n2ms\t pirates of the carribbean -> pirates of the caribbean\n0ms\t pirates carricean -> pirates caribbean\n1ms\t pirates of the carriben -> pirates of the caribbean\n0ms\t pirates of the carabien -> pirates of the caribbean\n0ms\t pirates of the carabbean -> pirates of the caribbean\n1ms\t pirates og carribean -> pirates of the caribbean\n0ms\t pirates of the caribbean music -> pirates of the caribbean soundtrack\n0ms\t pirates of the caribbean soundtrack -> pirates of the caribbean score\n0ms\t pirate of carabian -> pirate of caribbean\n0ms\t pirate of caribbean -> pirates of caribbean\n0ms\t pirates of caribbean -> pirates of caribbean\n0ms\t homm 4 -> homm iv\n0ms\t the pilates -> null\n\n\nUsing the phrase ngram token suggestion using token matrices checked against an apriori index. A lot of queries required for one suggestion. Instantiated index as apriori saves plenty of millis. This is  expensive stuff, but works pretty good. \n\n72ms\t the pilates -> the pirates\n440ms\t heroes of fight and magic -> heroes of might and magic\n417ms\t heroes of right and magic -> heroes of might and magic\n383ms\t heroes of magic and light -> heroes of might and magic\n20ms\t heroesof lightand magik -> null\n385ms\t heroes of light and magik -> heroes of might and magic\n0ms\t heroesof lightand magik -> heroes of might and magic\n385ms\t heroes of magic and might -> heroes of might and magic \n\n(That 0ms is becase previous was cached. One does not have to use this cache.) ",
            "author": "Karl Wettin",
            "id": "comment-12520421"
        },
        {
            "date": "2007-08-17T02:06:26+0000",
            "content": "RAMDirectory vs. InstantiatedIndex as apriori index: the latter is 5 to 25 times faster (leave first out).\n\nRAMDirectory:\n72ms the pilates -> the pirates\n440ms heroes of fight and magic -> heroes of might and magic\n417ms heroes of right and magic -> heroes of might and magic\n383ms heroes of magic and light -> heroes of might and magic\n20ms heroesof lightand magik -> null\n385ms heroes of light and magik -> heroes of might and magic\n0ms heroesof lightand magik -> heroes of might and magic\n385ms heroes of magic and might -> heroes of might and magic \n\n\nInstantiatedIndex:\n171ms\t the pilates -> the pirates\n66ms\t heroes of fight and magic -> heroes of might and magic\n36ms\t heroes of right and magic -> heroes of might and magic\n14ms\t heroes of magic and light -> heroes of might and magic\n6ms\t heroesof lightand magik -> null\n15ms\t heroes of light and magik -> heroes of might and magic\n0ms\t heroesof lightand magik -> heroes of might and magic\n16ms\t heroes of magic and might -> heroes of might and magic ",
            "author": "Karl Wettin",
            "id": "comment-12520435"
        },
        {
            "date": "2007-10-16T18:45:13+0000",
            "content": "New in this patch:\n\n\n\tDictionary persistence using BDB/je/3.2.44\n\tLots of refactoring to make the code easier to follow\n\n\n\nNext patch will probably focus on:\n\n\n\tPruning of dictionary\n\tDocumentation of non-consumer methods\n\n ",
            "author": "Karl Wettin",
            "id": "comment-12535314"
        },
        {
            "date": "2007-10-23T20:18:32+0000",
            "content": "In this patch:\n\n\n\tUpdated package javadoc\n\n\n\n\n\tSimplified consumer interface with persistent session management :\n\n\n\n\nSuggestionFacade facade = new SuggestionFacade(new File(\"data\"));\nfacade.getDictionary().getPrioritesBySecondLevelSuggester().putAll(facade.secondLevelSuggestionFactory());\n...\nQuerySession session = facade.getQuerySessionManager().sessionFactory();\n...\nString query = \"heros of mght and magik\";\nHits hits = searcher.search(queryFactory(query));\nString suggested = facade.didYouMean(query);\nsession.query(query, hits.length(), suggested);\n...\nfacade.getQuerySessionManager().getSessionsByID().put(session);\n...\nfacade.trainExpiredSessions();\n...\nfacade.close();\n\n\n\n\n\tOptimizations. On my MacBook it now takes five minutes for the big unit test to process 3,500,000 queries: training the dictionary and extracts an a priori corpus by inverting the dictionary of the phrases and words people have most problem spelling.\n\n\n\n\n\tDepends on LUCENE-550 by default again. When it took 30 seconds to execute 100,000 span near queries in a RAMDirectory and less than one second to do the same witn an InstantiatedIndex it simply did not make sense to use RAMDirectory as default. Replacing one line of code removes the dependency to InstantiatedIndex.\n\n\n\n\n\tNew algorithmic second level suggester for queries containing terms not close enough in the text to be found in the a priori. Added with lowest priority and checks against the system index rather than the a priori index. Soon the second level suggster classes will needs a bit of refactoring.\n\n\n\n ",
            "author": "Karl Wettin",
            "id": "comment-12537124"
        },
        {
            "date": "2008-04-17T20:02:52+0000",
            "content": "If anyone have some rather large query logs with session id, time stamp and preferably click through data that I can test on this, that would be great. It really needs to be adjusted to more than one. ",
            "author": "Karl Wettin",
            "id": "comment-12590189"
        },
        {
            "date": "2010-01-22T11:14:01+0000",
            "content": "FYI: I started working on updating on Karl's patch. The code is not yet in a compilable state, but can be found on GitHub: http://github.com/mkamstrup/lucene-didyoumean\n\nMy plans for this is to:\n\n\n\tPort it to Lucene 3+ API\n\tAbstract out the BDB dependency to allow for any old storage payer (BDB, JDBC, what have we)\n\n\n\nThanks for the great work Karl! ",
            "author": "Mikkel Kamstrup Erlandsen",
            "id": "comment-12803666"
        },
        {
            "date": "2010-01-25T14:45:37+0000",
            "content": "@Karl: The test sources refer a file http://ginandtonique.org/~kalle/LUCENE-626/queries_grouped.txt.gz which is not online anymore, is this resource still available somewhere? ",
            "author": "Mikkel Kamstrup Erlandsen",
            "id": "comment-12804554"
        },
        {
            "date": "2010-01-25T14:53:26+0000",
            "content": "Status update: All tests except two are passing since commit 7e4eb7989d81e50cc81b6f33ac5fa188467f5d3e on http://github.com/mkamstrup/lucene-didyoumean :\n\n 1) TestTokenPhraseSuggester gives me a ArrayIndexOutOfBoundsException roughly half way through the test cases (which otherwise pass)\n 2) Missing the sample query log to import from the resource http://ginandtonique.org/~kalle/LUCENE-626/queries_grouped.txt.gz\n\n ! But be aware that this is still work in progress ! ",
            "author": "Mikkel Kamstrup Erlandsen",
            "id": "comment-12804556"
        },
        {
            "date": "2010-01-26T12:51:13+0000",
            "content": "Status update: All tests pass now, since the tag 'milestone3'\n\nMissing essentials:\n\n\tAn on-disk backend for Dictionary and QuerySessionManager, either via JDBC or some Lucene magic\n\tMore large scale testing on said on-disk backends\n\n\n\nMissing nice-to-haves:\n\n\tCode cleanup\n\tMore javadocs\n\tOptimizations (there's a lot of low hanging fruit - we sprinkle objects and string copies all over the place!)\n\n ",
            "author": "Mikkel Kamstrup Erlandsen",
            "id": "comment-12805011"
        },
        {
            "date": "2010-01-26T13:12:20+0000",
            "content": "Hej Mikkel,\n\nthe test case data set is on an HDD hidden away on an attic 600km away from me, but I've asked for someone in the vicinity to fetch it for me. Might take a little while. Sorry!\n\nHowever extremely cool that you're working with this old beast! I'm super busy as always but I promise to follow your progress in case there is something you wonder about. It's been a few years since I looked at the code though. ",
            "author": "Karl Wettin",
            "id": "comment-12805021"
        },
        {
            "date": "2010-01-26T19:56:39+0000",
            "content": "Hej Karl,\n\nSuper that you are still around!  Even more sweet that you are willing to try on turn up these files!\n\nDevelopment is going pretty well, and I am finally feeling that I can wrap my head around it, but it is most valuable to have you in the back hand!\n ",
            "author": "Mikkel Kamstrup Erlandsen",
            "id": "comment-12805161"
        },
        {
            "date": "2010-06-11T10:48:29+0000",
            "content": "I have forked Mikkels project, this is now availeble at (also at GitHup): http://github.com/hkirk/lucene-didyoumean\n\nThe plan for this is more or less the same as Mikkel:\n\n\n\tKeep updated with Lucene trunk (3.0.1+)\n\tAn on-disk backend for Dictionary and QuerySessionManager + large scale testing\n\n\n\nRunning projects:\n\n\tCode cleanup\n\tJavaDoc\n\tOptimizations\n\n ",
            "author": "Henrik Bitsch Kirk",
            "id": "comment-12877775"
        }
    ]
}