{
    "id": "LUCENE-7429",
    "title": "DelegatingAnalyzerWrapper should delegate normalization too",
    "details": {
        "resolution": "Fixed",
        "affect_versions": "6.2",
        "components": [],
        "labels": "",
        "fix_versions": [
            "6.3",
            "7.0"
        ],
        "priority": "Minor",
        "status": "Closed",
        "type": "Bug"
    },
    "description": "This is something that I overlooked in LUCENE-7355: (Delegating)AnalyzerWrapper uses the default implementation of initReaderForNormalization and normalize, meaning that by default the normalization is a no-op. It should delegate to the wrapped analyzer.",
    "attachments": {
        "LUCENE-7355.patch": "https://issues.apache.org/jira/secure/attachment/12825650/LUCENE-7355.patch",
        "LUCENE-7429.patch": "https://issues.apache.org/jira/secure/attachment/12825975/LUCENE-7429.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "id": "comment-15438814",
            "author": "Adrien Grand",
            "date": "2016-08-26T11:24:57+0000",
            "content": "Here is a patch. "
        },
        {
            "id": "comment-15445244",
            "author": "Adrien Grand",
            "date": "2016-08-29T08:32:18+0000",
            "content": "New patch that also makes sure to use the same attribute factory as the wrapped analyzer and adds more tests. I think it's ready. "
        },
        {
            "id": "comment-15451486",
            "author": "Adrien Grand",
            "date": "2016-08-31T07:48:49+0000",
            "content": "Uwe Schindler Would you mind having a look? "
        },
        {
            "id": "comment-15451648",
            "author": "Uwe Schindler",
            "date": "2016-08-31T09:01:29+0000",
            "content": "I am trying to understand what's going on. The attributeFactory / fieldname looks strange to me.... "
        },
        {
            "id": "comment-15451727",
            "author": "Adrien Grand",
            "date": "2016-08-31T09:28:29+0000",
            "content": "This part was necessary because AnalyzerWrapper has Analyzer getWrappedAnalyzer(String fieldName). So in order to know which attribute factory to use, I had to add a fieldName parameter, so that AnalyzerWrapper.attributeFactory can be implemented as:\n\n\n  @Override\n  protected final AttributeFactory attributeFactory(String fieldName) {\n    return getWrappedAnalyzer(fieldName).attributeFactory(fieldName);\n  }\n\n\n\nOtherwise we could not figure out which analyzer to delegate to? "
        },
        {
            "id": "comment-15451738",
            "author": "Uwe Schindler",
            "date": "2016-08-31T09:35:22+0000",
            "content": "I know why you did this, but it just looks wrong! IMHO, the whole attributefactory as part of the ctor of Tokenizers is not really a good idea, but some people like to have this! The AttributeFactory should be passed by the ctor of the subclass of a Tokenizer to super, if a Tokenizer needs a special one. But passing that around everywhere is not really useful. "
        },
        {
            "id": "comment-15451853",
            "author": "Adrien Grand",
            "date": "2016-08-31T10:29:24+0000",
            "content": "Agreed on that point. Since all we need for normalization is to use the same attribute factory as the regular analysis chain, would it work better for you if we tried to borrow the attribute source from a token stream created by Analyzer.tokenStream like in the attached patch (the relevant bits are the removal of Analyzer.attributeFactory() and how Analyzer.normalize assigns the attributeFactory variable? "
        },
        {
            "id": "comment-15452873",
            "author": "Uwe Schindler",
            "date": "2016-08-31T17:49:27+0000",
            "content": "Hi,\nI'd suggest to use the previous patch. I don't like it to create (and consume) a TokenStream just to get its attribute source. This may be heavy, although it is unlikely for stuff that gets normalized.\nThe issue here is mostly that we need to create a new TokenStream (StringTokenStream) for the normalization and we need to use the same attribute types. Although this is sometimes broken for use-cases, where TokenStreams create binary tokens. But those would never be normalized, I think (!?)\nUwe "
        },
        {
            "id": "comment-15455008",
            "author": "Adrien Grand",
            "date": "2016-09-01T10:19:01+0000",
            "content": "The issue here is mostly that we need to create a new TokenStream (StringTokenStream) for the normalization and we need to use the same attribute types.\n\nExactly. For instance if a term attribute produces utf-16 encoded tokens, \n\nAlthough this is sometimes broken for use-cases, where TokenStreams create binary tokens. But those would never be normalized, I think (!?)\n\nDo you mean that you cannot think of any use-case for using both a non-default term attribute and token filters in the same analysis chain? I am wondering about CJK analyzers since I think UTF16 stores CJK characters a bit more efficiently on average than UTF8 (I may be completely wrong, in which case please let me know) so users might be tempted to use a different term attribute impl? "
        },
        {
            "id": "comment-15607938",
            "author": "Adrien Grand",
            "date": "2016-10-26T09:12:04+0000",
            "content": "I would like to move forward on this issue with the patch that I proposed on August 29th if there are no objections. "
        },
        {
            "id": "comment-15612063",
            "author": "ASF subversion and git services",
            "date": "2016-10-27T14:34:45+0000",
            "content": "Commit ed102d634a7aa48c1b995ba81548cc7454a467a9 in lucene-solr's branch refs/heads/branch_6x from Adrien Grand\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=ed102d6 ]\n\nLUCENE-7429: AnalyzerWrapper can now wrap the normalization analysis chain too. "
        },
        {
            "id": "comment-15612064",
            "author": "ASF subversion and git services",
            "date": "2016-10-27T14:34:48+0000",
            "content": "Commit af60048097a83220aae135b09d209a0f2d4ba3c6 in lucene-solr's branch refs/heads/master from Adrien Grand\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=af60048 ]\n\nLUCENE-7429: AnalyzerWrapper can now wrap the normalization analysis chain too. "
        },
        {
            "id": "comment-15650258",
            "author": "Shalin Shekhar Mangar",
            "date": "2016-11-09T08:38:02+0000",
            "content": "Closing after 6.3.0 release. "
        }
    ]
}