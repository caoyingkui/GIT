{
    "id": "SOLR-269",
    "title": "UpdateRequestProcessorFactory - process requests before submitting them",
    "details": {
        "affect_versions": "None",
        "status": "Closed",
        "fix_versions": [
            "1.3"
        ],
        "components": [],
        "type": "New Feature",
        "priority": "Major",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "A simple UpdateRequestProcessor was added to a bloated SOLR-133 commit. \n\nAn UpdateRequestProcessor lets clients plug in logic after a document has been parsed and before it has been 'updated' with the index.  This is a good place to add custom logic for:\n\n\ttransforming the document fields\n\tfine grained authorization (can user X updated document Y?)\n\tallow update, but not delete (by query?)\n\n\n\n\n   <requestHandler name=\"/update\" class=\"solr.StaxUpdateRequestHandler\" >\n     <str name=\"update.processor.class\">org.apache.solr.handler.UpdateRequestProcessor</str>\n     <lst name=\"update.processor.args\">\n      ... (optionally pass in arguments to the factory init method) ...\n     </lst> \n   </requestHandler>\n\n\nhttp://www.nabble.com/Re%3A-svn-commit%3A-r547495---in--lucene-solr-trunk%3A-example-solr-conf-solrconfig.xml-src-java-org-apache-solr-handler-StaxUpdateRequestHandler.java-src-java-org-apache-solr-handler-UpdateRequestProcessor.jav-tf3950072.html#a11206583",
    "attachments": {
        "SOLR-269-simple.patch": "https://issues.apache.org/jira/secure/attachment/12386858/SOLR-269-simple.patch",
        "SOLR-269-UpdateRequestProcessorFactory.patch": "https://issues.apache.org/jira/secure/attachment/12360309/SOLR-269-UpdateRequestProcessorFactory.patch",
        "UpdateProcessor.patch": "https://issues.apache.org/jira/secure/attachment/12361231/UpdateProcessor.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Yonik Seeley",
            "id": "comment-12509725",
            "date": "2007-07-03T01:27:39+0000",
            "content": "Looking at UpdateRequestProcessor further, it seems like these should be singletons (instance per entry in solrconfig, no factory needed), and any extra state that is needed\nshould be added to classes we already have (like AddCommand, etc), no? "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12509732",
            "date": "2007-07-03T02:06:03+0000",
            "content": "I think the newly added incremental time should not be on by default, as well as logging per id for deletes and adds.\nMike added the id aggregation code specifically because logging each add was taking so much time. "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-12509733",
            "date": "2007-07-03T02:15:27+0000",
            "content": "maybe.  I'm not sure I totally understand your suggestion though.  \n\nI need something that is easily subclassed and can cleanly holds state across an entire request cycle.  The alternative is to pass the SolrQueryRequest/Response into each action and maybe pull out the schema/updateHandler/logged in user/etc for each command (each document in the list of 100)\n\nIs the factory a performance concern?  (to my tastes) it seems nicer to work with:\n\n processDelete( DeleteUpdateCommand cmd )\n {\n   if( user.isAdmin() ) \n{\n     updateHandler.delete( cmd );\n   }\n  \n   else \n{\n   \t...\n   }\n }\n\n than:\n\n processDelete( DeleteUpdateCommand cmd, SolrQueryRequest req, SolrQueryResponse rsp )\n {\n   User user = req.getContext().get( \"user\" );\n   if( user.isAdmin() ) \n{\n    SolrCore core = req.getCore();\n    SolrSchema schema = core.getSchema();\n    UpdateHandler updateHandler = core.getUpdateHandler();\n    updateHandler.delete( cmd );\n   }\n  \n   else \n{\n     ...\n   }\n }\n\nI'm fine either way, like the easy 1 per-request interface.   "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-12509734",
            "date": "2007-07-03T02:16:50+0000",
            "content": "> I think the newly added incremental time should not be on by default, as well as logging per id for deletes and adds.\n> Mike added the id aggregation code specifically because logging each add was taking so much time.\n\nsounds good.  the testing I did showed that lots of time is spent in the logging phase.\n\nI will remove it from the default implementation. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12509737",
            "date": "2007-07-03T02:41:22+0000",
            "content": "> I need something that is easily subclassed and can cleanly holds state across an entire request cycle.\n\nHaving a factory and separate object so that one can use core instead of req.getCore(), etc, seems like overkill for the normal case though since\ngetCore(), getSchema(), getUpdateHandler() all just return instance variables.  I was thinking any state like that could be on the UpdateCommand.\n\nI'd like to have potentially several request processors, but if people start doing single doc add requests, instantiating and initializing all those request processors will get expensive.\n\nI do see your usecase though, in the case of multiple docs per add and you have some expensive state you only want to calculate once.\nIf it's a relatively rare case, one could put it in the request context.\nThe tradeoff would be an extra hash lookup per-document of a multi-document add vs an extra object creation for single-doc adds.\n\nDifferent Q on usage: is this where my document mutator stuff should go???  If I want a transformation done on a field, regardless of where the data is coming from (XML update handler, CSV update handler, future REST update handler, etc), how should that be done?  Is there a single place I can register a plugin to do this, and is UpdateRequestProcessor where you see it happening? "
        },
        {
            "author": "Hoss Man",
            "id": "comment-12510004",
            "date": "2007-07-03T21:32:10+0000",
            "content": "> Different Q on usage: is this where my document mutator stuff should go??? If I want a transformation done on a field, regardless of \n> where the data is coming from (XML update handler, CSV update handler, future REST update handler, etc), how should that be done? \n> Is there a single place I can register a plugin to do this, and is UpdateRequestProcessor where you see it happening?\n\ni believe that was acutally the initial intent of UpdateRequestProcesso, note the javadocs...\n\n\n\tThis is a good place for subclassed update handlers to process the document before it is\n\tindexed.  You may wish to add/remove fields or check if the requested user is allowed to\n\tupdate the given document...\n\t\n\tPerhaps you continue adding an error message (without indexing the document)...\n\tperhaps you throw an error and halt indexing (remove anything already indexed??)\n\n "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-12510009",
            "date": "2007-07-03T21:49:33+0000",
            "content": "\n> getCore(), getSchema(), getUpdateHandler() all just return instance variables.  \n> \n\nok, getCore() isn't a good canidate; It is annoying to start every function with a train wreck: req.getCore().getUpdateHandler()\n\nHaving a single class per request makes sense for a subclass I am working with \u2013 it does some expensive initialization and stores the results.  I could put this in req.getContext()\n\n\n> instantiating and initializing all those request processors will get expensive.\n\nReally?  the default initialize is trivial - stuff that would happen at the beginning of every function anyway.  I suppose GC could be an issue\n\n\n> I do see your usecase though, in the case of multiple docs per add and you have some expensive state you only want to calculate once.\n\nIn r552986, I changed the logging to match solr 1.2 \u2013 this required accumulating the id's and spitting them out at the end.  In 1.2 with processing and parsing entwined, this was just a giant loop.  To get the same behavior we need to stash it somewhere...\n\n\n> Different Q on usage: is this where my document mutator stuff should go??? \n\nYes.  The intent is to have a simple place between document parsing and indexing where you can do whatever you need to do.  Any parsing strategy (XML,JSON,etc) could share the same processor.\n\nLooking at SOLR-139, I now think the most flexible/useful way to support modifiable documents is to build utility functions for the UpdateProcessor that can manipulate SolrInputDocuments. \n\n\n\t- -\n\n\n\nI will take another crack at SOLR-139 implemented in the UpdateProcessor, then we should return to the question of singleton vs factory - trying to work with a more complex processor may make this choice more obvious. "
        },
        {
            "author": "Hoss Man",
            "id": "comment-12510012",
            "date": "2007-07-03T22:00:18+0000",
            "content": "> we should return to the question of singleton vs factory - trying to work with a more complex processor may make this choice more obvious.\n\ni'm not really sure if i understand the issue ... but if it's a question of performance in the default case then i don't really see an issue \u2013 a Factory API can return a Singleton provided the impl is threadsafe (iving us all the performance goodness of a Singleton) but switching to a Singleton API really limits what people can do when they want to have a complex UpdateRequestProcessor and know it might take a while.\n\nYonik, would your concerns be relieved if the default UpdateRequestProcessorFactory class was changed to look like this...\n\npublic class UpdateRequestProcessorFactory {\n  private final UpdateRequestProcessor SINGLETON;\n  public UpdateRequestProcessorFactory()  \n{ /*NOOP*/}\n  public void init( NamedList<Object> args ) \n{ \n     SINGLETON = new UpdateRequestProcessor( req );\n  }\n  public UpdateRequestProcessor getInstance( SolrQueryRequest req ) \n{\n    return SINGLETON  \n  }\n}\n\n? "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12510425",
            "date": "2007-07-05T17:54:45+0000",
            "content": "FYI, I'm working up a prototype right now to handle multiple request processors. "
        },
        {
            "author": "Hoss Man",
            "id": "comment-12510429",
            "date": "2007-07-05T17:59:11+0000",
            "content": "couldn't that just be a DelegateUpdateRequestProcessor that is constructed using a list of other UpdateRequestProcessors?\n\n     "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12510478",
            "date": "2007-07-05T20:53:06+0000",
            "content": "OK, this patch adds the ability to specify multiple processor factories.\n\nSummary:\n\n\tdecoupled changing the index from logging... I think it makes it much clearer how things work (there was much more logging code than anything else). This also would allow Ryan to add back his incremental timing to a different processor.\n\tadded SolrInputDocument to AddUpdateCommand, and added some methods\n\tremoved NamedList return from the XML update handler and started passing SolrQueryResponse around instead (this is more future-proof and flexible)\n\tremoved adding all the ids to the response... (back to 1.2 response format). We probably shouldn't add ids by default... think of CSV uploading millions of records, etc.\n\tAn array of factories is kept, and when a processor is instantiated, it is passed a \"next\" pointer. An alternative would be to expose a \"next factory\" pointer to every factory (any advantage to having the current factory call getInstance() on the next factory instead of us doing that?)\n\tuntested support for basic syntax to support multiple update processors:\n    <lst name=\"update.processor>\n      <str name=\"factory\">org.apache.solr....</str>\n      <lst name=\"args\">...</lst>\n\n "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12510479",
            "date": "2007-07-05T20:59:17+0000",
            "content": "> couldn't that just be a DelegateUpdateRequestProcessor that is constructed using a list of other UpdateRequestProcessors\n\nThat might be the way to go if multiple processors were to be very rare... but then you need to come\nup with a syntax for the args of DelegateUpdateRequestProcessor  to specify multiple delegates, and one ends up writing the same code with more complex configuration.\n "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-12510484",
            "date": "2007-07-05T21:23:47+0000",
            "content": "I like the AddUpdateCommand changes\n\nWhat do you see as the common use case for wanting to chain request processors?  Is the LogUpdateRequestProcessor just an example?  \n\nThe one compelling chained use case I can think of is for document transformation.  In SOLR-139, I toyed with SolrInputDocumentTransformer.  The default case does nothing, and a subclass may use something like:\n  for( SolrInputDocumentTransformer t : transformers ) \n{\n    doc = t.transform( doc );\n  } "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12510487",
            "date": "2007-07-05T21:38:02+0000",
            "content": "> What do you see as the common use case for wanting to chain request processors?\n\n\tconditional copyField, field transformations (between multiple fields too... something Analyzer can't do), loading certain fields from a database if missing,\n   updating a related document, etc.\n\n\n\n> Is the LogUpdateRequestProcessor just an example?\n\nIMO, it's a default since no logging is done by the ChangeUpdateRequestProcessor (anyone think of a better name for that?).\nThen in a Benchmarking section of the Solr Wiki, we could advise to remove logging altogether.  Or you could remove the ChangeUpdateRequestProcessor  to skip index\nchanges to better benchmark hotspots in the parsing + doc creation phase, etc.\n\n> The one compelling chained use case I can think of is for document transformation\n\nAh, I briefly looked at SOLR-139 when you mentioned it before, but missed the transformer stuff.\nIn a way multiple update processors are more generic and wide open... you could actually insert two documents into the index for each doc added,\nyou could do transforms on the actual Lucene document (add Field options that Solr doesn't currently support, etc. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12510504",
            "date": "2007-07-05T22:16:37+0000",
            "content": "Some other issues.... how to configure processors for multiple update handlers? Perhaps allow configuration of a global default for update handlers with no processors specified?  That would make it easy to make sure your custom processor was used everywhere.\nWe should probably have a base class for update handlers to implement initialization logic. "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-12510506",
            "date": "2007-07-05T22:21:52+0000",
            "content": ">  - conditional copyField, field transformations (between multiple fields too... something Analyzer can't do), loading certain fields from a database if missing,\n>    updating a related document, etc.\n> \n\nThis all works nicely with a simple 'transform' chain.\n\n\n>> Is the LogUpdateRequestProcessor just an example?\n> \n> IMO, it's a default since no logging is done by the ChangeUpdateRequestProcessor (anyone think of a better name for that?).\n> Then in a Benchmarking section of the Solr Wiki, we could advise to remove logging altogether.  Or you could remove the ChangeUpdateRequestProcessor  to skip index\n> changes to better benchmark hotspots in the parsing + doc creation phase, etc.\n> \n\nIsn't logging best configured with standard java.util.logging settings? If necessary, the base processor could check if the logging level is high enough to keep track of somethings.\n\nFor benchmarking, don't we just want a single noop processor?\n\n\n>> The one compelling chained use case I can think of is for document transformation\n> \n> Ah, I briefly looked at SOLR-139 when you mentioned it before, but missed the transformer stuff.\n> In a way multiple update processors are more generic and wide open... you could actually insert two documents into the index for each doc added,\n> you could do transforms on the actual Lucene document (add Field options that Solr doesn't currently support, etc.\n> \n\nI see what you are getting at, but makes the basic cases more complicated then it needs to be.  I have been considering UpdateRequestProcessor as an 'advanced' option where changing their behavior is writing custom code \u2013 not text configuration.\n\nIn the advanced case where you want to build multiple documents or munge the actual Lucene document existing it may be more difficult to live in a chain rather then have explicit control.  If \n\nI think the cleanest design would be a single entry point and keeping the real functionality in easily subclassed functions or utility classes.  The latest SOLR-139 tries that (but it could still use some cleanup) "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-12510510",
            "date": "2007-07-05T22:32:05+0000",
            "content": "\n> Some other issues.... how to configure processors for multiple update handlers? Perhaps allow configuration of a global default for update handlers with no processors specified?  That would make it easy to make sure your custom processor was used everywhere.\n\nSolrCore could have a single UpdateRequestProcessorFactory that handlers could use as the default.  I'm reluctant to add another plugin layer, but this would make it easier to share with the CSV update handler and others.\n\nSince its a factory, it will be thread safe across multiple handlers.\n\nAgain, I'm reluctant to think about configuring a processor chain in solrconfig.xml \u2013 we should make the most sensible/extendible default implementation, but IMO tweeking RequestProcessor functionality should be done with custom code. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12510518",
            "date": "2007-07-05T22:59:51+0000",
            "content": "> This all works nicely with a simple 'transform' chain. \n\nI don't see any code allowing initialization of the transform chain, or anything like that.\nWhat are you proposing?\n\nI think it gets tougher when one talks about updates rather than document adds too.\n\n> Isn't logging best configured with standard java.util.logging settings?\n\nNot if you want a different type... for example, you seemed to want timing per-document added for example.\nHaving log specific configuration (such as number of ids to log in a big add) in it's own processor seems slightly nicer too.\nIs there a downside to the logging being separated out in this case?  I really don't have strong feelings about it though (as long as we can keep the default version lean enough).\n\n> I see what you are getting at, but makes the basic cases more complicated then it needs to be.\n\nYes, with the upside that we know our transform interface isn't too limiting.\n\n> I'm reluctant to add another plugin layer\n\nMe too... which is why just doing transform with the processors seems desirable (one less type of plugin).\nIf transformations are not to be done with UpdateRequestProcessor, I'm not sure we should expose that interface at all as it's tightly coupled with DUH2.\nIt seems we really only need one type of plugin to do these document transformations.\n\n> SolrCore could have a single UpdateRequestProcessorFactory that handlers could use as the default.\n\nYes, with update processors, the needed interface to add a document changes... you need the processor rather than the update handler.\n "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12510538",
            "date": "2007-07-06T00:30:30+0000",
            "content": "> with update processors, the needed interface to add a document changes... you need the processor rather than the update handler.\n\nThinking on these lines a bit further... perhaps the extra functionality of transformations and updating should be pushed into the UpdateHandler interface\n(DUH2).  If it makes sense, we could deprecate the existing AddUpdateCommand  & methods in favor of new ones that use SolrInputDocument.\n\n "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-12510563",
            "date": "2007-07-06T03:58:03+0000",
            "content": "> perhaps the extra functionality of transformations and updating should be pushed into the UpdateHandler interface\n\nThat was the first SOLR-139 design!\n\nHaving thought about it for a while, i think there are nice advantages to keeping the updating/modifying outside of the UpdateHandler - the biggest one is that various RequestHandlers could transform the document differently.\n\nI'm putting together a hybrid example that (I hope) answers questions about chains/configuration/transformation, etc.  I'll post it shortly. "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-12510570",
            "date": "2007-07-06T04:27:52+0000",
            "content": "\n\tloads UpdateRequestProcessorFactories using the plugin loader stuff from SOLR-260.\n\tmakes a UpdateRequestHandlerBase class that XML and CSV share.\n\tloads and configures a chain of InputTransformations.\n\tmoves UpdateRequestProcessor from o.a.s.handler to o.a.s.update\n\n\n\nThis is the test config:\n\n<updateRequestProcessor>\n   <factory name=\"standard\" class=\"solr.UpdateRequestProcessorFactory\" />\n   <factory name=\"custom\" class=\"solr.CustomUpdateRequestProcessorFactory\" default=\"true\">\n     <args>\n\t    <lst name=\"name\">\n\t      <str name=\"n1\">v1</str>\n\t      <str name=\"n2\">v2</str>\n\t    </lst>\n     </args>\n     <transformer class=\"solr.CustomTransformerNoOp\" />\n     <transformer class=\"solr.CustomTransformerNoOp\" />\n     <transformer class=\"solr.CustomTransformerAdd\">\n       <str name=\"f0\">000</str>\n       <str name=\"f1\">111</str>\n     </transformer>\n     <transformer class=\"solr.CustomTransformerNoOp\" />\n   </factory>\n </updateRequestProcessor>\n\nI am not sure we want to make the transformer interface public yet, but it is here to show how I think it could be handled.\n\nIf you like this approach, I'll clean it up some more... "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-12510574",
            "date": "2007-07-06T04:50:01+0000",
            "content": "\n> I don't see any code allowing initialization of the transform chain, or anything like that.\n> What are you proposing?\n\nCheck the latest patch.  I'm not sure we need to have XML configuration for this, but I added it as an example.  The factory would hold a list of transformers:\n <transformer class=\"MyConditionalCopyField\" />\n <transformer class=\"SynonymCleaner\" />\n <transformer class=\"RunAnalyzerAndStoreAsMultiValuedFields\"> \n\n\n> Is there a downside to the logging being separated out in this case? \n\nonly that it justifies the UpdateRequestProcessorFactory chain   \n\n\n\t- - - -\n\n\n\nThis patch includes a UpdateRequestProcessorChainFactory - this is a UpdateRequestProcessorFactory that keeps a chain of UpdateRequestProcessorFactories and iterates through them.  This pointed out another thing I don't like about the chain pattern.\n\nI need a custom UpdateRequestProcessor that checks all the requests before executing any of them.  I plan to store the valid commands in a list and only execute them in the finish() call.  I'm not sure how to map that plan to an chain.  How would I pass the output from one processor to the next?   "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12510749",
            "date": "2007-07-06T17:43:55+0000",
            "content": "> I'm not sure we need to have XML configuration for this\n\nIf we have those multiple update processor factories, I agree we don't need XML config for the transformers.\n\n> I need a custom UpdateRequestProcessor that checks all the requests before executing any of them. I plan to store the valid commands in a list and only execute them in the finish() call. I'm not sure how to map that plan to an chain. How would I pass the output from one processor to the next?\n\nI had thought of that use-case too (bulk operations), which is why I added explicit flow contol (explicit calling of next.handleAdd() in the processor). \nYou can buffer up all the requests (you want to clone the UpdateCommands as they might be reused though) and not call \"next\".\nThen in finish, you can delegate all of the buffered commands. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12510754",
            "date": "2007-07-06T18:02:12+0000",
            "content": "What about working off the version I attached (or at least folding in those changes)?  It had a bunch of changes that I prefer, including\n\n\texplicit flow control between processors for greatest flexibility\n\tremoval of NamedList return (as you say, chaining those makes less sense anyway)\n\talready extracted and optimized the complex (or rather bigger) logging logic from the simple index updating\n\tpassed in SolrQueryResponse as well, enabling a processor to change the response\n\n "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-12510759",
            "date": "2007-07-06T18:54:18+0000",
            "content": "The only one I'm not sure about is:\n\n\texplicit flow control between processors for greatest flexibility\n\n\n\nI'm still trying to avoid the parent UpdateRequestProcessorFactory chain as a default behavior.  It seems fine as a super-duper custom controlller, but unurly in the default/slightly custom case.\n\nFolding in:\n\n\tremoval of NamedList return (as you say, chaining those makes less sense anyway)\n\talready extracted and optimized the complex (or rather bigger) logging logic from the simple index updating\n\tpassed in SolrQueryResponse as well, enabling a processor to change the response\nis no problem.\n\n\n\nIf you like the general structure / flow of SOLR-269-UpdateRequestProcessorFactory.patch, I'll clean it up and work in this stuff.  Otherwise I'll look at how to make UpdateRequestProcessorFactory[] feel more palatable. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12510771",
            "date": "2007-07-06T19:46:36+0000",
            "content": "> The only one I'm not sure about is:\n> - explicit flow control between processors for greatest flexibility\n\nIt's a single call per hook:\n  if (next != null) next.processAdd();\n\nAnd it's exactly what you need for your \"buffering\" situation.\nChaining is the model that Lucene uses for it's analyzers too (only difference is that it's a pull instead of a push).\n\n> I'm still trying to avoid the parent UpdateRequestProcessorFactory chain as a default behavior. It seems fine as a super-duper custom controlller, but unurly in the default/slightly custom case. \n\nI'm not clear on why... the configuration is more complex?\n\n> If you like the general structure / flow of SOLR-269-UpdateRequestProcessorFactory.patch\n\nI'm not sure about the named processors... are they needed?\nIt seems like we need a \"standard\" one that is used by default everywhere,\nand then maybe we need to be able to change them per-handler.  Do we need this up front, or could it be deferred?\n\nIt seems like there does need to be a method on SolrCore to get a RequestProcessor or Factory, since that becomes\nthe new interface to do an index change (otherwise you miss the doc transformations, etc).\n\n> Otherwise I'll look at how to make UpdateRequestProcessorFactory[] feel more palatable.\n\nThat could be wrapped in another UpdateRequestProcessorFactory if desired... it doesn't matter much if the impl is hidden by a class or a method IMO. "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-12510774",
            "date": "2007-07-06T20:15:39+0000",
            "content": "\n> It's a single call per hook:\n>   if (next != null) next.processAdd();\n> \n\nOk.  I'm convinced.\n\n\n> \n> I'm not sure about the named processors... are they needed?\n> It seems like we need a \"standard\" one that is used by default everywhere,\n> and then maybe we need to be able to change them per-handler.  Do we need this up front, or could it be deferred?\n\nI'm not sure.  The only reason I think we may want to do it now is to keep the initialization standard and in a single place.  If we declare a default processor and have each handler optionally initialize their own, the config may look different.  RequestHandlers only have access to a NamedList while initialized, they can't (without serious changes) declare something like:\n <requestHandler ...>\n   <updateProcessor class=\"\" />\n </requestHandler>\n\nWith that in mind, I think it best to build the updateProcessors using the standard PluginLoader framework and then have RequestHandlers access them by name.\n\n\n> \n>> Otherwise I'll look at how to make UpdateRequestProcessorFactory[] feel more palatable.\n> \n> That could be wrapped in another UpdateRequestProcessorFactory if desired... it doesn't matter much if the impl is hidden by a class or a method IMO.\n\nOk, I'll start with UpdateProcessor.patch and fold in my changes. "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-12510819",
            "date": "2007-07-06T22:46:51+0000",
            "content": "New version that started with Yonik's patch.  This masks the 'Chain' in a ChainedUpdateProcessorFactory.  By default it has two elements:\n 1. RunUpdateProcessor\n 2. LogUpdateProcessor\n\nI moved the processor stuff to o.a.s.update.processor.  The Classes need to be public for them to get created with the PluginLoader.  \n\nThis still has a map<String,Factory> in core.\n\nHere is the XML configuration I am using in the testing:\n\n <updateRequestProcessor>\n   <factory name=\"standard\" class=\"solr.ChainedUpdateProcessorFactory\" >\n     <chain class=\"solr.LogUpdateProcessorFactory\" >\n\t   <int name=\"maxNumToLog\">100</int>\n     </chain>\n     <chain class=\"solr.CustomUpdateRequestProcessorFactory\" >\n\t    <lst name=\"name\">\n\t      <str name=\"n1\">x1</str>\n\t      <str name=\"n2\">x2</str>\n\t    </lst>\n     </chain>\n     <chain class=\"solr.CustomUpdateRequestProcessorFactory\" >\n\t    <lst name=\"name\">\n\t      <str name=\"nA\">xA</str>\n\t      <str name=\"nA\">xA</str>\n\t    </lst>\n     </chain>\n   </factory>\n\n   <factory name=\"custom\" class=\"solr.CustomUpdateRequestProcessorFactory\" default=\"true\" >\n    <lst name=\"name\">\n      <str name=\"n8\">88</str>\n      <str name=\"n9\">99</str>\n    </lst>\n   </factory>\n </updateRequestProcessor>\n\n\nI'm starting to like the structure.  \n\nthoughts? "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12511178",
            "date": "2007-07-09T17:16:39+0000",
            "content": "One issue: the current way of having a custom processor (CustomUpdateRequestHandler) seems less than ideal.\nFirst is that CustomUpdateRequestHandler extends XMLUpdateRequestHandler.... but what if I want one for CSV, etc.\nIf update processors are to be a first-class part of Solr, it seems like one should be able to specify the processor to use\n for any update handler (CSV, XML, etc) without having to write extra classes for those.\n\nPerhaps something like:\n <requestHandler name=\"/customupdate\" class=\"solr.XmlUpdateRequestHandler\" >\n   <str name=\"update.processor\">standard</str>\n </requestHandler> "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-12511195",
            "date": "2007-07-09T17:40:26+0000",
            "content": "Hymm.  the behavior on trunk is:\n<requestHandler name=\"/customupdate\" class=\"solr.XmlUpdateRequestHandler\" >\n   <str name=\"update.processor.factory\">class name for factory</str>\n </requestHandler> \nThe latest patch has the argument lookup an XML configured factory.\n\nDo you mean:\n\n <requestHandler name=\"/customupdate\" class=\"solr.XmlUpdateRequestHandler\" >\n    <lst name=\"invariants\">\n      <str name=\"update.processor\">standard</str>\n    </lst>\n </requestHandler> \n\nGiven the direction we are heading, it seems nice to be able to change the update behavior from:\n /update?update.processor=do-fancy-document-cleanup\n /update?update.processor=go-quick-i-know-the-docs-are-clean\n\nI made it a 1-1 relation (processor-handler) to avoid a hash lookup for each request, but from a pram would be ok.\n "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12511198",
            "date": "2007-07-09T17:49:01+0000",
            "content": "> I made it a 1-1 relation (processor-handler) to avoid a hash lookup for each request,\n\nThat was my thinking too... I wasn't suggesting making it  an overrideable parameter, but I'm not really against it either.\n\n "
        },
        {
            "author": "Hoss Man",
            "id": "comment-12511206",
            "date": "2007-07-09T18:02:30+0000",
            "content": "the idea of letting people override the processor on a per request basis seems very scary and depending on what kinds of stuff yo uwere expecting hte processor to do, could introduce some serous bugs ... but then again, if it's a param, it can be specified as an invariant if you want to ensure that doesn't happen.\n\ni guess hte key thing is just that the RequestHandler has final say over what Processor gets used ... we can provide handy tools/conventions to get that info from the config or the request, but a very simplistic RequestHandler should be able to hardcode it for absolute control. "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-12512356",
            "date": "2007-07-13T04:06:50+0000",
            "content": "> the RequestHandler has final say over what Processor gets used\n\nabsolutely!  The question is just what do in the default /update case.  I'm inclined to have the request say what processor to use.  With 'invariants' that can be fixed to a single implementation, and will let people configure processors without a custom handler.\n\nHow do you all feel about the basic structure?  I like the structure, but am not sure how 'public' to make the configuration and implementation.  While it would be nice to keep the base stuff package protected, then we can't have external configuration and external classes could not reuse the other bits of the chain (defeating the 'chain' advantages)\n\nI have a pending deadline that depends on input processing and SOLR-139 modifiable documents \u2013 it would be great to work from a lightly patched trunk rather then a heavily patched one  "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-12512390",
            "date": "2007-07-13T07:48:28+0000",
            "content": "The latest patch on SOLR-139 includes a cleaned up version of SOLR-269.  One clever change is to have the LogUpdateProcessorFactory skip building a LogUpdateProcessor if the log level is not INFO rather then keep a flag. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12512502",
            "date": "2007-07-13T14:37:26+0000",
            "content": "> How do you all feel about the basic structure?\nIt's a go!\nIt will get more complicated, I think, with document modification (SOLR-139)\n\n> While it would be nice to keep the base stuff package protected,\n\nI'm more concerned with the other parts of the API that this moves front-and-center... \nmainly UpdateCommand and friends... those were really quick hacks on my part since there were no custom \"update\" handlers at the time.\n\n> One clever change is to have the LogUpdateProcessorFactory skip building a LogUpdateProcessor if the log level is not INFO rather then keep a flag.\n\nNice!\n\nI also need SOLR-139 btw, is it easy for you to commit this first to limit the size and scope of that patch? "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12616457",
            "date": "2008-07-24T12:08:06+0000",
            "content": "I've read through most of the discussion here and the wiki page at http://wiki.apache.org/solr/UpdateRequestProcessor but I couldn't understand the reasons behind the current design.\n\nLooking at the configuration we have:\n\n<updateRequestProcessor>                                               \n   <factory name=\"standard\" class=\"solr.ChainedUpdateProcessorFactory\" default=\"true\" >\n     <chain class=\"org.apache.solr.ConditionalCopyProcessorFactory\" />                                    \n     <chain class=\"solr.RunUpdateProcessorFactory\" />                    \n     <chain class=\"solr.LogUpdateProcessorFactory\" />                   \n   </factory>                                                           \n </updateRequestProcessor>\n\n\nWhy can't it be written as:\n\n<updateRequestProcessor name=\"standard\" default=\"true\">\n  <processor class=\"com.MyUpdateProcessor\" />\n  <processor class=\"solr.RunUpdateProcessor\" />\n</updateRequestProcessor>\n\n<!-- Another one -->\n<updateRequestProcessor name=\"alternate\">\n  <processor class=\"org.apache.solr.ConditionalCopyProcessor\" />\n  <processor class=\"solr.RunUpdateProcessor\" />\n  <processor class=\"solr.LogUpdateProcessor\" />\n</updateRequestProcessor>\n\n\nWhy do we need factories here? It seems like there is no advantage being added by multiple factories. If the only advantage is with the factory being able to choose between instantiating on each request or using an already instantiated processor then one can argue on having factories for RequestHandlers or SearchComponents too. The Processors should be created once and re-used. Most of them are stateless and the others can use the init method and store state in instance variables. The same is done with RequestHandlers and SearchComponents at present.\n\nWhy should we have a explicit ChainedUpdateRequestProcessorFactory? Seems from the use-cases that processors will always be chained. Let us have the implementation do the chaining instead of asking users to add a factory in the configuration.\n\nNot trying to be critical but seems like this is too complex for the use-cases it needs to support. "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-12616483",
            "date": "2008-07-24T14:11:24+0000",
            "content": "Not trying to be critical but seems like this is too complex for the use-cases it needs to support.\nNonsense \u2013 the more review / feedback / critique we get, the better \u2013 especially before a release \n\n\"Why do we need factories here?\"  \u2013  the model came from how things work with Token/Filter factories.  Many processors need to maintain state within a request.  Check the 'log' processor.  I have one that checks if the user has permission on everything in the request before executing the commands.  We could have something that keeps track of what it did and backs out the changes if there is an error.  If each processor were shared across all requests, any state access would need to be synchronized and have some Map<Request,State> that seems to get ugly pretty fast.\n\nWhy ChainedUpdateRequestProcessorFactory?  I see your point here.  I think we can force everything to be 'chained' \u2013 The original implementation was not chained, but then the functional parts got split into their own components and chained together.  Removing the parent chained factory could simplify the whole thing. "
        },
        {
            "author": "Noble Paul",
            "id": "comment-12616511",
            "date": "2008-07-24T15:59:59+0000",
            "content": "Many processors need to maintain state within a request. Check the 'log' processor. I have one that checks \n\nif the user has permission on everything in the request before executing the commands. \n\nI do not think we need a factory where we need to maintain local state . Everything can be maintained in the method stack \n\nexample\n\nclass LocalState{\n\n  private final SolrQueryRequest req;\n  private final SolrQueryResponse rsp;\n  private final UpdateRequestProcessor next;\n  private final NamedList<Object> toLog;\ndoSomething(){\n//do your thing\n}\n}\n\n public class LogUpdateProcessor extends UpdateRequestProcessor\n   \n\n  public void processAdd(AddUpdateCommand cmd) throws IOException {\n     LocalState state = new LocalState ();//pass the params\n     state.doSomeThing()\n    }\n    \n    }\n\n\n\nHere the method acts as the factory and not the fra "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12616520",
            "date": "2008-07-24T16:16:17+0000",
            "content": "If each processor were shared across all requests, any state access would need to be synchronized and have some Map<Request,State> that seems to get ugly pretty fast.\nBut we do have SolrQueryRequest#getContext to handle those cases, don't we? IMHO, we should not force users to write a factory class for each processor when the benefit is minimal and easy workarounds exist. Please correct me if I'm misunderstanding something.\n\nNonsense - the more review / feedback / critique we get, the better - especially before a release \nGlad to hear that, though I realize that I'm a year late and that we are very close to a release \n\nIt's just that I set out to use this API and had to jump around for quite a while to figure out how to use it and how it works. I was quite surprised to find the actual chaining happening in a class which is named NoOpUpdateProcessor \u2013 though it made sense to me later. Also, it took me a while to find the wiki page for this feature because it is not linked off the main page (or the update xml/csv pages). I could find it because I knew that a class named UpdateRequestProcessor existed. We should link it off the main page so that it can be found more easily. "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-12616544",
            "date": "2008-07-24T17:27:52+0000",
            "content": "I'm all for simplifying the API.  If you guys want to take a crack at it, I'll review it ASAP.   "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12616649",
            "date": "2008-07-24T20:44:13+0000",
            "content": "But we do have SolrQueryRequest#getContext to handle those cases, don't we? IMHO, we should not force users to write a factory class for each processor when the benefit is minimal and easy workarounds exist.\n\nRight... the alternative to a per-request instance would be to use the request context.\nIn general, I think that would be more complex for a user though (if it's something they want to do per request-batch).\nI think that can be made more efficient for bulk loading by using factories too... context lookups and decisions don't have to be made  for every document. "
        },
        {
            "author": "Noble Paul",
            "id": "comment-12616778",
            "date": "2008-07-25T07:08:51+0000",
            "content": "A very simple implementation. No factory. No state \nThe attached patch has not removed the existing stuff and it is not a working model . But it demonstrates how you can put in a simpler API . The design is inspired by the ServletFilter API. but without the filterChain.doFilter() part.(it relies on the return code)  \n\nThe configuration format is \n\n<updateRequestProcessorChain>\n  <processor class=\"com.MyUpdateProcessor\" />\n  <processor class=\"solr.RunUpdateProcessor\" />\n</updateRequestProcessor>\n\n<!-- Another one -->\n<updateRequestProcessorChain name=\"alternate\">\n  <processor class=\"org.apache.solr.ConditionalCopyProcessor\" />\n  <processor class=\"solr.RunUpdateProcessor\" />\n  <processor class=\"solr.LogUpdateProcessor\" />\n</updateRequestProcessorChain>\n\n\nThe usage must be as follows\n\nsolrCore.getUpdateProcessorChain(name).processXXX(command,  solrQueryRequest, solrQueryResponse);\n\n\n\nthis patch relies on SOLR-614 for simplifying configuration "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12616923",
            "date": "2008-07-25T15:29:27+0000",
            "content": "While I like the syntax of the config (getting rid of explicit chained update processor), I'm not sure about the internal changes:\n\n\tI think that removing the factories does not simplify things... most processors that do interesting things will need to parse some request arguments and keep some state. So they will end up with a separate object that is looked up in the Context (and created if it's not there and stuffed into the Context).  Same number of classes, but maybe even a little more complex.\n\tWe lose power by removing the explicit calling of \"next\" by components.  I actually have a component that needs to buffer up some documents and pass them down the chain in batches later.  I think Ryan might have something like this too.\n\n "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-12616927",
            "date": "2008-07-25T15:51:32+0000",
            "content": "I also like the simplified syntax, and I think the parent should always be a 'chain' \u2013 this can get rid of some of the ugliness.\n\nBut the power of the chain model is that each link can take over control without the others needing to know.  For example, I have a processor that validates everything in the request before passing it on to next processors.  To do this, it reads them all in without passing them down the chain and only continues when finish() is called.\n\nI also don't see a problem with the factory model.  creating a factory is no more/less difficult then creating a special 'state' object that gets put into the context.  But the the context option, the state is always a Map call away rather them being right there.  Now you have to worry about what key you used etc... "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12616929",
            "date": "2008-07-25T15:52:06+0000",
            "content": "I think that removing the factories does not simplify things... most processors that do interesting things will need to parse some request arguments and keep some state. So they will end up with a separate object that is looked up in the Context (and created if it's not there and stuffed into the Context). Same number of classes, but maybe even a little more complex.\n\nHow about giving this independence through configuration?\n\n<updateRequestProcessorChain scope=\"request\">\n  <processor class=\"com.MyUpdateProcessor\" />\n  <processor class=\"solr.RunUpdateProcessor\" />\n</updateRequestProcessor>\n\n<!-- Another one -->\n<updateRequestProcessorChain name=\"alternate\">\n  <processor class=\"org.apache.solr.ConditionalCopyProcessor\" scope=\"request\" />\n  <processor class=\"solr.RunUpdateProcessor\" />\n  <processor class=\"solr.LogUpdateProcessor\" />\n</updateRequestProcessorChain>\n\n\n\nA \"request\" scope will create the chain or individual processor for each request so that you may maintain state without using request's context. Otherwise, it will be created once and re-used for all requests. Will that solve this problem?\n\nWe lose power by removing the explicit calling of \"next\" by components. I actually have a component that needs to buffer up some documents and pass them down the chain in batches later. I think Ryan might have something like this too.\nIn Noble's patch, instead of calling super.processXXX method, you can return true/false to signal or avoid chaining. "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-12616932",
            "date": "2008-07-25T16:08:05+0000",
            "content": "A \"request\" scope will create the chain or individual processor for each request so that you may maintain state without using request's context. Otherwise, it will be created once and re-used for all requests. Will that solve this problem?\n\n-To me, that makes it more confusing then having each processor call next() explicitly...-  (dooh - answering the wrong question)  This gets overly complex too... do we add a special init() function?  would everything need a factory, but it may or may not be used?\n\nIf the motivation for making the objects shared across requests is clarity, i'm not sure it helps.  Is there some other reason?\n\n\nIn Noble's patch, instead of calling super.processXXX method, you can return true/false to signal or avoid chaining.\n\nbut then how would a processor be able to continue the chain?  Consider the buffering example... how would I be able to call all buffered functions on finish()?  What if I want a processor to make sure only one document is sent at a time? "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12616949",
            "date": "2008-07-25T16:57:26+0000",
            "content": "This gets overly complex too... do we add a special init() function? would everything need a factory, but it may or may not be used?\nNo, why would we need special methods or a factory? Just the init/inform will be fine. Just that they would be called once in their scope. Am I missing something?\n\nI don't really care about sharing objects across requests. My motivation is only to help make the API simpler.\n\nConsider the buffering example... how would I be able to call all buffered functions on finish()? What if I want a processor to make sure only one document is sent at a time?\nI see your point here. The next UpdateProcessor or a Servlet FilterChain like design will be necessary in that case.\n\nLet me think more on this since I've obviously under-estimated the use-cases for this API. I always thought that one should do heavy-duty processing like authentication etc. on the client side before sending documents to Solr or else one should extend/write an UpdateHandler. "
        },
        {
            "author": "Noble Paul",
            "id": "comment-12616966",
            "date": "2008-07-25T17:46:33+0000",
            "content": "The idea is to make the API simple. If a Processor wishes to create a\nstate object , it is easier to do it without a factory than with a\nfactory. The user has to care about very few interfaces. I can draw\nparallels with Servlet Filter. Users write very complex  filters and I\nhave never seen people complaining about it not having a factory .\nSolrDispatchFilter is a very good example. If it is simple enough\npeople will use it. If it is complex only the 'very smart people' use\nit. Most of the users are not power users and they just want to get\nthings done.\n\nOn Fri, Jul 25, 2008 at 10:27 PM, Shalin Shekhar Mangar (JIRA)\n\n\n\n\u2013 \n--Noble Paul "
        }
    ]
}