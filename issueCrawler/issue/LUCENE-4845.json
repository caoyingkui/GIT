{
    "id": "LUCENE-4845",
    "title": "Add AnalyzingInfixSuggester",
    "details": {
        "components": [
            "modules/spellchecker"
        ],
        "fix_versions": [
            "4.4",
            "6.0"
        ],
        "affect_versions": "None",
        "priority": "Major",
        "labels": "",
        "type": "Improvement",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "Our current suggester impls do prefix matching of the incoming text\nagainst all compiled suggestions, but in some cases it's useful to\nallow infix matching.  E.g, Netflix does infix suggestions in their\nsearch box.\n\nI did a straightforward impl, just using a normal Lucene index, and\nusing PostingsHighlighter to highlight matching tokens in the\nsuggestions.\n\nI think this likely only works well when your suggestions have a\nstrong prior ranking (weight input to build), eg Netflix knows\nthe popularity of movies.",
    "attachments": {
        "LUCENE-4845.patch": "https://issues.apache.org/jira/secure/attachment/12574090/LUCENE-4845.patch",
        "infixSuggest.png": "https://issues.apache.org/jira/secure/attachment/12574091/infixSuggest.png"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2013-03-17T22:19:10+0000",
            "content": "Initial patch, lots of nocommits, only a basic test so far... ",
            "author": "Michael McCandless",
            "id": "comment-13604771"
        },
        {
            "date": "2013-03-17T22:20:35+0000",
            "content": "Screen shot showing suggestions for \"hear\". ",
            "author": "Michael McCandless",
            "id": "comment-13604772"
        },
        {
            "date": "2013-03-17T22:22:00+0000",
            "content": "This is an example of the infix suggestions:  ",
            "author": "Michael McCandless",
            "id": "comment-13604774"
        },
        {
            "date": "2013-03-17T22:33:33+0000",
            "content": "Wouldnt the straightforward impl be to put the suffixes of the suggestions into the FST?\n\nso for \"this is a test\" \nyou also add \"is a test\", \"a test\", ...\n\nI feel like this could be done with just a tokenfilter used only at build-time + analyzingsuggester, and would be more performant. ",
            "author": "Robert Muir",
            "id": "comment-13604777"
        },
        {
            "date": "2013-03-18T22:51:42+0000",
            "content": "Another iteration:\n\n\n\tI use SortingAtomicReader to sort all docs by weight (impact\n    sorted postings), and then during the search I stop after\n    collecting the first N docs.\n\n\n\n\n\tI index leading ngrams up to a limit (default 4 characters) and\n    use those instead of PrefixQuery when the last term is short.\n\n\n\n\n\tI switched to a custom highlighter so prefix matches will always\n    highlight correctly.\n\n\n\nI tested on the FreeDB corpus (song titles) ... this is a pretty big\nset of suggestions: 44.5 M songs across 3.2 M albums.  I pick a random\nsubset of the titles, and then test 2,4,6,8 length prefixes:\n\n\n\t852 sec to build\n\t3.7 GB index\n\tPrefix 2: 50656.1 lookups/sec\n\tPrefix 4: 1361.0 lookups/sec\n\tPrefix 6: 7291.0 lookups/sec\n\tPrefix 8: 5364.5 lookups/sec\n\tPrefix 10: 4144.0 lookups/sec\n\n\n\nEg AnalyzingSuggester (which doesn't highlight so it's not quite a\nfair comparison):\n\n\n\t641 sec to build\n\t2.1 GB FST\n\tPrefix 2: 9719.3 lookups/sec\n\tPrefix 4: 15750.2 lookups/sec\n\tPrefix 6: 21491.4 lookups/sec\n\tPrefix 8: 27453.4 lookups/sec\n\tPrefix 10: 33168.4 lookups/sec\n\n\n\nSo it's quite a bit slower than AnalyzingSuggester but I think it's\nstill plenty fast for most apps (this is perf for a single thread). ",
            "author": "Michael McCandless",
            "id": "comment-13605768"
        },
        {
            "date": "2013-03-18T22:53:43+0000",
            "content": "Wouldnt the straightforward impl be to put the suffixes of the suggestions into the FST?\n\nI think so ... but then I worry about the FST blowing up.  I guess if we limit how \"deep\" the infixing can work that would limit the FST size ... but I'd rather not have that limit.\n\nWe should definitely try it ... it should be a lot faster.  I wonder how we could get highlighting working with AnalyzingSuggester. ",
            "author": "Michael McCandless",
            "id": "comment-13605769"
        },
        {
            "date": "2013-03-19T00:38:17+0000",
            "content": "\nI think so ... but then I worry about the FST blowing up. I guess if we limit how \"deep\" the infixing can work that would limit the FST size ... but I'd rather not have that limit.\n\nBut how is this any different than edge-ngrams up to a limit?\n\nWith words of <= 4 chars, this suggester avoids the typical bad complexity you would get from an inverted index because the docids are pre-sorted in weight-order, so it can early terminate.\n\nBut as soon as you type that 5th character: it can blow up. I'm not saying its likely, but can happen due to particulars of the content, for example if you had place names and you typed Shangh... and this prefix matches millions and millions of terms. ",
            "author": "Robert Muir",
            "id": "comment-13605868"
        },
        {
            "date": "2013-03-19T05:40:49+0000",
            "content": "ok here's the start of a hack patch. my trivial test passes.\n\nthe whole thing is a nocommit (and there is no depth bound for the infixing). \n\nIts also probably really slow and buggy  ",
            "author": "Robert Muir",
            "id": "comment-13606088"
        },
        {
            "date": "2013-03-19T05:41:07+0000",
            "content": "And this one is FuzzyAnalyzingInfixSuggester so you have to top that with your perf tests  ",
            "author": "Robert Muir",
            "id": "comment-13606089"
        },
        {
            "date": "2013-03-19T15:29:14+0000",
            "content": "This seems to not blow up for title-like fields:\nI did a quick test of geonames (8.3M place names, just using ID as the weight)\n\n\nAnalyzingSuggester: 117444563 bytes, 74887ms build time\nInfixingSuggester: 302127665 bytes, 125895ms build time\n\n\n\nI think realistically an N limit can work well here. After such a limit, the infixing is\npretty crazy anyway, and really infixing should \"punish\" the weight in some way since its\na very scary \"edit\" operation to do to the user.\n\nPlus you get optional fuzziness and real \"phrasing\" works too  ",
            "author": "Robert Muir",
            "id": "comment-13606405"
        },
        {
            "date": "2013-03-20T00:12:00+0000",
            "content": "I like this approach!  (Add epsilon transitions after the automaton is built).\n\nI managed to build the FreeDB suggest using this but ... it required a lot of RAM: it OOM'd at 14 GB heap but finished successfully at 20 GB heap.\n\nTook a longish time to build too, and made a biggish FST (more than 2X larger than the index):\n\n\n\t2466 sec to build\n\tFST is 8.6 GB\n\tPrefix 2: 2527.5 lookups/sec\n\tPrefix 4: 1681.7 lookups/sec\n\tPrefix 6: 1948.3 lookups/sec\n\tPrefix 8: 2050.9 lookups/sec\n\tPrefix 10: 2076.0 lookups/sec\n\n\n\nWe should try the N prefix limit ... but I don't really like that.  Maybe we should just offer both approaches ... ",
            "author": "Michael McCandless",
            "id": "comment-13607085"
        },
        {
            "date": "2013-03-20T00:48:39+0000",
            "content": "\nI managed to build the FreeDB suggest using this but ... it required a lot of RAM: it OOM'd at 14 GB heap but finished successfully at 20 GB heap.\n\nTook a longish time to build too, and made a biggish FST (more than 2X larger than the index):\n\nI think its because your FreeDB has a lot more words than my place names?\n\nBut really there must be a infixing limit for relevance reasons alone.\n\n\nWe should try the N prefix limit ... but I don't really like that. Maybe we should just offer both approaches ...\n\nWhy is it so bad, but the edge-ngrams limit ok? ",
            "author": "Robert Muir",
            "id": "comment-13607120"
        },
        {
            "date": "2013-03-20T12:09:26+0000",
            "content": "I think its because your FreeDB has a lot more words than my place names?\n\nI think so.  Song titles are longer than place names \n\nBut really there must be a infixing limit for relevance reasons alone.\n\nI think the app can decide this.\n\nWhy is it so bad, but the edge-ngrams limit ok?\n\nI don't think either limit is OK!  In the ideal world we wouldn't require such limits due to performance/RAM issues.\n\nBut no suggester is perfect, this is why we offer multiple options.  These two approaches have different tradeoffs... ",
            "author": "Michael McCandless",
            "id": "comment-13607539"
        },
        {
            "date": "2013-03-20T12:39:27+0000",
            "content": "\nI don't think either limit is OK! In the ideal world we wouldn't require such limits due to performance/RAM issues.\n\nYou still misunderstand me. I dont want the limit for performance/RAM reasons. I want it for relevance reasons. It\njust also gives better performance and memory for free. this is a really simple thing to do mike. Its a win/win\n\nOn the other hand your edge-ngrams limit is completely different. When exceeded, it causes that suggester to work\nin linear time! ",
            "author": "Robert Muir",
            "id": "comment-13607552"
        },
        {
            "date": "2013-05-22T10:44:51+0000",
            "content": "Just checkpointing my current patch, with changes from http://jirasearch.mikemccandless.com ... still lots of nocommits ... ",
            "author": "Michael McCandless",
            "id": "comment-13663992"
        },
        {
            "date": "2013-05-26T03:56:22+0000",
            "content": "Oops, I hit something on the keyboard while reading the issue and it just assigned it to me . ",
            "author": "Shai Erera",
            "id": "comment-13667207"
        },
        {
            "date": "2013-06-20T21:47:07+0000",
            "content": "New patch, fixing nocommits, adding tests. ",
            "author": "Michael McCandless",
            "id": "comment-13689720"
        },
        {
            "date": "2013-06-21T19:12:12+0000",
            "content": "New patch, adding the boolean allTermsRequired to the protected\nfinishTerms method, and fixed the ForkLastToken test case to only join\nthe last two tokens when the term is the same.\n\nI also pushed the latest patch to the Jira search\n(http://jirasearch.mikemccandless.com), which uses\nAnalyzingInfixSuggester for the auto-suggest, and it seems to be\nworking.\n\nHere's the benchmark results:\n\n -- construction time\n FuzzySuggester  input: 50001, time[ms]: 266 [+- 9.15]\n AnalyzingSuggester input: 50001, time[ms]: 270 [+- 41.81]\n AnalyzingInfixSuggester input: 50001, time[ms]: 360 [+- 7.14]\n JaspellLookup   input: 50001, time[ms]: 22 [+- 4.23]\n TSTLookup       input: 50001, time[ms]: 75 [+- 1.48]\n FSTCompletionLookup input: 50001, time[ms]: 127 [+- 3.34]\n WFSTCompletionLookup input: 50001, time[ms]: 119 [+- 3.84]\n\n -- prefixes: 2-4, num: 7, onlyMorePopular: false\n FuzzySuggester  queries: 50001, time[ms]: 2130 [+- 12.05], ~kQPS: 23\n AnalyzingSuggester queries: 50001, time[ms]: 642 [+- 8.80], ~kQPS: 78\n AnalyzingInfixSuggester queries: 50001, time[ms]: 863 [+- 9.50], ~kQPS: 58\n JaspellLookup   queries: 50001, time[ms]: 131 [+- 3.91], ~kQPS: 381\n TSTLookup       queries: 50001, time[ms]: 467 [+- 0.96], ~kQPS: 107\n FSTCompletionLookup queries: 50001, time[ms]: 369 [+- 5.21], ~kQPS: 135\n WFSTCompletionLookup queries: 50001, time[ms]: 291 [+- 4.64], ~kQPS: 172\n\n -- prefixes: 6-9, num: 7, onlyMorePopular: false\n FuzzySuggester  queries: 50001, time[ms]: 3216 [+- 14.12], ~kQPS: 16\n AnalyzingSuggester queries: 50001, time[ms]: 275 [+- 4.10], ~kQPS: 182\n AnalyzingInfixSuggester queries: 50001, time[ms]: 656 [+- 10.20], ~kQPS: 76\n JaspellLookup   queries: 50001, time[ms]: 73 [+- 3.17], ~kQPS: 688\n TSTLookup       queries: 50001, time[ms]: 61 [+- 1.99], ~kQPS: 815\n FSTCompletionLookup queries: 50001, time[ms]: 273 [+- 2.45], ~kQPS: 183\n WFSTCompletionLookup queries: 50001, time[ms]: 86 [+- 3.49], ~kQPS: 579\n\n -- prefixes: 100-200, num: 7, onlyMorePopular: false\n FuzzySuggester  queries: 50001, time[ms]: 3572 [+- 14.58], ~kQPS: 14\n AnalyzingSuggester queries: 50001, time[ms]: 251 [+- 4.99], ~kQPS: 199\n AnalyzingInfixSuggester queries: 50001, time[ms]: 502 [+- 12.07], ~kQPS: 100\n JaspellLookup   queries: 50001, time[ms]: 57 [+- 3.38], ~kQPS: 873\n TSTLookup       queries: 50001, time[ms]: 27 [+- 1.74], ~kQPS: 1851\n FSTCompletionLookup queries: 50001, time[ms]: 254 [+- 1.47], ~kQPS: 197\n WFSTCompletionLookup queries: 50001, time[ms]: 62 [+- 3.34], ~kQPS: 807\n\n -- RAM consumption\n FuzzySuggester  size[B]:      765,461\n AnalyzingSuggester size[B]:      765,461\n AnalyzingInfixSuggester size[B]:    2,228,216\n JaspellLookup   size[B]:    9,815,144\n TSTLookup       size[B]:    9,459,256\n FSTCompletionLookup size[B]:      376,896\n WFSTCompletionLookup size[B]:      450,384\n\n ",
            "author": "Michael McCandless",
            "id": "comment-13690610"
        },
        {
            "date": "2013-07-01T21:01:22+0000",
            "content": "I think the last patch is ready ... I'll commit this soon if there are no objections! ",
            "author": "Michael McCandless",
            "id": "comment-13697170"
        },
        {
            "date": "2013-07-08T06:29:45+0000",
            "content": "I guess, there should be an AnalyzingInfixLookupFactory in Solr as well? ",
            "author": "Artem Lukanin",
            "id": "comment-13701814"
        },
        {
            "date": "2013-07-15T14:04:57+0000",
            "content": "I guess, there should be an AnalyzingInfixLookupFactory in Solr as well?\n\nI agree ... but this can be done separately. ",
            "author": "Michael McCandless",
            "id": "comment-13708479"
        },
        {
            "date": "2013-07-15T14:12:35+0000",
            "content": "Mike, will you still commit it to 4.4? I think that the branch was created prematurely as there's still no resolution on whether to release or not. And this feature is pretty isolated to cause any instability ... it'd be a petty to have to wait with releasing it another 3-4 months just because of technicalities... ",
            "author": "Shai Erera",
            "id": "comment-13708484"
        },
        {
            "date": "2013-07-15T16:45:27+0000",
            "content": "Mike, will you still commit it to 4.4?\n\nOK I'll commit shortly & backport to 4.4 branch... ",
            "author": "Michael McCandless",
            "id": "comment-13708618"
        },
        {
            "date": "2013-07-15T17:06:33+0000",
            "content": "Commit 1503340 from Michael McCandless in branch 'dev/trunk'\n[ https://svn.apache.org/r1503340 ]\n\nLUCENE-4845: add AnalyzingInfixSuggester ",
            "author": "ASF subversion and git services",
            "id": "comment-13708640"
        },
        {
            "date": "2013-07-15T17:26:17+0000",
            "content": "Commit 1503356 from Michael McCandless in branch 'dev/branches/branch_4x'\n[ https://svn.apache.org/r1503356 ]\n\nLUCENE-4845: add AnalyzingInfixSuggester ",
            "author": "ASF subversion and git services",
            "id": "comment-13708674"
        },
        {
            "date": "2013-07-15T17:32:31+0000",
            "content": "Commit 1503359 from Michael McCandless in branch 'dev/branches/lucene_solr_4_4'\n[ https://svn.apache.org/r1503359 ]\n\nLUCENE-4845: add AnalyzingInfixSuggester ",
            "author": "ASF subversion and git services",
            "id": "comment-13708682"
        },
        {
            "date": "2013-07-15T20:29:33+0000",
            "content": "Commit 1503458 from Michael McCandless in branch 'dev/trunk'\n[ https://svn.apache.org/r1503458 ]\n\nLUCENE-4845: close tmp directory; fix test to catch un-closed files; add missing suggester.close() ",
            "author": "ASF subversion and git services",
            "id": "comment-13708934"
        },
        {
            "date": "2013-07-15T20:30:12+0000",
            "content": "Commit 1503459 from Michael McCandless in branch 'dev/branches/branch_4x'\n[ https://svn.apache.org/r1503459 ]\n\nLUCENE-4845: close tmp directory; fix test to catch un-closed files; add missing suggester.close() ",
            "author": "ASF subversion and git services",
            "id": "comment-13708937"
        },
        {
            "date": "2013-07-15T20:30:43+0000",
            "content": "Commit 1503460 from Michael McCandless in branch 'dev/branches/lucene_solr_4_4'\n[ https://svn.apache.org/r1503460 ]\n\nLUCENE-4845: close tmp directory; fix test to catch un-closed files; add missing suggester.close() ",
            "author": "ASF subversion and git services",
            "id": "comment-13708939"
        },
        {
            "date": "2013-07-15T21:09:48+0000",
            "content": "Commit 1503476 from Steve Rowe in branch 'dev/trunk'\n[ https://svn.apache.org/r1503476 ]\n\nLUCENE-4845: Maven and IntelliJ config ",
            "author": "ASF subversion and git services",
            "id": "comment-13708987"
        },
        {
            "date": "2013-07-15T21:10:45+0000",
            "content": "Commit 1503477 from Steve Rowe in branch 'dev/branches/branch_4x'\n[ https://svn.apache.org/r1503477 ]\n\nLUCENE-4845: Maven and IntelliJ config (merged trunk r1503476) ",
            "author": "ASF subversion and git services",
            "id": "comment-13708989"
        },
        {
            "date": "2013-07-15T21:11:19+0000",
            "content": "Commit 1503478 from Steve Rowe in branch 'dev/branches/lucene_solr_4_4'\n[ https://svn.apache.org/r1503478 ]\n\nLUCENE-4845: Maven and IntelliJ config (merged trunk r1503476) ",
            "author": "ASF subversion and git services",
            "id": "comment-13708992"
        },
        {
            "date": "2013-07-23T18:37:09+0000",
            "content": "Bulk close resolved 4.4 issues ",
            "author": "Steve Rowe",
            "id": "comment-13716767"
        }
    ]
}