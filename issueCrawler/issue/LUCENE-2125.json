{
    "id": "LUCENE-2125",
    "title": "Ability to store and retrieve attributes in the inverted index",
    "details": {
        "labels": "",
        "priority": "Minor",
        "components": [
            "core/index"
        ],
        "type": "New Feature",
        "fix_versions": [
            "4.9",
            "6.0"
        ],
        "affect_versions": "4.0-ALPHA",
        "resolution": "Unresolved",
        "status": "Open"
    },
    "description": "Now that we have the cool attribute-based TokenStream API and also the\ngreat new flexible indexing features, the next logical step is to\nallow storing the attributes inline in the posting lists. Currently\nthis is only supported for the PayloadAttribute.\n\nThe flex search APIs already provide an AttributeSource, so there will\nbe a very clean and performant symmetry. It should be seamlessly\npossible for the user to define a new attribute, add it to the\nTokenStream, and then retrieve it from the flex search APIs.\n\nWhat I'm planning to do is to add additional methods to the token\nattributes (e.g. by adding a new class TokenAttributeImpl, which\nextends AttributeImpl and is the super class of all impls in\no.a.l.a.tokenattributes):\n\n\tvoid serialize(DataOutput)\n\tvoid deserialize(DataInput)\n\tboolean storeInIndex()\n\n\n\nThe indexer will only call the serialize method of an\nTokenAttributeImpl in case its storeInIndex() returns true. \n\nThe big advantage here is the ease-of-use: A user can implement in one\nplace everything necessary to add the attribute to the index.\n\nBtw: I'd like to introduce DataOutput and DataInput as super classes\nof IndexOutput and IndexInput. They will contain methods like\nreadByte(), readVInt(), etc., but methods such as close(),\ngetFilePointer() etc. will stay in the super classes.\n\nCurrently the payload concept is hardcoded in \nTermsHashPerField and FreqProxTermsWriterPerField. These classes take\ncare of copying the contents of the PayloadAttribute over into the \nintermediate in-memory postinglist representation and reading it\nagain. Ideally these classes should not know about specific\nattributes, but only call serialze() on those attributes that shall\nbe stored in the posting list.\n\nWe also need to change the PositionsEnum and PositionsConsumer APIs to\ndeal with attributes instead of payloads.\n\nI think the new codecs should all support storing attributes. Only the\npreflex one should be hardcoded to only take the PayloadAttribute into\naccount.\n\nWe'll possibly need another extension point that allows us to influence \ncompression across multiple postings. Today we use the\nlength-compression trick for the payloads: if the previous payload had\nthe same length as the current one, we don't store the length\nexplicitly again, but only set a bit in the shifted position VInt. Since\noften all payloads of one posting list have the same length, this\nresults in effective compression.\nNow an advanced user might want to implement a similar encoding, where\nit's not enough to just control serialization of a single value, but\nwhere e.g. the previous position can be taken into account to decide\nhow to encode a value. \nI'm not sure yet how this extension point should look like. Maybe the\nflex APIs are actually already sufficient.\n\nOne major goal of this feature is performance: It ought to be more \nefficient to e.g. define an attribute that writes and reads a single \nVInt than storing that VInt as a payload. The payload has the overhead\nof converting the data into a byte array first. An attribute on the other \nhand should be able to call 'int value = dataInput.readVInt();' directly\nwithout the byte[] indirection.\n\nAfter this part is done I'd like to use a very similar approach for\ncolumn-stride fields.",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "date": "2009-12-07T09:40:33+0000",
            "content": "This sounds great \u2013 and is the logical next step for flex.\n\nSo you'd remove the explicit payload methods in PositionsEnum?  Ie,\nusers on migrating to flex would have to switch to the payloads\nattribute?\n\nNote the that preflex codec only has a reader (FieldsProducer), not a\nwriter.  Ie you can read the old index format but not write it.\n\nIdeally the serialize/unserialize could efficiently handle the\nfixed-length case without using up the 1 bit in the index.\n\nI wonder if we need to allow codecs to store data into\nSegmentInfo/FieldInfo for this (we don't now). ",
            "author": "Michael McCandless",
            "id": "comment-12786837"
        },
        {
            "date": "2009-12-07T10:15:43+0000",
            "content": "\nSo you'd remove the explicit payload methods in PositionsEnum? Ie,\nusers on migrating to flex would have to switch to the payloads\nattribute?\n\nI think that would make sense? Payloads don't have to be treated specially anymore,\nif any attribute can be stored in the posting lists.\n\n\nNote the that preflex codec only has a reader (FieldsProducer), not a\nwriter. Ie you can read the old index format but not write it.\n\nHmm, so the concern is that people have to make the switch to the flex APIs\nafter upgrading to the next Lucene version if they want to create indexes with \ngood old payloads?\n\n\nIdeally the serialize/unserialize could efficiently handle the\nfixed-length case without using up the 1 bit in the index.\n\nYes!\n\n\nI wonder if we need to allow codecs to store data into\nSegmentInfo/FieldInfo for this (we don't now).\n\nIMO we definitely do. E.g. for backwards-compatibility: if users switch the encoding\nof an attribute, then they need a way to determine in which format it is stored in a \ngiven segment.\n\nAnd we need to open up FieldInfo too: it has to store which and in what order the\nattributes are stored. \n\nI'm sure these are the things you had in mind too? ",
            "author": "Michael Busch",
            "id": "comment-12786848"
        },
        {
            "date": "2009-12-07T10:38:11+0000",
            "content": "I think it makes sense to not treat payloads specially in flex, ie, make it an attr.\n\n\nHmm, so the concern is that people have to make the switch to the flex APIs\nafter upgrading to the next Lucene version if they want to create indexes with \ngood old payloads?\n\nWell, not really \u2013 if you stick payloads into your tokens during analysis, presumably the standard (= default) codec would recognize the new payload attr, and store it like normal.  Then, any existing queries that do interesting things w/ payloads (PayloadNear/TermQuery), we'd cutover to the new API, and your custom Similarity would still be invoked?\n\nIt's only if you directly access TermPositions's payload API today, that you'd have to migrate to the new API?\n\nBut, even then, flex does back compat emulation, so a new index written with the standard codec could be accessed via the old API.\n\nBTW probably the attribute should include a \"merge\" operation, somehow, to be efficient (simply byte[] copying instead of decode/encode) in the merge case. ",
            "author": "Michael McCandless",
            "id": "comment-12786854"
        },
        {
            "date": "2009-12-07T10:42:50+0000",
            "content": "\nBTW probably the attribute should include a \"merge\" operation, somehow, to be efficient (simply byte[] copying instead of decode/encode) in the merge case.\n\nYes, and then I can also close LUCENE-1585!  ",
            "author": "Michael Busch",
            "id": "comment-12786855"
        },
        {
            "date": "2009-12-07T10:44:07+0000",
            "content": "\nI wonder if we need to allow codecs to store data into SegmentInfo/FieldInfo for this (we don't now).\n\nIMO we definitely do. E.g. for backwards-compatibility: if users switch the encoding\nof an attribute, then they need a way to determine in which format it is stored in a \ngiven segment.\n\nAnd we need to open up FieldInfo too: it has to store which and in what order the\nattributes are stored.\n\nI'm sure these are the things you had in mind too?\n\nWell... some stuff should be written into the header of each file, so eg a switch to encoding could be handled by the simple versioning the Codec API gives you (Codec.writeHeader/Codec.checkHeader).\n\nBut, yeah, for other stuff I've been assuming we need to open up Segment/FieldInfo.\n\nSo eg \"omitTermFreqAndPositions\" is something we could conceivably put under codec control, ie, Lucene core shouldn't need to know this attr even exists.  But, then we'd need extensibility of Field as well.  We've discussed splitting this setting, to separately control whether the freq is written and whether the positions are written, which makes complete sense.  It'd be great if such a change could be cleanly handled by simply creating a new version of the codec.  Likewise, \"hasProx\", which is derived from the omitTFAPs of all fields within the segment, should be computed/managed entirely within the codec. ",
            "author": "Michael McCandless",
            "id": "comment-12786856"
        },
        {
            "date": "2009-12-07T10:46:29+0000",
            "content": "Yes, and then I can also close LUCENE-1585! \n\nActually, flex now gives your codec a start, here \u2013 the merge has been refactored onto the Fields/Terms/Docs/PositionsEnum base classes.  This means you can make a codec that overrides how positions are merged, to change what's done with the payloads.\n\nBut, the solution proposed in this issue takes it further (better) \u2013 you shouldn't have to override all of positions merging just because one attr (payloads, or another) wants control over how it's merged. ",
            "author": "Michael McCandless",
            "id": "comment-12786857"
        },
        {
            "date": "2010-03-06T13:40:53+0000",
            "content": "I would prefer to not extend AttributeImpl but more make the attribute simply extend another interface: SerializableAttribute that provides input/output methods. Docinverter can then just check with instanceof, if the attribute is to be stored in index.\n\nThis would also help with ProxyAttributes (LUCENE-2154). ",
            "author": "Uwe Schindler",
            "id": "comment-12842259"
        },
        {
            "date": "2010-03-06T14:33:19+0000",
            "content": "We may need to allow for stateful serializers?\n\nEG (contribed example) imagine an attr that stays the same for most\ndocs, so, attr writes 1 byte for \"it's the same or not\" and then many\nbytes when there is a change.  The serializer will want to remember\nlast value it wrote?  (Hmm though I guess attr could also eg keep a\nbit inside noting that it had changed on the last call to .next(), as\nwell).  (The payload encoding length only when length changes is a\nsimilar example, but, this encoding \"takes avantage\" of being deeply\ntied to the codec since that bit is merged with the position length\ndelta.)\n\nOr imagine writing strings to the index, but the strings have dups,\nyet you don't know the full universe of strings up front.  So you make\na dict as you go (first time you see a string you assign it the next\nint).  This case goes beyond first one because this dict must be\nsaved on .close() (maybe optionally taking a different DataOutput to\nsave its state to), and, codec must remember which file that attr had\nbeen .close()d on so that at read time it can seek there and init the\nstateful deserializer (which should be lazy... ie if you don't request\nthe attr it shouldn't load the dict).\n\nAlso: codec would need to know if serialization is fixed width... or\nmaybe expose a .skip() method on deserializer?  EG I may be enuming\nonly docs/positions but not attrs (say, running a normal PhraseQuery),\nand I want to just skip (like how we skip payload today when its not\nread).\n\nI wonder if StandardCodec should inline serialized attrs into existing\npostings lists, or, make separate file to hold them...? ",
            "author": "Michael McCandless",
            "id": "comment-12842264"
        },
        {
            "date": "2010-03-08T00:31:34+0000",
            "content": "One question...\n\nSay I make an attr and it serializes to variable number of bytes, per\nposition.\n\nHow can we design serializer API so that this attr can do the same\nencoding trick we do with payload today?\n\nIe where we steal 1 bit from the pos-delta to state whether the length\nchanged from last time?\n\nIf we can do this then I think we should remove payload from the\nflex postings API and just move directly to attrs?\n\nThough: how, also, should we encode more than 1 attr per position?\nCan we somehow make this the responsibility of the serializer (if we\ncan somehow get one serializer for all attrs that are serializable in\nthe source)?\n\nThis way a user could make their own serializer if they know\ninteresting things about the attrs they need to serialize.  EG maybe\neither A or B needs to be serialized but never both... or C only is\nserialized if A is not null... etc.\n\nIf we do this then from Lucene's standpoint the serialization will\n\"feel\" just like payload feels today \u2013 an optional byte[] that may or\nmay not be variable length. ",
            "author": "Michael McCandless",
            "id": "comment-12842512"
        },
        {
            "date": "2013-07-23T18:44:34+0000",
            "content": "Bulk move 4.4 issues to 4.5 and 5.0 ",
            "author": "Steve Rowe",
            "id": "comment-13716988"
        },
        {
            "date": "2014-04-16T12:54:26+0000",
            "content": "Move issue to Lucene 4.9. ",
            "author": "Uwe Schindler",
            "id": "comment-13970755"
        }
    ]
}