{
    "id": "SOLR-8291",
    "title": "NPE calling export handler when useFilterForSortedQuery=true",
    "details": {
        "components": [
            "SolrCloud"
        ],
        "type": "Bug",
        "labels": "",
        "fix_versions": [],
        "affect_versions": "5.2.1",
        "status": "Open",
        "resolution": "Unresolved",
        "priority": "Major"
    },
    "description": "Updated: The stacktrace below was created when the solrconfig.xml has the following element:\n\n\n <useFilterForSortedQuery>true</useFilterForSortedQuery>\n\n\n\nIt was determined that useFilterForSortedQuery is incompatible with the /export handler.\n\nSee the comments near the end of the ticket for a potential work around if this flag needs to be set.\n\nGet NPE during calling export handler, here is the stack trace:\n\tat org.apache.lucene.util.BitSetIterator.<init>(BitSetIterator.java:58)\n\tat org.apache.solr.response.SortingResponseWriter.write(SortingResponseWriter.java:138)\n\tat org.apache.solr.response.QueryResponseWriterUtil.writeQueryResponse(QueryResponseWriterUtil.java:53)\n\tat org.apache.solr.servlet.HttpSolrCall.writeResponse(HttpSolrCall.java:727)\n\tat org.apache.solr.servlet.HttpSolrCall.call(HttpSolrCall.java:459)\n\tat org.apache.solr.servlet.SolrDispatchFilter.doFilter(SolrDispatchFilter.java:227)\n\tat org.apache.solr.servlet.SolrDispatchFilter.doFilter(SolrDispatchFilter.java:196)\n\tat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:274)\n\tat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:242)\n\tat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:274)\n\tat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:242)\n\tat org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:275)\n\tat org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:161)\n\tat org.jboss.web.tomcat.security.SecurityAssociationValve.invoke(SecurityAssociationValve.java:181)\n\tat org.jboss.modcluster.catalina.CatalinaContext$RequestListenerValve.event(CatalinaContext.java:285)\n\tat org.jboss.modcluster.catalina.CatalinaContext$RequestListenerValve.invoke(CatalinaContext.java:261)\n\tat org.jboss.web.tomcat.security.JaccContextValve.invoke(JaccContextValve.java:88)\n\tat org.jboss.web.tomcat.security.SecurityContextEstablishmentValve.invoke(SecurityContextEstablishmentValve.java:100)\n\tat org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:159)\n\tat org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:102)\n\tat org.jboss.web.tomcat.service.jca.CachedConnectionValve.invoke(CachedConnectionValve.java:158)\n\tat org.apache.catalina.valves.AccessLogValve.invoke(AccessLogValve.java:567)\n\tat org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:109)\n\tat org.jboss.web.tomcat.service.request.ActiveRequestResponseCacheValve.invoke(ActiveRequestResponseCacheValve.java:53)\n\tat org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:362)\n\tat org.apache.coyote.ajp.AjpAprProcessor.process(AjpAprProcessor.java:489)\n\tat org.apache.coyote.ajp.AjpAprProtocol$AjpConnectionHandler.process(AjpAprProtocol.java:452)\n\tat org.apache.tomcat.util.net.AprEndpoint$Worker.run(AprEndpoint.java:2019)\n\tat java.lang.Thread.run(Thread.java:745)\n\nIt seems there are some FixedBitSet was set to null",
    "attachments": {
        "solr.log": "https://issues.apache.org/jira/secure/attachment/12772801/solr.log",
        "SOLR-8291.patch": "https://issues.apache.org/jira/secure/attachment/12919132/SOLR-8291.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2015-11-13T22:48:43+0000",
            "author": "Erick Erickson",
            "content": "Do all of your docs have values in the field? If not maybe a dupe of SOLR-8285? ",
            "id": "comment-15004847"
        },
        {
            "date": "2015-11-13T22:53:21+0000",
            "author": "Ray",
            "content": "yes, some docs didn't have the value in field, it is same as SOLR-8285 ",
            "id": "comment-15004853"
        },
        {
            "date": "2015-11-13T23:06:29+0000",
            "author": "Joel Bernstein",
            "content": "It does appear to be the null in the sort field causing this error. \n\nI should have some time next week to work on SOLR-8285. ",
            "id": "comment-15004872"
        },
        {
            "date": "2015-11-13T23:08:55+0000",
            "author": "Ray",
            "content": "for my case, the sort field is not null, but some fields in fl  was null. ",
            "id": "comment-15004873"
        },
        {
            "date": "2015-11-13T23:21:14+0000",
            "author": "Joel Bernstein",
            "content": "Actually on further review it's not completely clear why this occurring. I'll keep reviewing the code. ",
            "id": "comment-15004892"
        },
        {
            "date": "2015-11-13T23:29:27+0000",
            "author": "Joel Bernstein",
            "content": "It looks like the ExportQParserPlugin is not populating the Bits for each segment. Not sure why that would be. \n\nRay, Could you post you're entire query?\n\nAre you using this in conjunction with the CollapsingQParserPlugin? ",
            "id": "comment-15004906"
        },
        {
            "date": "2015-11-13T23:44:55+0000",
            "author": "Joel Bernstein",
            "content": "Could you also post how you have configured the /export handler in the solrconfig.xml.\n\nAlso, do you have a custom PostFilter that might not be processing each segment? ",
            "id": "comment-15004925"
        },
        {
            "date": "2015-11-13T23:53:00+0000",
            "author": "Ray",
            "content": "Hi Joel:\n   1. I am not using CollapsingQParserPlugin, here is my query:, I found id1 and id2 sometimes had null values\n   http://host/solr/collection/export?q=date:[NOW+TO+*]&distrib=false&fl=id1,id2,doubleValue1&sort=doubleValue1+desc\n   2. We don't have custom PostFilter, here is the configure for export handler:\n\t<requestHandler name=\"/export\" class=\"solr.SearchHandler\">\n\t\u00a0\u00a0<lst name=\"invariants\">\n\t\u00a0\u00a0\u00a0\u00a0<str name=\"rq\">\n{!xport}\n</str>\n\t\u00a0\u00a0\u00a0\u00a0<str name=\"wt\">xsort</str>\n\t\u00a0\u00a0\u00a0\u00a0<str name=\"distrib\">false</str>\n\t\u00a0\u00a0</lst>\n\t\u00a0\u00a0<arr name=\"components\">\n\t\u00a0\u00a0\u00a0\u00a0<str>query</str>\n\t\u00a0\u00a0</arr>\n\t</requestHandler>\n ",
            "id": "comment-15004938"
        },
        {
            "date": "2015-11-14T00:06:59+0000",
            "author": "Joel Bernstein",
            "content": "We're going to have to try and reproduce this to fix it.\n\n1) Is every query failing for you, or just this one?\n2) How many segments are in the index? ",
            "id": "comment-15004951"
        },
        {
            "date": "2015-11-14T01:02:43+0000",
            "author": "Ray",
            "content": "1) the issues will not happen all the time, but when it happen, all the queries will failed, because we are only use this kind of query to fetch data.\n2) we had 3 shards for the collection, for each shard, there will be about 15 segments. ",
            "id": "comment-15005002"
        },
        {
            "date": "2015-11-16T13:13:10+0000",
            "author": "Joel Bernstein",
            "content": "I've been reviewing code looking for a way that this NPE could occur in normal operations and I don't see one. Can you post a log from the time period that this is occurring? I'd like to see what is happening on the server a few minutes before the NPE occurs.\n\nAlso you mention this doesn't occur all the time.  How do you get the query working again when this occurs? Does it occur for periods of time and self correct? ",
            "id": "comment-15006645"
        },
        {
            "date": "2015-11-16T18:17:14+0000",
            "author": "Ray",
            "content": "Hello Joel:\n    the issue will happen if I cleanup the index and index again, there are no special information in the log, It will work if I optimize the index explicitly, also I noticed it will start to work after a long time (1hr+?). Not sure if this is caused by index merge. ",
            "id": "comment-15007039"
        },
        {
            "date": "2015-11-16T19:12:49+0000",
            "author": "Joel Bernstein",
            "content": "Is the log level set to INFO? If it is then there is all kinds of useful information about what's occurring on the server, particularly during indexing.\n\nSo the chain of events:\n\n1) Index data.\n2) Cleanup the index. Does this mean delete all data?\n3) Index data again.\n4) Then the NPE occurs.\n\nAre you querying and indexing at the same time when the NPE occurs?\nOr does the NPE occur when indexing has stopped, or both?\nDoes this reproduce 100% of the time for you?\n ",
            "id": "comment-15007141"
        },
        {
            "date": "2015-11-16T21:18:51+0000",
            "author": "Ray",
            "content": "Here are the answers:\nout log is setting to INFO, but I didn't see any special messages\n\nthe NPE happened when we queried during indexing time, but even I stopped the index, the NPE was still there. it can be reproduce 100% of the time when it ocurred ",
            "id": "comment-15007343"
        },
        {
            "date": "2015-11-16T22:11:26+0000",
            "author": "Joel Bernstein",
            "content": "OK, I'm going to work on reproducing this. ",
            "id": "comment-15007460"
        },
        {
            "date": "2015-11-17T00:55:16+0000",
            "author": "Ray",
            "content": "Here are some logs I added in solr code to print the BitSet, hope it will be useful\n\n2015-11-17 00:51:08,453  priority=INFO  location=SortingResponseWriter line=168 sets is 17\n2015-11-17 00:51:08,454  priority=INFO  location=SortingResponseWriter line=170 set is org.apache.lucene.util.FixedBitSet@11ffcd53\n2015-11-17 00:51:08,454  priority=INFO  location=SortingResponseWriter line=170 set is org.apache.lucene.util.FixedBitSet@98761234\n2015-11-17 00:51:08,454  priority=INFO  location=SortingResponseWriter line=170 set is org.apache.lucene.util.FixedBitSet@98761234\n2015-11-17 00:51:08,454  priority=INFO  location=SortingResponseWriter line=170 set is org.apache.lucene.util.FixedBitSet@98761234\n2015-11-17 00:51:08,455  priority=INFO  location=SortingResponseWriter line=170 set is org.apache.lucene.util.FixedBitSet@98761234\n2015-11-17 00:51:08,455  priority=INFO  location=SortingResponseWriter line=170 set is org.apache.lucene.util.FixedBitSet@98761234\n2015-11-17 00:51:08,455  priority=INFO  location=SortingResponseWriter line=170 set is org.apache.lucene.util.FixedBitSet@98761234\n2015-11-17 00:51:08,455  priority=INFO  location=SortingResponseWriter line=170 set is org.apache.lucene.util.FixedBitSet@98761234\n2015-11-17 00:51:08,455  priority=INFO  location=SortingResponseWriter line=170 set is org.apache.lucene.util.FixedBitSet@98761234\n2015-11-17 00:51:08,455  priority=INFO  location=SortingResponseWriter line=170 set is org.apache.lucene.util.FixedBitSet@9876123c\n2015-11-17 00:51:08,455  priority=INFO  location=SortingResponseWriter line=170 set is null\n2015-11-17 00:51:08,455  priority=INFO  location=SortingResponseWriter line=170 set is null\n2015-11-17 00:51:08,455  priority=INFO  location=SortingResponseWriter line=170 set is null\n2015-11-17 00:51:08,456  priority=INFO  location=SortingResponseWriter line=170 set is null\n2015-11-17 00:51:08,456  priority=INFO  location=SortingResponseWriter line=170 set is null\n2015-11-17 00:51:08,456  priority=INFO  location=SortingResponseWriter line=170 set is null\n2015-11-17 00:51:08,456  priority=INFO  location=SortingResponseWriter line=170 set is null\n2015-11-17 00:51:08,456  priority=INFO  location=SortingResponseWriter line=172 totalHits=3012\n\n\nrelated code:\n\t\t\tif (info != null && ((req = info.getReq()) != null)) {\n\t\t\t\tMap context = req.getContext();\n\t\t\t\tlogger.info(\"sets is {}\", sets.length);\n\t\t\t\tfor (FixedBitSet set : sets) {\n\t\t\t\t\tlogger.info(\"set is {}\", set);\n\t\t\t\t}\n\t\t\t\tlogger.info(\"totalHits={}\", totalHits);\n\t\t\t\tcontext.put(\"export\", sets);\n\t\t\t\tcontext.put(\"totalHits\", totalHits);\n\t\t\t} ",
            "id": "comment-15007725"
        },
        {
            "date": "2015-11-17T04:38:05+0000",
            "author": "Joel Bernstein",
            "content": "Are you by any chance using early termination?\n\nI'm looking for some reason why the first 10 segments would have been visited, but the last 7 not visited. ",
            "id": "comment-15008017"
        },
        {
            "date": "2015-11-17T16:45:51+0000",
            "author": "Ray",
            "content": "Nope, I didn't use any post filter for that. it seems it is just the case, the first 10 segments got visited and the last 7 didn't.\nI also add some log in the ExportCollector.getLeafCollector method and only saw the 10 line logs ",
            "id": "comment-15008986"
        },
        {
            "date": "2015-11-17T17:04:12+0000",
            "author": "Joel Bernstein",
            "content": "Thanks, I was going to ask you to add those log lines. \n\nThis is an odd bug. Take a look at IndexSearcher line 803. This is the method that iterates the segments and calls getLeafCollector. If you can add some logging in here that might give us some interesting information.\n\nI'm continuing to review code to see how this could be occurring. ",
            "id": "comment-15009026"
        },
        {
            "date": "2015-11-17T17:09:10+0000",
            "author": "Joel Bernstein",
            "content": "Actually I'm looking at branch_5x. It's in a different spot in 5.2.1. Let me check the code in 5.2.1\n\nThe method is at IndexSearcher line 753 in 5.2.1\n\nprotected void search(List<LeafReaderContext> leaves, Weight weight, Collector collector) ",
            "id": "comment-15009039"
        },
        {
            "date": "2015-11-17T17:14:48+0000",
            "author": "Ray",
            "content": "I will add some logs and provided it to you ",
            "id": "comment-15009052"
        },
        {
            "date": "2015-11-17T18:49:23+0000",
            "author": "Ray",
            "content": "I found the call stack is as following:\n        at org.apache.solr.search.ExportQParserPlugin$ExportCollector.getLeafCollector(ExportQParserPlugin.java:140)\n        at org.apache.solr.search.SolrIndexSearcher.sortDocSet(SolrIndexSearcher.java:2048)\n        at org.apache.solr.search.SolrIndexSearcher.getDocListC(SolrIndexSearcher.java:1475)\n        at org.apache.solr.search.SolrIndexSearcher.search(SolrIndexSearcher.java:561)\n        at org.apache.solr.handler.component.QueryComponent.process(QueryComponent.java:518)\n\nI added some debug log in ExportCollector and SolrIndexSearcher, please refer to attachment:\nhere is the code fragment for org.apache.solr.search.SolrIndexSearcher.sortDocSet(QueryResult, QueryCommand)\n    LeafCollector leafCollector = null;\n    while (iter.hasNext()) {\n      int doc = iter.nextDoc();\n\t  logger.info(\"Before getLeafCollector, doc={}, end={}, base={}, readerIndex={}\", doc, end, base, readerIndex);\n      while (doc>=end) \n{\n        LeafReaderContext leaf = leafContexts.get(readerIndex++);\n        base = leaf.docBase;\n        end = base + leaf.reader().maxDoc();\n        leafCollector = topCollector.getLeafCollector(leaf);\n        // we should never need to set the scorer given the settings for the collector\n      }\n\t  logger.info(\"After getLeafCollector doc={}, end={}, base={}, readerIndex={}, leafCollector={}\", doc, end, base, readerIndex, leafCollector);\n      leafCollector.collect(doc-base);\n    } ",
            "id": "comment-15009236"
        },
        {
            "date": "2015-11-17T18:50:25+0000",
            "author": "Ray",
            "content": "From the log, it seems we will skip some leafreadercontext and which seems to cause the NPE in future ",
            "id": "comment-15009239"
        },
        {
            "date": "2015-11-17T19:08:58+0000",
            "author": "Joel Bernstein",
            "content": "Ah, you've got the useFilterCache flag on. This is not a code path that I've tested with the /export handler. I never would have been able to reproduce either\n\nIn the solrconfig there is a flag for this:\n\n\n <useFilterForSortedQuery>true</useFilterForSortedQuery>\n\n\n\nYou'll need to turn this off.\n ",
            "id": "comment-15009284"
        },
        {
            "date": "2015-11-17T19:13:39+0000",
            "author": "Joel Bernstein",
            "content": "Once you've verified this, I'll change the name of the Jira to reflect the issue. ",
            "id": "comment-15009293"
        },
        {
            "date": "2015-11-17T19:18:17+0000",
            "author": "Ray",
            "content": "After turning this off, there are no issues, so does it mean we cannot useFilterCache for export handler? is this a known issue?\nAs we need useFilterCache for other handlers in the same collection, any workaround? ",
            "id": "comment-15009301"
        },
        {
            "date": "2015-11-17T19:45:08+0000",
            "author": "Joel Bernstein",
            "content": "For now yes you'll need to turn off. I don't believe this was a known bug but it's possible that it's come up in the past. \n\nTake a look at line 1452 of the SolrIndexSearcher:\n\n\n if ((flags & (GET_SCORES|NO_CHECK_FILTERCACHE))==0 && useFilterForSortedQuery && cmd.getSort() != null && filterCache != null) {\n      useFilterCache=true;\n      SortField[] sfields = cmd.getSort().getSort();\n      for (SortField sf : sfields) {\n        if (sf.getType() == SortField.Type.SCORE) {\n          useFilterCache=false;\n          break;\n        }\n      }\n    }\n\n\n\nThere is a flag NO_CHECK_FILTERCACHE which is separate from useFilterForSortedQuery which comes from the solrconfig.xml. You could add a search component that would set this flag when the /export handler is run.\n ",
            "id": "comment-15009361"
        },
        {
            "date": "2018-02-27T11:54:22+0000",
            "author": "Ron Ben-Yosef",
            "content": "Hi,\n\nI've run into the same issue, or at least what I think is the same issue (I'm on 7.2.1, and the call stack leading up to the exception looks somewhat different, but reading everything written here I'm fairly sure it's the same issue. If it's not - let me know and I can open a separate bug for it).\n\nThe scenario is similar - querying the /export handler with the \"useFilterForSortedQuery\" configuration option enabled.\n\nHere's the call stack leading up to the exception:\n\no.a.s.s.HttpSolrCall null:java.lang.NullPointerException\nat org.apache.lucene.util.BitSetIterator.<init>(BitSetIterator.java:61)\nat org.apache.solr.handler.ExportWriter.writeDocs(ExportWriter.java:243)\nat org.apache.solr.handler.ExportWriter.lambda$null$1(ExportWriter.java:222)\nat org.apache.solr.response.JSONWriter.writeIterator(JSONResponseWriter.java:523)\nat org.apache.solr.response.TextResponseWriter.writeVal(TextResponseWriter.java:180)\nat org.apache.solr.response.JSONWriter$2.put(JSONResponseWriter.java:559)\nat org.apache.solr.handler.ExportWriter.lambda$null$2(ExportWriter.java:222)\nat org.apache.solr.response.JSONWriter.writeMap(JSONResponseWriter.java:547)\nat org.apache.solr.response.TextResponseWriter.writeVal(TextResponseWriter.java:198)\nat org.apache.solr.response.JSONWriter$2.put(JSONResponseWriter.java:559)\nat org.apache.solr.handler.ExportWriter.lambda$write$3(ExportWriter.java:220)\nat org.apache.solr.response.JSONWriter.writeMap(JSONResponseWriter.java:547)\nat org.apache.solr.handler.ExportWriter.write(ExportWriter.java:218)\nat org.apache.solr.core.SolrCore$3.write(SolrCore.java:2627)\nat org.apache.solr.response.QueryResponseWriterUtil.writeQueryResponse(QueryResponseWriterUtil.java:49)\nat org.apache.solr.servlet.HttpSolrCall.writeResponse(HttpSolrCall.java:788)\nat org.apache.solr.servlet.HttpSolrCall.call(HttpSolrCall.java:525)\nat org.apache.solr.servlet.SolrDispatchFilter.doFilter(SolrDispatchFilter.java:382)\nat org.apache.solr.servlet.SolrDispatchFilter.doFilter(SolrDispatchFilter.java:326)\nat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1751)\nat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:582)\nat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)\nat org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)\nat org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)\nat org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)\nat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)\nat org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)\nat org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)\nat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\nat org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)\nat org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)\nat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)\nat org.eclipse.jetty.rewrite.handler.RewriteHandler.handle(RewriteHandler.java:335)\nat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)\nat org.eclipse.jetty.server.Server.handle(Server.java:534)\nat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:320)\nat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)\nat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)\nat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)\nat org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)\nat org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)\nat org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)\nat org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)\nat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)\nat org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)\nat java.lang.Thread.run(Thread.java:748)\n\n\u00a0\n\nDebugging the issue, it seems what's happening is that when there's more than one leaf (=segment?) then the per-leaf bitsets are being created only upto the highest leaf with matching documents, and if that's not the last leaf then you're going to have null bitsets for all the leaves higher than the highest one containing a matching document. This happens in SolrIndexSearcher.java in the function sortDocSet:\n\n...\nLeafCollector leafCollector = null;\nwhile (iter.hasNext()) {\n int doc = iter.nextDoc();\n while (doc >= end) {\n  LeafReaderContext leaf = leafContexts.get(readerIndex++);\n  base = leaf.docBase;\n  end = base + leaf.reader().maxDoc();\n  leafCollector = topCollector.getLeafCollector(leaf);\n  // we should never need to set the scorer given the settings for the collector\n }\n leafCollector.collect(doc - base);\n}\n...\n\nAs can be seen in the code above, once there are no more matching documents the loop won't be entered anymore and so the function getLeafCollector will not be called for the remaining leaves. Since that is where ExportCollector sets the leaves' bitsets, the ones for which the function is not called will not get set and remain null, as can be seen in ExportQParserPlugin.java:\n\n@Override\npublic LeafCollector getLeafCollector(LeafReaderContext context) throws IOException {\n final FixedBitSet set = new FixedBitSet(context.reader().maxDoc());\n this.sets[context.ord] = set;\n return new LeafCollector() {\n \n  @Override\n  public void setScorer(Scorer scorer) throws IOException {}\n\n  @Override\n  public void collect(int docId) throws IOException{\n   ++totalHits;\n   set.set(docId);\n  }\n };\n}\n\nAnyhow, this array of bitsets eventually gets propagated and ends up at the ExportWriter's writeDocs method where the bitsets are used to create instances of BitSetIterator, the constructor of which then throws the NPE when trying to call the length method on the bitset in the case that it's null:\n\n...\nfor(int i=0; i<leaves.size(); i++) {\n sortDoc.setNextReader(leaves.get(i));\n DocIdSetIterator it = new BitSetIterator(sets[i], 0); // cost is not useful here\n int docId = -1;\n while((docId = it.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n  sortDoc.setValues(docId);\n  if(top.lessThan(sortDoc)) {\n   top.setValues(sortDoc);\n   top = queue.updateTop();\n  }\n }\n}\n...\n\n\u00a0\n\nAs for a fix - I tried two things, both of which seem to work:\n\n\tOne option is simply to not try iterate the null bitsets (their corresponding leaves don't include matching documents anyway, which is why the weren't set in the first place) , for instance by modifying the code from above (from ExportWriter::writeDocs) like this:\n\n\n\n\n...\nfor(int i=0; i<leaves.size(); i++) {\n if (sets[i] == null) continue;\n sortDoc.setNextReader(leaves.get(i));\n DocIdSetIterator it = new BitSetIterator(sets[i], 0); // cost is not useful here\n int docId = -1;\n while((docId = it.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n  sortDoc.setValues(docId);\n  if(top.lessThan(sortDoc)) {\n   top.setValues(sortDoc);\n   top = queue.updateTop();\n  }\n }\n}\n...\n\n\n\tThe second option is to modify SolrIndexSearcher::sortDocSet to create bitsets for the remaining leaves so that they're not null, for instance by calling getLeafCollector for them as well (even though there's no need for the collector since they include no matching documents) just for the bitsets to get created. For example:\n\n\n\n\n...\nLeafCollector leafCollector = null;\nwhile (iter.hasNext()) {\n int doc = iter.nextDoc();\n while (doc >= end) {\n  LeafReaderContext leaf = leafContexts.get(readerIndex++);\n  base = leaf.docBase;\n  end = base + leaf.reader().maxDoc();\n  leafCollector = topCollector.getLeafCollector(leaf);\n  // we should never need to set the scorer given the settings for the collector\n }\n leafCollector.collect(doc - base);\n}\n\nfor (int leaves = leafContexts.size(); readerIndex < leaves; readerIndex++) {\n topCollector.getLeafCollector(leafContexts.get(readerIndex));\n}\n...\n\n\u00a0\n\nThe first option of course won't solve any other flows where there might be attempts to access the null bitsets, but I don't know if there are any such flows or if it's at all relevant...\n\n\u00a0\n\n\u00a0\n\nSorry for the long comment.\n\n\u00a0\n\nThanks,\n\nRon ",
            "id": "comment-16378465"
        },
        {
            "date": "2018-04-16T00:05:32+0000",
            "author": "Ron Ben-Yosef",
            "content": "SOLR-8291.patch\n\nThe patch implements the first option - adding a null check for the bitsets in\u00a0ExportWriter::writeDocs. Didn't want to do the second option for now, just being careful in case it\u00a0has undesirable effects elsewhere that I might have\u00a0missed (other collector types, other flows, etc.)\n\n\u00a0\n\nFirst time preparing and submitting a git patch, so I hope I'm doing it right...\u00a0 ",
            "id": "comment-16438876"
        }
    ]
}