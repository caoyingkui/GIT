{
    "id": "SOLR-8868",
    "title": "SolrCloud: if zookeeper loses and then regains a quorum, Solr nodes and SolrJ Client do not recover and need to be restarted",
    "details": {
        "components": [
            "SolrCloud",
            "SolrJ"
        ],
        "type": "Bug",
        "labels": "",
        "fix_versions": [],
        "affect_versions": "5.3.1",
        "status": "Open",
        "resolution": "Unresolved",
        "priority": "Major"
    },
    "description": "Tried mailing list on 3/15 and 3/16 to no avail. Hopefully I gave enough details.\n\n\nJust wondering if my observation of SolrCloud behavior after ZooKeeper loses a quorum is normal or to-be-expected\n\nVersion of Solr: 5.3.1\nVersion of ZooKeeper: 3.4.7\nUsing SolrCloud with external ZooKeeper\nDeployed on AWS\n\nOur Solr cluster has 3 nodes (m3.large)\n\nOur Zookeeper ensemble consists of three nodes (t2.small) with the same config using DNS names e.g.\n\n$ more ../conf/zoo.cfg\ntickTime=2000\ndataDir=/var/zookeeper\ndataLogDir=/var/log/zookeeper\nclientPort=2181\ninitLimit=10\nsyncLimit=5\nstandaloneEnabled=false\nserver.1=zookeeper1.qa.eu-west-1.mysearch.com:2888:3888\nserver.2=zookeeper2.qa.eu-west-1.mysearch.com:2888:3888\nserver.3=zookeeper3.qa.eu-west-1.mysearch.com:2888:3888\n\n\n\nIf we terminate one of the zookeeper nodes we get a ZK election (and I think) a quorum is maintained.\nOperation continues OK and we detect the terminated instance and relaunch a new ZK node which comes up fine\n\nIf we terminate two of the ZK nodes we lose a quorum and then we observe the following\n\n1.1) Admin UI shows an error that it is unable to contact ZooKeeper \u201cCould not connect to ZooKeeper\"\n\n1.2) SolrJ returns the following\n\norg.apache.solr.common.SolrException: Could not load collection from ZK:qa_eu-west-1_public_index\nat org.apache.solr.common.cloud.ZkStateReader.getCollectionLive(ZkStateReader.java:850)\nat org.apache.solr.common.cloud.ZkStateReader$7.get(ZkStateReader.java:515)\nat org.apache.solr.client.solrj.impl.CloudSolrClient.getDocCollection(CloudSolrClient.java:1205)\nat org.apache.solr.client.solrj.impl.CloudSolrClient.requestWithRetryOnStaleState(CloudSolrClient.java:837)\nat org.apache.solr.client.solrj.impl.CloudSolrClient.request(CloudSolrClient.java:805)\nat org.apache.solr.client.solrj.SolrRequest.process(SolrRequest.java:135)\nat org.apache.solr.client.solrj.SolrClient.add(SolrClient.java:107)\nat org.apache.solr.client.solrj.SolrClient.add(SolrClient.java:72)\nat org.apache.solr.client.solrj.SolrClient.add(SolrClient.java:86)\nat com.here.scbe.search.solr.SolrFacadeImpl.addToSearchIndex(SolrFacadeImpl.java:112)\nCaused by: org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /collections/qa_eu-west-1_public_index/state.json\nat org.apache.zookeeper.KeeperException.create(KeeperException.java:99)\nat org.apache.zookeeper.KeeperException.create(KeeperException.java:51)\nat org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1155)\nat org.apache.solr.common.cloud.SolrZkClient$7.execute(SolrZkClient.java:345)\nat org.apache.solr.common.cloud.SolrZkClient$7.execute(SolrZkClient.java:342)\nat org.apache.solr.common.cloud.ZkCmdExecutor.retryOperation(ZkCmdExecutor.java:61)\nat org.apache.solr.common.cloud.SolrZkClient.getData(SolrZkClient.java:342)\nat org.apache.solr.common.cloud.ZkStateReader.getCollectionLive(ZkStateReader.java:841)\n... 24 more\n\n\n\nThis makes sense based on our understanding.\nWhen our AutoScale groups launch two new ZooKeeper nodes, initialize them, fix the DNS etc. we regain a quorum but at this point\n\n2.1) Admin UI shows the shards as \u201cGONE\u201d (all greyed out)\n\n2.2) SolrJ returns the same error even though the ZooKeeper DNS names are now bound to new IP addresses\n\nSo at this point I restart the Solr nodes. At this point then\n\n3.1) Admin UI shows the collections as OK (all shards are green) \u2013 yeah the nodes are back!\n\n3.2) SolrJ Client still shows the same error \u2013 namely\n\norg.apache.solr.common.SolrException: Could not load collection from ZK:qa_eu-west-1_here_account\nat org.apache.solr.common.cloud.ZkStateReader.getCollectionLive(ZkStateReader.java:850)\nat org.apache.solr.common.cloud.ZkStateReader$7.get(ZkStateReader.java:515)\nat org.apache.solr.client.solrj.impl.CloudSolrClient.getDocCollection(CloudSolrClient.java:1205)\nat org.apache.solr.client.solrj.impl.CloudSolrClient.requestWithRetryOnStaleState(CloudSolrClient.java:837)\nat org.apache.solr.client.solrj.impl.CloudSolrClient.request(CloudSolrClient.java:805)\nat org.apache.solr.client.solrj.SolrRequest.process(SolrRequest.java:135)\nat org.apache.solr.client.solrj.SolrClient.deleteById(SolrClient.java:825)\nat org.apache.solr.client.solrj.SolrClient.deleteById(SolrClient.java:788)\nat org.apache.solr.client.solrj.SolrClient.deleteById(SolrClient.java:803)\nat com.here.scbe.search.solr.SolrFacadeImpl.deleteById(SolrFacadeImpl.java:257)\n.\n.\nCaused by: org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /collections/qa_eu-west-1_here_account/state.json\nat org.apache.zookeeper.KeeperException.create(KeeperException.java:99)\nat org.apache.zookeeper.KeeperException.create(KeeperException.java:51)\nat org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1155)\nat org.apache.solr.common.cloud.SolrZkClient$7.execute(SolrZkClient.java:345)\nat org.apache.solr.common.cloud.SolrZkClient$7.execute(SolrZkClient.java:342)\nat org.apache.solr.common.cloud.ZkCmdExecutor.retryOperation(ZkCmdExecutor.java:61)\nat org.apache.solr.common.cloud.SolrZkClient.getData(SolrZkClient.java:342)\nat org.apache.solr.common.cloud.ZkStateReader.getCollectionLive(ZkStateReader.java:841)\n\n\n\nIs this behavior (lack of self-healing) a known and expected behavior?\n\nIf this is expected behavior then likely this should be recast as an Improvement request?\n\nIs this the same or similar behavior as documented here https://issues.apache.org/jira/browse/SOLR-5129\n\np.s. I can add Solr log files if they will help",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "date": "2016-12-21T07:34:30+0000",
            "author": "zarnigar",
            "content": "any solution found on this issue? ",
            "id": "comment-15766366"
        },
        {
            "date": "2017-05-27T22:39:09+0000",
            "author": "Martin Grotzke",
            "content": "We also experienced this issue, any update here?  ",
            "id": "comment-16027637"
        },
        {
            "date": "2017-07-04T11:10:16+0000",
            "author": "Felicity Tarnell",
            "content": "I think we're seeing this as well, running ZK and Solr on Kubernetes.  If Kubernetes restarts one of the ZooKeeper instances for some reason (like a host machine reboot) then its IP address changes, but since Solr doesn't notice that the DNS has changed, it never reconnects to that instance.   If only 1 or 2 ZK instances have been restarted, everything is fine, but as soon as all ZKs have been restarted since the time Solr started, it breaks and does not recover without a restart.\n\nAs a workaround, putting ZK behind a load balancer with a static IP address appears to fix the problem, but I'm not sure if this is a recommended configuration.  (My understanding is that Solr should be connected to all the ZK nodes.) ",
            "id": "comment-16073485"
        },
        {
            "date": "2017-07-10T13:31:46+0000",
            "author": "Sarunas Valaskevicius",
            "content": "we have the same problem as Felicity Tarnell.. still looking for a good solution ",
            "id": "comment-16080327"
        },
        {
            "date": "2018-10-10T15:01:33+0000",
            "author": "Michael",
            "content": "Same issue on SolrCloud 7.3.1 on Kubernetes. ",
            "id": "comment-16645105"
        },
        {
            "date": "2018-10-10T16:07:36+0000",
            "author": "Erick Erickson",
            "content": "not entirely sure upgrading ZooKeeper would fix this, but at least worth checking if we do.\n\n\u00a0\n\nI had some trouble when I tried upgrading ZK but I haven't had a chance to pursue it yet. ",
            "id": "comment-16645188"
        }
    ]
}