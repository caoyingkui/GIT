{
    "id": "SOLR-1150",
    "title": "OutofMemoryError on enabling highlighting",
    "details": {
        "affect_versions": "1.4",
        "status": "Closed",
        "fix_versions": [
            "1.4"
        ],
        "components": [
            "highlighter"
        ],
        "type": "Improvement",
        "priority": "Major",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "Please refer to following mail thread\n\nhttp://markmail.org/message/5nhkm5h3ongqlput\n\nI am testing with 2MB document size and just 500 documents. Indexing is working fine even with 128MB heap size. But on searching Solr throws OOM error. This issue is observed only when we enable highlighting. While indexing I am storing 1 MB text. While searching Solr reads all the 500 documents in the memory. It also reads the complete 1 MB stored field in the memory for all 500 documents. Due to this 500 docs * 1 MB * 2 (2 bytes per char) = 1000 MB memory is required for searching.\n\nThis memory usage can be reduced by reading one document at a time.",
    "attachments": {
        "SOLR-1150.patch": "https://issues.apache.org/jira/secure/attachment/12407756/SOLR-1150.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Siddharth Gargate",
            "id": "comment-12707932",
            "date": "2009-05-11T08:17:40+0000",
            "content": "I have attached the patch file with previous suggested code changes.. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-12711582",
            "date": "2009-05-21T11:54:14+0000",
            "content": "Patch looks right - my only concern would be a performance impact, but that does look unlikely. There is likely to be some benefit in loading them all at once, but I can't imagine one at a time is much of a loss. "
        },
        {
            "author": "Siddharth Gargate",
            "id": "comment-12711952",
            "date": "2009-05-22T05:23:00+0000",
            "content": "Thanks Mark.\nSolrIndexSearcher.readDocs method internally reads one doc at a time. So there shouldn't be any performance loss.  "
        },
        {
            "author": "Mark Miller",
            "id": "comment-12719597",
            "date": "2009-06-15T15:27:25+0000",
            "content": "Odd - change looks like it wouldnt affect this, but somehow the highlighter test fails as it attempts to access a deleted doc. Not quite sure what is up yet. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-12719598",
            "date": "2009-06-15T15:32:11+0000",
            "content": "There is a problem with distrib and highlighting as well. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12719599",
            "date": "2009-06-15T15:34:42+0000",
            "content": "It's trying to read the loop iterator (i.e. 0-9)   "
        },
        {
            "author": "Mark Miller",
            "id": "comment-12719601",
            "date": "2009-06-15T15:40:50+0000",
            "content": "ah, thanks for the spot yonik.\n\nIll switch it to use doc ids instead and see how things go  "
        },
        {
            "author": "Mark Miller",
            "id": "comment-12720136",
            "date": "2009-06-16T13:54:35+0000",
            "content": "Thanks Siddharth! "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12775733",
            "date": "2009-11-10T15:52:05+0000",
            "content": "Bulk close for Solr 1.4 "
        }
    ]
}