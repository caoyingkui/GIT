{
    "id": "LUCENE-4682",
    "title": "Reduce wasted bytes in FST due to array arcs",
    "details": {
        "components": [
            "core/FSTs"
        ],
        "fix_versions": [],
        "affect_versions": "None",
        "priority": "Minor",
        "labels": "",
        "type": "Improvement",
        "resolution": "Unresolved",
        "status": "Open"
    },
    "description": "When a node is close to the root, or it has many outgoing arcs, the FST writes the arcs as an array (each arc gets N bytes), so we can e.g. bin search on lookup.\n\nThe problem is N is set to the max(numBytesPerArc), so if you have an outlier arc e.g. with a big output, you can waste many bytes for all the other arcs that didn't need so many bytes.\n\nI generated Kuromoji's FST and found it has 271187 wasted bytes vs total size 1535612 = ~18% wasted.\n\nIt would be nice to reduce this.\n\nOne thing we could do without packing is: in addNode, if we detect that number of wasted bytes is above some threshold, then don't do the expansion.\n\nAnother thing, if we are packing: we could record stats in the first pass about which nodes wasted the most, and then in the second pass (paack) we could set the threshold based on the top X% nodes that waste ...\n\nAnother idea is maybe to deref large outputs, so that the numBytesPerArc is more uniform ...",
    "attachments": {
        "fstByteStats.txt": "https://issues.apache.org/jira/secure/attachment/12567435/fstByteStats.txt",
        "kuromoji.wasted.bytes.txt": "https://issues.apache.org/jira/secure/attachment/12564570/kuromoji.wasted.bytes.txt",
        "LUCENE-4682.patch": "https://issues.apache.org/jira/secure/attachment/12564592/LUCENE-4682.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2013-01-12T14:35:59+0000",
            "content": "A couple more ideas:\n\n\n\tSince the root arc is [usually?] cached ... we [usually] shouldn't make the root node into an array?\n\n\n\n\n\tThe building process sometimes has freedom in where the outputs are pushed ... so in theory we could push the outputs forwards if it would mean fewer wasted bytes on the prior node ... this would be a tricky optimization problem I think.\n\n ",
            "author": "Michael McCandless",
            "id": "comment-13551932"
        },
        {
            "date": "2013-01-12T14:43:38+0000",
            "content": "Maybe we should just tighten up the FST thresholds for when we make an array arc:\n\n  /**\n   * @see #shouldExpand(UnCompiledNode)\n   */\n  final static int FIXED_ARRAY_SHALLOW_DISTANCE = 3; // 0 => only root node.\n\n  /**\n   * @see #shouldExpand(UnCompiledNode)\n   */\n  final static int FIXED_ARRAY_NUM_ARCS_SHALLOW = 5;\n\n  /**\n   * @see #shouldExpand(UnCompiledNode)\n   */\n  final static int FIXED_ARRAY_NUM_ARCS_DEEP = 10;\n\n\n\nWhen I print out the waste, it's generally the smaller nodes that have higher proportional waste:\n\n     [java] waste: 44 numArcs=16 perArc=2.75\n     [java] waste: 20 numArcs=11 perArc=1.8181819\n     [java] waste: 13 numArcs=5 perArc=2.6\n     [java] waste: 20 numArcs=12 perArc=1.6666666\n     [java] waste: 60 numArcs=20 perArc=3.0\n     [java] waste: 0 numArcs=5 perArc=0.0\n     [java] waste: 48 numArcs=15 perArc=3.2\n     [java] waste: 16 numArcs=5 perArc=3.2\n     [java] waste: 20 numArcs=6 perArc=3.3333333\n     [java] waste: 8 numArcs=6 perArc=1.3333334\n     [java] waste: 24 numArcs=8 perArc=3.0\n     [java] waste: 32 numArcs=9 perArc=3.5555556\n     [java] waste: 17 numArcs=7 perArc=2.4285715\n     [java] waste: 13 numArcs=5 perArc=2.6\n     [java] waste: 17 numArcs=6 perArc=2.8333333\n     [java] waste: 28 numArcs=8 perArc=3.5\n     [java] waste: 20 numArcs=16 perArc=1.25\n     [java] waste: 44 numArcs=15 perArc=2.9333334\n     [java] waste: 28 numArcs=13 perArc=2.1538463\n     [java] waste: 28 numArcs=15 perArc=1.8666667\n\n ",
            "author": "Michael McCandless",
            "id": "comment-13551934"
        },
        {
            "date": "2013-01-12T14:56:21+0000",
            "content": "Shows the wasted bytes ... one line per node whose arcs were turned into an array, sorted by net bytes wasted. ",
            "author": "Michael McCandless",
            "id": "comment-13551936"
        },
        {
            "date": "2013-01-12T15:01:16+0000",
            "content": "As an experiment i turned off array arcs for kuromoji in my trunk checkout:\n\nFST\nbefore: [java]   53645 nodes, 253185 arcs, 1535612 bytes...   done\nafter:  [java]   53645 nodes, 253185 arcs, 1228816 bytes...   done\n\nJAR\nbefore: rw-rw-r-  1 rmuir rmuir 4581420 Jan 12 09:56 lucene-analyzers-kuromoji-4.1-SNAPSHOT.jar\nafter:  rw-rw-r- 1 rmuir rmuir  4306792 Jan 12 09:56 lucene-analyzers-kuromoji-5.0-SNAPSHOT.jar ",
            "author": "Robert Muir",
            "id": "comment-13551938"
        },
        {
            "date": "2013-01-12T15:02:54+0000",
            "content": "Even more than the 271,187 I measured (20% smaller FST), I think because the FST is now smaller we use fewer bytes writing the delta-coded node addresses ... ",
            "author": "Michael McCandless",
            "id": "comment-13551939"
        },
        {
            "date": "2013-01-12T15:16:46+0000",
            "content": "in the fixedArray case:\n\n// write a \"false\" first arc:\nwriter.writeByte(ARCS_AS_FIXED_ARRAY);\nwriter.writeVInt(nodeIn.numArcs);\n// placeholder -- we'll come back and write the number\n// of bytes per arc (int) here:\n// TODO: we could make this a vInt instead\nwriter.writeInt(0);\nfixedArrayStart = writer.getPosition();\n\n\n\nI think we should actually make that TODO line a writeByte.\n\nIf it turns out the max arcSize is > 255 i think we should just not encode as array arcs (just save our position before we write ARCS_AS_FIXED_ARRAY, rewind to that, and encode normally)\n\nThis would reduce the overhead of array-arcs, but also maybe prevent some worst cases causing waste as a side effect. ",
            "author": "Robert Muir",
            "id": "comment-13551940"
        },
        {
            "date": "2013-01-12T15:40:34+0000",
            "content": "Even more than the 271,187 I measured (20% smaller FST), I think because the FST is now smaller we use fewer bytes writing the delta-coded node addresses \n\nYes, these things are all tightly coupled.\n\nDawid ",
            "author": "Dawid Weiss",
            "id": "comment-13551944"
        },
        {
            "date": "2013-01-12T16:18:37+0000",
            "content": "Another datapoint: the FreeDB suggester (tool in luceneutil to create/test it) is 1.05 GB FST, and has 87.5 MB wasted bytes (~8%). ",
            "author": "Michael McCandless",
            "id": "comment-13551950"
        },
        {
            "date": "2013-01-12T20:47:38+0000",
            "content": "Mike can you try this patch on your corpus?\n\nIt cuts us over to vint for the maxBytesPerArc (saving 3 bytes for the unpacked case), and adds an \"acceptable overhead\" for array arcs (currently 1.25).\n\nFor the kuromoji packed case, this seems to solve the waste:\n\n     [java]   53645 nodes, 253185 arcs, 1309077 bytes...   done ",
            "author": "Robert Muir",
            "id": "comment-13552054"
        },
        {
            "date": "2013-01-12T21:03:09+0000",
            "content": "+1\n\nThis is much cleaner (write header in the end).\n\nI built the AnalyzingSuggester for FreeDB: trunk is 1.046 GB and with patch it's 0.917 GB = ~9% smaller! ",
            "author": "Michael McCandless",
            "id": "comment-13552057"
        },
        {
            "date": "2013-01-12T21:07:34+0000",
            "content": "I can cleanup+commit the patch with the heuristic commented out (so we still get the cutover to vint, which i think is an obvious win?)\n\nThis way we can benchmark and make sure the heuristic is set appropriately/doesnt hurt performance? ",
            "author": "Robert Muir",
            "id": "comment-13552061"
        },
        {
            "date": "2013-01-12T21:12:04+0000",
            "content": "+1 ",
            "author": "Michael McCandless",
            "id": "comment-13552063"
        },
        {
            "date": "2013-01-12T21:14:55+0000",
            "content": "+1. Nice. ",
            "author": "Dawid Weiss",
            "id": "comment-13552065"
        },
        {
            "date": "2013-01-12T21:20:28+0000",
            "content": "+1 ",
            "author": "Uwe Schindler",
            "id": "comment-13552067"
        },
        {
            "date": "2013-01-12T21:32:47+0000",
            "content": "ok i committed the vInt for maxBytesPerArc, but left out the heuristic (so we still have the waste!!!)\n\nHere's the comment i added:\n\n    // TODO: try to avoid wasteful cases: disable doFixedArray in that case\n    /* \n     * \n     * LUCENE-4682: what is a fair heuristic here?\n     * It could involve some of these:\n     * 1. how \"busy\" the node is: nodeIn.inputCount relative to frontier[0].inputCount?\n     * 2. how much binSearch saves over scan: nodeIn.numArcs\n     * 3. waste: numBytes vs numBytesExpanded\n     * \n     * the one below just looks at #3\n    if (doFixedArray) {\n      // rough heuristic: make this 1.25 \"waste factor\" a parameter to the phd ctor????\n      int numBytes = lastArcStart - startAddress;\n      int numBytesExpanded = maxBytesPerArc * nodeIn.numArcs;\n      if (numBytesExpanded > numBytes*1.25) {\n        doFixedArray = false;\n      }\n    }\n    */\n\n\n\nI think it would just be best to do some performance benchmarks and figure this out.\nI know all the kuromoji waste is at node.depth=1 exactly.\n\nAlso I indexed all of geonames with this heuristic and it barely changed the FST size:\n\ntrunk\nFST: 45296685\npackedFST: 39083451\nvint maxBytesPerArc:\nFST: 45052386\npackedFST: 39083451\nvint maxBytesPerArc+heuristic:\nFST: 44988400\npackedFST: 39029108\n\nSo the waste and heuristic doesn't affect all FSTs, only certain ones. ",
            "author": "Robert Muir",
            "id": "comment-13552071"
        },
        {
            "date": "2013-01-12T21:34:30+0000",
            "content": "[trunk commit] Robert Muir\nhttp://svn.apache.org/viewvc?view=revision&revision=1432522\n\nLUCENE-4682: vInt-encode maxBytesPerArc ",
            "author": "Commit Tag Bot",
            "id": "comment-13552072"
        },
        {
            "date": "2013-01-12T21:48:57+0000",
            "content": "Another simple idea: instead of boolean allowArrayArcs we just make this a float: acceptableArrayArcOverhead (or maybe a better name).\n\nyou would pass 0 to disable array arcs completely (and we'd internally still have our boolean allowArrayArcs and not waste \ntime computing stuff if this is actually <= 0) ",
            "author": "Robert Muir",
            "id": "comment-13552075"
        },
        {
            "date": "2013-01-13T12:18:57+0000",
            "content": "OK I ran several performance tests, comparing trunk (lots of waste),\nthe \"up to 25% waste\", and 0 waste (no array arcs).\n\nFirst, I tested luceneutil on all of English Wikipedia, on an optimized index:\n\nBase = trunk (lots of waste), comp = up to 25% waste:\n\n\n                    Task    QPS base      StdDev    QPS comp      StdDev                Pct diff\n                 Respell      167.37      (3.3%)      128.36      (3.2%)  -23.3% ( -28% -  -17%)\n                  Fuzzy2       83.54      (8.0%)       74.17      (7.2%)  -11.2% ( -24% -    4%)\n                PKLookup      359.62      (2.9%)      346.88      (4.5%)   -3.5% ( -10% -    4%)\n                Wildcard       28.48      (4.3%)       28.25      (3.9%)   -0.8% (  -8% -    7%)\n                  Fuzzy1       82.77      (7.1%)       82.36      (7.7%)   -0.5% ( -14% -   15%)\n        HighSloppyPhrase        0.78      (4.6%)        0.78      (4.5%)   -0.4% (  -9% -    9%)\n                  IntNRQ        3.38      (8.1%)        3.37      (8.1%)   -0.2% ( -15% -   17%)\n         MedSloppyPhrase       28.13      (2.4%)       28.13      (2.4%)   -0.0% (  -4% -    4%)\n         LowSloppyPhrase       25.10      (1.8%)       25.11      (1.8%)    0.0% (  -3% -    3%)\n                 Prefix3       18.40      (4.8%)       18.41      (5.3%)    0.1% (  -9% -   10%)\n                 MedTerm       65.42     (18.2%)       65.46     (17.7%)    0.1% ( -30% -   43%)\n                 LowTerm      316.34      (6.9%)      317.45      (7.1%)    0.4% ( -12% -   15%)\n               LowPhrase       23.30      (2.1%)       23.39      (1.8%)    0.4% (  -3% -    4%)\n                HighTerm       52.11     (18.6%)       52.33     (18.5%)    0.4% ( -30% -   46%)\n               OrHighMed       25.65      (6.7%)       25.76      (7.2%)    0.4% ( -12% -   15%)\n             AndHighHigh       19.42      (1.8%)       19.52      (2.0%)    0.5% (  -3% -    4%)\n               OrHighLow       24.19      (7.1%)       24.36      (7.4%)    0.7% ( -12% -   16%)\n              OrHighHigh       14.32      (6.6%)       14.45      (7.3%)    0.9% ( -12% -   15%)\n            HighSpanNear        3.30      (3.9%)        3.33      (3.1%)    0.9% (  -5% -    8%)\n             LowSpanNear        8.94      (4.3%)        9.04      (3.4%)    1.1% (  -6% -    9%)\n              AndHighMed       78.66      (1.6%)       79.82      (1.4%)    1.5% (  -1% -    4%)\n             MedSpanNear       30.45      (3.1%)       30.91      (2.8%)    1.5% (  -4% -    7%)\n               MedPhrase      130.74      (5.8%)      133.03      (5.9%)    1.8% (  -9% -   14%)\n              AndHighLow      571.07      (3.5%)      582.83      (2.8%)    2.1% (  -4% -    8%)\n              HighPhrase       11.62      (6.1%)       11.88      (6.4%)    2.2% (  -9% -   15%)\n\n\n\ntrunk .tip file was 23928963 and comp was 17125654 bytes (~28% smaller!).\n\nThen, base=trunk, comp=0 waste (no array arcs):\n\n\n                    Task    QPS base      StdDev    QPS comp      StdDev                Pct diff\n                PKLookup      359.26      (2.3%)      152.91      (5.3%)  -57.4% ( -63% -  -51%)\n                 Respell      168.82      (3.4%)      128.85      (2.2%)  -23.7% ( -28% -  -18%)\n                  Fuzzy2       85.59      (8.2%)       75.03      (6.6%)  -12.3% ( -25% -    2%)\n                 LowTerm      331.01      (7.9%)      324.30      (7.2%)   -2.0% ( -15% -   14%)\n                HighTerm       54.75     (19.2%)       54.00     (19.2%)   -1.4% ( -33% -   45%)\n                 MedTerm       68.68     (18.5%)       68.04     (19.0%)   -0.9% ( -32% -   44%)\n              AndHighMed       80.50      (1.4%)       79.78      (1.4%)   -0.9% (  -3% -    1%)\n                Wildcard       29.13      (4.5%)       28.89      (4.0%)   -0.8% (  -8% -    8%)\n               LowPhrase       23.88      (2.3%)       23.69      (1.5%)   -0.8% (  -4% -    3%)\n              AndHighLow      584.30      (2.9%)      582.17      (2.9%)   -0.4% (  -6% -    5%)\n                  Fuzzy1       83.84      (6.9%)       83.62      (6.7%)   -0.3% ( -12% -   14%)\n             AndHighHigh       19.88      (1.8%)       19.84      (1.5%)   -0.2% (  -3% -    3%)\n         LowSloppyPhrase       25.61      (1.9%)       25.56      (2.0%)   -0.2% (  -4% -    3%)\n             LowSpanNear        9.20      (3.6%)        9.20      (3.9%)    0.0% (  -7% -    7%)\n             MedSpanNear       31.32      (2.7%)       31.36      (2.9%)    0.1% (  -5% -    5%)\n         MedSloppyPhrase       28.67      (2.3%)       28.73      (2.2%)    0.2% (  -4% -    4%)\n                 Prefix3       18.83      (4.9%)       18.88      (5.4%)    0.3% (  -9% -   11%)\n              OrHighHigh       14.71      (7.5%)       14.76      (8.2%)    0.3% ( -14% -   17%)\n            HighSpanNear        3.39      (3.0%)        3.40      (2.9%)    0.5% (  -5% -    6%)\n               OrHighMed       26.28      (7.3%)       26.47      (8.1%)    0.7% ( -13% -   17%)\n                  IntNRQ        3.44      (8.6%)        3.47      (9.3%)    0.9% ( -15% -   20%)\n               OrHighLow       24.69      (7.3%)       24.97      (8.3%)    1.1% ( -13% -   18%)\n        HighSloppyPhrase        0.80      (4.8%)        0.81      (4.7%)    1.3% (  -7% -   11%)\n              HighPhrase       11.89      (6.1%)       12.20      (7.4%)    2.6% ( -10% -   17%)\n               MedPhrase      134.04      (5.5%)      138.07      (6.4%)    3.0% (  -8% -   15%)\n\n\n\ncomp .tip file was 16806594 (just a bit smaller than \"up to 25% waste\").\n\nCurious how PK was barely affected by the \"up to 25%\", but heavily\naffected by the \"0 waste\", and how Respell/Fuzzy2 lost perf going to\n\"up to 25% waste\" and then didn't lose much going to \"0 waste\".  I\nsuspect PK will be sensitive to the key structure (luceneutil uses\nbase 36 keys)...\n\n\nNext I tested Kuromoji, just tokenizing first 100K docs from jawiki.\n\n\n\ttrunk (lots of waste): TokenInfoFST was 1535643 bytes, tokenizing 100K docs took 163.3 sec\n\tup to 25% waste: TokenInfoFST was 1309108 bytes, tokenizing 100K docs took 215.3 sec\n\t0 waste: TokenInfoFST was 1228847 bytes, tokenizing 100K docs took 218.0 sec\n\n\n\nLooks like Kuromoji sees good gains from the > 25% waste arcs... but\nto keep this in perspective, in a \"real\" app, you index after\ntokenizing and that indexing time will dwarf the tokenization time.\nBut then on the flip side we are \"only\" talking about ~221 KB ...\n\nFinally, I tested building a no-outputs FST for all Wikipedia English\nterms (9.8 M terms):\n\n\n\ttrunk (lots of waste): 59267794 bytes, 566 nsec per lookup\n\tup to 25% waste: 58509011 bytes, 567 nsec per lookup\n\t0 waste: 56413148 bytes, 1808 nsec per lookup\n\n\n\nFor this case it looks like you get all the benefit allowing only 25%\nwaste (though, most of the byte increase also?). ",
            "author": "Michael McCandless",
            "id": "comment-13552184"
        },
        {
            "date": "2013-01-13T12:56:15+0000",
            "content": "Well, i think actually we shouldnt allow 25% waste. maybe only something like 10%.\n\nIn these waste-cases, doing array-arcs is a really inefficient/overkill way to just \ngain binary search... I think if it would be too wasteful (e.g. exceed 10%), we should \njust insert some skip points or something.\n ",
            "author": "Robert Muir",
            "id": "comment-13552189"
        },
        {
            "date": "2013-01-13T15:37:09+0000",
            "content": "I think if it would be too wasteful (e.g. exceed 10%), we should \njust insert some skip points or something\n\nI had the same thought. We only go with the extremes \u2013 either a linked list (essentially) or an array. A tree structure would be in between and would give logN searches and optimal space utilization. Obviously it'd also complicate the code.  ",
            "author": "Dawid Weiss",
            "id": "comment-13552218"
        },
        {
            "date": "2013-01-14T01:13:34+0000",
            "content": "I agree: about the code complication, its hard to try different things currently \n\nI think this is due to the reversing and BIT_TARGET_NEXT? does this really save us more\nthan the bloat of not being able to delta-encode 'target' ?\n\nThe packed case dereferences to nodeID and looks that up from packed ints right? But \nI wonder about that too: is the cost of this additional indirection in space worth it\nversus just delta-encoding with vint? ",
            "author": "Robert Muir",
            "id": "comment-13552374"
        },
        {
            "date": "2013-01-14T08:16:40+0000",
            "content": "Yeah, there are many ideas layered on top of each other and it's gotten beyond the point of being easy to comprehend.\n\nAs for the \"next\" bit \u2013 in any implementation I've seen this leads to significant reduction in automaton size. But I'm not saying it's the optimal way to do it, perhaps there are other encoding options that would reach similar compression levels without the added complexity. ",
            "author": "Dawid Weiss",
            "id": "comment-13552497"
        },
        {
            "date": "2013-01-14T12:39:27+0000",
            "content": "I tried removing NEXT opto in building the all-English-Wikipedia-terms FST and it was a big hit:\n\n\n\tWith NEXT: 59267794 bytes\n\n\n\n\n\tWithout NEXT: 82543993 bytes\n\n\n\nSo FST would be ~39% larger if we remove NEXT ... however lookup sped up from 726 ns per lookup to 636 ns.  But: we could get this speedup today, if we just fixed setting of a NEXT arc's target to be lazy instead.  Today it's very costly for non-array arcs because we scan to the end of all nodes to set the target, even if the caller isn't going to use it, which is really ridiculous.\n\nI also \"tested\" delta-coding the arc target instead of the abs vInt we have today ... it wasn't a real test, instead I just measured how many bytes the vInt delta would be vs how many bytes the vInt abs it today, and the results were disappointing:\n\n\n\tAbs vInt (what we do today): 26681349 bytes\n\n\n\n\n\tDelta vInt: 25479316 bytes\n\n\n\nWhich is surprising ... I guess we don't see much \"locality\" for the nodes ... or, eg the common suffixes freeze early on and then lots of future nodes refer to them.\n\nMaybe, we can find a way to do NEXT without the confusing per-node-reverse-bytes? ",
            "author": "Michael McCandless",
            "id": "comment-13552614"
        },
        {
            "date": "2013-01-14T12:43:29+0000",
            "content": "\nSo FST would be ~39% larger if we remove NEXT\n\nBut according to your notes above, we have 28% waste for this (with a long output).\nAre we making the right tradeoff?\n\n\nMaybe, we can find a way to do NEXT without the confusing per-node-reverse-bytes?\n\nOr, not do it at all if we cant figure it out? The reversing holds back other improvements so\nbenchmarking it by itself could be misleading. ",
            "author": "Robert Muir",
            "id": "comment-13552619"
        },
        {
            "date": "2013-01-14T12:50:35+0000",
            "content": "I also \"tested\" delta-coding the arc target instead of the abs vInt we have today ...\n\nI did such experiments when I was working on that paper. Remember \u2013 you don't publish negative results, unfortunately. Obviously I didn't try everything but: 1) NEXT was important, 2) the structure of the FST doesn't yield to easy local deltas; it's not easily separable and pointers typically jump all over.\n\nWhich is surprising ... I guess we don't see much \"locality\" for the nodes ... or, eg the common suffixes freeze early on and then lots of future nodes refer to them.\n\nNot really that surprising \u2013 you encode common suffixes after all so most of them will appear in a properly sized sample. This is actually why the strategy of moving nodes around works too \u2013 you move those that are super frequent but they'll most likely be reordered at the \"top\" suffix frequencies of the automaton anyway. ",
            "author": "Dawid Weiss",
            "id": "comment-13552624"
        },
        {
            "date": "2013-01-14T13:00:43+0000",
            "content": "\nSo FST would be ~39% larger if we remove NEXT\n\nBut according to your notes above, we have 28% waste for this (with a long output).\nAre we making the right tradeoff?\n\nWait: the 28% waste comes from the array arcs (unrelated to NEXT?).  To fix that I think we should use a skip list?  Surely the bytes required to encode the skip list are less than our waste today.\n\n\nMaybe, we can find a way to do NEXT without the confusing per-node-reverse-bytes?\n\nOr, not do it at all if we cant figure it out? The reversing holds back other improvements so\nbenchmarking it by itself could be misleading.\n\nI don't think we should drop NEXT unless we have some alternative?  39% increase is size is non-trivial!\n\nI know reversing held back delta-code of the node target, but, that looks like it won't gain much.  What else is it holding back? ",
            "author": "Michael McCandless",
            "id": "comment-13552633"
        },
        {
            "date": "2013-01-14T13:12:45+0000",
            "content": "\nWait: the 28% waste comes from the array arcs (unrelated to NEXT?). To fix that I think we should use a skip list? Surely the bytes required to encode the skip list are less than our waste today.\n\n\nI know reversing held back delta-code of the node target, but, that looks like it won't gain much. What else is it holding back?\n\nI mean in general NEXT/reversing adds more complexity here which makes it harder to try different things? Like a big doberman and BEWARE sign scaring off developers \n\nIts a big part of what sent me over the edge trying to refactor FST to have a store abstraction (LUCENE-4593). But fortunately you did that anyway...\n\nIt would be really really really good for FSTs long term to do things like remove reversing, remove packed (fold these optos or at least most of them in by default), etc. ",
            "author": "Robert Muir",
            "id": "comment-13552641"
        },
        {
            "date": "2013-01-14T13:35:50+0000",
            "content": "I mean in general NEXT/reversing adds more complexity here which makes it harder to try different things? Like a big doberman and BEWARE sign scaring off developers \n\nLOL \n\nBut yeah I agree.\n\nIts a big part of what sent me over the edge trying to refactor FST to have a store abstraction (LUCENE-4593). But fortunately you did that anyway...\n\nRight but it's not good if bus factor is 1 ... it's effectively dead code when that happens.\n\nIt would be really really really good for FSTs long term to do things like remove reversing, remove packed (fold these optos or at least most of them in by default), etc.\n\n+1, except that NEXT buys us a much smaller FST now.  We can't just drop it ... we need some way to simplify it (eg somehow stop reversing). ",
            "author": "Michael McCandless",
            "id": "comment-13552653"
        },
        {
            "date": "2013-01-18T14:12:13+0000",
            "content": "[branch_4x commit] Robert Muir\nhttp://svn.apache.org/viewvc?view=revision&revision=1435141\n\nLUCENE-4677, LUCENE-4682, LUCENE-4678, LUCENE-3298: Merged /lucene/dev/trunk:r1432459,1432466,1432472,1432474,1432522,1432646,1433026,1433109 ",
            "author": "Commit Tag Bot",
            "id": "comment-13557229"
        },
        {
            "date": "2013-01-31T05:02:34+0000",
            "content": "There's a pretty interesting approach here (http://www.aclweb.org/anthology/W/W09/W09-1505.pdf)\nthat might be a good tradeoff, so we aren't stuck with a black and white situation (array arcs or not).\n\ninstead we could (in theory) waste a few bits/mark/escape bytes in a similar way so we can do \nan \"approximate binary search\"... ",
            "author": "Robert Muir",
            "id": "comment-13567367"
        },
        {
            "date": "2013-01-31T07:50:40+0000",
            "content": "Yep, it's similar to what I was suggesting \u2013 instead of expanding the subnodes into a full array encode a tree-like structure that would allow binary-searching right away. They still use a binary search over this packed representation; I'd just encode the binary tree directly somehow. I guess it's a matter of checking which will be faster/more efficient. (can't devote any time for it now, sorry). ",
            "author": "Dawid Weiss",
            "id": "comment-13567434"
        },
        {
            "date": "2013-01-31T21:08:34+0000",
            "content": "I was curious about the number of times each byte value occurs in an FST ... because we could pick an uncommon one and use it as periodic marker (eg ever 5 arcs or something) to enable binary searching.\n\nSo I ran this on two FSTs ... first one is all Wikipedia terms and second one is FreeDB suggester (has some non-ascii song titles...).\n\nNot sure exactly what to conclude since a byte's frequency is FST dependent ... ",
            "author": "Michael McCandless",
            "id": "comment-13568101"
        },
        {
            "date": "2013-01-31T21:12:36+0000",
            "content": "\nNot sure exactly what to conclude since a byte's frequency is FST dependent ...\n\nSo we can just add it as another param to the massive FST.Builder ctor! ",
            "author": "Robert Muir",
            "id": "comment-13568108"
        }
    ]
}