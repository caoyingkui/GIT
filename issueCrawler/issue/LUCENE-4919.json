{
    "id": "LUCENE-4919",
    "title": "IntsRef, BytesRef and CharsRef return incorrect hashcode when filled with 0",
    "details": {
        "components": [
            "core/other"
        ],
        "fix_versions": [
            "4.3"
        ],
        "affect_versions": "4.2",
        "priority": "Major",
        "labels": "",
        "type": "Bug",
        "resolution": "Not A Problem",
        "status": "Closed"
    },
    "description": "IntsRef, BytesRef and CharsRef implementation do not follow the java Arrays.hashCode implementation, and return incorrect hashcode when filled with 0. \nFor example, an IntsRef with { 0 } will return the same hashcode than an IntsRef with { 0, 0 }.",
    "attachments": {
        "LUCENE-4919.patch": "https://issues.apache.org/jira/secure/attachment/12577773/LUCENE-4919.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2013-04-09T10:18:47+0000",
            "content": "Here is a patch for IntsRef, BytesRef and CharsRef including unit tests. The new hashcode implementation is identical to the one found in Arrays.hashCode. ",
            "author": "Renaud Delbru",
            "id": "comment-13626447"
        },
        {
            "date": "2013-04-09T10:23:24+0000",
            "content": "The hashcode here is not arbitrary, as mentioned in the javadocs:\n\n\n  /** Calculates the hash code as required by TermsHash during indexing.\n   * <p>It is defined as:\n   * <pre class=\"prettyprint\">\n   *  int hash = 0;\n   *  for (int i = offset; i &lt; offset + length; i++) {\n   *    hash = 31*hash + bytes[i];\n   *  }\n   * </pre>\n   */\n\n\n\nThere is code in BytesRefHash that relies upon this. ",
            "author": "Robert Muir",
            "id": "comment-13626450"
        },
        {
            "date": "2013-04-09T10:30:02+0000",
            "content": "This patch also doesn't fix code in UnicodeUtil that relies upon this.\n\nI think i'm against the change: the whole issue is wrong to me as the hashcode does what it documents it should do already, and a lot of things rely upon the current function.\n\nI don't understand why the javadocs for BytesRef.hashCode make it seem like it should be doing something else. ",
            "author": "Robert Muir",
            "id": "comment-13626453"
        },
        {
            "date": "2013-04-09T10:30:35+0000",
            "content": "Hi Robert,\n\nFrom my understanding, this applies only for BytesRef (even if this behavior sounds dangerous to me). However, why is IntsRef and CharsRef following the same behavior ? ",
            "author": "Renaud Delbru",
            "id": "comment-13626454"
        },
        {
            "date": "2013-04-09T10:41:19+0000",
            "content": "I see that BytesRef is used a bit everywhere in various contexts, contexts which are different from the TermsHash context. This hashcode behavior might cause unexpected problems, as I am sure most of the users of BytesRef are unaware of this particular behavior. ",
            "author": "Renaud Delbru",
            "id": "comment-13626458"
        },
        {
            "date": "2013-04-09T10:44:54+0000",
            "content": "The current hashcode seems to correspond with String.hashCode.\n\nI'm not against this change on some theoretical basis, only mentioning that to me there is no bug (it does exactly what it says it should do), and that changing it without being thorough will only create bugs since things rely upon this.\n\nAny patch to change the hashcode needs to update all these additional things, such as methods in UnicodeUtil, BytesRefHash collision probing, javadocs in TermToBytesRefAttribute, and anything else that relies upon this: otherwise it only causes more harm than good. ",
            "author": "Robert Muir",
            "id": "comment-13626461"
        },
        {
            "date": "2013-04-09T10:47:18+0000",
            "content": "I am not getting why this should return the same as Arrays.hashCode, can you elaborate on this a bit? ",
            "author": "Simon Willnauer",
            "id": "comment-13626462"
        },
        {
            "date": "2013-04-09T10:50:12+0000",
            "content": "Ok, I understand Robert. That sounds like a big task. I can try to make a first pass over it in the next days if you think it is worth it (personally I would feel more reassured knowing that the hashcode follows a more common behavior). ",
            "author": "Renaud Delbru",
            "id": "comment-13626471"
        },
        {
            "date": "2013-04-09T10:54:38+0000",
            "content": "I have no opinion: I'm not a hashing guy. I'm just mentioning the change is pretty serious.\n\nAdditionally I'm unhappy the hashcode is part of the API: so I dont think it should be changed in a minor release (e.g. things like TermToBytesRefAttribute expose this as an API requirement). But I think trunk is fine.\n\nOn the other hand I know the current situation has some bad worst-case behavior that users might actually hit (e.g. indexing increasing numerics), but I don't see sure how this patch addresses that. It seems to me that if we want to go thru all the trouble to improve the hashing (which would be a good thing), we should solve that too, maybe involving a totally different hashing scheme like what they did with java (i dont know). ",
            "author": "Robert Muir",
            "id": "comment-13626475"
        },
        {
            "date": "2013-04-09T11:01:35+0000",
            "content": "@Simon: I discovered the issue when using IntsRef. during query processing, I am streaming array of integers using IntsRef. I was relying on the hashCode to compute a unique identifier for the content of a particular IntsRef until I started to see unexpected results in my unit tests. Then I saw that the same behaviour is found in the other *Ref classes. \nI could live without it and bypass the problem by changing my implementation (and computing myself my own hash code). But I thought this behaviour is not very clear for the user, and could be potentially dangerous, and therefore good to share it with you. ",
            "author": "Renaud Delbru",
            "id": "comment-13626477"
        },
        {
            "date": "2013-04-09T11:01:53+0000",
            "content": "This isn't a bug, it's a definition like any other. In general any definition of hash(X), even hash(X) = 42 is also valid (obviously with poor space-distributing properties...). The question which particular hash function to pick and what inputs it should consume (number of elements, values of elements) is kind of difficult \u2013 when you include more elements into computations the distribution for certain inputs may be better but you'll probably loose some performance on the average case. ",
            "author": "Dawid Weiss",
            "id": "comment-13626478"
        },
        {
            "date": "2013-04-09T11:03:43+0000",
            "content": "Maybe a simpler solution would be to clearly state this behavior in all the methods javadoc. ",
            "author": "Renaud Delbru",
            "id": "comment-13626480"
        },
        {
            "date": "2013-04-09T11:07:06+0000",
            "content": "> I was relying on the hashCode to compute a unique identifier for the content of a particular IntsRef\n\nThis is generally an invalid assumption for any hashing function with a limited target function space. Unless you have something that implements minimal perfect hashing but this is typically data-specific (and even precomputed in advance). ",
            "author": "Dawid Weiss",
            "id": "comment-13626481"
        },
        {
            "date": "2013-04-09T11:09:06+0000",
            "content": "Btw. Arrays.hashCode is also not a \"unique\" identifier for the contents of an array so if you're using it this way your code... well, it has a problem.  ",
            "author": "Dawid Weiss",
            "id": "comment-13626483"
        },
        {
            "date": "2013-04-09T11:14:36+0000",
            "content": "I agree with you Dawid, but this particular behaviour increases the chance of getting the same hash for a certain type of inputs. Anyway, I think the general decision is to not change their hashCode behvaiour ;o), I am fine with it. Feel free to close the issue.\nThanks, and sorry for the distraction. ",
            "author": "Renaud Delbru",
            "id": "comment-13626486"
        }
    ]
}