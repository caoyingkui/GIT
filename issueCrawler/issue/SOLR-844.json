{
    "id": "SOLR-844",
    "title": "A SolrServer impl to front-end multiple urls",
    "details": {
        "affect_versions": "1.3",
        "status": "Closed",
        "fix_versions": [
            "1.4"
        ],
        "components": [
            "clients - java"
        ],
        "type": "New Feature",
        "priority": "Major",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "Currently a CommonsHttpSolrServer can talk to only one server. This demands that the user have a LoadBalancer or do the roundrobin on their own. We must have a LBHttpSolrServer which must automatically do a Loadbalancing between multiple hosts. This can be backed by the CommonsHttpSolrServer\n\n\n\nThis can have the following other features\n\n\n\tAutomatic failover\n\tOptionally take in  a file /url containing the the urls of servers so that the server list can be automatically updated  by periodically loading the config\n\tSupport for adding removing servers during runtime\n\tPluggable Loadbalancing mechanism. (round-robin, weighted round-robin, random etc)\n\tPluggable Failover mechanisms",
    "attachments": {
        "SOLR-844.patch": "https://issues.apache.org/jira/secure/attachment/12394934/SOLR-844.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Ian Holsman",
            "id": "comment-12646143",
            "date": "2008-11-10T01:52:26+0000",
            "content": "your opening a can of worms in this one Noble.\n\nFirstly there are about a thousand ways you can handle load balancing already out there on the backend side (both hardware and software). you can achieve what you want today by using the apache webserver and mod_proxy_balancer - http://httpd.apache.org/docs/2.2/mod/mod_proxy_balancer.html\n\n\nSecondly doing it on the client side means you will need to track ALL the clients who use your service. I don't think the URL config thing won't work well in practice.\n\nThirdly load balancing isn't easy. I've had the joy of debugging load balancing errors and outages, and wouldn't want to have to go through that again "
        },
        {
            "author": "Noble Paul",
            "id": "comment-12646165",
            "date": "2008-11-10T04:07:51+0000",
            "content": "Firstly there are about a thousand ways you can handle load balancing already out there on the backend side (both hardware and software)\nYes , But each extra layer introduces its own overhead. (in latency , hardware and maintenance). Moreover we are introducing a single point of failure.\n\n\nThis is similar to a MySql driver providing a feature to connect to multiple servers (maters/slaves) . it does round-robin at the driver side and provide automatic failover. http://dev.mysql.com/doc/refman/5.0/en/connector-j-reference-replication-connection.html\n\nSecondly doing it on the client side means you will need to track ALL the clients who use your service\n\nLet us discuss how best this can be handled. This is just an extension of what we already have , (a thin wrapper).  "
        },
        {
            "author": "Otis Gospodnetic",
            "id": "comment-12646362",
            "date": "2008-11-10T21:03:44+0000",
            "content": "I had a similar reaction as Ian.\nIf we decide we really need this, I wonder if it can be made a contrib instead of living in the core. "
        },
        {
            "author": "Noble Paul",
            "id": "comment-12646463",
            "date": "2008-11-11T04:06:59+0000",
            "content": "no probs.\nI'm sure that we do not use that internally , but there may be users who would find it useful. (one man's meat is another man's poison)\n\nAnother use case is distributed search. Do we really want to have an extra hop (Loadbalancer) for a shard to communicate to other shards? That is a few dozen requests per client request . How many LoadBalancers would we need to handle such load?\n\nIs it big enough to merit a contrib package for itself?. Maybe. \n\n\n "
        },
        {
            "author": "Noble Paul",
            "id": "comment-12651742",
            "date": "2008-11-29T18:51:11+0000",
            "content": "A simple round-robin based implementtaion. Keeps two lists of servers live and dead. If a request to a server fails it is added to the list of dead servers.\n\nPeriodically (once in a minute) the dead servers are pinged to find if they are up again. The ping is done in a thread which makes a normal request. A thread checks only one server\n\nNeeds another ConfigLBHttpSolrServer which can be driven from a config file (local/http) "
        },
        {
            "author": "Noble Paul",
            "id": "comment-12651785",
            "date": "2008-11-30T04:51:35+0000",
            "content": "there were a few bugs "
        },
        {
            "author": "Lance Norskog",
            "id": "comment-12660656",
            "date": "2009-01-05T01:40:27+0000",
            "content": "Concur with dubious reaction. However, what you mention about multiple hops is a valid point.\n\nThe distributed searcher could have an option that returns the shard set. A Solr client library could run the distributed search/merge and return that to its calling app.  A similar list of active \"all-in-one\" servers could also be handed back to this mythical client library. \n\nAnyway, here's a use case for load balancing: we wanted to take a server out of the load balancer, rewarm its caches, then put it back in the balancer. "
        },
        {
            "author": "Noble Paul",
            "id": "comment-12660661",
            "date": "2009-01-05T04:03:22+0000",
            "content": "The distributed searcher could have an option that returns the shard set. A Solr client library could run the distributed search/merge and return that to its calling app.\n\nDo you mean to say that the client library must handle the distributed search? \nThat may not be a good idea.\n\nAnyway, here's a use case for load balancing...\nIs it a point against this or for this? "
        },
        {
            "author": "Noble Paul",
            "id": "comment-12664828",
            "date": "2009-01-17T12:44:35+0000",
            "content": "with a test case and a few fixes "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12666255",
            "date": "2009-01-22T19:19:17+0000",
            "content": "Guys, are there any objections in committing this to trunk? If not, I'd like to go over the patch and commit it in a few days. I don't think this needs to go to a separate contrib since it is such a small piece of code and doesn't have any extra dependencies. "
        },
        {
            "author": "Otis Gospodnetic",
            "id": "comment-12666296",
            "date": "2009-01-22T21:12:29+0000",
            "content": "I'm not sure there is a clear consensus about this functionality being a good thing (also 0 votes).  Perhaps we can get more people's opinions? "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12666409",
            "date": "2009-01-23T03:45:53+0000",
            "content": "Walter Underwood on solr-dev:\nThis would be useful if there was search-specific balancing, like always send the same query back to the same server. That can make your cache far more effective.\n\nThat is an interesting thought. Right now Solrj does not have the means to construct the Query/Filter objects which are used as the key for the Solr caches. Let us try to figure out if/how it can be implemented.\n\nI'm not sure there is a clear consensus about this functionality being a good thing (also 0 votes). Perhaps we can get more people's opinions?\n\nYes Otis. That is exactly what I wanted to do with my comment \n\nI guess most people think that this is a solved problem and I agree. Solr has always required users to have load balancers and I guess our users have come to accept it. But if you look at the new distributed systems being developed (Katta/Bailey/CouchDB/Voldemort, etc.), almost none of them assume an external load balancer or fail over system in their design. If they do, external systems are made optional (Voldemort). Right now we force people to use and maintain an external system if they have a Solr master/slave architecture. Apache and mod_proxy_balancer are great but have a higher latency than hardware based load balancers and these are not cheap.\n\nThe current patch is very simple. However, better ways to handle configuration and load balancing can be added. I think this can be a good starting point for the Solr 2.0 proposals. Unfortunately, very few of us have time to implement all of the proposals in a big bang way. But if we focus on one issue at a time, we will get somewhere close sooner. This might not be the code which ends up in Solr 2.0 but I think it can provide a good transition path.\n\nThoughts? "
        },
        {
            "author": "Noble Paul",
            "id": "comment-12666413",
            "date": "2009-01-23T04:23:30+0000",
            "content": "I'm not sure there is a clear consensus about this functionality being a good thing\n\nThis is not a Solr functionality. This is an external feature. Solr is agnostic about it.\n\nMost of our users use Solr with an external LoadBalancer. It does not mean that that is the best solution always. They do it because that is the only way .We are trying to offer a choice. \n\n\nA very good comparison would be memcached client . It does load balancing at the client side . I have copied some ideas from there too. I have already mentioned the example of mysql.\n\nThe problems with the existing solutions is that there is no automatic failover. This implementation has it. \n\n\n\n "
        },
        {
            "author": "Mark Miller",
            "id": "comment-12666416",
            "date": "2009-01-23T04:41:20+0000",
            "content": "I think your missing Otis' point Noble. He is not dismissing this patch on its technical or useful merits. Hes pointing out that a couple of people have voiced skepticism and no one has voted for the issue. When thats the case, its not normal to put the issue in without more discussion. Which is what is happening, but I don't think your arguments alone should get the code committed. Rather, after you have expressed your arguments, we wait for votes, or more input. A couple people seem like they like the idea as well, but that info has just started coming, so lets let it play out a little before committing.\n\nMy opinion:\n\nMy initial thought was negative as well, for the obvious reasons. However, its such a simple thing (at least for this basic support), improves efficiency a bit, and could be a lot easier for a solr user to setup than a load balancer they don't know. I think I am a +1 myself.\n\nOn the patch: I havn't spent a lot of time looking at it, but I think its best practice to only access shared variables within the lock. For instance, you access isEmpty on a shared variable, then get the lock and access the shared variable. I realize you want to save the lock cost, but if you need the lock, you shouldn't do that.\n\n\n\tMark\n\n "
        },
        {
            "author": "Noble Paul",
            "id": "comment-12666417",
            "date": "2009-01-23T04:51:54+0000",
            "content": "Hi Mark, thanks\n\nI am in no hurry in getting this committed. I am just trying to raise opinions from other committers/users. \n\nFor instance, you access isEmpty on a shared variable, then get the lock and access the shared variable\n\nThe Object in question is a threadsafe object (CopyOnWriteArrayList) so I believe it should not hurt. \n "
        },
        {
            "author": "Mark Miller",
            "id": "comment-12666536",
            "date": "2009-01-23T13:03:38+0000",
            "content": "I am not convinced its right though. If you are using that lock pretty much everywhere anyway, why use a thread safe list? Something doesnt quite jive with me - I'll let others take a look and decide though.  I see that locking is done both with the lock and in one place the synchronize keyword. I think something is off myself. I havn't spent a lot of time, so perhaps it works, but I think a more standard treatment would be better for code maintainability.  "
        },
        {
            "author": "Noble Paul",
            "id": "comment-12666865",
            "date": "2009-01-24T09:30:53+0000",
            "content": "some bugs were fixed (missing lock.unLock()) "
        },
        {
            "author": "Noble Paul",
            "id": "comment-12666866",
            "date": "2009-01-24T09:36:38+0000",
            "content": "If you are using that lock pretty much everywhere anyway, why use a thread safe list?\nThe lock is used to ensure that only one thread does a check for isAlive at any given point in time. So all the variables which are modified during that is threadsafe. "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12668152",
            "date": "2009-01-28T20:38:38+0000",
            "content": "Mark, did you get a chance to look at the new patch?\n\nOverall, I'd like to see some more reactions on the idea/patch. I think it is a good idea and ground work for more advanced functionalities. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-12668155",
            "date": "2009-01-28T20:52:51+0000",
            "content": "I'd like to look at it closer, but I havn't had a chance yet.\n\nOne quick fix needed:     if (size < 1) new SolrServerException(\"No more SolrServers alive\");\n\nMissing the return in front of new.\n\n\n\tMark\n\n "
        },
        {
            "author": "Noble Paul",
            "id": "comment-12668338",
            "date": "2009-01-29T04:42:50+0000",
            "content": "One quick fix needed: if (size < 1) new SolrServerException(\"No more SolrServers alive\");\n\noops. nice catch . It should have been \n\nthrow new SolrServerException(\"No more SolrServers alive\");\n\n\n "
        },
        {
            "author": "Hoss Man",
            "id": "comment-12669808",
            "date": "2009-02-03T00:25:02+0000",
            "content": "i haven't reviewed the technical merits of hte patch, but on the subject of the idea...\n\nIn general i agree with ian/otis: functionality like this could very easily be abused/missued by novice users who may not realize that more robust solutions may be out there and can be just as easy to setup.  That said: any code that does what it's documentation says it does is going to be use to someone.  \n\nmy concern with the patch as written is that it doesn't have any documentation explaining what it does, or what the caveats are to useing it (ie: how it behaves in failure cases, what approach it takes to blanacing load, etc...) so it won't be clear to people when/if it fits their use cases.\n\nThe \"Hits\" class in Lucene-Java is a great example of code whose existence tended to do more harm then good \u2013 it was a simple API that was easy to use, but the implementation had a lot of \"gotchas\" that were hidden behind a black box and were too complicated to document cleanly for novice users; many people who used it ran into performance problems or problemswith closed IndexSearchers and came away with a bad impression of Lucene.  ... we just need to make sure we don't make more mistakes like that with convinienceclasses and \"simple\" APIs for hard problems.\n\nIf the behavior of this class can be documented in a straight forward way (spelling out both success and failure cases) as well as when it doesn't make sense to use it, then i see no reason not to commit.  (I'm assuming of course that the code actually works)\n\nHowever....\n\nI'm curious as to whether or not anyone has done any research into existing java libraries that implement http load balancing.  (I assume someone somewhere has implemented a generic wrapper/plugin for HttpCLient that does this already ... it's just a question of if it's OpenSource with a freindly liscence for us to link against)\n\n "
        },
        {
            "author": "Noble Paul",
            "id": "comment-12669863",
            "date": "2009-02-03T03:42:41+0000",
            "content": "Hoss. Thanks  \n\nIf the behavior of this class can be documented in a straight forward way (spelling out both success and failure cases)...\n\nA wiki page is added here: http://wiki.apache.org/solr/LBHttpSolrServer  "
        },
        {
            "author": "Otis Gospodnetic",
            "id": "comment-12670042",
            "date": "2009-02-03T18:17:02+0000",
            "content": "Good comment from Wunder's made on the ML:\n\nThis would be useful if there was search-specific balancing,\nlike always send the same query back to the same server. That\ncan make your cache far more effective.\n\nwunder "
        },
        {
            "author": "Hoss Man",
            "id": "comment-12670140",
            "date": "2009-02-03T22:11:51+0000",
            "content": "A wiki page is added here: http://wiki.apache.org/solr/LBHttpSolrServer\n\nActually i was referring to a need for javadoc comments in the class since there are none in the current patch. \n\nthe wiki and/or static pages like hte tutorial make sense for features all users need to be aware of, but when we're talking about solrj code that java apps will explicitly compile against there isreally no substitute for good package, class, and method level javadocs. "
        },
        {
            "author": "Noble Paul",
            "id": "comment-12671051",
            "date": "2009-02-06T08:35:27+0000",
            "content": "Same patch with javadocs "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12674498",
            "date": "2009-02-18T07:14:42+0000",
            "content": "Hoss, did you get a chance to see the latest patch? "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12675864",
            "date": "2009-02-23T12:03:54+0000",
            "content": "So what's the verdict on this one? Seems like most concerns were taken care of. Anything else we should do to get this committed? "
        },
        {
            "author": "Hoss Man",
            "id": "comment-12676136",
            "date": "2009-02-24T00:03:49+0000",
            "content": "I still think the javadocs should be beefed up a bit... at a minimum the info from \"When to use this ?\", \"How does the Load Balancing happen ?\", and \"How does it know if a server has come back up ?\" sections of the wiki page Noble made should be in the class level javadocs ... some of the \"How does it know...\" info made it into the javadocs for setAliveCheckInterval, but considering how important that method is there should be a ref to it in the class docs \u2013 and there definitely needs to be some explicit mention of the \"The ping is done not in a separate thread, it is done in a thread which made a normal request.\" fact, i would never have guessed that looking at the public docs in the class.\n\nAnd as I mentioned before: if there are concerns that this class will be misused (and it certainly seems like there are) then it really needs to contain javadocs explaining when it doesn't make sense to use it and some alternative suggestions (if nothing else, a link to wikipedia: http://en.wikipedia.org/wiki/Load_balancing_(computing)) "
        },
        {
            "author": "Noble Paul",
            "id": "comment-12678004",
            "date": "2009-03-02T15:04:53+0000",
            "content": "#implementation changed to do the pings in a separate thread. This keeps the code simple\n\n\tjavadocs added\n\n "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12682947",
            "date": "2009-03-18T07:45:38+0000",
            "content": "Changes\n\n\tJavadoc updated to say about load balancing strategy, which failures mark a server to be a failure, how do they come back up and other alternatives to this class\n\tChanged locking \u2013 all places where the two lists are modified are placed inside a lock, the reads are not locked\n\tIt uses the exception thrown by CommonsHttpSolrServer to detect when to mark server as dead\n\n "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12683809",
            "date": "2009-03-20T09:11:18+0000",
            "content": "Committed revision 756381.\n\nThanks to everybody who contributed! "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12683966",
            "date": "2009-03-20T17:50:06+0000",
            "content": "LBHttpSolrServer had the wrong import of SolrException which was causing compile failures when running tests through ant build file.\n\nCommitted revision 756682. "
        },
        {
            "author": "Noble Paul",
            "id": "comment-12700003",
            "date": "2009-04-17T04:59:51+0000",
            "content": "a bug fix as reported by a user \n\nhttp://markmail.org/thread/bvysveoibqcndj4n "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12700109",
            "date": "2009-04-17T10:05:15+0000",
            "content": "Committed revision 765912. "
        },
        {
            "author": "Jason Falk",
            "id": "comment-12758841",
            "date": "2009-09-23T19:18:16+0000",
            "content": "There seems to be an issue here with the check interval.  The documentation and even the default value assume that the check interval is measured in milliseconds, when in fact the code below has the TimeUnit as seconds.\n\ngetAliveCheckRunner(new WeakReference<LBHttpSolrServer>(this)), this.interval, this.interval, TimeUnit.SECONDS);\n\nSo basically right now the check interval is 60,000 seconds...yikes. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12758864",
            "date": "2009-09-23T20:27:31+0000",
            "content": "Thanks Jason, I just committed a fix for this that changed it to milliseconds. "
        }
    ]
}