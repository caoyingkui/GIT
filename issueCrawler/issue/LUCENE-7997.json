{
    "id": "LUCENE-7997",
    "title": "More sanity testing of similarities",
    "details": {
        "labels": "",
        "priority": "Minor",
        "resolution": "Fixed",
        "affect_versions": "None",
        "status": "Resolved",
        "type": "Task",
        "components": [],
        "fix_versions": [
            "master (8.0)"
        ]
    },
    "description": "LUCENE-7993 is a potential optimization that we could only apply if the similarity is an increasing functions of freq (all other things like DF and length being equal). This sounds like a very reasonable requirement for a similarity, so we should test it in the base similarity test case and maybe move broken similarities to sandbox?",
    "attachments": {
        "LUCENE-7997_wip.patch": "https://issues.apache.org/jira/secure/attachment/12893116/LUCENE-7997_wip.patch",
        "LUCENE-7997.patch": "https://issues.apache.org/jira/secure/attachment/12893847/LUCENE-7997.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "id": "comment-16208515",
            "date": "2017-10-17T22:29:59+0000",
            "content": "Exactly we need a picky base sim test for this (like how BaseTokenStreamTestCase checks various requirements for analyzers). Currently these properties are \"scattered\" across various parts of the code/tests/issues: such as scores not being inf/NaN for some collectors, not being negative, monotonic tf, etc that maxscore requires. Sims that use certain statistics should fallback to other things when term frequencies are omitted, etc. It would be better to ensure we test all sims for all these things with direct tests. We should also try to test all norm values explicitly so that there aren't problems with super large documents and so on.\n ",
            "author": "Robert Muir"
        },
        {
            "id": "comment-16211725",
            "date": "2017-10-19T20:57:12+0000",
            "content": "hacky patch with my current state. Spent a lot of time looking at reasonable state space, which is really hard since we don't have limits to number of documents, no bounds on boosts, etc. Tried really hard (maybe too much) to be super-fair to the similarity, e.g. test shouldn't generate scenarios that are impossible to create with IndexWriter. But some things (like huge tf values but tiny norm values) are fair game because we don't limit stacking terms/synonyms and so forth. This stuff may still have interesting test bugs if beasted enough.\n\nCurrently the test fails, it seems like our bm25 may \"go backwards\" for largish term freqs, looks like floating point issues to me. Haven't tried to debug that yet, other crabs to chase down first.\n\nCan't really debug anything about this test until i think, we first force explain() to exactly match score() for a sim. I realize this is a PITA, but I think we need that and will look into that next.\n\nHere is an example of test output for the \"going backwards\" example, where it fails the pairwise test but the explanation doesnt show it. Still need to improve this, so its really easy to write a one-line test method for any scenario, and so on.\n\n\n[junit4:pickseed] Seed property 'tests.seed' already defined: CA6EF971C3E23AAF\n   [junit4] <JUnit4> says ciao! Master seed: CA6EF971C3E23AAF\n   [junit4] Executing 1 suite with 1 JVM.\n   [junit4] \n   [junit4] Started J0 PID(16127@localhost).\n   [junit4] Suite: org.apache.lucene.search.similarities.TestBM25Similarity\n   [junit4]   1> 0.03627357 = score(doc=0,freq=113659.0 = prevFreq=113658\n   [junit4]   1> ), product of:\n   [junit4]   1>   0.016547536 = idf, computed as log(1 + (docCount - docFreq + 0.5) / (docFreq + 0.5)) from:\n   [junit4]   1>     449.0 = docFreq\n   [junit4]   1>     456.0 = docCount\n   [junit4]   1>   2.1920826 = tfNorm, computed as (freq * (k1 + 1)) / (freq + k1 * (1 - b + b * fieldLength / avgFieldLength)) from:\n   [junit4]   1>     113659.0 = prevFreq=113658\n   [junit4]   1>     1.2 = parameter k1\n   [junit4]   1>     0.75 = parameter b\n   [junit4]   1>     2300.5593 = avgFieldLength\n   [junit4]   1>     1048600.0 = fieldLength\n   [junit4]   1> \n   [junit4]   1> 0.03627357 = score(doc=0,freq=113659.0 = currentFreq=113659\n   [junit4]   1> ), product of:\n   [junit4]   1>   0.016547536 = idf, computed as log(1 + (docCount - docFreq + 0.5) / (docFreq + 0.5)) from:\n   [junit4]   1>     449.0 = docFreq\n   [junit4]   1>     456.0 = docCount\n   [junit4]   1>   2.1920826 = tfNorm, computed as (freq * (k1 + 1)) / (freq + k1 * (1 - b + b * fieldLength / avgFieldLength)) from:\n   [junit4]   1>     113659.0 = currentFreq=113659\n   [junit4]   1>     1.2 = parameter k1\n   [junit4]   1>     0.75 = parameter b\n   [junit4]   1>     2300.5593 = avgFieldLength\n   [junit4]   1>     1048600.0 = fieldLength\n   [junit4]   1> \n   [junit4]   1> BM25(k1=1.2,b=0.75)\n   [junit4]   1> field=\"field\",maxDoc=13938,docCount=456,sumTotalTermFreq=1049055,sumDocFreq=456\n   [junit4]   1> term=\"term\",docFreq=449,totalTermFreq=196765\n   [junit4]   1> norm=168 (doc length ~ 1048600)\n   [junit4]   1> freq=113659\n   [junit4]   2> NOTE: reproduce with: ant test  -Dtestcase=TestBM25Similarity -Dtests.method=testRandomScoring -Dtests.seed=CA6EF971C3E23AAF -Dtests.locale=el -Dtests.timezone=Etc/GMT-13 -Dtests.asserts=true -Dtests.file.encoding=UTF-8\n   [junit4] FAILURE 0.12s | TestBM25Similarity.testRandomScoring <<<\n   [junit4]    > Throwable #1: java.lang.AssertionError: score(113658)=0.036273565 > score(113659)=0.03627356\n   [junit4]    > \tat __randomizedtesting.SeedInfo.seed([CA6EF971C3E23AAF:41F1A0C3D995DCA5]:0)\n   [junit4]    > \tat org.apache.lucene.search.similarities.BaseSimilarityTestCase.doTestScoring(BaseSimilarityTestCase.java:324)\n   [junit4]    > \tat org.apache.lucene.search.similarities.BaseSimilarityTestCase.testRandomScoring(BaseSimilarityTestCase.java:296)\n   [junit4]    > \tat java.lang.Thread.run(Thread.java:745)\n   [junit4]   2> NOTE: test params are: codec=CheapBastard, sim=RandomSimilarity(queryNorm=true): {field=DFR I(ne)3(800.0)}, locale=el, timezone=Etc/GMT-13\n   [junit4]   2> NOTE: Linux 4.4.0-92-generic amd64/Oracle Corporation 1.8.0_45 (64-bit)/cpus=8,threads=1,free=134724456,total=189267968\n   [junit4]   2> NOTE: All tests run in this JVM: [TestBM25Similarity]\n   [junit4] Completed [1/1 (1!)] in 1.14s, 1 test, 1 failure <<< FAILURES!\n\n ",
            "author": "Robert Muir"
        },
        {
            "id": "comment-16211771",
            "date": "2017-10-19T21:30:07+0000",
            "content": "I updated patch with a possible fix for the monotonic issue.\n\nat least so tests pass for now and we can add other checks (like try to fix explain) and understand all the issues. ",
            "author": "Robert Muir"
        },
        {
            "id": "comment-16213478",
            "date": "2017-10-20T23:26:42+0000",
            "content": "Updated patch, also enforcing that explain == score (exactly, no floating point differences). \n\nI cleaned up the BM25 explain to be transparent and reflect how the calculation is done.\nMost importantly, explanation is now broken out as scaling * df * tf, like how we compute it, and described in http://kak.tx0.org/Information-Retrieval/TFxIDF rather than displaying the \"re-arranged formula\" with tf including the k1 + 1 scaling factor. Maybe its an improvement for debugging, too since it pulls out the independent scaling factor, making it easier to see the specifics of term frequency saturation and IDF across docs/terms? ",
            "author": "Robert Muir"
        },
        {
            "id": "comment-16213655",
            "date": "2017-10-21T01:51:13+0000",
            "content": "Updated patch with more cleanups around explain. I tried to add descriptions for parts of the formula and also use standard nomenclature. I think its better now, here is typical output:\n\n\n20.629753 = score(doc=0,freq=979.0), product of:\n  2.2 = scaling factor, k1 + 1\n  9.388654 = idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:\n    1.0 = n, number of documents containing term\n    17927.0 = N, total number of documents with field\n  0.9987758 = tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:\n    979.0 = freq, occurrences of term within document\n    1.2 = k1, term saturation parameter\n    0.75 = b, length normalization parameter\n    1.0 = dl, length of field\n    1.0 = avgdl, average length of field\n\n\n\nYou can more easily see term frequency saturation including extreme cases such as 1.0 where no more occurrences can help. You can kinda visualize how it can work for maxScore now \n\n\n...\n  1.0 = tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:\n    5.9470048E8 = freq, occurrences of term within document\n    1.2 = k1, term saturation parameter\n    0.75 = b, length normalization parameter\n    40.0 = dl, length of field (approximate)\n    3.72180768E8 = avgdl, average length of field\n...\n\n ",
            "author": "Robert Muir"
        },
        {
            "id": "comment-16213720",
            "date": "2017-10-21T04:13:37+0000",
            "content": "Added ClassicSimilarity and BooleanSimilarity to testing, randomized bm25 parameters and boosts.\nClassicSimilarity was fine just needed explain() cleaned up to exactly match score().\n\nNote that query boosts and bm25's k1 parameter are only tested within a \"reasonable\" ranges (0..Integer.MAX_VALUE) so we can fail the test if the sim has internal unexpected overflows, this is just trying to kick out the sim bugs. ",
            "author": "Robert Muir"
        },
        {
            "id": "comment-16213777",
            "date": "2017-10-21T07:10:45+0000",
            "content": "I like where the patch is going! ",
            "author": "Adrien Grand"
        },
        {
            "id": "comment-16216056",
            "date": "2017-10-23T23:37:51+0000",
            "content": "Updated patch with DFR passing/failing the new tests as expected:\n\n\tscoring models without warnings in the javadocs pass: models G, I(F), I(n), I(ne)\n\tones with warnings in javadocs all fail: models BE, D, and P\n\n\n\nI think this is a good sign it works to do what we need. To make DFR pass at all, I changed SimilarityBase to use double everywhere internally, then cast to 32-bit float at the end. This fixed all the numerical errors. I think this makes sense as this subclass is supposed to be simple and easy to use (separately, we should take another look at the whole thing now that a lot of ClassicSimilarity's complexity has been removed). It makes the formulas more elegant in many cases too because constants like 5.0 are naturally doubles and all java Math functions take doubles, so some casts etc get removed.\n\nWill work thru the other models and look at potential improvements to explain etc here too for consistency. ",
            "author": "Robert Muir"
        },
        {
            "id": "comment-16216086",
            "date": "2017-10-23T23:51:15+0000",
            "content": "patch with the 3 DFI models passing too. ",
            "author": "Robert Muir"
        },
        {
            "id": "comment-16216094",
            "date": "2017-10-23T23:58:55+0000",
            "content": "updated with the information-based models. LL passes the test, and SPL fails as expected, it has warnings in its javadocs. ",
            "author": "Robert Muir"
        },
        {
            "id": "comment-16216126",
            "date": "2017-10-24T00:27:49+0000",
            "content": "Updated patch with all remaining sims (axiomatic and language models) now tested.\nThe axiomatic F3EXP and F3LOG fail due to their gamma function driving scores negative, I added a warning to their javadocs about this. Also note that these two models don't have default parameter-free ctors. The other 4 models (F1EXP, F1LOG, F2EXP, F2LOG) are all fine, they don't have this gamma function.\n\nAt least now we have the lay of the land, it is as expected. \n\nStill need to deal with many parameters which aren't yet tested. In many cases these are also missing any range checks, we need to dig up/figure out the valid domain, randomize them, look for issues etc. But the default values are tested. ",
            "author": "Robert Muir"
        },
        {
            "id": "comment-16216195",
            "date": "2017-10-24T02:22:27+0000",
            "content": "Patch randomizing values of parameters, adding missing range checks/docs for these parameters. These are just the valid ranges documented by the formulas, for unbounded parameters (such as normalization c, smoothing parameter mu) we treat them the same as BM25's k1 and just ensure non-negative/finite in the range check, and test the range of 0..Integer.MAX_VALUE.\n\nStill TODO is axiomatic parameters, need to look at paper and existing code (it has some range checks already so it may be easy). ",
            "author": "Robert Muir"
        },
        {
            "id": "comment-16216211",
            "date": "2017-10-24T02:45:41+0000",
            "content": "updated to test all sims and parameters. ",
            "author": "Robert Muir"
        },
        {
            "id": "comment-16216243",
            "date": "2017-10-24T03:30:50+0000",
            "content": "Updated patch that also tests floating point tf values. We assume a computeSlopFactor has the range (0 .. 1] for testing. This found a leftover buggy float cast in DFR I(F) but also a new bug: Axiomatic model F1 will most likely return NaN values if you use SloppyPhraseQuery! frequency values < 1 cause its first log to go negative, then the next log to go NaN: formula is 1 + log(1 + log(freq)). Imagine freq=0.3, this is 1 + log(1 + -1.2) = 1 + log(-0.2) = NaN. If we alter the formula to use log(1 + freq) then tests pass but needs investigation/may not be an appropriate solution, so i marked AwaitsFix for now. ",
            "author": "Robert Muir"
        },
        {
            "id": "comment-16217005",
            "date": "2017-10-24T14:31:37+0000",
            "content": "I would like to commit this soonish, the patch will quickly conflict and go out of date.\n\nI will sanity test to ensure the changes didnt introduce bugs in the formulas. \n\nAnd I think open a 2nd issue about dealing with bad apple sims, and change the AwaitsFix to point to that. ",
            "author": "Robert Muir"
        },
        {
            "id": "comment-16217938",
            "date": "2017-10-25T00:50:26+0000",
            "content": "Updated patch. I hooked in CheckHits for more explains testing, and test nearby norm and nearby slightly rarer term to ensure relevance doesn't go backwards in those cases too.\n\nI updated the AwaitsFix url to a separate issue to fix sims with bugs / move to sandbox: LUCENE-8010\n\nFinally i optimized the tests to have more reasonable runtime. I think its ready for now. ",
            "author": "Robert Muir"
        },
        {
            "id": "comment-16218010",
            "date": "2017-10-25T02:48:42+0000",
            "content": "Commit 42717d5f4bbed46009f11a86f307541a19fd7fb5 in lucene-solr's branch refs/heads/master from Robert Muir\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=42717d5 ]\n\nLUCENE-7997: More sanity testing of similarities ",
            "author": "ASF subversion and git services"
        },
        {
            "id": "comment-16218014",
            "date": "2017-10-25T02:50:22+0000",
            "content": "I beasted the new tests 200 times (found/fixed a small hazard in DFR normalization 1), also did relevance smoke test to ensure i didn't mess something up.\n\nLets see how it does in jenkins... ",
            "author": "Robert Muir"
        },
        {
            "id": "comment-16218204",
            "date": "2017-10-25T07:23:05+0000",
            "content": "Thanks Robert! ",
            "author": "Adrien Grand"
        }
    ]
}