{
    "id": "SOLR-4813",
    "title": "Unavoidable IllegalArgumentException occurs when SynonymFilterFactory's setting has tokenizer factory's parameter.",
    "details": {
        "affect_versions": "4.3",
        "status": "Closed",
        "fix_versions": [
            "4.3.1",
            "4.4",
            "6.0"
        ],
        "components": [
            "Schema and Analysis"
        ],
        "type": "Bug",
        "priority": "Critical",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "When I write SynonymFilterFactory' setting in schema.xml as follows, ...\n\n\n<analyzer>\n  <tokenizer class=\"solr.NGramTokenizerFactory\" maxGramSize=\"2\" minGramSize=\"2\"/>\n  <filter class=\"solr.SynonymFilterFactory\" synonyms=\"synonyms.txt\" ignoreCase=\"true\" expand=\"true\"\n   tokenizerFactory=\"solr.NGramTokenizerFactory\" maxGramSize=\"2\" minGramSize=\"2\"/>\n</analyzer>\n\n\n\nIllegalArgumentException (\"Unknown parameters\") occurs.\n\n\nCaused by: java.lang.IllegalArgumentException: Unknown parameters: {maxGramSize=2, minGramSize=2}\n\tat org.apache.lucene.analysis.synonym.FSTSynonymFilterFactory.<init>(FSTSynonymFilterFactory.java:71)\n\tat org.apache.lucene.analysis.synonym.SynonymFilterFactory.<init>(SynonymFilterFactory.java:50)\n\t... 28 more\n\n\n\nHowever TokenizerFactory's params should be set to loadTokenizerFactory method in [FST|Slow]SynonymFilterFactory. (ref. SOLR-2909)\n\nI think, the problem was caused by LUCENE-4877 (\"Fix analyzer factories to throw exception when arguments are invalid\") and SOLR-3402 (\"Parse Version outside of Analysis Factories\").",
    "attachments": {
        "SOLR-4813__4x.patch": "https://issues.apache.org/jira/secure/attachment/12583179/SOLR-4813__4x.patch",
        "SOLR-4813.patch": "https://issues.apache.org/jira/secure/attachment/12582915/SOLR-4813.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Jack Krupansky",
            "id": "comment-13655749",
            "date": "2013-05-13T04:32:02+0000",
            "content": "The problem is not that you have a tokenizerFactory attribute, but that you are trying to use a tokenizer that has attributes. Solr is simply complaining that you have two attributes, maxGramSize and minGramSize that are not defined for the SynonymFilterFactory. Yes, that is a new feature in Solr! If your code was working in a previous release, you were lucky - it would have been using the default min and max of 1 and 1.\n\nThe synonym tokenizerFactory attribute has no provision for passing attributes to the synonym tokenizer. For now, you'll have to create a custom ngram tokenizer factor with the desired settings. "
        },
        {
            "author": "Shingo Sasaki",
            "id": "comment-13655772",
            "date": "2013-05-13T05:38:05+0000",
            "content": "Hi, Jack. Thank you for your comment.\nDo you mean that backward compatibility was lost? \n\nOn samples of SOLR-319, the filter tag of SynonymFilterFactory has attributes, minGramSize and maxGramSize,\nand TokenizerFactory's instance is inited by args in FSTSynonymFilterFactory.loadTokenizerFactory of Lucene 4.2.1's. "
        },
        {
            "author": "Shingo Sasaki",
            "id": "comment-13655897",
            "date": "2013-05-13T10:42:59+0000",
            "content": "I posted the patch of bug fix and improvement. Please review it. \n\nThe improvement is following.\n\n\nIf TokenizerFactory's parameter name is the same as SynonymFilterFactory's parameter name, you must add prefix \"tokenizerFactory.\" to TokenizerFactory's parameter name. "
        },
        {
            "author": "Jack Krupansky",
            "id": "comment-13655951",
            "date": "2013-05-13T13:15:43+0000",
            "content": "Yes, you are right, this is a regression - I checked 4.2 - all the original \"args\" get passed to the tokenizer factory. And your suggested improvement makes sense.\n\nYou should lobby to have this fix in 4.3.1.\n\nSome enhancement to the synonym filter factory Javadoc is also needed - to explain how tokenizer factory args are passed. "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13656565",
            "date": "2013-05-14T00:07:10+0000",
            "content": "Thanks for the bug report, and especially for the patch with test case!\n\nyour patch looks correct to me at first glance, but i'll review more closely and try to get in for 4.3.1 "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13656619",
            "date": "2013-05-14T01:21:51+0000",
            "content": "Shingo: a flaw in your test was that \"inform\" was never called on the SynonymFilterFactory you were manually constructing, so it never attempted to instantiate your \"TestTokenizerFactory\", so all of the checks you had in it's constructor were being ignored.\n\nI simplified the test to use tokenFilterFactory() to try and deal with this, but that exposed another problem: since your TestTokenizerFactory class isn't registered with SPI, \"lookupClass()\" fails on it.\n\nTo simplify all of this, I changed the test to us a real tokenizer factory with mandatory init arg (PatternTokenizerFactory), so we can check both the positive and negative cases \u2013 this includes an explicit check that specifying params which neither the SynonymFilterFactor nor the tokenizerFactory are expecting causes an error.\n\nI also tweaked your javadocs to try and clarify that the param prefix could be used even if the param names don't conflict, and re-ordered the param parsing code to group of of the tokenizerFactory stuff together.\n\nstill running full tests.\n "
        },
        {
            "author": "Shingo Sasaki",
            "id": "comment-13656650",
            "date": "2013-05-14T02:26:48+0000",
            "content": "Jack: Thanks for your check and advice.\n\nHoss: Thank you for compensating for the shortcomings of my patch.\n\nBy the way, the patch is applied to SynonymFilterFactory of trunk, but SynonymFilterFactory of branch_4x is  delegatee of [FST|Slow]SynonymFilterFactory.\n\nIs branch_4x's patch required for committing to 4.3.1? "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13657230",
            "date": "2013-05-14T17:23:24+0000",
            "content": "Hoss: Thank you for compensating for the shortcomings of my patch.\n\nHey man, you did the hard part \u2013 i just gave it a second pair of eyes and noticed the test glitch.\n\nIs branch_4x's patch required for committing to 4.3.1?\n\nNope, i'll take care of the backport \u2013 but thanks forthe reminder about FST vs Slow on 4x, i might have missed one.\n\nCommitted revision 1482474. - trunk ... backporting now. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13657257",
            "date": "2013-05-14T17:38:58+0000",
            "content": "Thanks to both of you especially for still preserving the checking!!! "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13657336",
            "date": "2013-05-14T18:30:17+0000",
            "content": "patch showing what the backport looks like.\n\nit's unfortunate there isn't more code reuse between Slow & FST SynonymFactories, but that that can be refactored another day.\n\nthe patch includes some additional test permutations to ensure the param checking works right regardless of which delegate is picked.\n\ni'm still running full tests & precommit "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13657361",
            "date": "2013-05-14T18:46:42+0000",
            "content": "backport looks great! "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13657402",
            "date": "2013-05-14T19:19:10+0000",
            "content": "Thanks rmuir,\n\nCommitted revision 1482527 - 4x\n\nBackport to 4.3.1 was clean, i'll commit there when the tests are done "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13657586",
            "date": "2013-05-14T22:12:20+0000",
            "content": "the 4.3.1 backport wasn't as clean as i originally thought, apparently i was depending on some test improvements that were committed to 4x as part of an improvement (LUCENE-3907) so i also merged back just the BaseTokenStreamFactoryTestCase changes from r1479892...\n\nCommitted revision 1482619. - branch 4_3 "
        },
        {
            "author": "Christian Moen",
            "id": "comment-13657937",
            "date": "2013-05-15T05:15:49+0000",
            "content": "Good work. Thanks! "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-13686935",
            "date": "2013-06-18T16:52:41+0000",
            "content": "Bulk close after 4.3.1 release "
        }
    ]
}