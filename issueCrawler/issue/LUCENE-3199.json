{
    "id": "LUCENE-3199",
    "title": "Add non-desctructive sort to BytesRefHash",
    "details": {
        "labels": "",
        "priority": "Minor",
        "components": [
            "core/index"
        ],
        "type": "Improvement",
        "fix_versions": [],
        "affect_versions": "4.0-ALPHA",
        "resolution": "Unresolved",
        "status": "Open"
    },
    "description": "Currently the BytesRefHash is destructive.  We can add a method that returns a non-destructively generated int[].",
    "attachments": {
        "LUCENE-3199.patch": "https://issues.apache.org/jira/secure/attachment/12492703/LUCENE-3199.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2011-06-14T06:01:34+0000",
            "content": "I think the issue with this, as it relates to realtime search, is in order to sort, we'll need to freeze indexing. ",
            "author": "Jason Rutherglen",
            "id": "comment-13048987"
        },
        {
            "date": "2011-09-02T03:35:30+0000",
            "content": "Here's a version of this issue.  Added are a couple of new methods to TestBytesRefHash to test the new frozen compact and sorting functionality of BytesRefHash.\n\nThis is being posted now because it's useful in relation to LUCENE-2312 and a terms dictionary that is composed of sorted by term[id]s int[]s. ",
            "author": "Jason Rutherglen",
            "id": "comment-13095750"
        },
        {
            "date": "2011-09-02T13:59:30+0000",
            "content": "This is a minor update when compared with the last patch.  \n\nIt adds the option of pruning the [oversized] int[] returned by the compact method.  \n\nAdded are additional unit tests. ",
            "author": "Jason Rutherglen",
            "id": "comment-13095991"
        },
        {
            "date": "2011-09-02T16:06:36+0000",
            "content": "hey jason, I actually moved this a little further and added a ReadOnly View To BytesRefHash. This View provides next(), seekExact() and seekCeil() methods just like we have TermsEnum. \nThe view is actually sorted if needed and can incrementally merge with a previously created view. \nInitially I wondered if this approach would be feasible performance wise but in fact this  is actually really fast. I did some poor-mans benchmarks where I opened a new view every 500 to 1000 new unique terms and this takes around 0.001 to 0.01 millisecond on average. I have never seen it taking longer than 0.1 ms. I think it would be worth while exploring if we can go that simple and reopen such a view for each document while we are indexing. The view actually allocates only one additional array and reuses all other references from the BytesRefHash instance. It seems this one additional int[] is not too bad though.\n\nthe patch is still rough. I will work further on it next week.  ",
            "author": "Simon Willnauer",
            "id": "comment-13096083"
        },
        {
            "date": "2011-09-02T16:16:03+0000",
            "content": "new version, fixed one concurrency issue and added some doc strings ",
            "author": "Simon Willnauer",
            "id": "comment-13096089"
        },
        {
            "date": "2011-09-02T16:23:55+0000",
            "content": "Cool idea with the view! Policeman work: SorterTemplate looks correct  ",
            "author": "Uwe Schindler",
            "id": "comment-13096094"
        },
        {
            "date": "2011-09-02T16:39:06+0000",
            "content": "Simon,\n\nIn summary this is using the BytesRefHash sort, performing array copies and\nthen merge [sorting] into a new copy / view. \n\nArray copies are fast and counter intuitively generate far less garbage than\nobjects (in Java). \n\nInstead of creating term 'segments' that would be merged while iterating the\nterms enum, we'll be generating static point-in-time terms dict views. These\nwill be useful for enabling DocTermsIndex field caches for RT, the only\nremaining design 'challenge' for RT / LUCENE-2312. Because there is a terms\nhash, we can seek exact to the term rather than perform an [optimized] seek to\nthe term. ",
            "author": "Jason Rutherglen",
            "id": "comment-13096108"
        },
        {
            "date": "2011-09-02T19:32:41+0000",
            "content": "Simon, I think your patch should be in a different issue, eg, sorted bytes ref hash view or something. ",
            "author": "Jason Rutherglen",
            "id": "comment-13096231"
        },
        {
            "date": "2011-09-05T18:54:41+0000",
            "content": "I started integrating the patch into LUCENE-2312.  I think the main functionality missing is a reverse int[] that points from a term id to the sorted ords array.  That array would be used for implementing the RT version of DocTermsIndex, where a doc id -> term id -> sorted term id index.   ",
            "author": "Jason Rutherglen",
            "id": "comment-13097246"
        },
        {
            "date": "2011-09-05T19:05:04+0000",
            "content": "Ok, solved the above comment by taking the sorted ord array and building a new reverse array from that...  ",
            "author": "Jason Rutherglen",
            "id": "comment-13097257"
        }
    ]
}