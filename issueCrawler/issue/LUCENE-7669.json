{
    "id": "LUCENE-7669",
    "title": "Rectangle.fromPolygon could compute smaller bounding boxes",
    "details": {
        "labels": "",
        "priority": "Minor",
        "resolution": "Unresolved",
        "affect_versions": "None",
        "status": "Open",
        "type": "Improvement",
        "components": [],
        "fix_versions": []
    },
    "description": "Currently it computes the smallest bounding box that does not cross the dateline. However allowing to cross the dateline could allow to create smaller bounding boxes. For instance, because of that, the bounding box of the Russia polygon has a width of 360 longitude degrees. By allowing rectangles that cross the dateline, we could get a polygon whose width is only 171 longitude degrees. This is useful combined with LUCENE-7661 since it means the grid would have higher resolution.",
    "attachments": {
        "LUCENE-7669.patch": "https://issues.apache.org/jira/secure/attachment/12850020/LUCENE-7669.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "id": "comment-15845620",
            "date": "2017-01-30T18:24:12+0000",
            "content": "Here is a patch. I am seeing a 6% QPS increase when benchmarking the Russia polygon with IndexAndSearchOpenStreetMaps. ",
            "author": "Adrien Grand"
        },
        {
            "id": "comment-15846718",
            "date": "2017-01-31T11:53:40+0000",
            "content": "This is a great idea!  But I'm a little confused exactly how the code is working.  Maybe add a few comments explaining how sorting by minLon first, then traversing the maxLon/deltas, leads to detecting the dateline case? ",
            "author": "Michael McCandless"
        },
        {
            "id": "comment-15846725",
            "date": "2017-01-31T12:02:12+0000",
            "content": "I think its a bit dangerous to have this boolean on this method?\n\nI'm not sure this optimization is worth it given the risk, i don't think real world queries will benefit from it. I just don't think many query polygons cross the dateline at all, and its not a case worth optimizing for, for like 6%.\n\nI also don't like the damage to the API. But maybe the optimization can be done in such a way that it doesn't impact a public API, produce large amounts of risk given how insanely rare it is, etc. Not sure... ",
            "author": "Robert Muir"
        },
        {
            "id": "comment-15846779",
            "date": "2017-01-31T12:59:06+0000",
            "content": "+1 to what Rob said. ",
            "author": "David Smiley"
        },
        {
            "id": "comment-15846854",
            "date": "2017-01-31T13:54:10+0000",
            "content": "I'll think more about it, one part of me agrees polygons that cross the dateline are uncommon, but on the other hand, it is also a pity things are deoptimized when polygons cross the dateline. The performance boost for the Russia polygon is small since this country covers a wide range of longitude anyway, but I suspect the difference would be much higher if you used a multipolygon of Fiji islands. Maybe a more general way to solve this problem would be to use multiple grids in case of multipolygons whose sub polygons are far from each other, for instance the Netherlands plus the Caribbean Netherlands. We could organize those multiple grids in a KD tree similarly to Polygon2D. ",
            "author": "Adrien Grand"
        },
        {
            "id": "comment-15852311",
            "date": "2017-02-03T23:18:08+0000",
            "content": "It's not a single polygon crossing the date line here right?  (I think we check and prevent that).  But rather N polygons in a multi-polygon search, where their overall bounding box crosses the dateline.  I do think it is bad that we become so slow in this case?  Why should we penalize people searching around the Fiji islands  ",
            "author": "Michael McCandless"
        },
        {
            "id": "comment-15852598",
            "date": "2017-02-04T05:09:01+0000",
            "content": "It's also true that there tends to be little data out there in the Pacific, and thus whoever is searching out there is going to find their searches to be fast in general by virtue of that factor.  This is a generalization of course. ",
            "author": "David Smiley"
        },
        {
            "id": "comment-15852718",
            "date": "2017-02-04T09:43:08+0000",
            "content": "\nI do think it is bad that we become so slow in this case? Why should we penalize people searching around the Fiji islands \n\nThis is incorrect. It is not \"so slow\". The difference is 6%.\n\nThe outer bounding box is entirely unnecessary: each individual sub-polygon (which cannot cross the dateline) already has its own bounding box in the KD-tree. The outer bounding box around the whole thing is just a micro-optimization that saves a kd-tree lookup before checking yet another bounding box. Please don't add rare optimizations to a micro-optimization that is already unnecessary \n\nRemoving it completely, not optimizing it, is the correct direction. Maybe the kd-tree lookup just needs some cpu speedup or something like that. ",
            "author": "Robert Muir"
        },
        {
            "id": "comment-15852732",
            "date": "2017-02-04T10:19:08+0000",
            "content": "\nMaybe a more general way to solve this problem would be to use multiple grids in case of multipolygons whose sub polygons are far from each other, for instance the Netherlands plus the Caribbean Netherlands. We could organize those multiple grids in a KD tree similarly to Polygon2D.\n\nI also think this is heading down the wrong path. We had a grid for polygon search before, and worked hard to remove it. Its good that you made a faster grid, but we should work to remove it yet again.\n\nInstead of optimizing optimizations for rare cases like dutch colonialism and searches of the fiji islands, we should e.g. look at speeding up polygon2d's kd-tree so the general case is faster. ",
            "author": "Robert Muir"
        }
    ]
}