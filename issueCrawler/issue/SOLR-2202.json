{
    "id": "SOLR-2202",
    "title": "Money/Currency FieldType",
    "details": {
        "affect_versions": "1.5",
        "status": "Closed",
        "fix_versions": [
            "3.6",
            "4.0-ALPHA"
        ],
        "components": [
            "Schema and Analysis"
        ],
        "type": "New Feature",
        "priority": "Major",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "Provides support for monetary values to Solr/Lucene with query-time currency conversion. The following features are supported:\n\n\n\tPoint queries\n\tRange quries\n\tSorting\n\tCurrency parsing by either currency code or symbol.\n\tSymmetric & Asymmetric exchange rates. (Asymmetric exchange rates are useful if there are fees associated with exchanging the currency.)\n\n\n\nAt indexing time, money fields can be indexed in a native currency. For example, if a product on an e-commerce site is listed in Euros, indexing the price field as \"1000,EUR\" will index it appropriately. By altering the currency.xml file, the sorting and querying against Solr can take into account fluctuations in currency exchange rates without having to re-index the documents.\n\nThe new \"money\" field type is a polyfield which indexes two fields, one which contains the amount of the value and another which contains the currency code or symbol. The currency metadata (names, symbols, codes, and exchange rates) are expected to be in an xml file which is pointed to by the field type declaration in the schema.xml.\n\nThe current patch is factored such that Money utility functions and configuration metadata lie in Lucene (see MoneyUtil and CurrencyConfig), while the MoneyType and MoneyValueSource lie in Solr. This was meant to mirror the work being done on the spacial field types.\n\nThis patch will be getting used to power the international search capabilities of the search engine at Etsy.\n\nAlso see WIKI page: http://wiki.apache.org/solr/MoneyFieldType",
    "attachments": {
        "SOLR-2202-solr-5.patch": "https://issues.apache.org/jira/secure/attachment/12458288/SOLR-2202-solr-5.patch",
        "SOLR-2202-solr-4.patch": "https://issues.apache.org/jira/secure/attachment/12458221/SOLR-2202-solr-4.patch",
        "SOLR-2202-solr-9.patch": "https://issues.apache.org/jira/secure/attachment/12458924/SOLR-2202-solr-9.patch",
        "SOLR-2202-fix-NPE-if-no-tlong-fieldType.patch": "https://issues.apache.org/jira/secure/attachment/12517882/SOLR-2202-fix-NPE-if-no-tlong-fieldType.patch",
        "SOLR-2022-solr-3.patch": "https://issues.apache.org/jira/secure/attachment/12458191/SOLR-2022-solr-3.patch",
        "SOLR-2202.patch": "https://issues.apache.org/jira/secure/attachment/12496857/SOLR-2202.patch",
        "SOLR-2202-solr-8.patch": "https://issues.apache.org/jira/secure/attachment/12458838/SOLR-2202-solr-8.patch",
        "SOLR-2202-solr-10.patch": "https://issues.apache.org/jira/secure/attachment/12515927/SOLR-2202-solr-10.patch",
        "SOLR-2202-no-fieldtype-deps.patch": "https://issues.apache.org/jira/secure/attachment/12517961/SOLR-2202-no-fieldtype-deps.patch",
        "SOLR-2202-solr-6.patch": "https://issues.apache.org/jira/secure/attachment/12458746/SOLR-2202-solr-6.patch",
        "SOLR-2202-lucene-1.patch": "https://issues.apache.org/jira/secure/attachment/12458115/SOLR-2202-lucene-1.patch",
        "SOLR-2202-solr-2.patch": "https://issues.apache.org/jira/secure/attachment/12458116/SOLR-2202-solr-2.patch",
        "SOLR-2202-solr-7.patch": "https://issues.apache.org/jira/secure/attachment/12458760/SOLR-2202-solr-7.patch",
        "SOLR-2202-3x-stabilize-provider-interface.patch": "https://issues.apache.org/jira/secure/attachment/12520510/SOLR-2202-3x-stabilize-provider-interface.patch",
        "SOLR-2202-solr-1.patch": "https://issues.apache.org/jira/secure/attachment/12458114/SOLR-2202-solr-1.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Greg Fodor",
            "id": "comment-12925183",
            "date": "2010-10-26T22:52:33+0000",
            "content": "Initial patch. "
        },
        {
            "author": "Greg Fodor",
            "id": "comment-12925184",
            "date": "2010-10-26T22:55:14+0000",
            "content": "Forgot to include currency.xml. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-12925338",
            "date": "2010-10-27T11:50:04+0000",
            "content": "Hello, taking a look at the code, is there any specific reason you didn't use NumberFormat/Currency in java for parsing, output, symbols, etc?\n\nI think this would be easier in order to support more locales.\n\nSome examples below, using NumberFormat.getCurrencyInstance() with a specified currency, specifying locale:\n\nthai baht:\n\nen_US: THB1,234.50\nth_TH: \u0e3f1,234.50\nth_TH_TH: \u0e3f\u0e51,\u0e52\u0e53\u0e54.\u0e55\u0e50\n\n\n\neuro:\n\nde_DE: 1.234,50 \u20ac\nen_US: EUR1,234.50\n\n "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-12925340",
            "date": "2010-10-27T11:55:40+0000",
            "content": "The other question is, why you don't use NumericField (in Solr it's the TrieField type) and instead save the stuff as plain numbers in index?\n\nIn general its wrong to use float/double as currency-backing type, as you have rounding problems. To index/store the fields in lucene/solr or any database, you have to use fixed point. E.g. a TrieField instance saing the \"US-Cent\" value.\n\nThis would enable Range Queries without the field cache! "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-12925342",
            "date": "2010-10-27T12:02:44+0000",
            "content": "Here some infos, why it's wrong to use double/float: http://download.oracle.com/javase/tutorial/java/nutsandbolts/datatypes.html "
        },
        {
            "author": "Robert Muir",
            "id": "comment-12925344",
            "date": "2010-10-27T12:06:51+0000",
            "content": "Here some infos, why it's wrong to use double/float: http://download.oracle.com/javase/tutorial/java/nutsandbolts/datatypes.html\n\nAlso, you can use Currency.getDefaultFractionDigits to fix this.\n\nFor example, the default number of fraction digits for the Euro is 2, while for the Japanese Yen it's 0. In the case of pseudo-currencies, such as IMF Special Drawing Rights, -1 is returned. "
        },
        {
            "author": "Greg Fodor",
            "id": "comment-12925418",
            "date": "2010-10-27T15:33:03+0000",
            "content": "Hey Uwe & Robert, thank you for your feedback. I will look into better integration with the native Currency classes, that makes a lot of sense. As far as the numerical indexing goes, I might need some help.\n\nFirst, I'm guessing the necessary change will be to change the \"amount\" subfield from a double to a tdouble field type. (TrieDouble) How exactly does this help with rounding errors? I'm not that familiar with the Trie types, but it seems that since the values are coerced through the ValueSource to doubles there is always a risk of rounding error.\n\nAdditionally, how does the trie field prevent hitting the field cache? I am implementing a custom value source, which does the currency conversion by applying it by iterating over the ValueSource's for the subfields.\n\nFinally, you mention saving the values as \"plain numbers in the index\" \u2013 I assumed this is what I was already doing via the construction of the subfields and storing the values in \"double\" FieldType'd field \"amount\". Can you explain what steps I need to take to be sure these values are being stored as numbers in the index?\n\nThanks! "
        },
        {
            "author": "Robert Muir",
            "id": "comment-12925461",
            "date": "2010-10-27T17:06:58+0000",
            "content": "I will look into better integration with the native Currency classes, that makes a lot of sense.\n\nGreat! Just for your own reference at least, you get even more powerful stuff with the ICU Currency stuff.\n\nFor example, if you use NumberFormat.getInstance(new ULocale(\"en\", \"US\"), NumberFormat.PLURALCURRENCYSTYLE),\nthen setCurrency to Currency.getInstance(\"USD\"), it will output \"1,234.50 US dollars\".\n\nSo, with ICU you dont have to maintain the plural data you have (or worry about the plural formatting, etc). "
        },
        {
            "author": "Greg Fodor",
            "id": "comment-12925466",
            "date": "2010-10-27T17:20:10+0000",
            "content": "A few questions, now that I've done a bit more research and thinking:\n\n\n\tFirst, currency parsing in Java appears locale-dependent (which obviously makes sense.) The concern here is that the locale of the end-user performing queries is likely not the same as the locale of the search engine. Is there currently a standard mechanism in Solr to acquire the user's locale? What do we do for other internationalized components?\n\n\n\n\n\tNumberFormat parsing fails to parse \"10.00USD\", or \"10.00 USD\", instead relying upon the symbol. (\"$10.00\"). This seems like a limitation since generally using the currency code as suffix is a locale-independent way of specifying a monetary value, making indexing code easy to write (simply append the currency code for the document to the value). It may very well be a good idea to simply standardize on this approach for the purposes of indexing, and avoid all the locale-specific issues that come up regarding currency symbols.\n\n\n\n\n\tThe NumberFormat parsing does not yield back the currency, just the value. It seems the currency itself still needs to be extracted somehow. Is there a built in mechanism to do this? Currently the patch iterates over all currencies attempting to extract the symbol or code from the value.\n\n\n\n\n\tHow important is it that users have control over the currencies table? It was quite useful to have the ability to define fake currencies for testing (as is done in the example currency.xml file), it seems that if I changed the implementation to use Java's currency table this might be a limitation if non-testing oriented use-cases exist.\n\n\n\n\n\tI wanted to know in more detail what rounding related errors, if any, I need to be concerned with. You'll notice in the patch that the range query applies an EPSILON on the edges to avoid floating point equality issues, and the point query actually executes a range query. Are there additional problems I need to address? It seems there will always be some margin of error when exchange rates are being applied since this requires floating point multiplications of values in the index at execution time.\n\n\n\n\n\tLooking further I'm not really sure I understand how the TrieField can benefit me here. It seems that an entire iteration through the ValueSource is necessary for range queries, as conversion rates may dictate that the minimum and maximum amount value documents need to be visited.\n\n\n\n\n\tRight now the name and plural name, etc are unused. It definitely will make sense to remove or incorporate Java's native APIs to get those if they end up being needed, however.\n\n\n\nThanks again for reviewing this patch! "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-12925471",
            "date": "2010-10-27T17:30:07+0000",
            "content": "Looking further I'm not really sure I understand how the TrieField can benefit me here. It seems that an entire iteration through the ValueSource is necessary for range queries, as conversion rates may dictate that the minimum and maximum amount value documents need to be visited. \n\nVery easy: Dont do the transformation for each value in terms index/per document. Just convert the currency value from the query string to the index local before building the trie range.\n\nFirst, I'm guessing the necessary change will be to change the \"amount\" subfield from a double to a tdouble field type. (TrieDouble) How exactly does this help with rounding errors? I'm not that familiar with the Trie types, but it seems that since the values are coerced through the ValueSource to doubles there is always a risk of rounding error.\n\nI said, you should remove double/long completely and save the value as a \"long\" or \"tlong\" using the Currency.getDefaultFractionDigits (e.g. convert euros into eurocents, because for EUR the fraction digits are 2). "
        },
        {
            "author": "Robert Muir",
            "id": "comment-12925473",
            "date": "2010-10-27T17:34:55+0000",
            "content": "Hi Greg, these are excellent questions... I'll reply only to the localization ones and let Uwe or others talk about the Trie stuff.\n\nFirst, currency parsing in Java appears locale-dependent (which obviously makes sense.) The concern here is that the locale of the end-user performing queries is likely not the same as the locale of the search engine. Is there currently a standard mechanism in Solr to acquire the user's locale? What do we do for other internationalized components?\n\nWell, in general components are internationalized, but this is actually a localization problem. Usually for Solr, the Solr service is not handlign the end-users request, so its best if Locale is somehow a parameter, and the default Locale never used at all. In other words, its up to you to figure out how you want to determine what Locale to use, and Solr would just respect that.\n\nNumberFormat parsing fails to parse \"10.00USD\", or \"10.00 USD\", instead relying upon the symbol. (\"$10.00\"). This seems like a limitation since generally using the currency code as suffix is a locale-independent way of specifying a monetary value, making indexing code easy to write (simply append the currency code for the document to the value). It may very well be a good idea to simply standardize on this approach for the purposes of indexing, and avoid all the locale-specific issues that come up regarding currency symbols.\n\nIts not really a limitation, it depends upon the NumberFormat in use. The one you used for parsing is just the Locale default format for that Locale from getCurrencyInstance... but you can supply your own DecimalFormat pattern too. This is a printf/scanf like pattern that can contain special characters, particularly \u00a4 (\\u00A4): Currency sign, replaced by currency symbol. If doubled, replaced by international currency symbol. If present in a pattern, the monetary decimal separator is used instead of the decimal separator.\n\nIdeally here, you could allow this pattern to be a parameter.\n\nThe NumberFormat parsing does not yield back the currency, just the value. It seems the currency itself still needs to be extracted somehow. Is there a built in mechanism to do this? Currently the patch iterates over all currencies attempting to extract the symbol or code from the value.\n\nRight, NumberFormat parses the actual number. Really its best if the currency ISO code (e.g. USD) itself is supplied as a parameter, because these symbols are not unique, for example $ is used for many currencies.  I think this is what Solr should do. if the end-user application doesn't know this somehow, the end-user application can use more sophisticated mechanisms to \"guess\" it, particularly things like ICU's \"CurrencyMetaInfo\" allow you to supply a \"filter\" based on things like region, and timeframes, to get a list of the currencies used in that region at that time, but I think Solr should just take the ISO code as input.\n\n\nHow important is it that users have control over the currencies table? It was quite useful to have the ability to define fake currencies for testing (as is done in the example currency.xml file), it seems that if I changed the implementation to use Java's currency table this might be a limitation if non-testing oriented use-cases exist.\n\nI don't think its import to have fake currencies, but such things can be done with the Locale SPI ... I think. I think we could just use real currencies for testing.\n\n "
        },
        {
            "author": "Robert Muir",
            "id": "comment-12925475",
            "date": "2010-10-27T17:39:17+0000",
            "content": "Sorry for editing my response above, i just wanted to be more clear in that I think any guess-work should be outside the scope of Solr  "
        },
        {
            "author": "Greg Fodor",
            "id": "comment-12925488",
            "date": "2010-10-27T18:20:22+0000",
            "content": "Uwe: apologies if I'm missing something, but I'm still having a hard time understanding how this would work. If the user performs a query for 10.00EUR, it seems the appropriate trie range, in theory, would be the largest and smallest possible converted currency value, across all currencies. For example, if we assume currencies 1FOO = 100EUR, and 1BAR = 0.001EUR, then we'd have to do a trie range for the query 1EUR from 0.001 to 100, is this correct?\n\nIf this is what you're proposing, I'm not sure if it will be that big a win, due to the fact that there are exchange rates exceeding 100X (for example, USD -> JPY). Presumably, if you are indexing e-commerce products that range from say $10.00 to $1,000USD, you'll likely be forced to scan the entire range of values for most queries. For example, a $25.00USD query will need to scan from approx 10.00 -> 2500.00 to be sure no documents are missed. (lower bound dictated by GBP or EUR, upper bound by JPY for example.)\n\nRobert: Thanks for the clarifications. First, if no such mechanism exists, would it make sense to include the locale as one of the parameters to the query via the edismax parser? I think the locale specified can be useful for parsing the currency in cases where \"$\", for example, is ambiguous, and we should defer as you said to the ICU/Java parser. However, I think including the currency code as part of the value itself (particularly when indexing it as a field) is an important use case to support as well, since it makes indexing so much easier to implement. Is this what you mean by Solr taking the ISO code as input? For example: \"price:10.00USD\", where the code is part of the value. This is what is currently supported by the patch. Note that I do not allow spaces, since that breaks the range query parser. (\"price:[10.00USD to 40.00USD]\") This can probably be addressed later. "
        },
        {
            "author": "Greg Fodor",
            "id": "comment-12925493",
            "date": "2010-10-27T18:31:48+0000",
            "content": "I guess I should clarify my comment re: TrieField. I guess I'm wondering if it is more expensive to perform a Trie-based query against a large portion of the value's range instead of a direct fieldcache based range query. My assumption (which might be incorrect) is that trie-based range queries across the entire span of values are more expensive than non-Trie full-span range queries. If this isn't the case then it makes sense to do as you suggest and use Trie ranges even though often they will span the entire range of values. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-12925494",
            "date": "2010-10-27T18:38:19+0000",
            "content": "However, I think including the currency code as part of the value itself (particularly when indexing it as a field) is an important use case to support as well, since it makes indexing so much easier to implement. Is this what you mean by Solr taking the ISO code as input? For example: \"price:10.00USD\", where the code is part of the value.\n\nNo, I don't think we should do this.\n\nI think the code, even in this case should be provided separate.\nBecause 10.00USD is just still a number format (NumberFormat.ISOCURRENCYSTYLE), not any less ambiguous than $10.00 (NumberFormat.CURRENCYSTYLE) to me.\n\nUnder a chinese locale its USD10.00, under german its 10,00\u00a0USD (with a space!)\n\nReally I can't stand how the current date-range stuff is handled by Lucene either via queryparsing.\nIn my opinion, when queryparsing this stuff: for a date range query/indexing, you should have to provide a DateFormat.\nfor a currency query/indexing, you should have to provide a DecimalFormat.\n\nFor dates, it seems Solr opted to go with a standardized required DateFormat across the board, and its up to clients to convert.\nWe really need to think this through for Currency, because passing the necessary stuff to build a DecimalFormat its going to be verbose (Locale + Currency ISO Code + Format String + the String containing the currency value itself)...\n\nReally I wonder if we could force the client to deal with localization and parsing, since thats where it fits best anyway, and make it provide just the raw long + ISO code to solr for this...\n\nthe fact that Solr forces you to implement query-parsing server-side is going to introduce complexity here unless we can find a trick... "
        },
        {
            "author": "Greg Fodor",
            "id": "comment-12925501",
            "date": "2010-10-27T18:48:39+0000",
            "content": "I think the fact that we do have a locale-independent way to specify currency, the ISO code, is the lever we need. \n\nYou'll notice that the MoneyType is a polyfield of string and double. It could be that we might want to introduce a standard syntax for specifying polyfield values, which could be leveraged here. For PointType it's merely comma delimited. So, we could use the raw long and the ISO code, separated by a comma. \n\nprice: 12345,USD\n\nIt's not pretty to look at, but it at least would be a \"correct\" solution by removing the dependency upon locale altogether.  "
        },
        {
            "author": "Robert Muir",
            "id": "comment-12925504",
            "date": "2010-10-27T18:52:51+0000",
            "content": "It's not pretty to look at, but it at least would be a \"correct\" solution by removing the dependency upon locale altogether.\n\nright, i definitely have no problem with that, from a localization standpoint... then there is no issue at all, and its up to the client\nto deal with formatting/parsing/pluralization/whatever "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-12925511",
            "date": "2010-10-27T19:04:45+0000",
            "content": "I guess I should clarify my comment re: TrieField. I guess I'm wondering if it is more expensive to perform a Trie-based query against a large portion of the value's range instead of a direct fieldcache based range query. My assumption (which might be incorrect) is that trie-based range queries across the entire span of values are more expensive than non-Trie full-span range queries. If this isn't the case then it makes sense to do as you suggest and use Trie ranges even though often they will span the entire range of values. \n\nThat exactly the trick behind the trie field. A query that spans all values is as fast as a query which spans only less values (ok it still depends on the number of documents, but the part that selects the terms to match is very effective). The trick behin trie is to reduce the number of terms by using multiple indexed values in the same field and only choose those that match best. Please read the docs about Lucene's NumericRangeQuery. If the range matches only some values on a sparse index, you loose lots of time on iterating the FieldCache.\n\nAnd FieldCache (in 3.x) has a big disadvantage: It supports only one value per document and it cannot detect NULL values. "
        },
        {
            "author": "Greg Fodor",
            "id": "comment-12925514",
            "date": "2010-10-27T19:10:58+0000",
            "content": "Ok, great, thanks Uwe. I will make a pass to incorporate the changes noted here:\n\n\n\tIndexing tlong instead of double\n\tConstruct range query efficiently based upon maximal/minimal conversion rate\n\tRemove locale specific logic, standardize on input format being <long value>,<ISO code>\n\n\n\nNote that coercion to double's will still occur during the actual conversion, but they will be immediately coerced back into long's. "
        },
        {
            "author": "Greg Fodor",
            "id": "comment-12925560",
            "date": "2010-10-27T21:33:51+0000",
            "content": "I've attached an updated patch. In the process of removing the cruft for Currency parsing, I pulled everything that was in Lucene out. This is entirely a Solr-based patch now.\n\nMoney based field expect their values in the form <long>,<ISO code> where <long> is the converted long value based upon the known currency fraction digits for the ISO code.\n\nUwe, could you please check my implementation of getRangeQuery()? The way I implemented this was via the creation of a range query on the TrieField, which has as its range the max and min potential conversions of the upper and lower bound of the user specified range respectively. This query is then wrapped with a FilteredQuery that applies a Filter that performs the same ValueSource based Scorer as before over the documents to determine if they fall within the range (once converted).\n\nPresumably this means is the outer range query will only pass forward documents to the inner, more expensive, ValueSource filter if they have amount values that fall within the max and min possible amounts across all currencies (given the specified range being queried.) I'm assuming that the Filter in a FilteredQuery is applied after the documents are screened from by the Query being filtered. "
        },
        {
            "author": "Greg Fodor",
            "id": "comment-12925664",
            "date": "2010-10-28T03:11:48+0000",
            "content": "Bugfixes for computation of bounding range for trie query. "
        },
        {
            "author": "Greg Fodor",
            "id": "comment-12925985",
            "date": "2010-10-28T23:19:47+0000",
            "content": "Fix for error when computing converted values. "
        },
        {
            "author": "Lance Norskog",
            "id": "comment-12926221",
            "date": "2010-10-29T09:27:36+0000",
            "content": "This is a really interesting concept. Do other search engines or databases have a currency field type with this configurability? The range value support alone makes it cool.\n\nAlso, it is nice to have a full example of how to implement Polyfields outside of the spatial code. And Trie integration and ZooKeeper integrations.\n\nA minor nit: equals(Object other) has to be transitive. So this.equals(other) has to do the same thing as other.equals(this).\n{{\n{  if (o == null || getClass() != o.getClass()) return false;}\n}}\nIf other is null, this.equals(other) returns false but other.equals(this) throws a null pointer exception. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-12926974",
            "date": "2010-11-01T12:12:42+0000",
            "content": "Greg, one more nitpick:\n\nI think the reloadCurrencyConfig could be improved:\n\n\tIt seems to use resource loader to read in the xml file into a String line-by-line, but then concats all these lines and converts back into a bytearray, just to get an input stream.\n\tIt uses a charset of \"UTF8\" (should be \"UTF-8\").\n\n\n\nI think easier/safer would be to just get an InputStream directly from the resource loader (ResourceLoader.openResource) without this encoding conversion. "
        },
        {
            "author": "Greg Fodor",
            "id": "comment-12927895",
            "date": "2010-11-03T16:33:06+0000",
            "content": "Please ignore, there are problems in the current patch, will update later today. "
        },
        {
            "author": "Greg Fodor",
            "id": "comment-12927990",
            "date": "2010-11-03T20:34:10+0000",
            "content": "This update to the patch includes a number of performance enhancements and is the version of the patch we will be likely to push to production.\n\nFirst, this patch introduces the defaultCurrency parameter, which defaults to USD. The default currency allows you to omit the currency code in the field value (ie, \"5000\" instead of \"5000,USD\".) However, it plays a more pivotal role in improving performance.\n\nThe previous patches provided a naive approach to constructing the trie bounding range by taking the current max and min currency exchange rates to the target currency. This proved to be minimally useful since the relative magnitude of currency units vary wildly and hence the bounding range often spanned the full document set.\n\nThe solution I took in this patch is to compute the bounding range by taking into account the \"currency drift.\" Before getting to that, though, the indexing process was updated to include a new dynamic field that indexes the value of the field in the default currency, exchanged at the current rate at indexing time. (Additionally, a stored field is optionally created if the money field is marked as stored.)\n\nThe historical max and min exchange rates (the \"drift\") are now tracked by solr in a properties file. The properties file is named after the currency config file. For example, if the config file is \"currency.xml\", the properties file is \"currency.xml.drift.properties\". This file is designed to work correctly with replication, and is updated by Solr whenever the currency config file is loaded.\n\nTo compute an accurate bounding range, it is necessary to compute the max and min \"historical composite exchange rates\". The \"historical\" refers to the fact that the historical max/min exchange rates are used instead of the current exchange rate. The \"composite\" refers to the fact that the max/min exchange rate is computed by taking the max/min of a composition of the max/min exchange rates between the source currency S, the target currency T, and all intermediate currencies Z. For example, to compute the max historical composite exchange rate between USD and EUR, take the max value of the the value x*y, where x is the max historical exchange rate between USD->Z, and y is the max historical exchange rate between Z->EUR, for all currencies Z.\n\nI made an attempt at proving mathematically that this historical composite exchange rate approach computes a minimal upper bound and maximal lower bound for the trie query. If necessary I can attach this proof.\n\nBeyond this, I added some additional intra-query caching and changed the query construction from the FilteredQuery approach (which seemed to be inefficient in leveraging the trie query) to the BooleanQuery. You'll note that I rely upon the second clause in the BooleanQuery being scored first, which eliminates the expensive exchange rate conversions from happening for documents that fall outside the trie range.\n\nI ran into a limitation of the current resource loader API, however, in that it does not allow access to creating or writing new resources, which is needed to maintain the drift properties file. For now, I only support SolrResourceLoader which writes to the local filesystem by extracting the config directory. However, the new ZkResourceLoader is not supported, for example. A non-fatal warning is emitted to the log when this occurs. The side effect of this is that currency exchange rate drift will not be tracked, resulting in incorrect range and point queries if the currency.xml file is updated. It would be nice if it were possible to ask the ResourceLoader for an OutputStream to a new resource for this purpose.\n\nSome limitations:\n\n\n\tThe default currency cannot be changed after the initial index, otherwise the index effectively is corrupt since the value for the trie bound is indexed in the default currency.\n\tLoss or corruption of the drift file will cause erroneous range and point queries (documents will be omitted from the results, though no incorrect documents will appear.)\n\tAs mentioned above, the only ResourceLoader supported are SolrResourceLoaders that respond to getConfigDir(). Please let me know if there is a safer, more canonical way to store and load Solr-maintained metadata that lives with the index.\n\n\n\nAlso note that this has been tested with replication. The only thing necessary for replication to work is that the currency.xml and currency.xml.drift.properties file be included as part of the replication. A limitation here is that if no documents are updated but the currency exchange rates change, the file will not be replicated due to Solr's policy of not replicating files without index changes. It would be useful to allow this behavior to be overridden. In our case this isn't a problem since our index churn is high enough that replication events happen regularly.\n\nIn the end these changes result in accurate currency range queries that perform nearly as fast as their non-currency counterparts.  "
        },
        {
            "author": "Greg Fodor",
            "id": "comment-12928310",
            "date": "2010-11-04T19:12:12+0000",
            "content": "Small bugfix for currency drift not considering asymmetric conversions correctly. "
        },
        {
            "author": "Greg Fodor",
            "id": "comment-12928650",
            "date": "2010-11-05T16:14:22+0000",
            "content": "Further testing on production datasets revealed that the use of the trie query, particularly in conjunction with the currency based scorer, yielded much poorer performance than simply computing the values directly using the field cache. (My guess is the reason for this is due to the low cardinality of price values in practical datasets.)\n\nSo, this patch rolls back a lot of the complexity of previous patches by removing the need to construct accurate trie bounds. This removes the entire \"currency drift\" properties file discussed above and also removes the incompatibility with the zookeeper resource loader.\n\nOther changes in this patch are improvements to the MoneyValueSource to improve performance through caching and removing boxing. "
        },
        {
            "author": "Greg Fodor",
            "id": "comment-12971386",
            "date": "2010-12-14T19:46:23+0000",
            "content": "Etsy has been running this patch in production for a little over a month now successfully. One issue is that reloading the currency.xml file requires a full core reload, which can cause live query performance to suffer. We're working on adding a request handler to handle this instead of waiting for schema change notifications for folks who need this optimization.\n\nThat said, the implementation appears correct, performant, and useful enough for our needs. I'd like to see if there are any outstanding TODOs for this to be seriously considered for inclusion into Solr. "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-13051955",
            "date": "2011-06-20T12:39:16+0000",
            "content": "Any interest in reviving this and work towards committing a first version? "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-13115375",
            "date": "2011-09-27T10:01:20+0000",
            "content": "Greg, do you have an updatet patch for this one? We'll help you get it the last mile for inclusion.\n\nPS: When uploading patches, we prefer that you name it SOLR-2202.patch every time. JIRA will automatically \"grey out\" the older versions for you. "
        },
        {
            "author": "Greg Fodor",
            "id": "comment-13115803",
            "date": "2011-09-27T18:56:49+0000",
            "content": "Hey Jan, awesome! The latest patch is the implementation we have been running in production for some time now. (We are on Solr trunk, however, and there were some small tweaks necessary to get it to build there.) One enhancement we are likely to make is the ability to reload the currency.xml file without reloading the Solr cores. If we can live without that feature, I think this should be good to go. \n\nIt's been quite a while since I have looked at this patch \u2013 please let me know if you find that it does not merge in or test properly with the current release of Solr. Also, let me know what I need to do documentation wise and so on. \n\nThanks a bunch, excited to see this come together! "
        },
        {
            "author": "Greg Fodor",
            "id": "comment-13115807",
            "date": "2011-09-27T19:02:07+0000",
            "content": "I will actually take a crack at merging this into Solr's latest release today. My guess is since it has been so long there are surely a few issues. "
        },
        {
            "author": "Steve Rowe",
            "id": "comment-13115837",
            "date": "2011-09-27T19:33:34+0000",
            "content": "Greg, there have been structural changes since your last patch; you can read about it in SOLR-2452.\n\nI committed a Perl script that can convert a patch against the old structure into a patch against the current structure.  You can find it in your working copy at: \n\ndev-tools/scripts/SOLR-2452.patch.hack.pl\n\n\nThere is an example of its use in a comment at the top of the script.\n\n "
        },
        {
            "author": "Greg Fodor",
            "id": "comment-13116269",
            "date": "2011-09-28T07:36:01+0000",
            "content": "Yeah, this patch is a total mess now. I will see if other engineers at Etsy have been maintaining it (I think they have, since we are on some variation of trunk.) If not, I'm sad to say I don't expect to be able to find time to clean it up and re-learn the internals I needed to learn to get it working anytime soon. "
        },
        {
            "author": "Greg Fodor",
            "id": "comment-13116290",
            "date": "2011-09-28T08:33:45+0000",
            "content": "I decided to roll up my sleeves, wasn't as bad as I thought! New patch attached, passes against trunk. "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-13116368",
            "date": "2011-09-28T12:11:41+0000",
            "content": "Great, Greg.\n\nThe patch now applies cleanly. I've tested it a bit and uploaded a new patch:\n\n\tAdded CHANGES.txt entry\n\tAdded <fieldType> and <dynamicField> entries to example schema\n\tAdded currency.xml to example config with real rates between USD and many currencies as well as cross-rates for GBP, EUR, NOK\n\tAdded money.xml in exampledocs/\n\n\n\nI also added a new Wiki page at http://wiki.apache.org/solr/MoneyFieldType trying to document. Plese review and change where I've got it wrong.\n\nAt the bottom of the Wiki page I've put some questions/TODOs which I couldn't figure out immediately:\n\n\tHow do decimals work? I.e. should USD values be entered including two decimals so that $1.00 is written as \"100,USD\" ?\n\tCan you return a value in another currency than what's indexed in the search result?\n\tRange facets do not work with this field type - this should be fixed\n\n\n\nI think it could be nice to switch the \"price\" field in the example schema over from float to \"money\", but that should wait until range facets work for money field type. "
        },
        {
            "author": "Greg Fodor",
            "id": "comment-13116638",
            "date": "2011-09-28T17:57:15+0000",
            "content": "Hey Jan, thanks for cleaning things up!\n\nTo answer your questions:\n\n\n\tYes, decimals should be encoded as 100,USD.\n\tNot as far as I know, the way we do this at Etsy is we do a conversion on the way out at render-time. This requires the frontend to have access to the same currency exchange rates as the search engine.\n\tCan you explain in a bit more detail what is required here? I'm not sure how to address this.\n\n "
        },
        {
            "author": "Greg Fodor",
            "id": "comment-13116647",
            "date": "2011-09-28T18:08:59+0000",
            "content": "I noticed a reference to currency.xml.drift.properties in the wiki. This drift idea was abandoned by me after realizing the performance was no good. Was there somewhere you saw this file cropping up? There should be no trace of it in the current patch. "
        },
        {
            "author": "Greg Fodor",
            "id": "comment-13116664",
            "date": "2011-09-28T18:20:51+0000",
            "content": "wiki updated to reflect the answers above "
        },
        {
            "author": "Simon Rosenthal",
            "id": "comment-13116722",
            "date": "2011-09-28T19:31:22+0000",
            "content": "One enhancement we are likely to make is the ability to reload the currency.xml file without reloading the Solr cores\n\nGreg:  I'm working on a patch to handle the more general case of reloading changed config files  ( stopwords.txt, synonyms.txt, etc.) without requiring a core reload. The class just needs to be resourceLoaderAware, which seems to be the case here.\n\nWill submit this patch for issue SOLR-1307. "
        },
        {
            "author": "Greg Fodor",
            "id": "comment-13116735",
            "date": "2011-09-28T19:47:38+0000",
            "content": "This is excellent news! Thanks a bunch. This is an issue we've been struggling with at Etsy and haven't had a chance to try to address appropriately.  "
        },
        {
            "author": "Lance Norskog",
            "id": "comment-13116897",
            "date": "2011-09-28T23:28:56+0000",
            "content": "+1 on getting this in. It's a cool feature that makes sense, but nobody would think of. (Ok, no American  ) "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-13117090",
            "date": "2011-09-29T07:38:09+0000",
            "content": "Greg,\nCan you explain in a bit more detail what is required here? I'm not sure how to address this.\nfacet.range can do range facets for numbers and dates. It would be natural to apply range facets to prices, but this does currently not work. Guess we should document it as a limitation, open a Jira for it and tackle it later. It doesn't make sense to operate on mixed currencies in a facet, so the faceting code would need to operate on a normalized currency, most naturally the defaultCurrency?\n\nAnother thing is that it would be sooo much more user friendly to allow decimal in the user-facing form, e.g. to be allowed to insert \"1.00,USD\" instead of \"100,USD\". Could we not allow this in the string-form of the input and stored version, but normalize it to whatever other internal format in the indexed version? "
        },
        {
            "author": "Greg Fodor",
            "id": "comment-13117387",
            "date": "2011-09-29T16:05:09+0000",
            "content": "Hm. It could be tricky to allow decimal input, no? Right now, there is no locale-specific code in this implementation, it's generic. If we allowed decimal input, we'd have to understand each locale and how to convert it to the internal format. For example, with decimal support, \"1,USD\" could mean \"100,USD\" or \"1,USD\", and we'd need to know for USD there are hundredths (cents), so we'd save 100. Am I misunderstanding? "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-13117639",
            "date": "2011-09-29T21:44:56+0000",
            "content": "I'm no currency expert, but it feels wrong to put this burden on the user (or front-end or Solr APIs for different programming languages) to know that inputting \"1\" means 0.01 for USD but means 1 for JPY? We're not talking locale support here, but a strict format with \".\" as decimal point: \"1.234,CCC\". Could not conversion from decimal form to internal integer form be done by the FieldType:\n\n\ndouble d = 1.2345;\nString c = \"USD\";\nlong l = Math.round(d*Math.pow(10.0,Currency.getInstance(c).getDefaultFractionDigits()));\n==> 123\n\n\n\nPerhaps I'm missing something here? "
        },
        {
            "author": "Greg Fodor",
            "id": "comment-13117648",
            "date": "2011-09-29T21:56:26+0000",
            "content": "Actually that makes sense. I was getting my wires crossed thinking this would be locale specific, not currency specific, which is OK. I will try to work this in. "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-13193155",
            "date": "2012-01-25T18:02:53+0000",
            "content": "Greg, I'm gonna look at this again and try to prepare a first candidate for committing to 3.x.\nWhat we have is already quite good I think!\n\nDo you have time to do the planned last changes? Do you need any help? "
        },
        {
            "author": "Greg Fodor",
            "id": "comment-13193208",
            "date": "2012-01-25T18:55:53+0000",
            "content": "Hey Jan, I can try to take a crack at it this week. The biggest issue right now is that if we change the indexing format we have to change our indexer at Etsy which is a very scary proposition.  "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-13193467",
            "date": "2012-01-26T00:22:31+0000",
            "content": "My biggest wish is human-friendly decimal support e.g. \"1.5,USD\". Are you sure you need to change the index format for this, perhaps enough to add some parse/display code?\n\nReloading config would be nice, but as there is a known workaround by reloading core it's not a blocker. "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-13193512",
            "date": "2012-01-26T01:59:34+0000",
            "content": "My biggest wish is human-friendly decimal support e.g. \"1.5,USD\". Are you sure you need to change the index format for this, perhaps enough to add some parse/display code?\n\nperhaps this is a good candidate for a DocTransformer \u2013 though it seems like something this is likely better done at the client end... "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-13193683",
            "date": "2012-01-26T09:25:08+0000",
            "content": "Updated patch which applies cleanly to current trunk. DocValues renamed to FunctionValues. Had to change an assert in testMoneyFieldType() to test for fields[i].numericValue() instead of fields[i].binaryValue() to get the test to pass. "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-13193688",
            "date": "2012-01-26T09:30:47+0000",
            "content": "Updated description, as it was a bit outdated "
        },
        {
            "author": "Greg Fodor",
            "id": "comment-13195393",
            "date": "2012-01-28T03:58:11+0000",
            "content": "Hey Jan, I took a crack at making your proposed change, but I'm afraid it seems to break the point query test. (Yet range queries strangely are OK.) I have no clue how this could be since the change to the parser seems pretty straightforward. Seems like a floating point rounding thing but I'm still very confused. Let me know if you have any ideas or if you want to go forward with the current version. I can try looking into it more but right now I'm fairly pressed for time. "
        },
        {
            "author": "Greg Fodor",
            "id": "comment-13195400",
            "date": "2012-01-28T04:11:44+0000",
            "content": "Success! I was calling parse() twice in the call chain for point queries, and that no longer works since it scales the value by the fraction digits 2x on the way in. Fixed patch is attached. "
        },
        {
            "author": "Greg Fodor",
            "id": "comment-13195405",
            "date": "2012-01-28T04:20:20+0000",
            "content": "Wiki updated "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-13195477",
            "date": "2012-01-28T10:10:09+0000",
            "content": "This is great! I'll see if I can test it a bit more next week, and see if I spot any bugs or improvements.\n\nThis will be a great addition.\nIt would be kind of nice to demo the fieldType in all the prices in the exampledocs. Then we need to change fieldType of the \"price\" field to MoneyType etc. Only problem then is that we cannot demo price range facets in /browse as we do now.\n\nDo anyone know what it takes to make range facets work with this field type?\n\nAnd a minor one: Why do we call the class MoneyType? All the other fields are called XxxField (except for the LatLonType and PointType). Is this intentional. To me it would sound even better with \"CurrencyField\"  "
        },
        {
            "author": "Greg Fodor",
            "id": "comment-13199198",
            "date": "2012-02-02T20:41:49+0000",
            "content": "I have no problems with renaming it \u2013 at the time I started the patch LatLonType and PointType were the polyfields I saw in the repo \u2013 at this point so much has probably changed naming things appropriately makes sense. Let me know if this is a patch you'd like me to do or if you want to take it from here. Thanks Jan! "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-13199231",
            "date": "2012-02-02T21:15:31+0000",
            "content": "Other opinions on the naming? Or other blockers for committing? I have not tested the latest change regarding decimal point support yet but will try to soon... "
        },
        {
            "author": "Greg Fodor",
            "id": "comment-13210538",
            "date": "2012-02-17T20:46:12+0000",
            "content": "Any updates on this?  "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-13210893",
            "date": "2012-02-18T10:41:59+0000",
            "content": "Had no chance to get back to this yet. Afraid I won't have time next week either \n\nIn the mean time, perhaps other committers could chime in with their views on preferred naming?\na) MoneyType\nb) MoneyField\nc) CurrencyType\nd) CurrencyField\n\nAs for range facets, I'll open a new issue once the basics for this is committed. "
        },
        {
            "author": "Erik Hatcher",
            "id": "comment-13215607",
            "date": "2012-02-24T13:48:25+0000",
            "content": "d) CurrencyField - that's more consistent with the likes of TextField, StrField, etc.  We have some new field types that suffix with \"Type\", but they're the exception rather than the norm.  I prefer the term Currency over the less formal Money. "
        },
        {
            "author": "Andrew Morrison",
            "id": "comment-13215675",
            "date": "2012-02-24T15:28:47+0000",
            "content": "Hello Jan.\n\nI've attached a patch against https://svn.apache.org/repos/asf/lucene/dev/trunk@1220795 that adds the ability to do range faceting. I'd be happy to move this to another ticket and clean it up. "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13225493",
            "date": "2012-03-08T20:57:21+0000",
            "content": "a) CurrencyField (and by extension \"CurrencyValue\") gets my vote\n\nb) i really only reviewed the facet stuff in SOLR-2202-solr-10.patch (i know Jan has already been reviewing the more core stuff about the type) ... it makes me realize that we really need to refactor the range faceting code to be easier to do in custom FieldTypes, but that's certainly no fault of this issue and can be done later.\n\nThe facet code itself looks correct but my one concern is that (if i'm understanding all of this MoneyValue conversion stuff correctly) it should be possible to facet with start/end/gap values specified in any currency, as long as they are all consistent \u2013 but there is not test of this situation.  the negative test only looks at using an inconsistent gap, and the positive tests only use USD, or the \"default\" which is also USD.  We should have at least one test that uses something like EUR for start/end/gap and verifies that the counts are correct given the conversion rates used in the test.\n\nincidentally: I don't see anything actually enforcing that start/end are in the same currency \u2013 just that gap is in the same currency as the values it's being added to, so essentially that start and gap use hte same currenty.  But I'm actually not at all clear on why there is any attempt to enforce that the currencies used are the same, since the whole point of the type (as i understand it) is that you can do conversions on the fly \u2013 it may seem silly for someone to say facet.range.start=0,USD & facet.range.gap=200,EUR & facet.range.end=1000,YEN but is there any technical reason why we can't let them do that? "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-13225589",
            "date": "2012-03-08T22:09:42+0000",
            "content": "New patch (without faceting).\n\n\tRenamed to CurrencyField\n\tFixed bug when default type missing in document\n\tAdded a copyField from price to price_c in schema\n\tVarious cleanup\n\n\n\nI think this is more or less ready "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-13225595",
            "date": "2012-03-08T22:13:30+0000",
            "content": "Andrew, please see SOLR-3218 for faceting support.\nI suggest we first commit this basic field type for Solr3.6, and then add faceting support "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-13226098",
            "date": "2012-03-09T14:35:51+0000",
            "content": "I have a new patch ready soon. It\n\n\thas truly pluggable ExchangeRateProvider through new param exchangeRateProvider on fieldType\n\tpulls out ExchangeRateProvider interface into its own file, with init(), reload(), inform() and list() methods\n\treading and parsing of config file delegated to FileExchangeRateProvider\n\tcleans up static strings into constants\n\tnormalizes stored value when currency missing i.e. an input of \"3.5\" would be \"3.5,USD\" if USD is default currency\n\tadds ASL license headers to all new files\n\treverts schema field \"price\" back to \"float\" for backward compat\n\tremoves defaultCurrency param from <field> definition and adds it to <fieldType>\n\n\n\nActually, defaultCurrency param does not work at all on <field> level. Any ideas on how it could be made working?\nWe should create a test with a different ExchangeRateProvider plugin just to prove that it works.. "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-13226101",
            "date": "2012-03-09T14:38:50+0000",
            "content": "Here's the patch "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-13226132",
            "date": "2012-03-09T15:24:58+0000",
            "content": "New patch:\n\n\tAdded MockExchangeRateProvider with hardcoded rates\n\tAdded fieldType and field for mock provider in test-schema\n\tAdded test case validating mock provider\n\n "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-13226178",
            "date": "2012-03-09T16:26:31+0000",
            "content": "Some further tests added and fixed bug in listAvailableCurrencies(). Also now printing the price_c value instead of price in Velocity \"/browse\" template, looks nice \n\nI plan to commit this to trunk shortly and start backporting to 3.x. "
        },
        {
            "author": "Greg Fodor",
            "id": "comment-13226321",
            "date": "2012-03-09T18:57:37+0000",
            "content": "Great! Thanks for the cleanup work  "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-13226557",
            "date": "2012-03-09T22:41:18+0000",
            "content": "Committed to trunk. Now go start building ExchangeRateProviders  "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-13226796",
            "date": "2012-03-10T08:24:42+0000",
            "content": "Backport from SOLR-3228 committed to branch_3x "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-13226807",
            "date": "2012-03-10T09:45:05+0000",
            "content": "Updated Wiki: http://wiki.apache.org/solr/CurrencyField "
        },
        {
            "author": "Koji Sekiguchi",
            "id": "comment-13226997",
            "date": "2012-03-11T06:08:39+0000",
            "content": "Reopening, as CurrencyField depends on the definition \"tlong\" in schema.xml and I don't think it is a good idea.\n\nIf tlong fieldType is not there, I got NPE.\n\nCurrencyField.java\nprotected static final String FIELD_TYPE_CURRENCY         = \"string\";\nprotected static final String FIELD_TYPE_AMOUNT_RAW       = \"tlong\";\n\n "
        },
        {
            "author": "Koji Sekiguchi",
            "id": "comment-13226998",
            "date": "2012-03-11T06:10:58+0000",
            "content": "A draft patch which hasn't been tested yet. "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-13227021",
            "date": "2012-03-11T08:59:48+0000",
            "content": "Agree, it should be possible to create a schema with only one \"currency\" field in it. Thanks for the patch. "
        },
        {
            "author": "Koji Sekiguchi",
            "id": "comment-13227037",
            "date": "2012-03-11T12:15:30+0000",
            "content": "My patch introduces another NPE problem (try to go to schema browser, for example) because \"tlong\" field which is created in init() method lacks some required properties (e.g. typeName).\n\nI don't like the idea of hard coding to construct tlong object, how about introducing an attribute something like \"subFieldType\", that the way of currently AbstractSubTypeFieldType does?\n\n\"subFieldType\" is set to tlong as default is ok I think this time, as we can throw SolrException if the sub type doesn't exist, like AbstractSubTypeFieldType does. "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-13227206",
            "date": "2012-03-11T19:13:00+0000",
            "content": "Here's a patch based on Koji's, independent from other schema fields. We create the two fields, with omitNorms=true and we now also allow precisionStep to be specified, which will be passed on to the TrieLong. All tests pass.\n\nI don't think anyone will need the extra configurability of choosing other fieldTypes. If such a request comes, we can easily add it later. "
        },
        {
            "author": "Koji Sekiguchi",
            "id": "comment-13227330",
            "date": "2012-03-12T06:02:43+0000",
            "content": "Patch looks good! "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-13227408",
            "date": "2012-03-12T10:25:01+0000",
            "content": "Fix checked in to trunk and branch_3x. We now do not rely on other fieldTypes in schema, and we can control precisionStep for the TrieLong. Wiki updated. "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-13241616",
            "date": "2012-03-29T20:54:57+0000",
            "content": "This patch backports the ExchangeRateProvider interface stabilizations and class loader fixes checked in to TRUNK as part of SOLR-3255. This should now be a good basis for coding new providers. "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-13241620",
            "date": "2012-03-29T20:57:45+0000",
            "content": "Checked in stabilization patch to branch_3x "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13241998",
            "date": "2012-03-30T01:31:02+0000",
            "content": "I can't seem to run a lot of tests from IntelliJ after this.\n\n\nCaused by: java.lang.RuntimeException: Can't find resource 'open-exchange-rates.json' in classpath or '/opt/code/lusolr/solr/build/solr-idea/classes/test/solr/conf/', cwd=/opt/code/lusolr\n\tat org.apache.solr.core.SolrResourceLoader.openResource(SolrResourceLoader.java:293)\n\tat org.apache.solr.schema.OpenExchangeRatesOrgProvider.reload(OpenExchangeRatesOrgProvider.java:126)\n\n\n$ find . -name open-exchange-rates.json\n./build/solr-core/test-files/solr/conf/open-exchange-rates.json\n./core/src/test-files/solr/conf/open-exchange-rates.json\n\n\n\n\nAnyone else? "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-13242129",
            "date": "2012-03-30T07:28:26+0000",
            "content": "I think this rather could be something related to the latest checkin for SOLR-3255 ?\nThe test \"OpenExchangeRatesOrgProviderTest\" depends on the file \"open-exchange-rates.json\" in test-files/solr/conf. It appears that SolrResourceLoader does not look there when you run tests from IntelliJ? "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-13242813",
            "date": "2012-03-30T22:30:01+0000",
            "content": "Looks like all of the files are in \n./build/solr-idea/classes/test/solr/conf\nexcept for one... the .json file.  It's either not being copied in the first place, or it's being deleted somehow. "
        },
        {
            "author": "Chris Male",
            "id": "comment-13242858",
            "date": "2012-03-30T23:52:38+0000",
            "content": "Is it that your Compiler settings in IntelliJ don't include .json files? That is usually my first goto when a file with an exotic extension isn't getting copied into the build space. "
        },
        {
            "author": "Steve Rowe",
            "id": "comment-13242865",
            "date": "2012-03-30T23:57:57+0000",
            "content": "Is it that your Compiler settings in IntelliJ don't include .json files? That is usually my first goto when a file with an exotic extension isn't getting copied into the build space.\n\nYes, this was the problem.  I committed a fix to both trunk and branch_3x after Yonik asked me about the problem on #lucene-dev IRC. "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-13243209",
            "date": "2012-03-31T16:21:25+0000",
            "content": "Thanks for sorting this out! "
        }
    ]
}