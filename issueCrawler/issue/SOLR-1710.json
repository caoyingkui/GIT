{
    "id": "SOLR-1710",
    "title": "convert worddelimiterfilter to new tokenstream API",
    "details": {
        "affect_versions": "None",
        "status": "Closed",
        "fix_versions": [
            "3.1"
        ],
        "components": [
            "Schema and Analysis"
        ],
        "type": "Improvement",
        "priority": "Major",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "This one was a doozy, attached is a patch to convert it to the new tokenstream API.\n\nSome of the logic was split into WordDelimiterIterator (exposes a BreakIterator-like api for iterating subwords)\nthe filter is much more efficient now, no cloning.\n\nbefore applying the patch, copy the existing WordDelimiterFilter to OriginalWordDelimiterFilter\nthe patch includes a testcase (TestWordDelimiterBWComp) which generates random strings from various subword combinations.\nFor each random string, it compares output against the existing WordDelimiterFilter for all 512 combinations of boolean parameters.\n\nNOTE: due to bugs found (SOLR-1706), this currently only tests 256 of these combinations. The bugs discovered in SOLR-1706 are fixed here.",
    "attachments": {
        "SOLR-1710-readable.patch": "https://issues.apache.org/jira/secure/attachment/12429851/SOLR-1710-readable.patch",
        "SOLR-1710.patch": "https://issues.apache.org/jira/secure/attachment/12429745/SOLR-1710.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Robert Muir",
            "id": "comment-12798208",
            "date": "2010-01-08T22:25:46+0000",
            "content": "for the 'wdf is only modifying single word with punctuation', don't clearAttributes() if its the first token, even though its modified... unless preserveOriginal is on (in this case the preserved original contained the attributes already, and we must clear).\n\nthis is a little confusing since the behavior for custom attributes depends on this preserveOriginal value, but i think it makes sense. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12798234",
            "date": "2010-01-08T23:12:11+0000",
            "content": "For each random string, it compares output against the existing WordDelimiterFilter for all 512 combinations of boolean parameters\n\nWhew... nice thorough work. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-12798239",
            "date": "2010-01-08T23:16:18+0000",
            "content": "Yonik, thanks. Again i have a hesitation: the SOLR-1706 problem.\n\nIf i could fix this bug in the original code, i would be able to enable the problematic combinations in backwards testing:\n\n\tcatenateNumbers != catenateWords\n\tgenerateWordParts != generateNumberParts\n\n\n\nI was unable to figure this one out though, so excluding these from the test makes me a little nervous... what is there to do?  "
        },
        {
            "author": "Chris Male",
            "id": "comment-12798240",
            "date": "2010-01-08T23:18:18+0000",
            "content": "Hi,\n\nI notice in the patch that it references OriginalWordDelimiterFilter in TestWordDelimiterBWComp.  Is this an error?\n\nCheers "
        },
        {
            "author": "Robert Muir",
            "id": "comment-12798241",
            "date": "2010-01-08T23:20:42+0000",
            "content": "Chris, not really, if you see the description i say:\nbefore applying the patch, rename the existing WordDelimiterFilter to OriginalWordDelimiterFilter\n\nI guess this should say instead: make a copy of... I will fix.\n\nobviously OriginalWordDelimiterFilter should not be committed, nor this random test that compares results against it.\n\nbut for now its convenient while working the issue to simply blast random strings against the old filter for testing. "
        },
        {
            "author": "Chris Male",
            "id": "comment-12798245",
            "date": "2010-01-08T23:23:18+0000",
            "content": "Ah right, sorry missed that description. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-12798248",
            "date": "2010-01-08T23:29:30+0000",
            "content": "Chris, no problem, I created this confusion until the patch is OK'ed.\n\nonce this happens, i can include some additional testcases that I had problems with.\ni have all 7 revisions i made of this filter locally so i can see which scenarios fail on each previous iteration, I think these are good tests. "
        },
        {
            "author": "Chris Male",
            "id": "comment-12798260",
            "date": "2010-01-09T00:08:35+0000",
            "content": "I am working with this patch with the goal of simplifying its logic and increasing readability.  Seems great thus far though. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-12798261",
            "date": "2010-01-09T00:13:24+0000",
            "content": "thanks in advance chris, I will help with testing and benchmarking anything you can do. \nI think i may have taken it as far as I can go, my head almost exploded. "
        },
        {
            "author": "Chris Male",
            "id": "comment-12798266",
            "date": "2010-01-09T00:33:18+0000",
            "content": "Just wondering what the return type of WordDelimiterIterator#next() supposed to indicate? I see that it either returns the end index, or DONE but this value never seems to be used by the filter.  Does it have a role? "
        },
        {
            "author": "Robert Muir",
            "id": "comment-12798268",
            "date": "2010-01-09T00:40:36+0000",
            "content": "chris yeah, its supposed to be similar to http://java.sun.com/j2se/1.4.2/docs/api/java/text/BreakIterator.html#next%28%29\n\ni started by mimicing this api somewhat, i guess a future improvement would be if somehow this truly was a real BreakIterator.\nThen say, you could create a RuleBasedBreakIterator or DictionaryBasedBreakIterator (which are fast compiled DFAs), and customize how words are delimited.\ncurrently, you can only do this with by customizing the charTypeTable, which cannot take any context into account, so its rather limited.\n\nall of the above is really just theoretical and not anything we should worry about, for practical purposes i mimiced BreakIterator api (but diverged somewhat), just because I am used to working with it and found it was one way to separate a lot of the logic. "
        },
        {
            "author": "Chris Male",
            "id": "comment-12798502",
            "date": "2010-01-10T16:44:43+0000",
            "content": "Attaching a first pass at improving the readability of this code.  \n\nFocused mostly on breaking up #incrementToken, extracting common behavior into helper methods, documenting each method, putting fields in a consistent place, trimming if else statement blocks etc etc.\n\nI imagine there might be a small performance improvement due to these improvements, but they could have all been done by the compiler too. "
        },
        {
            "author": "Chris Male",
            "id": "comment-12798539",
            "date": "2010-01-10T19:54:00+0000",
            "content": "Updated patch with method name changes.  doXYZ is now shouldXYZ and writeClear is now writeAndClear "
        },
        {
            "author": "Robert Muir",
            "id": "comment-12850605",
            "date": "2010-03-27T23:23:05+0000",
            "content": "This was resolved in revision 922957. "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-13013225",
            "date": "2011-03-30T15:45:55+0000",
            "content": "Bulk close for 3.1.0 release "
        }
    ]
}