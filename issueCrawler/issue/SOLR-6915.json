{
    "id": "SOLR-6915",
    "title": "SaslZkACLProvider and Kerberos Test Using MiniKdc",
    "details": {
        "components": [
            "SolrCloud"
        ],
        "type": "Improvement",
        "labels": "",
        "fix_versions": [
            "5.1",
            "6.0"
        ],
        "affect_versions": "None",
        "status": "Closed",
        "resolution": "Fixed",
        "priority": "Major"
    },
    "description": "We should provide a ZkACLProvider that requires SASL authentication.  This provider will be useful for administration in a kerberos environment.   In such an environment, the administrator wants solr to authenticate to zookeeper using SASL, since this is only way to authenticate with zookeeper via kerberos.\n\nThe authorization model in such a setup can vary, e.g. you can imagine a scenario where solr owns (is the only writer of) the non-config znodes, but some set of trusted users are allowed to modify the configs.  It's hard to predict all the possibilities here, but one model that seems generally useful is to have a model where solr itself owns all the znodes and all actions that require changing the znodes are routed to Solr APIs.  That seems simple and reasonable as a first version.\n\nAs for testing, I noticed while working on SOLR-6625 that we don't really have any infrastructure for testing kerberos integration in unit tests.  Internally, I've been testing using kerberos-enabled VM clusters, but this isn't great since we won't notice any breakages until someone actually spins up a VM.  So part of this JIRA is to provide some infrastructure for testing kerberos at the unit test level (using Hadoop's MiniKdc, HADOOP-9848).",
    "attachments": {
        "fail.log": "https://issues.apache.org/jira/secure/attachment/12691961/fail.log",
        "SOLR-6915.patch": "https://issues.apache.org/jira/secure/attachment/12691461/SOLR-6915.patch",
        "tests-failures.txt": "https://issues.apache.org/jira/secure/attachment/12693891/tests-failures.txt"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2015-01-10T01:27:00+0000",
            "author": "Gregory Chanan",
            "content": "Here's a patch implementing the ACLProvider and a test.\n\nNotes:\n1) the MiniKdc in hadoop didn't come in until hadoop 2.3.0, so I upgraded the dependency version\n2) As the test demonstrates, you don't need to provide a CredentialsProvider to get the sasl authentication; modifying the javax.security Configuration takes care of that\n3) ZooKeeper maintains a static collection of AuthenticationProviders.  Thus, if we don't add the SASLAuthenticationProvider to the system properties the first time we spin up a zookeeper, we won't ever be able to use Sasl, even if it's in a subsequent test in the same jvm.  So, we now set this up in ZkTestServer.\n4) For the apache directory server dependency, I used apacheds-all, rather than picking the individual components we need.  If we picked the individual components we'd save ~33% of the size of the jar for the complexity of maintaining all the version, licenses/noticies/etc.  I can go either way with that. ",
            "id": "comment-14272205"
        },
        {
            "date": "2015-01-11T20:01:17+0000",
            "author": "Mark Miller",
            "content": "+1, looks great.\n\nComments:\n\nMight be worth calling out the hadoop version update in it's own issue.\n\nRemember to make sure those new sha files go up with eol-syle:native properties for precommit. ",
            "id": "comment-14273038"
        },
        {
            "date": "2015-01-12T22:48:17+0000",
            "author": "Gregory Chanan",
            "content": "Here's a version without the hadoop upgrade diffs, which have been committed in SOLR-6963. ",
            "id": "comment-14274320"
        },
        {
            "date": "2015-01-13T02:04:00+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1651264 from gchanan@apache.org in branch 'dev/trunk'\n[ https://svn.apache.org/r1651264 ]\n\nSOLR-6915: SaslZkACLProvider and Kerberos Test Using MiniKdc ",
            "id": "comment-14274590"
        },
        {
            "date": "2015-01-13T02:18:21+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1651266 from gchanan@apache.org in branch 'dev/branches/branch_5x'\n[ https://svn.apache.org/r1651266 ]\n\nSOLR-6915: SaslZkACLProvider and Kerberos Test Using MiniKdc ",
            "id": "comment-14274605"
        },
        {
            "date": "2015-01-13T02:18:59+0000",
            "author": "Gregory Chanan",
            "content": "Thanks for the review Mark, committed to 5.0 and trunk. ",
            "id": "comment-14274606"
        },
        {
            "date": "2015-01-13T15:15:23+0000",
            "author": "Mark Miller",
            "content": "I'm seeing a lot of failures of SsaslZkACLProviderTest - it's pretty consistent on my jenkins machine and I've seen it in the jenkins cluster emails.\n\nWe are getting connection loss in this setup call easily for some reason - and it should be retrying on connection loss so I am not sure what is up yet.\n\n\norg.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /solr\n\tat __randomizedtesting.SeedInfo.seed([75A11210F50D7764:715544C86C49D46A]:0)\n\tat org.apache.zookeeper.KeeperException.create(KeeperException.java:99)\n\tat org.apache.zookeeper.KeeperException.create(KeeperException.java:51)\n\tat org.apache.zookeeper.ZooKeeper.exists(ZooKeeper.java:1045)\n\tat org.apache.solr.common.cloud.SolrZkClient$4.execute(SolrZkClient.java:293)\n\tat org.apache.solr.common.cloud.SolrZkClient$4.execute(SolrZkClient.java:290)\n\tat org.apache.solr.common.cloud.ZkCmdExecutor.retryOperation(ZkCmdExecutor.java:61)\n\tat org.apache.solr.common.cloud.SolrZkClient.exists(SolrZkClient.java:290)\n\tat org.apache.solr.common.cloud.SolrZkClient.makePath(SolrZkClient.java:485)\n\tat org.apache.solr.common.cloud.SolrZkClient.makePath(SolrZkClient.java:402)\n\tat org.apache.solr.cloud.SaslZkACLProviderTest.setUp(SaslZkACLProviderTest.java:80)\n\n ",
            "id": "comment-14275350"
        },
        {
            "date": "2015-01-13T15:28:43+0000",
            "author": "Mark Miller",
            "content": "On my jenkins machine, I'm seeing it pretty consistently on 5x but not at all on trunk. ",
            "id": "comment-14275378"
        },
        {
            "date": "2015-01-13T15:48:33+0000",
            "author": "Mark Miller",
            "content": "I've attached a fail log.\n\nAre these exceptions expected?\n\n\noazs.NIOServerCnxnFactory.run WARN Ignoring unexpected runtime exception java.security.AccessControlException: access denied (\"javax.security.auth.PrivateCredentialPermission\" \"javax.security.auth.kerberos.KeyTab\" \"read\")\n\n ",
            "id": "comment-14275422"
        },
        {
            "date": "2015-01-13T16:07:27+0000",
            "author": "Mark Miller",
            "content": "Yeah, I don't see all that logging in a clean local run. It looks like we may have to add that permission as an exception as well? But why isn't that a consistent issue? ",
            "id": "comment-14275453"
        },
        {
            "date": "2015-01-13T16:41:00+0000",
            "author": "Gregory Chanan",
            "content": "Interesting \u2013 have you seen it at all on trunk yet?  We should probably just add it for now and I'll investigate in the background. ",
            "id": "comment-14275511"
        },
        {
            "date": "2015-01-13T17:00:13+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1651407 from Mark Miller in branch 'dev/trunk'\n[ https://svn.apache.org/r1651407 ]\n\nSOLR-6915: Add javax.security.auth.kerberos.KeyTab read permissions. ",
            "id": "comment-14275539"
        },
        {
            "date": "2015-01-13T17:00:41+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1651409 from Mark Miller in branch 'dev/branches/branch_5x'\n[ https://svn.apache.org/r1651409 ]\n\nSOLR-6915: Add javax.security.auth.kerberos.KeyTab read permissions. ",
            "id": "comment-14275541"
        },
        {
            "date": "2015-01-13T17:03:08+0000",
            "author": "Mark Miller",
            "content": "have you seen it at all on trunk yet? \n\nI have not yet, but I've only looked at one or two of the fails from the jenkins cluster.\n\nOn my local jenkins it has failed 5 out of 5 on 5x and passed about the same on trunk. On my dev box (same sim env as jenkins box) 5x tests seem to run fine. ",
            "id": "comment-14275547"
        },
        {
            "date": "2015-01-13T20:34:17+0000",
            "author": "Mark Miller",
            "content": "A bit of whack a mole I guess - now this one pops up: access denied (\"javax.security.auth.PrivateCredentialPermission\" \"sun.security.jgss.krb5.Krb5Util$KeysFromKeyTab\" \"read\") ",
            "id": "comment-14275890"
        },
        {
            "date": "2015-01-13T20:56:25+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1651487 from Mark Miller in branch 'dev/trunk'\n[ https://svn.apache.org/r1651487 ]\n\nSOLR-6915: Add KeysFromKeyTab read permissions. ",
            "id": "comment-14275927"
        },
        {
            "date": "2015-01-13T20:58:40+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1651488 from Mark Miller in branch 'dev/branches/branch_5x'\n[ https://svn.apache.org/r1651488 ]\n\nSOLR-6915: Add KeysFromKeyTab read permissions. ",
            "id": "comment-14275931"
        },
        {
            "date": "2015-01-13T21:29:47+0000",
            "author": "Gregory Chanan",
            "content": "That last addition makes me nervous \u2013 do we test on other jvms?  For example, see this code in hadoop: https://github.com/apache/hadoop/blob/5fdcc3f360552a21eb1402a6253d32f012956959/src/core/org/apache/hadoop/security/SecurityUtil.java#L152-L159\n\nwhich suggests we need a different class for ibm jvms.  I noticed this code is gone in later hadoop versions, so maybe there is a better way. ",
            "id": "comment-14275975"
        },
        {
            "date": "2015-01-13T21:32:25+0000",
            "author": "Mark Miller",
            "content": "I'm not too concerned about that in the short term - I'm just going to add perms until it's passing and we can figure out what is actually happening. ",
            "id": "comment-14275980"
        },
        {
            "date": "2015-01-13T21:39:24+0000",
            "author": "Mark Miller",
            "content": "Okay, the test now passes on 5x on my jenkins box:\n\n\n   [junit4] Suite: org.apache.solr.cloud.SaslZkACLProviderTest\n   [junit4] Completed on J0 in 24.26s, 1 test\n\n ",
            "id": "comment-14275991"
        },
        {
            "date": "2015-01-13T23:41:32+0000",
            "author": "Gregory Chanan",
            "content": "Thanks Mark!\n\nI was able to reproduce with failures on my local machine on jdk7, so it appears to be a jdk7 vs jdk8 issue.  Your patches fixed the issue for me as well.  This java bug seems at least related to what we are seeing: http://bugs.java.com/bugdatabase/view_bug.do?bug_id=8004488 (explains Krb5Util I think, not sure about the KeyTab permission).\n\nI also tried an ibm jdk, given my above comment and it failed before getting to the permission checks.  It seems like the JAAS configuration needs to be a bit different on an IBM jdk.  I'll investigate and report back. ",
            "id": "comment-14276210"
        },
        {
            "date": "2015-01-14T19:03:57+0000",
            "author": "Mark Miller",
            "content": "Here is a different intermittent interesting fail (log attached). ",
            "id": "comment-14277459"
        },
        {
            "date": "2015-01-14T20:19:57+0000",
            "author": "Gregory Chanan",
            "content": "Thanks Mark, I'll take a look at that as well.\n\nI investigated the IBM jvm issue a bit; it looks like the JAAS format required is different; i.e. useKeyTab (\"true\") vs useKeytab (file://path/to/keytab).  I seem to have gotten past that issue but the test is still failing for me on an IBM jvm. ",
            "id": "comment-14277602"
        },
        {
            "date": "2015-01-14T21:15:30+0000",
            "author": "Mark Miller",
            "content": "Cool - I wouldn't worry too much more about it. There is some assume you can use to skip the test on IBM jvms - I believe there are some tests that already do this. ",
            "id": "comment-14277695"
        },
        {
            "date": "2015-01-22T14:33:57+0000",
            "author": "Shalin Shekhar Mangar",
            "content": "I saw a failure locally on this test. The logs are attached.\n\nI am able to reproduce the failure on linux and macos on trunk with jdk8 with the following:\n\nant test  -Dtestcase=SaslZkACLProviderTest -Dtests.method=testSaslZkACLProvider -Dtests.seed=69C665DFFD76343A -Dtests.slow=true -Dtests.locale=th_TH_TH_#u-nu-thai -Dtests.timezone=GMT0 -Dtests.asserts=true -Dtests.file.encoding=US-ASCII\n\n\n\n\n[junit4] ERROR   3.05s J3 | SaslZkACLProviderTest.testSaslZkACLProvider <<<\n   [junit4]    > Throwable #1: java.lang.RuntimeException: org.apache.directory.api.ldap.model.exception.LdapOtherException: org.apache.directory.api.ldap.model.exception.LdapOtherException: ERR_04447_CANNOT_NORMALIZE_VALUE Cannot normalize the wrapped value ERR_04473_NOT_VALID_VALUE Not a valid value '20090818022733Z' for the AttributeType 'ATTRIBUTE_TYPE ( 1.3.6.1.4.1.18060.0.4.1.2.35\n   [junit4]    >  NAME 'schemaModifyTimestamp'\n   [junit4]    >  DESC time which schema was modified\n   [junit4]    >  SUP modifyTimestamp\n   [junit4]    >  EQUALITY generalizedTimeMatch\n   [junit4]    >  ORDERING generalizedTimeOrderingMatch\n   [junit4]    >  SYNTAX 1.3.6.1.4.1.1466.115.121.1.24\n   [junit4]    >  USAGE directoryOperation\n   [junit4]    >  )\n   [junit4]    > '\n   [junit4]    > \tat org.apache.solr.cloud.SaslZkACLProviderTest$SaslZkTestServer.run(SaslZkACLProviderTest.java:204)\n   [junit4]    > \tat org.apache.solr.cloud.SaslZkACLProviderTest.setUp(SaslZkACLProviderTest.java:74)\n   [junit4]    > \tat java.lang.Thread.run(Thread.java:745)\n   [junit4]    > Caused by: org.apache.directory.api.ldap.model.exception.LdapOtherException: org.apache.directory.api.ldap.model.exception.LdapOtherException: ERR_04447_CANNOT_NORMALIZE_VALUE Cannot normalize the wrapped value ERR_04473_NOT_VALID_VALUE Not a valid value '20090818022733Z' for the AttributeType 'ATTRIBUTE_TYPE ( 1.3.6.1.4.1.18060.0.4.1.2.35\n   [junit4]    >  NAME 'schemaModifyTimestamp'\n   [junit4]    >  DESC time which schema was modified\n   [junit4]    >  SUP modifyTimestamp\n   [junit4]    >  EQUALITY generalizedTimeMatch\n   [junit4]    >  ORDERING generalizedTimeOrderingMatch\n   [junit4]    >  SYNTAX 1.3.6.1.4.1.1466.115.121.1.24\n   [junit4]    >  USAGE directoryOperation\n   [junit4]    >  )\n   [junit4]    > '\n   [junit4]    > \tat org.apache.directory.server.core.api.partition.AbstractPartition.initialize(AbstractPartition.java:84)\n   [junit4]    > \tat org.apache.directory.server.core.DefaultDirectoryService.initialize(DefaultDirectoryService.java:1808)\n   [junit4]    > \tat org.apache.directory.server.core.DefaultDirectoryService.startup(DefaultDirectoryService.java:1248)\n   [junit4]    > \tat org.apache.hadoop.minikdc.MiniKdc.initDirectoryService(MiniKdc.java:375)\n   [junit4]    > \tat org.apache.hadoop.minikdc.MiniKdc.start(MiniKdc.java:310)\n   [junit4]    > \tat org.apache.solr.cloud.SaslZkACLProviderTest$SaslZkTestServer.run(SaslZkACLProviderTest.java:197)\n   [junit4]    > \t... 39 more\n   [junit4]    > Caused by: java.lang.RuntimeException: org.apache.directory.api.ldap.model.exception.LdapOtherException: ERR_04447_CANNOT_NORMALIZE_VALUE Cannot normalize the wrapped value ERR_04473_NOT_VALID_VALUE Not a valid value '20090818022733Z' for the AttributeType 'ATTRIBUTE_TYPE ( 1.3.6.1.4.1.18060.0.4.1.2.35\n   [junit4]    >  NAME 'schemaModifyTimestamp'\n   [junit4]    >  DESC time which schema was modified\n   [junit4]    >  SUP modifyTimestamp\n   [junit4]    >  EQUALITY generalizedTimeMatch\n   [junit4]    >  ORDERING generalizedTimeOrderingMatch\n   [junit4]    >  SYNTAX 1.3.6.1.4.1.1466.115.121.1.24\n   [junit4]    >  USAGE directoryOperation\n   [junit4]    >  )\n   [junit4]    > '\n   [junit4]    > \tat org.apache.directory.server.core.api.schema.SchemaPartition.doInit(SchemaPartition.java:226)\n   [junit4]    > \tat org.apache.directory.server.core.api.partition.AbstractPartition.initialize(AbstractPartition.java:79)\n   [junit4]    > \t... 44 more\n   [junit4]    > Caused by: org.apache.directory.api.ldap.model.exception.LdapOtherException: ERR_04447_CANNOT_NORMALIZE_VALUE Cannot normalize the wrapped value ERR_04473_NOT_VALID_VALUE Not a valid value '20090818022733Z' for the AttributeType 'ATTRIBUTE_TYPE ( 1.3.6.1.4.1.18060.0.4.1.2.35\n   [junit4]    >  NAME 'schemaModifyTimestamp'\n   [junit4]    >  DESC time which schema was modified\n   [junit4]    >  SUP modifyTimestamp\n   [junit4]    >  EQUALITY generalizedTimeMatch\n   [junit4]    >  ORDERING generalizedTimeOrderingMatch\n   [junit4]    >  SYNTAX 1.3.6.1.4.1.1466.115.121.1.24\n   [junit4]    >  USAGE directoryOperation\n   [junit4]    >  )\n   [junit4]    > '\n   [junit4]    > \tat org.apache.directory.server.core.api.partition.AbstractPartition.initialize(AbstractPartition.java:84)\n   [junit4]    > \tat org.apache.directory.server.core.api.schema.SchemaPartition.doInit(SchemaPartition.java:219)\n   [junit4]    > \t... 45 more\n   [junit4]    > Caused by: org.apache.directory.api.ldap.model.exception.LdapInvalidAttributeValueException: ERR_04447_CANNOT_NORMALIZE_VALUE Cannot normalize the wrapped value ERR_04473_NOT_VALID_VALUE Not a valid value '20090818022733Z' for the AttributeType 'ATTRIBUTE_TYPE ( 1.3.6.1.4.1.18060.0.4.1.2.35\n   [junit4]    >  NAME 'schemaModifyTimestamp'\n   [junit4]    >  DESC time which schema was modified\n   [junit4]    >  SUP modifyTimestamp\n   [junit4]    >  EQUALITY generalizedTimeMatch\n   [junit4]    >  ORDERING generalizedTimeOrderingMatch\n   [junit4]    >  SYNTAX 1.3.6.1.4.1.1466.115.121.1.24\n   [junit4]    >  USAGE directoryOperation\n   [junit4]    >  )\n   [junit4]    > '\n   [junit4]    > \tat org.apache.directory.api.ldap.model.entry.AbstractValue.apply(AbstractValue.java:211)\n   [junit4]    > \tat org.apache.directory.api.ldap.model.entry.StringValue.<init>(StringValue.java:107)\n   [junit4]    > \tat org.apache.directory.api.ldap.model.entry.DefaultAttribute.<init>(DefaultAttribute.java:468)\n   [junit4]    > \tat org.apache.directory.api.ldap.model.entry.DefaultEntry.<init>(DefaultEntry.java:315)\n   [junit4]    > \tat org.apache.directory.server.core.partition.ldif.LdifPartition.loadEntries(LdifPartition.java:517)\n   [junit4]    > \tat org.apache.directory.server.core.partition.ldif.LdifPartition.loadEntries(LdifPartition.java:549)\n   [junit4]    > \tat org.apache.directory.server.core.partition.ldif.LdifPartition.doInit(LdifPartition.java:164)\n   [junit4]    > \tat org.apache.directory.server.core.api.partition.AbstractPartition.initialize(AbstractPartition.java:79)\n   [junit4]    > \t... 46 more\n   [junit4]    > Caused by: org.apache.directory.api.ldap.model.exception.LdapInvalidAttributeValueException: ERR_04473_NOT_VALID_VALUE Not a valid value '20090818022733Z' for the AttributeType 'ATTRIBUTE_TYPE ( 1.3.6.1.4.1.18060.0.4.1.2.35\n   [junit4]    >  NAME 'schemaModifyTimestamp'\n   [junit4]    >  DESC time which schema was modified\n   [junit4]    >  SUP modifyTimestamp\n   [junit4]    >  EQUALITY generalizedTimeMatch\n   [junit4]    >  ORDERING generalizedTimeOrderingMatch\n   [junit4]    >  SYNTAX 1.3.6.1.4.1.1466.115.121.1.24\n   [junit4]    >  USAGE directoryOperation\n   [junit4]    >  )\n   [junit4]    > '\n   [junit4]    > \tat org.apache.directory.api.ldap.model.entry.AbstractValue.apply(AbstractValue.java:204)\n   [junit4]    > \t... 53 moreThrowable #2: java.lang.NullPointerException\n   [junit4]    > \tat org.apache.solr.cloud.ZkTestServer$ZKServerMain.shutdown(ZkTestServer.java:332)\n   [junit4]    > \tat org.apache.solr.cloud.ZkTestServer.shutdown(ZkTestServer.java:492)\n   [junit4]    > \tat org.apache.solr.cloud.SaslZkACLProviderTest$SaslZkTestServer.shutdown(SaslZkACLProviderTest.java:211)\n   [junit4]    > \tat org.apache.solr.cloud.SaslZkACLProviderTest.tearDown(SaslZkACLProviderTest.java:109)\n   [junit4]    > \tat java.lang.Thread.run(Thread.java:745)\n\n ",
            "id": "comment-14287516"
        },
        {
            "date": "2015-01-23T04:15:52+0000",
            "author": "Gregory Chanan",
            "content": "Thanks Shalin, I was able to reproduce.\n\nIt looks like Apache Directory Server (which Hadoop MiniKDC is built on top of) isn't handling that Locale correctly.  I still need to do some more investigation, and I'll check if there are other locales that are a problem as well. ",
            "id": "comment-14288718"
        },
        {
            "date": "2015-01-26T21:20:32+0000",
            "author": "Gregory Chanan",
            "content": "These locales fail for me locally on java8:\n th_TH_TH_#u-nu-thai\nja_JP_JP_#u-ca-japanese\nhi_IN ",
            "id": "comment-14292428"
        },
        {
            "date": "2015-01-26T23:24:45+0000",
            "author": "Gregory Chanan",
            "content": " th_TH_TH_#u-nu-thai and  hi_IN seem to be issues with apacheds-ldap-api, they have the backtrace that Shalin posted above.\n\n ja_JP_JP_#u-ca-japanese seems to be a bouncycastle issue; the exception is here:\n\n209475 T11 oasc.SaslZkACLProviderTest.setUp Exception:invalid date string: Unparseable date: \"270126230030Z\" java.lang.IllegalArgumentException: invalid date string: Unparseable date: \"270126230030Z\"\n   [junit4]   2> \tat org.bouncycastle.asn1.DERGeneralizedTime.<init>(Unknown Source)\n   [junit4]   2> \tat org.bouncycastle.asn1.x509.Time.<init>(Unknown Source)\n   [junit4]   2> \tat org.bouncycastle.x509.X509V1CertificateGenerator.setNotBefore(Unknown Source)\n   [junit4]   2> \tat org.apache.directory.server.core.security.TlsKeyGenerator.addKeyPair(TlsKeyGenerator.java:277)\n   [junit4]   2> \tat org.apache.directory.server.core.DefaultDirectoryService.createBootstrapEntries(DefaultDirectoryService.java:1483)\n   [junit4]   2> \tat org.apache.directory.server.core.DefaultDirectoryService.initialize(DefaultDirectoryService.java:1828)\n   [junit4]   2> \tat org.apache.directory.server.core.DefaultDirectoryService.startup(DefaultDirectoryService.java:1248)\n   [junit4]   2> \tat org.apache.hadoop.minikdc.MiniKdc.initDirectoryService(MiniKdc.java:375)\n   [junit4]   2> \tat org.apache.hadoop.minikdc.MiniKdc.start(MiniKdc.java:310)\n\n ",
            "id": "comment-14292616"
        },
        {
            "date": "2015-01-27T01:58:29+0000",
            "author": "Gregory Chanan",
            "content": "Filed DIRAPI-219 for the ldap-api issues. ",
            "id": "comment-14292842"
        },
        {
            "date": "2015-01-27T09:27:18+0000",
            "author": "Emmanuel Lecharny",
            "content": "I would suggest you switch to ApacheDS M19. M15 is quite ancient, and depends on LDAP API 1.0.0-M20, which is 9 version behind already.\n\nAlthough the GenerilizedTimeSyntaxChecker has not changed for years... FTR, the date \"270126230030Z\" is perfectly valid, and I don't see how possibly it can fail. Here is the code :\n\nhttp://svn.apache.org/viewvc/directory/shared/trunk/ldap/model/src/main/java/org/apache/directory/api/ldap/model/schema/syntaxCheckers/GeneralizedTimeSyntaxChecker.java?revision=1002871&view=markup ",
            "id": "comment-14293247"
        },
        {
            "date": "2015-01-27T21:32:21+0000",
            "author": "Gregory Chanan",
            "content": "Emmanuel Lecharny thanks for the suggestion, I'll look into it but I may not be able to do anything because I'm relying on hadoop MiniKDC, so likely they would have to upgrade the dependency first.\n\nAbout the date \"270126230030Z\" I think you are right, that comment refers to an error coming from bouncycastle, not from apacheds.  I believe the errors coming from apacheds are only the two locales:\nth_TH_TH_#u-nu-thai\nhi_IN ",
            "id": "comment-14294226"
        },
        {
            "date": "2015-01-27T23:00:20+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1655187 from gchanan@apache.org in branch 'dev/trunk'\n[ https://svn.apache.org/r1655187 ]\n\nSOLR-6915: Avoid broken Locales and skip IBM J9 ",
            "id": "comment-14294367"
        },
        {
            "date": "2015-01-27T23:00:54+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1655188 from gchanan@apache.org in branch 'dev/branches/branch_5x'\n[ https://svn.apache.org/r1655188 ]\n\nSOLR-6915: Avoid broken Locales and skip IBM J9 ",
            "id": "comment-14294369"
        },
        {
            "date": "2015-01-27T23:01:59+0000",
            "author": "Gregory Chanan",
            "content": "Committed a change to 5.1 and trunk that skips IBM J9 and avoids the broken locales. ",
            "id": "comment-14294371"
        },
        {
            "date": "2015-01-27T23:16:56+0000",
            "author": "Emmanuel Lecharny",
            "content": "Can you bit a bit more explicit about what you are doing that breaks in ApacheDS when using the Thai locale ? ",
            "id": "comment-14294394"
        },
        {
            "date": "2015-02-06T00:41:32+0000",
            "author": "Gregory Chanan",
            "content": "Emmanuel Lecharny sorry for the late reply.  I'm just starting up a Hadoop MiniKDC.  See the code here for more details: https://github.com/apache/hadoop/blob/4641196fe02af5cab3d56a9f3c78875c495dbe03/hadoop-common-project/hadoop-minikdc/src/main/java/org/apache/hadoop/minikdc/MiniKdc.java#L322-L389 ",
            "id": "comment-14308354"
        },
        {
            "date": "2015-04-15T00:30:48+0000",
            "author": "Timothy Potter",
            "content": "Bulk close after 5.1 release ",
            "id": "comment-14495363"
        },
        {
            "date": "2015-06-02T22:25:16+0000",
            "author": "Mark Miller",
            "content": "This apacheds-all jar seems troublesome - currently it has conflicting slf4j classes in it...\n\nJar conflicts between /lucene-solr-trunk-1/solr/core/test-lib/apacheds-all-2.0.0-M15.jar and /lucene-solr-trunk-1/solr/solrj/lib/slf4j-api-1.7.7.jar ",
            "id": "comment-14569870"
        },
        {
            "date": "2015-06-02T22:28:06+0000",
            "author": "Gregory Chanan",
            "content": "This apacheds-all jar seems troublesome - currently it has conflicting slf4j classes in it...\n\nI believe it's possible to not use the apacheds-all jar; when I looked previously it looked like it took ~20 dependencies, some on different versions, and I couldn't find a link on the apacheds site about which versions were compatible with which..  I'll file a jira to investigate. ",
            "id": "comment-14569875"
        },
        {
            "date": "2015-06-02T22:31:20+0000",
            "author": "Gregory Chanan",
            "content": "I believe it's possible to not use the apacheds-all jar; when I looked previously it looked like it took ~20 dependencies, some on different versions, and I couldn't find a link on the apacheds site about which versions were compatible with which.. I'll file a jira to investigate.\n\nSOLR-7628 ",
            "id": "comment-14569893"
        },
        {
            "date": "2015-08-22T22:59:02+0000",
            "author": "Uwe Schindler",
            "content": "This happened again last night with locale uz_UZ_#Cyrl\n\nWe should maybe fix the test's locale ",
            "id": "comment-14708211"
        },
        {
            "date": "2015-08-23T00:09:47+0000",
            "author": "Uwe Schindler",
            "content": "It can fail because it uses Calendar.getDefault(), hwich is the main issue with this code. ",
            "id": "comment-14708234"
        },
        {
            "date": "2015-09-25T13:21:54+0000",
            "author": "Uwe Schindler",
            "content": "DIRAPI-219 is now solved. Looks like a bugfix release was done. ",
            "id": "comment-14908023"
        },
        {
            "date": "2015-09-25T17:29:15+0000",
            "author": "Gregory Chanan",
            "content": "Great.  I seem to recall that the latest releases weren't compatible with whatever MiniKDC was expecting, so we may need Hadoop MiniKDC to adopt and release those changes first. ",
            "id": "comment-14908365"
        },
        {
            "date": "2015-11-25T09:15:10+0000",
            "author": "Alan Woodward",
            "content": "This is still failing fairly frequently on Jenkins runs, particularly on Java 9 (eg http://jenkins.thetaphi.de/job/Lucene-Solr-5.x-Linux/14737/).  Maybe the thing to do is to wrap the MiniKDC startup method in an assumeTrue(), if we know there are certain locales that break this? ",
            "id": "comment-15026468"
        },
        {
            "date": "2015-11-30T23:25:49+0000",
            "author": "Gregory Chanan",
            "content": "This is still failing fairly frequently on Jenkins runs, particularly on Java 9 (eg http://jenkins.thetaphi.de/job/Lucene-Solr-5.x-Linux/14737/). Maybe the thing to do is to wrap the MiniKDC startup method in an assumeTrue(), if we know there are certain locales that break this?\n\nI think that's more or less what was done in SOLR-7183.  I think the issue is that just maintains a list of known bad locales instead of running checks on the locales to programatically figure out what was wrong.  And there are new locales in JDK9.  So easiest thing to do is add more to the list, medium solution is to runs checks on the locale, best solution is to fix MiniKDC.\n\nJust a note: http://jenkins.thetaphi.de/job/Lucene-Solr-5.x-Linux/14789/ fails with ar_TD ",
            "id": "comment-15032710"
        },
        {
            "date": "2015-12-03T02:23:15+0000",
            "author": "Gregory Chanan",
            "content": "Ok, ran the test through all the locales on my install of java 9.  Here's what failed:\nar_JO\ndz_BT\nar_SA\nfa_AF\nar_TD\nar_EG\nne_IN\nar_SD\nar_KM\nfa_IR\nfa\nne\nmy\nar_IL\nar_SY\nar_PS\nur_IN\nar_YE\nps\nuz_UZ_#Cyrl\nmr_IN\nuz\nar_OM\nuz_UZ_#Latn\nbn\nbn_BD\nps_AF\nmr\ndz\nbn_IN\nks__#Arab\nar_SS\nar_ER\nth_TH_TH_#u-nu-thai\nar_SO\nuz__#Arab\nar_AE\nas\nmy_MM\nar_BH\nja_JP_JP_#u-ca-japanese\nuz__#Cyrl\nne_NP\nuz_AF_#Arab\nks\nas_IN\nar_IQ\nar_QA\nar\nuz__#Latn\nks_IN_#Arab\nar_001\nar_KW\nar_DJ ",
            "id": "comment-15037096"
        },
        {
            "date": "2015-12-03T06:45:22+0000",
            "author": "Mark Miller",
            "content": "Another option is just hard coding to one working locale for now right? ",
            "id": "comment-15037375"
        },
        {
            "date": "2015-12-03T08:59:09+0000",
            "author": "Ishan Chattopadhyaya",
            "content": "Maybe we should move this discussion to SOLR-7183, where I added a way to black list the known bad locales in the util class? ",
            "id": "comment-15037521"
        },
        {
            "date": "2015-12-03T09:01:31+0000",
            "author": "Ishan Chattopadhyaya",
            "content": "best solution is to fix MiniKDC\n+1, but seems like longer term. ",
            "id": "comment-15037534"
        }
    ]
}