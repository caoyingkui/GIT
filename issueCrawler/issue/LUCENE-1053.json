{
    "id": "LUCENE-1053",
    "title": "OutOfMemoryError on search in large, simple index",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [
            "core/search"
        ],
        "type": "Bug",
        "fix_versions": [],
        "affect_versions": "2.0.0",
        "resolution": "Invalid",
        "status": "Resolved"
    },
    "description": "We get OutOfMemoryError when performing a one-term search in our index.  The search, if completed, should give only a few thousand hits, but from inspecting a heap dump it appears that many more documents in the index get stored in Lucene during the search. Our index consists of eight fields per document, fairly regularly sized, the total index size is 170GB, spread over about 400 million documents (425 bytes per document).  The search is a simple TermQuery, the search term a trivial string, the code in question looks like this (cut together for conciseness):\n\n\tpublic static final String FIELD_URL = \"url\";\n...\n        luceneSearcher = new IndexSearcher(indexDir.getAbsolutePath());\n        Query query = new TermQuery(new Term(DigestIndexer.FIELD_URL, uri));\n        try {\n            Hits hits = luceneSearcher.search(query);\n\n\nStack trace:\nOct 11, 2007 4:02:19 PM org.slf4j.impl.JCLLoggerAdapter error\nSEVERE: EXCEPTION \njava.lang.OutOfMemoryError: Java heap space\n        at org.apache.lucene.index.SegmentReader.getNorms(SegmentReader.java:384)\n        at org.apache.lucene.index.SegmentReader.norms(SegmentReader.java:393)\n        at org.apache.lucene.search.TermQuery$TermWeight.scorer(TermQuery.java:68)\n        at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:129)\n        at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:99)\n        at org.apache.lucene.search.Hits.getMoreDocs(Hits.java:65)\n        at org.apache.lucene.search.Hits.(Hits.java:44)\n        at org.apache.lucene.search.Searcher.search(Searcher.java:44)\n        at org.apache.lucene.search.Searcher.search(Searcher.java:36)\n        at dk.netarkivet.common.distribute.arcrepository.ARCLookup.luceneLookup(ARCLookup.java:166)\n        at dk.netarkivet.common.distribute.arcrepository.ARCLookup.lookup(ARCLookup.java:130)\n        at dk.netarkivet.viewerproxy.ARCArchiveAccess.lookup(ARCArchiveAccess.java:126)\n        at dk.netarkivet.viewerproxy.NotifyingURIResolver.lookup(NotifyingURIResolver.java:72)\n        at dk.netarkivet.viewerproxy.CommandResolver.lookup(CommandResolver.java:80)\n        at dk.netarkivet.viewerproxy.CommandResolver.lookup(CommandResolver.java:80)\n        at dk.netarkivet.viewerproxy.CommandResolver.lookup(CommandResolver.java:80)\n        at dk.netarkivet.viewerproxy.WebProxy.handle(WebProxy.java:129)\n        at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:139)\n        at org.mortbay.jetty.Server.handle(Server.java:285)\n        at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:457)\n        at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:751)\n        at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:500)\n        at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:209)\n        at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:357)\n        at org.mortbay.jetty.bio.SocketConnector$Connection.run(SocketConnector.java:217)\n        at org.mortbay.thread.BoundedThreadPool$PoolThread.run(BoundedThreadPool.java:475)",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "date": "2007-11-13T12:38:23+0000",
            "content": "Hi Lars,\n\nGenerally we recommend you open discussion of issues you are having with your applications use of Lucene by asking questions on the java-user mailing list.  What you are reporting doesn't necessarily sound like a bug in Lucene, so let's discuss it on java-user first and hopefully we can get you some answers there first.\n\nStart by posting what you have here, plus add in what your heap settings are, etc.  Lucene doesn't scale infinitely (nor does any search application or, for that matter, program), when you reach a certain index size, you will have to start doing things like distributed search whereby you split your index across 2 or more machines.  You MAY have hit those limits and may need to distribute your search.\n\nCheers,\nGrant ",
            "author": "Grant Ingersoll",
            "id": "comment-12542129"
        }
    ]
}