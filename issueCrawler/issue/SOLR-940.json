{
    "id": "SOLR-940",
    "title": "TrieRange support",
    "details": {
        "affect_versions": "None",
        "status": "Closed",
        "fix_versions": [
            "1.4"
        ],
        "components": [],
        "type": "New Feature",
        "priority": "Major",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "We need support in Solr for the new TrieRange Lucene functionality.",
    "attachments": {
        "SOLR-940-newTrieAPI.patch": "https://issues.apache.org/jira/secure/attachment/12404673/SOLR-940-newTrieAPI.patch",
        "SOLR-940-LUCENE-1701-addition.patch": "https://issues.apache.org/jira/secure/attachment/12413408/SOLR-940-LUCENE-1701-addition.patch",
        "SOLR-940-LUCENE-1602.patch": "https://issues.apache.org/jira/secure/attachment/12405656/SOLR-940-LUCENE-1602.patch",
        "SOLR-940.patch": "https://issues.apache.org/jira/secure/attachment/12401171/SOLR-940.patch",
        "SOLR-940-1261-1241.patch": "https://issues.apache.org/jira/secure/attachment/12413576/SOLR-940-1261-1241.patch",
        "ASF.LICENSE.NOT.GRANTED--SOLR-940-newTrieAPI.patch": "https://issues.apache.org/jira/secure/attachment/12404587/ASF.LICENSE.NOT.GRANTED--SOLR-940-newTrieAPI.patch",
        "SOLR-940-rangequery.patch": "https://issues.apache.org/jira/secure/attachment/12401960/SOLR-940-rangequery.patch",
        "SOLR-940-test.patch": "https://issues.apache.org/jira/secure/attachment/12402030/SOLR-940-test.patch",
        "SOLR-940-LUCENE-1701.patch": "https://issues.apache.org/jira/secure/attachment/12411582/SOLR-940-LUCENE-1701.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12676323",
            "date": "2009-02-24T16:13:29+0000",
            "content": "Yonik, are you working on this? If not, I can start. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12676324",
            "date": "2009-02-24T16:21:20+0000",
            "content": "I haven't started to work on it - go for it! "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12676341",
            "date": "2009-02-24T17:27:06+0000",
            "content": "Great! I need to upgrade the Lucene jars to get the new updated Trie API. "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-12676551",
            "date": "2009-02-25T07:55:24+0000",
            "content": "Cool, I am open for queries and requests about the API and can help where applicable. What do the Solr people think about LUCENE-1541? I keep it open, but I think it makes things to complicated. "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12676570",
            "date": "2009-02-25T09:13:39+0000",
            "content": "Thanks Uwe! I have just started to look at the API, the discussion in LUCENE-1470 and on the mailing list. So, I'll definitely need some help. My first priority is to get it working in a simple way, then add more configuration/tuning options depending on feedback.\n\nAs for, LUCENE-1541, I'm yet to get to that. Probably others may have more thoughts on that. "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-12676577",
            "date": "2009-02-25T09:25:50+0000",
            "content": "So, I'll definitely need some help. My first priority is to get it working in a simple way, then add more configuration/tuning options depending on feedback\n\nJust a question: Do you need help implementing (working power), or is the documentation not yet understandable for a beginner? I added some indexing and query examples in the package overview, but maybe it is not so easy for others to understand. Maybe we can improve the documentation.\n\nI am not so familar with Solr internals, but as I understand you have datatypes and field configurations in your XML documents. Maybe you should add new types \"trie-long\",... and index them using TrieUtils. I will check out svn trunk of Solr and look into it. In the first step, I would only use the APIs taking one field name (which creates the internal helper field ending in \"#trie\", that would automatically be created but \"invisible\" to the user). This ensures simplicity and the possibility to sort efficient using the SortField factory from TrieUtils (without custom sort comparators and so on). "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12676630",
            "date": "2009-02-25T12:40:53+0000",
            "content": "Just a question: Do you need help implementing (working power), or is the documentation not yet understandable for a beginner? I added some indexing and query examples in the package overview, but maybe it is not so easy for others to understand. Maybe we can improve the documentation.\n\nI meant that I have only started looking at this so I may have questions later \n\nMaybe you should add new types \"trie-long\",... and index them using TrieUtils.\n\nYes, that seems to be the right way. I'll create TrieIntField and TrieLongField. We can use the implicit helper field or have it as a configuration option in schema.xml. We'd also need changes to the SolrQueryParser so that range queries on such fields are handled correctly.\n\nI'll try to have a patch by tomorrow. "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-12676635",
            "date": "2009-02-25T12:54:24+0000",
            "content": "Yes, that seems to be the right way. I'll create TrieIntField and TrieLongField. We can use the implicit helper field or have it as a configuration option in schema.xml. We'd also need changes to the SolrQueryParser so that range queries on such fields are handled correctly.\n\nAnd how about using this for floats, doubles, and dates (which also have corresponding Solr field types)? You could create field descriptions for that too (subclasses of TrieIntField and TrieLongField), to be able to index these types using trie. "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-12676643",
            "date": "2009-02-25T13:18:01+0000",
            "content": "By the way, when looking through the schema code, I found out, that with Lucene trunk, it is now also possible to sort the \"SortableLongField\" & others using the new SortField ctors that LUCENE-1478 introduced. Currently these fields are sorted by SortField.STRING, whcih is inefficient. Just as a side-note. "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-12676698",
            "date": "2009-02-25T16:41:46+0000",
            "content": "Just an idea (that came to me...): How about creating a TokenStream that returns the results of TrieUtils.trieCode[Long|Int]() with TokenIncrement 0. You should be able to search this with TrieRangeFilter (using the same field name for the highest and lower precision trie fields). "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12676710",
            "date": "2009-02-25T17:15:32+0000",
            "content": "Just an idea (that came to me...): How about creating a TokenStream that returns the results of TrieUtils.trieCode[Long|Int]() with TokenIncrement 0. You should be able to search this with TrieRangeFilter (using the same field name for the highest and lower precision trie fields).\n\nThe difficulty is in identifying what type of tokenizer was used (TrieInt, TrieLong etc.) to index the field. The user will need to use the localparam syntax explicitly for us to use IntTrieRangeFilter e.g fq=\n{trieint}\ntint:[10 TO 100]. I would like to avoid the use of such syntax as far as possible. Creating the field type may be more work than this option, but it can help us use the correct Filter and SortField automatically.\n\nAnd how about using this for floats, doubles, and dates (which also have corresponding Solr field types)? You could create field descriptions for that too (subclasses of TrieIntField and TrieLongField), to be able to index these types using trie.\n\nYes, we should support those too.\n\nBy the way, when looking through the schema code, I found out, that with Lucene trunk, it is now also possible to sort the \"SortableLongField\" & others using the new SortField ctors that LUCENE-1478 introduced. Currently these fields are sorted by SortField.STRING, whcih is inefficient. Just as a side-note. \n\nThanks for the pointing this out. I'll take a look at this too. "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-12676717",
            "date": "2009-02-25T17:44:18+0000",
            "content": "\nJust an idea (that came to me...): How about creating a TokenStream that returns the results of TrieUtils.trieCode[Long|Int]() with TokenIncrement 0. You should be able to search this with TrieRangeFilter (using the same field name for the highest and lower precision trie fields).\n\nThe difficulty is in identifying what type of tokenizer was used (TrieInt, TrieLong etc.) to index the field. The user will need to use the localparam syntax explicitly for us to use IntTrieRangeFilter e.g fq=\nUnknown macro: {trieint} \ntint:[10 TO 100]. I would like to avoid the use of such syntax as far as possible. Creating the field type may be more work than this option, but it can help us use the correct Filter and SortField automatically.\n\nNow I understand the problem, Yonik had with the original TrieRange implementation and wanted to change the API. Your problem is, that you must be able to not just map the numerical value to one field and token. You have to index one numeric value to more than one token before indexing them.\n\nMy idea was, to just use create a FieldType subclass for indexing TrieRangeFilter and overwrite the getAnalyzer() and getQueryAnalyzer() methods. The analyzer would get the numerical value and create tokens from it. Normally, it would be only one token for numerical values that is converted using the toXXXX methods in FieldType. But now you have to create more than one token (one for each precision). This could be done by the analyzer that is returned by FieldType. This analyzer does really nothing, only returns a Tokenizer that does not really tokenize, it just returns Tokens containing the prefix encoded values of the given String converted to the numeric value in different precisions (using TrieUtils.trieCodeLong()). "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-12676721",
            "date": "2009-02-25T18:05:19+0000",
            "content": "I would program this tokenizer in this way (using the old Lucene Token API):\n\n\npublic class TrieTokenStream extends TokenStream/Tokenizer {\n  public TrieTokenStream(long value,...) {\n    this.trieVals=Arrays.asList(TrieUtils.trieCodeLong(value,...)).iterator();\n  }\n\n  public Token next(Token token) {\n    if (!s.hasNext()) return null;\n    token.reinit(trieVals.next(),0,0);\n    token.setPositionIncrement(0);\n    return token;\n  }\n\n  private final Iterator<String> trieVals;\n}\n\n\n\nUsing this, you could index the field (without an additional helper field and so not sortable) using the standard Lucene Fieldable mechanism. No further changes to solar on the indexing side might be needed. "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12676723",
            "date": "2009-02-25T18:06:14+0000",
            "content": "Now I understand the problem, Yonik had with the original TrieRange implementation and wanted to change the API. Your problem is, that you must be able to not just map the numerical value to one field and token. You have to index one numeric value to more than one token before indexing them.\n\nI was just reading Yonik's comment on java-dev to figure out what Yonik had in mind. Normally, the toInternal/toExternal methods take care of encoding/decoding. But we cannot use them because the trie encoding produces multiple tokens. That can be done through a tokenizer as you said. But, a tokenizer cannot add tokens in another field which is requred for the filter to work correctly. "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-12676726",
            "date": "2009-02-25T18:10:18+0000",
            "content": "But, a tokenizer cannot add tokens in another field which is requred for the filter to work correctly.\n\nYou can tokenize it into one field and use TrieRangeFilter with the same field name for the field and the lower precision field (second constructor). After that, search works, but you cannot sort anymore, because more than one token per document in this field. "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12676727",
            "date": "2009-02-25T18:10:47+0000",
            "content": "Using this, you could index the field (without an additional helper field and so not sortable) using the standard Lucene Fieldable mechanism. No further changes to solar on the indexing side might be needed.\n\nHmm, no sort should be OK for a start. Users can be instructed to use a copyField for sorting (just like we have integer and sint in the schema). Thanks for the tip Uwe! I'll try this out and let you know if this works out well. "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-12676806",
            "date": "2009-02-25T22:56:53+0000",
            "content": "I have not followed this closely, so correct me if I am way off base...\n\nAssuming TrieRange does all the number mojo needed in lucene, should it eventually replace the existing number implementaions?\n\nIn solr 2.0, would it make sense that int,sint,float,sfloat, etc are all implemented with TrieRange?  Obviously we need to keep the existing field types for 1.X\n\nIf this is true, should we deprecate the existing Number implementations for 1.4?  perhaps just NumberUtils?\n\nShould changing the schema version to 1.2 trigger using the TrieRange classes rather then the NumberUtils classes?  Becides supporting existing indexes, is there any reason to keep the solr number formats rather then the Trie version? "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12677713",
            "date": "2009-02-28T20:06:27+0000",
            "content": "Attaching first cut with the following changes:\n\n\tBaseTrieField - Base class for trie fields, hardcodes the field to be multi-valued and tokenized\n\tTrieIntField - Support for ints\n\tTrieIntTokenizer/Factory - Uses TrieUtils to create sequence of trie coded numbers for a given integer, decreasing in precision\n\tChanges to SolrQueryParser to use IntTrieRangeFilter is field is instance of TrieIntField\n\tTestTrie - Simple test for int range search\n\tsrc/test/test-files/conf/schema-trie.xml uses the trie int\n\n\n\nThe precisionStep is not configurable at the moment. This is because the same precisionStep must be used for indexing (by the Tokenizer) and to create the range filter (in SolrQueryParser) and I could not find a way to share this information between the two classes.\n\nTODO:\n\n\tSupport for float, long, doubles\n\tJavadocs\n\tChanges to example schema, clearly highlighting that trie fields cannot be used for sorting (one should use copyFields into a integer for sorting)\n\n\n\nThanks Uwe for suggesting the tokenizer approach, works great!\n\nEdit - Forgot to mention that needs updated Lucene jars (trunk). "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12677714",
            "date": "2009-02-28T20:12:46+0000",
            "content": "Assuming TrieRange does all the number mojo needed in lucene, should it eventually replace the existing number implementaions?\n\nNot until we can support sorting. Also, trie indexes many tokens per value, increasing the index size. Users who do not need range searches should not pay this penalty. "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-12677726",
            "date": "2009-02-28T21:11:51+0000",
            "content": "\nAssuming TrieRange does all the number mojo needed in lucene, should it eventually replace the existing number implementaions?\n\nNot until we can support sorting. Also, trie indexes many tokens per value, increasing the index size. Users who do not need range searches should not pay this penalty.\n\nIf the precisionStep is configureable, you can simply use 32 (for ints) or 64 (for longs) to not create additional precisions. "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-12677740",
            "date": "2009-02-28T22:21:11+0000",
            "content": "Just one question:\nIn queryParser you use: FieldType ft = schema.getFieldType(field); So if you have the FieldType, why are you not able to extract the precisionStep from the schema? The user would only have a problem, if he changes the precision step in the schema, but with a fixed schema, that contains the precisionStep as a parameter, you should be able to search indexed data. If you change the schema, you have to reindex (or use a precisionStep that is a multiple of the original one, see trie Javadoc: if you have indexed with step 2, you can search without problems using step 4)\n\nBy the way: For future usage, you could use TrieUtils.get[Int|Long]SortField for FieldType.getSortField instead of using SortField.String. If the problem with more than one field name is solved, sorting works using the Trie-SortField using the correct parser. "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12677772",
            "date": "2009-03-01T05:28:35+0000",
            "content": "New patch with the following changes:\n\n\tSupports int, float, long, double\n\tThere are no separate classes for each type (too much boilerplate code), instead they are folded into one \u2013 TrieField\n\tSame as above for Tokenizer - TrieTokenizerFactory\n\tIn the schema, one needs to specify an additional attribute 'type' when declaring the field type, example:\n\n<fieldType name=\"tdouble\" class=\"solr.TrieField\" type=\"double\" omitNorms=\"true\"\npositionIncrementGap=\"0\" indexed=\"true\" stored=\"false\" />\n\n\n\tPrecision step is now configurable and can be specified in field type declaration, example:\n\n<fieldType name=\"tdouble16\" class=\"solr.TrieField\" type=\"double\" precisionStep=\"16\"\n omitNorms=\"true\" positionIncrementGap=\"0\" indexed=\"true\" stored=\"false\" />\n\n\n\tTest expanded for float, long, double types\n\n\n\nTODO:\n\n\tDate type\n\tMore javadocs?\n\tUpdate wiki\n\tChanges to example schema\n\n "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12677773",
            "date": "2009-03-01T05:32:00+0000",
            "content": "If the precisionStep is configureable, you can simply use 32 (for ints) or 64 (for longs) to not create additional precisions.\n\nThat's great, I'll document this on the wiki.\n\nIn queryParser you use: FieldType ft = schema.getFieldType(field); So if you have the FieldType, why are you not able to extract the precisionStep from the schema?\nYes, done, must have been the late night effect \n\nFor future usage, you could use TrieUtils.get[Int|Long]SortField for FieldType.getSortField instead of using SortField.String. If the problem with more than one field name is solved, sorting works using the Trie-SortField using the correct parser.\n\nDone too "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-12677799",
            "date": "2009-03-01T09:35:43+0000",
            "content": "Looks cool, great!\nI have no Solr installed here to test in large scale, but from what I see, It seems sophisticated. I have only seen these points:\n\n\tMissing support for half-open ranges with \"*\" (just add the test for \"*\" and pass null to TrieRangeFilter)\n\tThe example with a different configured precisionStep should use a precisionStep < 8 [16 is a possible value, but useless,because of number of terms. The possible number of terms increses dramatically with higher precision steps (factor 2^precisionStep). Javadocs should note, that 32/64 should be used for no additional trie fields]\n\tDate support should be trivial, too.\n\tDoes it work with the tokenizer for standard term queries? e.g. somebody asks for all documents containing the long value x, but not using a TrieRange for that (this works, but can solr handle this?), is the value correctly tokenized? The problem here maybe that during parsing the query, the analyzer is used and generates a \"OR\" BolleanQuery of all terms incl lower precisions. Or is for the query another tokenizer used (but then this tokenizer should just generate one term using XxxxToPrefixCoded (without shift).\n\n "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-12677801",
            "date": "2009-03-01T10:25:46+0000",
            "content": "About the sorting problem:\n\nAs already discussed in the original TrieRange issue, the sorting is a problem for trie encoded fields. The problem is, that the current FieldCache has two problems:\n\n\tit stores the last term (the last term in the TermEnum!) in the cache\n\tit throws an exception, when the number of term in one field > the number of docs (I think this was the case)\n\n\n\nFor trie fields it would be good, to have something like \"sorting on the first term of the document\". This would be conformant with TrieRange, as the first term in trieCodeXxx() is always the highest precision one (and also in your tokenizer). I think, we should discuss more in LUCENE-1372, where this sorting problem is discussed. If it would be fixed before 2.9, I could remove the whole multi-field parts out of TrieRange API and only support one field name (with what I would be really happy). Then you can index all trie terms in one field and sort on it (if the order of generated trie terms is preserved through the whole indexing and TermDocs array (which is not really simple for the field cache to handle). "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12677929",
            "date": "2009-03-02T08:57:05+0000",
            "content": "Changes:\n\n\tAdding support for open ranges\n\tChanged precision step in test schema.xml to 4\n\tRenamed TrieTokenizerFactory to TrieIndexTokenizerFactory\n\tAdded a TrieQueryTokenizerFactory which converts query token to xxxToPrefixCoded form. Now term queries (in q or fq) are supported\n\tUpdated tests for open ranges and term queries\n\tMinor javadoc updates\n\n\n\nTODO:\n\n\tDate support\n\tWiki updates\n\tExample schema updates\n\n "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12677936",
            "date": "2009-03-02T09:21:29+0000",
            "content": "Thanks Uwe for spotting those problems. The latest patch should take care of these issues.\n\nFor trie fields it would be good, to have something like \"sorting on the first term of the document\".\n\nHmm, yeah. This looks like the easiest solution. "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12678286",
            "date": "2009-03-03T11:03:17+0000",
            "content": "Changes:\n\n\tSupport for date types\n\tTrieField and TrieIndexTokenizer keep a static instance of DateField class whose parseMath and toObject methods are used. This makes sure that all date format related semantics as well as the DateMath syntax works as usual with trie dates.\n\tUpdated test for date type\n\n\n\nTODO:\n\n\tUpdate example schema\n\tUpdate wiki\n\tCommit?\n\n "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12678291",
            "date": "2009-03-03T11:36:32+0000",
            "content": "Hmm, I think the TriField.toObject is not correct. We need to use TrieUtils to convert the prefix coded form back to int/float/long etc. Also, we need to add the TrieField as a known type for the binary response format. "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12678344",
            "date": "2009-03-03T15:16:39+0000",
            "content": "Please ignore my comment about toObject I made earlier. It is not necessary.\n\nChanges:\n\n\tAdded TrieField as a known type in BinaryResponseWriter so that TrieField.toObject is serialized\n\tChanges to example schema with documentation\n\tUpdated javadocs\n\tUse TrieUtils.getLongSortField for dates too\n\tRemove hardcoded isMultivalued in TrieField\n\n\n\nThis is a good time for folks to take this out for a spin  "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-12678367",
            "date": "2009-03-03T17:12:34+0000",
            "content": "Cool!\nWhen looking through the code, I found out that TrieQueryTokenizer is missing Date support, nothing else! And I would always throw an IllegalArgumentException in the default case of all switch(type) statements. This helps finding such errors faster. "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12678381",
            "date": "2009-03-03T18:18:14+0000",
            "content": "When looking through the code, I found out that TrieQueryTokenizer is missing Date support, nothing else!\n\nAh right, I forgot that term queries won't work without it. I'll add it.\n\nAnd I would always throw an IllegalArgumentException in the default case of all switch(type) statements. This helps finding such errors faster.\n\nGood point. Will do that too.\n\nThanks! "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12678423",
            "date": "2009-03-03T19:33:31+0000",
            "content": "Changes:\n\n\tSupport term queries for trie dates\n\tUpdate test for term queries on dates\n\tThrow SolrException for unknown trie type in switch (actually this can not happen because the enum has a fixed number of types and we are using all of them).\n\n "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-12678485",
            "date": "2009-03-03T22:21:53+0000",
            "content": "The patch is the same as before, maybe you uploaded the wrong one. "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12678579",
            "date": "2009-03-04T04:27:32+0000",
            "content": "The last patch was incorrect. Uploading the correct patch. "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12679961",
            "date": "2009-03-08T07:23:55+0000",
            "content": "Updating javadocs to note that trie fields cannot be used in function queries. No other changes.\n\nWhat do people feel about committing this patch?\n\nAnother thought - If we can write a ValueSource for trie fields whose DocValues return only the first indexed term, we should be able to use function queries. Will this be too expensive if Lucene does not support building such field caches for us?\n\nIf this can be done then basic sorting would be possible through function queries (though they would be part of the score). However one still would not be able to use trie fields in the sort parameter (or mix their sorting with non-numeric fields). "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12680977",
            "date": "2009-03-11T18:44:46+0000",
            "content": "Committed revision 752562.\n\nThanks Uwe for the ideas and the reviews! "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12680989",
            "date": "2009-03-11T19:03:24+0000",
            "content": "Instead of explicitly testing for TrieField in the QueryParser, how about adding a\nFieldType.getRangeQuery()?  We'll need that anyway in the future to support value source range query, etc. "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12680996",
            "date": "2009-03-11T19:09:07+0000",
            "content": "Instead of explicitly testing for TrieField in the QueryParser, how about adding a FieldType.getRangeQuery()?\n\nSounds good. I'll give a patch. "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12681003",
            "date": "2009-03-11T19:43:32+0000",
            "content": "\n\tAdding FieldType.getRangeQuery method which uses the ConstantScore version of RangeQuery.\n\tTrieField overrides it to provide its own implementation.\n\tSolrQueryParser uses fieldType.getRangeQuery\n\n\n\nI'll commit this shortly. "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12681007",
            "date": "2009-03-11T19:50:39+0000",
            "content": "Committed revision 752596. "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12681171",
            "date": "2009-03-12T06:04:06+0000",
            "content": "From Hoss on solr-dev about the last patch:\n\nI don't think treating \"*\" as special is something FieldType (or\nTrieField) should do \u2013 that's specific to the syntax of the QueryParser.\nThe FieldType classes should treat the string as a string. (otherwise if i\nwrite a new QueryParser where * isn't a special character and use some\nsyntax like \"phoneNumber < *69\" i'm screwed.\n\"*69\" as the\n\nI also think having a single \"inclusive\" boolean is a bad idea.\n\nI would javadoc that the lower/upper bounds can be null, and have\nSolrQueryParser pass null when it sees \"*\" in the syntax.  we should also\nbe explicit in the javadocs about what combinations of inclusion booleans\nand null values are allowed so that subclasses know what to expect\n\nIn this patch:\n\n\tFieldType no longer treats '*' specially\n\tSolrQueryParser passes null for '*'\n\tSingle inclusive parameter replaced by two parameters \u2013 minInclusive and maxInclusive\n\tJavadoc updated to mention that nulls are allowed for part1 and part2, SolrQueryParser passes null for '*' character and same (true) values for minInclusive and maxInclusive. However other QueryParsers may have different semantics.\n\tCorresponding changes to TrieField\n\n\n\nI'll commit shortly. "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12681183",
            "date": "2009-03-12T06:37:16+0000",
            "content": "Committed revision 752785.\n\nFixed a single char bug in the previous patch at FieldType.getRangeQuery. "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12681244",
            "date": "2009-03-12T09:59:46+0000",
            "content": "Changing test to index and search for NOW/DAY TO NOW/DAY+10DAYS otherwise the millisecond precision fails the test intermittently.\n\nI'll commit this shortly. "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12681245",
            "date": "2009-03-12T10:04:12+0000",
            "content": "Committed revision 752823. "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-12694975",
            "date": "2009-04-02T12:12:35+0000",
            "content": "I created a new issue LUCENE-1582 to fix the sorting problem and also support a TokenStream directly by trieCodeLong/Int(). The API will change, but this would be simplification for the Solr implementation (as the TokenStream can be directly used) and is more memory efficient. "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-12695581",
            "date": "2009-04-03T21:11:19+0000",
            "content": "This patch modifies Solr support for trie fields to the new Trie API (not committed until now).\nThis class simplifies the TokenizerFactories (no Solr-internal indexing Tokenizer needed anymore as trie API supplies TokenStream). The TrieQueryTokenizerFactory was simplified to use KeywordTokenizer instead of implementing an own one (this change can be left of, if you like your solution more).\nFor this to compile and work, the latest trunk builds of Lucene must be placed in lib and another small change because of a change in Fieldable interface must be added (not included in patch). "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-12695761",
            "date": "2009-04-04T15:54:52+0000",
            "content": "I forget to mention: with LUCENE-1582 and this patch, sorting now works for trie fields. I changed the schema.xml in the patch to note this.\n\nAbout function queries: If they use the \"normal\" field cache (long, int, double, float) with the supplied trie parser (as the trie SortField factory does), it would work. The parser for the nurmeric values is also separately available in TrieUtils. But I do not know, how to enable this in Solr (SortField support is available through the schema), maybe you can do this, or change the comments.\n\nBy the way, the change needed for compilation with the new Lucene JARs is the omitTf thing (SOLR-1079), I have done this in my local checkout to be able to create this patch. "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12695765",
            "date": "2009-04-04T17:01:43+0000",
            "content": "Thanks Uwe!\n\nI'm having trouble applying the patch:\n\nshalinsmangar@shalinsmangar-laptop:~/work/oss/solr-trunk$ patch --dry-run -p0 < /home/shalinsmangar/Desktop/SOLR-940-newTrieAPI.patch \n(Stripping trailing CRs from patch.)\npatching file example/solr/conf/schema.xml\n(Stripping trailing CRs from patch.)\npatching file src/java/org/apache/solr/analysis/TrieIndexTokenizerFactory.java\nHunk #3 FAILED at 51.\n1 out of 3 hunks FAILED -- saving rejects to file src/java/org/apache/solr/analysis/TrieIndexTokenizerFactory.java.rej\n(Stripping trailing CRs from patch.)\npatching file src/java/org/apache/solr/analysis/TrieQueryTokenizerFactory.java\n(Stripping trailing CRs from patch.)\npatching file src/java/org/apache/solr/schema/TrieField.java\n\n\n\nNo biggie, I'll take care of it.\n\nI forget to mention: with LUCENE-1582 and this patch, sorting now works for trie fields.\nThat is great news!\n\nAbout function queries: If they use the \"normal\" field cache (long, int, double, float) with the supplied trie parser\nThe function query stuff does use FieldCache but through the ValueSource abstraction. It should be possible by creating a TrieValueSource which uses the trie field cache parsers when creating the value source.\n\nBy the way, the change needed for compilation with the new Lucene JARs is the omitTf thing (SOLR-1079).\nOk, I think we can commit that first as soon as there is consensus on the name. "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-12695766",
            "date": "2009-04-04T17:08:35+0000",
            "content": "I'm having trouble applying the patch:\nI created the patch from the SVN trunk checkout yesterday. Maybe it is in windows-format with CR-LF. For me it applies cleanly using TortoiseSVN merge function.\n\nDid the LUCENE-1582 patch apply to Lucene correctly? "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12695813",
            "date": "2009-04-05T06:53:09+0000",
            "content": "Did the LUCENE-1582 patch apply to Lucene correctly?\n\nYes, that one applies fine. I think going ahead with LUCENE-1582, SOLR-1079 and then looking at this patch will make things easier. "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-12695881",
            "date": "2009-04-05T17:33:46+0000",
            "content": "Updated patch, that supports ValueSource (currently not for Date Trie fields, I do not know how this should work, the orginal DateField uses a StringIndex as ValueSource, which is not possible for trie date fields, as no parser available and if using the standard string index, would fail because of more than one term/doc). Some tests for function queries are needed (especially as Double and FloatParser are not tested by Lucene at the moment), maybe change a test for conventional XxxFields to do the same test with a trie field. "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-12696492",
            "date": "2009-04-07T11:56:44+0000",
            "content": "The change is now committed in Lucene trunk!\nShalin: Can you reopen this issue (I cannot do this), to not forget about it? "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12696496",
            "date": "2009-04-07T12:14:49+0000",
            "content": "Re-opening to incorporate changes in Lucene. "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-12696681",
            "date": "2009-04-07T18:41:11+0000",
            "content": "One note to sorting:\nI am not really sure, if sorting works with Solr. The Sortfield returned by TrieUtils.getSortField contains an own parser (new feature in Lucene 2.9). When looking through the solr code, searching for SortField in trunk, I noticed, that QueryComponent has own comparators and FieldCache code (duplicating the Lucene code), and ignoring the parser given in SortField (the parser is not passed to FieldCache.getInts() & Co.).\n\nIf this is the case, it will simply not work. As I do not know anything about the internals of Solr and what QueryComponent does, so can you create a test-case that tests sorting of trie fields?\n\nBy the way: In QueryComponent is a package-private StringFieldable just to convert the strings. Why not simply use a conventional Field instance to do this, why implement the whole interface? You can do everything done with this StringFieldable with Field, too. This is the problem of the omitTf thing: the interface changed again in Lucene 2.9, needing a change in this class. Replacing this by a simple reuseable Field instance solves the interface problem completely. "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-12696702",
            "date": "2009-04-07T19:18:38+0000",
            "content": "I attached a patch to SOLR-1079 to fix the QueryComponent problem (remove the StringFieldable). "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12697477",
            "date": "2009-04-09T11:27:41+0000",
            "content": "This patch includes all of Uwe's changes in addition to SOLR-1079 and another change to SolrHighlighter to accomodate LUCENE-1500.\n\nAll tests pass. "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12698184",
            "date": "2009-04-12T07:49:48+0000",
            "content": "\nOne note to sorting:\nI am not really sure, if sorting works with Solr. The Sortfield returned by TrieUtils.getSortField contains an own parser (new feature in Lucene 2.9). When looking through the solr code, searching for SortField in trunk, I noticed, that QueryComponent has own comparators and FieldCache code (duplicating the Lucene code), and ignoring the parser given in SortField (the parser is not passed to FieldCache.getInts() & Co.).\n\nIf this is the case, it will simply not work. As I do not know anything about the internals of Solr and what QueryComponent does, so can you create a test-case that tests sorting of trie fields?\n\nI'm also not very familiar with that code in QueryComponent but I guess that is executed only when field-sort-values are requested (for distributed search). I wrote tests for sorting and it works fine! So I think the problem will only be during Distributed Search. I'll modify TestDistributedSearch to test sorting of trie fields to be sure. If it doesn't, I'll open another issue to replace the deprecated ScoreDocComparator with FieldComparator.\n\n\nUpdated patch, that supports ValueSource (currently not for Date Trie fields, I do not know how this should work, the orginal DateField uses a StringIndex as ValueSource, which is not possible for trie date fields, as no parser available and if using the standard string index, would fail because of more than one term/doc). Some tests for function queries are needed (especially as Double and FloatParser are not tested by Lucene at the moment), maybe change a test for conventional XxxFields to do the same test with a trie field.\n\nI'll write tests for these as well. But trie date is just a trie long field so we should be able to use a LongFieldSource for this, right? "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-12698188",
            "date": "2009-04-12T08:14:24+0000",
            "content": "I'm also not very familiar with that code in QueryComponent but I guess that is executed only when field-sort-values are requested (for distributed search). I wrote tests for sorting and it works fine! So I think the problem will only be during Distributed Search. I'll modify TestDistributedSearch to test sorting of trie fields to be sure. If it doesn't, I'll open another issue to replace the deprecated ScoreDocComparator with FieldComparator.\n\nOK. If distributed search does not work, the problems are bigger: The problem is not the comparator alone, the problem is the FieldCache. The distributed search should fill the values into FieldCache and then let the comparator do the work. Comparing lucenes code with the solr ones shows, that there are some parts of LUCENE-1478 missing. The Comparators use the default parser instead of the one given in SortField.getParser() to parse the values (when retrieving FieldCache.getInts() & Co).\n\nI am not really sure, why Solr needs to duplicate the sorting code from Lucene? Maybe this is no longer needed? In this case, everything would be ok when removed. "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12698202",
            "date": "2009-04-12T10:21:05+0000",
            "content": "Changes:\n\n\tAdded Tests for Sorting on all trie type fields\n\tReturn a LongFieldSource for trie date types\n\tAdded Tests for function queries on all trie type fields\n\tUpgraded Lucene jars to r764281\n\tCreated new ReverseStringFilterFactory for ReverseStringFilter through ant stub-factories\n\n\n\nAll tests pass.\n\nThis patch also contains changes for SOLR-1079 and LUCENE-1500. These are enough changes for one issue. I'll commit this shortly and then we can deal with sorting in distributed search through a new issue. "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12698208",
            "date": "2009-04-12T11:06:29+0000",
            "content": "Committed revision 764291.\n\nThanks Uwe!\n\n\n\tUpdating Lucene jars\n\tUpdating Trie field types per Lucene's changes\n\tAdding ReverseStringFilterFactory\n\tFix compile errors related to LUCENE-1500\n\n\n\nCommitting all the above changes in one go to avoid compile errors due to Lucene API updates (except for ReverseStringFilterFactory). "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-12699694",
            "date": "2009-04-16T13:20:51+0000",
            "content": "Again a change....\n*TrieRangeQuery is now available as separate class, *TrieRangeFilter is not needed for Solr range queries (LUCENE-1602). It has now equal sematics liek RangeQuery and can also be switched between constant score and boolean query rewrite.\nThe next change will be the move to core, package renames and a possibly new name NumericRangeQuery in Lucene core (see java-dev@lucene discussions). Stay tuned. "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12699732",
            "date": "2009-04-16T15:45:00+0000",
            "content": "Lets keep this issue open until trie is in core. "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12699735",
            "date": "2009-04-16T16:03:44+0000",
            "content": "Patch to incorporate LUCENE-1602\n\nNeed to upgrade Lucene jars before we can commit this. "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-12702096",
            "date": "2009-04-23T20:43:47+0000",
            "content": "I modified the patch a little bit to also include an updated documentation about sorting and function queries. "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12702307",
            "date": "2009-04-24T10:07:13+0000",
            "content": "Committed revision 768240.\n\nI also added a method SolrIndexSearcher#search(Weight, Filter, Collector) to fix a compile error.\n\nThanks Uwe! "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-12721947",
            "date": "2009-06-19T19:21:25+0000",
            "content": "The first part of the move to core is done, when the second part (LUCENE-1701) is done, I will post a patch! "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-12723342",
            "date": "2009-06-23T22:51:55+0000",
            "content": "Patch with changes for new Trie API in Lucene Core, the term \"trie\" does not appear anymore in Lucene (its now NumericRangeQuery, NumericTokenStream, NumericField, NumericUtils). This patch only contains changes for Trie and FieldCache/ExtendedFieldCache merging (as this affects trie, ExtendedFieldCache was deprecated in Lucene and merged into FieldCache. LongParsers now extend FieldCache.LongParser, for backwards compatibility there is a ExFieldCache.LongParser, too, but the new TrieAPI cannot handle this. So all occurences to ExtendedFieldCache must be removed from Solr)\n\nThe latest changes to Collector (new abstract method handleDocsOutOfOrder()) are not handled!!! Patch is therefore untested, but should work.\n\nThere is also FSDirectory-Factory of Solr changed to use the new FSDirectory.open() call that is the same like your factory (chooses dir dependent on platform). "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12723752",
            "date": "2009-06-24T21:30:45+0000",
            "content": "Thanks Uwe!\n\nRegarding Collector#acceptsDocsOutOfOrder, I think we need to\n\n\tReturn true when we do not need scores, otherwise false.\n\tDocSetCollector and DocSetDelegateCollector collect in order so we return false\n\n\n\nIt'd be great if someone who know more about this stuff can confirm.\n\nSOLR-1241 must also be committed together with this issue to avoid compile errors.\n\nI'm also seeing this exception in many tests (DisMaxRequestHandlerTest, TestTrie, TestDistributedSearch) which, I guess, are related to LUCENE-1630\n\nSEVERE: java.lang.UnsupportedOperationException\n\tat org.apache.lucene.search.Query.createQueryWeight(Query.java:102)\n\tat org.apache.lucene.search.BooleanQuery$BooleanWeight.<init>(BooleanQuery.java:185)\n\tat org.apache.lucene.search.BooleanQuery.createQueryWeight(BooleanQuery.java:401)\n\tat org.apache.lucene.search.Query.queryWeight(Query.java:120)\n\tat org.apache.lucene.search.Searcher.createQueryWeight(Searcher.java:237)\n\tat org.apache.lucene.search.Searcher.search(Searcher.java:173)\n\tat org.apache.solr.search.SolrIndexSearcher.getDocListAndSetNC(SolrIndexSearcher.java:1103)\n\tat org.apache.solr.search.SolrIndexSearcher.getDocListC(SolrIndexSearcher.java:880)\n\tat org.apache.solr.search.SolrIndexSearcher.search(SolrIndexSearcher.java:341)\n\tat org.apache.solr.handler.component.QueryComponent.process(QueryComponent.java:176)\n\tat org.apache.solr.handler.component.SearchHandler.handleRequestBody(SearchHandler.java:195)\n\tat org.apache.solr.handler.RequestHandlerBase.handleRequest(RequestHandlerBase.java:131)\n\tat org.apache.solr.core.SolrCore.execute(SolrCore.java:1290)\n\nI'll try to have another look tomorrow. "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-12723938",
            "date": "2009-06-25T08:10:35+0000",
            "content": "\nRegarding Collector#acceptsDocsOutOfOrder, I think we need to\n\n\tReturn true when we do not need scores, otherwise false.\n\tDocSetCollector and DocSetDelegateCollector collect in order so we return false\nIt'd be great if someone who know more about this stuff can confirm.\n\n\n\nMy explanation without guarantee: If you set it to true or false depends on your collector not on the type of query or sorting or you need scores. It gives the query engine a hint, if it is possible to deliver the doc ids out of order.\n\nSimple case is the example in the Collector JavaDocs: if you just mark the docids in an OpenBitSet, the order is irrelevant (bitset is not faster/slower when it does not get the docs in correct order). On the other hand collectors like TopDocs and so on can be optimized to be faster when the docs come in order. One example would be: if you read stored fields of documents using the setNextReader() given indexReader, it may be good to have the docs in order to avoid back/forward seeking all the time.\n\nI'm also seeing this exception in many tests (DisMaxRequestHandlerTest, TestTrie, TestDistributedSearch) which, I guess, are related to LUCENE-1630\n\nI think, this is because you have a custom query type which implements an own weight. There are possibilities to fix this using a wrapper, not sure. "
        },
        {
            "author": "Michael McCandless",
            "id": "comment-12723975",
            "date": "2009-06-25T09:41:44+0000",
            "content": "Shalin I think that exception you got is a break in back-compat.  Sorry   I'm reopening LUCENE-1630 to fix it... "
        },
        {
            "author": "Michael McCandless",
            "id": "comment-12724080",
            "date": "2009-06-25T13:14:23+0000",
            "content": "OK I just committed a fix for LUCENE-1630 that should fix that exception. "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12724248",
            "date": "2009-06-25T20:13:33+0000",
            "content": "OK I just committed a fix for LUCENE-1630 that should fix that exception\n\nThanks Mike. I upgraded to lucene trunk and something is still not right. Now I see a StackOverflowException:\n\njava.lang.StackOverflowError\n        at org.apache.solr.search.function.FunctionQuery.rewrite(FunctionQuery.java:50)\n        at org.apache.lucene.search.IndexSearcher.rewrite(IndexSearcher.java:291)\n        at org.apache.lucene.search.Query.queryWeight(Query.java:125)\n        at org.apache.lucene.search.Query.weight(Query.java:117)\n        at org.apache.lucene.search.Query.createQueryWeight(Query.java:108)\n        at org.apache.lucene.search.Query.queryWeight(Query.java:126)\n        at org.apache.lucene.search.Query.weight(Query.java:117)\n        at org.apache.lucene.search.Query.createQueryWeight(Query.java:108)\n        at org.apache.lucene.search.Query.queryWeight(Query.java:126)\n        at org.apache.lucene.search.Query.weight(Query.java:117) "
        },
        {
            "author": "Michael McCandless",
            "id": "comment-12724255",
            "date": "2009-06-25T20:28:08+0000",
            "content": "Sigh.  I'll go reopen LUCENE-1630! "
        },
        {
            "author": "Michael McCandless",
            "id": "comment-12724286",
            "date": "2009-06-25T20:57:39+0000",
            "content": "OK try again?  Maybe 3rd time's the charm... "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12725566",
            "date": "2009-06-30T10:29:38+0000",
            "content": "Uwe, is there a reason to disallow fully open ranges?\n\nWith the previous IntTrieRangeFilter, I could do a query for field:[* TO *] but this is not allowed anymore because NumericRangeQuery can take only one of the boundaries as null but not both. "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-12725568",
            "date": "2009-06-30T10:32:26+0000",
            "content": "Oh, this was intended.\n\nthe reason was, that all other range filters in lucene core do not allow this. In general one should use a MatchAllDocsQuery in this case, as it is more performant.\nI could enable it again, but I have to think about the other range queries and filters then.\n\nHow do you handle that with other range queries? "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12725588",
            "date": "2009-06-30T11:55:06+0000",
            "content": "\nthe reason was, that all other range filters in lucene core do not allow this. \n\nIf you look at RangeQuery constructor, it creates a new Term instance (even for null lower and upper) so an open ended search executes fine.\n\nIn general one should use a MatchAllDocsQuery in this case, as it is more performant\n\nBut a MatchAllDocsQuery is not equivalent to this when some documents do not have a value for this field. For example,  fq=: AND -f:[* TO *] will match all documents which do not have a value for field f. "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-12725590",
            "date": "2009-06-30T12:08:08+0000",
            "content": "You are right, but normally a new Term(field,null) should be not allowed. The init method should normally prevent this, but only checks for the terms ==null. The RangeTermEnum is then positioned on the null term (should be \"\").\n\nI will change this back (also in FieldCacheRangeFilter) and fix the wrong logic of RangeQuery to clearly support it. "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-12725594",
            "date": "2009-06-30T12:29:44+0000",
            "content": "Fixed in Lucene trunk rev 789692. The strange null handling in RangeQuery (which caused by change) will be fixed together in LUCENE-1713, when RangeQuery will be deprecated and renamed. "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12725597",
            "date": "2009-06-30T12:33:44+0000",
            "content": "I think you are fixing it the wrong way.\n\nWhy should it not be allowed? This is something which has worked since a long time. I don't think it is a bug and it is useful at times.\n\nSorry I posted too soon.\n\nReading your comment again, I guess that you are indeed going to support such queries? "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-12725600",
            "date": "2009-06-30T12:43:16+0000",
            "content": "I think you are fixing it the wrong way. \n\nYou misunderstood, I meant:\nI fix it, that it is clear what it really does. I will not change RangeQuerys behaviour, I will remove the whole internal Term handling in LUCENE-1713 and only use String field, lower, upper. Then it is clear how it works. The current code has this strange behaviour (how it handles Term instances)  because of the retrofitting of RangeQuery to MultiTermQuery. "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-12725605",
            "date": "2009-06-30T12:48:30+0000",
            "content": "Yes, it now works with RangeQuery/Filter (as before), NumericRangeQuery/Filter and FieldCacheRangeFilter.\n\nI will fix the strange usage of Term instance when we deprecate the old RangeQuery in favour of TermRangeQuery & Co. (LUCENE-1713).\nThe current check in RangeQuery ony prevents you to create a RangeQuery using the Term instances (instead of field, string, string), where both are null (because with both terms entirely null, no field name is available). "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12725619",
            "date": "2009-06-30T13:12:57+0000",
            "content": "Yes, it now works with RangeQuery/Filter (as before), NumericRangeQuery/Filter and FieldCacheRangeFilter. \n\nSuper, Thanks! "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12726047",
            "date": "2009-07-01T13:10:10+0000",
            "content": "This patch includes Uwe's last patch, changes related to LUCENE-1614 and SOLR-1241.\n\nThe QueryElevationComponentTest fails with Lucene trunk which I'll look into. "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-12730479",
            "date": "2009-07-13T19:43:30+0000",
            "content": "Hi Shalin,\n\nhere is an additional patch (but only for the trie parts), that is more intelligent and also uses NumericTokenStream for the query time factory. Your previous patch must be applied, then revert the changes in analysis.TrieXxxxTokenizerFactory and TrieField. Then apply the patch, which removes the old factories and creates a new one TrieTokenizerFactory. It should compile, but not really tested (it is hard to apply all your changes). If there are compile errors, they can be easily fixed \n\nThe idea is to use the same tokenstream for query time analysis. To only produce the highest precision token needed for that, it is simply using a precisionStep of 32 for int/float and 64 for long/double/date of the former TrieIndexTokenizerFactory. No magic with KeywordTokenizer needed. NumericUtils, which is a expert Lucene class (not really public) is not needed anymore. "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-12730759",
            "date": "2009-07-14T09:51:51+0000",
            "content": "Same patch updated, but uses the new feature of TrieRange to specify any large precStep to index only one token (uses now Integer.MAX_VALUE as precStep for the query tokenizer). "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12731320",
            "date": "2009-07-15T07:35:36+0000",
            "content": "Thanks Uwe!\n\nI'm having trouble figuring out the root cause behind the failure of QueryElevationComponentTest. When elevation is enabled, it seems to be sorting by score desc even if score asc is specified. I've written a testcase which I'll post to java-user to get some info on what could be going wrong. "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-12731396",
            "date": "2009-07-15T11:23:26+0000",
            "content": "I think your problem is solved now (thanks Mike).\n\nIf you update to latest trunk, you must also apply SOLR-1261 (rename of RangeQuery to TermRangeQuery). "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12731558",
            "date": "2009-07-15T17:00:19+0000",
            "content": "Attached patch which combines SOLR-940, SOLR-1261 and SOLR-1241 which need to be committed together to avoid compile errors.\n\nI'll upgrade Lucene jars to Lucene 2.9-dev r794238.\n\nAll tests pass. I'll commit shortly. "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-12731567",
            "date": "2009-07-15T17:22:12+0000",
            "content": "Patch looks good! "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12731571",
            "date": "2009-07-15T17:26:59+0000",
            "content": "Committed revision 794328.\n\nThanks Uwe and Mike! "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12775620",
            "date": "2009-11-10T15:51:54+0000",
            "content": "Bulk close for Solr 1.4 "
        }
    ]
}