{
    "id": "LUCENE-527",
    "title": "Bug in  the TermDocs.freq() method?",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [],
        "type": "Bug",
        "fix_versions": [],
        "affect_versions": "1.9",
        "resolution": "Invalid",
        "status": "Closed"
    },
    "description": "I belive I get incorrect data from the TermDocs.freq() method. The attached code demonstrate this. Document one has correct term count. In document zero and two, the term \"stored\" and \"indexed\" is reported to occure once in both documents. This is incorrect.\n\n\n// LuceneTest.java\n\nimport org.apache.lucene.analysis.Analyzer;\nimport org.apache.lucene.analysis.standard.StandardAnalyzer;\nimport org.apache.lucene.queryParser.ParseException;\nimport org.apache.lucene.document.*;\nimport org.apache.lucene.index.*;\nimport org.apache.lucene.search.*;\nimport org.apache.lucene.queryParser.QueryParser;\nimport org.apache.lucene.store.RAMDirectory;\nimport org.apache.lucene.store.Directory;\n\npublic class LuceneTest{\n\n\tpublic LuceneTest(){}\n\n    public static void main(String[] args){\n\n\t\tIndexWriter writer;\n\t\tIndexReader reader;\n\t\tSearcher searcher;\n\t\tDocument doc;\n\t\tDirectory dir = new RAMDirectory();\n\n\t\ttry{\n\t\t\t// create index\n\t\t\twriter = new IndexWriter( dir , new StandardAnalyzer(), true);\n\n\t\t\tdoc = new Document();\n\t\t\tdoc.add( new Field( \"title\", \"Doc 0\", Field.Store.YES, Field.Index.TOKENIZED ) );\n\t\t\tdoc.add( new Field( \"contents\", \"Text Text and more Text\", Field.Store.NO, Field.Index.TOKENIZED ) );\n\t\t\twriter.addDocument(doc);\n\n\t\t\tdoc = new Document();\n\t\t\tdoc.add( new Field( \"title\", \"Doc 1\", Field.Store.YES, Field.Index.TOKENIZED ) );\n\t\t\tdoc.add( new Field( \"contents\", \"This text is not stored, only indexed.\", Field.Store.NO, Field.Index.TOKENIZED ) );\n\t\t\twriter.addDocument(doc);\n\n\t\t\tdoc = new Document();\n\t\t\tdoc.add( new Field( \"title\", \"Doc 2\", Field.Store.YES, Field.Index.TOKENIZED ) );\n\t\t\tdoc.add( new Field( \"contents\", \"Text Text Text Text\", Field.Store.NO, Field.Index.TOKENIZED ) );\n\t\t\twriter.addDocument(doc);\n\n\t\t\twriter.close();\n\n\t\t\t// search\n\t\t\tsearcher = new IndexSearcher(dir);\n\t\t\treader = IndexReader.open(dir);\n\n\t\t\tQueryParser qp = new QueryParser(\"contents\", new StandardAnalyzer());\n            Query query = qp.parse(\"stored and indexed text\");\n        \tString[] terms = \n{\"stored\", \"indexed\", \"text\"}\n;\n\n\t\t\tHits queryHits = searcher.search(query);\n\n\t\t\t// print results\n\t\t\tSystem.out.println( \"Found \" + queryHits.length() + \" hits.\");\n\n\t\t\tfor(int i=0; i<queryHits.length(); i++){\n\t\t\t\tdoc = queryHits.doc;\n\t\t\t\tSystem.out.println(\"*** \" + doc.get(\"title\") + \" ***\");\n\n\t\t\t\tint docID = queryHits.id;\n\t\t\t\tfor (int j=0; j<terms.length; j++)\n{\n\t\t\t\t\tTermDocs td = reader.termDocs( new Term(\"contents\", terms[j]) );\n\t\t\t\t\ttd.skipTo(docID);\n\t\t\t\t\tSystem.out.println( \"Term '\" + terms[j] + \"' occures \" +\n\t\t\t\t\t\ttd.freq() + \" time(s) in document nr. \" + docID );\n\t\t\t\t}\n\t\t\t}\n\n\t\t}catch(Exception e)\n{System.out.println(\"Darn\");}\n\t}\n\n}",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "date": "2006-03-20T16:10:56+0000",
            "content": "This is not a valid test case.\n\nFrom the documentation for TermDocs.skipTo...\n\nSkips entries to the first beyond the current whose document number is greater than or equal to target.\n\nIt returns true or false to indicate if there was any such entry, and the doc() method should be used to check and see what the first document it found was \u2013 you can't assume it will be the same as the docId you specified.\n\ni believe the test will demonstrate what you expect, if you replace your j-loop with...\n\nfor (int j=0; j<terms.length; j++){\n    TermDocs td = reader.termDocs( new Term(\"contents\", terms[j]) );\n    if (td.skipTo(docID) && td.doc() == docID) \n{\n        System.out.println( \"Term '\" + terms[j] + \"' occures \" +\n                            td.freq() + \" time(s) in document nr. \" + docID );\n    }\n}\n\n\n ",
            "author": "Hoss Man",
            "id": "comment-12371047"
        },
        {
            "date": "2006-03-20T18:15:24+0000",
            "content": "My mistake then.\n\nThanks for the help, and sorry about raising bells unnessessary.\n\nChanged the code to :\nfor (int j=0; j<terms.length; j++){\n\tTermDocs td = reader.termDocs( new Term(\"contents\", terms[j]) );\n\tif (td.skipTo(docID) && td.doc() == docID) \n{\n\t\tSystem.out.println( \"Term '\" + terms[j] + \"' occures \" +\n\t\ttd.freq() + \" time(s) in document nr. \" + docID );\n\t}\n\telse \n{\n\t\tSystem.out.println( \"Term '\" + terms[j] + \"' occures \" +\n\t\t0 + \" time(s) in document nr. \" + docID );\n\t}\n} ",
            "author": "H\u00e5kon T. Bommen",
            "id": "comment-12371055"
        }
    ]
}