{
    "id": "SOLR-11968",
    "title": "Multi-words query time synonyms",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [
            "query parsers",
            "Schema and Analysis"
        ],
        "type": "Bug",
        "fix_versions": [],
        "affect_versions": "6.6.2,                                            master (8.0)",
        "resolution": "Duplicate",
        "status": "Resolved"
    },
    "description": "I am trying multi words query time synonyms with Solr 6.6.2 and SynonymGraphFilterFactory filter as explain in this article\n https://lucidworks.com/2017/04/18/multi-word-synonyms-solr-adds-query-time-support/\n \u00a0\n My field type is :\n\n<fieldType name=\"textSyn\" class=\"solr.TextField\" positionIncrementGap=\"100\">\n \u00a0 \u00a0 <analyzer type=\"index\">\n \u00a0 \u00a0 \u00a0 <tokenizer class=\"solr.StandardTokenizerFactory\"/>\n \u00a0 \u00a0 \u00a0 <filter class=\"solr.ElisionFilterFactory\" ignoreCase=\"true\"\u00a0\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 articles=\"lang/contractions_fr.txt\"/>\n \u00a0 \u00a0 \u00a0 <filter class=\"solr.LowerCaseFilterFactory\"/>\n \u00a0 \u00a0 \u00a0 <filter class=\"solr.ASCIIFoldingFilterFactory\"/>\n \u00a0 \u00a0 \u00a0 <filter class=\"solr.StopFilterFactory\" words=\"stopwords.txt\" ignoreCase=\"true\"/>\n \u00a0 \u00a0 \u00a0 <filter class=\"solr.FrenchMinimalStemFilterFactory\"/>\n \u00a0 \u00a0 </analyzer>\n \u00a0 \u00a0 <analyzer type=\"query\">\n \u00a0 \u00a0 \u00a0 <tokenizer class=\"solr.StandardTokenizerFactory\"/>\n \u00a0 \u00a0 \u00a0 <filter class=\"solr.ElisionFilterFactory\" ignoreCase=\"true\"\u00a0\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 articles=\"lang/contractions_fr.txt\"/>\n \u00a0 \u00a0 \u00a0 <filter class=\"solr.LowerCaseFilterFactory\"/>\n \u00a0 \u00a0 \u00a0 <filter class=\"solr.SynonymGraphFilterFactory\" synonyms=\"synonyms.txt\"\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ignoreCase=\"true\" expand=\"true\"/>\n \u00a0 \u00a0 \u00a0 <filter class=\"solr.ASCIIFoldingFilterFactory\"/>\n \u00a0 \u00a0 \u00a0 <filter class=\"solr.StopFilterFactory\" words=\"stopwords.txt\" ignoreCase=\"true\"/>\n \u00a0 \u00a0 \u00a0 <filter class=\"solr.FrenchMinimalStemFilterFactory\"/>\n \u00a0 \u00a0 </analyzer>\n \u00a0 </fieldType>\n\n\u00a0\n synonyms.txt contains the line :\n\nom, olympique de marseille\n\n\u00a0\n stopwords.txt contains the word\u00a0\n\nde\n\n\u00a0\n The order of words in my query has an impact on the generated query in edismax\n\nq={!edismax qf='name_text_gp' v=$qq}\n &sow=false\n &qq=...\n\nwith \"qq=om maillot\" or \"qq=olympique de marseille maillot\", I can see the synonyms expansion. It is working as expected.\n\n\"parsedquery_toString\":\"+(((+name_text_gp:olympiqu +name_text_gp:marseil +name_text_gp:maillot) name_text_gp:om))\",\n \"parsedquery_toString\":\"+((name_text_gp:om (+name_text_gp:olympiqu +name_text_gp:marseil +name_text_gp:maillot)))\",\n\nwith \"qq=maillot om\" or \"qq=maillot olympique de marseille\", I can see the same generated query\u00a0\n\n\"parsedquery_toString\":\"+((name_text_gp:maillot) (name_text_gp:om))\",\n \"parsedquery_toString\":\"+((name_text_gp:maillot) (name_text_gp:om))\",\n\nI don't understand these generated queries. The first one looks like the synonym expansion is ignored, but the second one shows it is not ignored and only the synonym term is used.\n \u00a0\n When I test the analisys for the field type the synonyms are correctly expanded for both expressions\n\nom maillot\u00a0\u00a0\n maillot om\n olympique de marseille maillot\n maillot olympique de marseille\n\nresulting outputs always include the following terms (obvioulsly not always in the same order)\n\nolympiqu om marseil maillot\u00a0\n\n\u00a0\n So, i suspect an issue with edismax query parser.",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "date": "2018-02-11T20:28:42+0000",
            "content": "I can see the same behavior on master too, not just on the releases/lucene-solr/6.6.2 tag.\n\nOne interesting thing I found is that if I remove the stop filter from the query analyzer, I get the following for qq=\u201cmaillot om\u201d:\n\n+((name_text_gp:maillot) (((+name_text_gp:olympiqu +name_text_gp:de +name_text_gp:marseil) name_text_gp:om))) ",
            "author": "Steve Rowe",
            "id": "comment-16360105"
        },
        {
            "date": "2018-02-11T21:56:16+0000",
            "content": "According to steve's comments, I made this test :\n\n1/ put the SynonymGraphFilterFactory after the StopFilterFactory in query time analyze chain\n\n<analyzer type=\"query\">\n <tokenizer class=\"solr.StandardTokenizerFactory\"/>\n <filter class=\"solr.ElisionFilterFactory\" ignoreCase=\"true\" articles=\"lang/contractions_fr.txt\"/>\n <filter class=\"solr.LowerCaseFilterFactory\"/>\n <filter class=\"solr.ASCIIFoldingFilterFactory\"/>\n <filter class=\"solr.StopFilterFactory\" words=\"stopwords.txt\" ignoreCase=\"true\"/>\n <filter class=\"solr.SynonymGraphFilterFactory\" synonyms=\"synonyms.txt\"\n    ignoreCase=\"true\" expand=\"true\" />\n <filter class=\"solr.FrenchMinimalStemFilterFactory\"/>\n</analyzer>\n\n2/ remove the stop word in the synonyms file\n\nom, olympique marseille\n\nThe parsed query string are :\n\nfor \"om maillot\"\n\n\"parsedquery_toString\":\"+(((((+name_text_gp:olympiqu +name_text_gp:marseil) name_text_gp:om)) (name_text_gp:maillot))~1)\",\n\nfor \"olympique de marseille maillot\"\n\n\"parsedquery_toString\":\"+((((name_text_gp:om (+name_text_gp:olympiqu +name_text_gp:marseil))) (name_text_gp:maillot))~1)\",\n\nfor \"maillot om\"\n\nparsedquery_toString\":\"+(((name_text_gp:maillot) (((+name_text_gp:olympiqu +name_text_gp:marseil) name_text_gp:om)))~1)\",\n\nfor \"maillot olympique de marseille\"\n\n\"parsedquery_toString\":\"+(((name_text_gp:maillot) ((name_text_gp:om (+name_text_gp:olympiqu +name_text_gp:marseil))))~1)\",\n\nThe query result count (numFound) are also the same for all queries. ",
            "author": "Dominique B\u00e9jean",
            "id": "comment-16360143"
        },
        {
            "date": "2018-02-16T03:56:20+0000",
            "content": "I think the root cause is LUCENE-4065.  I'll try to make a simple test demonstrating this. ",
            "author": "Steve Rowe",
            "id": "comment-16366586"
        },
        {
            "date": "2018-02-21T02:53:17+0000",
            "content": "I think the root cause is LUCENE-4065. I'll try to make a simple test demonstrating this.\n\nNot so - LUCENE-4065 should probably be closed as won't-fix (I'll comment there in a sec).\n\nInstead, this looks like the problem described in LUCENE-7848.  I tracked the problem down to a bug in Lucene's QueryBuilder, which is dropping tokens in side paths with position gaps that are caused by StopFilter.\n\nBelow is a test that shows the problem - MockSynonymFilter has synonym \"cavy\" for \"guinea pig\", and the anonymous analyzer below has \"pig\" on its stopfilter's stoplist.  QueryBuilder produces a query for only \"cavy\", even though the token stream also contains \"guinea\".\n\nTestQueryBuilder.java\n  public void testGraphStop() {\n    Query syn1 = new TermQuery(new Term(\"field\", \"guinea\"));\n    Query syn2 = new TermQuery(new Term(\"field\", \"cavy\"));\n\n    BooleanQuery synQuery = new BooleanQuery.Builder()\n        .add(syn1, BooleanClause.Occur.SHOULD)\n        .add(syn2, BooleanClause.Occur.SHOULD)\n        .build();\n    BooleanQuery expectedGraphQuery = new BooleanQuery.Builder()\n        .add(synQuery, BooleanClause.Occur.SHOULD)\n        .build();\n    QueryBuilder queryBuilder = new QueryBuilder(new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        MockTokenizer tokenizer = new MockTokenizer();\n        TokenStream stream = new MockSynonymFilter(tokenizer);\n        stream = new StopFilter(stream, CharArraySet.copy(Collections.singleton(\"pig\")));\n        return new TokenStreamComponents(tokenizer, stream);\n      }\n    });\n    queryBuilder.setAutoGenerateMultiTermSynonymsPhraseQuery(true);\n    assertEquals(expectedGraphQuery, queryBuilder.createBooleanQuery(\"field\", \"guinea pig\", BooleanClause.Occur.SHOULD));\n  }\n}\n\n ",
            "author": "Steve Rowe",
            "id": "comment-16370883"
        },
        {
            "date": "2018-02-21T03:14:26+0000",
            "content": "LUCENE-4065 should probably be closed as won't-fix (I'll comment there in a sec).\n\nMaybe not?  Although the enablePositionIncrements() option was removed from StopFilter et al via LUCENE-4963, Robert Muir wrote that the idea in LUCENE-4065 may still have merit: https://discuss.elastic.co/t/stop-filter-problem-enablepositionincrements-false-is-not-supported-anymore-as-of-lucene-4-4-as-it-can-create-broken-token-streams/13457/5 ",
            "author": "Steve Rowe",
            "id": "comment-16370899"
        },
        {
            "date": "2018-02-21T04:03:55+0000",
            "content": "I think the issue is still valid, its a little more complex now because of positionLength (means more buffering when you see posLength > 1, because you'll need to adjust if you remove something in its path), but the idea is the same: give the user a choice between \"insert mode\" and \"replace mode\". But this new \"insert mode\" would actually work correctly, correcting posLengths before and posIncs after as appropriate. similar to how your editor might have to recompute some line breaks/word wrapping and so on.\n\nIf you have baseball (length=2), base(length=1), ball(length=1), and you delete \"base\" in this case, you need to change baseball's length to 1 before you omit it, because you deleted base. Thats the \"buffering before\" that would be required for posLength. And you still need the same buffering described on the issue for posInc=0 that might occur after the fact, so you don't wrongly transfer synonyms to different words entirely.\n\nIt would be slower than \"replace mode\" that we have today, but only because of the buffering, and I think its pretty contained, but I haven't fully thought it thru or tried to write any code. ",
            "author": "Robert Muir",
            "id": "comment-16370916"
        },
        {
            "date": "2018-02-21T21:23:55+0000",
            "content": "FYI Robert Muir I'm going to copy your comment ^^ over to LUCENE-4065 and comment on it there. ",
            "author": "Steve Rowe",
            "id": "comment-16372030"
        },
        {
            "date": "2018-02-21T22:35:05+0000",
            "content": "This issue is also described in\u00a0https://issues.apache.org/jira/browse/LUCENE-8137\u00a0. https://issues.apache.org/jira/browse/LUCENE-7848\u00a0is different, it is about adding gaps in the span query produced when multi-words synonym occurs. The problem here is about broken token stream where the posLength of some multi-word synonyms are invalidated by the removal of a token.\u00a0 The query builder in this case will omit some tokens because posLength is broken for some tokens. I like the idea of adding a new mode to StopFilter that updates posLength and posInc when needed because I don't think we can \"fix\" a broken token stream outside of the token filter that broke it. ",
            "author": "Jim Ferenczi",
            "id": "comment-16372127"
        },
        {
            "date": "2018-02-22T15:45:48+0000",
            "content": "Thanks Jim Ferenczi, I hadn't seen LUCENE-8137, I'll resolve this issue as a duplicate.\n\nThe problem here is about broken token stream where the posLength of some multi-word synonyms are invalidated by the removal of a token.\n\nI don't think the token streams are always broken?  E.g. for \"olimpique de marseille\" with synonym \"om\" and \"de\" as stopword (see this issue's description):\n\n\n\n\n\u00a0\nolimpique\nom\nmarseille\n\n\nposinc\n1\n0\n2\n\n\nposlen\n1\n3\n1\n\n\n\n\n\nIn ^^ , the posLength is not invalidated.  What exactly is broken here? ",
            "author": "Steve Rowe",
            "id": "comment-16372968"
        },
        {
            "date": "2018-02-22T17:23:53+0000",
            "content": "The posLen of olimpique is 1 but marseille has a posInc of 2. This means that there is a hole between olimpique and marseille but posLen doesn't indicate this hole. It should be corrected by the stop filter (e.g. setting the posInc of marseille to 1 or setting the poslen of olimpique to 2). We could try to detect this when we build the graph (olimpique points to a state that doesn't exist), that's what TokenStreamToAutomaton does but I don't think it can catch all cases. I think it's simpler to make sure that stopfilter doesn't break a graph like Robert suggested. ",
            "author": "Jim Ferenczi",
            "id": "comment-16373105"
        },
        {
            "date": "2018-02-22T17:30:52+0000",
            "content": "The posLen of olimpique is 1 but marseille has a posInc of 2. This means that there is a hole between olimpique and marseille but posLen doesn't indicate this hole.\n\nI think you're wrong, Jim Ferenczi.\n\nposLen (on olimpique) doesn't have to indicate this hole, because it doesn't have anything to do with the gap.\n\nolimpique points to a state that doesn't exist\n\nAha, this is the crux, I assume: the \"state that doesn't exist\" isn't actually represented by these two attributes, it has to be inferred.  IMHO the brokenness here is inability to handle gaps, not in token filters that produce them.\n\nI think it's simpler to make sure that stopfilter doesn't break a graph like Robert suggested.\n\nAFAICT Robert is suggesting a StopFilter mode that would optionally remove gaps.  IOW its current behavior would remain (and be the default). ",
            "author": "Steve Rowe",
            "id": "comment-16373123"
        },
        {
            "date": "2018-02-22T22:14:23+0000",
            "content": "\u00a0I think you're wrong,\u00a0Jim Ferenczi.\n\nwell it depends how you see the problem. I agree that the gap could be inferred when we build the graph, I have a patch that does that but there are some cases where we just can't. For instance the following synonym rules:\n\n`twd, the walking dead` creates a broken token stream if you set a stop word filter that removes \"the\" after the synonym filter:\n\n\n\n\n\u00a0\ntwd\nwalking\ndead\n\n\nposinc\n1\n1\n1\n\n\nposlen\n3\n1\n1\n\n\n\n\n\nThe gap produced by \"the\" is not propagated to the posInc of \"walking\" because the stop word appears on a token with a posInc equals to 0. There are other cases where it is not possible to \"fix\" the graph produced by the token stream which is why I said that a stop filter that would remove gaps is IMO the best solution.\n\n\u00a0AFAICT Robert is suggesting a StopFilter\u00a0mode\u00a0that would\u00a0optionally\u00a0remove gaps. IOW its current behavior would remain (and be the default).\n\nYes I know that it would be an optional mode but at least it would allow to remove stop words inside a multi words synonyms. ",
            "author": "Jim Ferenczi",
            "id": "comment-16373554"
        },
        {
            "date": "2018-02-22T23:59:51+0000",
            "content": "Thanks Jim, I didn't realize that StopFilter (and other FilteringTokenFilter's I assume) can still produce bad token streams.  I added a test showing this, based on your example, to LUCENE-4065.\n\nThere are other cases where it is not possible to \"fix\" the graph produced by the token stream which is why I said that a stop filter that would remove gaps is IMO the best solution\n\nDo you have examples of these other cases?  Maybe put them on LUCENE-4065? ",
            "author": "Steve Rowe",
            "id": "comment-16373710"
        },
        {
            "date": "2018-02-23T01:15:56+0000",
            "content": "Jim Ferenczi, sorry, based on feedback from Robert over on LUCENE-4065 (see my comments there), I no longer see how your \"twd/the walking dead\" example represents graph corruption.  Can you say more about why you call it corruption? ",
            "author": "Steve Rowe",
            "id": "comment-16373775"
        },
        {
            "date": "2018-02-23T04:51:45+0000",
            "content": "\nAFAICT Robert is suggesting a StopFilter mode that would optionally remove gaps. IOW its current behavior would remain (and be the default).\n\nI'm not sure about whether it should be the default, first we should even see if we can make it work so we can test it out. \n\nMaybe \"leaving a hole/gap\" that we do today is actually what is wrong, and just doesn't make sense at all now that positionLength is at play? Honestly it was kind of strange to begin with, e.g. that stopword removal has no impact on phrase queries. For example its definitely not what google seems to do with phrase queries, try \"walk plank\". \n\nThis definitely relates to the whole reason that I opened LUCENE-4065 in the first place: there was too much all conflated to one configuration option: the strange \"gap\" stuff mixed together with \"don't move synonyms to entirely different words\" all combined into one boolean. ",
            "author": "Robert Muir",
            "id": "comment-16373928"
        },
        {
            "date": "2018-02-23T05:10:36+0000",
            "content": "Also the stupid gap stuff acts different depending on language, how should exact phrases match singular<->plural in english but not farsi. And they won't match definite article \"the\" in english but will in bulgarian because thats a suffix there. Totally crazy even for non-graph cases  ",
            "author": "Robert Muir",
            "id": "comment-16373936"
        },
        {
            "date": "2018-02-23T09:37:45+0000",
            "content": "Jim Ferenczi, sorry, based on feedback from Robert over on LUCENE-4065 (see my comments there), I no longer see how your \"twd/the walking dead\" example represents graph corruption. Can you say more about why you call it corruption?\n\nSteve Rowe what I mean by corruption is that we need to \"infer\" the holes when we build the graph from the token stream. For some cases we are able to reconstruct the correct graph (see how TokenStreamToAutomaton does when it sees dead states) but there are cases where it is not possible. Here is another example:\n\nTestStopFilterFactory.java\npublic void testLeadingStopwordSynonymGraph() throws Exception {\n\u00a0 SynonymMap.Builder builder = new SynonymMap.Builder(true);\n\u00a0 builder.add(new CharsRef(\"twd\"), new CharsRef(\"the\\u0000walking\\u0000dead\"), true);\n\u00a0 builder.add(new CharsRef(\"twd\"), new CharsRef(\"the\\u0000man\"), false);\n\u00a0 final SynonymMap synonymMap = builder.build();\n\u00a0\n\u00a0 Analyzer analyzer = new Analyzer() {\n\u00a0 \u00a0 @Override\n\u00a0 \u00a0 protected TokenStreamComponents createComponents(String fieldName) {\n\u00a0 \u00a0 \u00a0 MockTokenizer tokenizer = new MockTokenizer();\n\u00a0 \u00a0 \u00a0 TokenStream stream = new SynonymGraphFilter(tokenizer, synonymMap, true);\n\u00a0 \u00a0 \u00a0 stream = new StopFilter(stream, CharArraySet.copy(Collections.singleton(\"the\")));\n\u00a0 \u00a0 \u00a0 return new TokenStreamComponents(tokenizer, stream);\n\u00a0 \u00a0 }\n\n\u00a0 };\n\u00a0TokenStream tokenStream = analyzer.tokenStream(\"field\", \"twd\");\n\u00a0assertTokenStreamContents(tokenStream,\n\u00a0new String[] \\{ \"twd\", \"walking\", \"dead\", \"man\" },\n\u00a0        null, null,\n \u00a0       new int[] \\{ 1,      1,             1,          1 }, // posinc\n\u00a0        new int[] \\{ 4,      1,             2,          1 }, // poslen\n\u00a0null);\n}\n\n\n\nIn this case \"walking\" and \"man\" appears on the same path so the graph contains \"twd\", \"walking dead\" and \"walking man\".\nThe token stream is not corrupted but the graph is wrong and I don't see how we can \"fix\" it outside of the stop filter. ",
            "author": "Jim Ferenczi",
            "id": "comment-16374145"
        }
    ]
}