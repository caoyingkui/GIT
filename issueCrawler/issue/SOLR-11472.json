{
    "id": "SOLR-11472",
    "title": "Leader election bug",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [],
        "type": "Bug",
        "fix_versions": [],
        "affect_versions": "7.1,                                            master (8.0)",
        "resolution": "Duplicate",
        "status": "Resolved"
    },
    "description": "SOLR-11407 uncovered a bug in leader election, where the same failing node is retried indefinitely.",
    "attachments": {
        "Console_output_of_AutoscalingHistoryHandlerTest_failure.txt": "https://issues.apache.org/jira/secure/attachment/12891669/Console_output_of_AutoscalingHistoryHandlerTest_failure.txt"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2017-11-06T22:57:14+0000",
            "content": "Is there any notes on how this bug manifests? ",
            "author": "Varun Thacker",
            "id": "comment-16241146"
        },
        {
            "date": "2017-11-07T08:39:37+0000",
            "content": "I'm looking at this Varun. I'll post a summary once I've it pinned down. ",
            "author": "Shalin Shekhar Mangar",
            "id": "comment-16241677"
        },
        {
            "date": "2017-11-08T11:30:51+0000",
            "content": "Here's the sequence of events:\n\n\ncore_node3 is leader for .system collection\nTest starts a new node at port 50071\nNode Added Trigger fires and a plan is computed.\naction=MOVEREPLICA&collection=.system&targetNode=127.0.0.1:50071_solr&replica=core_node3\n\tis processed first and core_node8 is added on port 50071\n\tbut before it recovers fully, the leader node core_node3 is unloaded\n\tcore_node6 becomes the leader and asks core_node8 to recover\naction=MOVEREPLICA&collection=.system&targetNode=127.0.0.1:50071_solr&replica=core_node6\n\tnow core_node6 is to be moved and core_node10 is added on port 50071\n\tbut before it can recover, core_node6 is also unloaded\n\tsystem_shard1_replica_n2 on port 49937 becomes the leader and asks core_node8 and core_node10 to sync with it\n\tbut before they can recover the test stops node 49937.\n\tThe NodeLostTrigger fires and tries to create a new replica\n\tBut leader election cannot happen because no nodes have any data and/or none of them were active before.\n\n\n\nThe crux of the issue is that move replica unloaded the leader before the newly added replica becomes active. Actually, Andrzej has fixed this problem already in SOLR-11448. The leader election issue seen in these logs is a known problem in SolrCloud. Mark Miller created SOLR-7065 to address the gridlock of leader election in such cases.\n\nI'll audit jenkins again to see if this test has failed since SOLR-11448 was committed. If not, then I'll close this issue. ",
            "author": "Shalin Shekhar Mangar",
            "id": "comment-16243764"
        },
        {
            "date": "2017-11-10T07:27:17+0000",
            "content": "The root cause has been fixed in SOLR-11448. I found 1 similar test failure on Oct 23 which was after SOLR-11448 was committed but the logs no longer exist and I haven't seen anything since. So I'll close this and re-open if necessary. ",
            "author": "Shalin Shekhar Mangar",
            "id": "comment-16247116"
        }
    ]
}