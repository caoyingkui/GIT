{
    "id": "SOLR-1499",
    "title": "SolrEntityProcessor - DIH EntityProcessor that queries an external Solr via SolrJ",
    "details": {
        "affect_versions": "None",
        "status": "Closed",
        "fix_versions": [
            "3.6",
            "4.0-ALPHA"
        ],
        "components": [
            "contrib - DataImportHandler"
        ],
        "type": "New Feature",
        "priority": "Major",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "The SolrEntityProcessor queries an external Solr instance. The Solr documents returned are unpacked and emitted as DIH fields.\n\nThe SolrEntityProcessor uses the following attributes:\n\n\n\tsolr='http://localhost:8983/solr/sms'\n\t\n\t\tThis gives the URL of the target Solr instance.\n\t\t\n\t\t\tNote: the connection to the target Solr uses the binary SolrJ format.\n\t\t\n\t\t\n\t\n\t\n\n\n\n\n\tquery='Jefferson&sort=id+asc'\n\t\n\t\tThis gives the base query string use with Solr. It can include any standard Solr request parameter. This attribute is processed under the variable resolution rules and can be driven in an inner stage of the indexing pipeline.\n\t\n\t\n\n\n\n\n\trows='10'\n\t\n\t\tThis gives the number of rows to fetch per request..\n\t\tThe SolrEntityProcessor always fetches every document that matches the request..\n\t\n\t\n\n\n\n\n\tfields='id,tag'\n\t\n\t\tThis selects the fields to be returned from the Solr request.\n\t\tThese must also be declared as <field> elements.\n\t\tAs with all fields, template processors can be used to alter the contents to be passed downwards.\n\t\n\t\n\n\n\n\n\ttimeout='30'\n\t\n\t\tThis limits the query to 5 seconds. This can be used as a fail-safe to prevent the indexing session from freezing up. By default the timeout is 5 minutes.\n\t\n\t\n\n\n\nLimitations:\n\n\tSolr errors are not handled correctly.\n\tLoop control constructs have not been tested.\n\tMulti-valued returned fields have not been tested.\n\n\n\nThe unit tests give examples of how to use it as the root entity and an inner entity.",
    "attachments": {
        "SOLR-1499.core.rev1182017.patch": "https://issues.apache.org/jira/secure/attachment/12498644/SOLR-1499.core.rev1182017.patch",
        "SOLR-1499.tests.rev1182017.patch": "https://issues.apache.org/jira/secure/attachment/12498643/SOLR-1499.tests.rev1182017.patch",
        "SOLR-1499.patch": "https://issues.apache.org/jira/secure/attachment/12421693/SOLR-1499.patch",
        "SOLR-1499-trunk.patch": "https://issues.apache.org/jira/secure/attachment/12506734/SOLR-1499-trunk.patch",
        "SOLR-1499-3x.patch": "https://issues.apache.org/jira/secure/attachment/12506730/SOLR-1499-3x.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Lance Norskog",
            "id": "comment-12763779",
            "date": "2009-10-09T01:45:34+0000",
            "content": "First release of SolrEntityProcessor + three unit tests. "
        },
        {
            "author": "Noble Paul",
            "id": "comment-12763804",
            "date": "2009-10-09T03:54:29+0000",
            "content": "Lance , could you have a usecase for this?  "
        },
        {
            "author": "Erik Hatcher",
            "id": "comment-12764686",
            "date": "2009-10-12T13:58:32+0000",
            "content": "The use case: a project that uses an intermediate Solr as a data \"store\".  This is then indexed from the store into (another) Solr instance, blending with other entities from other data sources. "
        },
        {
            "author": "Lance Norskog",
            "id": "comment-12764767",
            "date": "2009-10-12T17:57:44+0000",
            "content": "Formatting error in first uploaded patch file. "
        },
        {
            "author": "Erik Hatcher",
            "id": "comment-12765079",
            "date": "2009-10-13T13:48:58+0000",
            "content": "Attached new patch.  Reformats code, removing tabs.  Adjusts the hardcoded path (to make tests run in an IDE, set the current working dir to (<solr-working-dir>/contrib/dataimporthandler/src/test/resources) so tests run on my machine.   Refactored the mock stuff slightly so a setter is used rather than the entity processor knowing about the mock. "
        },
        {
            "author": "Erik Hatcher",
            "id": "comment-12765165",
            "date": "2009-10-13T17:45:38+0000",
            "content": "One issue, the iteration isn't stopping when it should.  Here's how I've set up my environment:\n\nLaunched Solr example the standard way, java -jar start.jar from the example directory.  Then java -jar post.jar *.xml from the exampledocs directory.\n\nUsing this configuration:\n\n<dataConfig>\n  <document>\n    <entity name=\"sep\" processor=\"SolrEntityProcessor\" solr=\"http://localhost:8983/solr\" query=\":\" transformer=\"TemplateTransformer\">\n      <field column=\"id\" template=\"COPYOF-${sep.id}\"/>\n    </entity>\n  </document>\n</dataConfig>\n\nMapped into solrconfig.xml like this: \n\n   <requestHandler name=\"/dataimport\" class=\"org.apache.solr.handler.dataimport.DataImportHandler\">\n    <lst name=\"defaults\">\n    \t<str name=\"config\">dataimport-solr.xml</str>\n    </lst>\n  </requestHandler>\n\nI then launched another Solr (with debugger enabled) like this:\nant run-example -Dexample.data.dir=example/sep -Dexample.debug=true -Dexample.jetty.port=8888\n\nDoing a full-import, I see the source Solr log this:\n\nINFO: [] webapp=/solr path=/select params=\n{wt=javabin&rows=50&start=0&timeAllowed=300000&q=*:*&version=1}\n hits=19 status=0 QTime=10 \nOct 13, 2009 1:40:45 PM org.apache.solr.core.SolrCore execute\nINFO: [] webapp=/solr path=/select params=\n{wt=javabin&rows=50&start=19&timeAllowed=300000&q=*:*&version=1}\n hits=19 status=0 QTime=0 \n\nSince there are only 19 documents, a second request shouldn't be made as all documents are in the first 50 originally requested.  \n\nReporting this for information.  I'm working on fixing it now. "
        },
        {
            "author": "Erik Hatcher",
            "id": "comment-12765218",
            "date": "2009-10-13T20:26:40+0000",
            "content": "This patch changes the iterator to throw NoSuchElementException, adjusts DIH, removes @Test annotations (convention of test* works for me , removed test-only SolrEntityProcessor(String) ctor as it wasn't needed, fixed issue with extra unnecessary request to source Solr, added root entity bit to DIH base TestContext. "
        },
        {
            "author": "Erik Hatcher",
            "id": "comment-12776000",
            "date": "2009-11-10T18:41:10+0000",
            "content": "we're seeing success with this in the field.  i'll polish and commit soon, barring objections. "
        },
        {
            "author": "Noble Paul",
            "id": "comment-12776005",
            "date": "2009-11-10T18:54:37+0000",
            "content": "is this entity processor planning to handle the onError flag? "
        },
        {
            "author": "Lance Norskog",
            "id": "comment-12838711",
            "date": "2010-02-26T05:06:47+0000",
            "content": "Add error-handling. Correctly handles skip, continue and abort.\nAdd unit tests for error-handling.\nRename unit tests for more clarity.\n\nStill has the flaw that all attributes are evaluated at the beginning. \nIt is not thread-safe.\n\nIncludes one non-backwards-compatible change: the 'solr' attribute is now 'url' to maintain consistency with the rest of the DIH.  "
        },
        {
            "author": "Hoss Man",
            "id": "comment-12872629",
            "date": "2010-05-27T22:09:32+0000",
            "content": "Bulk updating 240 Solr issues to set the Fix Version to \"next\" per the process outlined in this email...\n\nhttp://mail-archives.apache.org/mod_mbox/lucene-dev/201005.mbox/%3Calpine.DEB.1.10.1005251052040.24672@radix.cryptio.net%3E\n\nSelection criteria was \"Unresolved\" with a Fix Version of 1.5, 1.6, 3.1, or 4.0.  email notifications were suppressed.\n\nA unique token for finding these 240 issues in the future: hossversioncleanup20100527 "
        },
        {
            "author": "Ahmet Arslan",
            "id": "comment-13007236",
            "date": "2011-03-15T22:31:32+0000",
            "content": "Hi,\n\nCan i use this to upgrade solr version? Where the lucene/solr indices are not compatible?\n\nThanks,\nAhmet "
        },
        {
            "author": "Lance Norskog",
            "id": "comment-13007314",
            "date": "2011-03-16T02:07:59+0000",
            "content": "Yes you can!\n\n\n\tThe source index has to store all of the fields.\n\tI would do a series of short queries rather than one long one.\n\n\n\nThank you for thinking of this.\n\nIt could also be used to recombine cores- you can change your partitioning strategy, for example. "
        },
        {
            "author": "Ahmet Arslan",
            "id": "comment-13007516",
            "date": "2011-03-16T15:46:49+0000",
            "content": "Hi Lance,\n\nI setup patch to latest trunk. It required some change though. \nI pointed out a solr URL (version 1.4.0) to upgrade from 1.4.0 to trunk.\n\nI received :\n\nCaused by: java.lang.RuntimeException: Invalid version (expected 2, but 1) or the data in not in 'javabin' format\n\tat org.apache.solr.common.util.JavaBinCodec.unmarshal(JavaBinCodec.java:99)\n\tat org.apache.solr.client.solrj.impl.BinaryResponseParser.processResponse(BinaryResponseParser.java:41)\n\tat org.apache.solr.client.solrj.impl.CommonsHttpSolrServer.request(CommonsHttpSolrServer.java:478)\n\tat org.apache.solr.client.solrj.impl.CommonsHttpSolrServer.request(CommonsHttpSolrServer.java:245)\n\n\nWhat can be a work around to overcome this? "
        },
        {
            "author": "Erik Hatcher",
            "id": "comment-13007580",
            "date": "2011-03-16T17:28:07+0000",
            "content": "SolrEntityProcessor uses the SolrJ version of the indexing server... and unfortunately you can't overcome this currently, though I imagine a slight change to get the SolrJ calls using XML rather than javabin would work.\n\nAn alternative, if all you're doing is pulling stored fields and reindexing into another Solr, is to write a little script to do it.  In solr-ruby-speak, for example, there is a SolrSource class that can be used to iterate results... and then could be used to pass back into an Indexer.   The SolrEntityProcessor is more meant for when you need to blend data from other sources using the rest of DIH's capabilities. "
        },
        {
            "author": "Ahmet Arslan",
            "id": "comment-13007700",
            "date": "2011-03-16T21:43:19+0000",
            "content": "Eric,\n\nThanks for the pointer. As you said when I use \n\nnew CommonsHttpSolrServer(new URL(\"http://solr1.4.0Instance:8080/solr\"), null, new XMLResponseParser(), false);\n\nI was able to communicate to solr 1.4.0 instance using solrj-trunk.\n\nDo you recommend modifying this patch in this manner? Any performance hits?\n\n\nPlus, What do you think about copy-pasting JavaBinCodec.java from source version to destination version and Using a custom BinaryResponseParser that uses that copy-paste class? Seems working for 1.4.0 to trunk.\n\nOr should i stick with writing a little script to do it?\n\nP.S. I am just trying to use a feature that will be already maintained by solr commnunity. "
        },
        {
            "author": "Erik Hatcher",
            "id": "comment-13007919",
            "date": "2011-03-17T13:56:41+0000",
            "content": "Seems like a parameter to the SolrEntityProcessor that controls the format (format=\"javabin|xml\", perhaps) is warranted.  Performance hit?  I'm sure somewhat... since it now adds XML parsing and a larger payload over the wire.  \n\nAs for copying over the old codec - I think I'd rather just see it use the XML format for sanity's sake. "
        },
        {
            "author": "Erik Hatcher",
            "id": "comment-13007920",
            "date": "2011-03-17T13:57:32+0000",
            "content": "not an active area of development currently. "
        },
        {
            "author": "Ahmet Arslan",
            "id": "comment-13007990",
            "date": "2011-03-17T16:39:15+0000",
            "content": "Bring upto trunk version 1082579.\nAdd (format=\"javabin|xml\") parameter. xml is needed for solr upgrade where solr versions are not compatible. Test cases needs to be updated. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13043636",
            "date": "2011-06-03T16:46:14+0000",
            "content": "Bulk move 3.2 -> 3.3 "
        },
        {
            "author": "Lance Norskog",
            "id": "comment-13058848",
            "date": "2011-07-01T22:58:07+0000",
            "content": "Ahmet- are you still using this?  "
        },
        {
            "author": "Ahmet Arslan",
            "id": "comment-13059333",
            "date": "2011-07-04T06:34:10+0000",
            "content": "Lance, I used it once to upgrade.  "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13106487",
            "date": "2011-09-16T14:51:18+0000",
            "content": "3.4 -> 3.5 "
        },
        {
            "author": "Pulkit Singhal",
            "id": "comment-13124522",
            "date": "2011-10-10T22:09:27+0000",
            "content": "The updated patch is for lucene-solr trunk is attached. Sorry for naming it badly but apparently I can't edit the file name after attaching it: SOLR-1499.rev1181269.buggy.patch\n\nI need to message multivalued fields, is there any guidance around that? I know its not tested but how should one go about experimenting with it?\n\nFYI: To prove the patch works, I got a basic sanity-test to work where the data-config.xml file in my bbyopen2 core got its data from the initital bbyopen core:\n  1 <dataConfig>\n  2   <document>\n  3     <entity name=\"sep\"\n  4             processor=\"SolrEntityProcessor\"\n  5             url=\"http://localhost:8983/solr/bbyopen\"\n  6             query=\"sku:1000159\"\n  7             format=\"javabin\"\n  8             transformer=\"TemplateTransformer\">\n  9       <field column=\"sku\" template=\"COPYOF-${sep.sku}\"/>\n 10     </entity>\n 11    </document>\n 12 </dataConfig> "
        },
        {
            "author": "Lance Norskog",
            "id": "comment-13124649",
            "date": "2011-10-11T02:28:04+0000",
            "content": "Hi-\n\nFirst, get the unit tests to work. After that, we're ready to work on it. You do a full build at the top with \n\nant compile'\n\n\nand then cd to solr/contrib/dataimporthandler and \n\nant test\n\n\nWhen the unit tests do not work, something fundamental is broken and there is no point going further. In this case, the tests are broken because a solrconfig.xml sample file they depended on has gone away and you need to find replacements. "
        },
        {
            "author": "Erik Hatcher",
            "id": "comment-13124992",
            "date": "2011-10-11T12:53:35+0000",
            "content": "Pulkit - be sure check the box to license your patches to the ASF via ASL - otherwise we can't incorporate them. "
        },
        {
            "author": "Pulkit Singhal",
            "id": "comment-13125224",
            "date": "2011-10-11T17:49:56+0000",
            "content": "@ehatcher - Sure Erik, I'll keep that in mind from now on and will update the patch soon.\n@lancenorskog - Hey Lance, since you kicked this off, would you mind telling me what the purpose of contentstream-solrconfig.xml used to be so that I can find a replacement and include it with the patch update? "
        },
        {
            "author": "Pulkit Singhal",
            "id": "comment-13125231",
            "date": "2011-10-11T17:58:36+0000",
            "content": "Searching through \n\nsvn log -v\n\n shows:\nR /lucene/dev/trunk/solr/contrib/dataimporthandler/src/test-files/solr-dih/conf/contentstream-solrconfig.xml (from /lucene/dev/branches/solr2452/solr/contrib/dataimporthandler/src/test-files/solr-dih/conf/contentstream-solrconfig.xml:1144716)\n\nAnd a quick cmd+shift+r in Eclipse shows that a file with the same name exists at:\n/lucene_solr/solr/contrib/dataimporthandler/src/test-files/dih/solr/conf/contentstream-solrconfig.xml\n\nSo it seems that the path fragment \"/test-files/solr-dih/\" got changed to \"/test-files/dih/solr/\" "
        },
        {
            "author": "Pulkit Singhal",
            "id": "comment-13125283",
            "date": "2011-10-11T18:52:32+0000",
            "content": "@Lance - I've fixed the file path errors but with the the super.setup() errors, I cannot figure out how the test cases were meant to be setup and function. Can you please take this further when you have the time?\n\nYou will find the tests separated and attached to the latest trunk revision as of this comment:\nSOLR-1499.tests.rev1182017.patch\n\nThe core functionality seems to work well on its own when I use it without the test cases by just configuring my own sanity tests on the data-config.xml so I've updated and attached the core code to the latest trunk revision as of this comment:\nSOLR-1499.core.rev1182017.patch\n\nHopefully as soon as the test cases are in business, one of the committers will review this and commit it. "
        },
        {
            "author": "Luca Cavanna",
            "id": "comment-13139585",
            "date": "2011-10-30T11:06:30+0000",
            "content": "I tried the last 3.x patch and I've found a bug: I had 230 documents to import and rows=50 (default), but I imported only 200 documents (50*4); it means the last iteration, which had less than 50 rows to process, was skipped. I've fixed it.\nI've added a unit test to show the issue: it was failing before the correction and now it works. I changed the MockSolrServer to have a more real behaviour related to the \"rows\" and \"start\" parameters.\n\nFurthermore, multiValued fields seem to be working, so I added a unit test also for this.\n\nI've corrected some path errors on the last 3.x patch, also two tests (TestSolrEntityProcessorInner and TestSolrEntityProcessorOuter) were failing due to a wrong path. I added a base class to avoid repeating the SolrInstance inner class on both those tests.\n\nSince this is my first contribution, let me know if there's something wrong, I will be glad to correct my patch.  "
        },
        {
            "author": "Martijn van Groningen",
            "id": "comment-13139648",
            "date": "2011-10-30T15:50:04+0000",
            "content": "Looks good Luca! I see that the only differences between 3x and trunk are the changes in DataImporter class, so it easy to port this to trunk. I think we should move forward with this issue and get this feature committed. This issue has been created more than 2 years ago! So lets try to get this in the 3.5 release. "
        },
        {
            "author": "Luca Cavanna",
            "id": "comment-13144164",
            "date": "2011-11-04T17:03:46+0000",
            "content": "I attached a new version of the patch.\nI cleaned up the code and added a new core into the example-DIH folder to show how the SolrEntityProcessor works. The only problem  I see is that the example requires one more solr instance running and its address needs to be specified into the solr-data-config.xml file.\n\nI also have some doubts about the condition \nif (root) {\n  solrQuery.setQuery(queryString);\n}\n\ninside the SolrEntityProcessor#init method, but I haven't had yet the time to write a specific test.\nPlease let me know if you have some more suggestions! "
        },
        {
            "author": "Lance Norskog",
            "id": "comment-13144608",
            "date": "2011-11-05T06:26:48+0000",
            "content": "You can have the example point to the same Solr. One use case for this is for database updates: instead of relying on a file, you actually go query Solr to decide whether a record should be updated. "
        },
        {
            "author": "Martijn van Groningen",
            "id": "comment-13145584",
            "date": "2011-11-07T16:13:31+0000",
            "content": "Yes we can just point to db or rss core that is also included in the example.\n\nAfter looking into the code I have some concerns when the SolrEntityProcessor is configured with threads > 1 it seems to me that the code will fail. Basically the SolrQuery which is used to keep track of the offset is set as a field of the rowIterator and the rowIterator is a field of SolrEntityProcessor (actually its super class). It seems to me when more than one thread is operating on the SolrEntityProcessor that each thread can overwrite the offset of another thread. Seems like we need some locking.\n "
        },
        {
            "author": "Lance Norskog",
            "id": "comment-13145820",
            "date": "2011-11-07T21:24:38+0000",
            "content": "Good eye! I'm sure this is true. This was written before threads were implemented.  "
        },
        {
            "author": "Luca Cavanna",
            "id": "comment-13145855",
            "date": "2011-11-07T21:56:00+0000",
            "content": "You're of course right. There's also a comment at the beginning of the SolrEntityProcessor class: \"Is not thread-safe\". So, I guess at least the author of the comment was aware of it.  "
        },
        {
            "author": "Luca Cavanna",
            "id": "comment-13154224",
            "date": "2011-11-21T14:58:42+0000",
            "content": "I attached a new version of the patch.\nI made some refactors, added support for the fq parameter and added some test methods.\n\nRegarding the thread safety: of course the SolrEntityProcessor isn't thread-safe but the synchronization is handled outside that class, since nextRow() and init() methods are both called from a synchronized block. In fact, queries are not executed concurrently. I added some comments, and a specific unit test method which works like the EntityRunner. We can of course make the processor thread-safe itself adding some lock, but I don't think it's worthwhile.\n\nActually the patch is easier to apply also to the trunk I guess, since it contains just new files.\n\nPlease, let me know your thoughts! "
        },
        {
            "author": "Luca Cavanna",
            "id": "comment-13163441",
            "date": "2011-12-06T08:36:50+0000",
            "content": "Does someone have the time to have a look at my last patch? I'd like to know your opinions, hopefully we can have this feature available with the 3.6 version. "
        },
        {
            "author": "Martijn van Groningen",
            "id": "comment-13166042",
            "date": "2011-12-09T10:30:28+0000",
            "content": "\nRegarding the thread safety: of course the SolrEntityProcessor isn't thread-safe but the synchronization is handled outside that class, since nextRow() and init() methods are both called from a synchronized block. In fact, queries are not executed concurrently. I added some comments, and a specific unit test method which works like the EntityRunner. We can of course make the processor thread-safe itself adding some lock, but I don't think it's worthwhile.\nI see the ThreadedEntityProcessorWrapper#nextRow() method synchronizes the calls to nextRow(). This means that EntityProcessor implementations don't have to worry about synchronization. "
        },
        {
            "author": "Luca Cavanna",
            "id": "comment-13166047",
            "date": "2011-12-09T10:35:12+0000",
            "content": "I see the ThreadedEntityProcessorWrapper#nextRow() method synchronizes the calls to nextRow(). This means that EntityProcessor implementations don't have to worry about synchronization.\n\nRight, that's what I meant. "
        },
        {
            "author": "Martijn van Groningen",
            "id": "comment-13166096",
            "date": "2011-12-09T11:26:56+0000",
            "content": "Patch looks good. Made some minor changes:\n\n\tRemoved @override from interface methods (3x is java5)\n\tFixed example configuration\n\tMinor code format changes.\n\n\n\nI think it is ready to get committed. "
        },
        {
            "author": "Martijn van Groningen",
            "id": "comment-13166120",
            "date": "2011-12-09T12:08:57+0000",
            "content": "Patch for trunk. "
        },
        {
            "author": "Martijn van Groningen",
            "id": "comment-13166146",
            "date": "2011-12-09T13:19:01+0000",
            "content": "Committed to trunk and 3x. "
        },
        {
            "author": "Lance Norskog",
            "id": "comment-13167304",
            "date": "2011-12-12T01:27:50+0000",
            "content": "Cool!  Thanks everyone. "
        },
        {
            "author": "Mikhail Khludnev",
            "id": "comment-13181569",
            "date": "2012-01-06T20:22:54+0000",
            "content": "Couldn't you help me understand the DIH design: Why it's an EntityProcessor but not a DataSource?  "
        },
        {
            "author": "Noble Paul",
            "id": "comment-13182386",
            "date": "2012-01-09T06:25:40+0000",
            "content": "An DataSource is responsible for fetching data from an appropriate datastore say url/db/file etc . An EntitiProcessor should give the necessary input to the DataSource (e.g an sql query) and take get the rows of data from the DataSource and apply the needed transformations and put it to the index  "
        },
        {
            "author": "Lance Norskog",
            "id": "comment-13183000",
            "date": "2012-01-10T01:51:22+0000",
            "content": "There is no other EntityProcessor that would make use of a Solr DataSource, so it is ok for the SolrEntityProcessor to just have its own connection.  "
        },
        {
            "author": "Mikhail Khludnev",
            "id": "comment-13183535",
            "date": "2012-01-10T20:20:39+0000",
            "content": "@Noble,\nAgree. And why SolrDatasource can't get an url or q= or q=..&fq=... part from entity processor and return Iterator<Map<>> which is actually (or adaptable from) SolrDocumentList?\n\n@Lance,\nHypothetically why SqlEntityProcessor can't consume SolrDocumentList from SolrDatasource?\n\nIt seems I've missed something. Thanks for your replies. I'm asking because I need to make a lot of index scaffolding work like generate some random documents, etc. I feel something common with this ticket.\nI'm considering to employ ScriptTransformer idea and create ScriptDatasource or ScriptEntityProcessor. The former one seems much promising to me, because it can be used with any of entity processors. As an a query I consider just a string which is passed to script engine for evaluation. WDYT? "
        },
        {
            "author": "Lance Norskog",
            "id": "comment-13183767",
            "date": "2012-01-11T01:07:16+0000",
            "content": "Hypothetically why SqlEntityProcessor can't consume SolrDocumentList from SolrDatasource?\nNobody has needed this feature. The DataSource abstraction seems to be important when multiple entities share a common connection, or a common sequence of data from the DataSource. The SolrEP does not have this problem.\nSolrEP supplies fields to its child entities, and that has been enough for its users. "
        }
    ]
}