{
    "id": "LUCENE-8004",
    "title": "IndexUpgraderTool should rewrite segments rather than forceMerge",
    "details": {
        "labels": "",
        "priority": "Major",
        "resolution": "Won't Fix",
        "affect_versions": "None",
        "status": "Resolved",
        "type": "Improvement",
        "components": [],
        "fix_versions": []
    },
    "description": "Spinoff from LUCENE-7976. We help users get themselves into a corner by using forceMerge on an index to rewrite all segments in the current Lucene format. We should rewrite each individual segment instead. This would also help with upgrading X-2->X-1, then X-1->X.\n\nOf course the preferred method is to re-index from scratch.",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "id": "comment-16215507",
            "date": "2017-10-23T17:38:16+0000",
            "content": "Related, but definitely a tangent:\n\nI have noted in the past that forceMerge (optimize in Solr) runs quite a lot slower than the transfer rates that my disk array can reach.  On a system where the RAID10 array can easily go WELL beyond 100 megabytes per second for both reads and writes, the merge down to one segment only results in disk writes at 20 to 30 megabytes per second.  I would like to see this go faster, but when I think about the data manipulations required to combine postings for multiple segments, I can accept it if Lucene experts tell me that it's going as fast as it can already.\n\nBut I do wonder if maybe a segment rewrite as Erick has suggested here (which would not be an actual merge of multiple segments) could be improved so the postings are simply converted to the new format, rather than being rebuilt entirely as I believe a merge requires.  Since I am not very familiar with the actual format or exactly what it is that a merge actually does, I am not currently able to examine the code and answer my own question. ",
            "author": "Shawn Heisey"
        },
        {
            "id": "comment-16215682",
            "date": "2017-10-23T19:11:48+0000",
            "content": "Merges are usually compute bound, and a given merge is single threaded ... if you look in IndexWriter's info stream log you'll see which parts take the most time; it's usually postings in my experience.\n\nEspecially if you are merging away deleted docs, then we can't apply bulk copy optos for stored fields and term vectors.\n\nWe don't have a bulk copy opto for postings. ",
            "author": "Michael McCandless"
        },
        {
            "id": "comment-16423075",
            "date": "2018-04-02T20:19:40+0000",
            "content": "I'm about to tear into 7976, and this may come along \"for free\" so I'll take it, at least temporarily so as not to lose track of it. ",
            "author": "Erick Erickson"
        },
        {
            "id": "comment-16473283",
            "date": "2018-05-12T22:03:22+0000",
            "content": "Marking as blocker since I think there are some observations here that should be discussed and resolved before releasing 7.4. Related to LUCENE-7976.\n\n1> By default it uses TMP and merges down to one segment. It's ironic that we say \"don't optimize\", then provide a tool that does exactly that.\n\n2> if we are respecting max segment size (the new default), TMP will not attempt to merge segments that are >= the max segment size and have no deleted docs.\n\n3> <1> and <2> mean that the bit at the end of UpgradeIndexMergePolicy.findForcedMerges where it collects all the old segments not returned by in.findForcedMerges into one segment has the potential to create a very large segments, which is trappy.\n\nStraw-man proposal:\n\nI really dislike constructs like\n\n{{ if (instanceof TieredMergePolicy) \n{ do one thing}\n else \n{ do something else}\n }}\n\nSeems like that knowledge should be built into the classes themselves. WDYT about a new method or two in MergePolicy? They'd be no-ops for everything except TMP at this point. We need a couple of things:\n\n1> hard-coding w.forceMerge(1); in IndexUpgrader is evil so I'm thinking of something like w.forceMerge(iwc.getMergePolicy().getDefaultForceMergeSegmentCount()); instead. It would return 1 by default. Return default in MergePolicy and override only in TMP? Make it abstract and override everywhere?\n\n2a> We need a way to tell TMP.findForcedMerges to return segments even if they're large and have no deletes in this case. Another (expert) method on MergePolicy set/getUsingForUpgrade? I don't particularly like that at all\n\n2b.1> change UpgradeIndexMergePolicy.findForcedMerges to singleton-merge all leftover segments rather than merge them all into a single segment. I'd argue that this is \"more correct\"; Anything findForcedMerges leaves un-merged was determined by the merge policy NOT to be \"cheap\" so we should respect that.\n\n2.b.2> change UpgradeIndexMergePolicy to \"somehow\" respect max segment size when it gathers the segments into at the end of findForcedMerges(). This pollutes MergePolicy some more.\n\n2.b.3> Add a new method to MergePolicy findRewriteAllSegments or something. It'd look just like findForcedMerges except it would \"understand\" that every segment would need to be rewritten, even large ones with no deleted documents. This would make <1> unnecessary. For everything except TMP it would be a passthrough to findForcedMerges at this point.\n\nI don't much like changing MergePolicy, it's nice and clean and adding methods to get specifics from each subclass pollutes it a bit. So <2.b.2> at least doesn't require that the caller understand anything about the guts of the class.\n\nAlso keep in mind that distributed systems have a hard time using the IndexUpgrader on every node in the system, so we need to have something that is easy to invoke in that environment, see the discussion at LUCENE-8264.\n\nI'm totally open to any better ideas, haven't started work on this yet. ",
            "author": "Erick Erickson"
        },
        {
            "id": "comment-16510104",
            "date": "2018-06-12T19:54:12+0000",
            "content": "Since LUCENE-7976 hasn't been added to 7.4, this is not a blocker for 7.4. ",
            "author": "Erick Erickson"
        },
        {
            "id": "comment-16514163",
            "date": "2018-06-15T17:52:24+0000",
            "content": "Made it not a blocker since I actually looked at the code and the call is forceMerge with maxSegments = 1. So this will still work as it does now even after I check in LUCENE-7976 today.\n\nOnce we get through JIRAs like LUCENE-8264 and SOLR-12259, making this tool work without creating one segment will, I hope, be simple so we can revisit this then. ",
            "author": "Erick Erickson"
        },
        {
            "id": "comment-16583215",
            "date": "2018-08-17T00:25:13+0000",
            "content": "This was an offshoot of\u00a0LUCENE-8264, and made the same assumption, that a full rewrite from Lucene X-2 > Lucene X-1 -> Lucene X was possible and making IndexUpgrader rewrite all segments while respecting MaxMergedSegmentMB would facilitate that process. Since the assumption was mistaken, I want to close this as \"Won't fix\" unless there are objections. ",
            "author": "Erick Erickson"
        }
    ]
}