{
    "id": "SOLR-5423",
    "title": "CSV output doesn't include function field",
    "details": {
        "affect_versions": "4.4",
        "status": "Closed",
        "fix_versions": [
            "4.7.1",
            "4.8",
            "6.0"
        ],
        "components": [],
        "type": "Bug",
        "priority": "Major",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "Given a schema with \n\n   <field name=\"price\"  type=\"float\" indexed=\"true\" stored=\"true\"/>\n   <field name='numpages' type='int' indexed='true' stored='true'/>\n\nthe following query returns no rows:\n\nhttp://localhost:8983/solr/collection1/select?q=*%3A*&rows=30&fl=div(price%2Cnumpages)&wt=csv&indent=true\n\nHowever, setting wt=json or wt=xml, it works.",
    "attachments": {
        "SOLR-5423.patch": "https://issues.apache.org/jira/secure/attachment/12629222/SOLR-5423.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Arun Kumar",
            "id": "comment-13889470",
            "date": "2014-02-03T13:33:37+0000",
            "content": "Fix for the csv output doesn't work for function fields "
        },
        {
            "author": "Arun Kumar",
            "id": "comment-13889471",
            "date": "2014-02-03T13:33:47+0000",
            "content": "I have fixed this issue. Attached the patch file for the fix. "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13893715",
            "date": "2014-02-06T19:47:54+0000",
            "content": "Hey Arun, some comments about your patch:\n\n\n\tplease generate patches against he entire code base so they are easier to apply & review: https://wiki.apache.org/solr/HowToContribute#Generating_a_patch\n\tcan you explain what's going on with the getOriginalNameForFunctionField function in your patch? ... it seems extremely sketchy.  if the problem is just that ValueSourceAugmenter's \"getName\" doesn't match the actual fieldname the transformer puts in the modified documents, we should fix that in ValueSourceAugmenter\n\tin general, the amount of instanceof checking going on in your patch seems really brittle, and i'm not exactly sure why it's neccessary.  As I understand it the CSVResponseWriter already loops over all of the field names in the documents to be returned to get the list of column names it should output \u2013 so as long as the transformer logic is applied before that, then won't the field names be picked up automatically?\n\n\n\nindependent of any of the above questions about this patch, we shouldn't move forward with committing support for transformers to the csv repsonse writer w/o having some tests that prove it works.\n "
        },
        {
            "author": "Arun Kumar",
            "id": "comment-13894474",
            "date": "2014-02-07T12:55:02+0000",
            "content": "Generated the patch at the project root level with proper naming convention "
        },
        {
            "author": "Arun Kumar",
            "id": "comment-13894495",
            "date": "2014-02-07T13:14:58+0000",
            "content": "Hi Hoss,\n\nThanks for your review. I have attached the patch generated at the root level and followed the naming convention for the file.\n\nHere are my inputs on your other comments:\n\nThe reason for including a new method getOriginalNameForFunctionField is the ValueSourceAugmenter.getName() returns the name with a function prefix to it, as like this. \n\n public String getName()\n  {\n    return \"function(\"+name+\")\";\n  }\n\nWe can't change this method directly as it has been referred in few other places in the code, it may break other places. Even I thought of including a new method in ValueSourceAugmenter as getOriginalName()\n{return name;}\n but for this we have to change the abstract class DocTransformer and should implement this new method in all the child classes which are extending DocTransformer. So I dropped this option and wrote a method specific to CSVResponseWriter.\n\nOn number of instanceof used, in writeResponse method of CSVResponseWriter the responseObj type is coming as ResultContext only when we have functions in the query. so I am filtering the ResultContext instance and then the other two instanceof is required when one function is present in the query then the transformer type is of ValueSourceAugmenter and if we have multiple functions in the same query then the transformer type is DocTransformers (array of ValueSourceAugmenter) so we need to check these instanceof to process accordingly. In general the transformer logic followed for xml/json is different than the csv. In csv we don't have headers and the format also simple. Because of this difference the transformers are not considering the function field as a field for the csv type. Please let me know if there are any other better way to handle this.\n\nOn the test case, yes I can write a unit test case to prove this fix works. \n\nThanks,\nArun "
        },
        {
            "author": "Arun Kumar",
            "id": "comment-13898049",
            "date": "2014-02-11T17:25:00+0000",
            "content": "Attached the updated patch with a supporting unit test to test the fix. "
        },
        {
            "author": "Steve Rowe",
            "id": "comment-13900808",
            "date": "2014-02-13T22:22:48+0000",
            "content": "Hi Arun,\n\n1. About  getOriginalNameForFunctionField() - Hoss wrote:\n\nif the problem is just that ValueSourceAugmenter's \"getName\" doesn't match the actual fieldname the transformer puts in the modified documents, we should fix that in ValueSourceAugmenter\n\nand then you wrote:\n\nWe can't change this method directly as it has been referred in few other places in the code, it may break other places.\n\nThat's not a problem, you can fix them in those other places.\n\n2. About instanceof - Hoss wrote:\n\nin general, the amount of instanceof checking going on in your patch seems really brittle, and i'm not exactly sure why it's neccessary. As I understand it the CSVResponseWriter already loops over all of the field names in the documents to be returned to get the list of column names it should output \u2013 so as long as the transformer logic is applied before that, then won't the field names be picked up automatically?\n\nIf you look at the loop Hoss describes, where fields are pulled from the response documents (starting at line #244 in your patched version of CSVResponseWriter.java), you shouldn't need to do any of the transformer interrogation you're doing at all.  Maybe the condition around the loop needs to be expanded to include cases when there are function fields (returnFields.getTransformer() != null or something like that)?\n\n3. Unit tests: you added one case, but I'd suggest you add a few more, e.g. the one in this issue's description, where there is no field renaming. "
        },
        {
            "author": "Arun Kumar",
            "id": "comment-13902446",
            "date": "2014-02-15T16:01:44+0000",
            "content": "Hi Steve,\n\nThanks for your review, I have attached an updated patch.\n\n1. I removed the new method getOriginalNameForFunctionField() instead as you suggested I updated the getName() of ValueSourceAugmenter. There are no impacts because of this change, I tested the unit test case\ncovering this ValueSourceAugmenter.\n\n2. Made correction as you & Hoss suggested\n\n3. Covered additional unit test without alias names and single/multiple functions in query\n\n-Arun "
        },
        {
            "author": "Steve Rowe",
            "id": "comment-13908547",
            "date": "2014-02-21T17:24:00+0000",
            "content": "Hi Arun,\n\nWhen you post patches, you don't need to remove older versions - in fact, you shouldn't - JIRA will gray out older same-named files, and people can see the evolution of proposed changes.  You can see that with the patch file I'm attaching now - your most recent one and mine are both there.  If you hover your mouse pointer over an attachment file name, you can see some metadata about it in the tooltip: who posted it and when.\n\nIn looking at your patch, I noticed that your solution of appending fields by getting their names from the corresponding transformers would put fields in the wrong order if a function pseudofield is not last in the requested fields list.  I reordered the requested fields in one of your tests to illustrate this problem.\n\nHoss's and my comments about the get-all-fields-from-the-docs loop already having access to all fields was wrong, because the transformation logic happens later, at the end of CSVResponseWriter.writeResponse(), in the call to TextResponseWriter.writeDocuments().  Even if we had been right, appending fields in an order different from the requested order would have been wrong.  \n\nSo the field ordering problem has to be fixed based on the actual requested fields list.  The attached patch handles this in SolrReturnFields, where the requested fields list is parsed, by putting function pseudofields into the (ordered) requested field names - at present, the only consumer of this is CSVWriter.writeResponse().  This solution doesn't need to change CSVResponseWriter itself at all.  I also added a test to ReturnFieldsTest.\n\nI think this is ready to go. "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-13911072",
            "date": "2014-02-25T01:03:08+0000",
            "content": "Commit 1571505 from Steve Rowe in branch 'dev/trunk'\n[ https://svn.apache.org/r1571505 ]\n\nSOLR-5423: CSV output doesn't include function field "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-13911238",
            "date": "2014-02-25T04:33:45+0000",
            "content": "Commit 1571559 from Steve Rowe in branch 'dev/branches/branch_4x'\n[ https://svn.apache.org/r1571559 ]\n\nSOLR-5423: CSV output doesn't include function field (merged trunk r1571505) "
        },
        {
            "author": "Steve Rowe",
            "id": "comment-13911243",
            "date": "2014-02-25T04:36:01+0000",
            "content": "Committed to trunk and branch_4x. "
        },
        {
            "author": "Steve Rowe",
            "id": "comment-13945253",
            "date": "2014-03-24T15:51:05+0000",
            "content": "I'll backport this to 4.7.1 "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-13945455",
            "date": "2014-03-24T18:19:15+0000",
            "content": "Commit 1580965 from Steve Rowe in branch 'dev/branches/lucene_solr_4_7'\n[ https://svn.apache.org/r1580965 ]\n\nSOLR-5423: CSV output doesn't include function field (merged branch_4x r1571559) "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-13945461",
            "date": "2014-03-24T18:20:00+0000",
            "content": "Commit 1580967 from Steve Rowe in branch 'dev/trunk'\n[ https://svn.apache.org/r1580967 ]\n\nSOLR-5423: move CHANGES.txt entry to 4.7.1 section "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-13945465",
            "date": "2014-03-24T18:21:34+0000",
            "content": "Commit 1580969 from Steve Rowe in branch 'dev/branches/branch_4x'\n[ https://svn.apache.org/r1580969 ]\n\nSOLR-5423: move CHANGES.txt entry to 4.7.1 section (merged trunk r1580967) "
        },
        {
            "author": "Steve Rowe",
            "id": "comment-13957747",
            "date": "2014-04-02T15:03:39+0000",
            "content": "Bulk close 4.7.1 issues "
        }
    ]
}