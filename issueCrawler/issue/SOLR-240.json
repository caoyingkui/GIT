{
    "id": "SOLR-240",
    "title": "java.io.IOException: Lock obtain timed out: SimpleFSLock",
    "details": {
        "affect_versions": "1.2",
        "status": "Closed",
        "fix_versions": [
            "1.3"
        ],
        "components": [
            "update"
        ],
        "type": "Bug",
        "priority": "Major",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "when running the soon to be attached sample application against solr it will eventually die.  this same error has happened on both windows and rh4 linux.  the app is just submitting docs with an id in batches of 10, performing a commit then repeating over and over again.",
    "attachments": {
        "IndexWriter2.patch": "https://issues.apache.org/jira/secure/attachment/12357424/IndexWriter2.patch",
        "ASF.LICENSE.NOT.GRANTED--IndexWriter.patch": "https://issues.apache.org/jira/secure/attachment/12357418/ASF.LICENSE.NOT.GRANTED--IndexWriter.patch",
        "ThrashIndex.java": "https://issues.apache.org/jira/secure/attachment/12357416/ThrashIndex.java",
        "stacktrace.txt": "https://issues.apache.org/jira/secure/attachment/12357417/stacktrace.txt"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Yonik Seeley",
            "id": "comment-12496106",
            "date": "2007-05-15T20:02:50+0000",
            "content": "Thanks Will, I'll try and reproduce this. "
        },
        {
            "author": "Will Johnson",
            "id": "comment-12496111",
            "date": "2007-05-15T20:11:16+0000",
            "content": "I found this:\n\nhttp://lucene.zones.apache.org:8080/hudson/job/Lucene-Nightly/javadoc/or\ng/apache/lucene/store/NativeFSLockFactory.html\n\nAnd so I made the attached patch which seems to run at least 100x longer\nthan without.\n\n\n\twill\n\n\n\n\n\n\n "
        },
        {
            "author": "Hoss Man",
            "id": "comment-12496115",
            "date": "2007-05-15T20:26:21+0000",
            "content": "the idea of using different lock implementations has come up in the past, \n\nhttp://www.nabble.com/switch-to-native-locks-by-default--tf2967095.html\n\none reason not to hardcode native locks was because not all file systems support it \u2013 so we left in the usage of SimpleFSLock because it's the most generally reusable.\n\nrather then change from one hardcoded lock type to another hardcoded lock type, we should support a config option for making the choice ... perhaps even adding a SolrLockFactory that defines an init(NamedList) method and creating simple SOlr sucbclasses of all the core Lucene LockFactor Imples so it's easy for people to write their own if they want (and we don't just have \"if (lockType.equlas(\"simple\"))...\" type config parsing. "
        },
        {
            "author": "Will Johnson",
            "id": "comment-12496140",
            "date": "2007-05-15T21:24:01+0000",
            "content": "the attached patch adds a param to SolrIndexConfig called useNativeLocks.  the default is false which will keeps with the existing design using SimpleFSLockFactory.  if people think we should allow fully pluggable locking mechanisms i'm game but i wasn't quite sure how to tackle that problem.  \n\nas for testing, i wasn't quite sure how to run tests to ensure that the locks were working beyond some basic println's (which passed).  if anyone has good ideas i'm all ears.\n\n\n\twill\n\n "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12499354",
            "date": "2007-05-26T20:43:07+0000",
            "content": "I'm running ThrashIndex against two solr/resin instances on a RHEL4 box, one using the servlet, another using the new dispatch filter.  I haven't seen any exceptions for either yet... "
        },
        {
            "author": "Will Johnson",
            "id": "comment-12499843",
            "date": "2007-05-29T16:42:41+0000",
            "content": "i get the stacktrace below with the latest from head with useNativeLocks turned off (from my patch).  this took about 2 minutes to reproduce on my windows laptop.\n\none thing i thought of is that local antivirus scanning / backup software which we run here may be getting in the way.  i know many other search engines / high performance databases out there have issues with antivirus software because it causes similar locking issues.  i'm disabling as much of the IT 'malware' as possible and seeing better results even with default locking however i had everything running when i had good results with the native locking enabled so it still seems to be a good idea to use the patch (or something similar).\n\n\n\twill\n\n\n\nSEVERE: org.apache.lucene.store.LockObtainFailedException: Lock obtain timed out: SimpleFSLock@solr\\data\\index\\lucene-e7\nb822c61c394dd5f449aaf5e5717356-write.lock\n        at org.apache.lucene.store.Lock.obtain(Lock.java:70)\n        at org.apache.lucene.index.IndexWriter.init(IndexWriter.java:579)\n        at org.apache.lucene.index.IndexWriter.<init>(IndexWriter.java:391)\n        at org.apache.solr.update.SolrIndexWriter.<init>(SolrIndexWriter.java:81)\n        at org.apache.solr.update.UpdateHandler.createMainIndexWriter(UpdateHandler.java:120)\n        at org.apache.solr.update.DirectUpdateHandler2.openWriter(DirectUpdateHandler2.java:181)\n        at org.apache.solr.update.DirectUpdateHandler2.addDoc(DirectUpdateHandler2.java:259)\n        at org.apache.solr.handler.XmlUpdateRequestHandler.update(XmlUpdateRequestHandler.java:166)\n        at org.apache.solr.handler.XmlUpdateRequestHandler.handleRequestBody(XmlUpdateRequestHandler.java:84)\n        at org.apache.solr.handler.RequestHandlerBase.handleRequest(RequestHandlerBase.java:79)\n        at org.apache.solr.core.SolrCore.execute(SolrCore.java:658)\n        at org.apache.solr.servlet.SolrDispatchFilter.execute(SolrDispatchFilter.java:198)\n        at org.apache.solr.servlet.SolrDispatchFilter.doFilter(SolrDispatchFilter.java:166)\n        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1089)\n        at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:365)\n        at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)\n        at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:181)\n        at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:712)\n        at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:405)\n        at org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:211)\n        at org.mortbay.jetty.handler.HandlerCollection.handle(HandlerCollection.java:114)\n        at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:139)\n        at org.mortbay.jetty.Server.handle(Server.java:285)\n        at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:502)\n        at org.mortbay.jetty.HttpConnection$RequestHandler.content(HttpConnection.java:835)\n        at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:641)\n        at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:208)\n        at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:378)\n        at org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:368)\n        at org.mortbay.thread.BoundedThreadPool$PoolThread.run(BoundedThreadPool.java:442) "
        },
        {
            "author": "Luis Neves",
            "id": "comment-12506472",
            "date": "2007-06-20T09:41:27+0000",
            "content": "Hi,\nI'm also experiencing this problem. Every 4 hours or so the server starts spewing this stacktrace when updating the index.\n\nMy environment is:\n\nResin 3.0.23 / Solr 1.2 / JDK6u1\n$ cat /proc/version\nLinux version 2.6.16-1-686-smp (Debian 2.6.16-10) (waldi@debian.org) (gcc version 4.0.4 20060422 (prerelease) (Debian 4.0.3-2)) #2 SMP Tue Apr 25 20:45:37 UTC 2006\n\nThe IndexWriter2.patch seems to fix the problem, the server has now been running for 48h without problems. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12506973",
            "date": "2007-06-21T17:55:35+0000",
            "content": "> And so I made the attached patch which seems to run at least 100x longer than without.\n\nDoes this mean you still had occasional issues with native locking?\n\nDoes anyone ever see exceptions relating to removal of the lockfile (presumably that's why it can't be aquired by the new IndexWriter instance?)\n\nIt's worrying that it's also reproducable on Linux... (although the oldest Solr collections have been running in CNET for 2 years now, and I've never seen this happen).   What I have seen is that exact exception when the server died, restarted, and then couldn't grab the write lock.... normally due to not a big enough heap causing excessive GC and leading resin's wrapper to restart the container. "
        },
        {
            "author": "Will Johnson",
            "id": "comment-12506983",
            "date": "2007-06-21T18:28:27+0000",
            "content": "longer >>than without.\n\n\nNo, after I applied the patch I have never seen a lockup. \n\noldest Solr collections have been running in CNET for 2 years now, and\nI've never seen this happen).   What I have seen is that exact\nexception when the server died, restarted, and then couldn't grab the\nwrite lock.... normally due to not a big enough heap causing excessive\nGC and leading resin's wrapper to restart the container.\n\nAnother reason to use native locking.  From the lucene native fs lock\njavadocs:  \"Furthermore, if the JVM crashes, the OS will free any held\nlocks, whereas SimpleFSLockFactory will keep the locks held, requiring\nmanual removal before re-running Lucene.\"  \n\nMy hunch (and that's all it is) is that people seeing/not seeing the\nissue may come down to usage patterns.  My project is heavily focused on\nlow indexing latency so we're doing huge numbers of\nadd/deletes/commits/searches in very fast succession and from multiple\nclients.  A more batch oriented update usage pattern may not see the\nissue.\n\nThe patch because as is, it doesn't change any api or cause any change\nof existing functionality whatsoever unless you use the new option in\nsolrconfig.  I would argue that using native locking should be the\ndefault though.\n\n\n\twill\n\n "
        },
        {
            "author": "Hoss Man",
            "id": "comment-12512319",
            "date": "2007-07-13T00:47:12+0000",
            "content": "This is a variation on Will's IndexWriter2.patch that replaces the \"useNativeLocks\" boolean config option with a string config option allowing people to pick any of the 4 built in Lucene lock factories.\n\n(i'd been meaning to try and write a \"LockFactoryFactory\" to allow people to specify any arbitrary LockFactory impl as a plugin, but it seemed like overkill \u2013 having Will's useNativeLocks option didn't preclude adding something like that later, but recent comments reminded me that for the majority of SOlr users, the \"NoLockFactory\" would actually be perfectly fine since Solr only ever opens one IndexWriter at a time)\n\nso this patch provides a little bit more flexibility then the previous one, without going whole-hog to a FactoryFactory/plugin model.\n\nIt should be noted that I left the hardcoded default in the code in to be SimpleFSLockFactory but i set the \"example\" default to be NoLockFactory with a comment that that should be find for any Solr user not modifying the index externally to Solr.\n\ncomments? "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12512330",
            "date": "2007-07-13T01:22:55+0000",
            "content": "> i set the \"example\" default to be NoLockFactory \n\nHow about SingleInstanceLockFactory to aid in catching concurrency bugs? "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12512332",
            "date": "2007-07-13T01:30:45+0000",
            "content": "> SingleInstanceLockFactory \nor even better, a subclass or other implementation: SingleInstanceWarnLockFactory or SingleInstanceCoordinatedLockFactory that log a failure if obtain() is called for a lock that is already locked. "
        },
        {
            "author": "Hoss Man",
            "id": "comment-12512552",
            "date": "2007-07-13T17:52:33+0000",
            "content": "good point about recommending 'single' in the event of concurrency bugs.\n\ni've never really looked at the internals of the LockFactories so i'm going to punt on the subclass idea for now (i like it i just don't have time to do it) but we can always redefine \"single\" later.  (i'll open another bug if we're okay with committing this new patch as is)\n\nrevised patch just changes the wording and suggested value in solrconfig.xml\n\n\nobjections? "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12512554",
            "date": "2007-07-13T17:58:39+0000",
            "content": "No objections... a hang (in the event of bugs) will suffice for now. "
        },
        {
            "author": "Hoss Man",
            "id": "comment-12512579",
            "date": "2007-07-13T18:49:10+0000",
            "content": "Committed revision 556099. "
        }
    ]
}