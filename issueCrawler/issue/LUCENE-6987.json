{
    "id": "LUCENE-6987",
    "title": "Clarify TokenStream workflow documentation",
    "details": {
        "resolution": "Unresolved",
        "affect_versions": "None",
        "components": [],
        "labels": "",
        "fix_versions": [],
        "priority": "Major",
        "status": "Open",
        "type": "Task"
    },
    "description": "On SOLR-4619, Robert Muir noted:\n\nAccording to TokenStream's class javadocs:\n\n\nThe workflow of the new TokenStream API is as follows:\n\n1. Instantiation of TokenStream/TokenFilters which add/get attributes to/from the AttributeSource.\n2. The consumer calls reset().\n3. The consumer retrieves attributes from the stream and stores local references to all attributes it wants to access.\n\nSo we have consumers (such as QueryBuilder) doing stuff out of order: if they do step 3 before they do step 2.\n\nMy question is, can we detect this in tests? If MockAnalyzer can enforce it, it is easier to fix it consistently everywhere. One idea is if MockTokenizer deferred initializing its attributes until reset()? Its not going to be the best (we need to tie it into its state machine logic somehow for that), but it might be an easy step.\n\nAlso, majority of TokenFilters (which basically also serve as consumers too), are doing step 3 before step 2 today. Most of them are just assigning to final variables in their constructor.\n\nSo something is off: we gotta go one of two ways. Either fix the documentation to swap step 3 before step 2 [...], or we make a massive change to tons of tokenizers (making them more complex and less efficient).\nBut I think we have to do something, at least we should fix the docs to be clear, they need to reflect reality.",
    "attachments": {},
    "issue_links": {},
    "comments": []
}