{
    "id": "SOLR-3056",
    "title": "Introduce Japanese field type in schema.xml",
    "details": {
        "affect_versions": "3.6,                                            4.0-ALPHA",
        "status": "Closed",
        "fix_versions": [
            "3.6",
            "4.0-ALPHA"
        ],
        "components": [
            "Schema and Analysis"
        ],
        "type": "New Feature",
        "priority": "Major",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "Kuromoji (LUCENE-3305) is now on both on trunk and branch_3x (thanks again Robert, Uwe and Simon). It would be very good to get a default field type defined for Japanese in schema.xml so we can good Japanese out-of-the-box support in Solr.\n\nI've been playing with the below configuration today, which I think is a reasonable starting point for Japanese.  There's lot to be said about various considerations necessary when searching Japanese, but perhaps a wiki page is more suitable to cover the wider topic?\n\nIn order to make the below text_ja field type work, Kuromoji itself and its analyzers need to be seen by the Solr classloader.  However, these are currently in contrib and I'm wondering if we should consider moving them to core to make them directly available.  If there are concerns with additional memory usage, etc. for non-Japanese users, we can make sure resources are loaded lazily and only when needed in factory-land.\n\nAny thoughts?\n\n\n<!-- Text field type is suitable for Japanese text using morphological analysis\n\n     NOTE: Please copy files\n       contrib/analysis-extras/lucene-libs/lucene-kuromoji-x.y.z.jar\n       dist/apache-solr-analysis-extras-x.y.z.jar\n     to your Solr lib directory (i.e. example/solr/lib) before before starting Solr.\n     (x.y.z refers to a version number)\n\n     If you would like to optimize for precision, default operator AND with\n       <solrQueryParser defaultOperator=\"AND\"/>\n     below (this file).  Use \"OR\" if you would like to optimize for recall (default).\n-->\n<fieldType name=\"text_ja\" class=\"solr.TextField\" positionIncrementGap=\"100\" autoGeneratePhraseQueries=\"false\">\n  <analyzer>\n    <!-- Kuromoji Japanese morphological analyzer/tokenizer\n\n         Use search-mode to get a noun-decompounding effect useful for search.\n\n         Example:\n           \u95a2\u897f\u56fd\u969b\u7a7a\u6e2f (Kansai International Airpart) becomes \u95a2\u897f (Kansai) \u56fd\u969b (International) \u7a7a\u6e2f (airport)\n           so we get a match for \u7a7a\u6e2f (airport) as we would expect from a good search engine\n\n         Valid values for mode are:\n            normal: default segmentation\n            search: segmentation useful for search (extra compound splitting)\n          extended: search mode with unigramming of unknown words (experimental)\n\n         NOTE: Search mode improves segmentation for search at the expense of part-of-speech accuracy\n    -->\n    <tokenizer class=\"solr.KuromojiTokenizerFactory\" mode=\"search\"/>\n    <!-- Reduces inflected verbs and adjectives to their base/dectionary forms (\u8f9e\u66f8\u5f62) -->\t\n    <filter class=\"solr.KuromojiBaseFormFilterFactory\"/>\n    <!-- Optionally remove tokens with certain part-of-speeches\n    <filter class=\"solr.KuromojiPartOfSpeechStopFilterFactory\" tags=\"stopTags.txt\" enablePositionIncrements=\"true\"/> -->\n    <!-- Normalizes full-width romaji to half-with and half-width kana to full-width (Unicode NFKC subset) -->\n    <filter class=\"solr.CJKWidthFilterFactory\"/>\n    <!-- Lower-case romaji characters -->\n    <filter class=\"solr.LowerCaseFilterFactory\"/>\n  </analyzer>\n</fieldType>",
    "attachments": {
        "SOLR-3056_schema40.patch": "https://issues.apache.org/jira/secure/attachment/12512756/SOLR-3056_schema40.patch",
        "SOLR-3056_move.patch": "https://issues.apache.org/jira/secure/attachment/12512747/SOLR-3056_move.patch",
        "SOLR-3056.patch": "https://issues.apache.org/jira/secure/attachment/12513809/SOLR-3056.patch",
        "SOLR-3056_typo.patch": "https://issues.apache.org/jira/secure/attachment/12514035/SOLR-3056_typo.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Robert Muir",
            "id": "comment-13190747",
            "date": "2012-01-22T19:35:40+0000",
            "content": "\nIt would be very good to get a default field type defined for Japanese in schema.xml so we can good Japanese out-of-the-box support in Solr.\n\nI agree, we really need this for all languages, including stopwords_xx files and fieldtypes actually,\nbut lets start with japanese because its complicated.\n\n\nI've been playing with the below configuration today, which I think is a reasonable starting point for Japanese. There's lot to be said about various considerations necessary when searching Japanese, but perhaps a wiki page is more suitable to cover the wider topic?\n\nI think the ideal situation would be to have a single reasonable default (like the configuration you have), but then also a \nfull wiki page on Kuromoji explaining the different options, maybe even with alternative configurations or examples. we could\nlink to this page from the other wikipages about the analyzers.\n\n\nIn order to make the below text_ja field type work, Kuromoji itself and its analyzers need to be seen by the Solr classloader. However, these are currently in contrib and I'm wondering if we should consider moving them to core to make them directly available. If there are concerns with additional memory usage, etc. for non-Japanese users, we can make sure resources are loaded lazily and only when needed in factory-land.\n\nYeah I don't think having kuromoji in contrib is ideal. I think instead we should have examples for all supported languages\nso its easy to get started. Currently someone has to jump thru serious hoops to segment chinese or japanese into words,\nbut as I mentioned before all non-english languages currently are 'hard' in that there are no fieldtypes setup for them.\n\nbut anyway, my vote is to move these analyzers to core and nuke this contrib totally. But it would be great for some\npeople to speak up and get consensus on this because it would only be more confusing to go back and forth between\ncontrib and core.\n\n\nAs far as the default configuration,\n\nChristian maybe if you have some time you could look at/review the stopTags.txt we have in the analyzer right now? \n\nhttp://svn.apache.org/viewvc/lucene/dev/trunk/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/kuromoji/stoptags.txt?view=markup\n\nI created this file from the ipadic manual (there could/likely are silly errors too), in an attempt to also document the POS tagset.\nBut we should also see if the uncommented POS tags in that file are appropriate for a 'good stop set'. I think i just arbitrarily\npicked a few trying to be conservative.\n "
        },
        {
            "author": "Christian Moen",
            "id": "comment-13190919",
            "date": "2012-01-23T08:18:00+0000",
            "content": "Robert,\n\nThanks for the feedback.  I completely agree with the idea of providing extensive language support out-of-the-box.  My primary goal with donating Kuromoji was to do exactly that for Japanese.\n\nI have to admit that I don't know all that much about the general state of the other items in contrib, but I at least think Kuromoji should be moved to core if we'd like to provide a good out-of-the-box Japanese experience.  Perhaps moving other parts of contrib to core is a reasonable longer term goal?\n\nI believe Kuromoji ended up in contrib since that seemed like the most reasonable starting point for integration it at the time rather than careful consideration of where it should reside long term.  Please feel free to chime in, Simon.\n\nI'm proposing that we move Kuromoji to core to make Japanese supported out-of-the-box with a useful field type and corresponding documentation on the wiki.  Longer term, I think we should do the same for other languages well, but as you say, we can start with Japanese because it's complicated.\n\n\nI've also had a look at your stop POS tags.  I haven't reviewed them for completeness against IPADIC, but the defaults you have chosen as stop POS tags look fine to me.  Good job. "
        },
        {
            "author": "Chris Male",
            "id": "comment-13190927",
            "date": "2012-01-23T08:37:43+0000",
            "content": "\nbut anyway, my vote is to move these analyzers to core and nuke this contrib totally. But it would be great for some\npeople to speak up and get consensus on this because it would only be more confusing to go back and forth between\ncontrib and core.\n\n+1 to moving them to core and removing the contrib.  We support the Analyzers, they are of good quality with tests and obviously active development so should be treated as core.  "
        },
        {
            "author": "Uwe Schindler",
            "id": "comment-13190934",
            "date": "2012-01-23T08:48:09+0000",
            "content": "+1, I don't see a reason why having a damn-stupid factory in contrib makes any sense, it can also reside in core. The actual analyzer is in the official Lucene distribution, so there is nothing wrong with moving to core, as its just \"glue\" code. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13194403",
            "date": "2012-01-27T03:36:17+0000",
            "content": "As a first step, lets adjust the analyzer defaults so that the Lucene analyzer supports search mode by default.\nI have a few questions about this mode I want to throw out there, so I'll create a new issue. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13194413",
            "date": "2012-01-27T03:48:35+0000",
            "content": "I opened LUCENE-3726 for the search mode discussion. "
        },
        {
            "author": "Christian Moen",
            "id": "comment-13195966",
            "date": "2012-01-30T07:06:54+0000",
            "content": "Robert, I've improved the search mode heuristic (see LUCENE-3730 with patch) and I've also provided some feedback on LUCENE-3726.  Before providing a patch to use search mode as our default, I'd like to do some corpus-based testing to make sure overall segmentation quality is where I'd like it to be.\n\nAs for this JIRA, I guess it has branched out into the following topics:\n\n\n\tIntroduce field type for Japanese in schema.xml\n\tMove Kuromoji to core to make it generally available in Solr\n\tGet rid of contrib altogether\n\n\n\nThere seems to be consensus to move Kuromoji to core from at least three people (excluding myself).\n\nDo you prefer that we conclude on LUCENE-3726 before we follow up on getting Japanese support for Solr and Lucene working out-of-the-box \u2013 or can we conclude on default search mode separately?\n\nI'm happy to start JIRAs for moving Kuromoji to get Japanese support in place if that's the best next course of action.  Please advise.  Many thanks. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13196074",
            "date": "2012-01-30T11:55:34+0000",
            "content": "\nGet rid of contrib altogether\n\nI still want to do this eventually: but lets do kuromoji first.\n\n\nDo you prefer that we conclude on LUCENE-3726 before we follow up on getting Japanese support for Solr and Lucene working out-of-the-box \u2013 or can we conclude on default search mode separately?\n\nNo reason to avoid working issues in parallel, I don't think any of these block each other. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13197802",
            "date": "2012-02-01T12:48:38+0000",
            "content": "Ill do the svn moves portion of this, so that we can iterate on the default configuration etc.\n\nI think what Christian defined in the description is the way to go as a start... "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13197814",
            "date": "2012-02-01T12:55:17+0000",
            "content": "Here's the patch showing differences of the move:\n\nThe three factories and 3 tests are svn move'd, but also StringMockSolrResourceLoader is moved to test-framework (i find myself using this in analysis tests, should probably look for more embedded dup-ed copies of this thing).\n\nI'll commit shortly. "
        },
        {
            "author": "Christian Moen",
            "id": "comment-13197872",
            "date": "2012-02-01T14:39:50+0000",
            "content": "Robert, I've build the latest trunk and I can confirm that the move is good.  Thanks!\n\nAttached a patch to introduce the text_ja field type to the Solr example schema (example/solr/conf/schema.xml) for trunk.  Will look at branch_3x in due time. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13197877",
            "date": "2012-02-01T14:44:30+0000",
            "content": "Don't worry, I can just merge whatever we do here to branch_3x (i think it should be exactly the same anyway)... so\nwe don't need a separate 3.x patch.\n\nThis patch looks good to me, though for good performance/relevance I think we should enable the stoptags by default?\nThis would be consistent with the lucene analyzer (which btw also has a small stopwords file, do we need those? should it be improved?)\nI can just put the stoptags file in the configuration directory if you think this works.\n "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13197882",
            "date": "2012-02-01T14:50:13+0000",
            "content": "A couple spelling nitpicks too \n\n\n\tdectionary -> dictionary\n\tpart-of-speeches -> part-of-speech tags\n\thalf-with -> half-width\n\n "
        },
        {
            "author": "Christian Moen",
            "id": "comment-13197897",
            "date": "2012-02-01T15:12:49+0000",
            "content": "Thanks for catching these and saving me the embarrassment of having them included in a release!  Very sorry.  The patch has been updated. "
        },
        {
            "author": "Christian Moen",
            "id": "comment-13197952",
            "date": "2012-02-01T16:58:49+0000",
            "content": "Robert, let's enable stop-words and stop-tags by default.\n\nThe stopwords list in the Lucene analyzer looks too small unless it's always used in combination with a stoptags filter.  I'll look into both of these.\n\nAlso, if we're using search mode, part-of-speech F will decrease so we might want to rely more on stopwords rather than stoptags if it goes down by a whole lot.  However, since tokens agree in 99.7% of the cases based on the tests I did earlier \u2013 and the part-of-speech tags we'd typically use as stop tags aren't involved with token-splits done by search mode, I don't expect this to be an issue, but it's something to keep in mind.\n\nI'll run some tests to verify this and follow up by suggesting configuration.\n\nI'll open up a separate JIRA for stopwords and stoptags, and aligning the Solr and Lucene default configurations. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13197990",
            "date": "2012-02-01T17:50:58+0000",
            "content": "\nI'll run some tests to verify this and follow up by suggesting configuration.\n\nI'll open up a separate JIRA for stopwords and stoptags, and aligning the Solr and Lucene default configurations.\n\nSounds great: the existing files were not created with tests at all and are really arbitrary,\nso I think this would be a big win. "
        },
        {
            "author": "Christian Moen",
            "id": "comment-13198593",
            "date": "2012-02-02T08:04:14+0000",
            "content": "I've opened up LUCENE-3745 for stopwords and stoptags. "
        },
        {
            "author": "Christian Moen",
            "id": "comment-13200688",
            "date": "2012-02-05T08:09:58+0000",
            "content": "Stopwords and stoptags for Solr are now tracked in SOLR-3097 and a patch is available. "
        },
        {
            "author": "Christian Moen",
            "id": "comment-13200689",
            "date": "2012-02-05T08:12:56+0000",
            "content": "Updated patch for schema.xml on trunk.\n\nThe field type text_ja now uses a KuromojiPartOfSpeechStopFilter and StopFilter for stopping and their configuration uses the stop sets in the SOLR-3097 patch.  Hence, SOLR-3097 should be applied before or at the same time as this patch. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13203564",
            "date": "2012-02-08T13:13:38+0000",
            "content": "Attached is Christians patch, synced up to trunk.\n\nAdditionally, I modified the factory to be more lazy, such that you pay no RAM unless you then go and use text_ja.\n\nSegmenter itself is very lightweight (except the first time called, where the classloader ensures the singletons are loaded). In fact the Lucene tokenizer even has a no-arg ctor with \"new Segmenter()\".\n\nBecause tokenstreams are reused anyway via threadlocal, we only call create() once per thread... and again its just a lightweight Segmenter which is likely cheaper than even all the attributesource stuff already needed for the tokenstream.\n\nSo this has no impact on kuromoji's performance, just defers the initialization so that if you don't use text_ja the resources are not loaded.\n\nI reviewed the fieldtype, and only have one last question! (I didnt change anything from your configuration)\n\nI noticed the order of the tokenfilters is different from the order defined in KuromojiAnalyzer. This order can be important in some situations, so I think we should correct one or the other to be consistent? "
        },
        {
            "author": "Christian Moen",
            "id": "comment-13203616",
            "date": "2012-02-08T13:59:34+0000",
            "content": "Thanks a lot, Robert.\n\nI'll open up a separate JIRA for stopwords and stoptags, and aligning the Solr and Lucene default configurations.\n\nI created LUCENE-3751 with a patch earlier make sure the default Lucene and Solr configurations are aligned.  Sorry for not pointing this out clearly by linking the JIRAs. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13203622",
            "date": "2012-02-08T14:08:50+0000",
            "content": "Ugh, sorry Christian... I totally missed that issue!\n\nLets take care of that one first... "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13203635",
            "date": "2012-02-08T14:24:06+0000",
            "content": "OK, LUCENE-3751 is good, but to totally match that I think we should adjust the stopfilter here\nto ignore case (ignoreCase=\"true\") by default. \n\nIts a negligible cost, and, since it comes before the stopfilter, would prevent confusion if someone\nwere to also add english stopwords (The, etc) to their stopset.\n\nSomeone could always change to ignoreCase=false, but I think thats more expert, and only good\nas a default for languages like Turkish that have alternate casing behavior. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13203642",
            "date": "2012-02-08T14:34:23+0000",
            "content": "Actually, sorry, this is consistent. I missed the fact KuromojiAnalyzer actually\nexplicitly loads the stopset with ignoreCase=false.\n\nI still am unsure if we should do that, if the lowercasefilter is going to be \nafter the stopwordfilter, just for the same reasons I mentioned above. "
        },
        {
            "author": "Christian Moen",
            "id": "comment-13203662",
            "date": "2012-02-08T15:24:25+0000",
            "content": "Thanks, Robert.\n\nI was thinking to leave the StopFilter case-sensitive as I thought not having it normalized would give us flexibility, but it's also prone to error and surprises.  I think it's reasonable to do make the default ignore case to support adding English or other romaji terms to the stopset with ease.\n\nHowever, if we following down this path path, we might also want to do width-normalization for the Japanese stopset to make sure there's no confusion with that, either.  I suggest that we resolve that as a separate issue and just document this clearly in the stopset file.\n\nI think it's still reasonable to leave the LowerCaseFilter last as-is, though, so that users won't need to reorder the chain in case they want case-sensitive stopping.\n\nI'll update the configuration in both KuromojiAnalyzer and the text_ja field type to ignore case in their StopFilter tomorrow. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13203678",
            "date": "2012-02-08T15:48:00+0000",
            "content": "\nHowever, if we following down this path path, we might also want to do width-normalization for the Japanese stopset to make sure there's no confusion with that, either. I suggest that we resolve that as a separate issue.\n\nWell, I think in general we could probably solve the width issue with documentation. \nThe reason is that supporting a lot of different 'casing' schemes (especially ones that aren't 1:1, like normalizing width of kana),\nin CharArrayMap/Set could become confusing and tricky.\n\nFor example, because GreekAnalyzer's stopword list expects sigma to always be '\u03c3' and never '\u03c2' (even in final position), we document\nthat the stopword list should also be configured this way:\n\n   * <b>NOTE:</b> The stopwords set should be pre-processed with the logic of \n   * {@link GreekLowerCaseFilter} for best results.\n\n\n\nBut, I think we should also document any expectations in the example file itself, now that we are also using them as example configurations\nfor Solr users (who we might expect, would never read the javadocs to the corresponding Analyzer).\n\nI'll redundantly add comments to the stoplists where appropriate for the other languages, but I think its a good way to solve the width issue too. "
        },
        {
            "author": "Christian Moen",
            "id": "comment-13204438",
            "date": "2012-02-09T10:48:33+0000",
            "content": "I agree, Robert.  I'll add suitable documentation to stopwords.txt to clarify case- and width-handling.\n\nFind attached a patch that includes your latest changes and a StopFilter ignoring case for text_ja.  I've also revised the comments some and made sure the morphological field type text_ja references text_cjk to make users aware of the bigram alternative as well. "
        },
        {
            "author": "Christian Moen",
            "id": "comment-13204448",
            "date": "2012-02-09T11:02:24+0000",
            "content": "KuromojiAnalyzer (LUCENE-3751) has also been updated to ignore case in its StopFilter. "
        },
        {
            "author": "Christian Moen",
            "id": "comment-13204461",
            "date": "2012-02-09T11:38:03+0000",
            "content": "An improved description of stopwords.txt/stopwords_ja.txt with patch to clarify case- and width-handling is tracked by SOLR-3115. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13204980",
            "date": "2012-02-09T22:46:06+0000",
            "content": "Thanks for the hard work here Christian! "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13204993",
            "date": "2012-02-09T22:58:53+0000",
            "content": "found a tiny nitpick:\n\njust an unpaired xml comment... for some reason everything worked fine with this (i have no clue...) "
        }
    ]
}