{
    "id": "LUCENE-2771",
    "title": "Remove norms() support from non-atomic IndexReaders",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [],
        "type": "Improvement",
        "fix_versions": [
            "4.0-ALPHA"
        ],
        "affect_versions": "None",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "Spin-off from LUCENE-2769:\nCurrently all IndexReaders support norms(), but the core of Lucene never uses it and its even dangerous because of memory usage. We should do the same like with MultiFields and factor it out and throw UOE on non-atomic readers.\n\nThe SlowMultiReaderWrapper can then manage the norms. Also ParallelReader needs to be fixed.",
    "attachments": {
        "LUCENE-2771_needsCache.patch": "https://issues.apache.org/jira/secure/attachment/12460042/LUCENE-2771_needsCache.patch",
        "LUCENE-2771.patch": "https://issues.apache.org/jira/secure/attachment/12460047/LUCENE-2771.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2010-11-19T18:48:15+0000",
            "content": "Here the relevant comments:\n\n\nRobert Muir added a comment - 19/Nov/10 04:28 AM\n\nhere is a hack patch for Uwe's idea about the norms.\nwe need to change SegmentMerger to not call norms on the top-level IR but populate its normBuffer from the subs. \nin my opinion it seems crazy we are currently creating these big arrays this way (yeah there is the hairy code for re-open that re-uses the big merged cache for the NRT case, but still).\n\nMaybe i am missing something.\n\nRobert Muir added a comment - 19/Nov/10 04:28 AM\n\nhere is a hack patch for Uwe's idea about the norms. we need to change SegmentMerger to not call norms on the top-level IR but populate its normBuffer from the subs. in my opinion it seems crazy we are currently creating these big arrays this way (yeah there is the hairy code for re-open that re-uses the big merged cache for the NRT case, but still). Maybe i am missing something. \n\nRobert Muir added a comment - 19/Nov/10 04:58 AM\n\nhere's another hacky update: but still a few tests explicitly check these norms and need to be fixed. \nmaybe we could add an uncached \"MultiNorms\" or something at least in src/test for convenience,\njust to fill the byte arrays so these tests can assertEquals\n\notherwise we are going to have to put a lot of SlowMultiReaderWrappers in these tests.\n\nRobert Muir added a comment - 19/Nov/10 04:58 AM\n\nhere's another hacky update: but still a few tests explicitly check these norms and need to be fixed. maybe we could add an uncached \"MultiNorms\" or something at least in src/test for convenience, just to fill the byte arrays so these tests can assertEquals otherwise we are going to have to put a lot of SlowMultiReaderWrappers in these tests. \n\nRobert Muir added a comment - 19/Nov/10 07:45 AM\n\nhere is an updated patch, with core/contrib/solr tests passing. \nFor ParallelReader i forced it to require non-composite readers only (e.g. SlowMultiReaderWrap them if thats not the case).\n\nTODO: \n\n\tParallelReader shouldnt need multifields etc anymore\n\tthere are 5 @Ignore'd ParallelReader-related tests, because of things like reopen/isOptimized/isCurrent\n\tmerge in Uwe's improved SegmentsMerger\n\tclean up code.\n\n\n\nRobert Muir added a comment - 19/Nov/10 07:45 AM\n\nhere is an updated patch, with core/contrib/solr tests passing. For ParallelReader i forced it to require non-composite readers only (e.g. SlowMultiReaderWrap them if thats not the case). TODO: \nParallelReader shouldnt need multifields etc anymore \nthere are 5 @Ignore'd ParallelReader-related tests, because of things like reopen/isOptimized/isCurrent \nmerge in Uwe's improved SegmentsMerger \nclean up code.  ",
            "author": "Uwe Schindler",
            "id": "comment-12933911"
        },
        {
            "date": "2010-11-19T19:29:01+0000",
            "content": "I think there may be hope for ParallelReader.\n\nIe, if the readers added to it a \"congruent\" (consist same-sized\nsub-readers), which I think  is common, then we can implement\ngetSequentialSubReaders as simply returning an array of\nParallelReaders of the sub-readers.\n\nIf they are not congruent then it's effectively a\nSlowMultiReaderWrapper. ",
            "author": "Michael McCandless",
            "id": "comment-12933925"
        },
        {
            "date": "2010-11-19T20:07:48+0000",
            "content": "here is a start to the new approach i described.\n\nit needs some cleanup and optimization, but mostly just to add a cache to ParallelReader\nlike i did to SlowMultiReaderWrapper... \n\nall tests pass, this is much simpler. ",
            "author": "Robert Muir",
            "id": "comment-12933951"
        },
        {
            "date": "2010-11-19T20:23:20+0000",
            "content": "here is a patch with a cache on ParallelReader.\ni also fixed some bugs in my previous patch \n\nin general the patch should be reviewed, as things are mostly unoptimized.\ne.g. the ParallelReader norms methods might not need to be entirely synchronized\nand maybe it can have a ctor that re-uses parts of the norms cache like DirectoryReader had before (though that was complicated)\n ",
            "author": "Robert Muir",
            "id": "comment-12933957"
        },
        {
            "date": "2010-11-19T20:58:35+0000",
            "content": "Ok, not really related, but i just can't stand it:\n\nIn the contrib/demo \"SearchFiles\" example, there is a OneNorms FilterIndexReader.\nI think this entire thing is a no-op since per-segment search, and not a good\nthing to have in an example.  I removed this here.\n\ni also turned some nocommits into TODO's: really this Slow* stuff doesn't need to be\nhyper-optimized. ",
            "author": "Robert Muir",
            "id": "comment-12933977"
        },
        {
            "date": "2010-11-20T02:13:40+0000",
            "content": "SegmentReader and AllOtherReaders are becoming less and less similar. Is it time to remove their common parent class? ",
            "author": "Earwin Burrfoot",
            "id": "comment-12934078"
        },
        {
            "date": "2010-11-20T18:58:12+0000",
            "content": "Updated patch after commit of subissue LUCENE-2772.\n\nSome throughts: The cache currently dont support reopening readers, as FilterIndexReader throws UOE on reopen (which is fine for most cases). But for this reader we should support reopen and implement it in the FilterIndexReader with optimized norms recreation (copy over in the map only reopened segments?).\n\nAnother thing about MultiNorms: We are inconsistent now: We are using MultiFields everywhere in core queries but not MultiNorms. E.g. for a TermQuery you can currently get a Scorer, but as soon as this scorer requests norms, it will throw UOE. We should be consistent. As we have now the SlowMultiReaderWrapper, we should remove MultiFields support from everywhere else in core (Filters and Queries, but also FieldCache?). +1 for that from my side!\n\nEDIT We use MultiFields nor everywhere anymore, eg no longer in TermQuery/Scorer. But still in filters and other parts. So we should open issue to remove all usage! ",
            "author": "Uwe Schindler",
            "id": "comment-12934167"
        },
        {
            "date": "2010-11-20T19:04:54+0000",
            "content": "Some throughts: The cache currently dont support reopening readers, as FilterIndexReader throws UOE on reopen\n\nI don't see why SlowMultiReaderWrapper needs to support reopen, is there really a use case for this?\nBut parallelreader still does, with the patch (and its tests pass). ",
            "author": "Robert Muir",
            "id": "comment-12934169"
        },
        {
            "date": "2010-11-20T19:13:05+0000",
            "content": "In fact, reopen is completely unrelated to this issue, or the cache here at all... so i don't understand your comment. ",
            "author": "Robert Muir",
            "id": "comment-12934171"
        },
        {
            "date": "2010-11-20T20:03:37+0000",
            "content": "In fact, reopen is completely unrelated to this issue, or the cache here at all... so i don't understand your comment. \n\nIf you reopen an reader you can reuse the cache partly (so instead of copying all norms from all subreaders again, you can sometimes simply override a part of only a refreshed subreader). ",
            "author": "Uwe Schindler",
            "id": "comment-12934181"
        },
        {
            "date": "2010-11-20T20:30:47+0000",
            "content": "right but slowmultiwrapper never supported reopen before... so its unrelated. ",
            "author": "Robert Muir",
            "id": "comment-12934185"
        },
        {
            "date": "2010-11-20T20:42:34+0000",
            "content": "I am just collecting ideas! ",
            "author": "Uwe Schindler",
            "id": "comment-12934188"
        },
        {
            "date": "2010-11-29T12:37:15+0000",
            "content": "Whats going on here, should i commit the patch? ",
            "author": "Robert Muir",
            "id": "comment-12964728"
        },
        {
            "date": "2010-11-29T12:42:01+0000",
            "content": "I had no time to further look into it, I just have to recapitulate my comments and review the patch again.\n\nWe should in all cases open another issue and remove Multi* support from all core queries and filters (where it is left). If you use a filter with a MultiReader, it can throw UOE. Then you can always use SlowMultiReaderWrapper. ",
            "author": "Uwe Schindler",
            "id": "comment-12964729"
        },
        {
            "date": "2010-11-29T12:47:40+0000",
            "content": "\nWe should in all cases open another issue and remove Multi* support from all core queries and filters (where it is left). If you use a filter with a MultiReader, it can throw UOE. Then you can always use SlowMultiReaderWrapper.\n\n+1 ",
            "author": "Robert Muir",
            "id": "comment-12964732"
        },
        {
            "date": "2011-01-04T17:01:36+0000",
            "content": "This looks great!  Any reason not to commit now? ",
            "author": "Michael McCandless",
            "id": "comment-12977345"
        },
        {
            "date": "2011-01-04T17:09:26+0000",
            "content": "I was just only waiting for a review... i'll merge the patch and test again and commit shortly. ",
            "author": "Robert Muir",
            "id": "comment-12977348"
        },
        {
            "date": "2011-01-04T23:12:01+0000",
            "content": "Committed revision 1055238. ",
            "author": "Robert Muir",
            "id": "comment-12977522"
        }
    ]
}