{
    "id": "SOLR-6333",
    "title": "Solr node(cores) cannot recover quickly when there are lots of updates in the good node",
    "details": {
        "affect_versions": "4.7",
        "status": "Closed",
        "fix_versions": [],
        "components": [
            "SolrCloud"
        ],
        "type": "Bug",
        "priority": "Major",
        "labels": "",
        "resolution": "Cannot Reproduce"
    },
    "description": "http://lucene.472066.n3.nabble.com/Cannot-finish-recovery-due-to-always-met-ReplicationHandler-SnapPull-failed-Unable-to-download-xxx-fy-td4151611.html#a4151621\n\nI have 2 solr nodes(solr1 and solr2) in a SolrCloud. \nAfter some issue happened, solr2 are in recovering state. The peersync cannot finish in about 15 min, so it turn to snappull. \nBut when it's doing snap pull, it always met this issue below. Meanwhile, there are still update requests sent to this recovering node(solr2) and the good node(solr1). And the index in the recovering node is deleted and rebuild again and again. So it takes lots of time to finish. \n\nIs it a bug or as solr design? \nAnd could anyone help me on accelerate the progress of recovery? \n\n2014\u5e747\u670817\u65e5 \u4e0b\u53485:12:50\tERROR\tReplicationHandler\tSnapPull failed :org.apache.solr.common.SolrException: Unable to download _vdq.fdt completely. Downloaded 0!=182945 \nSnapPull failed :org.apache.solr.common.SolrException: Unable to download _vdq.fdt completely. Downloaded 0!=182945 \n   at org.apache.solr.handler.SnapPuller$DirectoryFileFetcher.cleanup(SnapPuller.java:1305) \n   at org.apache.solr.handler.SnapPuller$DirectoryFileFetcher.fetchFile(SnapPuller.java:1185) \n   at org.apache.solr.handler.SnapPuller.downloadIndexFiles(SnapPuller.java:771) \n   at org.apache.solr.handler.SnapPuller.fetchLatestIndex(SnapPuller.java:421) \n   at org.apache.solr.handler.ReplicationHandler.doFetch(ReplicationHandler.java:322) \n   at org.apache.solr.cloud.RecoveryStrategy.replicate(RecoveryStrategy.java:155) \n   at org.apache.solr.cloud.RecoveryStrategy.doRecovery(RecoveryStrategy.java:437) \n   at org.apache.solr.cloud.RecoveryStrategy.run(RecoveryStrategy.java:247) \n\n\nWe have below settings in solrconfig.xml: \n     <autoCommit>  \n       <maxDocs>1000</maxDocs>  \n       <maxTime>${solr.autoCommit.maxTime:15000}</maxTime>\n       <openSearcher>true</openSearcher>  \n     </autoCommit>\n\n     <autoSoftCommit>  \n       <maxTime>${solr.autoSoftCommit.maxTime:-1}</maxTime>\n     </autoSoftCommit>\n\nand the <maxIndexingThreads>8</maxIndexingThreads> is as default.",
    "attachments": {
        "solrconfig.xml": "https://issues.apache.org/jira/secure/attachment/12660349/solrconfig.xml"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Forest Soup",
            "id": "comment-14089030",
            "date": "2014-08-07T09:01:34+0000",
            "content": "my config are in this file "
        },
        {
            "author": "Ishan Chattopadhyaya",
            "id": "comment-15684133",
            "date": "2016-11-21T17:16:29+0000",
            "content": "I used Solr 6.3 to creat two nodes, created a collection with two shards, two replicas each. Indexed a bunch of documents, restarted one of the nodes, indexed a few documents while restarting was going on. Upon restarting, there was a recovery attempt by the node and peersync succeeded without any problems.\n\nI think this issue could've been present on some old Solr version, or there could've been some network issue. Since I couldn't reproduce this issue, I suggest we close the issue for now and reopen if someone can assist in reproducing it. "
        }
    ]
}