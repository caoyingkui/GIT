{
    "id": "LUCENE-8186",
    "title": "CustomAnalyzer with a LowerCaseTokenizerFactory fails to normalize multiterms",
    "details": {
        "labels": "",
        "priority": "Minor",
        "resolution": "Fixed",
        "affect_versions": "None",
        "status": "Closed",
        "type": "Bug",
        "components": [],
        "fix_versions": [
            "7.4",
            "master (8.0)"
        ]
    },
    "description": "While working on SOLR-12034, a unit test that relied on the LowerCaseTokenizerFactory failed.\n\nAfter some digging, I was able to replicate this at the Lucene level.\n\nUnit test:\n\n  @Test\n  public void testLCTokenizerFactoryNormalize() throws Exception {\n\n    Analyzer analyzer =  CustomAnalyzer.builder().withTokenizer(LowerCaseTokenizerFactory.class).build();\n\n    //fails\n    assertEquals(new BytesRef(\"hello\"), analyzer.normalize(\"f\", \"Hello\"));\n    \n    //now try an integration test with the classic query parser\n    QueryParser p = new QueryParser(\"f\", analyzer);\n    Query q = p.parse(\"Hello\");\n    //passes\n    assertEquals(new TermQuery(new Term(\"f\", \"hello\")), q);\n\n    q = p.parse(\"Hello*\");\n    //fails\n    assertEquals(new PrefixQuery(new Term(\"f\", \"hello\")), q);\n\n    q = p.parse(\"Hel*o\");\n    //fails\n    assertEquals(new WildcardQuery(new Term(\"f\", \"hel*o\")), q);\n  }\n\n\n\nThe problem is that the CustomAnalyzer iterates through the tokenfilters, but does not call the tokenizer, which, in the case of the LowerCaseTokenizer, does the filtering work.",
    "attachments": {
        "LUCENE-8186.patch": "https://issues.apache.org/jira/secure/attachment/12912951/LUCENE-8186.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "id": "comment-16378612",
            "date": "2018-02-27T13:57:38+0000",
            "content": "I think the main problem is that \"normalizing\" is defined to only apply all the tokenfilters on a single term, not doing tokenization!\n\nThe problem in your example is LowercaseTokenizer, which does 2 things at same time. IMHO, LowercaseTokenizer should be deprecated and removed. It is always always replaceable by using the LetterTokenizer with LowercaseFilter. There should be no performance difference anymore, as both do the same, it's just an additional method call and the loop is executed twice instead of once. But the expensive work is the same. ",
            "author": "Uwe Schindler"
        },
        {
            "id": "comment-16385297",
            "date": "2018-03-04T19:16:45+0000",
            "content": "Uwe: I agree with you. For \"normalize\" the tokenization is implicitly keyword. Tokenizers can't concern themselves with the syntax of wildcards or regex, sorry. They work on real text.\n\nI also agree that LowerCaseTokenizer is stupid  But its factory does the correct thing and returns a LowerCase*Filter* for these purposes!\n\nhttps://github.com/apache/lucene-solr/blob/master/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/LowerCaseTokenizerFactory.java#L70-L74\n\nSo I think CustomAnalyzer forgets to call this method on the TokenizerFactory, just in case the tokenizer is doing something like this. It seems like this is really easy to fix in CustomAnalyzer.normalize? And yeah, separately, we should deprecate LowerCaseTokenizer. ",
            "author": "Robert Muir"
        },
        {
            "id": "comment-16385302",
            "date": "2018-03-04T19:34:13+0000",
            "content": "Thanks Robert. Looks ok, although horrible.\n\nHow about CharFilters? Do they have the same problem? ",
            "author": "Uwe Schindler"
        },
        {
            "id": "comment-16385309",
            "date": "2018-03-04T19:36:23+0000",
            "content": "CharFilterFactories can normalize too, but I think CustomAnalyzer already does the right thing for them?  ",
            "author": "Robert Muir"
        },
        {
            "id": "comment-16385312",
            "date": "2018-03-04T19:37:27+0000",
            "content": "See code for that: https://github.com/apache/lucene-solr/blob/master/lucene/analysis/common/src/java/org/apache/lucene/analysis/custom/CustomAnalyzer.java#L125-L134 ",
            "author": "Robert Muir"
        },
        {
            "id": "comment-16385316",
            "date": "2018-03-04T19:41:08+0000",
            "content": "Ok. It's so horrible. Who invented that? \ud83e\udd14 ",
            "author": "Uwe Schindler"
        },
        {
            "id": "comment-16385321",
            "date": "2018-03-04T19:46:38+0000",
            "content": "I still don't understand why the Solr TokenizerChain does not do this, although the reporter claimed that in Solr it works: https://github.com/apache/lucene-solr/blob/e2521b2a8baabdaf43b92192588f51e042d21e97/solr/core/src/java/org/apache/solr/analysis/TokenizerChain.java ",
            "author": "Uwe Schindler"
        },
        {
            "id": "comment-16385323",
            "date": "2018-03-04T19:47:41+0000",
            "content": "Yeah, the biggest issue i see is the lack of type safety. Currently the method is on an interface like this:\n\n\npublic AbstractAnalysisFactory getMultiTermComponent();\n\n\n\nThis means a CharFilterFactory can return a TokenizerFactory or other crazy possibilities. Users will get ClassCastException in such cases. This is all unrelated to this issue, but its horrible.\n\nIMO it would be better if the api worked different, e.g. three methods that enforce the correct return type. This would remove the casts and prevent stupid stuff from happening in the factories themselves.\n\n\nTokenizerFactory:\n  public TokenFilterFactory getMultiTermComponent() { return null; }\nTokenFilterFactory:\n  public TokenFilterFactory getMultiTermComponent() { return null; }\nCharFilterFactory:\n  public CharFilterFactory getMultiTermComponent() { return null; }\n\n ",
            "author": "Robert Muir"
        },
        {
            "id": "comment-16385362",
            "date": "2018-03-04T20:32:21+0000",
            "content": "+1 to this patch and +1 to improve type safety of these APIs. ",
            "author": "Adrien Grand"
        },
        {
            "id": "comment-16385376",
            "date": "2018-03-04T20:52:00+0000",
            "content": "Tim Allison could you explain why this works with Solr's TokenizerChain, or was this a new test that you added? Solr has exactly same code in TokenizerChain... ",
            "author": "Uwe Schindler"
        },
        {
            "id": "comment-16385449",
            "date": "2018-03-05T00:23:18+0000",
            "content": "I think it would be best to fix this bug here, then let Tim remove any duplication, then refactor the API to be safer. ",
            "author": "Robert Muir"
        },
        {
            "id": "comment-16386042",
            "date": "2018-03-05T13:04:39+0000",
            "content": "Uwe Schindler, it works because multiterms are normalized in TextField's analyzeMultiTerm: https://github.com/tballison/lucene-solr/blob/master/solr/core/src/java/org/apache/solr/schema/TextField.java#L168 , which uses the full analyzer including the tokenizer.\n\nAFAICT, TokenizerChain's normalize() is never actually called at the moment, which, I'm guessing, is why no one found SOLR-11976 until I did when refactoring my code for SOLR-5410.  ",
            "author": "Tim Allison"
        },
        {
            "id": "comment-16492756",
            "date": "2018-05-28T14:52:10+0000",
            "content": "Commit 9ea8927f1c33edcd041b5b83f22af0e0a473ed54 in lucene-solr's branch refs/heads/branch_7x from Adrien Grand\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=9ea8927 ]\n\nLUCENE-8186: LowerCaseTokenizerFactory now lowercases text in multi-term queries. ",
            "author": "ASF subversion and git services"
        },
        {
            "id": "comment-16492757",
            "date": "2018-05-28T14:52:11+0000",
            "content": "Commit 1971ef310906239d88602444ae6b74081648f3e4 in lucene-solr's branch refs/heads/master from Adrien Grand\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=1971ef3 ]\n\nLUCENE-8186: LowerCaseTokenizerFactory now lowercases text in multi-term queries. ",
            "author": "ASF subversion and git services"
        },
        {
            "id": "comment-16492759",
            "date": "2018-05-28T14:53:55+0000",
            "content": "Thanks Tim Allison. ",
            "author": "Adrien Grand"
        }
    ]
}