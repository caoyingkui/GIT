{
    "id": "LUCENE-724",
    "title": "Oracle JVM implementation for Lucene DataStore also a preliminary implementation for an Oracle Domain index using Lucene",
    "details": {
        "labels": "",
        "priority": "Minor",
        "components": [
            "core/store"
        ],
        "type": "New Feature",
        "fix_versions": [],
        "affect_versions": "2.0.0,                                            2.2",
        "resolution": "Not A Problem",
        "status": "Closed"
    },
    "description": "Here a preliminary implementation of the Oracle JVM Directory data store which replace a file system by BLOB data storage.\nThe reason to do this is:\n\n\tUsing traditional File System for storing the inverted index is not a good option for some users.\n\tUsing BLOB for storing the inverted index running Lucene outside the Oracle database has a bad performance because there are a lot of network round trips and data marshalling.\n\tIndexing relational data stores such as tables with VARCHAR2, CLOB or XMLType with Lucene running outside the database has the same problem as the previous point.\n\tThe JVM included inside the Oracle database can scale up to 10.000+ concurrent threads without memory leaks or deadlock and all the operation on tables are in the same memory space!!\n  With these points in mind, I uploaded the complete Lucene framework inside the Oracle JVM and I runned the complete JUnit test case successful, except for some test such as the RMI test which requires special grants to open ports inside the database.\n  The Lucene's test cases run faster inside the Oracle database (11g) than the Sun JDK 1.5, because the classes are automatically JITed after some executions.\n  I had implemented and OJVMDirectory Lucene Store which replaces the file system storage with a BLOB based storage, compared with a RAMDirectory implementation is a bit slower but we gets all the benefits of the BLOB storage (backup, concurrence control, and so on).\n The OJVMDirectory is cloned from the source at\nhttp://issues.apache.org/jira/browse/LUCENE-150 (DBDirectory) but with some changes to run faster inside the Oracle JVM.\n At this moment, I am working in a full integration with the SQL Engine using the Data Cartridge API, it means using Lucene as a new Oracle Domain Index.\n With this extension we can create a Lucene Inverted index in a table using:\n\n\n\ncreate index it1 on t1(f2) indextype is LuceneIndex parameters('test');\n\n assuming that the table t1 has a column f2 of type VARCHAR2, CLOB or XMLType, after this, the query against the Lucene inverted index can be made using a new Oracle operator:\n\nselect * from t1 where contains(f2, 'Marcelo') = 1;\n\n the important point here is that this query is integrated with the execution plan of the Oracle database, so in this simple example the Oracle optimizer see that the column \"f2\" is indexed with the Lucene Domain index, then using the Data Cartridge API a Java code running inside the Oracle JVM is executed to open the search, a fetch all the ROWID that match with \"Marcelo\" and get the rows using the pointer,\nhere the output:\n\nSELECT STATEMENT                                      ALL_ROWS      3       1       115\n       TABLE ACCESS(BY INDEX ROWID) LUCENE.T1          3       1       115\n            DOMAIN INDEX LUCENE.IT1\n\n Another benefits of using the Data Cartridge API is that if the table T1 has insert, update or delete rows operations a corresponding Java method will be called to automatically update the Lucene Index.\n  There is a simple HTML file with some explanation of the code.\n   The install.sql script is not fully tested and must be lunched into the Oracle database, not remotely.\n  Best regards, Marcelo.\n\n\n\tFor Oracle users the big question is, Why do I use Lucene instead of Oracle Text which is implemented in C?\n  I think that the answer is too simple, Lucene is open source and anybody can extend it and add the functionality needed\n\tFor Lucene users which try to use Lucene as enterprise search engine, the Oracle JVM provides an highly scalable container which can scale up to 10.000+ concurrent session and with the facility of querying table in the same memory space.",
    "attachments": {
        "ojvm-11-28-06.tar.gz": "https://issues.apache.org/jira/secure/attachment/12345967/ojvm-11-28-06.tar.gz",
        "ojvm-09-27-07.tar.gz": "https://issues.apache.org/jira/secure/attachment/12366661/ojvm-09-27-07.tar.gz",
        "ojvm-01-09-07.tar.gz": "https://issues.apache.org/jira/secure/attachment/12348574/ojvm-01-09-07.tar.gz",
        "ojvm-12-20-06.tar.gz": "https://issues.apache.org/jira/secure/attachment/12347614/ojvm-12-20-06.tar.gz",
        "ojvm.tar.gz": "https://issues.apache.org/jira/secure/attachment/12345516/ojvm.tar.gz"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2006-11-22T23:45:21+0000",
            "content": "see patch description ",
            "author": "Marcelo F. Ochoa",
            "id": "comment-12452081"
        },
        {
            "date": "2006-11-28T21:04:56+0000",
            "content": "This new version of the OracleJVM extension for Lucene has these changes:\n\n\tA new build.xml file can be used to compile and install remotely the OJVM extension, this distribution is designed to uncompress into the contrib directory of lucene-2.0.0\n\tThe lucene build.xml file requires an addition to pack the test suites as jars with something like this:\n  <target name=\"jar-test\" depends=\"compile-test\">\n    <jar\n      destfile=\"${build.dir}/${final.name}-test.jar\"\n      basedir=\"${build.dir}/classes/test\"\n      excludes=\"*/.java\"\n      />\n  </target>\n\tThe OracleJVM extension uses this entries into the build.properties file:\ndb.str=orcl\ndb.usr=lucene \ndb.pwd=lucene \ndba.usr=sys \ndba.pwd=change_on_install\nto know which database users and passwords are used to install into the target DB.\n\tIf you want to run the OJVMDirectory test remotely to compare it against the database version add this line into the target \"test\" of the common-build.xml file\n      <!-- Oracle JVM Directory implementation -->\n      <sysproperty key=\"db.str\" value=\"${db.str}\"/>\n      <sysproperty key=\"db.usr\" value=\"${db.usr}\"/>\n      <sysproperty key=\"db.pwd\" value=\"${db.pwd}\"/>\nthese lines will pass the user name, password and SQLNet connect string to the tests as java's System properties.\n\tThe complet API for the Oracle Domain index was completed, but the solution for the operator contains outside the where clause is not good.\n\tI will implement a singleton solution for the OJVMDirectory object when is used in read only mode, typically when user performs select operations against tables which have columns indexed with Lucene. This implementation will increase a lot the final performance because the index reader will be ready for each select operation. Obviously I will check if another user or thread makes a write operation on the index to reload the read-only singleton.\n\tThe queue for storing the changes on the index is not implemented yet, I'll add it in a short time.\n\tI am looking for a big set of XML documents, I dowload the DBLP database which is over 300mb of text documents, but I need to upload to the Oracle Database which is not a simple operation \nBest regards, Marcelo.\n\n ",
            "author": "Marcelo F. Ochoa",
            "id": "comment-12454124"
        },
        {
            "date": "2006-12-20T22:03:02+0000",
            "content": "This new release of the OJVMDirectory Lucene Store includes a fully functional Oracle Domain Index with a queue for update/insert massive operations and a lot of performance improvement.\nSee the db/readmeOJVM.html file for more detail. ",
            "author": "Marcelo F. Ochoa",
            "id": "comment-12460070"
        },
        {
            "date": "2007-01-09T19:40:48+0000",
            "content": "Latest code includes:\n\n\tThe  Data Cartridge API is used without column data to reduce the data stored on the queue of changes and speedup the operation of the synchronize method.\n\tQuery Hits are cached associated to the index search and the string returned by the QueryParser.toString() method.\n\tIf no ancillary operator is used in the select, do not store the score list.\n\tThe \"Stemmer\" argument is recognized as parameter given the argument for the SnowBall analyzer, for example: create index it1 on t1(f2) indextype is lucene.LuceneIndex parameters('Stemmer:English');.\n\tBefore installing the ojvm extension is necessary to execute \"ant jar-core\" on the snowball directory.\n\tThe IndexWriter.setUseCompoundFile(false) is called to use multi file storage (faster than the compound file) because there is no file descriptor limitation inside the OJVM, BLOBs are used instead of File.\n\tFiles are marked for deletion and they are purged when calling to Sync or Optimize methods.\n\tBlob are created and populated in one call using Oracle SQL RETURNING information.\n\tA testing script for using OE sample schema, with query comparisons against Oracle Text ctxsys.context index.\n\n\n\nTODO:\n\n\tODCI Stats interface implementation to provide to the optimizer the information about the cost of using the Domain Index.\n\tA binding for using FIRST_ROWS optimizer hint.\n\tA Digester class for loading DBLP database for testing very big indexes.\n\tSupport for column with XDBUriType values.\n\n ",
            "author": "Marcelo F. Ochoa",
            "id": "comment-12463377"
        },
        {
            "date": "2007-07-12T16:45:18+0000",
            "content": "Marcelo,\n\nAre you still working on this?  I have been experimenting with it recently \u2013 thank you for creating it.  Do you think that the I/O might be faster if the Vector was replaced with BLOB I/O via InputStream, OutputStream directly?  That is what I am working with right now, and I did observe my indexing time for a sample data set go from 22 seconds to 13 seconds.  I do currently have the problem that the resulting index is not behaving correctly and am working on that. ",
            "author": "Michael Goddard",
            "id": "comment-12512169"
        },
        {
            "date": "2007-07-12T18:49:08+0000",
            "content": "Michel:\n  I am not tested replacing vector based storage to direct BLOB IO.\n  Now I am too busy in a project, may be I'll have some time in a few week.\n  If you are replacing the vector based access by BLOB IO sure I would\nlike to test it.\n  I am having some open issues specially with the integration of the\ndata cartridge API and the optimizer.\n  Do you have access to an open CVS server to share the code?\n  If not, we can use DBPrism cvs repository at Source Forge.\n  Also in a few week Oracle 11g will be ready for download at OTN\nwebsite, so you can get a lot of performance improvement by using\nSECURE LOB (faster than NFS storage) and the JDK 1.5 JIT included in\nlatest Oracle JVM.\n  Best regards, Marcelo.\n\n\n\n\u2013 \nMarcelo F. Ochoa\nhttp://marcelo.ochoa.googlepages.com/home\n______________\nDo you Know DBPrism? Look @ DB Prism's Web Site\nhttp://www.dbprism.com.ar/index.html\nMore info?\nChapter 17 of the book \"Programming the Oracle Database using Java &\nWeb Services\"\nhttp://www.amazon.com/gp/product/1555583296/\nChapter 21 of the book \"Professional XML Databases\" - Wrox Press\nhttp://www.amazon.com/gp/product/1861003587/\nChapter 8 of the book \"Oracle & Open Source\" - O'Reilly\nhttp://www.oreilly.com/catalog/oracleopen/ ",
            "author": "Marcelo F. Ochoa",
            "id": "comment-12512212"
        },
        {
            "date": "2007-09-14T13:44:38+0000",
            "content": "Joaquin at lucene-java-dev wrote:\nI'm very happy to announce the partial rework and extension to LUCENE-724 (Oracle-Lucene Integration), primarily based on new requirements from LendingClub.com, who commissioned the work to Marcelo Ochoa, the contributer of the original patch (great job Marcelo!). As contribution of LendingClub.com to the Lucene community we have posted the code on a public CVS (sourceforge) as explained below.\n\nHere at Lending Club ( www.lendingclub.com) we have very specific needs regarding the indexing of both structured and unstructured data, most of it transactional in nature and siting in our Oracle !0gR2 DB, with a highly complex schema. Our \"ranking\" of loans in the inventory includes components of exact, textual and hardcore mathematical calculations including time, amount and spatial constraints. This integration of Lucene into Oracle as a Domain Index will now allow us to query this inventory in real-time. Going against the Lucene index, created on \"synthetic documents\" comprised of fields being populated from diverse tables (user data store), eliminates the need to create very complex joins to link data from different tables at query time. This, along with the support of the full Lucene query language, makes this a great alternative to:\n\n   1. Using Lucene outside the database which requires \"crawling\" the data and storing the index outside the database, loosing all the benefits of a fully transactional system and a secure environment.\n   2. Using Oracle Text, which is very powerful but lacks the extensibility and flexibility that Lucene offers (for example, being able to query directly the index from the Java layer or implementing our our ranking algorithm), though to be completely fair some of it is addressed in the new Oracle DB 11g version. \n\nIf anyone is interested in learning more how we are going to use this within Lending Club, please drop me a line. BTW, please make sure you check us out: \"Lending Club ( http://www.lendingclub.com/), the rapidly growing people-to-people (P2P) lending service that launched as a Facebook application in May 2007, today announced the public availability of its services with the launch of LendingClub.com. Lending Club connects lenders and borrowers based upon shared affinities, enabling them to bypass banks to secure better interest rates on loans\"... more about the announcement here http://www.sys-con.com/read/428678.htm. We have seen man entrepreneurs applying for loans and being helped by regular people to build their business with the money obtained at very low interest.\n\nOK, without further marketing stuff (sorry for that), here is the original note sent to me by Marcelo that summarizes all the new cool functionalities:\n\nOJVMDirectory, a Lucene Integration running inside the Oracle JVM is going one step further.\n\nThis new release includes:\n\n\n\tSynchronized with latest Lucene 2.2.0 production\n\tReplaced in memory storage using Vector based implementation by direct BLOB IO, reducing memory usage for large index.\n\tSupport for user data stores, it means you can not only index one column at time (limited by Data Cartridge API on 10g), now you can index multiples columns at base table and columns on related tabled joined together.\n\tUser Data Stores can be customized by the user, it means writing a simple Java Class users can control which column are indexed, padding\n\tused or any other functionality previous to document adding step.\n\tThere is a DefaultUserDataStore which gets all columns of the query and built a Lucene Document with Fields representing each database\n\tcolumns these fields are automatically padded if they have NUMBER or rounded if they have DATE data, for example.\n\tlcontains() SQL operator support full Lucene's QueryParser syntax to provide access to all columns indexed, see examples below.\n\tSupport for DOMAIN_INDEX_SORT and FIRST_ROWS hint, it means that if you want to get rows order by lscore() operator (ascending,descending) the optimizer hint will assume that Lucene Domain Index will returns rowids in proper order avoided an inline-view to sort it.\n\tAutomatic index synchronization by using AQ's Call Back.\n\tLucene Domain Index creates extra tables named IndexName$T and an Oracle AQ named IndexName$Q with his storage table IndexName$QT at user's schema, so you can alter storage's preference if you want.\n\tojvm project is at SourceForge.net CVS, so anybody can get it and collaborate \n\tTested against 10gR2 and 11g database.\n\n\n\n\nSome sample usages:\n\ncreate table t2 (\n f4 number primary key,\n f5 VARCHAR2(200));\ncreate table t1 (\n f1 number,\n f2 CLOB,\n f3 number,\n CONSTRAINT t1_t2_fk FOREIGN KEY (f3)\n     REFERENCES t2(f4) ON DELETE cascade);\ncreate index it1 on t1(f3) indextype is lucene.LuceneIndex\n parameters('Analyzer:org.apache.lucene.analysis\n.SimpleAnalyzer;ExtraCols:f2');\n\nalter index it1\nparameters('ExtraCols:f2,t2.f5;ExtraTabs:t2;WhereCondition:t1.f3=t2.f4;DecimalFormat:000');\n\nLucene domain index will store f2 and f3 columns of table t1 plus f5 of table t2.\n\nSo you can query then with:\n\n select lscore(1),f2 from t1 where lcontains(f3, 'f2:test',1) > 0;\nor\n select lscore(1),f2 from t1 where lcontains(f3, 'f2:test and f3:[001 to 200]',1) > 0;\n\n select /*+ DOMAIN_INDEX_SORT */ lscore(1),f2,t2.f5\n from t1,t2\n where lcontains(f3, 'f2:test1 and f3:[001 to 200] and t2.f5:test2',1) > 0\n and t1.f3=t2.f4\n order by lscore(1) asc;\n\nIn latest example Oracle's optimizer will assume that Lucene Domain Index will resolve first a set of rowid matching \"f2:test1 and f3:[001 to 200] and t2.f5:test2\" then will direct access by by index rowid on table t1 and perform the join with t2.\n\nMore examples and information can be found at:\nhttp://dbprism.cvs.sourceforge.net/dbprism/ojvm/Readme.txt?revision=1.10&view=markup ",
            "author": "Marcelo F. Ochoa",
            "id": "comment-12527500"
        },
        {
            "date": "2007-09-27T12:39:03+0000",
            "content": "This new release includes:\n\n\tSynchronized with latest Lucene 2.2.0 production\n\tReplaced in memory storage using Vector based implementation by direct BLOB IO, reducing memory usage for large index.\n\tSupport for user data stores, it means you can not only index one column at time (limited by Data Cartridge API on 10g), now you can index multiples columns at base table and columns on related tabled joined together.\n\tUser Data Stores can be customized by the user, it means writing a simple Java Class users can control which column are indexed, padding used or any other functionality previous to document adding step.\n\tThere is a DefaultUserDataStore which gets all columns of the query and built a Lucene Document with Fields representing each database\n\tcolumns these fields are automatically padded if they have NUMBER or rounded if they have DATE data, for example.\n\tlcontains() SQL operator support full Lucene's QueryParser syntax to provide access to all columns indexed, see examples below.\n\tSupport for DOMAIN_INDEX_SORT hint, it means that if you want to get rows order by lscore() operator (ascending,descending) the optimizer hint will assume that Lucene Domain Index will returns rowids in proper order avoided an inline-view to sort it.\n\tAutomatic index synchronization by using AQ's Call Back.\n\tLucene Domain Index creates extra tables named IndexName$T and an Oracle AQ named IndexName$Q with his storage table IndexName$QT at user's schema, so you can alter storage's preference if you want.\n\tojvm project is at SourceForge.net CVS, so anybody can get it and collaborate \n\tTested against 10gR2 and 11g database.\n\tLuceneDomainIndex.countHits() function to replace select count from .. where lcontains(..)>0 syntax.\n\n\n\tsupport inline pagination at lcontains(col,'rownum:[n TO m] AND ...\") function\n\n\n\tsee Readme.txt for details of usage and installation.\n-------\nThanks to LendingClub.com to support this contribution.\n\n ",
            "author": "Marcelo F. Ochoa",
            "id": "comment-12530700"
        },
        {
            "date": "2007-09-27T13:21:51+0000",
            "content": "Is the intent of this to be committed as a contrib module (I notice you do grant ASF license)?  This seems like really useful stuff, just not sure how it should be incorporated into Lucene such that we can maintain it.  Presumably it needs an Oracle DB to run, right?  I also notice CVS directories, etc. ",
            "author": "Grant Ingersoll",
            "id": "comment-12530709"
        },
        {
            "date": "2007-09-28T11:01:39+0000",
            "content": "Hi Grant:\n I would like to share this code with all Lucene users.\n Sure it depends on Oracle libraries to compile, (see\nrequired-libs.txt file at lib directory).\n The code is designed to be extracted at contrib directory of Lucene\n2.2.0 layout and only requires a minor change at main Lucene's\nbuild.xml file:\n <target name=\"jar-test\" depends=\"compile-test\">\n   <jar\n     destfile=\"${build.dir}/${final.name}-test.jar\"\n     basedir=\"${build.dir}/classes/test\"\n     excludes=\"*/.java\"\n     />\n </target>\n Which packages Lucene's test suites as jar for uploading inside Oracle JVM.\n As part of the contract with LendingClub.com I suggested that the\nlicense and the code still as Apache 2.0 license and sure they agree\non that.\n I uploaded the code into source forge to provide daily changes to\nLendingClub team but we can move the code to apache CVS if you want.\n Best regards, Marcelo.\n\u2013\nMarcelo F. Ochoa\nhttp://marceloochoa.blogspot.com/ ",
            "author": "Marcelo F. Ochoa",
            "id": "comment-12530976"
        },
        {
            "date": "2007-11-03T05:42:19+0000",
            "content": "Hi Grant:\n  I would like to share this code with all Lucene users.\n  Sure it depends on Oracle libraries to compile, (see\nrequired-libs.txt file at lib directory).\n  The code is designed to be extracted at contrib directory of Lucene\n2.2.0 layout and only requires a minor change at main Lucene's\nbuild.xml file:\n  <target name=\"jar-test\" depends=\"compile-test\">\n    <jar\n      destfile=\"${build.dir}/${final.name}-test.jar\"\n      basedir=\"${build.dir}/classes/test\"\n      excludes=\"*/.java\"\n      />\n  </target>\n  Which packages Lucene's test as jar for uploading inside Oracle JVM.\n  As part of the contract with LendingClub.com I suggested that the\nlicense and the code still as Apache 2.0 license and sure they agree\non that.\n  I uploaded the code into source forge to provide daily changes to\nLendingClub team but we can mode the code to apache CVS if you want.\n  Best regards, Marcelo.\n\n\n\u2013 \nMarcelo F. Ochoa\nhttp://marceloochoa.blogspot.com/\nhttp://marcelo.ochoa.googlepages.com/home\n______________\nDo you Know DBPrism? Look @ DB Prism's Web Site\nhttp://www.dbprism.com.ar/index.html\nMore info?\nChapter 17 of the book \"Programming the Oracle Database using Java &\nWeb Services\"\nhttp://www.amazon.com/gp/product/1555583296/\nChapter 21 of the book \"Professional XML Databases\" - Wrox Press\nhttp://www.amazon.com/gp/product/1861003587/\nChapter 8 of the book \"Oracle & Open Source\" - O'Reilly\nhttp://www.oreilly.com/catalog/oracleopen/ ",
            "author": "Marcelo F. Ochoa",
            "id": "comment-12539823"
        },
        {
            "date": "2011-01-26T08:31:30+0000",
            "content": "Due to long inactivity, and because I'm not sure we want to introduce dependencies on Oracle, (or DB2, SqlServer etc.). We have a DBDirectory over Berkley DB which demonstrates how to create a Directory impl over some DB instance. ",
            "author": "Shai Erera",
            "id": "comment-12986892"
        }
    ]
}