{
    "id": "LUCENE-2840",
    "title": "Multi-Threading in IndexSearcher (after removal of MultiSearcher and ParallelMultiSearcher)",
    "details": {
        "labels": "",
        "priority": "Minor",
        "components": [
            "core/search"
        ],
        "type": "Sub-task",
        "fix_versions": [
            "4.9",
            "6.0"
        ],
        "affect_versions": "None",
        "resolution": "Unresolved",
        "status": "Open"
    },
    "description": "Spin-off from parent issue:\n\n\nWe should discuss about how many threads should be spawned. If you have an index with many segments, even small ones, I think only the larger segments should be separate threads, all others should be handled sequentially. So maybe add a maxThreads cound, then sort the IndexReaders by maxDoc and then only spawn maxThreads-1 threads for the bigger readers and then one additional thread for the rest?",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "date": "2010-12-30T12:36:46+0000",
            "content": "I use the following scheme:\n\n\tThere is a fixed pool of threads shared by all searches, that limits total concurrency.\n\tEach new search apprehends at most a fixed number of threads from this pool (say, 2-3 of 8 in my setup),\n\tand these threads churn through segments as through a queue (in maxDoc order, but I think even that is unnecessary).\n\n\n\nNo special smart binding between threads and segments (eg. 1 thread for each biggie, 1 thread for all of the small ones) -\nmeans simpler code, and zero possibility of stalling, when there are threads to run, segments to search, but binding policy does not connect them.\nUsing fewer threads per-search than total available is a precaution against biggie searches blocking fast ones. ",
            "author": "Earwin Burrfoot",
            "id": "comment-12976027"
        },
        {
            "date": "2011-01-03T20:05:17+0000",
            "content": "Using fewer threads per-search than total available is a precaution against biggie searches blocking fast ones.\n\nBut doesn't that mean that an app w/ rare queries but each query is massive fails to use all available concurrency? ",
            "author": "Michael McCandless",
            "id": "comment-12976928"
        },
        {
            "date": "2011-01-09T08:50:09+0000",
            "content": "But doesn't that mean that an app w/ rare queries but each query is massive fails to use all available concurrency?\nYes. But that's not my case. And likely not someone else's.\n\nI think if you want to be super-generic, it's better to defer exact threading to the user, instead of doing a one-size-fits-all solution. Else you risk conjuring another ConcurrentMergeScheduler.\nWhile we're at it, we can throw in some sample implementation, which can satisfy some of the users, but not everyone. ",
            "author": "Earwin Burrfoot",
            "id": "comment-12979276"
        },
        {
            "date": "2011-01-09T10:06:31+0000",
            "content": "Is it a possible that with this, searching a large optimized index (single segment) might be slower than searching an un-optimzed index of the same size, since the latter enjoys concurrency? If so, is it too wild for more than one thread to handle that single segment? ",
            "author": "Doron Cohen",
            "id": "comment-12979284"
        },
        {
            "date": "2011-01-09T11:10:24+0000",
            "content": "I think if you want to be super-generic, it's better to defer exact threading to the user, instead of doing a one-size-fits-all solution. Else you risk conjuring another ConcurrentMergeScheduler.\n\nI think something like CMS (basically a custom ES w/ proper thread prio/scheduling) will be necessary here.\n\nUntil Java can schedule threads the way an OS schedules processes we'll need to emulate it ourselves.\n\nYou want long running queries (or, merges) to be gracefully down prioritized so that new/fast queries (merges) finish quickly.\n\nAnd you want searches (merges) to use the allowed concurrency fully. ",
            "author": "Michael McCandless",
            "id": "comment-12979293"
        },
        {
            "date": "2011-01-09T11:51:56+0000",
            "content": "A lot of fork-join type frameworks don't even care. Even though scheduling threads is something people supposedly use them for.\nWhy? I guess that's due to low yield/cost ratio.\nYou frequently quote \"progress, not perfection\" in relation to the code, but why don't we apply this same principle to our threading guarantees?\nI don't want to use allowed concurrency fully. That's not realistic. I want 85% of it. That's already a huge leap ahead of single-threaded searches. ",
            "author": "Earwin Burrfoot",
            "id": "comment-12979306"
        },
        {
            "date": "2011-01-09T14:48:37+0000",
            "content": "You frequently quote \"progress, not perfection\" in relation to the code, but why don't we apply this same principle to our threading guarantees?\n\nOh we should definitely apply progress not perfection here \u2013 in fact we already are: for starters (today), we bind concurrency to segments (so eg an \"optimized\" index has no concurrency), and we just use an ES (punt this thread scheduling problem to the caller).  This is better than nothing, but not good enough \u2013 we can do better.\n\nThere's another quote that applies here: \"big dreams, small steps\".  My comment above is \"dreaming\" but when it comes time to actually get the real work done / making progress towards that dream, of course we take baby steps / progress not perfection.\n\nDesign discussions should start w/ the big dreams but then once you've got a rough sense of where you want to get to in the future you shift back to the baby steps you do today, in the direction of that future goal.\n\nMaybe I should wrap my comments in </dream> tags and </babysteps> tags! ",
            "author": "Michael McCandless",
            "id": "comment-12979337"
        },
        {
            "date": "2013-07-23T18:44:45+0000",
            "content": "Bulk move 4.4 issues to 4.5 and 5.0 ",
            "author": "Steve Rowe",
            "id": "comment-13717047"
        },
        {
            "date": "2014-04-16T12:54:41+0000",
            "content": "Move issue to Lucene 4.9. ",
            "author": "Uwe Schindler",
            "id": "comment-13970842"
        }
    ]
}