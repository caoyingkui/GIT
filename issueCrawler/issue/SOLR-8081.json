{
    "id": "SOLR-8081",
    "title": "When creating a collection, we need a way to utilize multiple disks available on a node.",
    "details": {
        "components": [
            "SolrCloud"
        ],
        "type": "Improvement",
        "labels": "",
        "fix_versions": [],
        "affect_versions": "None",
        "status": "Resolved",
        "resolution": "Won't Fix",
        "priority": "Major"
    },
    "description": "Currently, if I want to change the dataDir for a core (such as to utilize multiple disks on a Solr node), I need to either setup a symlink or change the dataDir property in core.properties and restart the Solr node. For instance, if I have a 4-node SolrCloud cluster and want to create a collection with 4 shards with rf=2, then 8 Solr cores will be created across the cluster, 2 per node. If I want to have each core use a separate disk, then I have to do that after the fact. I'm aware that I could create the collection with rf=1 and then use AddReplica to add additional replicas with a different dataDir set, but that feels cumbersome as well.\n\nWhat would be nice is to have a way for me to specify available disks and have Solr use that information when provisioning cores on the node. Anshum Gupta mentioned this might be best accomplished with a replica placement strategy.",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "date": "2015-09-22T04:04:46+0000",
            "author": "Varun Thacker",
            "content": "I'm aware that I could create the collection with rf=1 \n\nWe could create a coreless collection and then have the ability to control the dataDir for all replicas.\n\nIt will be really good if replica placement strategy could have this feature. ",
            "id": "comment-14901891"
        },
        {
            "date": "2015-09-22T10:14:37+0000",
            "author": "Noble Paul",
            "content": "The replica placement strategy will help you if you have multiple nodes running in the same host pointing to different disks. If you have a single node running in a host and you still want different cores to point to different disks , it's not possible ",
            "id": "comment-14902341"
        },
        {
            "date": "2015-09-22T11:26:00+0000",
            "author": "Noble Paul",
            "content": "I would recommend adding the list of available disks for a solr node in solr.xml as follows\n\n\n<solr>\n  \n  <disks>\n    <str name=\"disk1\">/mount/point/disk1/data/dir</str>\n    <str name=\"disk2\">/mount/point/disk2/data/dir</str>\n<disks>\n</solr>\n\n\n\n\nand use something like maxReplicasPerDisk=n while creating a collection. So the node can decide where the datadir for the core would live ",
            "id": "comment-14902416"
        },
        {
            "date": "2015-09-22T22:26:22+0000",
            "author": "Timothy Potter",
            "content": "Thanks Noble Paul ... I think that should work as well as the main concern is to utilize all disks available. I suppose this is not something that needs to have an API since you'll need to make sure the mount points for the disks have the correct perms.\n\nI'd like Solr to be smart about assigning replicas to available disks vs. using maxReplicasPerDisk, such as if we need to allocate 3 replicas on 2 disks, pick the disk to put the 3rd replica on based on disk capacity. ",
            "id": "comment-14903566"
        },
        {
            "date": "2015-09-23T07:39:14+0000",
            "author": "Noble Paul",
            "content": "such as if we need to allocate 3 replicas on 2 disks, pick the disk to put the 3rd replica on based on disk capacity.\n\nUsually, when the replicas are created , the disks would be empty. If you are creating a replica after disks are filled up (partially) itmay make sense.\n\nI suppose this is not something that needs to have an API since you'll need to make sure the mount points for the disks have the correct perms.\n\nI'm not sure if we can do this automatically. How does solr know where in the mo9unt point should the datadir be?\n\nWhat if we don't want Solr to use certain disks? ",
            "id": "comment-14904107"
        },
        {
            "date": "2015-09-23T09:17:50+0000",
            "author": "Jan H\u00f8ydahl",
            "content": "Is this really something for application-level Solr to worry about? Even the most novice IT manager knows how to deploy RAID... ",
            "id": "comment-14904225"
        },
        {
            "date": "2015-09-23T09:19:55+0000",
            "author": "Noble Paul",
            "content": "deploying RAID is not what we are discussing. If you have a bunch of RAID disks how do you ensure that your Solr utilizes them properly  ",
            "id": "comment-14904227"
        },
        {
            "date": "2015-09-23T09:37:22+0000",
            "author": "Jan H\u00f8ydahl",
            "content": "Well, that's up to the IT guys that provision the servers by choosing a sutitable RAID level or other similar technology to present a large single, virtual volume to the application. Thus we do not need to worry how Solr utilize single disks, that is taken care of at OS level. ",
            "id": "comment-14904250"
        },
        {
            "date": "2015-09-23T09:52:16+0000",
            "author": "Noble Paul",
            "content": "I don't know if RAID works like that. Even if it does it is going to be inefficient. What if the same index is written to different physical disks ? Each request may need to hit multiple disks . \n\nI'm not very knowledgeable about this. But in my past job our System admin used to point one solr on each disk to ensure that all disks are utilized fairly ",
            "id": "comment-14904273"
        },
        {
            "date": "2015-09-23T11:39:45+0000",
            "author": "Jan H\u00f8ydahl",
            "content": "In the good old days when I worked for FAST, that were the days when RAM was expensive and all search engines were disk-bound. It was ultra important to get maximum disk I/O throughput, and the solution was either SAN with fibre channel or multiple local disks with RAID (typically HW RAID), striping with well tuned block sizes and stripe sizes. Then you got way better sequential read performance than from single disks.\n\nBut these days we use RAM/CPU much more, indexes are smaller and we do not need to invest that much in optimized disk systems except for special cases. I'm not a disk expert either but I'd argue that the complexity of juggling cores between multiple disks, each which can run full at different times, as well as the unavoidable future requirement to migrate an existing core from one disk to another etc may not be worth it; as long as the problem can be solved futher down the stack. https://en.wikipedia.org/wiki/RAID ",
            "id": "comment-14904373"
        },
        {
            "date": "2015-09-23T17:15:10+0000",
            "author": "Timothy Potter",
            "content": "I'll go ahead and close this for now and go with the suggestion that users should just use RAID to present a single volume to Solr for now\n\nThanks for the input Jan and Noble ",
            "id": "comment-14904847"
        }
    ]
}