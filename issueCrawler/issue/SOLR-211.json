{
    "id": "SOLR-211",
    "title": "regex split() Tokenizer",
    "details": {
        "affect_versions": "None",
        "status": "Closed",
        "fix_versions": [
            "1.2"
        ],
        "components": [
            "search"
        ],
        "type": "New Feature",
        "priority": "Major",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "A TokenizerFactory that makes tokens from:\n\n  string.split( regex );",
    "attachments": {
        "SOLR-211-RegexSplitTokenizer.patch": "https://issues.apache.org/jira/secure/attachment/12356094/SOLR-211-RegexSplitTokenizer.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Ryan McKinley",
            "id": "comment-12491079",
            "date": "2007-04-23T22:00:34+0000",
            "content": "simple regex tokenizer and a test.\n\n\n<fieldType name=\"splitText\" class=\"solr.TextField\" positionIncrementGap=\"100\">\n     <analyzer>\n       <tokenizer class=\"solr.RegexSplitTokenizerFactory\" regex=\"--\"/>\n       <filter class=\"solr.TrimFilterFactory\" />\n     </analyzer>\n </fieldType>\n\n\nGiven a field:\n  \"Architecture-United States-19th century\"\n\nwill create tokens for:\n  \"Architecture\"\n  \"United States\"\n \"19th century\"\n "
        },
        {
            "author": "Hoss Man",
            "id": "comment-12491106",
            "date": "2007-04-24T00:33:38+0000",
            "content": "some quick comments based on a cursory reading of the patch...\n\n1) RegexSplitTokenizerFactory.init should probably compile the regex into a pattern that can be reused more then once ... i think  String.split calls recompile each time.\n2) i don't think the offset stuff will work properly ... the length of the regex string is not the same as the length of the string it matches on when splitting (ie: \\p\n{javaWhitespace}\n) ... we would probably need to use the Matcher API and iterate over the individual matches.\n3) in the vein of like things having like names, we may wan to call this the PatternSplitTokenizer and name it's init param \"pattern\" (to match PatternReplaceFilter) "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12491109",
            "date": "2007-04-24T00:54:36+0000",
            "content": "> should probably compile the regex [...]\n\nYep... beat me to it.\nI was off trying to look up if there was a way to avoid reading everything into a String too... but I don't see a way to use a regex directly on a Reader. "
        },
        {
            "author": "Hoss Man",
            "id": "comment-12491125",
            "date": "2007-04-24T03:55:26+0000",
            "content": "> but I don't see a way to use a regex directly on a Reader.\n\n...I think it's pretty much impossible to have a robust regex system that can operate on character streams, regex engines need to be able to backup .... a lot. "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-12491134",
            "date": "2007-04-24T05:07:44+0000",
            "content": "Thanks for the quick feedback!\n\nHere is an updated version that \n\n1. uses a compiled Pattern\n2. uses matcher.find() to set proper start and offeset\n3. is called PatternSplitTokenizerFactory\n4. The tests make sure the output is the same as you would get with string.split( pattern )\n "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-12491398",
            "date": "2007-04-24T18:50:27+0000",
            "content": "Using a Matcher to generate the tokens makes it easy enough to return the match as token \u2013 not just the split()\n\n\n\tUpdated to take a \"group\" argument - if the group is less then zero, it behaves as a split, otherwise it uses the matched group as the token.\n\n\n\n\n\tChanged the name to PatternTokenizerFactory as it is more general then just split\n\n "
        },
        {
            "author": "Ken Krugler",
            "id": "comment-12491852",
            "date": "2007-04-26T00:25:17+0000",
            "content": "I think we must be working on similar types of projects \n\nI did something similar to the above, but in two different ways:\n\n\n\tI extended WhitespaceTokenizerFactory to take optional pattern & replacement parameters. If these exist, then I apply them before the tokenizer gets called. This lets me do something like strip out all XML fields other than the content of the one that I want to index from a bunch of XML going into a Solr field.\n\tI added a CSVTokenizerFactory, which takes an optional split character and an optional remapping file. This lets me get a field like \"Java,Python,C#\" and turn it into \"java python csharp\", which are the index tokens I need, while leaving the display text as-is.\n\n\n\nI don't know if your new PatternTokenizerFactory could replace either of these, though. For the first case, I still want the white space tokenization after I've stripped off all the junk I don't want. And for the second, I need to be able to do the remapping. "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-12492132",
            "date": "2007-04-26T22:21:54+0000",
            "content": "> \n> I don't know if your new PatternTokenizerFactory could replace either of these, though. For the first case, I still want the white space tokenization after I've stripped off all the junk I don't want. And for the second, I need to be able to do the remapping.\n> \n\nIf your really good with regular expressions, perhaps it could all be combined... I'm not   \n\nIn my real use case, I use the general PatternTokenizerFactory to split the input into a bunch of tokens, then I have a custom (ugly!) TokenFilter transform the stream with other one-off transformations similar to what you describe.  \n "
        },
        {
            "author": "Ryan McKinley",
            "id": "comment-12492134",
            "date": "2007-04-26T22:24:58+0000",
            "content": "added in rev:532508\n\nI'm not sure how to make the svn changelog show up in JIRA.  It looks like issues may get automatically linked if  you start the svn comment with SOLR-XXX.  Is this true?\n\nhttps://issues.apache.org/jira/browse/SOLR-104?page=com.atlassian.jira.plugin.ext.subversion:subversion-commits-tabpanel "
        },
        {
            "author": "Hoss Man",
            "id": "comment-12589311",
            "date": "2008-04-15T23:44:45+0000",
            "content": "This bug was modified as part of a bulk update using the criteria...\n\n\n\tMarked (\"Resolved\" or \"Closed\") and \"Fixed\"\n\tHad no \"Fix Version\" versions\n\tWas listed in the CHANGES.txt for 1.2\n\n\n\nThe Fix Version for all 39 issues found was set to 1.2, email notification\nwas suppressed to prevent excessive email.\n\nFor a list of all the issues modified, search jira comments for this\n(hopefully) unique string: 20080415hossman2 "
        }
    ]
}