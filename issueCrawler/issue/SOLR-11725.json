{
    "id": "SOLR-11725",
    "title": "json.facet's stddev() function should be changed to use the \"Corrected sample stddev\" formula",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [
            "Facet Module"
        ],
        "type": "Improvement",
        "fix_versions": [],
        "affect_versions": "None",
        "resolution": "Unresolved",
        "status": "Open"
    },
    "description": "While working on some equivalence tests/demonstrations for facet.pivot+stats.field vs json.facet I noticed that the stddev calculations done between the two code paths can be measurably different, and realized this is due to them using very different code...\n\n\n\tjson.facet=foo:stddev(foo)\n\t\n\t\tStddevAgg.java\n\t\tMath.sqrt((sumSq/count)-Math.pow(sum/count, 2))\n\t\n\t\n\tstats.field={!stddev=true}foo\n\t\n\t\tStatsValuesFactory.java\n\t\tMath.sqrt(((count * sumOfSquares) - (sum * sum)) / (count * (count - 1.0D)))\n\t\n\t\n\n\n\nSince I\"m not really a math guy, I consulting with a bunch of smart math/stat nerds I know online to help me sanity check if these equations (some how) reduced to eachother (In which case the discrepancies I was seeing in my results might have just been due to the order of intermediate operation execution & floating point rounding differences).\n\nThey confirmed that the two bits of code are not equivalent to each other, and explained that the code JSON Faceting is using is equivalent to the \"Uncorrected sample stddev\" formula, while StatsComponent's code is equivalent to the the \"Corrected sample stddev\" formula...\n\nhttps://en.wikipedia.org/wiki/Standard_deviation#Uncorrected_sample_standard_deviation\n\nWhen I told them that stuff like this is why no one likes mathematicians and pressed them to explain which one was the \"most canonical\" (or \"most generally applicable\" or \"best\") definition of stddev, I was told that:\n\n\n\tThis is something statisticians frequently disagree on\n\tPractically speaking the diff between the calculations doesn't tend to differ significantly when count is \"very large\"\n\t\"Corrected sample stddev\" is more appropriate when comparing two distributions\n\n\n\nGiven that:\n\n\n\tthe primary usage of computing the stddev of a field/function against a Solr result set (or against a sub-set of results defined by a facet constraint) is probably to compare that distribution to a different Solr result set (or to compare N sub-sets of results defined by N facet constraints)\n\tthe size of the sets of documents (values) can be relatively small when computing stats over facet constraint sub-sets\n\n\n\n...it seems like StddevAgg.java should be updated to use the \"Corrected sample stddev\" equation.",
    "attachments": {
        "SOLR-11725.patch": "https://issues.apache.org/jira/secure/attachment/12901054/SOLR-11725.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2017-12-07T11:52:50+0000",
            "content": "I had to find my old Stats notes to check, but the logic here checks out, based on my understanding of the usage.\n\nI took the liberty of running tests/precommit overnight, and both passed for me.  Attaching a trivial patch containing the change Hoss spelled out above.\n ",
            "author": "Jason Gerlowski",
            "id": "comment-16281750"
        },
        {
            "date": "2017-12-07T13:26:07+0000",
            "content": "+1 for changing... \"N-1\" is the more standard form.\n\nAttaching a trivial patch containing the change Hoss spelled out above.\nNote that the accumulator needs to be changed as well for non-distributed stddev calculation.  The Merger is not used in that case.\n\nThis does bring up the question of what to do when N=1 (or N=0 for that matter).\nStandard deviation of a population of N=1 is 0, but of a sample of N=1 is undefined (or infinity?)\n\nWhen N=0, the current code produces 0, but I don't think that's the best choice.\nIn general we've been moving toward omitting undefined functions.  Stats like min() and max() already do this.\n\nTestJsonFacets has this:\n\n    // stats at top level, matching documents, but no values in the field\n    // NOTE: this represents the current state of what is returned, not the ultimate desired state.\n    client.testJQ(params(p, \"q\", \"id:3\"\n        , \"json.facet\", \"{ sum1:'sum(${num_d})', sumsq1:'sumsq(${num_d})', avg1:'avg(${num_d})', min1:'min(${num_d})', max1:'max(${num_d})'\" +\n            \", numwhere:'unique(${where_s})', unique_num_i:'unique(${num_i})', unique_num_d:'unique(${num_d})', unique_date:'unique(${date})'\" +\n            \", where_hll:'hll(${where_s})', hll_num_i:'hll(${num_i})', hll_num_d:'hll(${num_d})', hll_date:'hll(${date})'\" +\n            \", med:'percentile(${num_d},50)', perc:'percentile(${num_d},0,50.0,100)', variance:'variance(${num_d})', stddev:'stddev(${num_d})' }\"\n        )\n        , \"facets=={count:1 \" +\n            \",sum1:0.0,\" +\n            \" sumsq1:0.0,\" +\n            \" avg1:0.0,\" +   // TODO: undesirable. omit?\n            // \" min1:'NaN',\" +\n            // \" max1:'NaN',\" +\n            \" numwhere:0,\" +\n            \" unique_num_i:0,\" +\n            \" unique_num_d:0,\" +\n            \" unique_date:0,\" +\n            \" where_hll:0,\" +\n            \" hll_num_i:0,\" +\n            \" hll_num_d:0,\" +\n            \" hll_date:0,\" +\n            \" variance:0.0,\" +\n            \" stddev:0.0\" +\n            \" }\"\n    );\n\n\n\nI'd be tempted to treat N=0 and N=1 as undefined, and omit them.  Note that we need to be careful to have the N=1 case still contribute to a distributed bucket, even if it's undefined locally!\nIn the distributed case, N=0 is normally handled generically for anything that doesn't produce a result (they are \"missing\"/null and are sorted after anything that has a value).  Things may work if we make getDouble() return 0 (for sorting), but then override getMergedResult() to return null when N <= 1.\n\nOh, and whatever treatment we give stddev(), we should presumably give to variance()?\n\nWhen thinking about the sorting, it occurs to me that there is probably a minor sorting bug.\nN=0 is treated the same as a true 0 standard deviation, but they shouldn't sort equivalently.\nBut we still have a sorting bug locally anyway with respect to sort-missing-last: SOLR-10618 ",
            "author": "Yonik Seeley",
            "id": "comment-16281837"
        },
        {
            "date": "2017-12-07T19:12:54+0000",
            "content": "\n\nThis does bring up the question of what to do when N=1 (or N=0 for that matter).\n\nI ommitted them from my original description for brevity to focus on the bigger picture of the equations, but for the record the full implemetnion of stddev in each of the two classes mentioned are...\n\n\n\tStddevAgg.java: \n\ndouble val = count == 0 ? 0.0d : Math.sqrt((sumSq/count)-Math.pow(sum/count, 2));\nreturn val;\n\n\n\tStatsValuesFactory.java: \n\nif (count <= 1.0D) {\n  return 0.0D;\n}\n\nreturn Math.sqrt(((count * sumOfSquares) - (sum * sum)) / (count * (count - 1.0D)));\n\n\n\n\n\n\nWhen N=0, the current code produces 0, but I don't think that's the best choice. ...\n\nAgreed, it should really be 'null' (or 'NaN')\n\n(i'm not sure why StatsValuesFactory.java currently returns 0.0D when count==0 ... other StatsValuesFactory.java stats like min/max correctly return 'null' ... it's weird)\n\n...In general we've been moving toward omitting undefined functions. Stats like min() and max() already do this.\n\nWhoa... really? ... that seems like it would make th client parsing realy hard...\n\nYou're saying users can't expect that every \"facet\" key they specify in the request will be include in the response? (in the event it's 'null' or 'NaN' or whatever makes sense given it's data type)  Why???\n\nI'd be tempted to treat N=0 and N=1 as undefined\n\nAs I said, for N=0 I agree with you that the result should be \"undefined/null/NaN\" (and if that means that it's excluded from the response to be consistent with the existing behavior in json.facet then so be it) ... but i'm a big \"-1\" (vote, i mean, not math) on treating stddev(N=1) as \"undefined\" ... that makes no sense to me.  \n\nFor a singleton set, the stddev() should absolutely be \"0\" \u2013 all of the value(s) in the set are identical, the amount of deviation between the value(s) in set is \"none\".  For the purpose of comparing the \"consistency\" of this set to any other sets, you know that this set is as consistent as it can possibly be.\n\nWhy sould the stddv([42]} be any different then the stddev([42,42,42,42,42,....]) ????\n\nOh, and whatever treatment we give stddev(), we should presumably give to variance()?\n\nI would asssume so, but first i'd have to go refresh my memory on how exactly variance differs from stddev \n\n ",
            "author": "Hoss Man",
            "id": "comment-16282354"
        },
        {
            "date": "2017-12-12T19:03:13+0000",
            "content": "Commit 53f2d4aa3aa171d5f37284eba9ca56d987729796 in lucene-solr's branch refs/heads/branch_7x from Chris Hostetter\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=53f2d4a ]\n\nBeef up testing of json.facet 'refine:simple' when dealing with 'Long Tail' terms\n\nIn an attempt to get more familiar with json.facet refinement, I set out to try and refactor/generalize/clone\nsome of the existing facet.pivot refinement tests to assert that json.facet could produce the same results.\nThis test is a baby step towards doing that: Cloning DistributedFacetPivotLongTailTest into\nDistributedFacetSimpleRefinementLongTailTest (with shared index building code).\n\nAlong the way, I learned that the core logic of 'refine:simple' is actually quite different then how facet.field\n& facet.pivot work (see discussion in SOLR-11733), so they do NOT produce the same results in many \"Long Tail\"\nSitautions.  As a result, many of the logic/assertions inDistributedFacetSimpleRefinementLongTailTest are very\ndiffernet then their counter parts in DistributedFacetPivotLongTailTest, with detailed explanations in comments.\n\nHopefully this test will prove useful down the road to anyone who might want to compare/contrast facet.pivot\nwith json.facet, and to prevent regressions in 'refine:simple' if/when we add more complex refinement\napproaches in the future.\n\nThere are also a few TODOs in the test related to some other small discrepencies between json.facet and\nstats.field that I opened along the way, indicating where the tests should be modified once those issues are\naddressed in json.facet...\n\n\n\tSOLR-11706: support for multivalued numeric fields in stats\n\tSOLR-11695: support for 'missing()' & 'num_vals()' (aka: 'count' from stats.field) numeric stats\n\tSOLR-11725: switch from 'uncorrected stddev' to 'corrected stddev'\n\n\n\n(cherry picked from commit 2990c88a927213177483b61fe8e6971df04fc3ed) ",
            "author": "ASF subversion and git services",
            "id": "comment-16288086"
        },
        {
            "date": "2017-12-12T19:03:25+0000",
            "content": "Commit 2990c88a927213177483b61fe8e6971df04fc3ed in lucene-solr's branch refs/heads/master from Chris Hostetter\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=2990c88 ]\n\nBeef up testing of json.facet 'refine:simple' when dealing with 'Long Tail' terms\n\nIn an attempt to get more familiar with json.facet refinement, I set out to try and refactor/generalize/clone\nsome of the existing facet.pivot refinement tests to assert that json.facet could produce the same results.\nThis test is a baby step towards doing that: Cloning DistributedFacetPivotLongTailTest into\nDistributedFacetSimpleRefinementLongTailTest (with shared index building code).\n\nAlong the way, I learned that the core logic of 'refine:simple' is actually quite different then how facet.field\n& facet.pivot work (see discussion in SOLR-11733), so they do NOT produce the same results in many \"Long Tail\"\nSitautions.  As a result, many of the logic/assertions inDistributedFacetSimpleRefinementLongTailTest are very\ndiffernet then their counter parts in DistributedFacetPivotLongTailTest, with detailed explanations in comments.\n\nHopefully this test will prove useful down the road to anyone who might want to compare/contrast facet.pivot\nwith json.facet, and to prevent regressions in 'refine:simple' if/when we add more complex refinement\napproaches in the future.\n\nThere are also a few TODOs in the test related to some other small discrepencies between json.facet and\nstats.field that I opened along the way, indicating where the tests should be modified once those issues are\naddressed in json.facet...\n\n\n\tSOLR-11706: support for multivalued numeric fields in stats\n\tSOLR-11695: support for 'missing()' & 'num_vals()' (aka: 'count' from stats.field) numeric stats\n\tSOLR-11725: switch from 'uncorrected stddev' to 'corrected stddev'\n\n ",
            "author": "ASF subversion and git services",
            "id": "comment-16288090"
        },
        {
            "date": "2017-12-29T05:13:09+0000",
            "content": "\n> ...In general we've been moving toward omitting undefined functions. Stats like min() and max() already do this.\nWhoa... really? ... that seems like it would make th client parsing realy hard...\n\nTrying to remember.  I think it may have just worked out that way originally when null is returned as the value from SlotAcc.getValue()\nAnd I may have also conflated \"empty bucket\" with \"stat over no values\".  I'm not sure if client parsing is really much harder since a map interface of bucket.get(\"mystat\") would return null in both cases.\nOn the other hand, I can see how it could be confusing to request a stat and not see it at all in the response.  Overall I guess I'm leaning toward returning \"mystat\":null for a non-empty bucket where mystat has no value / undefined value.\n\nFor a singleton set, the stddev() should absolutely be \"0\"\n\nStandard deviation of a population of size 1, yes. But this issue was about switching to standard deviation of samples, and that is undefined (or infinite) for a single sample.\nPython throws an exception: https://docs.python.org/3/library/statistics.html#statistics.stdev\nGoogle sheets will return a div-by-0 error: https://support.google.com/docs/answer/3094054?hl=en\nExcel also gives a div-by-0 error with a single value.  I can't find anything using the \"N-1\" variant that uses 0 for a single sample.\n ",
            "author": "Yonik Seeley",
            "id": "comment-16305994"
        }
    ]
}