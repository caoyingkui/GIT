{
    "id": "SOLR-8263",
    "title": "Tlog replication could interfere with the replay of buffered updates",
    "details": {
        "components": [],
        "type": "Sub-task",
        "labels": "",
        "fix_versions": [
            "5.5",
            "6.0"
        ],
        "affect_versions": "None",
        "status": "Closed",
        "resolution": "Fixed",
        "priority": "Major"
    },
    "description": "The current implementation of the tlog replication might interfere with the replay of the buffered updates. The current tlog replication works as follow:\n1) Fetch the the tlog files from the master\n2) reset the update log before switching the tlog directory\n3) switch the tlog directory and re-initialise the update log with the new directory.\nCurrently there is no logic to keep \"buffered updates\" while resetting and reinitializing the update log.",
    "attachments": {
        "SOLR-8263.patch": "https://issues.apache.org/jira/secure/attachment/12775960/SOLR-8263.patch",
        "SOLR-8263-trunk-3.patch": "https://issues.apache.org/jira/secure/attachment/12774089/SOLR-8263-trunk-3.patch",
        "SOLR-8263-trunk-2.patch": "https://issues.apache.org/jira/secure/attachment/12772244/SOLR-8263-trunk-2.patch",
        "SOLR-6273-plus-8263-5x.patch": "https://issues.apache.org/jira/secure/attachment/12775959/SOLR-6273-plus-8263-5x.patch",
        "SOLR-8263-trunk-1.patch": "https://issues.apache.org/jira/secure/attachment/12771959/SOLR-8263-trunk-1.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2015-11-12T12:45:26+0000",
            "author": "Renaud Delbru",
            "content": "Shalin Shekhar Mangar Erick Erickson An initial first patch for this issue. It includes a unit test that was able to reproduce the described issue, and an initial fix for the issue.\nThe index fetcher is now taking care of moving the buffered updates from the previous update log to the new one. During the move, the index fetcher is blocking updates to ensure that no buffered updates are missed. ",
            "id": "comment-15002018"
        },
        {
            "date": "2015-11-13T17:37:25+0000",
            "author": "Renaud Delbru",
            "content": "A new version of the patch (this replaces the previous one) which includes a fix related to the write lock.\nIn the previous patch, the write lock was removed accidentally while re-initialising the update log with the new set of tlog files (the init method was creating a new instance of the VersionInfo). As a consequence there was a small time frame where updates were lost (a batch of documents was missed in 1 over 10 runs). The fix introduces a new init method that preserves the original VersionInfo instance and therefore preserves the write lock.\nI have run the test 50 times without seeing anymore the issue. ",
            "id": "comment-15004348"
        },
        {
            "date": "2015-11-19T11:30:43+0000",
            "author": "Shalin Shekhar Mangar",
            "content": "Thanks Renaud, I am reviewing this patch. Erick, if you want, I can take this up. ",
            "id": "comment-15013388"
        },
        {
            "date": "2015-11-19T15:05:35+0000",
            "author": "Erick Erickson",
            "content": "Shalin Shekhar Mangar I've already put it in my local copy and beasted the tests and I'll handle committing back to trunk etc.\n\nAll eyes on the code are welcome of course, thanks for your attention! ",
            "id": "comment-15013660"
        },
        {
            "date": "2015-11-23T17:06:10+0000",
            "author": "Shalin Shekhar Mangar",
            "content": "Renaud Delbru - I went through the patch and it looks good.\n\nIf I understood the sequence of operations correctly \u2013 the update log's recovery info (and hence the tlog file name and offset) is stored and the update log is initialised with these details. The old buffered tlog file is read and each and every operation starting from the offset is copied over to the new update logs. The old tlog file is discarded at this point. RecoverStrategy then proceeds to apply buffered updates as usual.\n\nCan you please confirm or correct my understanding of the solution? If this is correct then we're good to commit this patch. I beasted the tests for a while and found no data loss.\n\nThe only negative to this solution is that the replica may have the same updates in the update log again (one copy as written on the leader and another copied over from the old buffered tlog) which means that they will be replicated twice (albeit harmlessly) to the peer cluster? ",
            "id": "comment-15022474"
        },
        {
            "date": "2015-11-24T15:29:53+0000",
            "author": "Renaud Delbru",
            "content": "Shalin Shekhar Mangar Yes, you understood the sequence correctly. To be more precise here is how it works:\n1) the tlog files of the leader are downloaded in a temporary directory\n2) After the files have been downloaded properly, a write lock is acquired by the IndexFetcher. The original tlog directory is renamed as a backup directory, and the temporary directory is renamed as the active tlog directory.\n3) The update log is reset with the new active log directory. During this reset, the recovery info is used to read the backup buffered tlog file and every buffered operation is copied to the new buffered tlog.\n4) The write lock is released, and the recovery operation will continue and apply the buffered updates.\n\nIndeed, the buffered tlog can contain duplicate operations with the replica update log. During the recovery operation, the replica might receive from the leader some operations that will be buffered, but they might be also present in one of the tlog that is downloaded from the leader. Apart from the disk space usage of these duplicate operations and the additional network transfer, there is no harm, as these duplicate operations will be ignored by the peer cluster. We could improve the tlog recovery operation to de-duplicate the buffered tlog while copying the buffered updates. We could check the version of the latest operations in the downloaded tlog, and skip operations from the buffered tlog if their version is inferior to the latest know. It should be a relatively small patch. I can try to work on that in the next days and submit something, if that's fine with you and Erick Erickson ?\n ",
            "id": "comment-15024675"
        },
        {
            "date": "2015-11-24T16:07:23+0000",
            "author": "Renaud Delbru",
            "content": "Shalin Shekhar Mangar Erick Erickson A new patch including the dedup logic for the buffered updates. I have launched a few runs without any issue. The changes are minimal, but it might be good to beast it a last time ? ",
            "id": "comment-15024736"
        },
        {
            "date": "2015-11-24T16:20:03+0000",
            "author": "Shalin Shekhar Mangar",
            "content": "+1 LGTM\n\nThanks Renaud. ",
            "id": "comment-15024770"
        },
        {
            "date": "2015-11-24T18:30:42+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1716229 from Erick Erickson in branch 'dev/trunk'\n[ https://svn.apache.org/r1716229 ]\n\nSOLR-8263: Tlog replication could interfere with the replay of buffered updates ",
            "id": "comment-15025048"
        },
        {
            "date": "2015-11-24T18:50:16+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1716233 from Erick Erickson in branch 'dev/trunk'\n[ https://svn.apache.org/r1716233 ]\n\nSOLR-8263: Reverting commit, missed latest patch from Renaud ",
            "id": "comment-15025091"
        },
        {
            "date": "2015-11-27T17:42:34+0000",
            "author": "Erick Erickson",
            "content": "This patch must be applied after SOLR-6273, especially if you're applying the 5x patch to your own build ",
            "id": "comment-15030090"
        },
        {
            "date": "2015-12-06T01:29:22+0000",
            "author": "ASF subversion and git services",
            "content": "Commit 1718142 from Erick Erickson in branch 'dev/trunk'\n[ https://svn.apache.org/r1718142 ]\n\nSOLR-8263: Tlog replication could interfere with the replay of buffered updates ",
            "id": "comment-15043626"
        },
        {
            "date": "2015-12-06T01:34:58+0000",
            "author": "Erick Erickson",
            "content": "This patch is for 5x if we ever want to put CDCR in a 5x release since both SOLR-6273 and SOLR-8263 should be committed. I'll put this patch on both JIRAs. The patch should just be applied to 5x, no merging from trunk is necessary there.\n\nNOTE: The 5x patch was a little tricky to generate as dis-allowing local loggers happened between times, but all that is incorporated here.\n\nMany kudos to Renaud for all this work ",
            "id": "comment-15043628"
        },
        {
            "date": "2015-12-06T01:36:50+0000",
            "author": "Erick Erickson",
            "content": "The final patch for just this JIRA to be applied after the trunk version after SOLR-6273. This patch supersedes all of the earlier 8263 patches\n\nThis patch is included in the SOLR-6273-plus-8263-5x.patch. ",
            "id": "comment-15043629"
        },
        {
            "date": "2015-12-06T01:39:10+0000",
            "author": "Erick Erickson",
            "content": "Thanks Renaud! ",
            "id": "comment-15043632"
        },
        {
            "date": "2015-12-07T11:35:30+0000",
            "author": "Renaud Delbru",
            "content": "While the patch SOLR-8263-trunk-3 which added the dedup logic for the buffered updates seems straightforward, it introduced an issue which could lead to loss of documents.\nThe dedup logic was using the version of the last operation from the tlog files transferred from the master as a starting point for the dedup logic. However, these tlog files were not in synch with the index commit point, there were likely ahead of the index commit point (i.e., there were containing operations that occurred after the index commit point). Therefore, the starting point of the dedup logic was ahead of the index commit point, and therefore it was dropping all operations that occurred between the index commit point and the time the tlog files were transferred from the master.\nIn order to solve this, we had to modify the ReplicationHandler to filter out tlog files that were not associated to a given commit point. To find the tlog files associated to an index commit point, we fetch the max version of an index commit using VersionInfo.getMaxVersionFromIndex and use this version number to discard tlog files. Tlog file name encodes the version of their starting operation (this was originally used for seeking more efficiently across multiple tlog files), and we use this starting version to discard tlog that were created after the commit point (i.e., if starting version > max version).\nThe new patch committed by Erick includes this approach. ",
            "id": "comment-15044802"
        },
        {
            "date": "2015-12-07T14:24:12+0000",
            "author": "Shalin Shekhar Mangar",
            "content": "Good to know, thanks Renaud! ",
            "id": "comment-15045009"
        }
    ]
}