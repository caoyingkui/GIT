{
    "id": "LUCENE-1812",
    "title": "Static index pruning by in-document term frequency (Carmel pruning)",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [
            "modules/other"
        ],
        "type": "New Feature",
        "fix_versions": [
            "3.6"
        ],
        "affect_versions": "None",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "This module provides tools to produce a subset of input indexes by removing postings data for those terms where their in-document frequency is below a specified threshold. The net effect of this processing is a much smaller index that for common types of queries returns nearly identical top-N results as compared with the original index, but with increased performance. \n\nOptionally, stored values and term vectors can also be removed. This functionality is largely independent, so it can be used without term pruning (when term freq. threshold is set to 1).\n\nAs the threshold value increases, the total size of the index decreases, search performance increases, and recall decreases (i.e. search quality deteriorates). NOTE: especially phrase recall deteriorates significantly at higher threshold values. \n\nPrimary purpose of this class is to produce small first-tier indexes that fit completely in RAM, and store these indexes using IndexWriter.addIndexes(IndexReader[]). Usually the performance of this class will not be sufficient to use the resulting index view for on-the-fly pruning and searching. \n\nNOTE: If the input index is optimized (i.e. doesn't contain deletions) then the index produced via IndexWriter.addIndexes(IndexReader[]) will preserve internal document id-s so that they are in sync with the original index. This means that all other auxiliary information not necessary for first-tier processing, such as some stored fields, can also be removed, to be quickly retrieved on-demand from the original index using the same internal document id. \n\nThreshold values can be specified globally (for terms in all fields) using defaultThreshold parameter, and can be overriden using per-field or per-term values supplied in a thresholds map. Keys in this map are either field names, or terms in field:text format. The precedence of these values is the following: first a per-term threshold is used if present, then per-field threshold if present, and finally the default threshold.\n\nA command-line tool (PruningTool) is provided for convenience. At this moment it doesn't support all functionality available through API.",
    "attachments": {
        "pruning.patch": "https://issues.apache.org/jira/secure/attachment/12416662/pruning.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2009-08-15T14:58:42+0000",
            "content": "Patch relative to the current trunk. ",
            "author": "Andrzej Bialecki",
            "id": "comment-12743722"
        },
        {
            "date": "2009-11-02T14:36:21+0000",
            "content": "Updated patch against trunk/ . This patch is a major refactoring that opens way for other implementations of stored fields and postings pruning. Two policies are included in this patch - the original Carmel method, and a simple TF-based threshold method. ",
            "author": "Andrzej Bialecki",
            "id": "comment-12772521"
        },
        {
            "date": "2009-11-06T18:36:18+0000",
            "content": "Andzrej, when I try to look at the PDF you posted on the StaticIndexPruning wiki page, Adobe Acrobat gives me the following error:\n\n\nCannot extract the embedded font 'CAAAA+ArialMT'.  Some characters may not display or print correctly.\n\nand the text is illegible - everything except the page titles looks like a series of dots. ",
            "author": "Steve Rowe",
            "id": "comment-12774355"
        },
        {
            "date": "2009-11-06T18:46:22+0000",
            "content": "There have been problems with PDF uploads since the recent Wiki upgrade ... I'll keep trying until it gets through in one piece. Sorry ... ",
            "author": "Andrzej Bialecki",
            "id": "comment-12774363"
        },
        {
            "date": "2009-11-10T03:46:48+0000",
            "content": "Andrzej, i tested your patch. I found two places where @override was on an interface, only problem so far.\n\nhere are some results on the hamshahri persian test collection (I used TF method with -t 2)\n\n\n\n\nMeasure\nUnpruned\nPruned\n\n\nindex size\n98627KB\n42339KB\n\n\nmap\n0.4809\n0.4241\n\n\nrecip_rank\n0.8368\n0.8393\n\n\nP5\n0.6277\n0.6369\n\n\nP10\n0.5677\n0.5785\n\n\nP15\n0.5436\n0.5231\n\n\nP20\n0.5185\n0.4969\n\n\nP30\n0.4703\n0.4385\n\n\nP100\n0.2782\n0.2440\n\n\n\n\n\nthe queries in this corpus are somewhat general, but seems to be a nice way to reduce the index to more than half its size, still with reasonable quality. ",
            "author": "Robert Muir",
            "id": "comment-12775266"
        },
        {
            "date": "2009-11-10T09:50:23+0000",
            "content": "Nice job, Robert - thanks! BTW, your results show an effect that was reported in the papers on this subject, namely that some metrics may actually improve, like MRR and P@10 above. ",
            "author": "Andrzej Bialecki",
            "id": "comment-12775358"
        },
        {
            "date": "2009-11-10T15:10:53+0000",
            "content": "Andrzej, are you still working on the carmel policy? \nI see -conf isn't yet implemented, and I can't seem to get it to prune anything with just a default threshold... guessing its still work in progress? ",
            "author": "Robert Muir",
            "id": "comment-12775443"
        },
        {
            "date": "2009-11-11T13:38:06+0000",
            "content": "Default threshold of what? When using the Carmel method, the threshold value should be between 0.0 - 1.0, where 1.0 means no pruning, i.e. 100% of docs are retained. I'm sorry for the confusion - the documentation should be clearer on this point. ",
            "author": "Andrzej Bialecki",
            "id": "comment-12776450"
        },
        {
            "date": "2009-11-11T14:45:43+0000",
            "content": "Default threshold of what?\n\nWhat was confusing me is that the console output always says \"deleted: 0\" for -impl carmel\nFor -impl tf, the console output is correct.\n\nBut looking at the resulting index (which I should have done earlier, sorry), I can see that -impl carmel does work. ",
            "author": "Robert Muir",
            "id": "comment-12776472"
        },
        {
            "date": "2009-11-11T15:05:37+0000",
            "content": "Code seems to be Java 1.5, which is good, but I am wondering about some @SuppressWarnings e.g. in getFieldNames(). The original overriden method returns Collection<String>, if you change that to return the correct type it doesn't need SuppressWarnings. There are more places. Also if you use Collections.<Type>emptyMap() and so on, it is also type safe.\n\nAlso we use no space after comma in Generic type parameters.\n\nBut I like the patch, nice work! ",
            "author": "Uwe Schindler",
            "id": "comment-12776479"
        },
        {
            "date": "2009-11-11T19:23:02+0000",
            "content": "I'll prepare a new patch - the reason for these deficiencies is that I worked against trunk just before the generics patches were applied  ",
            "author": "Andrzej Bialecki",
            "id": "comment-12776589"
        },
        {
            "date": "2010-05-18T15:18:43+0000",
            "content": "Updated patch relative to branch_3x. ",
            "author": "Andrzej Bialecki",
            "id": "comment-12868678"
        },
        {
            "date": "2010-05-18T16:41:13+0000",
            "content": "Hi Andrzej, thanks for updating the patch.\n\nI am curious about package organization here, do you anticipate adding some additional pruning functionality in the future that would be different than an index modification tool?\n\nI only ask, because looking at reorganizing our contrib area (LUCENE-2323), I've often thought that perhaps we need a \"contrib/index\" for all the index-related tools, instead of having various ones in \"miscellaneous\", and I wonder what your opinions are on that.\n\nIn any event we could always reorganize this after this issue is resolved if thats the best thing to do, and it could temporarily be contrib/pruning, its just svn moves. ",
            "author": "Robert Muir",
            "id": "comment-12868719"
        },
        {
            "date": "2010-05-18T16:52:11+0000",
            "content": "I'm fine with reorganizing it - I originally put this into contrib/pruning to avoid polluting the contrib/misc. If we end up putting this stuff in contrib/index together with other tools then perhaps we should create sub-packages for related functionality, otherwise it would look messy. ",
            "author": "Andrzej Bialecki",
            "id": "comment-12868730"
        },
        {
            "date": "2010-05-23T10:30:22+0000",
            "content": "Hi Andrzej, Robert, please note that IBM holds a patent on Lossy index compression.\nI am checking with the IP department at IBM about committing an implementation of the patent in Lucene, and will update here as soon as I know where it stands - could you hold committing this until then? ",
            "author": "Doron Cohen",
            "id": "comment-12870383"
        },
        {
            "date": "2010-05-24T05:10:50+0000",
            "content": "Thank you - yes, I think we will need to wait with this. I wasn't aware of the patent when I implemented this patch, and now after reading it I have the impression that it covers the exact algorithm described in the original paper, so perhaps we should be in the clear if we focus on other methods or a modified versions of it, but of course IANAL. ",
            "author": "Andrzej Bialecki",
            "id": "comment-12870507"
        },
        {
            "date": "2010-08-10T00:11:03+0000",
            "content": "Doron, were you able to check on the patent situation? If there's a chance of solving this in a positive way, how long do you think this could take? ",
            "author": "Andrzej Bialecki",
            "id": "comment-12896742"
        },
        {
            "date": "2010-08-10T20:25:08+0000",
            "content": "Hi Andrzej, chances seem pretty good. We were thinking about further developing the index pruning implementation, however didn't get to it, hope to, later this year. If you rather not wait for that please go ahead with the current implementation. Thanks, Doron. ",
            "author": "Doron Cohen",
            "id": "comment-12897030"
        },
        {
            "date": "2010-08-10T21:08:41+0000",
            "content": "That's great news, thanks! However, now you got me thinking ... considering there is legal aspect to the matter, do we (the Apache Lucene project) need something more substantial from IBM (e.g. a statement from your IP dept.) than just your \"go ahead\" in a JIRA comment? ",
            "author": "Andrzej Bialecki",
            "id": "comment-12897043"
        },
        {
            "date": "2010-08-12T10:12:42+0000",
            "content": "Hi Andrzej, I would have asked the same question  Fortunately this is cleared by the following patch I am attaching next (with that little check box in the Attach-Files dialog) ",
            "author": "Doron Cohen",
            "id": "comment-12897671"
        },
        {
            "date": "2010-08-12T12:12:09+0000",
            "content": "The pruning framework is pretty cool - it is quite easy to add a new pruning policy!\n\nInitially I planned to focus on CarmelPruningPolicy plus add the more sophisticated algorithm (tpoK) described in the paper, but eventually found myself doing more changes - Andrzej, I hope you like the changes - like some methods I renamed - otherwise please feel free to rename them back.\n\nPatch Details\n\n\n\tDocumentation changes - mainly moved things to where I thought they belong, like moving from CarmelPruning to TFPruning the general discussion that applies to any Term pruning implementation.\n\tRenamed some of TermPruningPolicy methods for better readability - well, to me :) \u2013 hope you agree with the new names, othewise please feel free to change back.\n\tRenamed CarmelTermPruningPolicy to CarmelTermPruningUniformPolicy. - quite a long name... but descriptive, as this an enhanced form of the \"uniform\" case from the paper. Modified documentation accordingly.\n\tAdded CarmelTermPruningTopKPolicy - this is the more sophisticated/strong form of pruning described in the paper. (Test case added.)\n\tFixed some compiler warnings (1.5, Lucene.Version..)\n\tBug (?) in CarmelTermPruningPolicy in initTermPositions() - it sorts by docid before selecting the top subset, but in fact this seems dead code? Added a \"TODO deadcode\" there, maybe I am missing something.\n\tEnabled topK pruning through the PruningTool program (untested)\n\tSimplified the if statements in PruningRedaer.PruningTermEnum.next() - hopefully not missing something t here...\n\n\n\nThere's more to do though not sure when I'll have the cycles..:\n\n\tQuality/performance test for the topK pruning algorithm - using LAtimes or some other judged collection.\n  Or perhaps Robert can try it on that Persian test collection. \n\tAdd also the \"Delta Pruning\" policy as described in the paper\n\tJunit for CarmelTermPruningUniformPolicy\n\n\n\nDoron ",
            "author": "Doron Cohen",
            "id": "comment-12897715"
        },
        {
            "date": "2010-08-13T09:11:59+0000",
            "content": "Doron, thank you very much for pushing forward this issue! I think your patch looks good, I'm still reviewing it in the light of 3.1 APIs. It's great that you added a new policy and test cases - this looks solid now.\n\nIn the meantime however I still doubt if the JIRA checkbox is a sufficient counterweight to a possibility of a patent infringement suit against users of Lucene... I think in cases like this, where there is a known existing patent that this implementation uses, the ASF requires an explicit software grant to be made (http://www.apache.org/licenses/software-grant.txt) which would protect Lucene users from infringing on IBM's IP. I'll forward this to legal@apache.org to see what they say about it - if you can obtain such a grant without too much trouble then I'm sure we could then close this issue. ",
            "author": "Andrzej Bialecki",
            "id": "comment-12898139"
        },
        {
            "date": "2010-08-13T15:29:29+0000",
            "content": "ASF legal thinks this is sufficient, so fortunately a software grant is not needed and from a legal point of view we can commit it. Yay! ",
            "author": "Andrzej Bialecki",
            "id": "comment-12898275"
        },
        {
            "date": "2010-08-13T16:02:50+0000",
            "content": "Great! ",
            "author": "Doron Cohen",
            "id": "comment-12898290"
        },
        {
            "date": "2010-08-23T15:20:48+0000",
            "content": "Renamed some of TermPruningPolicy methods for better readability - well, to me \n\nI agree, this looks clearer now.\n\nBug  in CarmelTermPruningPolicy in initTermPositions() - it sorts by docid before selecting the top subset, but in fact this seems dead code? Added a \"TODO deadcode\" there, maybe I am missing something.\n\nWell spotted, indeed this section was not needed.\n\nSimplified the if statements in PruningRedaer.PruningTermEnum.next() - hopefully not missing something t here...\n\nLooks good to me. Thanks!\n\nOkay, if there are no further comments I'd like to commit this soon. ",
            "author": "Andrzej Bialecki",
            "id": "comment-12901437"
        },
        {
            "date": "2010-12-27T18:29:31+0000",
            "content": "Hey,\nWhile trying to use this (wonderful!) component I noticed few things that might require some work:\n\n1. The issue says this affects lucene 2.9 as well, however the code seems to be hard-coded for 3.0 (uses the LUCENE_30 constant, as well as some new API's such as IndexWriterConfig).\n     I created a patch that'll make it work with 2.9.3 (so I can use it with a Solr 1.4.1 deployment), and I can post it as a patch if seems useful, but I suspect we might want to come up with a more generic solution as well\n     as clear definition of supported versions. Personally I think will be very useful to have a backport for 2.9.x so that users of current stable Solr release can use it (1.4.x)\n\n2. The code does not compile with the trunk (lucene/solr 4.0). Is this known issue? something we wish to solve? \n\n3. When using it with the 3.0 branch, it does indeed work, However when it reads an older version of the index and emits a newer one (e.g reads in 2.9.x, spits out 3.x) it renders the pruned index unusable by some platforms (e.g solr 1.4.x as mentioned above). Is this something that can be fixed? i.e forcing output index to be same version as input one? I was gonna do some work on my own there but this issue seems alittle more delicate and requires deeper understanding of lucene innards than i afford..\n\n-Chak\n ",
            "author": "Kaktu Chakarabati",
            "id": "comment-12975304"
        },
        {
            "date": "2010-12-27T23:33:22+0000",
            "content": "I plan to work on this for 3.x and trunk, did not notice that it was marked for 2.9, but can look at that as well. \nAndrej are you working on this or can I take it? \nAs for writing in 2.9 format I think it is better to backport to 2.9 rather than having the 3.x (or trunk) version write in 2.9 format?\nDoron ",
            "author": "Doron Cohen",
            "id": "comment-12975380"
        },
        {
            "date": "2011-01-03T14:20:37+0000",
            "content": "Doron, feel free to work on this - I won't be able to do any work on this in January. ",
            "author": "Andrzej Bialecki",
            "id": "comment-12976752"
        },
        {
            "date": "2011-06-03T16:40:46+0000",
            "content": "bulk move 3.2 -> 3.3 ",
            "author": "Robert Muir",
            "id": "comment-13043559"
        },
        {
            "date": "2011-08-29T08:29:06+0000",
            "content": "where can i download the codes about the pruning ,i can't found in \nhttps://svn.apache.org/repos/asf/lucene/dev/branches/branch_3x\n\nthanks ",
            "author": "luo",
            "id": "comment-13092696"
        },
        {
            "date": "2012-01-23T15:31:36+0000",
            "content": "Updated patch for current 3x. ",
            "author": "Doron Cohen",
            "id": "comment-13191205"
        },
        {
            "date": "2012-01-23T15:33:18+0000",
            "content": "Getting to this, at last. \n\nI did not handle the above TODO's and I rather commit so they can be handled later separately (\"progress not perfection\" as Mike says). \n\nChanges in this patch: \n\n\tPruningReader overrides also getSequentialSubReaders(), otherwise no pruning takes place on sub-readers (and tests fail).\n\tStorePruningPolicy fixed to use FieldInfos API.\n\n\n\nI modified for Idea and maven by following templates for other contrib components but have no way to test this and would appreciate a review of this. ",
            "author": "Doron Cohen",
            "id": "comment-13191206"
        },
        {
            "date": "2012-01-23T15:40:32+0000",
            "content": "I now see that all other contrib components have svn:ignore for *.iml and pom.xml - I'll add that for pruning as well (though it is not in the attached patch). ",
            "author": "Doron Cohen",
            "id": "comment-13191209"
        },
        {
            "date": "2012-01-23T15:42:22+0000",
            "content": "Hi Doron,\n\nI modified for Idea and maven by following templates for other contrib components but have no way to test this and would appreciate a review of this.\n\nI looked at these configurations and they should be functional.  I didn't test them, but I will once they have been committed. ",
            "author": "Steve Rowe",
            "id": "comment-13191211"
        },
        {
            "date": "2012-01-23T15:57:02+0000",
            "content": "I didn't test them, but I will once they have been committed.\n\nGreat, thanks!  ",
            "author": "Doron Cohen",
            "id": "comment-13191222"
        },
        {
            "date": "2012-01-24T12:53:35+0000",
            "content": "I ran 'javadocs' under 3x/lucene/contrib/pruning and 'javadocs-all' under 3x/lucene. \n\nThe latter failed due to multiple package.html under o.a.l.index - in core and under contrib/pruning. \n\nEntirely renaming the package to o.a.l.pruning.index won't work because PruningReader accesses package protected SegmentTermVector.\n\nI can move the other classes to that new package and keep only PruningReader in that \"index friend\" package. (Unless there are javadoc/ant tricks that will avoid this error and still generate valid javadocs in both cases). ",
            "author": "Doron Cohen",
            "id": "comment-13192101"
        },
        {
            "date": "2012-01-30T18:30:43+0000",
            "content": "Updated patch: package.html and all pruning classes moved to another package, except for PruningReader. Now ant javadocs-all passes as well. There are 3 TODO's:\n\n\timplement CarmelTermPruningDeltaTopPolicy\n\tdead code question in CarmelUniformTermPruningPolicy\n\tmissing details in package.html\n\n\n\nThe first one can wait but the other two I would like to handle before committing. ",
            "author": "Doron Cohen",
            "id": "comment-13196282"
        },
        {
            "date": "2012-01-30T19:20:22+0000",
            "content": "That dead code was removed and some javadocs added. \nStill room for more javadocs - e.g.  the static tool - and better test coverage.\nCommitted to 3x: r1237937. ",
            "author": "Doron Cohen",
            "id": "comment-13196339"
        },
        {
            "date": "2012-01-30T20:16:11+0000",
            "content": "Excellent, thanks for seeing this through! ",
            "author": "Andrzej Bialecki",
            "id": "comment-13196385"
        },
        {
            "date": "2012-01-30T21:23:40+0000",
            "content": "Excellent, thanks for seeing this through!\n\nYeah, only more than a year delay \n\nBTW in trunk it will be under modules. ",
            "author": "Doron Cohen",
            "id": "comment-13196429"
        },
        {
            "date": "2012-01-31T11:42:51+0000",
            "content": "while merging to trunk I noticed that idea's settings for modules/queries and modules/queryparser refer to lucene/contrib instead of modules. Seems trivial to fix but I have no Idea installed at the moment so no way to verify. Created LUCENE-3737 to handle that later. ",
            "author": "Doron Cohen",
            "id": "comment-13196845"
        },
        {
            "date": "2012-03-25T16:49:27+0000",
            "content": "This is really still open I think for the 4.x port.\n\nTo eliminate confusion: I'll mark this resolved and create a 4.0 issue to port pruning to trunk APIs. ",
            "author": "Robert Muir",
            "id": "comment-13237922"
        },
        {
            "date": "2012-03-25T16:51:31+0000",
            "content": "Marking this resolved: I created LUCENE-3917 for the 4.x port for JIRA organization purposes. ",
            "author": "Robert Muir",
            "id": "comment-13237923"
        }
    ]
}