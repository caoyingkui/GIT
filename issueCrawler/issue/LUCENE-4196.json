{
    "id": "LUCENE-4196",
    "title": "Turn asserts in I/O related code into hard checks",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [
            "core/index"
        ],
        "type": "Task",
        "fix_versions": [],
        "affect_versions": "4.0-ALPHA",
        "resolution": "Unresolved",
        "status": "Open"
    },
    "description": "In lots of codecs we only assert, that e.g. some things inside files are correctly in bounds, which leads to security problems (ok, not as bad as C-Style buffer overflows), but e.g. allocating a large array after reading a VInt from a file header and then OOM, is a security issue. So we have to check all those contracts for files as hard checks, especially as a simply check in most cases dont cost anything (and it costs not more than the assert itsself, as the assert also takes CPU power, because it needs a check one time on a static final class field).\nOf course we cannot check values we read when reading postings, but the simple checks that any postings file has correct header and something like a positive number of elements, or number of elements < file size,..., a bit-fireld only contains valid bits in StoredFieldsReader, or non-duplicate filenames (CFS) are very important. We had those checks in 3.x, but in 4.0, Mike changed all of those to asserts during the flex development (in my opinion with no real reason).",
    "attachments": {
        "LUCENE-4196.patch": "https://issues.apache.org/jira/secure/attachment/12543223/LUCENE-4196.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2012-07-05T15:03:40+0000",
            "content": "I agree, sometimes I added asserts that I feel should be real checks but I feel its safest to just do the assert.\n\nLucene3xNormsProducer:119 is an example. if it fails it means you have a corrumpt .nrm file with wrong norms mismatched\nfor different fields. ",
            "author": "Robert Muir",
            "id": "comment-13407194"
        },
        {
            "date": "2012-07-05T15:24:49+0000",
            "content": "That one is a good example of something we should watch out for, i think its ok because it uses IndexInput.length,\nbut we should make sure we don't directly turn asserts that use things like Directory.fileExists or Directory.fileLength into\nreal checks, it could cause problems for NFS (LUCENE-3727)\n ",
            "author": "Robert Muir",
            "id": "comment-13407207"
        },
        {
            "date": "2012-07-11T23:03:45+0000",
            "content": "bulk cleanup of 4.0-ALPHA / 4.0 Jira versioning. all bulk edited issues have hoss20120711-bulk-40-change in a comment ",
            "author": "Hoss Man",
            "id": "comment-13412303"
        },
        {
            "date": "2012-08-07T03:41:28+0000",
            "content": "rmuir20120906-bulk-40-change ",
            "author": "Robert Muir",
            "id": "comment-13429712"
        },
        {
            "date": "2012-08-31T03:34:53+0000",
            "content": "Hi Uwe... tricky issue.\n\nI think in general we were doing pretty good actually: often times various things like assert value >= 0 after a readVLong (well, thats ok to be an assert since readVLong does a real check anyways).\n\nBut I think we were missing a few key checks that cost nothing and would detect issues:\n\n\twhen reading things like #fields or #segments, check thats not negative. otherwise the loop does nothing and it acts like zero.\n\tthings like docCount in the .si really need to be checked they are positive: this file isn't checksummed (the information used to be in sis which is) and had basically no checks.\n\tcheck that we consume entire .si file just like we do with .fnm\n\tthe asserts for checking duplicate field names/numbers in FieldInfos and terms dicts were a good idea, but a real check for duplicate values is basically free anyway, since Map.put returns the previous value and its just a null check.\n\tstatistics are a wonderful cheap check in term dicts impls at startup...\n\n\n\nAnyway I think this is a good start. I'll wait for review but I'd like to commit this patch tomorrow. ",
            "author": "Robert Muir",
            "id": "comment-13445601"
        },
        {
            "date": "2012-08-31T03:44:32+0000",
            "content": "By the way: not to be done here, but maybe for something like 4.1Codec we should consider using ChecksumIndexInput/Output\nfor various tiny read-once files like .fnm/.si/.cfe etc? Seems like it wouldn't have a real cost and be worth the effort since\nwe are slurping these things in anyway. ",
            "author": "Robert Muir",
            "id": "comment-13445604"
        },
        {
            "date": "2012-08-31T05:04:00+0000",
            "content": "+1, that is exactly what I had in mind! The duplicate fields check is really cool, the return value of map is useful and is a simple check. Adding Exceptions to things reading on opening files is a must, as those can early detect corrupt segments and throw errors early. Especially as they cost nothing like the ones here. ",
            "author": "Uwe Schindler",
            "id": "comment-13445665"
        },
        {
            "date": "2012-09-10T17:43:16+0000",
            "content": "What do you think Uwe, can we resolve this? Of course we should always look out for this, but in general I think we are much better for 4.0 ",
            "author": "Robert Muir",
            "id": "comment-13452232"
        },
        {
            "date": "2012-09-11T10:09:15+0000",
            "content": "Hi Robert,\nI wanted to go through the codec code to check this myself. I just had no time to do it. E.g. things like the CompoundFileReader not using hard checks is one reason, why I want to go through it a second time. Whats the issue with keeping this issue open as a \"todo task\"? ",
            "author": "Uwe Schindler",
            "id": "comment-13452871"
        },
        {
            "date": "2012-09-11T10:19:08+0000",
            "content": "There is no issue except the \"fix version\" field: I'm just trying to get things with fixVersion=4.0 contained and assigned to people who\nare actually planning on working the issues in the next few days, or moved out of the release.\n\nIf there is really more work thats necessary before 4.0 and someone is planning on working on it, then I think it should have the fixVersion.\n\nBut if its just a \"future\" item that would be nice, then it should be moved out. ",
            "author": "Robert Muir",
            "id": "comment-13452876"
        },
        {
            "date": "2012-09-11T10:21:19+0000",
            "content": "Just remove the fix version alltogether. ",
            "author": "Uwe Schindler",
            "id": "comment-13452877"
        },
        {
            "date": "2013-03-22T16:43:27+0000",
            "content": "[branch_4x commit] Robert Muir\nhttp://svn.apache.org/viewvc?view=revision&revision=1381590\n\nLUCENE-4196: hard check not assert ",
            "author": "Commit Tag Bot",
            "id": "comment-13610906"
        }
    ]
}