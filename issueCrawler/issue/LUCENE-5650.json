{
    "id": "LUCENE-5650",
    "title": "Enforce read-only access to any path outside the temporary folder via security manager",
    "details": {
        "type": "Improvement",
        "priority": "Minor",
        "labels": "",
        "resolution": "Fixed",
        "components": [
            "general/test"
        ],
        "affect_versions": "None",
        "status": "Closed",
        "fix_versions": [
            "5.0",
            "6.0"
        ]
    },
    "description": "The recent refactoring to all the create temp file/dir functions (which is great!) has a minor regression from what existed before.  With the old LuceneTestCase.TEMP_DIR, the directory was created if it did not exist.  So, if you set java.io.tmpdir to \"./temp\", then it would create that dir within the per jvm working dir.  However, getBaseTempDirForClass() now does asserts that check the dir exists, is a dir, and is writeable.\n\nLucene uses \".\" as java.io.tmpdir.  Then in the test security manager, the per jvm cwd has read/write/execute permissions.  However, this allows tests to write to their cwd, which I'm trying to protect against (by setting cwd to read/execute in my test security manager).",
    "attachments": {
        "LUCENE-5650.patch": "https://issues.apache.org/jira/secure/attachment/12643833/LUCENE-5650.patch",
        "dih.patch": "https://issues.apache.org/jira/secure/attachment/12645807/dih.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "id": "comment-13991108",
            "author": "Dawid Weiss",
            "content": "Ryan, is this for a use case in Lucene/ Solr or in your own derived code? I'm trying to think how to best handle this. mkdirs() is obviously possible too, but trying to get the bigger picture first. ",
            "date": "2014-05-06T20:46:57+0000"
        },
        {
            "id": "comment-13991164",
            "author": "Robert Muir",
            "content": "Really this should be fixed here too (IMO).\n\nI tried to do this, but its currently hung on issues in a couple solr contribs: LUCENE-5154\n ",
            "date": "2014-05-06T21:33:02+0000"
        },
        {
            "id": "comment-13991167",
            "author": "Ryan Ernst",
            "content": "This is for my code using lucene/solr, in which I use the test framework. I agree with Robert it would be better to fix this in lucene as well (so tests cannot write to cwd). ",
            "date": "2014-05-06T21:35:32+0000"
        },
        {
            "id": "comment-13991172",
            "author": "Robert Muir",
            "content": "The main upside is it increases sandboxing: being lazy and letting tests read/write to CWD means you have a higher possibility of failures because tests \"interfere with each other\". When they make their own temp dirs this doesnt happen.\n\nBut, as soon as a logging framework gets in my way on something, i drop out. I just cant deal with them \n\nMaybe someone else can follow thru the final inch so we can ban this, or at least only allow it for the modules that aren't fixed. ",
            "date": "2014-05-06T21:39:59+0000"
        },
        {
            "id": "comment-13991682",
            "author": "Dawid Weiss",
            "content": "> I agree with Robert it would be better to fix this in lucene as well (so tests cannot write to cwd).\n\nIn Lucene and in Solr this bit is kind of taken care of because junit4 ANT task isolates cwds of each forked JVM. I agree though that tests shouldn't be allowed to write to cwd.\n\nWould you be able to provide a patch that would change the default behavior of getBaseTempDirForClass() to mkdirs() if it doesn't exists (and fail if the directory couldn't be created)? It would be also nice if you could provide a permission policy update; at least we'd see which tests are currently offenders. \n\nI've just returned from short holidays and I won't be able to look into it until the end of the week; trying to dig myself out of the stuff that piled up. ",
            "date": "2014-05-07T09:13:47+0000"
        },
        {
            "id": "comment-13992128",
            "author": "Ryan Ernst",
            "content": "Here's a patch with the mkdirs() and test policy changes.  Interestingly, hunspell tests all seem to fail.  They depend on java.io.tmpdir already existing.  I think this worked before in Robert's old patch because LuceneTestCase.TEMP_DIR was created in a static block, so before the tests actually ran.  Not sure what to do about that...can we initialize tempDirBase in a static block like before? ",
            "date": "2014-05-07T19:11:13+0000"
        },
        {
            "id": "comment-13992286",
            "author": "Ryan Ernst",
            "content": "I created LUCENE-5655 to address the hunspell/suggester issue with OfflineSorter. ",
            "date": "2014-05-07T22:06:37+0000"
        },
        {
            "id": "comment-13992348",
            "author": "Robert Muir",
            "content": "\nIn Lucene and in Solr this bit is kind of taken care of because junit4 ANT task isolates cwds of each forked JVM\n\nJust to clarify: I'm not talking about per-jvm sandboxing. I'm talking about sandboxing individual tests that run inside the same JVM from each other.\n\nIf they do I/O to \"shared places\" such as their per-JVM CWD (versus their own private per-test temporary directories), then its possible for them to interfere with each other. This can be quite difficult to debug. ",
            "date": "2014-05-07T23:17:53+0000"
        },
        {
            "id": "comment-13993902",
            "author": "Dawid Weiss",
            "content": "Hmm.. I stopped receiving jira updates for some reason \u2013 didn't see your replies, guys. Investigating. ",
            "date": "2014-05-09T20:49:32+0000"
        },
        {
            "id": "comment-13993921",
            "author": "Dawid Weiss",
            "content": "Uwe Schindler pointed me at the Apache blog wrt mail problems. Bad timing. \n\nAnyway, Ryan:\n\nLuceneTestCase.TEMP_DIR was created in a static block, so before the tests actually ran. Not sure what to do about that...can we initialize tempDirBase in a static block like before?\n\nDon't use static blocks in tests. Static blocks are executed during class loading and any code inside them is executed before the tests even commence. This effectively prevents any sandboxing/ checks the test runner attempts to provide. Also, it's not really predictable when these blocks will execute. The right way to execute one-time initialization in JUnit is via BeforeClass hooks or a class rule.\n\nThanks for the patch, it looks good to me. I'll do some testing and commit it in. Sorry about the delay. ",
            "date": "2014-05-09T21:14:32+0000"
        },
        {
            "id": "comment-13993990",
            "author": "Dawid Weiss",
            "content": "This is an adjustment to Ryan's patch. I moved a lot of the temp-file related code out of LuceneTestCase (leaving appropriate delegate calls to the rule code and its logic).\n\nA side-effect of this is that temp. dir gets created before any test code below the rule is executed. This helps hunspell tests. \n\nAll Lucene test pass. Solr's does have a few offenders still; haven't looked at them yet. ",
            "date": "2014-05-09T22:22:33+0000"
        },
        {
            "id": "comment-13993996",
            "author": "Dawid Weiss",
            "content": "I think this patch is great. Ran Solr tests and it clearly shows that there are things the tests shouldn't be doing.\n\n  2> 175732 T527 oasc.CoreContainer.recordAndThrow ERROR Unable to create core: collection1 org.apache.solr.common.SolrException: access denied (\"java.io.FilePermission\" \"C:\\Work\\lucene\\trunk\\solr\\example\\solr\\collection1\\data\\index\" \"write\")\n  2> \tat org.apache.solr.core.SolrCore.<init>(SolrCore.java:869)\n  2> \tat org.apache.solr.core.SolrCore.<init>(SolrCore.java:644)\n  2> \tat org.apache.solr.core.CoreContainer.create(CoreContainer.java:556)\n  2> \tat org.apache.solr.core.CoreContainer$1.call(CoreContainer.java:261)\n  2> \tat org.apache.solr.core.CoreContainer$1.call(CoreContainer.java:253)\n  2> \tat java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)\n  2> \tat java.util.concurrent.FutureTask.run(FutureTask.java:166)\n  2> \tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n  2> \tat java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)\n  2> \tat java.util.concurrent.FutureTask.run(FutureTask.java:166)\n  2> \tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)\n  2> \tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)\n  2> \tat java.lang.Thread.run(Thread.java:722)\n  2> Caused by: java.security.AccessControlException: access denied (\"java.io.FilePermission\" \"C:\\Work\\lucene\\trunk\\solr\\example\\solr\\collection1\\data\\index\" \"write\")\n  2> \tat java.security.AccessControlContext.checkPermission(AccessControlContext.java:366)\n  2> \tat java.security.AccessController.checkPermission(AccessController.java:555)\n  2> \tat java.lang.SecurityManager.checkPermission(SecurityManager.java:549)\n  2> \tat java.lang.SecurityManager.checkWrite(SecurityManager.java:979)\n  2> \tat java.io.File.mkdir(File.java:1237)\n  2> \tat java.io.File.mkdirs(File.java:1266)\n  2> \tat org.apache.lucene.store.NativeFSLock.obtain(NativeFSLockFactory.java:136)\n  2> \tat org.apache.lucene.store.MockLockFactoryWrapper$MockLock.obtain(MockLockFactoryWrapper.java:72)\n  2> \tat org.apache.lucene.store.Lock.obtain(Lock.java:77)\n  2> \tat org.apache.lucene.index.IndexWriter.<init>(IndexWriter.java:714)\n  2> \tat org.apache.solr.update.SolrIndexWriter.<init>(SolrIndexWriter.java:77)\n  2> \tat org.apache.solr.update.SolrIndexWriter.create(SolrIndexWriter.java:64)\n  2> \tat org.apache.solr.core.SolrCore.initIndex(SolrCore.java:521)\n  2> \tat org.apache.solr.core.SolrCore.<init>(SolrCore.java:775)\n  2> \t... 12 more\n\n ",
            "date": "2014-05-09T22:29:46+0000"
        },
        {
            "id": "comment-13994144",
            "author": "Ryan Ernst",
            "content": "I spun off SOLR-6055 for that particular issue.  I'm not exactly sure how to solve it (looks like a real bug). ",
            "date": "2014-05-10T05:14:28+0000"
        },
        {
            "id": "comment-13994331",
            "author": "Ryan Ernst",
            "content": "Thanks Dawid, your refactorings look good.\n\nThis patch adds fixes for the solr tests.  There is one nocommit for SOLR-6055. ",
            "date": "2014-05-10T23:42:59+0000"
        },
        {
            "id": "comment-13999521",
            "author": "Ryan Ernst",
            "content": "New patch. All tests pass.\n\nI fixed SOLR-6055 in this by adding a separate update log dir to SolrCore, which is independently forced to be absolute (for the local filesystem, not the DirectoryFactory).  I also made the javaTempDir in the new test rule always absolute so that the ulog isAbsolute check would work. ",
            "date": "2014-05-16T01:45:18+0000"
        },
        {
            "id": "comment-13999864",
            "author": "Dawid Weiss",
            "content": "Awesome, thanks Ryan! I'll rerun the tests in the evening and then commit. ",
            "date": "2014-05-16T14:58:50+0000"
        },
        {
            "id": "comment-14000208",
            "author": "Dawid Weiss",
            "content": "Hi Ryan. Just browsed through the patch. Is this commented out nocommit still applicable?\n\n+          // nocommit: this check needs to be fixed, see SOLR-6055\n+          //if (!new File(dataDir).isAbsolute()) {\n\n\nI'm running the tests now. ",
            "date": "2014-05-16T19:47:32+0000"
        },
        {
            "id": "comment-14000237",
            "author": "Dawid Weiss",
            "content": "I think your last patch was inconsistent \u2013 it didn't include the new rule, for example (only patched javaTempDir.getAbsoluteFile). \n\nI've tried to consolidate all of it and pushed it to a branch:\nhttps://svn.apache.org/repos/asf/lucene/dev/branches/lucene5650\n\nI'm running the tests right now. I still didn't know what to make of the nocommit \u2013 please fix it on the branch, add CHANGES entry and I think we're ready to go? ",
            "date": "2014-05-16T20:07:11+0000"
        },
        {
            "id": "comment-14000264",
            "author": "Dawid Weiss",
            "content": "org.apache.lucene.search.join.TestBlockJoin fails for me on the branch, but I think it's an unrelated issue (it also fails on trunk).\n\nI think I screwed up something when merging your patch though because Solr tests fail for me with access denied. Could you take a look at the branch and diff with your own code? ",
            "date": "2014-05-16T20:31:40+0000"
        },
        {
            "id": "comment-14000888",
            "author": "ASF subversion and git services",
            "content": "Commit 1595546 from Ryan Ernst in branch 'dev/branches/lucene5650'\n[ https://svn.apache.org/r1595546 ]\n\nLUCENE-5650: fix some solr tests ",
            "date": "2014-05-17T21:39:28+0000"
        },
        {
            "id": "comment-14000889",
            "author": "Ryan Ernst",
            "content": "Sorry about that.  The nocommit was left by mistake.  The failure was a goof on my part.  I've put a fix for it in the branch. ",
            "date": "2014-05-17T21:40:36+0000"
        },
        {
            "id": "comment-14000902",
            "author": "ASF subversion and git services",
            "content": "Commit 1595551 from Ryan Ernst in branch 'dev/branches/lucene5650'\n[ https://svn.apache.org/r1595551 ]\n\nLUCENE-5650: fix one more solr test ",
            "date": "2014-05-17T22:16:04+0000"
        },
        {
            "id": "comment-14000997",
            "author": "ASF subversion and git services",
            "content": "Commit 1595562 from Ryan Ernst in branch 'dev/branches/lucene5650'\n[ https://svn.apache.org/r1595562 ]\n\nLUCENE-5650: fix solrj test ",
            "date": "2014-05-18T05:04:00+0000"
        },
        {
            "id": "comment-14001202",
            "author": "Dawid Weiss",
            "content": "Are you sure you don't have any exclusion properties in your default setup? Because I still see a number of failures. I just fixed two tests in map-reduce, but there's a number of other failures left:\n\n[22:26:32.432] ERROR   0.00s J3 | TestICUCollationFieldOptions (suite) <<<\n   > Throwable #1: org.apache.solr.common.SolrException: SolrCore 'collection1' is not available due to init failure: access denied (\"java.io.FilePermission\" \"analysis-extras\\solr\\collection1\\conf\" \"write\")\n\n[22:26:32.459] ERROR   0.00s J2 | TestFoldingMultitermExtrasQuery (suite) <<<\n   > Throwable #1: org.apache.solr.common.SolrException: SolrCore 'collection1' is not available due to init failure: access denied (\"java.io.FilePermission\" \"analysis-extras\\solr\\collection1\\conf\" \"write\")\n\n[22:26:48.767] ERROR   0.00s J1 | CarrotClusteringEngineTest (suite) <<<\n   > Throwable #1: org.apache.solr.common.SolrException: SolrCore 'collection1' is not available due to init failure: access denied (\"java.io.FilePermission\" \"clustering\\solr\\collection1\\conf\" \"write\")\n\n[22:27:52.483] FAILURE 0.04s | TestDocBuilder.testDeltaImportNoRows_MustNotCommit <<<\n(caused by, in the logs)\n  2> Caused by: java.security.AccessControlException: access denied (\"java.io.FilePermission\" \".\\dataimport.properties\" \"write\")\n\n[22:31:24.108] ERROR   0.36s | VelocityResponseWriterTest.testSolrResourceLoaderTemplate <<<\n   > Throwable #1: java.lang.RuntimeException: org.apache.velocity.exception.VelocityException: Error initializing log: Failed to initialize an instance of org.apache.velocity.runtime.log.Log4JLogChute with the current runtime configuration.\n...\n   > Caused by: java.security.AccessControlException: access denied (\"java.io.FilePermission\" \"velocity.log\" \"write\")\n[22:26:07.003] ERROR   0.05s J0 | TestLBHttpSolrServer.testReliability <<<\n   > Throwable #1: java.security.AccessControlException: access denied (\"java.io.FilePermission\" \"org.apache.solr.client.solrj.TestLBHttpSolrServer$SolrInstance-1400444767005\\solr\\collection10\" \"write\")\n\n\n\nThese are the few I quickly noticed. Did they pass for you? My master seed was 324BDB00052353EE\n ",
            "date": "2014-05-18T20:49:46+0000"
        },
        {
            "id": "comment-14001362",
            "author": "Ryan Ernst",
            "content": "These are the few I quickly noticed. Did they pass for you?\n\nI have now realized I've been running these tests all wrong. I had one unrelated failure in my run, which I did not realize would stop other tests from running.  I've now run with -Dtests.haltonfailure=false (thanks for the tip) and I see all these failures. ",
            "date": "2014-05-19T03:50:26+0000"
        },
        {
            "id": "comment-14001447",
            "author": "Dawid Weiss",
            "content": "No problem. I'll be polishing my Buzzwords presentation today, but once I'm done I'll try to take a look at these too. There seems to be a common underlying cause (logger sinks, test collection) so hopefully it's not as bad as the count of errors suggests.\n\nStill, I think it's a really valuable improvement and worth persuing. ",
            "date": "2014-05-19T07:23:25+0000"
        },
        {
            "id": "comment-14002557",
            "author": "ASF subversion and git services",
            "content": "Commit 1596094 from Ryan Ernst in branch 'dev/branches/lucene5650'\n[ https://svn.apache.org/r1596094 ]\n\nLUCENE-5650: fix more contrib tests ",
            "date": "2014-05-19T23:11:48+0000"
        },
        {
            "id": "comment-14002559",
            "author": "Ryan Ernst",
            "content": "Ok I fixed a bunch more contrib tests.  There are still failures for DIH and velocity (same ones that Robert noted in LUCENE-5154). ",
            "date": "2014-05-19T23:13:40+0000"
        },
        {
            "id": "comment-14003071",
            "author": "Dawid Weiss",
            "content": "I handled some of the velocity and DIH. Running the tests now. ",
            "date": "2014-05-20T10:49:33+0000"
        },
        {
            "id": "comment-14003441",
            "author": "Ryan Ernst",
            "content": "Looks like we overlapped on fixing these.  I like how you handle velocity better than me (I hacked through a way to set the log file).  But I'm not sure I like the DIH change.  I think it is bogus to default to the CWD if running without a core (which seems to only happen in tests?).  I changed this to default to solr.solr.home, then set this to a temp dir in the abstract DIH test base (see attached patch). ",
            "date": "2014-05-20T15:28:33+0000"
        },
        {
            "id": "comment-14004367",
            "author": "Dawid Weiss",
            "content": "Commit it to the branch, Ryan. I fixed it the way I understand how Solr's source code works (which is to say: vaguely familiar). I'm sure your patch is better.\n\nThe build yesterday ended with this failure related to perm. denied:\n\n[13:07:35.284] ERROR   0.00s J1 | TestFoldingMultitermExtrasQuery (suite) <<<    \n> Throwable #1: org.apache.solr.common.SolrException: SolrCore 'collection1' is not available due to init failure: access denied (\"java.io.FilePermission\" \"analysis-extras\\solr\\collection1\\conf\" \"write\")\n\n\n\nand the following, I guess notorious offenders:\n\n  - org.apache.solr.spelling.suggest.TestAnalyzeInfixSuggestions (could not remove temp. files)\n  - TestBlendedInfixSuggestions (same thing)\n\n  - org.apache.solr.cloud.SyncSliceTest.testDistribSearch\n   > Throwable #1: org.apache.solr.client.solrj.SolrServerException: No live SolrServers available to handle this request\n\n  - org.apache.solr.cloud.RecoveryZkTest.testDistribSearch \n   > Throwable #1: java.lang.AssertionError: shard1 is not consistent.  Got 92 from https://127.0.0.1:54379/_koq/fr/collection1lastClient and got 60 from https://127.0.0.1:54410/_koq/fr/collection1\n\n\n\nI won't be able to return to this today (maybe in the evening). Change my DIH fixes to yours on the branch \u2013 I don't mind at all. ",
            "date": "2014-05-21T05:23:27+0000"
        },
        {
            "id": "comment-14004368",
            "author": "Dawid Weiss",
            "content": "One comment wrt the dih patch:\n\n+    System.clearProperty(\"solr.solr.home\");\n\n\nI think there is a restore-sys-props rule somewhere in the upper class that will take care of this. In Lucene there is no such rule, but in Solr so many properties get set (even from other software packages) that it didn't make sense to track them all manually. You'd have to check though, I may be wrong.\n\n ",
            "date": "2014-05-21T05:27:05+0000"
        },
        {
            "id": "comment-14004372",
            "author": "ASF subversion and git services",
            "content": "Commit 1596472 from Dawid Weiss in branch 'dev/branches/lucene5650'\n[ https://svn.apache.org/r1596472 ]\n\nLUCENE-5650: applying Ryan's DIH patch. ",
            "date": "2014-05-21T05:37:49+0000"
        },
        {
            "id": "comment-14004378",
            "author": "ASF subversion and git services",
            "content": "Commit 1596475 from Dawid Weiss in branch 'dev/branches/lucene5650'\n[ https://svn.apache.org/r1596475 ]\n\nLUCENE-5650: fixed solr home to rw access by copying ",
            "date": "2014-05-21T05:45:59+0000"
        },
        {
            "id": "comment-14004436",
            "author": "ASF subversion and git services",
            "content": "Commit 1596497 from Dawid Weiss in branch 'dev/branches/lucene5650'\n[ https://svn.apache.org/r1596497 ]\n\nSOLR-6100, LUCENE-5650: fix an uncloseable file leak in solr suggesters. ",
            "date": "2014-05-21T07:21:37+0000"
        },
        {
            "id": "comment-14004515",
            "author": "Dawid Weiss",
            "content": "All tests passed for me with the current state of the branch (including nightlies). ",
            "date": "2014-05-21T09:11:27+0000"
        },
        {
            "id": "comment-14004911",
            "author": "Ryan Ernst",
            "content": "+1, everything looks good to me (and test pass for me as well). ",
            "date": "2014-05-21T17:01:30+0000"
        },
        {
            "id": "comment-14005092",
            "author": "Dawid Weiss",
            "content": "Please commit it to trunk, Ryan! I'll be at work in ~9hours so should something pop up in jenkins runs I'll take care of these. ",
            "date": "2014-05-21T18:56:01+0000"
        },
        {
            "id": "comment-14005649",
            "author": "Dawid Weiss",
            "content": "I'm merging with the trunk right now. Will commit in a moment. ",
            "date": "2014-05-22T06:07:49+0000"
        },
        {
            "id": "comment-14005651",
            "author": "ASF subversion and git services",
            "content": "Commit 1596767 from Dawid Weiss in branch 'dev/trunk'\n[ https://svn.apache.org/r1596767 ]\n\nLUCENE-5650: Enforce read-only access to any path outside the temporary folder via security manager ",
            "date": "2014-05-22T06:15:28+0000"
        },
        {
            "id": "comment-14005653",
            "author": "Dawid Weiss",
            "content": "I've committed this patch to trunk. Let it bake a bit before backporting to 4x. I've made a few cosmetic changes while merging so if backporting, use commit changeset 1596767 from trunk. ",
            "date": "2014-05-22T06:17:35+0000"
        },
        {
            "id": "comment-14016976",
            "author": "Steve Rowe",
            "content": "I'm seeing what look like security manager-related exceptions on trunk with o.a.s.search.TestRecoveryHdfs on OS X 10.9.3 w/Oracle Java 1.7.0_55 - here's the first exception (9 out of 9 non-ignored tests fail):\n\n\n   [junit4] <JUnit4> says \u4f60\u597d! Master seed: 37AA21AA8F6886DF\n   [junit4] Executing 1 suite with 1 JVM.\n   [junit4] \n   [junit4] Started J0 PID(36452@smb.local).\n   [junit4] Suite: org.apache.solr.search.TestRecoveryHdfs\n[...]\n   [junit4]   2> 7871 T118 oasc.CoreContainer.recordAndThrow ERROR Unable to create core: collection1 org.apache.solr.common.SolrException: Problem creating directory: solr_hdfs_home/collection1/Users/sarowe/svn/lucene/dev/trunk4/solr/build/solr-core/test/J0/temp/solr.search.TestRecoveryHdfs-37AA21AA8F6886DF-001/init-core-data-001\n   [junit4]   2> \tat org.apache.solr.core.SolrCore.<init>(SolrCore.java:885)\n   [junit4]   2> \tat org.apache.solr.core.SolrCore.<init>(SolrCore.java:649)\n   [junit4]   2> \tat org.apache.solr.core.CoreContainer.create(CoreContainer.java:556)\n   [junit4]   2> \tat org.apache.solr.core.CoreContainer$1.call(CoreContainer.java:261)\n   [junit4]   2> \tat org.apache.solr.core.CoreContainer$1.call(CoreContainer.java:253)\n   [junit4]   2> \tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n   [junit4]   2> \tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n   [junit4]   2> \tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n   [junit4]   2> \tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n   [junit4]   2> \tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n   [junit4]   2> \tat java.lang.Thread.run(Thread.java:745)\n   [junit4]   2> Caused by: java.lang.RuntimeException: Problem creating directory: solr_hdfs_home/collection1/Users/sarowe/svn/lucene/dev/trunk4/solr/build/solr-core/test/J0/temp/solr.search.TestRecoveryHdfs-37AA21AA8F6886DF-001/init-core-data-001\n   [junit4]   2> \tat org.apache.solr.store.hdfs.HdfsDirectory.<init>(HdfsDirectory.java:87)\n   [junit4]   2> \tat org.apache.solr.core.HdfsDirectoryFactory.create(HdfsDirectoryFactory.java:148)\n   [junit4]   2> \tat org.apache.solr.core.CachingDirectoryFactory.get(CachingDirectoryFactory.java:351)\n   [junit4]   2> \tat org.apache.solr.core.SolrCore.getNewIndexDir(SolrCore.java:273)\n   [junit4]   2> \tat org.apache.solr.core.SolrCore.initIndex(SolrCore.java:485)\n   [junit4]   2> \tat org.apache.solr.core.SolrCore.<init>(SolrCore.java:791)\n   [junit4]   2> \t... 10 more\n   [junit4]   2> Caused by: java.security.AccessControlException: access denied (\"java.io.FilePermission\" \"/Users/sarowe/svn/lucene/dev/trunk4/solr/build/solr-core/test/J0\" \"write\")\n   [junit4]   2> \tat java.security.AccessControlContext.checkPermission(AccessControlContext.java:372)\n   [junit4]   2> \tat java.security.AccessController.checkPermission(AccessController.java:559)\n   [junit4]   2> \tat java.lang.SecurityManager.checkPermission(SecurityManager.java:549)\n   [junit4]   2> \tat java.lang.SecurityManager.checkWrite(SecurityManager.java:979)\n   [junit4]   2> \tat java.io.File.mkdir(File.java:1305)\n   [junit4]   2> \tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:427)\n   [junit4]   2> \tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:427)\n   [junit4]   2> \tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:427)\n   [junit4]   2> \tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:427)\n   [junit4]   2> \tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:427)\n   [junit4]   2> \tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:427)\n   [junit4]   2> \tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:427)\n   [junit4]   2> \tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:427)\n   [junit4]   2> \tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:427)\n   [junit4]   2> \tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:427)\n   [junit4]   2> \tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:427)\n   [junit4]   2> \tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:427)\n   [junit4]   2> \tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:427)\n   [junit4]   2> \tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:427)\n   [junit4]   2> \tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:427)\n   [junit4]   2> \tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:427)\n   [junit4]   2> \tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:427)\n   [junit4]   2> \tat org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:584)\n   [junit4]   2> \tat org.apache.solr.store.hdfs.HdfsDirectory.<init>(HdfsDirectory.java:63)\n   [junit4]   2> \t... 15 more\n   [junit4]\n[...] \n   [junit4] Tests with failures:\n   [junit4]   - org.apache.solr.search.TestRecoveryHdfs.testLogReplay\n   [junit4]   - org.apache.solr.search.TestRecoveryHdfs.testRemoveOldLogs\n   [junit4]   - org.apache.solr.search.TestRecoveryHdfs.testBufferingFlags\n   [junit4]   - org.apache.solr.search.TestRecoveryHdfs.testCleanShutdown\n   [junit4]   - org.apache.solr.search.TestRecoveryHdfs.testCorruptLog\n   [junit4]   - org.apache.solr.search.TestRecoveryHdfs.testVersionsOnRestart\n   [junit4]   - org.apache.solr.search.TestRecoveryHdfs.testRecoveryMultipleLogs\n   [junit4]   - org.apache.solr.search.TestRecoveryHdfs.testTruncatedLog\n   [junit4]   - org.apache.solr.search.TestRecoveryHdfs.testBuffering\n\n ",
            "date": "2014-06-03T18:46:51+0000"
        },
        {
            "id": "comment-14017051",
            "author": "Dawid Weiss",
            "content": "This looks like a screwup in Hadoop because it attempts to create all parent folders, including those it has no access to (and which MUST already exist at that time):\n\nCaused by: java.security.AccessControlException: access denied (\"java.io.FilePermission\" \"/Users/sarowe/svn/lucene/dev/trunk4/solr/build/solr-core/test/J0\" \"write\")\n   [junit4]   2> \tat java.security.AccessControlContext.checkPermission(AccessControlContext.java:372)\n   [junit4]   2> \tat java.security.AccessController.checkPermission(AccessController.java:559)\n   [junit4]   2> \tat java.lang.SecurityManager.checkPermission(SecurityManager.java:549)\n   [junit4]   2> \tat java.lang.SecurityManager.checkWrite(SecurityManager.java:979)\n   [junit4]   2> \tat java.io.File.mkdir(File.java:1305)\n   [junit4]   2> \tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:427)\n...\n\n\n\nHere is what this routine looks like:\n\n  /**\n   * Creates the specified directory hierarchy. Does not\n   * treat existence as an error.\n   */\n  @Override\n  public boolean mkdirs(Path f) throws IOException {\n    if(f == null) {\n      throw new IllegalArgumentException(\"mkdirs path arg is null\");\n    }\n    Path parent = f.getParent();\n    File p2f = pathToFile(f);\n    if(parent != null) {\n      File parent2f = pathToFile(parent);\n      if(parent2f != null && parent2f.exists() && !parent2f.isDirectory()) {\n        throw new FileAlreadyExistsException(\"Parent path is not a directory: \" \n            + parent);\n      }\n    }\n    return (parent == null || mkdirs(parent)) &&\n      (p2f.mkdir() || p2f.isDirectory());\n  }\n\n\n\nI think this is an error in Hadoop \u2013 they always mkdirs() on parent folders, even if they exist. ",
            "date": "2014-06-03T19:48:00+0000"
        },
        {
            "id": "comment-14017206",
            "author": "Steve Rowe",
            "content": "Yeah, that does look dumb.  And pathToFile() absolutizes relative directories against the CWD, so using a relative dir won't help.\n\nI found a solution that allows all the tests to succeed on my box, though I admit it's totally cargo-culted from o.a.s.cloud.hdfs.StressHdfsTest:\n\n\nIndex: solr/core/src/test/org/apache/solr/search/TestRecoveryHdfs.java\n===================================================================\n--- solr/core/src/test/org/apache/solr/search/TestRecoveryHdfs.java\t(revision 1599731)\n+++ solr/core/src/test/org/apache/solr/search/TestRecoveryHdfs.java\t(working copy)\n@@ -78,6 +78,7 @@\n   @BeforeClass\n   public static void beforeClass() throws Exception {\n     dfsCluster = HdfsTestUtil.setupClass(createTempDir().getAbsolutePath());\n+    System.setProperty(\"solr.hdfs.home\", dfsCluster.getURI().toString() + \"/solr\");\n     hdfsUri = dfsCluster.getFileSystem().getUri().toString();\n     \n     try {\n\n\n\nAny objections to committing this? Mark Miller? ",
            "date": "2014-06-03T22:10:45+0000"
        },
        {
            "id": "comment-14017222",
            "author": "Mark Miller",
            "content": "That looks like a workaround for a test bug JIRA I opened a whe back. On my phone so hard to dig. Hdfs.home was being set to local fs rather than an hdfs location.  Looks like your setting it correct after the above line sets it incorrectly to local fs. \n\nIf that's the case, that fix actually belongs in the hdfs util call right above - instead of where it incorrectly sets the solr.hdfs.home. But feel free to just use your patch if you want and I'll clean it up when I resolve that issue.  ",
            "date": "2014-06-03T22:24:58+0000"
        },
        {
            "id": "comment-14017787",
            "author": "Steve Rowe",
            "content": "But feel free to just use your patch if you want and I'll clean it up when I resolve that issue.\n\nThanks, I'll do that. ",
            "date": "2014-06-04T15:47:36+0000"
        },
        {
            "id": "comment-14017788",
            "author": "ASF subversion and git services",
            "content": "Commit 1600310 from Steve Rowe in branch 'dev/trunk'\n[ https://svn.apache.org/r1600310 ]\n\nLUCENE-5650: Reset solr.hdfs.home correctly to allow TestRecoveryHdfs tests to pass ",
            "date": "2014-06-04T15:49:06+0000"
        },
        {
            "id": "comment-14107604",
            "author": "Hoss Man",
            "content": "Back in may Dawid Weiss mentioned letting this soak on trunk a bit before backporting ... did it slip through the cracks?\n\nFWIW: SOLR-6410 popped up on 4x but was already fixed on trunk as part of this issue, i'm going to backport just the key elements of this issue that related to that bug to 4x under the banner of SOLR-6410 in order to backport to branch_4_10 as well. ",
            "date": "2014-08-22T22:20:14+0000"
        },
        {
            "id": "comment-14107625",
            "author": "ASF subversion and git services",
            "content": "Commit 1619947 from hossman@apache.org in branch 'dev/branches/branch_4x'\n[ https://svn.apache.org/r1619947 ]\n\nSOLR-6410: Ensure all Lookup instances are closed via CloseHook (merge r1596767 from LUCENE-5650 just for the solr/spelling/suggest paths; and merge r1619946 for the CHANGES.txt entry) ",
            "date": "2014-08-22T22:37:37+0000"
        },
        {
            "id": "comment-14108059",
            "author": "ASF subversion and git services",
            "content": "Commit 1620054 from Ryan Ernst in branch 'dev/branches/branch_4x'\n[ https://svn.apache.org/r1620054 ]\n\nLUCENE-5650: Enforce read-only access to any path outside the temporary folder via security manager (merged r1596767, r1600310) ",
            "date": "2014-08-23T17:22:37+0000"
        },
        {
            "id": "comment-14108060",
            "author": "ASF subversion and git services",
            "content": "Commit 1620055 from Ryan Ernst in branch 'dev/branches/branch_4x'\n[ https://svn.apache.org/r1620055 ]\n\nLUCENE-5650: Enforce read-only access to any path outside the temporary folder via security manager (merged r1596767, r1600310) ",
            "date": "2014-08-23T17:22:58+0000"
        },
        {
            "id": "comment-14108062",
            "author": "ASF subversion and git services",
            "content": "Commit 1620056 from Ryan Ernst in branch 'dev/trunk'\n[ https://svn.apache.org/r1620056 ]\n\nLUCENE-5650: Move changes entry to reflect backport to 4x ",
            "date": "2014-08-23T17:25:58+0000"
        },
        {
            "id": "comment-14108063",
            "author": "ASF subversion and git services",
            "content": "Commit 1620057 from Ryan Ernst in branch 'dev/branches/branch_4x'\n[ https://svn.apache.org/r1620057 ]\n\nLUCENE-5650: Move changes entry to reflect backport to 4x ",
            "date": "2014-08-23T17:27:19+0000"
        },
        {
            "id": "comment-14108590",
            "author": "Dawid Weiss",
            "content": "Thank you for doing the backport, Ryan! ",
            "date": "2014-08-24T21:13:50+0000"
        },
        {
            "id": "comment-14332664",
            "author": "Anshum Gupta",
            "content": "Bulk close after 5.0 release. ",
            "date": "2015-02-23T05:01:13+0000"
        }
    ]
}