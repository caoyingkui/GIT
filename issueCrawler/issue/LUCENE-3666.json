{
    "id": "LUCENE-3666",
    "title": "Update org.apache.lucene.analysis package summary",
    "details": {
        "labels": "",
        "priority": "Minor",
        "components": [
            "general/javadocs"
        ],
        "type": "Improvement",
        "fix_versions": [
            "3.6",
            "4.0-ALPHA"
        ],
        "affect_versions": "3.5",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "package.html in lucene/src/java/org/apache/lucene/analysis/ is out of date.\n\nIt looks like the contents of the branch_3x version haven't changed substantially since the Lucene 2.9 release, e.g. it refers to TermAttribute instead of CharTermAttribute.\n\nThe trunk version is more modern - it refers to CharTermAttribute - but it also has some issues.  E.g., I can see that the LengthFilter discussion doesn't refer to FilteringTokenFilter.",
    "attachments": {
        "LUCENE-3666-trunk.patch": "https://issues.apache.org/jira/secure/attachment/12508604/LUCENE-3666-trunk.patch",
        "LUCENE-3666-branch_3x.patch": "https://issues.apache.org/jira/secure/attachment/12508578/LUCENE-3666-branch_3x.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2011-12-23T23:10:24+0000",
            "content": "Patch for branch_3x.\n\nChanges:\n\n\n\tAdded CharStream/-Filter to analysis components discussion\n\tTermAttribute -> CharTermAttribute\n\tAdded KeywordAttribute to the list of out-of-the-box attributes\n\tVersion parameter added to analysis component c-tors.\n\tCustom MyAnalyzer extends ReusableAnalyzerBase\n\tAdded @Override annotation to overridden methods\n\tLengthFilter extends FilteringTokenFilter\n\n ",
            "author": "Steve Rowe",
            "id": "comment-13175616"
        },
        {
            "date": "2011-12-24T22:20:44+0000",
            "content": "Updated branch_3x patch to remove javadocs warnings about @Override and @Deprecated annotatations in sample code by wrapping with \n{@literal ...} ",
            "author": "Steve Rowe",
            "id": "comment-13175778"
        },
        {
            "date": "2011-12-25T04:53:26+0000",
            "content": "minor fixes to the branch_3x patch ",
            "author": "Steve Rowe",
            "id": "comment-13175802"
        },
        {
            "date": "2011-12-25T04:54:19+0000",
            "content": "Trunk patch. ",
            "author": "Steve Rowe",
            "id": "comment-13175803"
        },
        {
            "date": "2011-12-25T04:55:33+0000",
            "content": "I think this is ready to commit.\n\nI'll wait a few days before committing, though, to give people a chance to review. ",
            "author": "Steve Rowe",
            "id": "comment-13175804"
        },
        {
            "date": "2012-01-17T22:56:59+0000",
            "content": "Here my commets as posted on IRC:\n\n22:38\tThetaPh1\t+ A CharStream adds character offset correction functionality over\n22:38\tThetaPh1\t+ \n{@link java.io.Reader}\n. All Tokenizers accept a CharStream instead of\n22:38\tThetaPh1\t+ Reader as input, which enables arbitrary character based filtering\n22:38\tThetaPh1\t+ before tokenization.\n22:39\tThetaPh1\tah charfilters are also there\n22:39\tThetaPh1\tbecause that description is a little bit limited, charstreams on itsself are never used\n22:40\tsarowe\tright\n22:40\tThetaPh1\tbut there is missing some general information what CharFilters do, at least I dont see it in the patch\n22:40\tThetaPh1\tthe reader simply say: wtf is this charstream good for?\n22:40\tsarowe\tgood point\n22:40\tsarowe\tI'll revisit\n22:41\tThetaPh1\tin the following para i would replace CharStream by CharFilter\n22:41\tsarowe\t(I know more about CharFilter guts after working on HTMLStripCharFilter replacement)\n22:41\tThetaPh1\tthe input is in all cases a Reader\n22:41\tThetaPh1\thehe yes\n22:41\tThetaPh1\tin my opinion the charfilters are horrible by the design\n22:41\tThetaPh1\twe changed it shortly before 2.9 to fix some very bad behaviour\n22:41\tsarowe\tright, I recall that - performance fixes\n22:41\tThetaPh1\tbut its still hard to understand whats going on\n22:42\tsarowe\tyes, and no docs\n22:42\tThetaPh1\tthe problem is that they wrap Readers\n22:42\tThetaPh1\tand instanceof checks in Tokenizer and so on\n22:42\tsarowe\tI've added a little more docs in the JFlexHTMLStripCharFilter issue\n22:42\tThetaPh1\tto prevent those instanceof checks everywhere in code, Tokenizer has a correctOffset method, right?\n22:43\tsarowe\tok, I know about the method, didn't know that was why it was there\n22:43\tThetaPh1\t+ <b>Lucene 2.9 introduced a new TokenStream API. Please see the section \"New TokenStream API\" below for more details.</b>\n22:43\tThetaPh1\twe should chnage the second sentence, there is no old api anymore\n22:43\tsarowe\tright\n22:44\tsarowe\tin trunk, anyway\n22:45\tThetaPh1\tin 3.x, the same\n22:45\tThetaPh1\tand remove \"new\"\n22:45\tThetaPh1\tthe example with LengthFilter is good\n22:45\tsarowe\tcool\n22:45\tThetaPh1\tas it shows as example how its implemented (for filtering tokens based on accept())\n22:46\tThetaPh1\tbut also how a conventional filter would look like\n22:46\tsarowe\tright\n22:47\tThetaPh1\tequals and hascode no longer need to be implemented\n22:47\tThetaPh1\tits no longer required\n22:47\tsarowe\tok\n22:48\tThetaPh1\t+ \n{@literal @Override}\n22:48\tThetaPh1\tpublic void copyTo(AttributeImpl target) \n{\n22:48\tThetaPh1\t((PartOfSpeechAttributeImpl) target).pos = pos;\n22:48\tThetaPh1\t}\n22:48\tThetaPh1\tthis one shpoudl not cast to *Impl\n22:48\tThetaPh1\tit should simply cast to the interface\n22:48\tsarowe\tok\n22:48\tThetaPh1\tits done like this in all attributes in lucene, maybe we missed that one in docs\n22:49\tsarowe\tI'll check\n22:49\tThetaPh1\tthe idea is that e.g. a CharTermAttribute can be copied to a good old Token (die,die,die)\n22:49\tThetaPh1\tso the copy operation should not rely on the type\n22:49\tThetaPh1\ti mean impl\n22:49\tsarowe\tright, the interface instead\n22:50\tThetaPh1\t((PartOfSpeechAttributeImpl) target).setPos(pos);\n22:50\tThetaPh1\tsomething like that\n22:50\tThetaPh1\ta without impl\n22:50\tsarowe\t right\n22:50\tThetaPh1\t((PartOfSpeechAttribute) target).setPos(pos);\n22:50\tsarowe\tok\n22:50\tThetaPh1\tattributes also no longer need to impl toString(), but thats not in the example\n22:51\tThetaPh1\tthey can implement reflectWith for nice debugging output in solr\n22:51\tThetaPh1\tbut thats too much information\n22:51\tsarowe\t\n22:51\tThetaPh1\tjust remove the hashcode/equals and toString if they are in exaple\n22:51\tThetaPh1\ta minimum example would be ideal\n22:51\tsarowe\tok\n22:52\tThetaPh1\t+<code>AttributeImpl</code> class and therefore implements its abstract methods <code>clear(), copyTo(), equals(), hashCode()</code>.\n22:52\tThetaPh1\tnot sure how this is solved in 3.x\n22:52\tThetaPh1\tin trunk they are gone\n22:52\tThetaPh1\t(have to look up)\n22:52\tsarowe\tok\n22:52\tThetaPh1\ti only know that in 3.x most attributes that existed before simply implement equals/hashcode\n22:52\tThetaPh1\tbut just for backwards reasons\n22:53\tsarowe\tok\n22:53\tThetaPh1\tone thing\n22:54\tThetaPh1\tyou should note for CharTermAttribute that it implemens CharSequence and Appendable\n22:54\tThetaPh1\ti had a code review before\n22:54\tThetaPh1\tand have seen stupidness like calling toString() useless\n22:54\tsarowe\tright\n22:54\tThetaPh1\ti have seen people doing termAtt.toString().length() < 10 in a lengthfilter-like fileter\n22:54\tsarowe\tthat's the main reason for CharTermAttr to replace TermAttr, I believe\n22:55\tThetaPh1\tyes\n22:55\tThetaPh1\totherwise I see nothing wrong\n22:55\tsarowe\tcool, thanks for the review ",
            "author": "Uwe Schindler",
            "id": "comment-13188103"
        },
        {
            "date": "2012-01-18T14:36:06+0000",
            "content": "Patches incorporating Uwe's suggested changes.\n\nCommitting shortly. ",
            "author": "Steve Rowe",
            "id": "comment-13188474"
        },
        {
            "date": "2012-01-18T14:37:40+0000",
            "content": "Committed to branch_3x and trunk. ",
            "author": "Steve Rowe",
            "id": "comment-13188475"
        },
        {
            "date": "2012-01-18T15:16:05+0000",
            "content": "oh small changes needed:\n\nThis example consumer code is incomplete:\n\n\n+<PRE class=\"prettyprint\">\n+    Analyzer analyzer = new StandardAnalyzer(Version.LUCENE_XY); // or any other analyzer\n+    TokenStream ts = analyzer.tokenStream(\"myfield\",new StringReader(\"some text goes here\"));\n+    while (ts.incrementToken()) {\n+      System.out.println(\"token: \"+ts));\n+    }\n+</PRE>\n\n\n\n\n\tTokenStream needs to call reset() before incrementing tokens (thats the contract)\n\tIt should call end() after incrementToken()\n\tIt must call close finally (ideally in try/finally)\n\n\n\nFinally TokenStream no longer is required to implement toString(), so this one may produce useless standard toString() output (in 4.0 it does print TokenStreamClass@hashcode, in 3.x for backwards compatibility it prints the same like reflectAsString).\n\nTo get Token debug outbut, use http://lucene.apache.org/java/3_5_0/api/core/org/apache/lucene/util/AttributeSource.html#reflectAsString(boolean), e.g. \n\nSystem.out.println(\"token: \"+ts.reflectAsString(true))\n\n.\n\nIdeally the example code would use one attribute as example.\n\nThe example attribute impl's copyTo is using the actual Attribute (not the impl) when casting, but the attribute has no fields, only methods. The copyTo must call set setPos() method of the attribute interface.\n\nThats all. ",
            "author": "Uwe Schindler",
            "id": "comment-13188493"
        },
        {
            "date": "2012-01-18T18:25:33+0000",
            "content": "This example consumer code is incomplete:\n\n[snip]\n\nThe fixed version:\n\n\n<PRE class=\"prettyprint\">\n    Version matchVersion = Version.LUCENE_XY; // Substitute desired Lucene version for XY\n    Analyzer analyzer = new StandardAnalyzer(matchVersion); // or any other analyzer\n    TokenStream ts = analyzer.tokenStream(\"myfield\", new StringReader(\"some text goes here\"));\n    OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);\n    \n    try {\n      ts.reset(); // Resets this stream to the beginning. (Required)\n      while (ts.incrementToken()) {\n        // Use {@link org.apache.lucene.util.AttributeSource#reflectAsString(boolean)}\n        // for token stream debugging.\n        System.out.println(\"token: \" + ts.reflectAsString(true));\n\n        System.out.println(\"token start offset: \" + offsetAtt.startOffset());\n        System.out.println(\"  token end offset: \" + offsetAtt.endOffset());\n      }\n      ts.end();   // Perform end-of-stream operations, e.g. set the final offset.\n    } finally {\n      ts.close(); // Release resources associated with this stream.\n    }\n</PRE>\n\n\n\nI also wrapped the other TokenStream examples with \n\ntry { ... } finally { ts.close(); }\n\n\nThe copyTo must call set setPos() method of the attribute interface.\n\nHere's the fixed version:\n\n\n  {@literal @Override}\n  public void copyTo(AttributeImpl target) {\n    ((PartOfSpeechAttribute) target).setPartOfSpeech(pos);\n  }\n\n\n\nI'll commit shortly. ",
            "author": "Steve Rowe",
            "id": "comment-13188592"
        },
        {
            "date": "2012-01-18T18:36:54+0000",
            "content": "Committed to branch_3x and trunk.\n\nThanks Uwe! ",
            "author": "Steve Rowe",
            "id": "comment-13188600"
        }
    ]
}