{
    "id": "LUCENE-600",
    "title": "ParallelWriter companion to ParallelReader",
    "details": {
        "labels": "",
        "priority": "Minor",
        "components": [
            "core/index"
        ],
        "type": "Improvement",
        "fix_versions": [],
        "affect_versions": "2.1",
        "resolution": "Won't Fix",
        "status": "Closed"
    },
    "description": "A new class ParallelWriter is provided that serves as a companion to ParallelReader.  ParallelWriter meets all of the doc-id synchronization requirements of ParallelReader, subject to:\n    1.  ParallelWriter.addDocument() is synchronized, which might have an adverse effect on performance.  The writes to the sub-indexes are, however, done in parallel.\n    2.  The application must ensure that the ParallelReader is never reopened inside ParallelWriter.addDocument(), else it might find the sub-indexes out of sync.\n    3.  The application must deal with recovery from ParallelWriter.addDocument() exceptions.  Recovery must restore the synchronization of doc-ids, e.g. by deleting any trailing document(s) in one sub-index that were not successfully added to all sub-indexes, and then optimizing all sub-indexes.\n\nA new interface, Writable, is provided to abstract IndexWriter and ParallelWriter.  This is in the same spirit as the existing Searchable and Fieldable classes.\n\nThis implementation uses java 1.5.  The patch applies against today's svn head.  All tests pass, including the new TestParallelWriter.",
    "attachments": {
        "ParallelWriter.patch": "https://issues.apache.org/jira/secure/attachment/12335358/ParallelWriter.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2006-06-13T03:47:46+0000",
            "content": "Patch to create and integrate ParallelWriter, Writable and TestParallelWriter \u2013 also modifies build to use java 1.5. ",
            "author": "Chuck Williams",
            "id": "comment-12415909"
        },
        {
            "date": "2009-08-31T08:06:10+0000",
            "content": "This solution has the severe drawback that it only works if the IndexWriter is used in flush-by-docCount mode. Lucene's default behavior is flush-by-size now.\n\nSee LUCENE-1879 for a more generic approach. ",
            "author": "Michael Busch",
            "id": "comment-12749413"
        },
        {
            "date": "2009-08-31T09:57:40+0000",
            "content": "I contributed the first patch to make flush-by-size possible; see Lucene-709.  There is no incompatibility with ParallelWriter, even the early version contributed here 3 years ago.  We've been doing efficient updating of selected mutable fields now for a long time and filed for a patent on the method.  See published patent application 20090193406. ",
            "author": "Chuck Williams",
            "id": "comment-12749450"
        },
        {
            "date": "2009-08-31T13:45:20+0000",
            "content": "and filed for a patent on the method\n\nI'm the furthest thing from a lawyer, but didn't you publish your own killer prior art right here? Patch posted 06, filing 08?\n\nRhetorical question to a degree I guess - this patent stuff is really fascinating. Nonetheless, one of the reasons I envy Europe. ",
            "author": "Mark Miller",
            "id": "comment-12749497"
        },
        {
            "date": "2009-08-31T20:10:49+0000",
            "content": "The patent isn't on the parallel writer stuff, it's on the update method.  Using parallel indexes is just the first simple step to an efficient update method, far from the complete solution.\n\nPersonally I'm not a supporter of software patents and hope Bilski raises the bar substantially.  However, we live in the world we live in now and companies, including the ones I've worked for who funded this work, want to protect their IP, at least for defensive reasons.  I tried to broker a deal to contribute the update method and code to lucene instead of protecting it, but there was lack of interest in the lucene community at the time and so the deal fell apart.\n\nAt this point the patent is filed and published, so if it issues anybody who infringes risks a charge of doing so knowingly, which substantially increases penalties.\n\nI'm the messenger here, so please don't shoot me. ",
            "author": "Chuck Williams",
            "id": "comment-12749599"
        },
        {
            "date": "2009-08-31T21:51:49+0000",
            "content": "\nI contributed the first patch to make flush-by-size possible; see Lucene-709. There is no incompatibility with ParallelWriter, even the early version contributed here 3 years ago.\n\nI should have been more precise: flush and merge by size. Also the patch provided here doesn't allow deleting by term or query, unless the field(s) the terms or queries are searched on are contained in all parallel indexes, right? Also with this approach, what happens if you commit one indexWriter successfully, but a parallel one fails during commit and needs to be rolled back. How are these consistency issues handled? ",
            "author": "Michael Busch",
            "id": "comment-12749641"
        },
        {
            "date": "2009-08-31T22:22:38+0000",
            "content": "The version attached here is from over 3 years ago.  Our version has evolved along with Lucene and the whole apparatus is fully functional with the latest lucene.\n\nThe fields in each subindex are disjoint.  A logical Document is the collection of all fields from each real Document in each real subindex with same doc-id (i.e., the model Doug started with ParallelReader).  There is no issue with deletion by query or term as it deletes the whole logical Document.  Field updates in our scheme don't use deletion.\n\nMerge-by-size is only an issue if you allow it to be decided independently in each subindex.  In practice that is not very important since one subindex is size-dominant (the one containing the document body field).  One can merge-by-size that subindex and force the others to merge consistently.\n\nThe only reason for the corresponding-segment constraint is that deletion changes doc-id's by purging deleted documents.  I know some Lucene apps address this by never purging deleted documents, which is ok in some domains where deletion is rare.  I think there are other ways to resolve it as well.\n ",
            "author": "Chuck Williams",
            "id": "comment-12749656"
        },
        {
            "date": "2009-08-31T22:36:10+0000",
            "content": "Erratum:  \"deletion changes doc-id's by purging deleted documents\" --> \"merging changes doc-id's by purging deleted documents\" ",
            "author": "Chuck Williams",
            "id": "comment-12749660"
        },
        {
            "date": "2009-08-31T22:38:59+0000",
            "content": "\nThe version attached here is from over 3 years ago. Our version has evolved along with Lucene and the whole apparatus is fully functional with the latest lucene. \n\nWell this issue hasn't been updated in 3 years, so I didn't know that it was still being worked on. Of course you're more than welcome to help working on LUCENE-1879 - it has the same goals and it's just a different JIRA number after all.\n\n\nThe only reason for the corresponding-segment constraint is that deletion changes doc-id's by purging deleted documents. \n\nSo does you approach require doc ids to be stable or can the app using your parallel writer delete docs and purge deleted docs? ",
            "author": "Michael Busch",
            "id": "comment-12749663"
        },
        {
            "date": "2009-08-31T23:37:21+0000",
            "content": "A given logical Document must have the same doc-id in each subindex, which is maintained by using a merge policy that guarantees consistency across the subindexes, either merge-by-count or merge-by-size as dictated by the size-dominant subindex.\n\nI just read your wiki page and it looks like your MasterMergePolicy is the same for the merge-by-size case, right?\n\nWe've bee using parallel incremental indexing in production apps now for a long time, along with the efficient update mechanism described in the patent app.\n\nThe original company I did this work for was acquired by a larger company who now owns the IP.  I don't know how they would feel about a contribution of the latest version of ParallelWriter, which works with the current Lucene.  I could inquire if you are truly open to it, but it sounds like you may be on your own path to a quite similar thing.\n\nYour wiki page says, \"when you need to reindex this field you can simply create a new generation of this parallel index and fill it with the new values\".  That is the rub of the problem, and the one we created an efficient algorithm and implementation for several years ago.  ParallelWriter is the easy part. ",
            "author": "Chuck Williams",
            "id": "comment-12749678"
        },
        {
            "date": "2009-08-31T23:49:59+0000",
            "content": "\nI just read your wiki page and it looks like your MasterMergePolicy is the same for the merge-by-size case, right?\n\nYep sounds very similar. The MasterMergePolicy can wrap any other MergePolicy. ",
            "author": "Michael Busch",
            "id": "comment-12749682"
        },
        {
            "date": "2009-09-01T02:46:58+0000",
            "content": "\nI could inquire if you are truly open to it, but it sounds like you may be on your own path to a quite similar thing.\n\nWell my goal is to get the best possible implementation of this feature into Lucene. Nothing is set in stone yet. So you should feel free to suggest improvements. And if you think your implementation is better or has details worth looking at it would be good if you could submit your code. ",
            "author": "Michael Busch",
            "id": "comment-12749740"
        }
    ]
}