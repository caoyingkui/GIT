{
    "id": "LUCENE-1594",
    "title": "Use source code specialization to maximize search performance",
    "details": {
        "labels": "",
        "priority": "Minor",
        "components": [
            "core/search"
        ],
        "type": "New Feature",
        "fix_versions": [],
        "affect_versions": "None",
        "resolution": "Won't Fix",
        "status": "Resolved"
    },
    "description": "Towards eeking absolute best search performance, and after seeing the\nJava ghosts in LUCENE-1575, I decided to build a simple prototype\nsource code specializer for Lucene's searches.\n\nThe idea is to write dynamic Java code, specialized to run a very\nspecific query context (eg TermQuery, collecting top N by field, no\nfilter, no deletions), compile that Java code, and run it.\n\nHere're the performance gains when compared to trunk:\n\n\n\n\nQuery\nSort\nFilt\nDeletes\nScoring\nHits\nQPS (base)\nQPS (new)\n%\n\n\n1\nDate (long)\nno\nno\nTrack,Max\n2561886\n6.8\n10.6\n55.9%\n\n\n1\nDate (long)\nno\n5%\nTrack,Max\n2433472\n6.3\n10.5\n66.7%\n\n\n1\nDate (long)\n25%\nno\nTrack,Max\n640022\n5.2\n9.9\n90.4%\n\n\n1\nDate (long)\n25%\n5%\nTrack,Max\n607949\n5.3\n10.3\n94.3%\n\n\n1\nDate (long)\n10%\nno\nTrack,Max\n256300\n6.7\n12.3\n83.6%\n\n\n1\nDate (long)\n10%\n5%\nTrack,Max\n243317\n6.6\n12.6\n90.9%\n\n\n1\nRelevance\nno\nno\nTrack,Max\n2561886\n11.2\n17.3\n54.5%\n\n\n1\nRelevance\nno\n5%\nTrack,Max\n2433472\n10.1\n15.7\n55.4%\n\n\n1\nRelevance\n25%\nno\nTrack,Max\n640022\n6.1\n14.1\n131.1%\n\n\n1\nRelevance\n25%\n5%\nTrack,Max\n607949\n6.2\n14.4\n132.3%\n\n\n1\nRelevance\n10%\nno\nTrack,Max\n256300\n7.7\n15.6\n102.6%\n\n\n1\nRelevance\n10%\n5%\nTrack,Max\n243317\n7.6\n15.9\n109.2%\n\n\n1\nTitle (string)\nno\nno\nTrack,Max\n2561886\n7.8\n12.5\n60.3%\n\n\n1\nTitle (string)\nno\n5%\nTrack,Max\n2433472\n7.5\n11.1\n48.0%\n\n\n1\nTitle (string)\n25%\nno\nTrack,Max\n640022\n5.7\n11.2\n96.5%\n\n\n1\nTitle (string)\n25%\n5%\nTrack,Max\n607949\n5.5\n11.3\n105.5%\n\n\n1\nTitle (string)\n10%\nno\nTrack,Max\n256300\n7.0\n12.7\n81.4%\n\n\n1\nTitle (string)\n10%\n5%\nTrack,Max\n243317\n6.7\n13.2\n97.0%\n\n\n\n\n\nThose tests were run on a 19M doc wikipedia index (splitting each\nWikipedia doc @ ~1024 chars), on Linux, Java 1.6.0_10\n\nBut: it only works with TermQuery for now; it's just a start.\n\nIt should be easy for others to run this test:\n\n\n\tapply patch\n\n\n\n\n\tcd contrib/benchmark\n\n\n\n\n\trun python -u bench.py -delindex </path/to/index/with/deletes>\n    -nodelindex </path/to/index/without/deletes>\n\n\n\n(You can leave off one of -delindex or -nodelindex and it'll skip\nthose tests).\n\nFor each test, bench.py generates a single Java source file that runs\nthat one query; you can open\ncontrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/FastSearchTask.java\nto see it.  I'll attach an example.  It writes \"results.txt\", in Jira\ntable format, which you should be able to copy/paste back here.\n\nThe specializer uses pretty much every search speedup I can think of\n\u2013 the ones from LUCENE-1575 (to score or not, to maxScore or not),\nthe ones suggested in the spinoff LUCENE-1593 (pre-fill w/ sentinels,\ndon't use docID for tie breaking), LUCENE-1536 (random access\nfilters).  It bypasses TermDocs and interacts directly with the\nIndexInput, and with BitVector for deletions.  It directly folds in\nthe collector, if possible.  A filter if used must be random access,\nand is assumed to pre-multiply-in the deleted docs.\n\nCurrent status:\n\n\n\tI only handle TermQuery.  I'd like to add others over time...\n\n\n\n\n\tIt can collect by score, or single field (with the 3 scoring\n    options in LUCENE-1575).  It can't do reverse field sort nor\n    multi-field sort now.\n\n\n\n\n\tThe auto-gen code (gen.py) is rather hideous.  It could use some\n    serious refactoring, etc.; I think we could get it to the point\n    where each Query can gen its own specialized code, maybe.  It also\n    needs to be eventually ported to Java.\n\n\n\n\n\tThe script runs old, then new, then checks that the topN results\n    are identical, and aborts if not.  So I'm pretty sure the\n    specialized code is working correctly, for the cases I'm testing.\n\n\n\n\n\tThe patch includes a few small changes to core, mostly to open up\n    package protected APIs so I can access stuff\n\n\n\nI think this is an interesting effort for several reasons:\n\n\n\tIt gives us a best-case upper bound performance we can expect from\n    Lucene's normal search classes (minus algorithmic improvements eg\n    PFOR) because it makes life as easy as possible on the\n    compiler/JRE to convert to assembly.\n\n\n\n\n\tWe can spin out optimization ideas from this back into the core\n    (eg LUCENE-1593 already has one example), and prioritize.  EG I\n    think given these results, optimizing for filters that support\n    random-access API is important.  As we fold speedups back into\n    core, the gains from specialization will naturally decrease.\n\n\n\n\n\tEventually (maybe, eg as a future \"experimental\" module) this can\n    be used in production as a simple \"search wrapper\".  Ie, for a\n    given query, the specializer is checked.  If the query \"matches\"\n    what the specializer can handle, then the specialized code is run;\n    else we fallback to Lucene core.  Likely one would pre-compile the\n    space of all specializations, or we could compile java-on-the-fly\n    (eg what a JSP source does when it's changed) but I'm not sure how\n    costly/portable that is.",
    "attachments": {
        "FastSearchTask.java": "https://issues.apache.org/jira/secure/attachment/12405167/FastSearchTask.java",
        "LUCENE-1594.patch": "https://issues.apache.org/jira/secure/attachment/12405166/LUCENE-1594.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2009-04-10T17:02:23+0000",
            "content": "Initial patch. ",
            "author": "Michael McCandless",
            "id": "comment-12697861"
        },
        {
            "date": "2009-04-10T17:03:53+0000",
            "content": "Example of what the specialized code looks like.  This one sorts by relevance, and does no filter & no deletions. ",
            "author": "Michael McCandless",
            "id": "comment-12697862"
        },
        {
            "date": "2009-04-26T20:04:06+0000",
            "content": "Another iteration... this patch is very large because I'm including\nall the generated classes.  Some changes:\n\n\n\tI moved everying under a new contrib/spec\n\n\n\n\n\tThere is now a simple \"FastSearch\" class that you can use to run\n    searches.  This makes it very simple to try out \u2013 if the\n    specializer can handle it, it will; else it falls back to\n    IndexSearcher's search methods.\n\n\n\n\n\tTwo-term boolean OR query is now covered\n\n\n\n\n\tString (ord/val) search is now specialized\n\n\n\nThe code is still horrific and there are many cases not handled.  Very\nearly in the iterations still...\n(reversed, multi-field, other query types, etc.). ",
            "author": "Michael McCandless",
            "id": "comment-12702930"
        },
        {
            "date": "2009-05-07T18:59:35+0000",
            "content": "New patch attached:\n\n\n\tSpecialize for the no norms cases\n\n\n\n\n\tN-clause BooleanQuery of TermQuerys now handled\n\n\n\n\n\tHandle \"setMinimumNumberShouldMatch\"\n\n\n\n\n\tMUST_NOT clauses handled\n\n\n\n\n\tAllow total hits to NOT be computed, and then when sorting by\n    field, do a fail fast on a doc while iterating the TermDocs if the\n    doc can't compete in the current PQ (discussed under LUCENE-1593)\n\n\n\n\n\tPre-replace nulls with U+0000 in StringIndex\n\n\n\n\n\tOther random optimizations\n\n\n\nPatch is small because I'm not including all generated sources (there\nare too many).\n\nThis patch always pre-fills the queue w/ sentinel values.\n\nThese optimizations result is very sizable performance gains,\nespecially with OR queries that sort by field, do not require total\nhit count (with or without filtering, deletions, scoring, etc.).  In\nthese cases the specialized code runs 2.5-3.5X faster than Lucene\ncore. ",
            "author": "Michael McCandless",
            "id": "comment-12707041"
        },
        {
            "date": "2009-05-07T21:13:19+0000",
            "content": "huh, it reduces hardware costs 2-3 times for larger setup! great ",
            "author": "Eks Dev",
            "id": "comment-12707116"
        },
        {
            "date": "2009-05-19T19:38:06+0000",
            "content": "Another iteration.  Many changes, eg:\n\n\n\tAll BooleanQuery clauses are now handled (MUST, SHOULD,\n    MUST_NOT).  But clauses must still be TermQuery.\n\n\n\n\n\tBoth chunk (like BooleanScorer) and \"doc at once\" (like\n    BooleanScorer2) scoring can be generated, except \"doc at once\"\n    requires at least one MUST clause (or non-random-access filter).\n\n\n\n\n\tIteration only filters are rewritten as a MUST clause on a\n    BooleanQuery\n\n\n\n\n\tDecoupled \"structural optimizations\" (rewriting BooleanQuery to\n    equivalent faster queries) from searching/specializing; much of\n    this is the same as what BooleanQuery.scorer does, but some is new\n    eg I drop all SHOULD clauses if minNR is 0 and no scoring is\n    done.\n\n\n\n\n\tThe gen code (Python) is getting somewhat cleaner but still far\n    from porting to Java.\n\n\n\n\n\tCreated a unit test (TestSpecializedSearch) that enumerates all\n    the specializations that can be handled, confirming that results\n    from core Lucene match the specializer's results\n\n\n\n\n\tMany micro optimizations\n\n ",
            "author": "Michael McCandless",
            "id": "comment-12710842"
        },
        {
            "date": "2013-03-16T19:18:25+0000",
            "content": "SPRING_CLEANING_2013. We can reopen if there's interest.\n\nHey Mike:\n\nGuessing this has been superseded by all the work that's gone on since you opened this one almost 4 years ago..... ",
            "author": "Erick Erickson",
            "id": "comment-13604389"
        }
    ]
}