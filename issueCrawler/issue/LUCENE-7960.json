{
    "id": "LUCENE-7960",
    "title": "NGram filters -- preserve the original token when it is outside the min/max size range",
    "details": {
        "labels": "",
        "priority": "Major",
        "resolution": "Fixed",
        "affect_versions": "None",
        "status": "Closed",
        "type": "Improvement",
        "components": [
            "modules/analysis"
        ],
        "fix_versions": [
            "7.4",
            "master (8.0)"
        ]
    },
    "description": "When ngram or edgengram filters are used, any terms that are shorter than the minGramSize are completely removed from the token stream.\n\nThis is probably 100% what was intended, but I've seen it cause a lot of problems for users.  I am not suggesting that the default behavior be changed.  That would be far too disruptive to the existing user base.\n\nI do think there should be a new boolean option, with a name like keepShortTerms, that defaults to false, to allow the short terms to be preserved.",
    "attachments": {
        "LUCENE-7960.patch": "https://issues.apache.org/jira/secure/attachment/12921504/LUCENE-7960.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "id": "comment-16421475",
            "date": "2018-03-31T20:38:13+0000",
            "content": "I'd like to propose a patch (see attached pull request #349) that adds two options to the EdgeNGramFilter:\n\n\tkeepShortTerms: Causes the filter to pass through input terms that are shorter than the minimum gram size.\n\tkeepLongTerms: Causes the filter to pass through input terms that are longer than the maximum gram size.\n\n\n\nI'm not entirely sure about the usefulness of keepLongTerms, but enabling the ability pass through short terms would certainly be neat for queries where you'd like to match ALL tokens as either prefixes or exact terms, but some query tokens are shorter than the minimum gram size. As far is I understand, a second field containing the exact terms isn't really a viable alternative there, because you can easily run into situations where only a subset of query tokens matches for either field. ",
            "author": "Ingomar Wesp"
        },
        {
            "id": "comment-16421479",
            "date": "2018-03-31T21:17:34+0000",
            "content": "When I created this issue, I didn't think about long terms.  Somebody probably needs the functionality.\n\nOn further reflection, I don't think that new parameter names should be plural.  Using \"keepShortTerm\" and \"keepLongTerm\" sounds better to me.  They could both be enabled if that's what the user wants.  The same options should be added to all ngram analysis components, not just EdgeNgramFilter.\n\nLet's consider a min length of 4 and a max length of 6, using EdgeNgramFilter.\n\nIf the input term is \"abcdefgh\", here's the basic term list from the filter:\n\nabcd abcde abcdef\n\nIf keepShortTerm is enabled with the longer input, there is no change.  If keepLongTerm is enabled with the longer input, then the term list will be:\n\nabcd abcde abcdef abcdefgh\n\nThe seven-character string would not be created.  If that's what the user wants, they should just increase the max value, rather than enable the new option.\n\nIf the input term is \"ab\", then the filter would not normally produce any terms.  With keepShortTerm, the output would be the input \u2013 \"ab\".\n\nThe keepLongTerm option would have no effect with a short input.  \n\nI did glance at the patch, but didn't examine it in detail, so I don't know if it does what I just described or not. ",
            "author": "Shawn Heisey"
        },
        {
            "id": "comment-16421621",
            "date": "2018-04-01T10:11:31+0000",
            "content": "Thanks for your feedback! Yes, this is exactly the behavior I tried to implement. I'll rename the parameters according to your suggestion.\n\nI will also have a look at the other ngram components as soon as I have time. ",
            "author": "Ingomar Wesp"
        },
        {
            "id": "comment-16426221",
            "date": "2018-04-04T21:44:42+0000",
            "content": "Ok, I just added the same paramteters to the NGramTokenFilter and updated the pull request. In the long term, it probably makes sense to move all the logic into the NGramTokenFilter and turn EdgeNGramTokenFilter into a simple wrapper. EdgeNGramTokenizer is already implemented this way.\n\nI presume it also makes sense to extend NGramTokenizer and EdgeNGramTokenizer accordingly? ",
            "author": "Ingomar Wesp"
        },
        {
            "id": "comment-16453005",
            "date": "2018-04-25T20:12:47+0000",
            "content": "I've just updated the patch in PR #362. I now also have a working patch for NGramTokenizer and EdgeNGramTokenizer in a separate branch, but it's still pretty messy and thus not yet ready for a PR.\n\nSince this issue deals with the filters specifically, could someone could have a look at PR #362 and merge it if it's acceptable? Once this is done, I would then open another issue for the tokenizers. ",
            "author": "Ingomar Wesp"
        },
        {
            "id": "comment-16459873",
            "date": "2018-05-01T17:16:00+0000",
            "content": "I've gotten a look at the PR.\n\nChanging the signature on an existing constructor isn't a good idea.  Lucene is a public API and there will be user code using that constructor that must continue to work if Lucene is upgraded.  We should add a new constructor and have the existing constructor(s) call that one with default values.\n\nThe only question about that is whether the existing constructor should be deprecated in stable and removed in master.  I'm not sure who to ask.\n\nThere are some variable renames.  They don't look like problems, especially because the visibility is private, but I'd like to get the opinion of someone who has deeper Lucene knowledge.\n\nI'm having a difficult time following the modifications to the filter logic.  Some of the modifications look like they're not directly related to implementing this issue, but I can't tell for sure. ",
            "author": "Shawn Heisey"
        },
        {
            "id": "comment-16460226",
            "date": "2018-05-01T22:22:05+0000",
            "content": "I have basically come to the conclusion that I have absolutely no idea how this stuff works and cannot make any sense out of what the patch does, or even what the classes are doing before the modifications. ",
            "author": "Shawn Heisey"
        },
        {
            "id": "comment-16460304",
            "date": "2018-05-01T23:34:05+0000",
            "content": "Applying the PR as-is does seem to work.  All the tests are passing.  I'm working on some minor alterations.  I've got precommit running, so far it looks good. ",
            "author": "Shawn Heisey"
        },
        {
            "id": "comment-16460312",
            "date": "2018-05-01T23:46:59+0000",
            "content": "Updated patch added.  Deprecates the existing 3-arg constructors, and removes all usage of the deprecated constructors from the codebase.  Tests in lucene/analysis and precommit at the root are passing. ",
            "author": "Shawn Heisey"
        },
        {
            "id": "comment-16461325",
            "date": "2018-05-02T17:14:25+0000",
            "content": "Thanks a lot for your support. I don't quite understand your comment regarding the constructors: Unless I'm missing something, I think I did preserve the original ones, which now delegate to the new ctors using defaullt values.\n\nIs there anything left that I can or should do to get this into master? ",
            "author": "Ingomar Wesp"
        },
        {
            "id": "comment-16461514",
            "date": "2018-05-02T19:14:11+0000",
            "content": "The patch doesn't add up to me. The description of this issue claims that the default behavior wouldn't be changed, but then the patch does just the opposite and makes the new parameters mandatory. 5 arguments is too many here, that's not usable IMO. ",
            "author": "Robert Muir"
        },
        {
            "id": "comment-16461660",
            "date": "2018-05-02T22:01:42+0000",
            "content": "Robert Muir so you would keep the current constructor around permanently?  I have no objection if that's what you'd prefer.\n\nIngomar Wesp You did preserve it.  When I looked at the patch (not the result of applying the patch) it looked like a replacement, which prompted that comment. ",
            "author": "Shawn Heisey"
        },
        {
            "id": "comment-16461673",
            "date": "2018-05-02T22:12:42+0000",
            "content": "Updated patch.  Does not deprecate constructors, does not fiddle with constructor usage in non-test code. ",
            "author": "Shawn Heisey"
        },
        {
            "id": "comment-16461683",
            "date": "2018-05-02T22:23:15+0000",
            "content": "my biggest concern is that these filters would then have two ctors:\n\n\n\tNGramTokenFilter(TokenStream)\n\tNGramTokenFilter(TokenStream, int, int, boolean, boolean)\n\n\n\nThe no-arg one starts looking more attractive to users at this point, and its mega-trappy (n=1,2)!!!!!!! That's the ctor that should be deprecated \n\nIn general I'll be honest, I don't like how trappy the apis are with these filters/tokenizers because of defaults like that. I also think its trappy they take a min and a max at all, because that's really creating (max-min) indexed fields all unioned into one. There aren't even any warnings about this. \n\nI haven't reviewed what the booleans of the patch does, but I am concerned that the use case may just be \"keep original\" which could be one boolean, or perhaps done in a different way entirely (e.g. KeywordRepeatFilter or perhaps something like LUCENE-8273). So if its acceptable to collapse it into one boolean that does that, I think that would be easier.\n\nI feel like any defaults that our apis lead to (and when you have multiple ctors, then thats a default) should be something that will perform and scale well and work for the general case. For example n=4 has been shown to work well in many relevance experiments. At least we should make it easy for you to explicitly ask for something like that without passing many parameters. ",
            "author": "Robert Muir"
        },
        {
            "id": "comment-16461695",
            "date": "2018-05-02T22:39:44+0000",
            "content": "My original idea would have been handled by one boolean \u2013 keeping terms shorter than minGram.  On more than one occasion, I've fielded questions where it turns out the user is trying to search for terms shorter than their minGram size.\n\nIn discussing it, the notion of long terms being removed by the min/max range also came up.  It was an idea I had not originally considered, but I have encountered someone since where they had ngram on the index side but not the query side, and wanted to search for terms longer than their maxGram size.\n\nIt could be reduced to one \"keep\" boolean to keep both short and long terms, but I think we're going to have people who want to keep short terms but not long terms, and vice versa. ",
            "author": "Shawn Heisey"
        },
        {
            "id": "comment-16461700",
            "date": "2018-05-02T22:44:09+0000",
            "content": "The \"obvious\" workaround to either situation is to decrease minGram and/or increase maxGram.  I find that increasing maxGram doesn't meet with a lot of resistance ... but decreasing minGram can lead to massive term explosion (with possible performance ramifications) and a big shift in recall/precision balance. ",
            "author": "Shawn Heisey"
        },
        {
            "id": "comment-16461757",
            "date": "2018-05-03T00:07:35+0000",
            "content": "I just thought of a particularly ugly idea that would preserve the current 3-arg capability and allow the extra booleans.  Make the constructor signature this:\n\n\n  public EdgeNGramTokenFilter(\n      TokenStream input, int minGram, int maxGram, boolean... flags)) {\n\n\n\nI sometimes do things like this in my own code with methods that nobody else is going to use.  But for a public API like Lucene, is that as bad an idea as it seems? ",
            "author": "Shawn Heisey"
        },
        {
            "id": "comment-16461767",
            "date": "2018-05-03T00:18:10+0000",
            "content": "An example of where I used the ellipsis notation in my own code to make a boolean argument optional:\n\n\n\t/**\n\t * Fully close a connection, statement, and result set, ignoring any errors\n\t * that occur. Any of the three resources here can be null, but at least one\n\t * of them must NOT be null.\n\t * \n\t * @param rs the ResultSet to close.\n\t * @param st the Statement to close.\n\t * @param conn The Connection to close.\n\t * @param forceFlags This odd ellipsis parameter is used for one thing\n\t *            currently: a flag to indicate whether or not a close will be\n\t *            forced on all provided resources even if everything doesn't\n\t *            match up. In theory, a statement derived from the resultset\n\t *            and connections derived from either one should be exactly the\n\t *            same object as the ones provided to the method. If the flag is\n\t *            false, then only the first non-null resource provided and any\n\t *            parent resources derived from that resource will be closed. If\n\t *            it is true, ALL resources including derived resources will be\n\t *            closed. Mismatches will be logged either way. The ellipsis\n\t *            notation is so that this parameter is optional. If omitted, it\n\t *            will default to false.\n\t * @throws IllegalArgumentException if all three resources are null.\n\t */\n\tpublic static void fullQuietClose(ResultSet rs, Statement st, Connection conn,\n\t\t\tboolean... forceFlags)\n\n ",
            "author": "Shawn Heisey"
        },
        {
            "id": "comment-16461777",
            "date": "2018-05-03T00:31:34+0000",
            "content": "The one thing that I do not know is whether an added argument with the ellipsis notation preserves API compatibility.  If we did that, would a program originally compiled against an older Lucene version still work correctly with the added parameter?\n\nI know that everything would be fine if the program were re-compiled.  Which I think technically meets our overall goal for a minor release, but preserving binary compatibility when possible is a good bonus. ",
            "author": "Shawn Heisey"
        },
        {
            "id": "comment-16461782",
            "date": "2018-05-03T00:35:49+0000",
            "content": "Sorry, varargs are completely uncalled for here. Arguing for 250 booleans instead of just 1 boolean isn't going to work as a \"negotiating\" strategy to get back to 2. Please take my recommendations seriously. ",
            "author": "Robert Muir"
        },
        {
            "id": "comment-16461792",
            "date": "2018-05-03T00:45:05+0000",
            "content": "That idea had nothing to do with the number of booleans.  Only with making any extra arguments (no matter how many there are) optional. ",
            "author": "Shawn Heisey"
        },
        {
            "id": "comment-16461976",
            "date": "2018-05-03T06:19:13+0000",
            "content": "I understand your concern. As far as I can tell, there are two options:\n\n1) Replace the booleans with an enum that covers the four possible combinations. Maybe \"keepMode\" with values \"DROP\", \"KEEP_SHORT_TERM\", \"KEEP_LONG_TERM\", \"KEEP_ALL\". I'm not really happy with the names, though - advice welcome.\n\n2) Fold the two booleans into one - maybe \"preserveOriginal\", akin to how the corresponding attribute in other filters is called.\n\nI personally prefer 1), but I'd happily adapt the patch to implement the other if it makes things easier from your perspective.\n ",
            "author": "Ingomar Wesp"
        },
        {
            "id": "comment-16463930",
            "date": "2018-05-04T14:13:28+0000",
            "content": "On first blush, an enum seems even more of a mess than one or two extra boolean parameters.  I will let Robert Muir and others with more experience in these matters make the call on that.  How would the factory (and by extension, text configuration files) handle it?\n\nIf two boolean parameters is going to meet with resistance, I can support preserveOriginal.  I think users will want long and short handled separately, but one flag would get the job done. ",
            "author": "Shawn Heisey"
        },
        {
            "id": "comment-16465152",
            "date": "2018-05-06T14:26:54+0000",
            "content": "Again I want to re-emphasize that anything more complex than a single boolean \"preserveOriginal\" is too much. If someone wants to remove too-short or too-long terms they can use LengthFilter for that. There is no need to have such complex stuff i the ngram filters itself.\n\nFurthermore I still think we need to address the traps I mentioned about about these filters emitting too many tokens already before we then go and add an option to make them produce even more... ",
            "author": "Robert Muir"
        },
        {
            "id": "comment-16465199",
            "date": "2018-05-06T15:44:15+0000",
            "content": "OK, so we re-engineer to only add a preserveOriginal parameter.  That parameter will keep original term when it is outside the min/max range.\n\nFor addressing the traps: Is that just removing the no-arg constructor, changing the default min/max, both, or was there something else you had in mind?\n\nIn master, what constructors do you think should be there?  My bias is to only have one, but I don't live and breathe Lucene code like you do, so I trust your judgement more than mine. ",
            "author": "Shawn Heisey"
        },
        {
            "id": "comment-16465221",
            "date": "2018-05-06T16:54:44+0000",
            "content": "There is no need to have only one constructor: two many parameters for the simple use case.\n\nI already explained my preference as to what they should be:\n\n\tNgramWhateverFilter(TokenStream, int)\n\tNgramWhateverFilter(TokenStream, int, int, boolean)\n\n\n\nSo remove the no-arg constructor, which means there is no need for any default min/max.\nIt is also important that the factory match this. Whatever parameters are mandatory for the tokenfilter also needs to be mandatory in the factory, too. I will insist on it. ",
            "author": "Robert Muir"
        },
        {
            "id": "comment-16465233",
            "date": "2018-05-06T17:44:02+0000",
            "content": "Thanks for the clarification.  Should the no-arg constructor go through deprecation in 7.x? ",
            "author": "Shawn Heisey"
        },
        {
            "id": "comment-16467599",
            "date": "2018-05-08T15:53:39+0000",
            "content": "A new preserveOriginal will be nice, and also consistent with other filters that have this.\nI agree with Rob about the defaults; users should explicitly state the gram length(s). ",
            "author": "David Smiley"
        },
        {
            "id": "comment-16467894",
            "date": "2018-05-08T20:00:57+0000",
            "content": "Yes, I think we should deprecate. It helps ppl upgrade and shouldn't be too bad in this case.\n\nIf we currently have 1-arg (TokenStream) and 3-arg (TokenStream, int, int), and we want to end up at 2-arg (TokenStream, int) and 4-arg (TokenStream, int, int, boolean) then 7.x can temporarily have 4 constructors: the existing two of which are deprecated and forward to the new ones. Their javadoc can even explain what the forwarding is doing. master would just have the two new ones with no cruft. ",
            "author": "Robert Muir"
        },
        {
            "id": "comment-16467964",
            "date": "2018-05-08T21:05:46+0000",
            "content": "What would happen when there's only one int in the constructor? ",
            "author": "Shawn Heisey"
        },
        {
            "id": "comment-16467968",
            "date": "2018-05-08T21:10:12+0000",
            "content": "then it would behave like you expect an n-gram filter to behave? min=max=4 or whatever. The two ints is really crazy/expert and doesn't match anyone's expectations about what n-grams are. Its also mega trappy as i mentioned above, it needs javadoc warnings. ",
            "author": "Robert Muir"
        },
        {
            "id": "comment-16468129",
            "date": "2018-05-09T00:02:58+0000",
            "content": "Uploading new patch.  Ingomar Wesp, please make sure I haven't broken anything, including test coverage.  Tests and precommit do pass.  Robert Muir, can you look it over too? ",
            "author": "Shawn Heisey"
        },
        {
            "id": "comment-16468156",
            "date": "2018-05-09T00:29:29+0000",
            "content": "The patch has a little confusion about back compat (e.g. breaks back compat with the factories by requiring parameters that were optional before, but leaves back compat in the tokenfilters), so I'm not sure if its geared at the master branch or not. Sometimes its easiest to make the patch with all the back-compat, commit it to master and merge it back, then make a separate commit to just master to remove the cruft, maybe its good in this case.\n\nThere are some cosmetic style changes such as moving attribute initialization into the ctor instead of inline, that is different than the style of all our other tokenfilters. It makes it hard to review the logic changes (have not looked at this, just the apis and docs).\n\nAs far as docs, I think there are easy wins. Lets take EdgeNGramTokenFilter just as an example.\n\nFor the ctor with all the parameters, it doesn't need to have documentation on what the other ctors do: they can have their own. It should only document the behavior and parameters like it does, so we can just remove its last line about that.\n\nFor the other ctors which are shortcuts/sugar, we can add a line such as this:\n\n   * <p>\n   * Behaves the same as {@link #EdgeNGramTokenFilter(TokenStream, int, int, boolean) \n   *                             EdgeNGramTokenFilter(input, minGram, maxGram, false)}\n\n\n\nThis helps make it clear what the shortcut/sugar is really doing with a clickable link, and it also helps the deprecated case, if someone has to transition their code. ",
            "author": "Robert Muir"
        },
        {
            "id": "comment-16468161",
            "date": "2018-05-09T00:32:40+0000",
            "content": "Also for the full ctor that allows a range, i really still think it needs some wording, a warning of sorts, that a big range is really the same (space/time-wise) as indexing the content N different ways. It may be also good to include the fact that if you pass true for preserveOriginal, its like indexing the content yet another time.\n\nThe ctor that just takes a fixed \"n\" for the n-gram doesn't need such warnings, its pretty safe. ",
            "author": "Robert Muir"
        },
        {
            "id": "comment-16468227",
            "date": "2018-05-09T02:13:02+0000",
            "content": "All good points.\n\nI made the min/max parameters required on the factory because the constructor without any size parameters is deprecated.  Is this something you don't like at all, or something you would only want to see in master?  You're right that there is some backcompat confusion in that.  I wasn't completely sure it was a good idea, decided to proceed, with the probability of not making that change in the backport to 7x.\n\nIf we do need to keep default values, the current defaults (1 and 2 for ngram, 1 and 1 for edgengram) really kinda suck.  But changing them is another backcompat break.  Seems better to completely get rid of defaults in master, and unless I misunderstood you, that seems to be your position as well.\n\nI would need to review the patch to be sure, but I think that the cosmetic style changes you mentioned were made by the contributor before I started working on it.  The changes to the inner workings of the filter looked like they were doing more than the issue requires, but I don't understand token handling code well enough to grasp what the changes were actually doing.  Tests pass, so if there's a problem there, it's not being caught by test coverage.  Please feel free to adjust or make suggestions!\n\nI'm done in for the night, and will poke at it again tomorrow.  If you could summarize everything that you'd like to see in a new patch, that would help me. ",
            "author": "Shawn Heisey"
        },
        {
            "id": "comment-16468292",
            "date": "2018-05-09T03:54:20+0000",
            "content": "\nI made the min/max parameters required on the factory because the constructor without any size parameters is deprecated. Is this something you don't like at all, or something you would only want to see in master?\n\nwhat does it mean \"not making that change in the backport to 7x\" ?\nAs i suggested above: consider making the patch against master fully backwards compatible. We can review it, then it can be committed, merged cleanly and safely back to 7.x. After that, remove the deprecations in master in a separate dedicated commit.\n\nIt seems like more work, but I think its less work than trying to do a shortcut, because you can have confidence you don't break stuff. \"Making changes during backports\" seems like trouble, and having a confusing patch makes the code review hard. The current one is confusing because it isn't really appropriate for either master (it has deprecations) nor 7x (it breaks backwards) ",
            "author": "Robert Muir"
        },
        {
            "id": "comment-16476383",
            "date": "2018-05-15T19:40:04+0000",
            "content": "Sorry for not responding earlier*. Looks good to me; however, the logic can be simplified further, now that we don't care about differentiating between the two cases anymore. Unless someone else wants\u00a0 to address this and Robert's other suggestions, I would like to further refine the patch and submit a new one this weekend.\n\n*) Even though I'm watching this issue, I'm not getting mails from Jira. Is this intentional for non-commiters? ",
            "author": "Ingomar Wesp"
        },
        {
            "id": "comment-16476817",
            "date": "2018-05-16T04:39:39+0000",
            "content": "\n*) Even though I'm watching this issue, I'm not getting mails from Jira. Is this intentional for non-commiters?\n\nAs far as I know, JIRA doesn't consider any roles. This is what the configuration says:\n\n\n\n\nIssue Commented\n\n\tAll Watchers\n\tCurrent Assignee\n\tReporter\n\tSingle Email Address (dev at lucene.apache.org)\n\n\n\n\n\n\n\nI added you to Contributors group so you can assign issues: maybe it helps. But it could be something SMTP-related or some other problem. Did you get any notifications when Shawn mentioned you on this issue? ",
            "author": "Robert Muir"
        },
        {
            "id": "comment-16477950",
            "date": "2018-05-16T19:25:07+0000",
            "content": "Thanks for looking into this. No, I didn't get anything, even when I was mentioned directly. Sadly, I'm not adminstrating my own mail server, so I can't really rule out that there's some mail transport issue on my end. I'll try alternative mail addresses see if that helps. ",
            "author": "Ingomar Wesp"
        },
        {
            "id": "comment-16482180",
            "date": "2018-05-21T04:39:46+0000",
            "content": "Just updated the patch. In the end, I decided against simplifying the filter logic, because that would mean that the sequence generated tokens would be a bit odd: It would have meant that the original term would always be generated first, unless it is in the minGram / maxGram range, which makes the tests a bit hard to read. The way it is now, the term is either output before the shortest (if it is shorter) or after the longest n-gram (if it is longer), which makes more sense IMHO. ",
            "author": "Ingomar Wesp"
        },
        {
            "id": "comment-16483721",
            "date": "2018-05-22T09:41:20+0000",
            "content": "looks good. thank you for making the updates. ",
            "author": "Robert Muir"
        },
        {
            "id": "comment-16500742",
            "date": "2018-06-04T19:17:53+0000",
            "content": "So ... anyone willing to merge this into master? ",
            "author": "Ingomar Wesp"
        },
        {
            "id": "comment-16501130",
            "date": "2018-06-05T01:33:51+0000",
            "content": "Commit 208d4a9c346ab0dca6c4ae659d55b9446b7d8c87 in lucene-solr's branch refs/heads/master from Robert Muir\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=208d4a9 ]\n\nLUCENE-7960: Add preserveOriginal option to the NGram and EdgeNGram filters\n\n(this is a correction of the issue number in both the CHANGES.txt and the commit message, sorry for the noise). ",
            "author": "ASF subversion and git services"
        },
        {
            "id": "comment-16501163",
            "date": "2018-06-05T02:06:08+0000",
            "content": "Commit 98bf43b3da5131f0d27c747ac8bfbe28945cc922 in lucene-solr's branch refs/heads/branch_7x from Robert Muir\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=98bf43b ]\n\nLUCENE-7960: Add preserveOriginal option to the NGram and EdgeNGram filters\n\n(this is a correction of the issue number in both the CHANGES.txt and the commit message, sorry for the noise). ",
            "author": "ASF subversion and git services"
        },
        {
            "id": "comment-16501211",
            "date": "2018-06-05T02:41:10+0000",
            "content": "Commit 5c6a49b13f47789c828995f747ec541810bdd0b4 in lucene-solr's branch refs/heads/master from Robert Muir\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=5c6a49b ]\n\nLUCENE-7960: remove deprecations ",
            "author": "ASF subversion and git services"
        },
        {
            "id": "comment-16501214",
            "date": "2018-06-05T02:42:38+0000",
            "content": "Thank you Ingomar Wesp ! ",
            "author": "Robert Muir"
        },
        {
            "id": "comment-16502057",
            "date": "2018-06-05T16:30:50+0000",
            "content": "Commit c587598096cde769c299594fb26d0a23b7bd5930 in lucene-solr's branch refs/heads/master from David Smiley\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=c587598 ]\n\nLUCENE-7960: fix Solr test to include mandatory args ",
            "author": "ASF subversion and git services"
        },
        {
            "id": "comment-16502061",
            "date": "2018-06-05T16:32:26+0000",
            "content": "Commit 3694bbdaaf9f9b094db364c892cd707facb0d680 in lucene-solr's branch refs/heads/branch_7x from David Smiley\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=3694bbd ]\n\nLUCENE-7960: fix Solr test to include mandatory args\n\n(cherry picked from commit c587598) ",
            "author": "ASF subversion and git services"
        }
    ]
}