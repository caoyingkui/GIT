{
    "id": "SOLR-10299",
    "title": "Provide search for online Ref Guide",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [
            "documentation"
        ],
        "type": "Sub-task",
        "fix_versions": [],
        "affect_versions": "None",
        "resolution": "Unresolved",
        "status": "Open"
    },
    "description": "The POC to move the Ref Guide off Confluence did not address providing full-text search of the page content. Not because it's hard or impossible, but because there were plenty of other issues to work on.\n\nThe current HTML page design provides a title index, but to replicate the current Confluence experience, the online version(s) need to provide a full-text search experience.",
    "attachments": {
        "basic-services-diagram.png": "https://issues.apache.org/jira/secure/attachment/12925829/basic-services-diagram.png"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2017-03-15T22:42:35+0000",
            "content": "Where would we host the search (and what middle-ware front it by)? Also do we want something like an auto-complete at my http://www.solr-start.com/javadoc/solr-lucene/index.html or something that returns a whole big page of search results? ",
            "author": "Alexandre Rafalovitch",
            "id": "comment-15927119"
        },
        {
            "date": "2017-03-21T14:53:27+0000",
            "content": "Quick and dirty option is Google Custom Search without ads (possible for non-profits), e.g. https://cse.google.com/cse/publicurl?cx=004505742152290171517:8cel-egeirq\n\nBut better to re-use our current site search search. LucidFind already has a category for solr refGuide that we could filter on from the search box. If sematext also added such a filter option, we'd be good to go? ",
            "author": "Jan H\u00f8ydahl",
            "id": "comment-15934734"
        },
        {
            "date": "2017-06-23T21:13:11+0000",
            "content": "This seems useful in parsing the content : http://asciidoctor.org/docs/asciidoctorj/\n\nI'm going to play around with this and see how can I index it into Solr.  ",
            "author": "Varun Thacker",
            "id": "comment-16061504"
        },
        {
            "date": "2017-06-24T19:50:06+0000",
            "content": "With http://asciidoctor.org/docs/asciidoctorj/ it was pretty easy to parse all the asciidoc files in Java. In the next couple of days I will play around with indexing it in Solr .\n\nI have no idea how to even integrate it but I'm not going to check that till I actually manage to get it indexed and have a search up locally.\n\nOne thing that might help in the short term could be enabling fuzzy search mentioned on https://github.com/christian-fei/Simple-Jekyll-Search ? the search.json file we have doesn't mention it and the docs doesn't specify whether it is true or false by default  ",
            "author": "Varun Thacker",
            "id": "comment-16062107"
        },
        {
            "date": "2017-06-27T14:27:42+0000",
            "content": "Parsing the raw content is one approach that might be successful. Indexing the generated HTML is another option. Seeing what happens with bin/post on the HTML files would be another simple experiment to try. I'm not sure it would be preferable, but will reflect what end-users see. We don't do this yet, but someday we will have raw content files that do not stand alone but are snippets included inside another file that together become a single HTML page. \n\nThe harder questions IMO are going to be how to integrate it with the CMS, keeping the index up to date, the facet options, the end-user UI, etc.\n\nOne thing that might help in the short term could be enabling fuzzy search mentioned on https://github.com/christian-fei/Simple-Jekyll-Search ? the search.json file we have doesn't mention it and the docs doesn't specify whether it is true or false by default\n\nAs I've mentioned a few times to the list(s), we're currently using a JavaScript to generate the title title-keyword approach that's in use now. That doesn't come from Jekyll, but from an open-source Jekyll theme that I borrowed for the basic layout of the pages. That Javascript can index the body when it's generated, but the author of it notes in his documentation that it can cause problems. I never had time to try it to see what these problems are so I can't speak to it being a satisfactory stopgap - I'll guess, though, that the problems are related to performance, relevance, and proper parsing of text (only, you know, all the problems that we know plague inadequate attempts at full-text search).\n\nIf you are interested, though, here are the docs for the keyword lookup that's currently in place: http://idratherbewriting.com/documentation-theme-jekyll/mydoc_search_configuration.html. You will see immediately the similarities between that site and ours \n\nI have seen the Simple-Jekyll-Search project early on, but I suspect it's going to be also inadequate for similar reasons the current JavaScript solution is inadequate. Since the theme I used already had a JavaScript-based lookup, I didn't bother to investigate another solution in favor of other issues that needed to be dealt with. Perhaps it's worth a look, I'm not sure.\n\nBy the way, the title-keyword lookup was 100% intended as the stopgap solution. I knew it would be unsatisfactory, but I also know that despite all I know of Solr, I cannot carry the majority of the weight to make this feature happen. ",
            "author": "Cassandra Targett",
            "id": "comment-16064927"
        },
        {
            "date": "2017-06-28T11:20:33+0000",
            "content": "Perhaps the ref-guide is small enough to offer a client-side in-memory static index, see https://github.com/dchest/static-search   The demo at https://www.codingrobots.com/search/ seems to satisfy the basic needs for a simple doc search. No idea how large the index would be given ~2Mb adoc content... ",
            "author": "Jan H\u00f8ydahl",
            "id": "comment-16066348"
        },
        {
            "date": "2017-06-28T12:36:31+0000",
            "content": "Just gave it a shot and built a static search index at http://cominvent.com/solr/\nThe search-index.js file is ~600kb which is not too bad, but would perhaps want to make the index load in the background.\nTry searching for e.g. \"numVersionBuckets\" or some other specific word and you'll see that it works since it is actually a full-text index.\nYou see the index itself in http://cominvent.com/solr/data/search-index.js\n\nBenefit of this solution is that we can build the index as part of the static ref-guide build script (needs GoLang to build index) and then upload it with the site itself without any server-side installs. The ref-guide site is 25Mb and this index is 0.6Mb extra.\n\nOf course this does not mean that the new ref-guide should not also be indexed by search-lucene.com or searchhub.lucidworks.com we can have both... ",
            "author": "Jan H\u00f8ydahl",
            "id": "comment-16066420"
        },
        {
            "date": "2017-06-30T11:25:42+0000",
            "content": "A downside of building the search index from HTML is that you get search hits from the left-hand TOC, the menu header and the navigation in footer, so a search for any word in the toc such as \"analysers\" will retrieve all pages (with the best on top though). A workaround for this if we let our ant build generate the index, is to introduce a new build target build-site-notoc or similar that produces clean HTML without the toc, menu bar and footer?\n\nUPDATE I tested. Built the site using _layouts/default_print.html and uploaded the index. Now we get much better precision! And the index also shrunk from 605k to 375k since the URL prefix is now in index.html and not in search-index.js  ",
            "author": "Jan H\u00f8ydahl",
            "id": "comment-16069939"
        },
        {
            "date": "2017-07-21T16:56:00+0000",
            "content": "Commit 4045fa9eb7b8326e52442dfa5527b22f9af93c6c in lucene-solr's branch refs/heads/master from Cassandra Targett\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=4045fa9 ]\n\nSOLR-10299: change \"search\" placeholder text to be more clear no one is actually searching ",
            "author": "ASF subversion and git services",
            "id": "comment-16096494"
        },
        {
            "date": "2017-07-21T16:56:42+0000",
            "content": "Commit 624127d0b24694fff25b796922d63a0c8f98caec in lucene-solr's branch refs/heads/branch_7x from Cassandra Targett\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=624127d ]\n\nSOLR-10299: change \"search\" placeholder text to be more clear no one is actually searching ",
            "author": "ASF subversion and git services",
            "id": "comment-16096500"
        },
        {
            "date": "2017-07-21T16:57:04+0000",
            "content": "Commit d85c9d068f01549a3ff46e1c2ecad8293d63a11b in lucene-solr's branch refs/heads/branch_7_0 from Cassandra Targett\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=d85c9d0 ]\n\nSOLR-10299: change \"search\" placeholder text to be more clear no one is actually searching ",
            "author": "ASF subversion and git services",
            "id": "comment-16096503"
        },
        {
            "date": "2017-07-21T17:41:54+0000",
            "content": "I decided if we aren't going to make progress on this in the short term, I'd at least update the placeholder text that appears in the \"search\" box so it's more clear. It says \"Page title keyword...\" now instead. ",
            "author": "Cassandra Targett",
            "id": "comment-16096602"
        },
        {
            "date": "2017-10-20T19:18:41+0000",
            "content": "Just to add this for reference, there is a Javascript search called Lunr.js (\"A bit like Solr, but much smaller and not as bright.\" - their words not mine) : https://lunrjs.com/\n\nThey do support pre-built indexes , but the pipeline is Node.js based and does have some dependencies. And require JSON documents generated to be indexed (like Solr I guess).\n\nThe other idea is to make Ref Guide one of the shipped (or downloadable) examples. So, it becomes bin/start -e refguide, possibly with browse interface or what not. Not sure the effort involved though and whether release timelines would line up. ",
            "author": "Alexandre Rafalovitch",
            "id": "comment-16213087"
        },
        {
            "date": "2017-10-23T12:29:29+0000",
            "content": "Alexandre Rafalovitch did you test my static client-side index at http://cominvent.com/solr/ ? ",
            "author": "Jan H\u00f8ydahl",
            "id": "comment-16215048"
        },
        {
            "date": "2017-10-23T15:09:03+0000",
            "content": "Jan H\u00f8ydahl I think I looked at the earlier version. Now I just rechecked the latest one. It looks great. +1 on that.\n\nThis does imply Go on a backend and React on frontend? I know Apache was -1 on React before license change, has that decision been reversed?  ",
            "author": "Alexandre Rafalovitch",
            "id": "comment-16215265"
        },
        {
            "date": "2017-10-23T15:42:16+0000",
            "content": "Can we use Docker to run this tool? ",
            "author": "Jan H\u00f8ydahl",
            "id": "comment-16215319"
        },
        {
            "date": "2018-05-23T16:48:34+0000",
            "content": "Jan H\u00f8ydahl, that implementation looks promising!\n\nMy attempts to try and find out the capabilities of the library you're using fell flat.  Are there any options for improving relevancy ranking?  Try putting 'admin' in the search box.  The results are not terrible, but if matches in the page title were to get a boost, I think it would be better.\n\nI did notice that the library uses stopwords. if that is removed, does it greatly inflate the index size? ",
            "author": "Shawn Heisey",
            "id": "comment-16487616"
        },
        {
            "date": "2018-05-23T18:15:03+0000",
            "content": "I still think it is a bad\u00a0optics\u00a0to not use Solr to search Reference Guide. The challenge is who/where to host it. Seems like\u00a0five\u00a0options:\n\n\tA sponsor (implies\u00a0some commitment) hosts it with the implementation being a mini Open-Source project\n\tA third-party individual hosts it, like Mike does with Jirasearch, bearing bandwidth and security costs\n\tWe bake the self-hosted example into Solr as an actual example.\n\tWe make it as a self-hosted example for a local Solr, but then people have to jump through the hoops\n\tWe do some sort of static-hosting+Javascript (like Jan's effort), but then there is an issue of tool-chain and it does not showcase Solr (bad optics)\n\n\n\nWhat did I miss?\n\n\u00a0 ",
            "author": "Alexandre Rafalovitch",
            "id": "comment-16487784"
        },
        {
            "date": "2018-05-23T18:21:27+0000",
            "content": "Forgot to mention that any option that is not an\u00a0official documentation link means the discoverability drops like a rock. Though, in all truth, Google's discoverability of the Reference Guide (and not the Wiki) is also a challenge right now, but two minuses do not make a plus. ",
            "author": "Alexandre Rafalovitch",
            "id": "comment-16487795"
        },
        {
            "date": "2018-05-23T18:49:41+0000",
            "content": "I support any option that does not involve using or hosting Solr. People may think that is what we do and so it\u2019s silly we don\u2019t do it for our ref guide, but hosting and maintaining a search service and experience is not what we do, it is very much not suited for what we do.\n\nI really like the sound of Jan\u2019s solution until the dependency\u00a0issue came up.\n\nIf sponsers want to host something that matches what they do, that is great, but we should not rely on it.\u00a0 ",
            "author": "Mark Miller",
            "id": "comment-16487842"
        },
        {
            "date": "2018-05-23T19:06:04+0000",
            "content": "Mark Miller - could you explain a bit more about \"not using\" Solr. I understanding \"not hosting\" (option 1, and 2) but you seem to also want to exclude option 3 and 4.\u00a0\n\nAs a straw man argument: since we are already building the ref guide as part of the process, we could theoretically index the just-generated ref guide into just-compiled Solr and put the generated\u00a0index into example folder to ship with a custom Solr config (similar to /browse example). For size purposes, it could refer to the stable URL locations to display actual pages and not store any fields. That would a variant of the option 3. I am reading you as -0\u00a0on that, but not clear on why.\n\nJust to re-clarify, I feel this issue is both technical (current search sucks, etc) and also community/politics optics similar to \"the\u00a0ugly homepage\" issue we had until a new one got sponsored. I think, ideally, we would discuss both aspects and find a solution advancing both halves of the issue. ",
            "author": "Alexandre Rafalovitch",
            "id": "comment-16487865"
        },
        {
            "date": "2018-05-23T19:23:16+0000",
            "content": "If you could use Solr in an embedded way that requires minimal to no maintenance, okay great. But Solr does not excel at that.\n\nIf someone figures out how to use Solr in a\u00a0convenient way, great. But it's a slippery slope. What if search goes down? Don't we work on SolrCloud? Shouldn't it be fault tolerant and always running? Shouldn't the search experience itself be A++ in all cases?\n\nI'm open to any solution that ends up making sense. But from my viewpoint, we just want some good enough keyword search that we don't have to maintain, and then for something better we can clearly link out to managed services like LucidFind that will showcase Solr much better than we will over the long term. ",
            "author": "Mark Miller",
            "id": "comment-16487890"
        },
        {
            "date": "2018-05-23T19:46:08+0000",
            "content": "Mark Miller, I have been discussing this very issue with Infra on their hipchat channel, then I saw your comment.  One idea they had was a VM (or maybe two for fault tolerance, I intended to ask about 3 for SolrCloud).  That solution would serve documentation pages and access Solr locally.  The project would be responsible for the software on the VM.\n\nIf there's strong opposition, I can drop the discussion with Infra. ",
            "author": "Shawn Heisey",
            "id": "comment-16487935"
        },
        {
            "date": "2018-05-23T19:52:16+0000",
            "content": "Just offering my opinion. Things like that tend to have a lot of energy in launching but lose attention over the months and years and suck away effort that may be better spent on things more core to the project. Others can weigh in and we can see what the consensus is. If there is a large enough group that thinks they will keep such a service going,\u00a0I wouldn't try and stop it. ",
            "author": "Mark Miller",
            "id": "comment-16487946"
        },
        {
            "date": "2018-05-23T21:51:48+0000",
            "content": "I propose that building the HTML version of the ref guide builds a static index using GO, it will first try find local golang install, if not found it will attempt \u201cdocker run go...\u201d and if that fails it will skip the search index. Meaning that the RM for refguide in the future either needs go or docker installed on the build machine. ",
            "author": "Jan H\u00f8ydahl",
            "id": "comment-16488087"
        },
        {
            "date": "2018-05-25T17:50:53+0000",
            "content": "Alexandre Rafalovitch, I found a project that is based on Lunr.  The name needs work. \n\nhttp://elasticlunr.com/docs/index.html\n\nI have no idea whether it's actually a good library, but what they have to say about themselves sounds very promising.  It has boosting, which would cover what I mentioned earlier as an issue with the current proof of concept.  License is MIT, which I believe is acceptable.\n\nThat would avoid the infrastructure we'd need to use Solr.  Although we could certainly do it, Mark Miller is correct that it's a headache we don't want to take on unless we have to. ",
            "author": "Shawn Heisey",
            "id": "comment-16491075"
        },
        {
            "date": "2018-05-25T17:56:00+0000",
            "content": "If it doesn't violate any ASF rules, I bet the elasticlunr author would be thrilled to be able to state on his site that the Solr project uses his library for searching documentation. ",
            "author": "Shawn Heisey",
            "id": "comment-16491085"
        },
        {
            "date": "2018-05-25T18:16:17+0000",
            "content": "ElasticLunr is not maintained anymore based on the repo's README.\n\nTo me, the correct solution is Solr. But I recognize other people's positions, so I am +0 on anything better than we have now.\n\nIncidentally, SearchHub has been down for at least several days. I am not quite sure in which way this should sway the argument though. ",
            "author": "Alexandre Rafalovitch",
            "id": "comment-16491114"
        },
        {
            "date": "2018-05-25T19:26:34+0000",
            "content": "How disappointing that it's basically a dead project.\n\nI haven't done any comprehensive comparison of lunr and elasticlunr.  A quick glance at the lunr pages doesn't reveal anything about boosting, which is something I'd really like to have, and the main thing that I found interesting on the elasticlunr site.\n\nBut if I run 'git grep boost' on a cloned lunr.js repository, I see evidence that it can boost just fine, so I think the original lunr would work.  And it's actively maintained.  They did a release six days ago! ",
            "author": "Shawn Heisey",
            "id": "comment-16491187"
        },
        {
            "date": "2018-05-30T18:00:32+0000",
            "content": "From HipChat:\u00a0\"But we wouldn't want it exposed to the open Internet, so accessing such a service from the documentation pages securely would require server side code.\"\n\nHTTPd config could easily limit the pages to (say) Apache committers, without any server side code.\n\nAlso note that if you're limiting the audience, then HA/failover should not be needed. It doesn't sound like you would need that for the smaller audience. Our VMs have great uptime, so failures would tend to be the software stack which generally means HA won't save you.\n\nPoint being: you can simplify your deployment.\n\n(and also, that we tend to provide just one VM to each project, so asking for \"several\" is typically a non-starter)\n\nGreg Stein\nInfrastructure Administrator, ASF\n\n\u00a0 ",
            "author": "Greg Stein",
            "id": "comment-16495503"
        },
        {
            "date": "2018-05-30T20:49:25+0000",
            "content": "But we wouldn't want it exposed to the open Internet,\nWe definitely want the search to be public for all, but we'd like to avoid building and maintaining a server-side application to serve\u00a0the search result page.\n\nMy recommendation is to pursue the in-browser JS search options mentioned. Then search follows each guide. With a hosted index we'd need to maintain separate indices for each released Solr version as well.\n\nJan ",
            "author": "Jan H\u00f8ydahl",
            "id": "comment-16495655"
        },
        {
            "date": "2018-05-30T23:15:06+0000",
            "content": "Greg Stein. the search capability for the reference guide needs to available to everyone.  It's our online documentation.  We can't limit it to just committers.\n\nWithin our project, there's no shortage of expertise in making Solr do amazing things.  But for the kind of setup that Infra provides for project web pages, running and accessing a service like Solr is extremely difficult. It is Solr that we don't want to expose to the Internet.  Solr shouldn't be accessible to anyone outside of trusted admins and the servers that will send updates and make queries on behalf of users.\n\nHere's a silly diagram of how it would normally look:\n\n \n\nThe current search capability in the reference guide is javascript, so it runs in the user's browser and accesses a json file with the search data that's generated along with the reference guide.  At the moment, it can only search page titles and doesn't have full-text search capability.  I think that our best bet is probably to continue that general approach, but change the search library to one that can do the job better. ",
            "author": "Shawn Heisey",
            "id": "comment-16495868"
        },
        {
            "date": "2018-05-30T23:30:28+0000",
            "content": "If we are getting a VM, there is nothing that stops that VM have a proxy in front of Solr that rejects everything but one route (/select or /manual or /manual730) from outside of localhost.And rejects anything that has '..' or other magic characters. And has CORS headers locking the - browser-originated - requests to the website hosting official manual only.\n\nThe Solr itself can also be configured to not even have Update Request Handler. The building of the index can be handled by the ant script that builds Solr itself, given that Solr and the documentation and - whatever - is all in one branch now. The index - built locally - can then be secure FTPd to the VM and an index swap command can be called by a watcher script.\n\nOr if Docker is supported, maybe - after the container gets built - it can be mounted read-only and only the latest manual is searchable. ",
            "author": "Alexandre Rafalovitch",
            "id": "comment-16495878"
        },
        {
            "date": "2018-07-26T21:45:25+0000",
            "content": "Here is a simple prototype http://people.apache.org/~mkhl/searchable-solr-guide-7-3/ Feedback is much appreciated.  ",
            "author": "Mikhail Khludnev",
            "id": "comment-16558932"
        },
        {
            "date": "2018-07-27T16:43:32+0000",
            "content": "It\u00a0took a bit of head-scratching to realize that the options will appear on hitting the enter as opposed to the current auto-complete.\n\nMore importantly, there is no feedback to evaluate the search by. It does seem to pick-up titles and text keywords much better than current implementation. It seems to give boost to the titles over plain text.\u00a0\n\nMaybe one thing I would add is which section the text is found in by splitting the page document into parent/child arrangement during indexing. We do have a lot of multi-topic pages. And then jump to the right page section from the screen. And/or highlighting matching text.\n\n\u00a0 ",
            "author": "Alexandre Rafalovitch",
            "id": "comment-16559984"
        }
    ]
}