{
    "id": "LUCENE-1750",
    "title": "Create a MergePolicy that limits the maximum size of it's segments",
    "details": {
        "labels": "",
        "priority": "Minor",
        "components": [
            "core/index"
        ],
        "type": "Improvement",
        "fix_versions": [
            "3.2",
            "4.0-ALPHA"
        ],
        "affect_versions": "2.4.1",
        "resolution": "Duplicate",
        "status": "Closed"
    },
    "description": "Basically I'm trying to create largish 2-4GB shards using\nLogByteSizeMergePolicy, however I've found in the attached unit\ntest segments that exceed maxMergeMB.\n\nThe goal is for segments to be merged up to 2GB, then all\nmerging to that segment stops, and then another 2GB segment is\ncreated. This helps when replicating in Solr where if a single\noptimized 60GB segment is created, the machine stops working due\nto IO and CPU starvation.",
    "attachments": {
        "LUCENE-1750.patch": "https://issues.apache.org/jira/secure/attachment/12413750/LUCENE-1750.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2009-07-16T22:30:57+0000",
            "content": "Unit test illustrating the issue. ",
            "author": "Jason Rutherglen",
            "id": "comment-12732209"
        },
        {
            "date": "2009-07-17T09:24:56+0000",
            "content": "maxMergeMB refers to the max size of segments selected for merging, not the max size of the resulting merged segment. ",
            "author": "Michael McCandless",
            "id": "comment-12732432"
        },
        {
            "date": "2009-07-17T19:13:13+0000",
            "content": "Yeah I realized that later. \n\nSo a new merge policy that inherits from LogByteSizeMergePolicy\nthat keeps a segment size limit will work. Ideally once a\nsegment reaches a near enough range, segments will stop being\nmerged to it. This was easier when the shards were in separate\ndirectories (i.e. fill up the directory, stop when it's at the\nlimit, optimize the directory, and move on).  ",
            "author": "Jason Rutherglen",
            "id": "comment-12732687"
        },
        {
            "date": "2009-07-19T05:48:34+0000",
            "content": "What happens after several such large segments are created? Wouldn't you want them to be merged into an even larger segment? Or, you'll have many such segments and search performance will degrade.\n\nI guess I never thought this is a problem. If I have enough disk space, and my index size reaches 600 GB (which is a huge index), and is split across 10 different segments of size 60GB each, I guess I'd want them to be merged into one larger 600GB segment. It will take ions until I'll accumulate another such 600 GB segment, no?\n\nMaybe we can have two merge factors: 1) for small segments, or up to a set size threshold, where we do the merges regularly. 2) Then, for really large segments we say the marge factor is different. For example, we can say that up to 1GB the merge factor is 10, and beyond the merge factor is 20. That will postpone the large IO merges until enough such segments accumulate.\n\nAlso, w/ the current proposal, how will optimize work? Will it skip the very large segments, or will they be included too? ",
            "author": "Shai Erera",
            "id": "comment-12732974"
        },
        {
            "date": "2009-07-20T22:50:46+0000",
            "content": "> Wouldn't you want them to be merged into an even larger\nsegment? \n\nI think once the segment reaches the limit (i.e. 4GB), it's\neffectively done and nothing more happens to it, except if it\naccumulates too many deletes (as a percentage of docs) then it\ncan be compacted and new segments merged into it?\n\nI think first of all, as we reach the capacity of the machine's\nIO and RAM, large segment merges thrash the machine (i.e. the IO\ncache is ruined and must be restored, IO is unavailable for\nsearches, further indexing stops), they become too large to pass\nbetween servers (i.e. Hadoop, Katta, or Solr's replication). \n\nI'm not sure how much search degrades due to 10-20 larger\nsegments as opposed to a single massive 60GB segment? But if\nsearch is unavailable on a machine due to the CPU and IO\nthrashing (of massive segment merges) it seems like a fair\ntradeoff?\n\nI think optimize remains as is although I would never call it.\nOr we could add an optimize(long maxSegmentSize) method which is\nanalogous to optimize(int maxSegments).  ",
            "author": "Jason Rutherglen",
            "id": "comment-12733389"
        },
        {
            "date": "2009-07-21T06:20:00+0000",
            "content": "we could add an optimize(long maxSegmentSize)\n\nThis I think would be useful anyway, and kind of required if we introduce the proposed merge policy. Otherwise, if someone's code calls optimize (w/ or w/o num segments limit), those large segments will be optimized as well.\n\nexcept if it accumulates too many deletes (as a percentage of docs) then it can be compacted and new segments merged into it?\n\nIf one would call expungeDeletes, and that segment will go below the max size, then it will be eligible for merging, right? But I have a question here, and it may be that I'm missing something in the merge process. Say I have the following segments, each at 4 GB (the limit), except D:\nA (docs 0-99), B (docs 100-230), C (docs 231-450) and D (docs 451-470). Then A accumulates 50 deletes. On one hand, we'd want it to be merged, but if we want that, we have to merge B and C either, right? We cannot merge A w/ D, because the doc IDs need to be in increasing order and retain the order they were added to the index?\n\nSo will the merge policy detect that? I think that it should and the way to work around that is to ensure that the first segment which is below the limit, triggers the merge of all following segments (in doc ID order), regardless of their size?\n\nI don't know if your patch already takes care of this case, and whether my understanding is correct, so if you already handle it that way (or some other way), then that's fine. ",
            "author": "Shai Erera",
            "id": "comment-12733498"
        },
        {
            "date": "2009-07-21T17:39:04+0000",
            "content": "We cannot merge A w/ D, because the doc IDs need to be in\nincreasing order and retain the order they were added to the\nindex?\n\nThe segments are merged in order because they may be sharing doc\nstores. I think we can refine this to only merge contiguous\nsegments that are sharing doc stores, otherwise we can merge\nnon-contiguous segments which continues with LUCENE-1076? \n\nWhen the shards are in their own directories (which is how Katta\nworks), the building process is somewhat easier as we're dealing\nwith a separate segmentInfos for each shard. I am not sure how\nSolr would handle an index sharded into multiple directories.  ",
            "author": "Jason Rutherglen",
            "id": "comment-12733740"
        },
        {
            "date": "2009-07-21T18:15:25+0000",
            "content": "I think we can refine this to only merge contiguous segments that are sharing doc stores\n\nSo in this case it means that segment A will remain smaller than 4 GB and will never get merged (b/c segments B and C reached their limit)? ",
            "author": "Shai Erera",
            "id": "comment-12733762"
        },
        {
            "date": "2012-03-20T15:57:14+0000",
            "content": "TieredMergePolicy does this... ",
            "author": "Michael McCandless",
            "id": "comment-13233512"
        }
    ]
}