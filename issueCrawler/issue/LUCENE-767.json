{
    "id": "LUCENE-767",
    "title": "maxDoc should be explicitly stored in the index, not derived from file length",
    "details": {
        "labels": "",
        "priority": "Minor",
        "components": [],
        "type": "Improvement",
        "fix_versions": [
            "2.1"
        ],
        "affect_versions": "1.9,                                            2.0.0,                                            2.1",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "This is a spinoff of LUCENE-140\n\nIn general we should rely on \"as little as possible\" from the file system.  Right now, maxDoc is derived by checking the file length of the FieldsReader index file (.fdx) which makes me nervous.  I think we should explicitly store it instead.\n\nNote that there are no known cases where this is actually causing a problem. There was some speculation in the discussion of LUCENE-140 that it could be one of the possible, but in digging / discussion there were no specifically relevant JVM bugs found (yet!).  So this would be a defensive fix at this point.",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "date": "2007-01-09T15:31:39+0000",
            "content": "Isn't maxDoc always the same as the docCount of the segment, which is stored?  I.e., couldn't SegmentReader.maxDoc() be equivalently defined as:\n\n  public int maxDoc() \n{\n    return si.docCount;\n  }\n\nSince maxDoc==numDocs==docCount for a newly merged segment, and deletion with a reader never changes numDocs or maxDoc, it seems to me these values should always be the same.\n\nAll Lucene tests pass with this definition.  I have code that relies on this equivalence and so would appreciate knowledge of any case where this equivalence might not hold. ",
            "author": "Chuck Williams",
            "id": "comment-12463322"
        },
        {
            "date": "2007-01-09T16:41:47+0000",
            "content": "Ooh that's great!  I think your logic is correct.\n\nBut I do see one unit test failing when I make that change locally (testIndexAndMerge in src/test/org/apache/lucene/index/TestDoc.java).  Actually, this unit test only fails with my last commit (yesterday) for LUCENE-140 , because I made the checking for \"docs out of order\" more strict (catch a previously missing boundary case), and this test seems to hit that boundary case.\n\nHowever, that test is buggy because it manually creates SegmentInfos with an incorrect docCount.  So I will fix the test, and commit your solution above.  Thanks! ",
            "author": "Michael McCandless",
            "id": "comment-12463335"
        },
        {
            "date": "2007-01-09T18:24:01+0000",
            "content": "\nCarrying over from the java-dev list:\n\n\nGrant Ingersoll wrote:\n\n> Can you explain in more detail on this bug why this makes you nervous?\n\nWell ... the only specific example I have is NFS (always my favorite\nexample!).\n\nAs I understand it, the NFS client typically uses a separate cache to\nhold the \"attributes\" of the file, including file length.  This cache\noften has weaker or maybe just \"different\" guarantees than the \"data\ncache\" that holds the file contents.  So basically you can ask what\nthe file length is and get a wrong (stale) answer.  EG see\nhttp://nfs.sourceforge.net, which describes Linux's NFS client\napproach.  The NFS client on Apple's OS X seems to be even worse!\n\nI think very likely Lucene may not trip up on this specifically since\na reader would only ask for this file's length for the first time once\nthe file is done being written (ie the commit of segments_N has\noccurred) and so hopefully it's not in the attribute cache yet?\n\nI think there may very well be cases of other filesystems where\n\"checking file length\" is risky (that we all just don't know about\n(yet!)), which is why I favor using explicit values instead of relying\non file system semantics, whenever possible.\n\nMaybe I'm just too paranoid \n\nBut for all the places / devices Lucene has gone and will go, relying\non the bare minimum set of IO operations I think will maximize our\noverall portability.  Every filesystem has its quirks. ",
            "author": "Michael McCandless",
            "id": "comment-12463358"
        },
        {
            "date": "2007-02-27T18:10:39+0000",
            "content": "Closing all issues that were resolved for 2.1. ",
            "author": "Michael McCandless",
            "id": "comment-12476279"
        }
    ]
}