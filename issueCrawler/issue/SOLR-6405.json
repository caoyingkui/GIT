{
    "id": "SOLR-6405",
    "title": "ZooKeeper calls can easily not be retried enough on ConnectionLoss.",
    "details": {
        "affect_versions": "None",
        "status": "Resolved",
        "fix_versions": [
            "4.10",
            "6.0"
        ],
        "components": [
            "SolrCloud"
        ],
        "type": "Bug",
        "priority": "Critical",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "The current design requires that we are sure we retry on connection loss until session expiration.",
    "attachments": {
        "SOLR-6405.patch": "https://issues.apache.org/jira/secure/attachment/12663655/SOLR-6405.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "ASF subversion and git services",
            "id": "comment-14106847",
            "date": "2014-08-22T14:02:08+0000",
            "content": "Commit 1619810 from Mark Miller in branch 'dev/trunk'\n[ https://svn.apache.org/r1619810 ]\n\nSOLR-6405: ZooKeeper calls can easily not be retried enough on ConnectionLoss. "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14106849",
            "date": "2014-08-22T14:04:05+0000",
            "content": "Commit 1619811 from Mark Miller in branch 'dev/branches/branch_4x'\n[ https://svn.apache.org/r1619811 ]\n\nSOLR-6405: ZooKeeper calls can easily not be retried enough on ConnectionLoss. "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14106883",
            "date": "2014-08-22T14:15:28+0000",
            "content": "Commit 1619817 from Mark Miller in branch 'dev/branches/lucene_solr_4_10'\n[ https://svn.apache.org/r1619817 ]\n\nSOLR-6405: ZooKeeper calls can easily not be retried enough on ConnectionLoss. "
        },
        {
            "author": "Jessica Cheng Mallet",
            "id": "comment-14107153",
            "date": "2014-08-22T17:39:48+0000",
            "content": "Should the \"if (attemptCount > 0)\" check be removed in retryDelay, now that the sleep is (attemptCount + 1) * retryDelay?\n\nI think in practice we'd never miss the initial 1.5s sleep since the padding on the retryDelay is enough to make up for it, but it's slightly harder to reason about. (The way I thought it worked was that roughly retry count is calculated so 1+2+3+4+...+retryCount ~= timeoutSec, so when that's multiplied by 1.5x (the retryDelay), we have the timeout covered. Is this right?) "
        },
        {
            "author": "Mark Miller",
            "id": "comment-14107199",
            "date": "2014-08-22T17:59:50+0000",
            "content": "Is this right?\n\nYeah, that was the idea basically - a fall back timeout that has some padding to ensure we try longer than the session timeout, but not so long as we are waiting for no reason and tying up threads. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-14107207",
            "date": "2014-08-22T18:03:55+0000",
            "content": "Should the \"if (attemptCount > 0)\" check be removed in retryDelay, now that the sleep is (attemptCount + 1) * retryDelay?\n\nYeah, good catch.\n\nI think in practice we'd never miss the initial 1.5s sleep since the padding on the retryDelay is enough to make up for it, \n\nAgreed. "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14107222",
            "date": "2014-08-22T18:13:22+0000",
            "content": "Commit 1619879 from Mark Miller in branch 'dev/trunk'\n[ https://svn.apache.org/r1619879 ]\n\nSOLR-6405: Remove unnecessary attemptCount > 0 check. "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14107236",
            "date": "2014-08-22T18:22:02+0000",
            "content": "Commit 1619886 from Mark Miller in branch 'dev/branches/branch_4x'\n[ https://svn.apache.org/r1619886 ]\n\nSOLR-6405: Remove unnecessary attemptCount > 0 check. "
        },
        {
            "author": "Jessica Cheng Mallet",
            "id": "comment-14107242",
            "date": "2014-08-22T18:23:15+0000",
            "content": "\nbut not so long as we are waiting for no reason and tying up threads\n\nThis is actually the other thing that I was worried about. With the padding being on a multiplier, for the default 15s timeout, we're already doing 7.5s of total extra sleep (1.5+3+4.5+6+7.5=22.5). Is that too much?\n\nWith your change of the comment \"// 1500 ms over for padding\", did you actually mean to do something like (attemptCount + 1) * 1000 + retryDelay? "
        },
        {
            "author": "Mark Miller",
            "id": "comment-14107250",
            "date": "2014-08-22T18:29:37+0000",
            "content": "Is that too much?\n\nI'm much more worried about doing too little than too much, that is why it was done that way. Perhaps the padding could be brought down (it was probably brought up to combat a sign of this bug - it was 1200 initially I think), but I think we want to error on the long wait side. \n\n// 1500 ms over for padding\n\nHmm, actually 500 over was right. It's mean to be a second, so anything over 1000 is the padding. "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14107257",
            "date": "2014-08-22T18:33:19+0000",
            "content": "Commit 1619891 from Mark Miller in branch 'dev/branches/lucene_solr_4_10'\n[ https://svn.apache.org/r1619891 ]\n\nSOLR-6405: Remove unnecessary attemptCount > 0 check. "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14107261",
            "date": "2014-08-22T18:35:11+0000",
            "content": "Commit 1619892 from Mark Miller in branch 'dev/trunk'\n[ https://svn.apache.org/r1619892 ]\n\nSOLR-6405: Update comment around retry pause padding. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-14107270",
            "date": "2014-08-22T18:38:49+0000",
            "content": "I'm much more worried about doing too little than too much\n\nAlso, keep in mind, it only keeps retrying on connection loss - it's going to end up getting the session expiration which will usually cause it to bail before waiting the full timeout. "
        },
        {
            "author": "ASF subversion and git services",
            "id": "comment-14107273",
            "date": "2014-08-22T18:39:29+0000",
            "content": "Commit 1619895 from Mark Miller in branch 'dev/branches/branch_4x'\n[ https://svn.apache.org/r1619895 ]\n\nSOLR-6405: Update comment around retry pause padding. "
        },
        {
            "author": "Jessica Cheng Mallet",
            "id": "comment-14107289",
            "date": "2014-08-22T18:59:26+0000",
            "content": "Right, most likely the first time it hits the ConnectionLoss it's not time=0 of the connection loss, so by loop i=4, it would've slept for 15s since the i=0 and therefore hit a SessionExpired.\n\nBut then, thinking about it again, why be clever at all about the padding or back-off?\n\nNot to propose that we change this now, but let's pretend we don't do back-off and just sleep 1s between each loop. If we were to get ConnectionLoss back in the next attempt, there's no harm to try at all because if we're disconnected, the attempt wouldn't be hitting zookeeper anyway. If we were to get SessionExpired back, great, we can break out now and throw the exception. If we've reconnected, then yay, we succeeded. Because with each call we're expecting to get either success, failure (SessionExpired), or \"in progress\" (ConnectionLoss), we can really just retry \"forever\" without limiting the loop count (unless we're worried that somehow we'll keep getting ConnectionLoss even though the session has expired, but that'd be a pretty serious zookeeper client bug. And if we're really worried about that, we can always say do 10 more loops after we have slept a total of timeout already). The advantage of this approach is to never sleep for too long before finding out the definitive answer of success or SessionExpired, while if the answer is ConnectionLoss, it's not really incurring any extra load on zookeeper anyway.\n\nIn the end, it's really weird that this method should ever semantically allow throwing a ConnectionLoss exception, if we got the math wrong, because the intent is to retry until we get a SessionExpired, isn't it? (Oh, or success of course. ) "
        },
        {
            "author": "Mark Miller",
            "id": "comment-14107325",
            "date": "2014-08-22T19:15:14+0000",
            "content": "we can really just retry \"forever\" without limiting the loop count\n\nYou can get other exceptions as well though. The original implementation around this waited forever I think and it caused a lot of issues in some cases - perhaps that was mainly in failure cases. I don't really remember the details currently and a lot has changed since then.\n\nThe advantage of this approach is to never sleep for too long before finding out the definitive answer of success or SessionExpired\n\nYeah, I guess it's just not been a big concern of mine since the extra wait is not really enough to matter, and the worst cases is not common or that bad either. This should be an exceptional case and either it's a quick blip or a really expensive recovery anyway. I didn't really see it as a goal to get out as fast as possible because there didn't seem to be much benefit, just to ensure we waited longer than expiration.\n\nIf you want to explore this alternative approach, let's open a new JIRA for it. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-14107370",
            "date": "2014-08-22T19:41:50+0000",
            "content": "SOLR-6409 Improve ZkCmdExecutor retry implementation. "
        },
        {
            "author": "Jessica Cheng Mallet",
            "id": "comment-14107382",
            "date": "2014-08-22T19:54:48+0000",
            "content": "OK, thanks for the explanations! It's really helpful. "
        },
        {
            "author": "Mark Miller",
            "id": "comment-14108413",
            "date": "2014-08-24T13:45:38+0000",
            "content": "Thanks Jessica! "
        }
    ]
}