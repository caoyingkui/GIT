{
    "id": "LUCENE-1039",
    "title": "Bayesian classifiers using Lucene as data store",
    "details": {
        "labels": "",
        "priority": "Minor",
        "components": [
            "core/store"
        ],
        "type": "New Feature",
        "fix_versions": [],
        "affect_versions": "None",
        "resolution": "Unresolved",
        "status": "Reopened"
    },
    "description": "Bayesian classifiers using Lucene as data store. Based on the Naive Bayes and Fisher method algorithms as described by Toby Segaran in \"Programming Collective Intelligence\", ISBN 978-0-596-52932-1. \n\nHave fun.\n\nPoor java docs, but the TestCase shows how to use it:\n\n\npublic class TestClassifier extends TestCase {\n\n  public void test() throws Exception {\n\n    InstanceFactory instanceFactory = new InstanceFactory() {\n\n      public Document factory(String text, String _class) {\n        Document doc = new Document();\n        doc.add(new Field(\"class\", _class, Field.Store.YES, Field.Index.NO_NORMS));\n\n        doc.add(new Field(\"text\", text, Field.Store.YES, Field.Index.NO, Field.TermVector.NO));\n\n        doc.add(new Field(\"text/ngrams/start\", text, Field.Store.NO, Field.Index.TOKENIZED, Field.TermVector.YES));\n        doc.add(new Field(\"text/ngrams/inner\", text, Field.Store.NO, Field.Index.TOKENIZED, Field.TermVector.YES));\n        doc.add(new Field(\"text/ngrams/end\", text, Field.Store.NO, Field.Index.TOKENIZED, Field.TermVector.YES));\n        return doc;\n      }\n\n      Analyzer analyzer = new Analyzer() {\n        private int minGram = 2;\n        private int maxGram = 3;\n\n        public TokenStream tokenStream(String fieldName, Reader reader) {\n          TokenStream ts = new StandardTokenizer(reader);\n          ts = new LowerCaseFilter(ts);\n          if (fieldName.endsWith(\"/ngrams/start\")) {\n            ts = new EdgeNGramTokenFilter(ts, EdgeNGramTokenFilter.Side.FRONT, minGram, maxGram);\n          } else if (fieldName.endsWith(\"/ngrams/inner\")) {\n            ts = new NGramTokenFilter(ts, minGram, maxGram);\n          } else if (fieldName.endsWith(\"/ngrams/end\")) {\n            ts = new EdgeNGramTokenFilter(ts, EdgeNGramTokenFilter.Side.BACK, minGram, maxGram);\n          }\n          return ts;\n        }\n      };\n\n      public Analyzer getAnalyzer() {\n        return analyzer;\n      }\n    };\n\n    Directory dir = new RAMDirectory();\n    new IndexWriter(dir, null, true).close();\n\n    Instances instances = new Instances(dir, instanceFactory, \"class\");\n\n    instances.addInstance(\"hello world\", \"en\");\n    instances.addInstance(\"hall\u00e5 v\u00e4rlden\", \"sv\");\n\n    instances.addInstance(\"this is london calling\", \"en\");\n    instances.addInstance(\"detta \u00e4r london som ringer\", \"sv\");\n\n    instances.addInstance(\"john has a long mustache\", \"en\");\n    instances.addInstance(\"john har en l\u00e5ng mustache\", \"sv\");\n\n    instances.addInstance(\"all work and no play makes jack a dull boy\", \"en\");\n    instances.addInstance(\"att bara arbeta och aldrig leka g\u00f6r jack en trist gosse\", \"sv\");\n\n    instances.addInstance(\"shrimp sandwich\", \"en\");\n    instances.addInstance(\"r\u00e4ksm\u00f6rg\u00e5s\", \"sv\");\n\n    instances.addInstance(\"it's now or never\", \"en\");\n    instances.addInstance(\"det \u00e4r nu eller aldrig\", \"sv\");\n\n    instances.addInstance(\"to tie up at a landing-stage\", \"en\");\n    instances.addInstance(\"att ang\u00f6ra en brygga\", \"sv\");\n\n    instances.addInstance(\"it's now time for the children's television shows\", \"en\");\n    instances.addInstance(\"nu \u00e4r det dags f\u00f6r barnprogram\", \"sv\");\n\n    instances.flush();\n\n    testClassifier(instances, new NaiveBayesClassifier());\n    testClassifier(instances, new FishersMethodClassifier());\n\n    instances.close();\n  }\n\n  private void testClassifier(Instances instances, BayesianClassifier classifier) throws IOException {\n\n    assertEquals(\"sv\", classifier.classify(instances, \"detta blir ett test\")[0].getClassification());\n    assertEquals(\"en\", classifier.classify(instances, \"this will be a test\")[0].getClassification());\n\n    // test training data instances. all ought to match!\n    for (int documentNumber = 0; documentNumber < instances.getIndexReader().maxDoc(); documentNumber++) {\n      if (!instances.getIndexReader().isDeleted(documentNumber)) {\n        Map<Term, Double> features = instances.extractFeatures(instances.getIndexReader(), documentNumber, classifier.isNormalized());\n        Document document = instances.getIndexReader().document(documentNumber);\n        assertEquals(document.get(\"class\"), classifier.classify(instances, features)[0].getClassification());\n      }\n    }\n  }",
    "attachments": {
        "LUCENE-1039.txt": "https://issues.apache.org/jira/secure/attachment/12368730/LUCENE-1039.txt"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2007-12-04T07:22:10+0000",
            "content": "Skimmed this very quickly - looks nice and clean to me!\nWhy is this not in contrib yet?  I didn't spot any dependencies....are there any? ",
            "author": "Otis Gospodnetic",
            "id": "comment-12548159"
        },
        {
            "date": "2007-12-04T13:07:05+0000",
            "content": "Otis Gospodnetic - 03/Dec/07 11:22 PM\n> Skimmed this very quickly - looks nice and clean to me!\n> Why is this not in contrib yet? I didn't spot any dependencies....are there any?\n\nNo dependencies, although I get a 5x-10x faster classifier using LUCENE-550 while trained with 15,000 small instances (documents). \n\nOne reason that this is not in the contrib might be that it is based on an O'Reilly book. That book contains an example implementation in Python but my code does not have much in common with it, except for the Greek kung fu found by a Brittish priest 250 years ago. \n\nIANAL, but according to what I've read in the preface there are no problems releasing this with ASL.\n\nTalk to permissions@oreilly.com if you really want to make sure. I can supply you with the Python code example if you want to compare. The book is however worth the $40 if you want to understand whats going on in there. ",
            "author": "Karl Wettin",
            "id": "comment-12548249"
        },
        {
            "date": "2008-02-19T23:09:42+0000",
            "content": "DId you consider using lucene's termvectors?\nSome of the feature extractions would be easier to do with termvectors, especially when the index contains many more docs than the ones on which the classifier is built.\nClassifying a document from its termvector is also quite natural. ",
            "author": "Paul Elschot",
            "id": "comment-12570494"
        },
        {
            "date": "2008-02-23T22:37:44+0000",
            "content": "\nDId you consider using lucene's termvectors?\nSome of the feature extractions would be easier to do with termvectors, \n\nNot sure what you mean, they are already used when extracting features? Or do you speak of using the term vectors as training instance data when classifying? Bayesian classification can rely on class feature frequency alone.\n\n\nespecially when the index contains many more docs than the ones on which the classifier is built.\n\nThe more documents not used for classification, the more scew the classification results will be as Pr(feature|class) is based on docFreq and numDocs in this implementation. ",
            "author": "Karl Wettin",
            "id": "comment-12571791"
        },
        {
            "date": "2008-02-23T23:08:22+0000",
            "content": "I'll have a more thorough look at the code, but do I understand correctly that it is using a lucene index per class?\n\nI'm just now building a Bayesian classifier using a single index with a field for the features (text terms) and a field for the classes.\nThe feature field also has termvectors, and these make the implementation for training and classifying quite straightforward, after using some queries on the class field to get the doc ids for each class.\nAlso, termvectors allow both a boolean and a strength implementation for the features. The strength is based on the frequency info in the term vectors that have the term frequency within a doc. ",
            "author": "Paul Elschot",
            "id": "comment-12571797"
        },
        {
            "date": "2008-02-23T23:25:49+0000",
            "content": "\ndo I understand correctly that it is using a lucene index per class?\n\nOne index per classifier. Each classifier can contain multiple classes. In the test case the field \"class\" is used to keep track of classes. Each document must only contain one token in the class field. Features can be stored in any number of fields. ",
            "author": "Karl Wettin",
            "id": "comment-12571801"
        },
        {
            "date": "2008-04-04T01:28:04+0000",
            "content": ">>Each document must only contain one token in the class field\n\nDoes that mean each document in the training set can only belong to one class? \n\nI try to run the test case but get NullPointerException:\n\nTestClassifier\norg.apache.lucene.classifier.TestClassifier\ntest(org.apache.lucene.classifier.TestClassifier)\njava.lang.NullPointerException\n\tat org.apache.lucene.index.MultiTermDocs.doc(MultiReader.java:356)\n\tat org.apache.lucene.classifier.BayesianClassifier.classFeatureFrequency(BayesianClassifier.java:92)\n\tat org.apache.lucene.classifier.BayesianClassifier.weightedFeatureClassProbability(BayesianClassifier.java:137)\n\tat org.apache.lucene.classifier.NaiveBayesClassifier.featuresClassProbability(NaiveBayesClassifier.java:54)\n\tat org.apache.lucene.classifier.NaiveBayesClassifier.classify(NaiveBayesClassifier.java:72)\n\tat org.apache.lucene.classifier.BayesianClassifier.classify(BayesianClassifier.java:70)\n\tat org.apache.lucene.classifier.BayesianClassifier.classify(BayesianClassifier.java:62)\n\tat org.apache.lucene.classifier.TestClassifier.testClassifier(TestClassifier.java:110)\n\tat org.apache.lucene.classifier.TestClassifier.test(TestClassifier.java:101)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n\tat java.lang.reflect.Method.invoke(Method.java:597)\n\tat junit.framework.TestCase.runTest(TestCase.java:154)\n\tat junit.framework.TestCase.runBare(TestCase.java:127)\n\tat junit.framework.TestResult$1.protect(TestResult.java:106)\n\tat junit.framework.TestResult.runProtected(TestResult.java:124)\n\tat junit.framework.TestResult.run(TestResult.java:109)\n\tat junit.framework.TestCase.run(TestCase.java:118)\n\tat junit.framework.TestSuite.runTest(TestSuite.java:208)\n\tat junit.framework.TestSuite.run(TestSuite.java:203)\n\tat org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:130)\n\tat org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)\n\tat org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:460)\n\tat org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:673)\n\tat org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:386)\n\tat org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:196)\n ",
            "author": "Cuong Hoang",
            "id": "comment-12585368"
        },
        {
            "date": "2008-04-04T18:50:56+0000",
            "content": "Cuong Hoang - 03/Apr/08 06:28 PM\n>>Each document must only contain one token in the class field\n>Does that mean each document in the training set can only belong to one class?\n\nYou can have multiple class fields, but you can only classify an instance to one class at the time. Currently class and classes buffer is set in instances, I think it should be possible to move that code to NaiveBayesClassifier to allow classification on multiple classes on the same Instances.\n\nInstances.java:\n\n  private String classField;\n  private String[] classes;\n\n\n\n>I try to run the test case but get NullPointerException:\n\n> at org.apache.lucene.classifier.BayesianClassifier.classFeatureFrequency(BayesianClassifier.java:92)\n\nThe pass tests here, did you perhaps alter the content in some way?\n\nIn BayesianClassifier.java, add the following on row 92:\n\n\n    classDocs.seek(new Term(instances.getClassField(), _class));\n+    classDocs.next();\n    while (featureDocs.next()) {\n\n\n\nDoes that help? ",
            "author": "Karl Wettin",
            "id": "comment-12585700"
        },
        {
            "date": "2008-08-24T12:23:19+0000",
            "content": "I close this issue due to uncertainy about intellectual property rights, pending an answer from Toby. I've tried to contact him several times via numerus media without response : ( ",
            "author": "Karl Wettin",
            "id": "comment-12625159"
        },
        {
            "date": "2008-09-12T00:25:14+0000",
            "content": "I'm the author of \"Programming Collective Intelligence\". I see no issue with property rights, the algorithm itself is widely known and my book just explains it. The code Karl wrote is completely original. ",
            "author": "Toby Segaran",
            "id": "comment-12630434"
        },
        {
            "date": "2009-01-09T18:46:17+0000",
            "content": "What do you people think, should I commit this to Lucene or Mahout? ",
            "author": "Karl Wettin",
            "id": "comment-12662467"
        },
        {
            "date": "2009-03-30T03:47:41+0000",
            "content": "Hi Karl,\n\nCan you tell me how to use this with FSDirectory() rather then RAMDirectory(). I am getting following error\n\nException in thread \"main\" java.lang.NullPointerException\n\tat org.apache.lucene.index.MultiSegmentReader$MultiTermDocs.doc(MultiSegmentReader.java:552)\n\tat org.apache.lucene.classifier.BayesianClassifier.classFeatureFrequency(BayesianClassifier.java:94)\n\tat org.apache.lucene.classifier.BayesianClassifier.weightedFeatureClassProbability(BayesianClassifier.java:139)\n\tat org.apache.lucene.classifier.NaiveBayesClassifier.featuresClassProbability(NaiveBayesClassifier.java:54)\n\tat org.apache.lucene.classifier.NaiveBayesClassifier.classify(NaiveBayesClassifier.java:71)\n\tat org.apache.lucene.classifier.BayesianClassifier.classify(BayesianClassifier.java:72)\n\tat org.apache.lucene.classifier.BayesianClassifier.classify(BayesianClassifier.java:64)\n\nWhen I am trying to use the FSDirectory(). I created the instance Index as per the test sample and closed it. Now while doing a classification I am getting the above error.\n\nThe way I create the directory is:\n\n\t\t\tFSDirectory dir = FSDirectory.getDirectory(new File(indexPath));\n\t\t\tIndexWriter iw = new IndexWriter(dir,instanceFactory.getAnalyzer(),create, MaxFieldLength.LIMITED);\n\t\t\tiw.close();\n\nThe  code for addinig the instance is :\ninstances.addInstance(record.getText(), record.getClass());\n\ninstance.flush() and instance.close() all go fine.\n\nWhile doing classification I again open the directory ( with just create set to false ) and rest call remains the same.\n\nInstances instances = new Instances(dir, indexCreator.instanceFactory, \"class\");\nclassifier = new NaiveBayesClassifier();\nreturn classifier.classify(instances, text)[0].getClassification();\n\nCan you help me in pointing out where I am doing wrong.\n\n--Thanks and Regards\nVaijanath N. Rao\n\n ",
            "author": "Vaijanath N. Rao",
            "id": "comment-12693643"
        },
        {
            "date": "2009-03-30T12:26:43+0000",
            "content": "Vaijanath,\n\ncan you please post a small test case that demonstrates the problem? ",
            "author": "Karl Wettin",
            "id": "comment-12693744"
        }
    ]
}