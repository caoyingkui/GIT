{
    "id": "LUCENE-5415",
    "title": "Support wildcard & co in PostingsHighlighter",
    "details": {
        "type": "Improvement",
        "priority": "Major",
        "labels": "",
        "resolution": "Fixed",
        "components": [
            "modules/highlighter"
        ],
        "affect_versions": "None",
        "status": "Closed",
        "fix_versions": [
            "4.7",
            "6.0"
        ]
    },
    "description": "PostingsHighlighter uses the offsets encoded in the postings lists for the terms to find query matches.\n\nAs such, it isn't really suitable for stuff like wildcards for two reasons:\n1. an expensive rewrite against the term dictionary (i think other highlighters share this problem)\n2. accumulating data from potentially many terms (e.g. reading many postings)\n\nHowever, we could provide an option for some of these queries to work, but in a different way, that avoids these downsides.\n\nInstead we can just grab the Automaton representation of the queries, and match it against the content directly (which won't blow up).",
    "attachments": {
        "LUCENE-5415.patch": "https://issues.apache.org/jira/secure/attachment/12625062/LUCENE-5415.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "id": "comment-13881109",
            "author": "Robert Muir",
            "content": "Here's a prototype. just has one trivial test (needs some more before committing), so the usual warnings apply. But it does not change the default behavior at all, or require any changes to the main loop of the highlighting algorithm. ",
            "date": "2014-01-24T16:22:41+0000"
        },
        {
            "id": "comment-13881494",
            "author": "Michael McCandless",
            "content": "I love this approach!  Assuming the analyzer is not too costly, this ought to scale much better than \"rewrite Query up front\" workaround when the query matches tons of terms, i.e. it's less susceptible to an adversary.\n\nThe patch is surprisingly simple \n\nHow will the FakeDocsEnum.freq() lie affect the default PassageScorer?  Will this bias against passages that had an MTQ match?\n\nSo, all MTQs are squished into a single fake/virtual term for matching, like I cannot tell which of the N MTQs in my query caused the hit.  I think this is OK for starters: it's unusual (maybe?) to run multiple MTQs and to also care about which one matched each hit in the highlight.  But I guess we could instead add N virtual terms, one per MTQ... later. ",
            "date": "2014-01-24T22:30:39+0000"
        },
        {
            "id": "comment-13881548",
            "author": "Robert Muir",
            "content": "\nHow will the FakeDocsEnum.freq() lie affect the default PassageScorer? Will this bias against passages that had an MTQ match?\n\nTerribly. Yes. Its a prototype  But remember: these are typically constant-score in lucene.\n\n\nSo, all MTQs are squished into a single fake/virtual term for matching, like I cannot tell which of the N MTQs in my query caused the hit. I think this is OK for starters: it's unusual (maybe?) to run multiple MTQs and to also care about which one matched each hit in the highlight. But I guess we could instead add N virtual terms, one per MTQ... later.\n\nSame as above: its a prototype. I avoided an automaton UNION operation (scared of perf, and well, multiple MTQs are rarish). But who uses the API to look at the terms? Does telling them which MTQ matched really seem that important? (nothing in the highlighter api uses this today!!!!!!) They have the offsets to know the actual text that matched still, so i mean... I think its ok for now? \n\nIn both cases: I tried to avoid special casing this stuff (sorry, i think if you have a serious search system, then wildcards are rare), and instead add them in a non-disruptive way so that its clear it doesnt break the algorithm, which I think is generally working \"ok\". ",
            "date": "2014-01-25T00:00:58+0000"
        },
        {
            "id": "comment-13881977",
            "author": "Robert Muir",
            "content": "Updated patch, I added some more queries, some more simple tests and refactored a bit to be less intrusive to PH.\n\nStill working... ",
            "date": "2014-01-25T18:28:01+0000"
        },
        {
            "id": "comment-13881987",
            "author": "Michael McCandless",
            "content": "Does telling them which MTQ matched really seem that important? \n\nIt seems like it may be useful?  Again, I don't think it should block this addition!  It can be done later.\n\nBut e.g. with the lucene server (LUCENE-5376) when you search for \"fast lucene\" and the content was \"Lucene's PostingsHighlighter is fast\", it returns this JSON today:\n\n\n{\n \"startOffset\":0,\n \"endOffset\":41,\n \"parts\":[\n  {\n   \"term\":\"lucene\",\n   \"text\":\"Lucene's\"\n  },\n  \" new PostingsHighlighter is \",\n  {\n   \"term\":\"fast\",\n   \"text\":\"fast\"\n  },\n  \".\"\n ]\n}\n\n\n\nIe, for each \"hit\" in the snippet it tells you which term from the original query \"caused\" that hit.  So I thought it would also be useful somehow to know which MTQ caused the hit too ... later! ",
            "date": "2014-01-25T18:54:13+0000"
        },
        {
            "id": "comment-13882012",
            "author": "Robert Muir",
            "content": "Thanks Mike: I didn't realize you were using it. I can give you the string for what caused the hit, in this case I think Query.toString() is the right one (it generally matches whatever the wildcard or whatever was). Will be slightly evil, but its better than having null. ",
            "date": "2014-01-25T19:43:48+0000"
        },
        {
            "id": "comment-13882016",
            "author": "Robert Muir",
            "content": "added more tests, and fakedocsenum returns the query that matched via its payload  ",
            "date": "2014-01-25T19:52:09+0000"
        },
        {
            "id": "comment-13882023",
            "author": "Michael McCandless",
            "content": "New patch just adding a test case to show that we \"identify\" which query caused each hit ... it passes! ",
            "date": "2014-01-25T20:08:34+0000"
        },
        {
            "id": "comment-13882044",
            "author": "Robert Muir",
            "content": "Thanks for the test Mike!\n\nI prevent creating this toString() per-match, added support for SpanMTQWrapper, added tests, and added solr support.\n\nI think this is ready. ",
            "date": "2014-01-25T20:59:52+0000"
        },
        {
            "id": "comment-13882098",
            "author": "Michael McCandless",
            "content": "+1, patch looks great!  Clever to use payload to send the Query back, thank you   This way apps can know which query or term caused a given highlight hit.\n\nAlso nice to fix those unrelated crabs in span queries... ",
            "date": "2014-01-25T22:58:31+0000"
        },
        {
            "id": "comment-13882173",
            "author": "ASF subversion and git services",
            "content": "Commit 1561451 from Robert Muir in branch 'dev/trunk'\n[ https://svn.apache.org/r1561451 ]\n\nLUCENE-5415: add multitermquery support to PostingsHighlighter ",
            "date": "2014-01-26T04:49:21+0000"
        },
        {
            "id": "comment-13882178",
            "author": "ASF subversion and git services",
            "content": "Commit 1561456 from Robert Muir in branch 'dev/branches/branch_4x'\n[ https://svn.apache.org/r1561456 ]\n\nLUCENE-5415: add multitermquery support to PostingsHighlighter ",
            "date": "2014-01-26T05:07:10+0000"
        },
        {
            "id": "comment-13882179",
            "author": "Robert Muir",
            "content": "Thanks Mike ",
            "date": "2014-01-26T05:07:32+0000"
        },
        {
            "id": "comment-13887909",
            "author": "ASF subversion and git services",
            "content": "Commit 1563180 from Michael McCandless in branch 'dev/branches/lucene5376'\n[ https://svn.apache.org/r1563180 ]\n\nLUCENE-5415,LUCENE-5376: get MultiTermQuery highlighting working; fix compilation errors ",
            "date": "2014-01-31T17:16:01+0000"
        }
    ]
}