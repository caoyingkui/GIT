{
    "id": "LUCENE-1219",
    "title": "support array/offset/ length setters for Field with binary data",
    "details": {
        "labels": "",
        "priority": "Minor",
        "components": [
            "core/index"
        ],
        "type": "Improvement",
        "fix_versions": [
            "2.4"
        ],
        "affect_versions": "None",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "currently Field/Fieldable interface supports only compact, zero based byte arrays. This forces end users to create and copy content of new objects before passing them to Lucene as such fields are often of variable size. Depending on use case, this can bring far from negligible  performance  improvement. \n\nthis approach extends Fieldable interface with 3 new methods   \ngetOffset(); gettLenght(); and getBinaryValue() (this only returns reference to the array)",
    "attachments": {
        "LUCENE-1219.patch": "https://issues.apache.org/jira/secure/attachment/12377614/LUCENE-1219.patch",
        "LUCENE-1219.extended.patch": "https://issues.apache.org/jira/secure/attachment/12387817/LUCENE-1219.extended.patch",
        "LUCENE-1219.take3.patch": "https://issues.apache.org/jira/secure/attachment/12387432/LUCENE-1219.take3.patch",
        "LUCENE-1219.take2.patch": "https://issues.apache.org/jira/secure/attachment/12377760/LUCENE-1219.take2.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2008-03-11T13:22:49+0000",
            "content": "all tests pass with this patch. \n some polish needed and probably more testing, TODOs:\n\n\n\tsomeone pedantic should check if these new set / get methods should be named better\n\tcheck if there are more places where this new feature cold/should be used, I think I have changed all of them but one place, direct subclass FieldForMerge in FieldsReader, this is the code I do not know so I did not touch it...\n\tjavadoc  is poor\n\n\n\nshould be enough to get us started.\n\nthe only \"pseudo-issue\"  I see is that \npublic byte[] binaryValue(); now creates byte[] and copies content into it, reference to original array can be now fetched via getBinaryValue() method... this is to preserve compatibility as users expect compact, zero based array from this method and we keep offset/length in Field now\nthis is \"pseudo issue\" as users already should have a reference to this array, so this method is rather superfluous for end users.\n\n\n\n ",
            "author": "Eks Dev",
            "id": "comment-12577437"
        },
        {
            "date": "2008-03-11T14:07:54+0000",
            "content": "Michael McCandless had some nice ideas on how to make  getValue() change performance penalty for legacy usage negligible, this patch includes them: \n\n\tdeprecates getValue() method\n\treturns direct reference if offset==0 && length == data.length\n\n ",
            "author": "Eks Dev",
            "id": "comment-12577451"
        },
        {
            "date": "2008-03-11T18:40:19+0000",
            "content": "Hmm ... one problem is Fieldable is an interface, and this patch adds methods to the interface, which I believe breaks our backwards compatibility requirement. ",
            "author": "Michael McCandless",
            "id": "comment-12577551"
        },
        {
            "date": "2008-03-11T20:48:29+0000",
            "content": "I do not know for sure if this is something we could not live with.  Adding new interface sounds equally bad, would work nicely, but I do not like it as it makes code harder to follow with too many interfaces  ... I'll have another look at it to see if there is a way to do it without interface changes. Any ideas?     ",
            "author": "Eks Dev",
            "id": "comment-12577597"
        },
        {
            "date": "2008-03-11T21:53:24+0000",
            "content": "this one keeps addition of new methods localized to AbstractField, does not change Fieldable interface... it looks like it could work done this way with a few instanceof checks in  FieldsWriter, This one has dependency on LUCENE-1217 \n\nit will not give you any benefit if you directly implement your Fieldable without extending AbstractField, therefore   I would suggest to eventually  change Fieldable to support all these methods that operate with offset/length. Or someone clever finds some way to change an interface without braking backwards compatibility  ",
            "author": "Eks Dev",
            "id": "comment-12577620"
        },
        {
            "date": "2008-03-12T10:02:31+0000",
            "content": "latest patch updated to the trunk (Lucene-1217 is there. Michael you did not mark it as resolved.) \n ",
            "author": "Eks Dev",
            "id": "comment-12577781"
        },
        {
            "date": "2008-03-13T09:34:43+0000",
            "content": "OK I updated the patch:\n\n\n\tAdded a ctor to Field to create binary fields with length &\n    offset\n\n\n\n\n\tAdded a test case\n\n\n\n\n\tRegularized whitespace\n\n\n\n\n\tRenamed things:\n      getLength -> getBinaryLength\n      getOffset -> getBinaryOffset\n      dataOffset -> binaryOffset\n      dataLength -> binaryLength\n\n\n\nEks can you see if the changes look OK?  Thanks. ",
            "author": "Michael McCandless",
            "id": "comment-12578198"
        },
        {
            "date": "2008-03-13T09:35:41+0000",
            "content": "Alas, I'm not really happy with introducing this API at the\nAbstractField level and not in Fieldable.  It's awkward that we've\ndeprecated binaryValue() in AbstractField and not in Fieldable.  But,\nI think it's our only way forward with this issue without breaking\nbackwards compatibility.\n\nIn 3.0 I'd like to at least promote this API up into Fieldable, but\neven that is somewhat messy because I think in 3.0 we would then\ndeprecate binaryValue() and move these 3 new methods up from\nAbstractField.\n\nWhat I'd really like to do in 3.0 is change Fieldable to not be an\nabstract base class instead.\n\nQuestion: could we simply move forward without Fieldable?  Ie,\ndeprecate Fieldable right now and state that the migration path is\n\"you should subclass from AbstractField\"?  I would leave \"implements\nFieldable\" in AbstractField now, but remove it in 3.0.  As far as I\ncan tell, all uses of Fieldable in Lucene are also using\nAbstractField.\n\nI guess I don't really understand the need for Fieldable.  In fact I\nalso don't really understand why we even needed to add AbstractField.\nWhy couldn't FieldForMerge and LazyField subclass Field?  It's\nsomewhat awkward now because we have newly added APIs to Field, like\nsetValue, which probably should have been added to Fieldable. ",
            "author": "Michael McCandless",
            "id": "comment-12578199"
        },
        {
            "date": "2008-03-13T11:43:30+0000",
            "content": ">>Eks can you see if the changes look OK? Thanks.\nIt looks perfect, you have brought it to the \"commit ready status\" already.\nI will it try it on our production mirror a bit later today and report back if something goes wrong.\n\n\n>>I guess I don't really understand the need for Fieldable. In fact I\nalso don't really understand why we even needed to add AbstractField.\n\nI am with you 100% here,  It looks to me as well that one concrete class could replace it all. But... maybe someone kicks-in with some god arguments why we have it that way. ",
            "author": "Eks Dev",
            "id": "comment-12578253"
        },
        {
            "date": "2008-08-03T21:03:38+0000",
            "content": "\n\tupdated this patch to apply to trunk\n\timplemented abstract getBinary***() methods in Fieldable, and removed a few ugly instanceof AbstractField from a few places (introduced by previous versions of this patch. This was there due to  the assumption that Fieldable should stay unchanged...)\n\n\n\n\nall test pass, (as expected, only minor diff to take2 version. much like the initial version )\n ",
            "author": "Eks Dev",
            "id": "comment-12619378"
        },
        {
            "date": "2008-08-05T10:51:38+0000",
            "content": "Thanks Eks \u2013 this looks good.  I think it's ready to commit, once LUCENE-1349 is in. ",
            "author": "Michael McCandless",
            "id": "comment-12619842"
        },
        {
            "date": "2008-08-05T19:53:11+0000",
            "content": "Great Mike,\nit gets better and better, i saw LUCENE-1340 committed. Thanks to you Grant, Doug and all others that voted for 1349  this happened so quickly. Trust me, these two issues are really making my life easier. I pushed decision to add new hardware to some future point (means, save customer's money now)... a few weeks later would be too late.\n\nNow it remains only to make one nice patch that enables us to pass our own byte[] for retrieving stored fields during search. I was thinking along the lines of  things you did in Analyzers.\n\nwe could pool the same trick for this, eg.\n\nField Document.getBinaryValue(String FIELD_NAME, Field destination);\n\nField already has all access methods (get/set), \n\nthe contract would be: If destination==null, new one will be created and returned, if not we use this one and returne the same object back. The method should check if byte[] is big enough, if not simple growth policy can be there.  This way we avoid new byte[] each time you fetch stored field..\n\nI did not look exactly at code now, but the last time I was looking into it it looked as quite simple to do something along these lines. Do you have some ideas how we could do it better?\n\nJust simple calculation in my case, \naverage Hits count is around 200, for each hit we have to fetch one stored field where we do some post-processing, re-scoring and whatnot. Currently we run max 30 rq/second , with average document length of 2k you lend at 2K * 200 * 30 = 6000 object allocations per second totaling 12Mb ... only to get the data... I can imagine people with much longer documents  (that would be typical lucene use case)  where it gets worse... simply reducing gc() pressure with really small amount of work. I am sure this would have nice effects on some other use cases in lucene.\n\nthanks again to all \"workers\"  behind this greet peace of software...\neks\n\nPS:  I need to find some time to peek at paul's work in LUVENE -1345 and my wish list will be complete, at least for now (at least until you get your magic with flexi index format done   \n ",
            "author": "Eks Dev",
            "id": "comment-12620019"
        },
        {
            "date": "2008-08-08T13:53:58+0000",
            "content": "Mike, \nThis new patch includes take3  and adds the following:\n\nFieldable  Document.getStoredBinaryField(String name, byte[] scratch);\n\nwhere scratch param represents user byte buffer that will be used in case it is big enough, if not, it will be simply allocated like today. If scratch is used, you get the same object through Fieldable.getByteValue()\n\n\nfor this to work, I added one new method in Fieldable \nabstract Fieldable getBinaryField(byte[] scratch);\n\nthe only interesting implementation is in LazyField \n\nThe reason for this is in my previous comment\n\nthis does not affect issues from take3 at all, but is dependant on it, as you need to know the length of byte[] you read. take3 remains good to commit, I just did not know how to make one isolated patch with only these changes without too much work in text editor \n ",
            "author": "Eks Dev",
            "id": "comment-12620935"
        },
        {
            "date": "2008-08-08T15:41:57+0000",
            "content": "Eks, could we instead add this to Field:\n\n  byte[] binaryValue(byte[] result)\n\nand then default the current binaryValue() to just call binaryValue(null)?\n\nAnd similar in Document add:\n\n  byte[] getBinaryValue(String name, byte[] result)\n\nThese would work the same way that TokenStream.next(Token result) works, ie, the method should try to use the result passed in, if it works, and return that; else it's free to allocate its own new byte[] and return it?\n\nAnd then only LazyField's implementation of binaryValue(byte[] result) would use byte[] result if it's large enough?\n\nAlso ... it'd be nice to have a way to do this re-use in the non-lazy case.  Ie somehow load a stored doc, but passing in your own Document result which would attempt to re-use the Field instances & byte[] for the binary fields.  But we should open another issue to explore that... ",
            "author": "Michael McCandless",
            "id": "comment-12620960"
        },
        {
            "date": "2008-08-08T20:08:33+0000",
            "content": "could we instead add this to Field:\nbyte[] binaryValue(byte[] result)\n\nthis is exactly where I started, but then realized I am missing actual length we read in LazyField, without it you would have to relocate each time, except in case where your buffer length equals toRead in LazyField... simply, the question is, how the caller of   byte[] getBinaryValue(String name, byte[] result) could know what is the length in this returned byte[]\n\nAm I missing something obvious? ",
            "author": "Eks Dev",
            "id": "comment-12621036"
        },
        {
            "date": "2008-08-08T20:25:34+0000",
            "content": "Also ... it'd be nice to have a way to do this re-use in the non-lazy case. Ie somehow load a stored doc, but passing in your own Document result which would attempt to re-use the Field instances & byte[] for the binary fields.\n\nRight.  This also gets back to the fact that the Document you retrieve should probably be different than the Document that you get by loading the stored fields.\n\nSome sort of lower level callback interface to populate a Document might even eliminate the need for some of the FieldSelector stuff... or at least it would mostly be independent of the field reading code and users could create more advanced implementations. ",
            "author": "Yonik Seeley",
            "id": "comment-12621043"
        },
        {
            "date": "2008-08-08T23:56:33+0000",
            "content": "realized I am missing actual length we read in LazyField\n\nDuh, right.\n\nThough: couldn't you just call document.getFieldable(name), and then call binaryValue(byte[] result) on that Fieldable, and then get the length from it (getBinaryLength()) too?  (Trying to minimize API changes).\n\nSome sort of lower level callback interface to populate a Document might even eliminate the need for some of the FieldSelector stuff... or at least it would mostly be independent of the field reading code and users could create more advanced implementations.\n\nThis sounds interesting... but how would you re-use your own byte[] with this approach? ",
            "author": "Michael McCandless",
            "id": "comment-12621099"
        },
        {
            "date": "2008-08-09T13:15:35+0000",
            "content": "couldn't you just call document.getFieldable(name), and then call binaryValue(byte[] result) on that Fieldable, and then get the length from it (getBinaryLength()) too? (Trying to minimize API changes).\n\nsure, good tip, I this could work.  No need to have this byte[]->Fieldable-byte[] loop, it confuses. I have attached patch that uses this approach. But I created getBinaryValue(byte[]) instead of binaryValue(byte[]) as we have binaryValue() as deprecated method (would be confusing as well). Not really tested, but looks simple enough \n\nJust thinking aloud\nThis is one nice feature, but I permanently had a feeling I do not understand this Field structures, roles and responsibilities   Field/Fieldable/AbstractField hierarchy is really ripe for good re-factoring.This bigamy with index / search use cases makes things not really easy to follow, Hoss has right, we need some way to divorce RetrievedField from FieldToBeIndexed, they are definitely not the same, just very similar.    ",
            "author": "Eks Dev",
            "id": "comment-12621138"
        },
        {
            "date": "2008-08-14T10:10:43+0000",
            "content": "OK this patch looks good!  I plan to commit in a day or two.\n\n\nThis is one nice feature, but I permanently had a feeling I do not understand this Field structures, roles and responsibilities  Field/Fieldable/AbstractField hierarchy is really ripe for good re-factoring.This bigamy with index / search use cases makes things not really easy to follow, Hoss has right, we need some way to divorce RetrievedField from FieldToBeIndexed, they are definitely not the same, just very similar.\n\nI completely agree! ",
            "author": "Michael McCandless",
            "id": "comment-12622502"
        },
        {
            "date": "2008-08-18T10:32:08+0000",
            "content": "OK, this one took a rather circuitous route but it is now committed!  Thanks Eks.  ",
            "author": "Michael McCandless",
            "id": "comment-12623316"
        },
        {
            "date": "2008-08-18T12:06:46+0000",
            "content": "how was it: \"repetitio est mater studiorum\" \n\nthanks Mike! \n\n\n\n----- Original Message ----\n\n\nSend instant messages to your online friends http://uk.messenger.yahoo.com ",
            "author": "Eks Dev",
            "id": "comment-12623332"
        },
        {
            "date": "2008-08-18T18:58:21+0000",
            "content": "Eks Dev: out of curiosity, did you ever measure the before/after performance difference?  If so, what numbers did you see? ",
            "author": "Otis Gospodnetic",
            "id": "comment-12623433"
        },
        {
            "date": "2008-08-19T07:50:01+0000",
            "content": "did you ever measure the before/after performance difference?\n\nsure we did, it's been a while we measured it so I do not have the real numbers at hand. But for both cases (indexing and fetching stored binary field)  it showed up during profiling as the only easy quick-win(s) we could make . \n\nWe index very short documents and indexing speed  per thread before this patch was is in  7.5k documents/ second range, after it we run it with the patch over 9.5-10K/Second, sweet...\n\nfor searching, I do not not remember the numbers, but it was surely above 5% range  (try to allocate 12Mb in 6k objects per second as unnecessary addition and you will see it  \n ",
            "author": "Eks Dev",
            "id": "comment-12623593"
        }
    ]
}