{
    "id": "LUCENE-5215",
    "title": "Add support for FieldInfos generation",
    "details": {
        "components": [
            "core/index"
        ],
        "fix_versions": [
            "4.6",
            "6.0"
        ],
        "affect_versions": "None",
        "priority": "Major",
        "labels": "",
        "type": "New Feature",
        "resolution": "Fixed",
        "status": "Resolved"
    },
    "description": "In LUCENE-5189 we've identified few reasons to do that:\n\n\n\tIf you want to update docs' values of field 'foo', where 'foo' exists in the index, but not in a specific segment (sparse DV), we cannot allow that and have to throw a late UOE. If we could rewrite FieldInfos (with generation), this would be possible since we'd also write a new generation of FIS.\n\n\n\n\n\tWhen we apply NDV updates, we call DVF.fieldsConsumer. Currently the consumer isn't allowed to change FI.attributes because we cannot modify the existing FIS. This is implicit however, and we silently ignore any modified attributes. FieldInfos.gen will allow that too.\n\n\n\nThe idea is to add to SIPC fieldInfosGen, add to each FieldInfo a dvGen and add support for FIS generation in FieldInfosFormat, SegReader etc., like we now do for DocValues. I'll work on a patch.\n\nAlso on LUCENE-5189, Rob raised a concern about SegmentInfo.attributes that have same limitation \u2013 if a Codec modifies them, they are silently being ignored, since we don't gen the .si files. I think we can easily solve that by recording SI.attributes in SegmentInfos, so they are recorded per-commit. But I think it should be handled in a separate issue.",
    "attachments": {
        "LUCENE-5215.patch": "https://issues.apache.org/jira/secure/attachment/12603422/LUCENE-5215.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2013-09-15T14:50:19+0000",
            "content": "SI attributes may not be used at all today. It worked well for handling the 3.x integration as it was a place for us to stuff things like hasSharedDocStores and indexwriter was still able to hackishly get at it, but deprecation might be a good option. we shoudl see what is using this in trunk. ",
            "author": "Robert Muir",
            "id": "comment-13767811"
        },
        {
            "date": "2013-09-15T16:20:52+0000",
            "content": "Well, SI.attributes says it's the place for Codecs to put custom attributes in, and I remember Mike and I once discussed using them for putting some facet related stuff, but we didn't pursue it. Maybe if we record them in SIS, it's simple enough and we can keep them? If they are meant to be used by Codecs only, then maybe we can force Codecs to manage them themselves, but if e.g. some other code will want to rely on them, would it be possible? ",
            "author": "Shai Erera",
            "id": "comment-13767831"
        },
        {
            "date": "2013-09-15T16:28:05+0000",
            "content": "Yes but the issue is that they are write-once. \n\nIf a codec component that needs attributes (e.g. a dv one) was to write this stuff in its own file, it would work with updates because of segment suffix. \n\nAdditionally we already have per-commit Map<String,String>: the one used by setCommitData(Map<String,String> commitUserData)... ",
            "author": "Robert Muir",
            "id": "comment-13767832"
        },
        {
            "date": "2013-09-15T16:32:46+0000",
            "content": "Anyway I agree we should spin off a separate issue for this... this issue for fieldinfos will be fun enough by itself  ",
            "author": "Robert Muir",
            "id": "comment-13767836"
        },
        {
            "date": "2013-09-15T19:54:40+0000",
            "content": "I started by creating a new Lucene46Codec and matching Lucene46FieldInfosFormat (+reader/writer). There is an API issue with FISFormat - it doesn't take segmentSuffix in neither FISReader.read() nor FISWriter.write(). We need to make an API break and I'm thinking if we want to do it big time and pass SegRead/WriteState already, instead of adding just one parameter? To be consistent with the other formats (well, as much as possible - the other formats take SRS/SWS and pass to their reader/writer). ",
            "author": "Shai Erera",
            "id": "comment-13767887"
        },
        {
            "date": "2013-09-15T21:40:15+0000",
            "content": "No, they dont take this and for damn good reason: SRS/SWS contain fieldinfos.  ",
            "author": "Robert Muir",
            "id": "comment-13767921"
        },
        {
            "date": "2013-09-16T03:49:34+0000",
            "content": "It's ok that SWS contains fieldInfos - FieldsWriter needs to write them. And I don't think it's bad SRS contains fieldInfos, we can just assert in FieldsReader that they are null? ",
            "author": "Shai Erera",
            "id": "comment-13768041"
        },
        {
            "date": "2013-09-16T04:10:37+0000",
            "content": "Sorry, that would be horribly really confusing.\n\nSegmentRead/Write state are for the data portions of the codec: postings, vectors, ...\nthey have all metadata available at this point, so it makes sense.\n\nHowever these metadata portions are \"bootstrapped\" do not. they only have limited things available. The api should only pass what they actually have access to: no nulls! ",
            "author": "Robert Muir",
            "id": "comment-13768049"
        },
        {
            "date": "2013-09-16T06:46:17+0000",
            "content": "Ok I'll add just segmentSuffix ",
            "author": "Shai Erera",
            "id": "comment-13768107"
        },
        {
            "date": "2013-09-16T20:34:45+0000",
            "content": "Patch adds FieldInfos generation:\n\n\n\tSegmentInfoPerCommit manages fieldInfosGen; SegmentInfos read/write it, like delGen.\n\t\n\t\tUpdated SegmentInfos format jdocs\n\t\n\t\n\tReaderAndLiveDocs writes a new FIS generation if there are DV updates, also updates existing FIs dvGen.\n\t\n\t\tWe now support updating documents in segments where the field wasn't indexed (sparse DV).\n\t\n\t\n\tNew Lucene46Codec and Lucene46FieldInfosFormat for writing the dvGen per field in the fnm file.\n\t\n\t\tUpdated package.html\n\t\tUpdated FieldInfosFormat jdocs\n\t\tDeprecated Lucene45Codec, moved Lucene42FieldInfosWriter to test-framework, added Lucene45RWCodec\n\t\n\t\n\tAdded a static utility method to SegmentReader to readFieldInfos from SIPC, since a couple of places in the code needed to execute same logic.\n\tAdded segmentSuffix to FieldsReader/Writer.\n\n\n\nMost of the changes in the patch are due to the new Lucene46Codec. I couldn't test FIS.gen without making all the other changes (Lucene45Codec deprecation etc.) because I didn't feel running tests with e.g. -Dtests.codec=Lucene46 is enough. So the patch is big, but if you want to review the FIS.gen changes, you should look at: Lucene46Codec, Lucene46FieldInfosFormat, ReaderAndLiveDocs, SIPC, SIS.\n\nCore tests pass, so I think it's ready for a review. Also, do I understand correctly that a 4.5 index for TestBackcompat will be created when we release 4.6 (if that issue makes it to 4.6)? ",
            "author": "Shai Erera",
            "id": "comment-13768724"
        },
        {
            "date": "2013-09-20T05:07:56+0000",
            "content": "Patch removes Facet45Codec, updates jdocs and updates to latest trunk changes. ",
            "author": "Shai Erera",
            "id": "comment-13772633"
        },
        {
            "date": "2013-09-20T09:34:13+0000",
            "content": "Fixed BasePostingsFormatTestCase to initialize Lucene46Codec (not 45). It was the last piece of code which still used the now deprecated Lucene45. All Lucene and Solr tests pass, so I think this is ready.\n\nBTW, I noticed that TestBackCompat suppresses Lucene41 and Lucene42. I ran it with -Dtests.codec=Lucene45 and it passed, so I'm not sure if I should add the now deprecated Lucene45Codec to the suppress list? ",
            "author": "Shai Erera",
            "id": "comment-13772905"
        },
        {
            "date": "2013-09-20T22:56:07+0000",
            "content": "Could you make the patch with --show-copies-as-adds?  Thanks! ",
            "author": "Michael McCandless",
            "id": "comment-13773566"
        },
        {
            "date": "2013-09-21T03:43:35+0000",
            "content": "Patch with --show-copies-as-adds ",
            "author": "Shai Erera",
            "id": "comment-13773711"
        },
        {
            "date": "2013-09-21T17:10:34+0000",
            "content": "BTW, I noticed that TestBackCompat suppresses Lucene41 and Lucene42. I ran it with -Dtests.codec=Lucene45 and it passed, so I'm not sure if I should add the now deprecated Lucene45Codec to the suppress list?\n\nI think just add Lucene45Codec to the suppress list?  This test is already testing old indices ... it doesn't need to then test that writing (using the impersonators) to old formats works ok?  I think? ",
            "author": "Michael McCandless",
            "id": "comment-13773854"
        },
        {
            "date": "2013-09-21T19:37:28+0000",
            "content": "Ok done. ",
            "author": "Shai Erera",
            "id": "comment-13773879"
        },
        {
            "date": "2013-09-21T21:28:28+0000",
            "content": "Net/net I think this is a good change ... I think it's cleaner that\neach (gen'd) FieldInfo stores the long dvGen, rather than the\nMap<Int,Long> we now have in SIPC.  It also means we can gen other\nper-field changes in the future, and it solves the sparse-fields\nupdates limitation.\n\nNice to see the controversial boolean is now gone:\n\n-  /** True is this instance represents a field update. */\n-  public final boolean isFieldUpdate; // TODO (DVU_FIELDINFOS_GEN) once we gen FieldInfos, get rid of this\n-  \n\n\n\nMaybe mark SegmentReader.readFieldInfos as @internal?\n\nIt's a little spooky that both SegmentCoreReaders and SegmentReader\nhas a FieldInfos?  Can we somehow remove the one in SCR?  Seems like\nonly the ctor and one method use it?\n\nI like the consolidation down to the single\nSegmentReader.readFieldInfos method, but it looks like we are now\ndouble-opening the CFS file, because SegmentCoreReaders opens it once,\nthen SegmentReader.readFieldInfos opens it (and quickly closes it)\nagain?\n\nWe really should rename RLD.writeLiveDocs!  It does so much more now \n\nIn TestNumericDocValuesUpdates.java, there's a missing a space between\n\"document\" and \"in\":\n\n\n     // update documentin the second segment\n\n ",
            "author": "Michael McCandless",
            "id": "comment-13773910"
        },
        {
            "date": "2013-09-22T14:37:25+0000",
            "content": "Maybe mark SegmentReader.readFieldInfos as @internal?\n\nGood idea, done.\n\nWe really should rename RLD.writeLiveDocs! It does so much more now\n\nI agree. There's a TODO which I'll take care of before merging to 4x (there are other renames too).\n\nIt's a little spooky that both SegmentCoreReaders and SegmentReader has a FieldInfos\n\nYes, that crossed my mind too. I was thinking perhaps SR.ctor can read it and pass to SCR.ctor?\n\nit looks like we are now double-opening the CFS file\n\nCorrect. It's also called from IndexWriter, which opened CFS if needed, therefore I thought it's not so critical. Also, note that SR uses SCR.cfsReader to read the gen'd DVP. But if I move reading FIS to SR only and pass to SCR, we won't be able to use SCR.cfsReader (as it's not initialized yet). How bad is it?\n\nIn TestNumericDocValuesUpdates.java, there's a missing a space between \"document\" and \"in\"\n\nFixed, thanks! ",
            "author": "Shai Erera",
            "id": "comment-13774012"
        },
        {
            "date": "2013-09-22T18:02:40+0000",
            "content": "SegmentCoreReaders no longer reads FieldInfos, but rather takes it from owner.fieldInfos. SegmentReader reads FieldInfos before initializing SegCoreReaders. It still opens a CFS and closes, if needed. ",
            "author": "Shai Erera",
            "id": "comment-13774021"
        },
        {
            "date": "2013-09-23T11:25:28+0000",
            "content": "Hmm, could we remove SCR.fieldInfos entirely?  And, pass it into ctor (passing null if it's not \"shared\"), and also into .getNormValues (it's only SegmentReader that calls this)?\n\n\nit looks like we are now double-opening the CFS file\n\nCorrect. It's also called from IndexWriter, which opened CFS if needed, therefore I thought it's not so critical.\n\nI'm less worried about IW, which does this once on open; apps \"typically\" open an IW and use it for a long time, opening many NRT readers from it.\n\nBut I don't like adding this double-open to SR's open path (SR's are \"typically\" opened more frequently than IWs), if we can help it.\n\nI mean technically I guess it's an optimization to not double-open the CFS file ... so we could instead open a follow-on issue to try to fix it. ",
            "author": "Michael McCandless",
            "id": "comment-13774471"
        },
        {
            "date": "2013-09-23T12:50:51+0000",
            "content": "could we remove SCR.fieldInfos entirely?\n\nDone.\n\nI mean technically I guess it's an optimization\n\nThe problem is that it's a chicken-and-egg problem: SR needs to open the CFS in order to read the FieldInfos, but doesn't need to hold it open. SCR needs the CFS for reading the various formats, but we must read FIS before we init SCR.\n\nNote that we only do this double-open in case we open a new SegReader, never when we share a reader (then, if we need to read FIS, it's always outside CFS, cause it must be gen'd). In that case, maybe it's not so bad to do this double-open? I put a TODO in the code for now. ",
            "author": "Shai Erera",
            "id": "comment-13774516"
        },
        {
            "date": "2013-09-25T06:12:57+0000",
            "content": "initial thoughts after one pass:\nmuch simpler than I imagined...\n\nthe changes to FieldInfosReader/Writer seem intuitive and obvious! this looks great.\n\nthanks for taking care of the new 46Codec, i know how much of a pain this is. admittedly i didnt do a review \"e.g. search for 4.5, Lucene45, such strings in eclipse\", but thats normally the stuff i do here. I dont see problems, just be paranoid \nI'm glad to see the feature listed under Lucene46Codec as a major structural change to the index.\n\nIn perFieldDocValuesFormat where we have suffixAtt = Integer.valueOf(suffixAtt);, do we have any concerns? since its serialized as a string att, maybe we should upgrade\nto long now and have no worries? Then again we can always do this later...\n\nThe changes to R&LDocs i wont attempt here, thats more Mike's forte anyway! Unfortunately this is the key to the whole patch and the most important thing to think about, ill try to apply it and take a second swipe unless mike beats me to it...\n\nOne thing i noticed from API perspective: the SegmentReader.readFieldInfos seems an awkward place to me for this: must it really be public or can it be package-private? I dont want to block the change on this (especially as I have no obvious clear suggestion to give), but I'm just worried its the right place.\n\nwherever you see @Deprecated (eg Lucene45Codec) ensure @deprecated <reason> in javadocs too. ",
            "author": "Robert Muir",
            "id": "comment-13777189"
        },
        {
            "date": "2013-09-25T08:43:22+0000",
            "content": "e.g. search for 4.5, Lucene45, such strings in eclipse\n\nGood idea. I searched for references to Lucene45Codec, and fixed them. I now searched for \"4.5\", \"45\" and \"lucene45\" and found few other places to fix.\n\nwherever you see @Deprecated (eg Lucene45Codec) ensure @deprecated <reason> in javadocs too\n\ndone.\n\nthe SegmentReader.readFieldInfos seems an awkward place to me for this: must it really be public or can it be package-private?\n\nI tried to find a good place for it too, and chose SegmentReader since it's mostly needed by it. As for package-private, it's also accessed by _TestUtil.getFieldInfos, but I see the only tests that call it are under o.a.l.index, so I think for now we can make it package-private and get rid of _TestUtil.getFieldInfos? Note that it's also marked @lucene.internal.\n\nIn perFieldDocValuesFormat where we have suffixAtt = Integer.valueOf(suffixAtt);, do we have any concerns?\n\nIsn't it increased per unique format? I don't mind changing it to a long, but do we really expect more than Integer.MAX_VAL formats!? ",
            "author": "Shai Erera",
            "id": "comment-13777279"
        },
        {
            "date": "2013-09-25T11:15:48+0000",
            "content": "The RLD changes look great to me! ",
            "author": "Michael McCandless",
            "id": "comment-13777362"
        },
        {
            "date": "2013-09-25T14:47:30+0000",
            "content": "Fixed some places which referenced Lucene45 (javadocs, comments etc.). Also made SR.readFieldInfos package-private, and added a deprecation comment to the new deprecated classes.\n\nI still didn't change PerField to use Long instead of Integer. Rob, if you think it's important, I'll do it, should be easy. Otherwise, I think it's ready to go in. I'll run some tests first. ",
            "author": "Shai Erera",
            "id": "comment-13777566"
        },
        {
            "date": "2013-09-26T07:01:09+0000",
            "content": "As long as its just bound by #formats and not influenced by generation number, no reason to touch. please proceed \n\nIMO we can then tackle the segmentinfos attributes issue (i recommend removal/simple solution here) and get all this baking and devise a plan to get this feature as a whole backported into our stable branch. ",
            "author": "Robert Muir",
            "id": "comment-13778532"
        },
        {
            "date": "2013-09-26T13:27:13+0000",
            "content": "As long as its just bound by #formats and not influenced by generation number, no reason to touch\n\nYes, the suffix isn't affected by the generation number. The generation is appended to the filename, outside PerField.\n\n\nIMO we can then tackle the segmentinfos attributes issue (i recommend removal/simple solution here) and get all this baking and devise a plan to get this feature as a whole backported into our stable branch.\n\nI think we should finish this, handle SI.attributes (LUCENE-5216) and then backport each issue separately, so that the commits are associated with the respective issues. Still, do all the backports together, but just separate the commmits according to the issues. What do you think? ",
            "author": "Shai Erera",
            "id": "comment-13778764"
        },
        {
            "date": "2013-09-28T06:19:02+0000",
            "content": "Commit 1527154 from Shai Erera in branch 'dev/trunk'\n[ https://svn.apache.org/r1527154 ]\n\nLUCENE-5215: Add support for FieldInfos generation ",
            "author": "ASF subversion and git services",
            "id": "comment-13780721"
        },
        {
            "date": "2013-09-28T06:21:49+0000",
            "content": "Committed to trunk. I'll move on to LUCENE-5216 ",
            "author": "Shai Erera",
            "id": "comment-13780722"
        },
        {
            "date": "2013-09-29T14:21:31+0000",
            "content": "Patch for the compile error mentioned by Paul. ",
            "author": "Han Jiang",
            "id": "comment-13781388"
        },
        {
            "date": "2013-09-29T14:44:17+0000",
            "content": "Why didn't I get any error though while running tests for this issue? These changes seem to affect when running tests with -Dtests.codec=Lucene45, right? But Paul hits a compilation error ... At any rate, I think it's a valid change, so +1 to commit. Just please make sure to attach the commit to this issue, so I remember to backport it to 4x along with the other commits. ",
            "author": "Shai Erera",
            "id": "comment-13781391"
        },
        {
            "date": "2013-09-29T14:51:09+0000",
            "content": "Commit 1527332 from Han Jiang in branch 'dev/trunk'\n[ https://svn.apache.org/r1527332 ]\n\nLUCENE-5215: resolve compilation error ",
            "author": "ASF subversion and git services",
            "id": "comment-13781393"
        },
        {
            "date": "2013-09-29T14:58:09+0000",
            "content": "Thanks Han, though I wish the commit message wasn't \"resolve compilation error\" as this doesn't fix any compilation error . Neither Jenkins nor my machines hit any compilation errors ... I believe Paul messed up somehow his environment, not 'svn up' from the root, or not cleaning properly. ",
            "author": "Shai Erera",
            "id": "comment-13781397"
        },
        {
            "date": "2013-09-29T15:17:07+0000",
            "content": "I guess so  ",
            "author": "Han Jiang",
            "id": "comment-13781405"
        },
        {
            "date": "2013-11-14T15:59:04+0000",
            "content": "Committed to 4x under LUCENE-5189. ",
            "author": "Shai Erera",
            "id": "comment-13822541"
        }
    ]
}