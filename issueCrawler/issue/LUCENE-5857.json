{
    "id": "LUCENE-5857",
    "title": "make genLookaheadCountLimit configurable, add genLookbackCountLimit parameter",
    "details": {
        "type": "Improvement",
        "priority": "Major",
        "labels": "",
        "resolution": "Duplicate",
        "components": [],
        "affect_versions": "None",
        "status": "Resolved",
        "fix_versions": []
    },
    "description": "The problem we saw was that an error-in-final-commit during solr-shutdown led to a corrupted segments_.... file which prevented subsequent solr-start, details below.\n\nthis change:\n\n\tadds genLookbackCountLimit similar to the existing genLookaheadCountLimit\n\tmakes both parameters configurable (initial values defaulted to existing behaviour)\n\n\n\nerror-in-final-commit result:\n\n\tsegments_2fi5 file present and zero-bytes long (https://issues.apache.org/jira/i#browse/SOLR-6296 concerns root cause)\n\tsegments_2fi4 file absent on disk (speculation: 2fi4 was result of in-memory segment merging)\n\tsegments_2fi3 file present and usable (but not found by existing looking-logic)\n\tsegments.gen file referenced 2fi3",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "id": "comment-14078063",
            "author": "ASF GitHub Bot",
            "content": "GitHub user cpoerschke opened a pull request:\n\n    https://github.com/apache/lucene-solr/pull/76\n\n    LUCENE-5857: genLookaheadCountLimit configurable, add genLookbackCountLimit\n\n    https://issues.apache.org/jira/i#browse/LUCENE-5857\n\nYou can merge this pull request into a Git repository by running:\n\n    $ git pull https://github.com/bloomberg/lucene-solr trunk-gen-look-lucene\n\nAlternatively you can review and apply these changes as the patch at:\n\n    https://github.com/apache/lucene-solr/pull/76.patch\n\nTo close this pull request, make a commit to your master/trunk branch\nwith (at least) the following in the commit message:\n\n    This closes #76\n\n\ncommit 47693ccdef418de0d3bb419a5071516e203a1de6\nAuthor: Christine Poerschke <cpoerschke@bloomberg.net>\nDate:   2014-06-17T18:40:48Z\n\n    lucene: make genLookaheadCountLimit configurable, add genLookbackCountLimit parameter\n\n    The problem we saw was that an error-in-final-commit during solr-shutdown led to a corrupted segments_.... file which prevented subsequent solr-start, details below.\n\n    this change:\n\n\tadds genLookbackCountLimit similar to the existing genLookaheadCountLimit\n\tmakes both parameters configurable (initial values defaulted to existing behaviour)\n\n\n\n    error-in-final-commit result:\n\n\tsegments_2fi5 file present and zero-bytes long\n\tsegments_2fi4 file absent on disk (speculation: 2fi4 was result of in-memory segment merging)\n\tsegments_2fi3 file present and usable (but not found by existing looking-logic)\n\tsegments.gen file referenced 2fi3\n\n\n\n    solr-start failure details:\n\n    ERROR [coreLoadExecutor-4-thread-6] o.a.s.c.CoreContainer [CoreContainer.java:910] Unable to create core: collection_shard_replica\n    org.apache.solr.common.SolrException: Error opening new searcher\n    \tat org.apache.solr.core.SolrCore.<init>(SolrCore.java:858)\n    \tat org.apache.solr.core.SolrCore.<init>(SolrCore.java:641)\n    \tat org.apache.solr.core.CoreContainer.create(CoreContainer.java:556)\n    \tat org.apache.solr.core.CoreContainer$1.call(CoreContainer.java:261)\n    \tat org.apache.solr.core.CoreContainer$1.call(CoreContainer.java:253)\n    \tat java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334) [na:1.7.0_10]\n    \tat java.util.concurrent.FutureTask.run(FutureTask.java:166) [na:1.7.0_10]\n    \tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) [na:1.7.0_10]\n    \tat java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334) [na:1.7.0_10]\n    \tat java.util.concurrent.FutureTask.run(FutureTask.java:166) [na:1.7.0_10]\n    \tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110) [na:1.7.0_10]\n    \tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603) [na:1.7.0_10]\n    \tat java.lang.Thread.run(Thread.java:722) [na:1.7.0_10]\n    Caused by: org.apache.solr.common.SolrException: Error opening new searcher\n    \tat org.apache.solr.core.SolrCore.openNewSearcher(SolrCore.java:1550)\n    \tat org.apache.solr.core.SolrCore.getSearcher(SolrCore.java:1662)\n    \tat org.apache.solr.core.SolrCore.<init>(SolrCore.java:838)\n    \t... 12 common frames omitted\n    Caused by: java.io.EOFException: read past EOF: MMapIndexInput(path=\"/dir/collection_shard_replica/data/index.YYYYMMDDHHMMSSMMM/segments_2fi5\")\n    \tat org.apache.lucene.store.ByteBufferIndexInput.readByte(ByteBufferIndexInput.java:78)\n    \tat org.apache.lucene.store.BufferedChecksumIndexInput.readByte(BufferedChecksumIndexInput.java:41)\n    \tat org.apache.lucene.store.DataInput.readInt(DataInput.java:96)\n    \tat org.apache.lucene.index.SegmentInfos.read(SegmentInfos.java:331)\n    \tat org.apache.lucene.index.SegmentInfos$1.doBody(SegmentInfos.java:416)\n    \tat org.apache.lucene.index.SegmentInfos$FindSegmentsFile.run(SegmentInfos.java:864)\n    \tat org.apache.lucene.index.SegmentInfos$FindSegmentsFile.run(SegmentInfos.java:710)\n    \tat org.apache.lucene.index.SegmentInfos.read(SegmentInfos.java:412)\n    \tat org.apache.lucene.index.IndexWriter.<init>(IndexWriter.java:749)\n    \tat org.apache.solr.update.SolrIndexWriter.<init>(SolrIndexWriter.java:77)\n    \tat org.apache.solr.update.SolrIndexWriter.create(SolrIndexWriter.java:64)\n    \tat org.apache.solr.update.DefaultSolrCoreState.createMainIndexWriter(DefaultSolrCoreState.java:267)\n    \tat org.apache.solr.update.DefaultSolrCoreState.getIndexWriter(DefaultSolrCoreState.java:110)\n    \tat org.apache.solr.core.SolrCore.openNewSearcher(SolrCore.java:1513)\n    \t... 14 common frames omitted\n    ERROR [coreLoadExecutor-4-thread-6] o.a.s.c.CoreContainer [SolrException.java:120] null:org.apache.solr.common.SolrException: Unable to create core: collection_shard_replica\n    \tat org.apache.solr.core.CoreContainer.recordAndThrow(CoreContainer.java:911)\n    \tat org.apache.solr.core.CoreContainer.create(CoreContainer.java:568)\n    \tat org.apache.solr.core.CoreContainer$1.call(CoreContainer.java:261)\n    \tat org.apache.solr.core.CoreContainer$1.call(CoreContainer.java:253)\n    \tat java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)\n    \tat java.util.concurrent.FutureTask.run(FutureTask.java:166)\n    \tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n    \tat java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)\n    \tat java.util.concurrent.FutureTask.run(FutureTask.java:166)\n    \tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)\n    \tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)\n    \tat java.lang.Thread.run(Thread.java:722)\n    Caused by: org.apache.solr.common.SolrException: Error opening new searcher\n    \tat org.apache.solr.core.SolrCore.<init>(SolrCore.java:858)\n    \tat org.apache.solr.core.SolrCore.<init>(SolrCore.java:641)\n    \tat org.apache.solr.core.CoreContainer.create(CoreContainer.java:556)\n    \t... 10 more\n    Caused by: org.apache.solr.common.SolrException: Error opening new searcher\n    \tat org.apache.solr.core.SolrCore.openNewSearcher(SolrCore.java:1550)\n    \tat org.apache.solr.core.SolrCore.getSearcher(SolrCore.java:1662)\n    \tat org.apache.solr.core.SolrCore.<init>(SolrCore.java:838)\n    \t... 12 more\n\n ",
            "date": "2014-07-29T17:47:17+0000"
        },
        {
            "id": "comment-14079112",
            "author": "Michael McCandless",
            "content": "It's somewhat dangerous to add this logic to try up to N commits backwards, e.g. in an app that saves multiple commit points, this could silently lose data if there is a transient IOException loading the \"true\" segments_N file.  It's already spooky enough that Lucene tries up to N commits forwards...\n\nBut maybe we could fix the logic to explicitly try the segments_N that segments.gen is pointing to?  That would have worked in this case.\n\nI'd like to understand how this index \"happened\", e.g.:\n\n(speculation: 2fi4 was result of in-memory segment merging)\n\nThat shouldn't be the case: merging does not write segments_N files.  Only an explicit commit/IW.close/shutdown does that.\n\nHmm maybe on hitting an exception while committing, Solr later tries to commit again instead of rollback? ",
            "date": "2014-07-30T09:38:39+0000"
        },
        {
            "id": "comment-14079123",
            "author": "Ramkumar Aiyengar",
            "content": "It's somewhat dangerous to add this logic to try up to N commits backwards, e.g. in an app that saves multiple commit points, this could silently lose data if there is a transient IOException loading the \"true\" segments_N file. It's already spooky enough that Lucene tries up to N commits forwards...\n\nWe had initially considered trying up to N commits backwards but not going behind segments.gen.\n\nThe application has a very short soft commit interval (125ms) and a longer hard commit. Couldn't it happen that there was a soft commit, and the following hard commit was interrupted? See SOLR-6296 for the stack which was interrupted by Solr, IW.close was interrupted during fsync, that would have tried to sync two segments_N files right? ",
            "date": "2014-07-30T09:58:37+0000"
        },
        {
            "id": "comment-14122985",
            "author": "Ramkumar Aiyengar",
            "content": "Robert Muir, does LUCENE-5925 do away with the need for this issue? ",
            "date": "2014-09-05T14:13:28+0000"
        },
        {
            "id": "comment-14122987",
            "author": "Robert Muir",
            "content": "Yes, i propose removing fallback logic completely. ",
            "date": "2014-09-05T14:16:27+0000"
        },
        {
            "id": "comment-14229177",
            "author": "Robert Muir",
            "content": "commit is atomic as of LUCENE-5925, so we don't have to deal with fallback. lookahead limit is removed, spinlock loop just retries as long as there is forward progress. IndexWriter init no longer does any of this since it has write.lock. ",
            "date": "2014-11-30T17:50:41+0000"
        },
        {
            "id": "comment-15094546",
            "author": "ASF GitHub Bot",
            "content": "Github user cpoerschke closed the pull request at:\n\n    https://github.com/apache/lucene-solr/pull/76 ",
            "date": "2016-01-12T19:10:24+0000"
        }
    ]
}