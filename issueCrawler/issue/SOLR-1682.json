{
    "id": "SOLR-1682",
    "title": "Implement CollapseComponent",
    "details": {
        "affect_versions": "None",
        "status": "Closed",
        "fix_versions": [
            "3.4",
            "4.0-ALPHA"
        ],
        "components": [
            "search"
        ],
        "type": "Sub-task",
        "priority": "Major",
        "labels": "",
        "resolution": "Fixed"
    },
    "description": "Child issue of SOLR-236. This issue is dedicated to field collapsing in general and all its code (CollapseComponent, DocumentCollapsers and CollapseCollectors). The main goal is the finalize the request parameters and response format.",
    "attachments": {
        "SOLR-1682_prototype.patch": "https://issues.apache.org/jira/secure/attachment/12448137/SOLR-1682_prototype.patch",
        "SOLR-1682.patch": "https://issues.apache.org/jira/secure/attachment/12429403/SOLR-1682.patch",
        "SOLR-236.patch": "https://issues.apache.org/jira/secure/attachment/12429131/SOLR-236.patch",
        "field-collapsing.patch": "https://issues.apache.org/jira/secure/attachment/12428656/field-collapsing.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Martijn van Groningen",
            "id": "comment-12793353",
            "date": "2009-12-21T20:45:16+0000",
            "content": "The code taken from the latest patch in SOLR-236. "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12793957",
            "date": "2009-12-23T07:17:25+0000",
            "content": "Isn't this issue the same as SOLR-236? It is better to have patches in one place than two. Lets close this one "
        },
        {
            "author": "Martijn van Groningen",
            "id": "comment-12793966",
            "date": "2009-12-23T08:01:02+0000",
            "content": "Well it is the core functionality without the changes to the core, changes to SolrJ and distributed field collapsing code. So it is not exactly the same. "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12795279",
            "date": "2009-12-30T10:41:06+0000",
            "content": "Here's an implementation based on Yonik's suggestion.\n\nThis is just a PoC and not fit to be committed. This implementation uses one pass for collapse.threshold=1 and two passes for collapse.threshold>1 so it should be a lot faster than the previous method. Though, I haven't benchmarked yet. Memory consumption should be proportional to start+count instead of index size.\n\nWhat is covered:\n\n\tNon-adjacent collapsing\n\tcollapse.threshold\n\tNew response format\n\tIncludes DocSetAwareCollector interface from SOLR-1680\n\n\n\nWhat is not covered:\n\n\tAdjacent collapsing\n\tAggregate functions (should be easy to add)\n\tFaceting (it doesn't keep/return the docsets needed for FacetComponent)\n\tCaching\n\tThis implementation does not return the correct numFound\n\n\n\nThe response adds special fields to only the first document in a group. Here's a sample of the first document in a group:\n\n<doc>\n      <int name=\"id\">1</int>\n      <str name=\"name_s1\">author1</str>\n      <str name=\"title_s1\">a tree</str>\n      <date name=\"timestamp\">2009-12-30T10:16:51.944Z</date>\n      <arr name=\"multiDefault\">\n        <str>muLti-Default</str>\n      </arr>\n      <int name=\"intDefault\">42</int>\n      <str name=\"collapse.value\">author1</str>\n      <int name=\"collapse.count\">1</int>\n      <float name=\"score\">0.67107505</float>\n    </doc>\n\n\n\nSee TestCollapseComponent.java for example usage. "
        },
        {
            "author": "Martijn van Groningen",
            "id": "comment-12796452",
            "date": "2010-01-05T00:31:40+0000",
            "content": "Shalin, I tried your patch out and I ran into a few problems with sorting and the collapse counts which turned out to be bugs.\n\n\tWhen I was sorting in ascending order(on a field or score), the order was itself was incorrect.\n\tThe collapse count was always one (when threshold=1 which is default was specified). I suppose the count should increment every time a document is collapsed.\n\n\n\nI fixed these issues in the new patch and added tests that show that.\n\nThough I have a question about the response format. When collapse.threshold is > 1 and more than one documents is collapsed then the collapse.count is named group.size. The field group.numFound is then added as well. Why did you gave it a different name?\n\nWhen collapse.threshold is larger than one two collectors are used. I understand that in both situations a different algorithm is used. But now also a search is done twice. Shouldn't it be better to have two complete distinct collectors that don't depend on one another? "
        },
        {
            "author": "Noble Paul",
            "id": "comment-12796529",
            "date": "2010-01-05T05:25:12+0000",
            "content": "\n\nBut now also a search is done twice. Shouldn't it be better to have two complete distinct collectors that don't depend on one another?\n\nBoth the collectors are designed to complement each other so that one can piggyback on other and minimize the code/work\n\nThe field group.numFound is then added as well. Why did you gave it a different name?\n\nThe names are up for debate . Let us reach a consensus on that . When collapse.threshhold=1 collapse.cout/collapse.groupSize can be avoided "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12799180",
            "date": "2010-01-12T12:41:39+0000",
            "content": "Shalin, I tried your patch out and I ran into a few problems with sorting and the collapse counts which turned out to be bugs. \n\nThanks Martijn.\n\n\nThough I have a question about the response format. When collapse.threshold is > 1 and more than one documents is collapsed then the collapse.count is named group.size. The field group.numFound is then added as well. Why did you gave it a different name?\n\nActually I intended to rename \"collapse.value\" to \"group.value\" and \"collapse.count\" to \"group.numFound\" but I forgot to do it in both the places.\n\n\tgroup.numFound = the total number of documents belonging to this group (i.e. have the same group.value)\n\tgroup.size = the number of documents in this result set belonging to the same group  which is equal to min(group.numFound, collapse.threshold)\n\n\n\nSo when collapse.threshold = 1, group.size=1 and group.numFound will be equal to the number of documents in the same group. Suppose collapse.threshold = 5, but group.numFound=4 then group.size=4. The group.size is required to read all docs belonging to the same group without having to maintain a set. Let me know if you have suggestions for a better name than these.\n\n\nWhen collapse.threshold is larger than one two collectors are used. I understand that in both situations a different algorithm is used. But now also a search is done twice. Shouldn't it be better to have two complete distinct collectors that don't depend on one another?\n\nWe can have distinct collectors. The CollapsedDocCollector uses some of the data that TopGroupCollector gathers and that is why it uses it directly. We could keep references to the individual objects that are needed too. As I said, this is just a PoC and not the final design.\n\nI'll give a new patch with the names fixed for both the cases. "
        },
        {
            "author": "Shalin Shekhar Mangar",
            "id": "comment-12799192",
            "date": "2010-01-12T13:26:56+0000",
            "content": "Patch which fixes the inconsistent names for the meta fields. "
        },
        {
            "author": "Lance Norskog",
            "id": "comment-12867944",
            "date": "2010-05-16T03:14:11+0000",
            "content": "What's the status on this? Has this patch served its purpose in life? Should it grow into a committable patch? "
        },
        {
            "author": "Hoss Man",
            "id": "comment-12872481",
            "date": "2010-05-27T22:06:13+0000",
            "content": "Bulk updating 240 Solr issues to set the Fix Version to \"next\" per the process outlined in this email...\n\nhttp://mail-archives.apache.org/mod_mbox/lucene-dev/201005.mbox/%3Calpine.DEB.1.10.1005251052040.24672@radix.cryptio.net%3E\n\nSelection criteria was \"Unresolved\" with a Fix Version of 1.5, 1.6, 3.1, or 4.0.  email notifications were suppressed.\n\nA unique token for finding these 240 issues in the future: hossversioncleanup20100527 "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12882877",
            "date": "2010-06-26T18:29:58+0000",
            "content": "Here's an early prototype of mine, updated to trunk.  It's designed to collapsing on an arbitrary function (value source).  It only implements the first-phase level-1 collapsing, and assumes a single comparator for simplicity.\n\nThe previous patches here (which I've just now started looking at) look pretty solid.  It's surprising how similar the first level collapse is (how a single field comparator group used for everything, defer building the treeset, etc).\n\nI have some time to work on this now... I think I'll approach it by merging this patch with mine, working on getting a single collapse option working well enough to commit.  The original SOLR-236 is simply too big and it feels like there are too many options to grapple with at the same time. "
        },
        {
            "author": "Martijn van Groningen",
            "id": "comment-12883718",
            "date": "2010-06-29T21:43:22+0000",
            "content": "I checked out the patch and I had to make a two changes to make it working (the new patch attached contains the changes):\n\n\tIn the buildSet method i changed the comparator to this:\n\nComparator<SearchGroup1> comparator = new Comparator<SearchGroup1>() {\n      public int compare(SearchGroup1 o1, SearchGroup1 o2) {\n        int comp =  fc.compare(o1.comparatorSlot, o2.comparatorSlot);\n        if (comp != 0) {\n          return comp;\n        }\n        if (o1.topDoc < o2.topDoc) {\n          return 1;\n        } else if (o1.topDoc > o2.topDoc) {\n          return -1;\n        }\n\n        return 0;\n      }\n    };\n\n\nIn cases where the sorting value was the same, collapse groups were lost (I was using the all query). This is the behavioir of TreeSet when the comparator returns 0. \n\tWhen no sorting is specified a NPE occured. I temporarly fixed this by adding the following code in the groupBy method before the fieldComparator is initialized:\n\nif (cmd.sort == null) {\n      cmd.sort = new Sort(new SortField(\"score\", SortField.SCORE, true));\n    }\n\n\n\n\n\nI also saw the following todo in the code: \nthese aren't valid if the group is every discarded then re-added.  keep track if there have been discards?\nI think this means that we have to keep all groups in memory. The cost is increase of the memory footprint, but we then do get accurate collapse counts. This change can be put in a different implementation off course. \n\nAlso we need to find a way of adding the collapse information to the response in a nice manner. I assume we still want the use the response format Shalin suggested? It does differ from the response the patch is currently generating. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12883913",
            "date": "2010-06-30T13:11:22+0000",
            "content": ">  these aren't valid if the group is every discarded then re-added. keep track if there have been discards?\nI think this means that we have to keep all groups in memory.\n\nI guess it depends... if this is the first phase only (just to find the top groups) then we don't really need the counts.  If the collapse count is one... then we need to either fix the counts another way, and potentially provide an option to not return the counts.\n\nAlso we need to find a way of adding the collapse information to the response in a nice manner. I assume we still want the use the response format Shalin suggested? It does differ from the response the patch is currently generating.\n\nMy prototype was just quick'n'dirty just to get the info out to the response writer to see if it worked.\nBut I'm not yet sure what the response format should be (and I've changed my mind before based on what types of usecases I'm thinking about).  For usecases like bestbuy (do a search for something like DVD to see their field collapsing), the grouping is pretty explicit and it seems to make sense to return multiple lists of documents.  One may also want to have a different sort in grouped documents, and for that it makes little sense to try and combine them all into a single list.  It's also the case that people may often want a fixed number of groups, rather than a fixed number of documents.  Also, it's possible that people may want to group on more than one field (like people facet on more than one field).\n\nThere are other use cases where collapsed docs are more of an exception and the traditional single-doc-list would be better.  But instead of trying to implement all these variants at once, I'm thinking of starting with a more generic groupedResults separate from normal results.  We can add options later for an alternate flattened representation.\n "
        },
        {
            "author": "Martijn van Groningen",
            "id": "comment-12885082",
            "date": "2010-07-04T21:42:25+0000",
            "content": "I guess it depends... if this is the first phase only (just to find the top groups) then we don't really need the counts. If the collapse count is one... then we need to either fix the counts another way, and potentially provide an option to not return the counts.\n\nIf no counts are required then it would be optimal and fast. In the cases when the counts or any other aggregate statistics are necessary we would need to keep all the collapse groups in order to be accurate. Or give an option that the aggregate values are 'estimated', but all these variants can be different implementations. I think we should get at least one implementation ready (preferably the fast one) and the architecture for the different algorithms.\n\nIn the patches in SOLR-236 there is a notion of CollapseCollector, this accepts document ids that are collapsed  / grouped and are not returned to the regular result. Each implementation can do anything with this document id. For example to compute count, max, average or to keep to later return is collapsed document in the collapse response. How do you see that such a concept could be integrated into this patch? Or do you think its better to keep this functionality in the grouping implementations.\n\nThere are other use cases where collapsed docs are more of an exception and the traditional single-doc-list would be better.\nThat is true, there are a lot of options to this to client in the response.  "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12886139",
            "date": "2010-07-07T22:43:31+0000",
            "content": "I've updated my phase1 collapsing to include an arbitrary sort, and fixed some bugs along the way.\n\nI've been trying to understand the other patches here... but there are some interesting mysteries.\n\nThere are multiple occurrences of comparator code like this:\n\n        if ((c < 0 && reverseMul[i] > 0) || (c > 0 && reverseMul[i] < 0)) {\n\n\n\nbut reverseMul has already been folded into \"c\", so a simple c<0 seems correct?\n\nAlso, looking at the second stage collapsing (CollapsedDocCollector) I think I see a number of issues:\n\n\tthe counts collected in the first phase may not be correct, but are used in the second phase\n\tsetBottom is used, but there really needs to be a bottom per group (actually, compareBottom is never used anyway)\n\tthe field comparator is used incorrectly... compare(doc,slot) is called, but that's actualy (slot1,slot2) so the results will be wrong (or throw an exception).\n\n\n\nI'm surprised that any included tests passed given these apparent problems (unless I'm reading the code incorrectly).  I think we'll need some very good random tests for this functionality to be sure we're hitting all of the corner cases.\n\nAnyway, I'm starting to implement the second phase collector with essentially a priority queue per group. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12886164",
            "date": "2010-07-08T00:25:16+0000",
            "content": "... there is a notion of CollapseCollector ...\n\nSeems like a useful concept, but perhaps for all docs in a group and not just the ones that aren't returned?  Or if it is useful to distinguish, we could provide support for both (via different collectors, or different methods on the collector). "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12887133",
            "date": "2010-07-11T01:41:17+0000",
            "content": "Here's an updated patch.  I started down the path at a combined hashmap/treemap... but reverted since it's pure premature optimization at this point.\n\nI did change the way that values are obtained from value sources (via a ValueFiller class).  This avoids every single DocValues in a complex function from creating a MutableValue for no reason, and avoids a cast that would be needed if the user passed in a value to be filled each time.\n\nThe second stage (for accurate counts, and for collapse counts greater than one) is now implemented. \n\nExample:\nhttp://localhost:8983/solr/select?q=*:*&groupby=popularity&docsPerGroup=3&fl=id,popularity\n\nExample of grouping by an arbitrary function:\nhttp://localhost:8983/solr/select?q=*:*&groupby=add%28popularity,popularity%29&docsPerGroup=3&fl=id,popularity\n\nCaveats:\n\n\tmuch of this is still test code... the parameter names will change, as will the upper level interface code and response format.  the focus so far has just been on the collectors and value sources.\n\tBoth the group sort and the documents within a group are currently governed by the \"sort\" param.  This won't always be the case.\n\tThis is only a general purpose algorithm that should work with a minimum of memory usage - there will be many different algorithms that offer better performance in specific scenarios in the future.\n\n "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12897982",
            "date": "2010-08-12T22:28:43+0000",
            "content": "I'm getting back to grouping/collapsing... here's a development patch.  I cleaned up a bunch of stuff, took a shot at coming up with a good HTTP API and response format, and enabled multiple field groupings in the same request.\n\nHTTP params:\n  group=true/false (like faceting, turn on/off grouping)\n  group.query=<the query>  - this is analogous to facet.query, but currently not implemented\n  group.field=<the field> - group by a field\n  group.func=<the function> - group by a function\n  group.limit - the top number of groups to report back (default is equal to the normal \"limit\" param, or 1 if unspecified)\n  group.docsPerGroup - the top number of documents per group to return\n\nWe'll need to be able to specify some of these per group.  That hasn't been implemented, but utilizing local params seems natural (since the alternate f.<fieldname>.param method only works well with fields).\n\nThe \"docsPerGroup\" name seems a little more verbose than normal - anyone have shorter ideas?  Perhaps some kind of limit/offset params for the docs in a group.\n\nHere's an example of the current API:\nhttp://localhost:8983/solr/select?wt=json&indent=true&q=*:*&fl=id&rows=3&group=true&group.docsPerGroup=2&group.field=popularity&group.func=add%28popularity,popularity%29\n\n{\n  \"responseHeader\":{\n    \"status\":0,\n    \"QTime\":2,\n    \"params\":{\n      \"fl\":\"id\",\n      \"indent\":\"true\",\n      \"q\":\"*:*\",\n      \"group.field\":\"popularity\",\n      \"group.func\":\"add(popularity,popularity)\",\n      \"group.docsPerGroup\":\"2\",\n      \"group\":\"true\",\n      \"wt\":\"json\",\n      \"rows\":\"3\"}},\n  \"grouped\":{\n    \"popularity\":{\n      \"groups\":[{\n          \"groupValue\":6,\n          \"matches\":5,\n          \"docs\":{\"numFound\":5,\"start\":0,\"docs\":[\n              {\n                \"id\":\"SP2514N\"},\n              {\n                \"id\":\"6H500F0\"}]\n          }},\n        {\n          \"groupValue\":1,\n          \"matches\":2,\n          \"docs\":{\"numFound\":2,\"start\":0,\"docs\":[\n              {\n                \"id\":\"F8V7067-APL-KIT\"},\n              {\n                \"id\":\"IW-02\"}]\n          }},\n        {\n          \"groupValue\":10,\n          \"matches\":2,\n          \"docs\":{\"numFound\":2,\"start\":0,\"docs\":[\n              {\n                \"id\":\"MA147LL/A\"},\n              {\n                \"id\":\"SOLR1000\"}]\n          }}]},\n    \"add(popularity,popularity)\":{\n      \"groups\":[{\n          \"groupValue\":12.0,\n          \"matches\":5,\n          \"docs\":{\"numFound\":5,\"start\":0,\"docs\":[\n              {\n                \"id\":\"SP2514N\"},\n              {\n                \"id\":\"6H500F0\"}]\n          }},\n        {\n          \"groupValue\":2.0,\n          \"matches\":2,\n          \"docs\":{\"numFound\":2,\"start\":0,\"docs\":[\n              {\n                \"id\":\"F8V7067-APL-KIT\"},\n              {\n                \"id\":\"IW-02\"}]\n          }},\n        {\n          \"groupValue\":20.0,\n          \"matches\":2,\n          \"docs\":{\"numFound\":2,\"start\":0,\"docs\":[\n              {\n                \"id\":\"MA147LL/A\"},\n              {\n                \"id\":\"SOLR1000\"}]\n          }}]}}}\n\n "
        },
        {
            "author": "Martijn van Groningen",
            "id": "comment-12898110",
            "date": "2010-08-13T07:08:41+0000",
            "content": "Cool stuff Yonik! I noticed in the SolrIndexSearcher#groupBy method that you were instantiating a Lucene filter from the filer docset but you are not using it as argument to the search method, so if some specifies a fq it would not work. I'll dive deeper into the patch in the next few days. "
        },
        {
            "author": "Martijn van Groningen",
            "id": "comment-12899062",
            "date": "2010-08-16T20:01:15+0000",
            "content": "I've attached a new patch that allows the user to specify:\ngroup.sort=<field> <order> - This activates the TopGroupSortCollector 1st phase collector (which extends the TopGroupCollector). The Phase2GroupCollector stayed the same. Only the sort argument is the group sort.\n\nAlso I've added the first tests in TestGroupingSearch mainly for the group sorting. \nI also created GroupSortCommand that holds the group sort which is a subclass of GroupCommandFunc. I'm not sure but maybe this belongs in this GroupCommandFunc, b/c it is a common functionality. \n\nThe \"docsPerGroup\" name seems a little more verbose than normal - anyone have shorter ideas? Perhaps some kind of limit/offset params for the docs in a group.\nI like group.limit and group.offset. This allows the user to paginate the group docs. On the other side doing this will properly be memory ineffecient just like deep paging only in this case worse b/c it done on all groups.\n "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12899097",
            "date": "2010-08-16T21:22:25+0000",
            "content": "Thanks Martijn, I'll try and merge your patch in with what I currently have (diffing patches... blech \n\nI like group.limit and group.offset.\n\nI'm already using group.limit as a limit on the number of groups.\ncollapse.threshold is the name that the original field collapsing patches used - but that name doesn't make as much sense when thinking about grouping. "
        },
        {
            "author": "Martijn van Groningen",
            "id": "comment-12899189",
            "date": "2010-08-16T23:35:42+0000",
            "content": "True always a hassle! \n\nI'm already using group.limit as a limit on the number of groups.\nThat one seems unused in the current patch. The group.docsPerGroup is used for that purpose now, but I guess that will change.\n\ncollapse.threshold is the name that the original field collapsing patches\nYes, collapse.threshold only makes sense when you're collapsing. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12899235",
            "date": "2010-08-17T01:53:27+0000",
            "content": "OK, so if I'm reading the patch correctly, it looks like the new group.sort you added decouples the sort of the groups from the sort of the documents within each group?  (and group.sort specifies the sort of the docs within each group?)\n\nWhat's the intended semantics of how to sort the groups?  For example: if I'm sorting the documents within each group by price desc, and I'm sorting the groups by popularity desc... what if the top docs kept in group A (those with the highest price) are not the docs with the highest  popularity?  Are groups sorted by the popularity of the first doc (i.e. the one with the highest price), or are they sorted by the highest popularity doc with group value A (even if it's not in the top N in that group)? "
        },
        {
            "author": "Martijn van Groningen",
            "id": "comment-12899376",
            "date": "2010-08-17T11:26:25+0000",
            "content": "OK, so if I'm reading the patch correctly, it looks like the new group.sort you added decouples the sort of the groups from the sort of the documents within each group? (and group.sort specifies the sort of the docs within each group?)\nYes it decouples the sort of the groups from the sort of the documents within the group and is specified via the group.sort parameter.\n\nWhat's the intended semantics of how to sort the groups?\nWhat happens is that documents inside a group are sorted by the group.sort parameter and the groups are sorted by the sort parameter.  The groups are sorted with the most relevant (first) document of a group. So in your example the first group in the result is not the most popular, but the most expensive popular group (the first document in the first group will be).\n\nAre groups sorted by the popularity of the first doc....\nGroups are sorted by the first and most relevant document in a group. In your example the document in a group with the highest price. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12899401",
            "date": "2010-08-17T13:24:10+0000",
            "content": "Groups are sorted by the first and most relevant document in a group.\n\nGoing back to a specific example... assuming we are sorting by price asc within a single group, but sorting groups by popularity desc (however that's defined).\nSo we have 2 sane choices about what the popularity of a group is:\n1) the popularity of a group is the lowest price doc (i.e. the first in the list for that group).  - this is what you did\n2) the popularity of a group is the max among all docs in that group\n\nI wonder which will be more useful to people?  Do we need both?\n#2 can be trivially implemented with the existing collectors (just use different sorts at the different stages) "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12899407",
            "date": "2010-08-17T13:52:51+0000",
            "content": "back to the naming of docsPerGroup: I guess if we stick with group.sort as the sort within a single group, then use of group.limit is perfectly consistent with that (I had planned on group.limit to be the number of groups returned - so I just need to get used to the new way of thinking about these) "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12899422",
            "date": "2010-08-17T14:45:11+0000",
            "content": "A group currently looks like this:\n\n\n        {\n          \"groupValue\":1,\n          \"matches\":2,\n          \"docs\":{\"numFound\":2,\"start\":0,\"docs\":[\n              {\n                \"id\":\"F8V7067-APL-KIT\",\n                \"price\":19.95},\n              {\n                \"id\":\"IW-02\",\n                \"price\":11.5}]\n          }},\n\n\n\nIt looks fine in XML, but in JSON the representation of a doclist as \"docs\" itself as part of it (so now we have \"docs\" nested directly in \"docs\").  Should we change the name of that outer \"docs\" to something else?  \"response\", \"matches\", \"topdocs\",\"doclist\", or just live with it? "
        },
        {
            "author": "Martijn van Groningen",
            "id": "comment-12899502",
            "date": "2010-08-17T18:09:34+0000",
            "content": "2) the popularity of a group is the max among all docs in that group\nIf done as different sort in the second phase collector. This means then that the groups themselves are sorted on popularity desc (most popular group end up as first result), but the documents inside the group on price asc. This can be confusing since the document responsible for getting the group in the result set (top 10) might not be put in inside the group during the second phase. I'm not sure if end user expect / want this.\n\nhad planned on group.limit to be the number of groups returned - so I just need to get used to the new way of thinking about these\nCan't we use rows parameter for that?\n\nIt looks fine in XML, but in JSON the representation of a doclist as \"docs\" it\nMaybe groupDocs fits as good description "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12900494",
            "date": "2010-08-19T22:19:28+0000",
            "content": "Here's an updated patch that merges in Martijn change, and implements some more tests (using the new JSON test method).  I also went with the name \"doclist\" for now. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12900556",
            "date": "2010-08-20T02:55:19+0000",
            "content": "Here's a patch that adds support for retrieving scores also.\nI think we're getting close to something committable! "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12900785",
            "date": "2010-08-20T17:26:27+0000",
            "content": "OK, here's another update:  other little fixes + tests, and \"matches\" is added at the top level to give a complete count of the number of docs that matched the query. "
        },
        {
            "author": "James Dyer",
            "id": "comment-12900842",
            "date": "2010-08-20T20:00:53+0000",
            "content": "In addition to \"matches\" for total # docs, do we have a way to get the total # of groups? "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12900846",
            "date": "2010-08-20T20:11:55+0000",
            "content": "No, with the current algorithm we avoid keeping all of the groups in memory at once, so we never know exactly how many unique ones we hit.  But an option to retrieve it is a good idea - we probably just don't want to do it by default. "
        },
        {
            "author": "Grant Ingersoll",
            "id": "comment-12903396",
            "date": "2010-08-27T13:18:03+0000",
            "content": "Can we back port to 3.x?  How hard? "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12903408",
            "date": "2010-08-27T13:33:29+0000",
            "content": "I'd rather not tackle backporting immediately - it's going to be under a lot of flux. "
        },
        {
            "author": "Lance Norskog",
            "id": "comment-12903790",
            "date": "2010-08-28T06:38:45+0000",
            "content": "If I want the Google search-style \"there are more results from this site\" UI, I don't care about counts. I can just pull the field from the first search N results and hunt for repeats.\n\nDoes this patch do that efficiently? Would a custom UpdateHandler or RequestHandler be the right way to do that? "
        },
        {
            "author": "Cuong Hoang",
            "id": "comment-12905867",
            "date": "2010-09-03T12:05:02+0000",
            "content": "I tried out this patch in trunk but it does seem to work with other components include Facet and Highlighter. These two components require docList in them ResponseBuilder instance passed to them while code to do grouping doesn't actually set docList and docSet like the normal QueryComponent. Is this intentional or am I missing something?  "
        },
        {
            "author": "Varun Gupta",
            "id": "comment-12909223",
            "date": "2010-09-14T12:59:15+0000",
            "content": "Is there any workaround to use Highlight and Facet components along with grouping? "
        },
        {
            "author": "Jasper van Veghel",
            "id": "comment-12916451",
            "date": "2010-09-30T12:23:40+0000",
            "content": "Great stuff guys. We're using Field Collapsing to fold in URLs of documents in our index which have the same URL but multiple individual content parts. We can't merge these earlier in the indexing proces as each individual page content-part has different access rights. As such, not every piece of content is accessible to everyone, but different users with different access rights might still end up on the same URL and might end up finding multiple results for the same page URL.\n\nAs for faceting and highlighting - I've managed to merge in the faceting patch from SOLR-2098 and have taken the highlighting changes from Yonik's github commit (r997870). This seems to be working flawlessly, and all we're rooting for now is for some love for distributed collapsing so we use it across multiple shards. So far we haven't run into any issues with the current (august 20th) patch. Keep up the good work! "
        },
        {
            "author": "Eric Caron",
            "id": "comment-12923138",
            "date": "2010-10-20T20:04:44+0000",
            "content": "Is anyone else having the issue that when supplying an offset/start, that the subset isn't being generated? For example, if I do start=0&rows=10, I get entries 1 through 10, but if I do start=10&rows=10, I get entries 1 through 20 (as of commit #1005652 in trunk). "
        },
        {
            "author": "Bill Bell",
            "id": "comment-12933874",
            "date": "2010-11-19T17:24:02+0000",
            "content": "Eric,\n\nGet the latest trunk. This is fixed. "
        },
        {
            "author": "Jasper van Veghel",
            "id": "comment-12969246",
            "date": "2010-12-08T08:22:22+0000",
            "content": "Is there any way to retrieve the request the total number of groups, in despite of the (previously noted) performance penalty involved? We'd like to be able to provide complete paging and total counts, but we can't when the total number of documents is say, 200, but the last group is say, 190. That would mean that the last page in a 10-document pager would be empty. "
        },
        {
            "author": "Bill Bell",
            "id": "comment-12969629",
            "date": "2010-12-09T05:11:22+0000",
            "content": "Jasper van Veghel - See my patch https://issues.apache.org/jira/browse/SOLR-2242\n\nThis will work if you use group.field for the same field you do the facet.field. Just make sure you set mincount=1 and limit=-1.\n\nThanks. "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-12996453",
            "date": "2011-02-18T15:29:55+0000",
            "content": "What's the state of backporting to 3.x? "
        },
        {
            "author": "Otis Gospodnetic",
            "id": "comment-12996556",
            "date": "2011-02-18T18:34:58+0000",
            "content": "Are there known trunk patches that make it possible to use field grouping/collapsing in distributed search based on what's in this SOLR-1682? "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13043663",
            "date": "2011-06-03T16:46:24+0000",
            "content": "Bulk move 3.2 -> 3.3 "
        },
        {
            "author": "bronco",
            "id": "comment-13120620",
            "date": "2011-10-05T00:48:45+0000",
            "content": "It doesn't work even if I use set mincount=1 and limit=-1. I always get the wrong numFound result. I try this now for 2 days to find a suitable way to make it work.\n\nI have on my search page 2 results but the pager thinks he has to draw 3 steps because the numFound result says 22. This is really not good. Are there any working solutions outside? "
        }
    ]
}