{
    "id": "LUCENE-7668",
    "title": "WordDelimiterGraphFilter fails to preserve token type",
    "details": {
        "labels": "",
        "priority": "Major",
        "resolution": "Fixed",
        "affect_versions": "None",
        "status": "Closed",
        "type": "Bug",
        "components": [],
        "fix_versions": [
            "6.5",
            "7.0"
        ]
    },
    "description": "It is supposed to preserve the incoming token type to all its output tokens but now it's always setting to the default word.",
    "attachments": {
        "LUCENE-7668.patch": "https://issues.apache.org/jira/secure/attachment/12849950/LUCENE-7668.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "id": "comment-15845091",
            "date": "2017-01-30T11:54:27+0000",
            "content": "Simple patch; I had to also fix CannedTokenStream to set the canned token type for the test case. ",
            "author": "Michael McCandless"
        },
        {
            "id": "comment-15845145",
            "date": "2017-01-30T12:51:04+0000",
            "content": "Why don't you capture all attributes with captureState and restore them instead of clearAttributes? After that you can change token text and offsets/position. There is a TODO about this in the source code.\n\nThe problem mentioned here also affects payloads or other attributes like flags, keyword, or the japanese ones.\n\nI fixed the same issue in NGramFilters a week ago. ",
            "author": "Uwe Schindler"
        },
        {
            "id": "comment-15845861",
            "date": "2017-01-30T20:33:35+0000",
            "content": "Ahh in fact it's already doing the captureState/restoreState here, and so in fact there is no bug!  I wrote the test first, and it was only failing because CannedTokenStream was failing to carry over the type I had asked for.\n\nHere's a new patch, just adding the test case, and removing dead code from WDGF.\n\nThanks Uwe Schindler. ",
            "author": "Michael McCandless"
        },
        {
            "id": "comment-15846149",
            "date": "2017-01-30T23:36:42+0000",
            "content": "Hah, thanks for bringing to closure!  Thanks for removing the dead TypeAttribute!\n\nMaybe we should fix CannedTokenStream to do what its comment says (captureState/restoreState).  ",
            "author": "Uwe Schindler"
        },
        {
            "id": "comment-15846168",
            "date": "2017-01-30T23:48:30+0000",
            "content": "Maybe we should fix CannedTokenStream to do what its comment says (captureState/restoreState).\n\nI would love to, but I'm not quite sure how to do it.  CannedTokenStream gets an array of Token in ... how can I do a restoreState from a Token? ",
            "author": "Michael McCandless"
        },
        {
            "id": "comment-15846179",
            "date": "2017-01-30T23:58:14+0000",
            "content": "There is one possibility: As CannedTokenStream is a source and owns the attributes, it could use the Token Attributefactory (see the final field on deprecated Token class) in its ctor. Because of this one could use copyTo of Token to copy it into the Token behind all attributes.\n\nBut as CannedTokenStream only supports the attributes of Token, we could also just ensure all of those are copied. So look which attributes are implemented and use those!\n\nNot sure what's the better idea. ",
            "author": "Uwe Schindler"
        },
        {
            "id": "comment-15846691",
            "date": "2017-01-31T11:27:55+0000",
            "content": "OK I tried your first idea Uwe Schindler, using Token's attribute factory for CannedTokenStream and then casting the offset attribute to Token and using copyTo.  It seems to work, as crazy as it looks! ",
            "author": "Michael McCandless"
        },
        {
            "id": "comment-15846789",
            "date": "2017-01-31T13:05:18+0000",
            "content": "Looks good! Thanks for adding the comment about the crazyness - I see no better way to do this (without casting)! It is also good that you left the clearAttributes(), because without it, the \"extra\" attributes maybe added by TokenFilters, would not be cleared and then the Asserting* tests would fail. ",
            "author": "Uwe Schindler"
        },
        {
            "id": "comment-15847119",
            "date": "2017-01-31T16:56:23+0000",
            "content": "Commit 72eaeab7151d421a28ecec1634b8c48599e524f5 in lucene-solr's branch refs/heads/master from Mike McCandless\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=72eaeab ]\n\nLUCENE-7668: add new test case; remove dead code; improve CannedTokenStream to copy all Token attributes ",
            "author": "ASF subversion and git services"
        },
        {
            "id": "comment-15847130",
            "date": "2017-01-31T17:01:33+0000",
            "content": "Commit d82b997864a958357dfe1c65870119782e0919ba in lucene-solr's branch refs/heads/branch_6x from Mike McCandless\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=d82b997 ]\n\nLUCENE-7668: add new test case; remove dead code; improve CannedTokenStream to copy all Token attributes ",
            "author": "ASF subversion and git services"
        },
        {
            "id": "comment-15847132",
            "date": "2017-01-31T17:01:52+0000",
            "content": "Thank you Uwe Schindler! ",
            "author": "Michael McCandless"
        }
    ]
}