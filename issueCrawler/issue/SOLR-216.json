{
    "id": "SOLR-216",
    "title": "Improvements to solr.py",
    "details": {
        "affect_versions": "1.2",
        "status": "Resolved",
        "fix_versions": [],
        "components": [
            "clients - python"
        ],
        "type": "Improvement",
        "priority": "Trivial",
        "labels": "",
        "resolution": "Won't Fix"
    },
    "description": "I've taken the original solr.py code and extended it to include higher-level functions.\n\n\n\tRequires python 2.3+\n\tSupports SSL (https://) schema\n\tConforms (mostly) to PEP 8 \u2013 the Python Style Guide\n\tProvides a high-level results object with implicit data type conversion\n\tSupports batching of update commands",
    "attachments": {
        "solr-solrpy-r5.patch": "https://issues.apache.org/jira/secure/attachment/12388189/solr-solrpy-r5.patch",
        "solr.py": "https://issues.apache.org/jira/secure/attachment/12356364/solr.py",
        "test_all.py": "https://issues.apache.org/jira/secure/attachment/12388190/test_all.py"
    },
    "issue_links": {},
    "comments": [
        {
            "author": "Jason Cater",
            "id": "comment-12492098",
            "date": "2007-04-26T19:16:19+0000",
            "content": "Updated solr.py file "
        },
        {
            "author": "Brian Whitman",
            "id": "comment-12493835",
            "date": "2007-05-05T00:39:13+0000",
            "content": "Hi Jason, this is really great. I had one small issue \u2013 highlighting did not seem to work. I looked into your code and found you were using hi.fl and hi, not hl.fl and hl. Not sure if your solr expects hi, but mine expects hl. Once I changed line 453 & 457 to hl instead of hi it works fine.  "
        },
        {
            "author": "Brian Whitman",
            "id": "comment-12495393",
            "date": "2007-05-13T18:41:52+0000",
            "content": "I'm noticing that you are looking for \n\n        if not data.startswith('<result status=\"0\"'):\n\nWhen detecting if /update didn't like something. With the latest solr trunk, that doesn't come back anymore. It looks like:\n\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<response>\n<lst name=\"responseHeader\"><int name=\"status\">0</int><int name=\"QTime\">40</int></lst>\n</response>\n\nnow. I'm not too used to python to fix this properly at the moment. "
        },
        {
            "author": "Mike Klaas",
            "id": "comment-12499273",
            "date": "2007-05-26T02:22:40+0000",
            "content": "Thanks for your contribution!  Some comments:\n\nstyle:\n\n\n\tlist comprehensions solely to perform looped execution are harder to parse and slower than explicitly writing a for loop\n\n\n\n\n\tshadowing builtins is generally a bad idea\n\n\n\n\n\tSolrConnection is an old-style class, but Response is new-style\n\n\n\nfunctionality:\n\n\n\twhy are 'status'/'QTime' returned as floats?\n\n\n\n\n\tall NamedList's appearing in the output are converted to dicts--this loses information (in particular, it will be unnecessarily hard for the user to use highlighting/debug data).  Using the python/json response format would prevent this.  Not returning highlight/debug data in the standard response format (and yet providing said parameters in the query() method) seems odd.  Am I missing something?  Oh, they are set as dynamic attributes of Response, I see.  Definitely needs documentation.\n\n\n\n\n\tpassing fields='' to query() will return all fields, when the desired return is likely no fields\n\n\n\n\n\tit might be better to settle on an api that permits doc/field boosts.  How about using a tuple as the field name in the field dict?\n\n\n\nconn.add_many([\n{'id': 1, ('field2', 2.33): u\"some text\"}\n])\n\ndoc boosts could be handled by optionally providing the fielddict as a (<fielddict>, boost) tuple.\n\n\n\tfor 2.5+, a cool addition might be:\n\n\n\nif sys.version > 2.5\n   import contextlib   \n   def batched(solrconn):\n          solrconn.begin_batch()\n\tyield solrconn\n\tsolrconn.end_batch()\n  batched = contextlib.contextmanager(batched)\n\nUse as:\n\nwith batched(solrconn):\n       solrconn.add(...)\n       solrconn.add(...)\n       solrconn.add(...) "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12499907",
            "date": "2007-05-29T20:05:27+0000",
            "content": "FYI, I ran into an issue with httplib in python.\nIt sends the headers and body separately when doing a POST, and this triggered some pretty bad performance on Linux systems using persistent connections (due to triggering Nagel's alg, I think)... 40 times slower than non-persistent connections.\n\nGET could probably normally be used for queries at least, but POST is still needed for updates. "
        },
        {
            "author": "Mike Klaas",
            "id": "comment-12499913",
            "date": "2007-05-29T20:37:13+0000",
            "content": "\nOn 29-May-07, at 12:41 PM, Jason Cater wrote:\nI've had my solr.py in production use internally for about a month now. So, as you can imagine, I've worked through a few oddball bugs that occasionally pop up.  It seems pretty stable for me.\n\nYes, I agree that it is looking good.  Since we would be replacing the existing implementation completely, I think that it is worth taking extra care and examining the api choices carefully so we won't have to replace it or deprecate things in the near future.\n\nI would prefer to have a complete directory structure (i.e., setup.py, unit tests, samples, etc) instead of just the solr.py file.  Would anyone see a problem with this?\n\n+1.  This would be great--a unittest that could be run against the solr example would be spectacular!\n\nAlso, on some of your comments:\n\n\n\tlist comprehensions solely to perform looped execution are harder to parse and slower than explicitly writing a for loop\n\n\n\n\nList comprehensions seem to be a matter of contention for some.  However, it's a battle I'm not interested in fighting, so changed it to a for loop.\n\nIt is not a matter of contention for me for use in creating a list, but ISTM less clear and less efficient if the purpose is solely to perform a loop:\n\n$ python -m timeit '[i+i for i in xrange(10000)]'\n100 loops, best of 3: 1.95 msec per loop\n\n$ python -m timeit 'for i in xrange(10000): i+i'\n100 loops, best of 3: 1.38 msec per loop\n\n\n\tshadowing builtins is generally a bad idea\nAny shadowing of builtins was unintentional.  Did you see specific examples?  I run the code through pychecker and pylint to try to avoid such cases.\n\n\n\n`id` is shadowed in a few places.  \n\n\n\n\tall NamedList's appearing in the output are converted to dicts--this loses information (in particular, it will be unnecessarily hard for the user to use highlighting/debug data).  Using the python/json response format would prevent this.  Not returning highlight/debug data in the standard response format (and yet providing said parameters in the query() method) seems odd.  Am I missing something?  Oh, they are set as dynamic attributes of Response, I see.  Definitely needs documentation.\n\n\n\n\nYes, this needs to be documented.  (Please c.f. to my question about allowing a complete directory structure.)\n\n\n\tpassing fields='' to query() will return all fields, when the desired return is likely no fields\n\n\n\n\nI've changed the default for fields= to be '', instead of None or \"\".  This way, passing in 'fields=\"\"' will result in 'fl=' being passed to the backend.  However, I still don't see the point, as passing both 'fl=' and 'fl=' return the exact same set of fields (i.e., \"all\") on my test setup.\n\nHmm, what if you pass fields='', score=True?  Ideally tha would pass fl=score to the backend, bypassing all stored fields.\n\n\n\tit might be better to settle on an api that permits doc/field boosts.  How about using a tuple as the field name in the field dict?\n\n\n\nconn.add_many([\n{'id': 1, ('field2', 2.33): u\"some text\"}\n])\n\ndoc boosts could be handled by optionally providing the fielddict as a (<fielddict>, boost) tuple.\n\n\nI agree. I was not aware of field boosts at the time. I'll code this change.\n\nUnfortunately, it is still somewhat awkward.  In my python client I end up passing (<name>, <value>, <field boost or None>) everywhere, but that clutters up the api considerably.\n\nIt might be worth taking a look at the ruby client to see what Eric's done for the api.\n\n\n\tfor 2.5+, a cool addition might be:\n\n\n\nif sys.version > 2.5\n   import contextlib      def batched(solrconn):\n          solrconn.begin_batch()\n\tyield solrconn\n\tsolrconn.end_batch()\n  batched = contextlib.contextmanager(batched)\n\nUse as:\n\nwith batched(solrconn):\n       solrconn.add(...)\n       solrconn.add(...)\n       solrconn.add(...)\n\n\nAdding...\n\nUnfortunately, it does push the required python version to 2.4.  Personally, I think that requiring 2.4 is not unreasonable, but I'm somewhat of a bleeding edge guy...\n\n[incidently, it would be best to keep comments in JIRA, for posterity] "
        },
        {
            "author": "Jason Cater",
            "id": "comment-12499915",
            "date": "2007-05-29T20:45:42+0000",
            "content": "In regard to Yonik Seeley's point of GET vs POST for queries, is there any need for us to keep everything as POSTs? It is fairly trivial to change my code to use GETs for queries.  \n\n(Mike Klaas: apologies for replying to the list earlier and not using JIRA ... I'm still learning.)\n "
        },
        {
            "author": "Mike Klaas",
            "id": "comment-12499922",
            "date": "2007-05-29T20:55:34+0000",
            "content": "I just noticed that I changed my own python query code to POST from GET two months ago, but I can't remember why at the moment.  It is possibly due to url length limitations (occasionally I was passing a lot of data in the query args), but that doesn't seem quite right now.  Changing to GET makes sense to me (though rapid updates are still a potential problem--perhaps it would be worth recommending against persistent connections on linux). "
        },
        {
            "author": "Walter Underwood",
            "id": "comment-12499923",
            "date": "2007-05-29T21:00:27+0000",
            "content": "GET is the right semantic for a query, since it doesn't change the resource. It also allows HTTP caching.\n\nIf Solr has URL length limits, that's a bug. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12519688",
            "date": "2007-08-14T14:13:19+0000",
            "content": "I quickly tried the example in comments, and ran into some issues:\n\nThe examples should be made to work with the example Solr install... so instead of\n   >>> c = SolrConnection('http://localhost:8983')\n   >>> c.add(id='500', name='python test doc', active=True)\n\nIt should be\n   >>> c = SolrConnection('http://localhost:8983/solr')    #need to specify full path to solr\n   >>> c.add(id='500', name='python test doc')                #active field doesn't exist\n\nAfter that, a document is added, but I get an exception on the python side.\nI guess it's probably related to response parsing?  It should probably be updated to check the HTTP response and not parse the response. "
        },
        {
            "author": "Yonik Seeley",
            "id": "comment-12519698",
            "date": "2007-08-14T14:53:48+0000",
            "content": "Uploading a  slightly patched version that works with the new update response format, and fixes some exception related issues (http reason is now grabbed, exception trace prints httpcode and reason) "
        },
        {
            "author": "Ed Summers",
            "id": "comment-12525590",
            "date": "2007-09-07T04:34:58+0000",
            "content": "Thanks guys for this really nice update. I was wrestling with the current solr.py in svn and solr v1.2, and then remembered seeing something on the list about an updated solr client for python.\n\nAnyhow, I was running some unicode through add() in the latest solr.py attached to this issue and noticed that the body isn't being encoded before sending off to httplib.HTTPConnection.request() on line 711:\n\n  self.conn.request('POST', url, body, headers)\n\nThis can result in a stack trace like this when sending utf8 over the wire:\n\nTraceback (most recent call last):\n  File \"./solr_index.py\", line 25, in <module>\n    solr.add_many([solr_doc])\n  File \"../../../wdl/solr.py\", line 587, in add_many\n    return self._update(xstr)\n  File \"../../../wdl/solr.py\", line 653, in _update\n    request, self.xmlheaders)\n  File \"../../../wdl/solr.py\", line 711, in _post\n    self.conn.request('POST', url, body, headers)\n  File \"/usr/lib/python2.5/httplib.py\", line 862, in request\n    self._send_request(method, url, body, headers)\n  File \"/usr/lib/python2.5/httplib.py\", line 888, in _send_request\n    self.send(body)\n  File \"/usr/lib/python2.5/httplib.py\", line 707, in send\n    self.sock.sendall(str)\n  File \"<string>\", line 1, in sendall\nUnicodeEncodeError: 'ascii' codec can't encode character u'\\u0302' in position 85: ordinal not in range(128)\n\nChanging line 711 to:\n\n  self.conn.request('POST', url, body.encode('utf-8'), headers)\n\nmakes the problem go away... "
        },
        {
            "author": "Ian Holsman",
            "id": "comment-12527319",
            "date": "2007-09-14T00:56:30+0000",
            "content": "Hi.\n\nI had a minor issue with UTF-8 encoded strings (for example \u05e9\u05d9\u05d5\u05d5\u05e7 )\n\nmy 'fix' for this was to encode the query string ala\n        params['q'] = q.encode('utf-8')\nin the 2-3 places, and it fixed it.\nI'm no python expert, so I'm not sure if this is right the thing to do or not. "
        },
        {
            "author": "Rob Young",
            "id": "comment-12597817",
            "date": "2008-05-18T16:33:34+0000",
            "content": "Added support for boosted documents and fields. Added Document and Field classes.\nExamples:\nconnection.add(id=\"mydoc\", auther=[\"you\", Field(\"me\", boost=2.0), Field(\"dupree\", boost=0.1)])\ndocument = Document(boost=1.5)\ndocument.add(id=\"mydoc\", auther=\"me\")\nconnection.add(document) "
        },
        {
            "author": "Dariusz Suchojad",
            "id": "comment-12622385",
            "date": "2008-08-13T23:07:44+0000",
            "content": "solr.py intended to work with Solr 1.2 "
        },
        {
            "author": "Dariusz Suchojad",
            "id": "comment-12622386",
            "date": "2008-08-13T23:09:20+0000",
            "content": "Patch against r5 of http://code.google.com/p/solrpy/ to make it work with Solr 1.2 "
        },
        {
            "author": "Dariusz Suchojad",
            "id": "comment-12622387",
            "date": "2008-08-13T23:10:13+0000",
            "content": "Tests for solr.py "
        },
        {
            "author": "Dariusz Suchojad",
            "id": "comment-12622390",
            "date": "2008-08-13T23:13:39+0000",
            "content": "Hello,\n\nthere are a few Python clients available, which is quite confusing, so I took \nthe one with the richest API available (http://code.google.com/p/solrpy/, rev5)\nand created a set of test cases which you may found in attached file test_all.py.\nThe tests are meant to be run with Solr 1.2 and only after applying attached\nsolr-solrpy-r5.patch, which fixes a couple of issues while still trying not to\nbreak the already exposed API. Attached is also a solr.py module with the\npatch applied. One of the tests is failing deliberately, I'm simply not sure \nwhether doing batch updates is still feasible with Solr 1.2.\n\nWhat I'd like to propose now is to integrate all the code available - solrpy\nand pysolr from code.google.com, the crude & tiny one from Solr SVN\n(http://svn.apache.org/viewvc/lucene/solr/trunk/client/python/), various patches\nfrom JIRA - replace the XML parser used currently with elementtree or, optionally, \nlxml (which is the toolkit for any high-performance XML processing with Python),\nadd more tests and have one officially blessed rich client for Python.\nI'm willing to do all the dirty work if there's a consensus among people using\nSolr with Python that doing so is a good idea.\n\nWhat do you think? "
        },
        {
            "author": "Mike Klaas",
            "id": "comment-12622391",
            "date": "2008-08-13T23:17:24+0000",
            "content": "Hi Dariusz,\n\nThere will almost certainly be no more releases of Solr 1.2.  1.3 will likely be released in less than a month.  However, it is good that you published this code so that it can be found by other parties.\n\nI'd be much more interested in working toward a client that is compatible with the upcoming 1.3 release (it is unlikely that it can be included, but it can be distributed separately).\n\ncheers,\n-Mike "
        },
        {
            "author": "Dariusz Suchojad",
            "id": "comment-12622470",
            "date": "2008-08-14T08:29:37+0000",
            "content": "I just checked solr.py with 1.3 (r685786) and, except for the one mentioned\nabove, all tests pass correctly. However, I would like to add some more tests\nbefore merging features from other places, replacing xml.sax with etree/lxml\nor use some other Python 2.5 niceties. One thing I still don't know what\nto do about though is batch updating, I can't get it working right now,\nand I'm still not sure what it is good for, hence it's hard for me to come up\nwith some good test cases here before trying to fix it  "
        },
        {
            "author": "Mike Klaas",
            "id": "comment-12629556",
            "date": "2008-09-09T18:05:47+0000",
            "content": "Dariusz, \n\nHave you thought about publishing the update python client as a thirdparty/standalone package?  If it becomes popular and stable, it could be folded back in to the Solr distro, but for the time being I suspect that it will be difficult to work on in trunk (since there don't seem to be core devs who use it).\n\ncheers,\n-Mike "
        },
        {
            "author": "Dariusz Suchojad",
            "id": "comment-12629976",
            "date": "2008-09-10T21:24:06+0000",
            "content": "Hi Mike,\n\nI've joined the solrpy (http://code.google.com/p/solrpy/) project where I'd\nlike to incorporate the changes I had made and to work on adding more\nfeatures to the Python client. I hope to get back to the discussion when,\nlike you said, it becomes more stable and popular. "
        },
        {
            "author": "Mike Klaas",
            "id": "comment-12629981",
            "date": "2008-09-10T21:29:28+0000",
            "content": "That's great!  Be sure to update http://wiki.apache.org/solr/SolPython as the project progresses.\n "
        },
        {
            "author": "Dorneles Tremea",
            "id": "comment-12638803",
            "date": "2008-10-11T22:34:06+0000",
            "content": "Looks like the above issues are now being addressed at http://code.google.com/p/solrpy/issues and so this ticket can be closed... "
        },
        {
            "author": "Otis Gospodnetic",
            "id": "comment-12800787",
            "date": "2010-01-15T17:45:45+0000",
            "content": "Closing per comment "
        }
    ]
}