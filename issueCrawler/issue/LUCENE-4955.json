{
    "id": "LUCENE-4955",
    "title": "NGramTokenFilter increments positions for each gram",
    "details": {
        "components": [
            "modules/analysis"
        ],
        "fix_versions": [
            "4.4",
            "6.0"
        ],
        "affect_versions": "4.3",
        "priority": "Major",
        "labels": "",
        "type": "Bug",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "NGramTokenFilter increments positions for each gram rather for the actual token which can lead to rather funny problems especially with highlighting. if this filter should be used for highlighting is a different story but today this seems to be a common practice in many situations to highlight sub-term matches.\n\nI have a test for highlighting that uses ngram failing with a StringIOOB since tokens are sorted by position which causes offsets to be mixed up due to ngram token filter.",
    "attachments": {
        "highlighter-test.patch": "https://issues.apache.org/jira/secure/attachment/12580305/highlighter-test.patch",
        "LUCENE-4955.patch": "https://issues.apache.org/jira/secure/attachment/12580304/LUCENE-4955.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2013-04-24T16:48:22+0000",
            "content": "here is a patch including the deprecation and version support (I bet somebody relies on this behaviour) ...for trunk I will remove the deprecated methods but I added it here to make sure I don't miss it. \n\nthe second patch is a test for the highlighter that produces a SIOOB without the patch but succeeds with the positions patch. ",
            "author": "Simon Willnauer",
            "id": "comment-13640636"
        },
        {
            "date": "2013-04-24T17:07:46+0000",
            "content": "I think that ngram filter and edge-ngram filter are rather different cases.\n\nWith edge-ngram it is abundantly clear that all of the edge ngrams \"stack up\" at the same position (at least for \"front\" edge ngrams!). But embedded ngrams seem more like a stretching out of the token, from one token to a sequence of tokens. Actually, it is k overlayed sequences, where k = maxGramSize minus minGramSize plus 1.\n\nI think the solution should be to have a \"mode\" which indicates whether the \"intent\" is merely variations (sub-tokens) for the token at the same position vs. a stretching the token into a sequence of tokens. Maybe call it \"expansionMode\": \"stack\" vs. \"sequence\".\n\nBut even for the latter, I would definitely recommend that each of the k sequences should restart the position at the original token position. ",
            "author": "Jack Krupansky",
            "id": "comment-13640657"
        },
        {
            "date": "2013-04-25T08:29:16+0000",
            "content": "Given that offsets can't go backwards and that tokens in the same position must have the same start offset, I think that the only way to get NGramTokenFilter out of TestRandomChains' exclusion list (LUCENE-4641) is to fix position increments (this issue), change the order tokens are emitted in (LUCENE-3920) and stop modifying offsets? I know some people rely on the current behavior but I think it's more important to get this filter out of TestRandomChains' exclusions since it causes highlighting bugs and makes the term vectors files unnecessary larger. ",
            "author": "Adrien Grand",
            "id": "comment-13641567"
        },
        {
            "date": "2013-04-25T12:01:51+0000",
            "content": "+1 Adrien. these analysis components should either be fixed or removed.\n\nWe can speed up the process now by changing IndexWriter to reject this kinda bogus shit. We shouldnt be putting broken data into e.g. term vectors. That should encourage the fixing process. ",
            "author": "Robert Muir",
            "id": "comment-13641704"
        },
        {
            "date": "2013-04-25T12:03:51+0000",
            "content": "We can speed up the process now by changing IndexWriter to reject this kinda bogus shit. We shouldnt be putting broken data into e.g. term vectors. That should encourage the fixing process.\n\n+1\n\nI updated the highlighter test and added analysis-common as a test dependency such that this can be run with ant. ",
            "author": "Simon Willnauer",
            "id": "comment-13641705"
        },
        {
            "date": "2013-04-25T12:05:16+0000",
            "content": "+1\n\nI'll work on fixing NGramTokenizer and NGramTokenFilter. ",
            "author": "Adrien Grand",
            "id": "comment-13641706"
        },
        {
            "date": "2013-04-25T12:06:57+0000",
            "content": "I don't think we should add analysis-common as a test dependency to the highlighter. I worked pretty hard to clean all this up with e.g. mocktokenizer so we didnt have dependency hell. It also keeps our tests clean. ",
            "author": "Robert Muir",
            "id": "comment-13641709"
        },
        {
            "date": "2013-04-25T12:10:45+0000",
            "content": "robert I agree, I added this as sep. patch to make sure that whatever we commit here we can at least test that the ngram filter doesn't throw an IOOB anymore. I just wanted to make it easier to run the test. ",
            "author": "Simon Willnauer",
            "id": "comment-13641710"
        },
        {
            "date": "2013-04-26T00:21:23+0000",
            "content": "I tried to iterate on Simon's patch:\n\n\n\tNGramTokenFilter doesn't modify offsets and emits all n-grams of a single term at the same position\n\n\n\n\n\tNGramTokenizer uses a sliding window.\n\n\n\n\n\tNGramTokenizer and NGramTokenFilter removed from TestRandomChains exclusions.\n\n\n\nIt was very hard to add the compatibility version support to NGramTokenizer so there are now two distinct classes and the factory picks the right one depending on the Lucene match version.\n\nSimon's highlighting test now fails because the highlighted content is different, but not because of a broken token stream. ",
            "author": "Adrien Grand",
            "id": "comment-13642424"
        },
        {
            "date": "2013-04-26T11:03:28+0000",
            "content": "[trunk commit] jpountz\nhttp://svn.apache.org/viewvc?view=revision&revision=1476135\n\nLUCENE-4955: Fix NGramTokenizer and NGramTokenFilter, and remove them from TestRandomChains' exclusion list. ",
            "author": "Commit Tag Bot",
            "id": "comment-13642744"
        },
        {
            "date": "2013-04-26T12:14:44+0000",
            "content": "[branch_4x commit] jpountz\nhttp://svn.apache.org/viewvc?view=revision&revision=1476159\n\nLUCENE-4955: Fix NGramTokenizer and NGramTokenFilter, and remove them from TestRandomChains' exclusion list (merged from r1476135).\n\nIn addition to the trunk changes, I had to fix SlowSynonymFilterFactory to reset the token stream before consuming it. ",
            "author": "Commit Tag Bot",
            "id": "comment-13642772"
        },
        {
            "date": "2013-05-10T22:49:14+0000",
            "content": "If there are no objections, I'd like to backport this to 4.3.1. ",
            "author": "Steve Rowe",
            "id": "comment-13654967"
        },
        {
            "date": "2013-05-11T19:32:31+0000",
            "content": "Steve, I don't think we should do this unless we add a Version.LUCENE_4_3_1. The problem here is that this filter would introduce a totally different behaviour compared to the 4.3 version that we released. If you build your index with 4.3 you would need to reindex if you switch to 4.3.1 unless we add the version so we can fallback on the old behaviour. Makes sense? ",
            "author": "Simon Willnauer",
            "id": "comment-13655346"
        },
        {
            "date": "2013-05-12T01:00:20+0000",
            "content": "\nSteve, I don't think we should do this unless we add a Version.LUCENE_4_3_1. The problem here is that this filter would introduce a totally different behaviour compared to the 4.3 version that we released. If you build your index with 4.3 you would need to reindex if you switch to 4.3.1 unless we add the version so we can fallback on the old behaviour. Makes sense?\n\nI agree, Simon.  I'll remove the lucene-4.3.1-candidate label. ",
            "author": "Steve Rowe",
            "id": "comment-13655415"
        },
        {
            "date": "2013-07-23T18:37:01+0000",
            "content": "Bulk close resolved 4.4 issues ",
            "author": "Steve Rowe",
            "id": "comment-13716719"
        }
    ]
}