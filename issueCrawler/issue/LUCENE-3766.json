{
    "id": "LUCENE-3766",
    "title": "Remove/deprecate Tokenizer's default ctor",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [],
        "type": "Improvement",
        "fix_versions": [
            "3.6",
            "4.0-ALPHA"
        ],
        "affect_versions": "None",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "I was working on a new Tokenizer... and I accidentally forgot to call super(input) (and super.reset(input) from my reset method)... which then meant my correctOffset() calls were silently a no-op; this is very trappy.\n\nFortunately the awesome BaseTokenStreamTestCase caught this (I hit failures because the offsets were not in fact being corrected).\n\nOne minimal thing we can do (but it sounds like from Robert there may be reasons why we can't) is add assert input != null in Tokenizer.correctOffset:\n\n\nIndex: lucene/core/src/java/org/apache/lucene/analysis/Tokenizer.java\n===================================================================\n--- lucene/core/src/java/org/apache/lucene/analysis/Tokenizer.java\t(revision 1242316)\n+++ lucene/core/src/java/org/apache/lucene/analysis/Tokenizer.java\t(working copy)\n@@ -82,6 +82,7 @@\n    * @see CharStream#correctOffset\n    */\n   protected final int correctOffset(int currentOff) {\n+    assert input != null: \"subclass failed to call super(Reader) or super.reset(Reader)\";\n     return (input instanceof CharStream) ? ((CharStream) input).correctOffset(currentOff) : currentOff;\n   }\n\n\n\nBut best would be to remove the default ctor that leaves input null...",
    "attachments": {
        "LUCENE-3766.patch": "https://issues.apache.org/jira/secure/attachment/12513978/LUCENE-3766.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2012-02-09T16:43:17+0000",
            "content": "I think its strange that tokenizer allows a null reader, but we can forget about that temporarily and nuke this default ctor.\n\nThen, we can put assert reader != null in the 'real' ctor and see which analyzers fail.\nMaybe its only PatternAnalyzer and it could be implemented differently/properly (e.g. make a TokenStream).\n\nThen we could also keep our assert. ",
            "author": "Robert Muir",
            "id": "comment-13204631"
        },
        {
            "date": "2012-02-09T17:15:12+0000",
            "content": "As far as I remember this was because of Solr. Some tokenizers in Solr were originally TokenStreams. After we restructured all of them, there is no reason to keep default ctor or allow null at all. ",
            "author": "Uwe Schindler",
            "id": "comment-13204660"
        },
        {
            "date": "2012-02-09T17:47:41+0000",
            "content": "Here's an initial patch.  Tests pass, but, it's hacky to pass new StringReader(\"\") to all those test tokenizers... really they should be TokenStreams instead. ",
            "author": "Michael McCandless",
            "id": "comment-13204689"
        },
        {
            "date": "2012-02-10T13:58:45+0000",
            "content": "updated patch: i tried to clean up these tests some. I think its good to go now. ",
            "author": "Robert Muir",
            "id": "comment-13205460"
        },
        {
            "date": "2012-02-10T18:34:27+0000",
            "content": "+1\n\nI like CannedTokenStream  ",
            "author": "Michael McCandless",
            "id": "comment-13205614"
        }
    ]
}