{
    "id": "LUCENE-893",
    "title": "Increase buffer sizes used during searching",
    "details": {
        "labels": "",
        "priority": "Major",
        "components": [
            "core/search"
        ],
        "type": "Improvement",
        "fix_versions": [],
        "affect_versions": "2.1",
        "resolution": "Won't Fix",
        "status": "Closed"
    },
    "description": "Spinoff of LUCENE-888.\n\nIn LUCENE-888 we increased buffer sizes that impact indexing and found\nsubstantial (10-18%) overall performance gains.\n\nIt's very likely that we can also gain some performance for searching\nby increasing the read buffers in BufferedIndexInput used by\nsearching.\n\nWe need to test performance impact to verify and then pick a good\noverall default buffer size, also being careful not to add too much\noverall HEAP RAM usage because a potentially very large number of\nBufferedIndexInput instances are created during searching\n(# segments X # index files per segment).",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "date": "2007-05-25T20:36:24+0000",
            "content": "> large number of BufferedIndexInput instances are created during searching\n> (# segments X # index files per segment)\n\nThe biggest factor is frequently the number of terms in the query. ",
            "author": "Doug Cutting",
            "id": "comment-12499222"
        },
        {
            "date": "2007-05-25T21:05:03+0000",
            "content": "> > large number of BufferedIndexInput instances are created during searching\n> > (# segments X # index files per segment)\n> \n> The biggest factor is frequently the number of terms in the query.\n\nAhh because we clone the freq/prox streams per term in the query... OK. ",
            "author": "Michael McCandless",
            "id": "comment-12499228"
        },
        {
            "date": "2007-05-26T07:21:20+0000",
            "content": "I ran some performance tests with the same setup I used for LUCENE-866:\n\n\n\t1.2 GB index, optimized, compound format, documents from Wikipedia\n\t50,000 queries, each query has 3 AND terms, each term has a df>100,\n  each query has one or more hits\n\t2.8 GHz Xeon, 4 GB RAM, SCSI HD, Windows Server 2003\n\n\n\nMy tests simply executes all 50k queries in a row and measures the \noverall time. I used the current trunk version patched with LUCENE-888\nand LUCENE-866 and varied the buffer size of the cfs reader. \nHere are the results:  \n\n 1 KB: Time: 51703 ms.\n 2 KB: Time: 50672 ms.\n 4 KB: Time: 50969 ms.\n 8 KB: Time: 57047 ms.\n16 KB: Time: 64547 ms.\n\nI seems that it doesn't really matter if the buffer size is 1 KB, 2 KB,\nor 4 KB. Above 4 KB the performance decreases significantly. \n\nNow the same test with a cfs reader buffer of 1 KB and varying buffer\nsizes for the freq stream in SegmentTermDocs:\n\n 1 KB: Time: 51875 ms.\n 2 KB: Time: 46828 ms.\n 4 KB: Time: 44500 ms.\n 8 KB: Time: 50953 ms.\n16 KB: Time: 64485 ms.\n\nWith 4 KB there is a performance improvement of 14%! But considering\nthe fact that this stream is cloned for every query term, I think\nthat 2 KB is the better choice, still a 10% improvement.\n\nNow I simply vary the readBufferSize for all buffered inputs:\n\n 1 KB: Time: 51778 ms.\n 2 KB: Time: 46172 ms.\n 4 KB: Time: 49000 ms.\n 8 KB: Time: 52187 ms.\n16 KB: Time: 69562 ms.\n\nNow the same test with 50k disjunction queries, 3 terms per query:\n\n1 KB: Time: 288422 ms.\n2 KB: Time: 259672 ms.\n4 KB: Time: 279563 ms.\n\n2 KB for all input buffers seems to be a good compromise. It's about\n10% faster than 1 KB for both types of queries. \n\nQuestion are:\n\n\tCan we afford the increased memory consumption?\n\tIs 2 KB also the best choice on other systems?\n\n ",
            "author": "Michael Busch",
            "id": "comment-12499290"
        },
        {
            "date": "2007-05-26T09:56:11+0000",
            "content": "Michael, \nhow many documents were in index? \nI assume in case where posting are longer bigger buffer brings more benefit,  especially for queries that are on dense terms. \n\nI am bringing this up as optimizing for \"general case\" is hard/impossible due to too many scenarios, influences. Having said that:\n\n1. Maybe we constrain things a bit,  e.g number of docs in index set to 10 Mio as a \"golden standard\"  target for optimization (high number makes sense, as for smaller indexes it is already fast enough, 10% faster from stunning fast is just not all that relevant)... maybe some other ideas what could be considered.\n2. Making it configurable, so everybody could tweak it, you never know what HW or file system one uses...\n ",
            "author": "Eks Dev",
            "id": "comment-12499298"
        },
        {
            "date": "2007-05-26T13:39:24+0000",
            "content": "Do you have any results for non-compound format?\n\nPerhaps CFS may have bigger gains because all CSIndexInput share the same base FSIndexInput, hence CFS needs to call file.seek() more often, even for sequential reads on a particular CSIndexInput? ",
            "author": "Yonik Seeley",
            "id": "comment-12499313"
        },
        {
            "date": "2007-05-26T16:22:15+0000",
            "content": "\n> how many documents were in index? \n\n ~1.1 million\n\n> I assume in case where posting are longer bigger buffer brings \n> more benefit,  especially for queries that are on dense terms. \n\nYes and no... of course for very short posting lists bigger buffers\ndon't speed up things. But on the other hand, on long posting\nlists it is more likely that more skips are performed, so it is also\nquestionable if increasing the buffer size always helps here.\n\n> I am bringing this up as optimizing for \"general case\" is \n> hard/impossible due to too many scenarios, influences. \n\nYes, I definitely agree. I know that my tests are very specific\nto my hardware, OS, queries, documents... Here 2 KB is the magic\nnumber, maybe on other systems it's different. It'd be good if \nothers could run some tests too on other systems.\n\n> 1. Maybe we constrain things a bit,  e.g number of docs in index \n> set to 10 Mio as a \"golden standard\"  target for optimization \n\nHaving constraints is desirable. But maybe it might prevent others\nfrom running tests? It takes time to get 10M docs, build indexes\nwith different settings, get good queries...\n\n> 2. Making it configurable, so everybody could tweak it, you never \n> know what HW or file system one uses...\n\nYes, we could think about adding static getters/setters for \nreadBufferSize and writeBufferSize. ",
            "author": "Michael Busch",
            "id": "comment-12499323"
        },
        {
            "date": "2007-05-26T16:26:48+0000",
            "content": "> Do you have any results for non-compound format?\n\nI converted the index to non-cfs format and reran the same test,\nvarying the readBufferSize (i. e. the buffer size for all input\nstreams). \n\nResults for conjunction queries:\n\n 1 KB: Time: 52422 ms.\n 2 KB: Time: 47718 ms.\n 4 KB: Time: 50078 ms.\n 8 KB: Time: 54719 ms.\n\nResults for disjunction queries:\n\n 1 KB: Time: 291000 ms.\n 2 KB: Time: 266110 ms.\n 4 KB: Time: 258844 ms.\n 8 KB: Time: 279812 ms. \n\nThe results look similar to compound format here. Again 2 KB looks\nlike the best value. ",
            "author": "Michael Busch",
            "id": "comment-12499325"
        },
        {
            "date": "2007-05-26T16:50:06+0000",
            "content": "Some food for thought:\n\nA couple of runs of XBench on hardware that is radically difference in terms of raw performance shows a nearly 4x performance improvement using 256k blocks during sequential access. For random reads the numbers are closer to 20x.\n\nThe trick is determining how much sequential data is (should) be read - the locality of data for the current query along with future queries, since even if Lucene reads extra unneeded data in this run, what is the chance that the data will be needed in future queries (thus having it already in the cache).\n\nIt would seem that these numbers show the ideal solution would vary the buffer size when the engine determines that it is going to read a lot of sequential data (e.g. a wide open range query), and use smaller buffer sizes when it expects only a few results.\n\nMaybe this might shove Lucene down the path where the index is optimized so that common queries terms are always put in a separate segment/index providing a high degree of locality to optimize the reading. Maybe there is some academic research in this area?\n\nDisk Test\t81.23\t\n\t\tSequential\t81.55\t\n\t\t\tUncached Write\t80.69\t33.63 MB/sec [4K blocks]\n\t\t\tUncached Write\t80.94\t33.15 MB/sec [256K blocks]\n\t\t\tUncached Read\t77.68\t12.30 MB/sec [4K blocks]\n\t\t\tUncached Read\t87.48\t35.35 MB/sec [256K blocks]\n\t\tRandom\t80.92\t\n\t\t\tUncached Write\t62.67\t0.94 MB/sec [4K blocks]\n\t\t\tUncached Write\t89.93\t20.28 MB/sec [256K blocks]\n\t\t\tUncached Read\t89.01\t0.59 MB/sec [4K blocks]\n\t\t\tUncached Read\t89.93\t18.51 MB/sec [256K blocks]\n\nDisk Test\t48.34\t\n\t\tSequential\t47.83\t\n\t\t\tUncached Write\t39.10\t16.30 MB/sec [4K blocks]\n\t\t\tUncached Write\t59.73\t24.46 MB/sec [256K blocks]\n\t\t\tUncached Read\t38.72\t6.13 MB/sec [4K blocks]\n\t\t\tUncached Read\t64.56\t26.08 MB/sec [256K blocks]\n\t\tRandom\t48.87\t\n\t\t\tUncached Write\t35.51\t0.53 MB/sec [4K blocks]\n\t\t\tUncached Write\t46.00\t10.37 MB/sec [256K blocks]\n\t\t\tUncached Read\t66.61\t0.44 MB/sec [4K blocks]\n\t\t\tUncached Read\t59.06\t12.15 MB/sec [256K blocks] ",
            "author": "robert engels",
            "id": "comment-12499332"
        },
        {
            "date": "2008-01-13T11:52:22+0000",
            "content": "I think the different results of 26 May 2007 for conjunction queries and disjunction queries may be caused by the use of TermScorer.skipTo() in conjunctions and TermScorer.next() in disjunctions.\n\nThat points to different optimal buffer sizes for conjunctions (smaller because of the skipping) and for disjunctions (larger because all postings are going to be needed).\n\nLUCENE-430 is about reducing term buffer size for the case when the buffer is not going to be used completely because of the small number of documents containing the term.\n\nIn all, I think it makes sense to allow the  (conjunction/disjunction)Scorer to choose the maximum buffer size for the term, and let the term itself choose a lower value when it needs less than that.\n\nAnother way to promote sequential reading for disjunction queries is to process all their terms sequentially, i.e. one term at a time. In lucene this is currently done by Filters for prefix queries and ranges. Unfortunately this cannot be done when the combined frequency of the terms in each document is needed. In that case DisjunctionSumScorer could be used, with larger buffers on the terms that are contained in many documents. ",
            "author": "Paul Elschot",
            "id": "comment-12558386"
        },
        {
            "date": "2008-01-13T12:01:51+0000",
            "content": "The last case is also the one in which scoring docs allowed out of order using BooleanScorer is faster than using DisjunctionSumScorer. This option is already available, but it could have a bigger impact when term buffer sizes are chosen closer to optimal. ",
            "author": "Paul Elschot",
            "id": "comment-12558387"
        },
        {
            "date": "2009-02-25T06:05:39+0000",
            "content": "Someone else on my team did some benchmarks for a query which was slow for us.\n\nWe have a tree of items (one item per document), and given N items, we walk the path from the root to the item until finding an item with certain properties (expected average queries per item is around 3.)  All the queries are against the same field (our unique ID field.)\n\nTimings of this process for 60,000 items:\n\nBuffer size\tTime\n1024\t1015s\n2048\t540s\n4096\t335s\n8196\t281s\n16384\t278s\n32768\t284s\n65536\t322s\n ",
            "author": "Trejkaz",
            "id": "comment-12676521"
        },
        {
            "date": "2013-03-10T13:20:48+0000",
            "content": "SPRING_CLEANING_2013 We can reopen if necessary. Think this code has been extensively re-worked anyway. ",
            "author": "Erick Erickson",
            "id": "comment-13598235"
        }
    ]
}