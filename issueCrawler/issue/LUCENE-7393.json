{
    "id": "LUCENE-7393",
    "title": "Incorrect ICUTokenization on South East Asian Language",
    "details": {
        "resolution": "Fixed",
        "affect_versions": "5.5",
        "components": [
            "modules/analysis"
        ],
        "labels": "",
        "fix_versions": [
            "6.2",
            "7.0"
        ],
        "priority": "Major",
        "status": "Closed",
        "type": "Bug"
    },
    "description": "Lucene 4.10.3 correctly tokenize a syllable into one token.  However in Lucune 5.5.0 it end up being two tokens which is incorrect.  Please let me know segmentation rules are implemented by native speakers of a particular language? In this particular example, it is M-y-a-n-m-a-r language.  I have understood that L-a-o, K-m-e-r and M-y-a-n-m-a-r fall into ICU category.  Thanks a lot.\n\nExample 4.10.3\n\n\nGET _analyze?tokenizer=icu_tokenizer&text=\"\u1014\u100a\u103a\"\n{\n   \"tokens\": [\n      {\n         \"token\": \"\u1014\u100a\u103a\",\n         \"start_offset\": 1,\n         \"end_offset\": 4,\n         \"type\": \"<ALPHANUM>\",\n         \"position\": 1\n      }\n   ]\n}\n\n\n\n\nExample 5.5.0\n\n\nGET _analyze?tokenizer=icu_tokenizer&text=\"\u1014\u100a\u103a\"\n{\n  \"tokens\": [\n    {\n      \"token\": \"\u1014\",\n      \"start_offset\": 0,\n      \"end_offset\": 1,\n      \"type\": \"<ALPHANUM>\",\n      \"position\": 0\n    },\n    {\n      \"token\": \"\u100a\u103a\",\n      \"start_offset\": 1,\n      \"end_offset\": 3,\n      \"type\": \"<ALPHANUM>\",\n      \"position\": 1\n    }\n  ]\n}",
    "attachments": {
        "LUCENE-7393.patch": "https://issues.apache.org/jira/secure/attachment/12819855/LUCENE-7393.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "id": "comment-15391033",
            "author": "Robert Muir",
            "date": "2016-07-24T11:46:20+0000",
            "content": "Hello,\n\n4.10.x used a simple set of rules (https://github.com/apache/lucene-solr/blob/releases/lucene-solr/4.10.4/lucene/analysis/icu/src/data/uax29/Myanmar.rbbi)\n\nNewer versions use ICU's dictionary-based algorithm (http://source.icu-project.org/repos/icu/icu4j/trunk/main/classes/core/src/com/ibm/icu/text/BurmeseBreakEngine.java), but that seems to be the problem here. \n\nYou can see that by testing here: http://unicode.org/cldr/utility/breaks.jsp\n\nI think we should file a bug with ICU.  "
        },
        {
            "id": "comment-15391039",
            "author": "Robert Muir",
            "date": "2016-07-24T12:03:42+0000",
            "content": "Looking at their code, i think you can see the problem. It only has a very simplistic fBeginWordSet and fEndWordSet, but no real handling for syllable structure (for example, no code to handle asat sign). "
        },
        {
            "id": "comment-15391043",
            "author": "Robert Muir",
            "date": "2016-07-24T12:19:04+0000",
            "content": "I opened this bug at ICU: http://bugs.icu-project.org/trac/ticket/12650 "
        },
        {
            "id": "comment-15391046",
            "author": "AM",
            "date": "2016-07-24T12:34:35+0000",
            "content": "Thank you Robert.  4.10.x does a good job even for words borrowed from foreign language.  For example, it would correctly segment \u1018\u1030\u1038\u101c\u103a as one syllable.  There are exceptional rules applied for loan words and it seems like rules in .rbbi file captures it correctly even for these exceptions.  However again in 5.5.0 it would end up two syllables \u1018\u1030\u1038 and \u101c\u103a which is not correct.  Hand coding all the logic in ICU's dictionary-based algorithm seems to be quite challenging.  Rules are more compact and does it nicely I think. \n\nPlease let me know where to find dictionary words use in ICU4j?\n\nMany thanks. "
        },
        {
            "id": "comment-15391047",
            "author": "AM",
            "date": "2016-07-24T12:38:55+0000",
            "content": "Also to clarify 4.10.x uses rules from Lucene project and 5.5.0 uses algorithm from ICU4J project?   "
        },
        {
            "id": "comment-15391056",
            "author": "Robert Muir",
            "date": "2016-07-24T13:00:34+0000",
            "content": "OK, that is interesting to hear. I agree that fixing the hand-coded stuff looks tricky. From my perspective, the ideal solution would first use rules to find syllable breaks: this would restrict where breaks can happen at all, and then the dictionary would just refine that further.\n\nHere is the link for the icu4j dictionary:\nhttp://source.icu-project.org/repos/icu/icu/trunk/source/data/brkitr/dictionaries/burmesedict.txt\n\nPerhaps we should restore the old syllable rules, and make \"syllable\" vs \"word\" available as an option for Myanmar? \n\nI replaced these syllable rules with the ICU dictionary functionality, for two reasons:\n1. Rules were of varying quality depending on language. Lao syllable splitting came from a paper (see https://github.com/apache/lucene-solr/blob/releases/lucene-solr/4.0.0/lucene/analysis/icu/src/data/uax29/Lao.rbbi) which claims > 98% accuracy. This is quite sophisticated and even has backtracking logic. On the other hand, I think the Myanmar rules were just something I came up with (unknown quality)...\n2. Unclear if syllable is a good indexing unit for search. In my mind, syllable-as-token does make sense when the language is mostly monosyllabic, at the same time, we don't have any kind of advanced IR test suites for these languages to really know for sure. "
        },
        {
            "id": "comment-15391057",
            "author": "Robert Muir",
            "date": "2016-07-24T13:03:35+0000",
            "content": "\nAlso to clarify 4.10.x uses rules from Lucene project and 5.5.0 uses algorithm from ICU4J project? \n\nYes, that is correct: For Myanmar language, we upgraded ICU library for 5.0 under this issue: https://issues.apache.org/jira/browse/LUCENE-5995 "
        },
        {
            "id": "comment-15391211",
            "author": "AM",
            "date": "2016-07-25T00:34:48+0000",
            "content": "Yes, syllable vs word option would be perfect.  For the dictionary base approach, some of the words might not always be correct, since semantic meaning of a word depends on the context. For example, '\u101b\u1014\u103a\u1000\u102f\u1014\u103a' means Yangon city and '\u1000\u102f\u1014\u103a\u101e\u100a\u103a' means trader.  But, when we have overlap in the phrase like \u1010\u1000\u103a\u101c\u102c\u101b\u1014\u103a\u1000\u102f\u1014\u103a\u101e\u100a\u103a\u1019\u103b\u102c\u1038\u1000 it should be segmented as \u1010\u1000\u103a|\u101c\u102c|\u101b\u1014\u103a|\u1000\u102f\u1014\u103a\u101e\u100a\u103a|\u1019\u103b\u102c\u1038|\u1000, instead of  \u1010\u1000\u103a|\u101c\u102c|\u101b\u1014\u103a\u1000\u102f\u1014\u103a|\u101e\u100a\u103a|\u1019\u103b\u102c\u1038|\u1000.  As you can see, syllable \u1000\u102f\u1014\u103a is the overlap.  Both words could be in the dictionary and it would require context knowledge to select the correct word and it would be very hard with hand-crafted algorithms.  Anyways, it is still good to have until we have better language understanding.  \n\nWould it be possible to add other words not in the ICU dictionary during analysis? \n\nThanks a lot.  "
        },
        {
            "id": "comment-15391339",
            "author": "Robert Muir",
            "date": "2016-07-25T04:39:02+0000",
            "content": "Here is a patch restoring the previous rule-based algorithm as an option.\n\nSince we may keep it around and improve it in the future, I added some simple tests.\n\nBased on the rules and statistical analysis here, I think we should improve it further to handle more of the special cases (these cases account for less than 1% but we should still try to do better)?\n\n\thttp://www.aclweb.org/anthology/I08-3010\n\thttp://gii2.nagaokaut.ac.jp/gii/media/share/20080901-ZMM%20Presentation.pdf\n\n\n\nSo as a followup issue, I think it would be good to simply adopt the algorithm they developed, to improve that additional 1%. The reason I do not do it here, is because maybe it is best to do that part in ICU itself. Their algorithm does not require huge amounts of context and can be implemented with tables and sets, might be a good solution for the ICU issue.\n "
        },
        {
            "id": "comment-15393642",
            "author": "AM",
            "date": "2016-07-26T11:11:12+0000",
            "content": "Agree, it is better ICU handle it.  To clarify, you meant 1% is for rule base syllable segmentation correct?  Because dictionary base approach for word segmentation would be definitely more than 1% (error rate).  In the ICU algorithm I noticed it does not segment person names.  As a user, if ICU algorithm could identify basic syllables + [Person, Location and Organizations] would be ideal.  But, dictionary is static and new words always popping up in addition to context sensitive nature, so I'm not sure how to handle it.  Rule base syllable algorithm is nearly to its perfection in Lucene and I'm satisfied with it.  Just also curious, where did you got the rules?\n\nI didn't see the patch link though.  \n\nThanks a lot.   "
        },
        {
            "id": "comment-15393761",
            "author": "Robert Muir",
            "date": "2016-07-26T13:11:50+0000",
            "content": "\nTo clarify, you meant 1% is for rule base syllable segmentation correct?\n\nYes: it is unmodified as before but I did some inspection of it. It handles all common structures but has no rules for rarer cases mentioned in that study: syllable chaining, great sa, etc.\n\n\nRule base syllable algorithm is nearly to its perfection in Lucene and I'm satisfied with it. Just also curious, where did you got the rules?\n\nAs I mentioned earlier, I created these almost 7 years ago informally. This is why I was eager to remove these rules, because we know they are not perfect. They were created when Myanmar in unicode was still rapidly changing, and I didn't find such formal algorithms at the time.\n\nThe rules are done in a \"unicode way\", really just using the base consonant and tries to let unicode properties take care of the rest (Word_Break=Extend, etc). It is really not much more than just this main part:\n\n\n$Cons = [[:Other_Letter:]&[:Myanmar:]];\n$Virama = [\\u1039];\n$Asat = [\\u103A];\n\n$ConsEx = $Cons ($Extend | $Format)*;\n$AsatEx = $Cons $Asat ($Virama $ConsEx)? ($Extend | $Format)*;\n$MyanmarSyllableEx = $ConsEx ($Virama $ConsEx)? ($AsatEx)*;\n\n\n\n\nI didn't see the patch link though. \n\nSee the top of this issue: there is an Attachments section, underneath the Description section. "
        },
        {
            "id": "comment-15397652",
            "author": "ASF subversion and git services",
            "date": "2016-07-28T15:01:14+0000",
            "content": "Commit 58f0fbd3767af649da1d47ea62f6f35b1ae28c19 in lucene-solr's branch refs/heads/master from Robert Muir\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=58f0fbd ]\n\nLUCENE-7393: restore old myanmar syllable tokenization as an option. "
        },
        {
            "id": "comment-15397665",
            "author": "ASF subversion and git services",
            "date": "2016-07-28T15:14:26+0000",
            "content": "Commit 5d88b242057177410a90a2ea74b07d6e25b4ac84 in lucene-solr's branch refs/heads/branch_6x from Robert Muir\n[ https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=5d88b24 ]\n\nLUCENE-7393: restore old myanmar syllable tokenization as an option. "
        },
        {
            "id": "comment-15397669",
            "author": "Robert Muir",
            "date": "2016-07-28T15:15:00+0000",
            "content": "Thanks for reporting this AM. "
        },
        {
            "id": "comment-15398497",
            "author": "AM",
            "date": "2016-07-29T00:29:09+0000",
            "content": "Thank you Robert.  Please let me know if there is a way to add more keywords to dictionary at run time?\n "
        },
        {
            "id": "comment-15398513",
            "author": "Robert Muir",
            "date": "2016-07-29T00:50:09+0000",
            "content": "I don't think ICU exposes anything like that. "
        },
        {
            "id": "comment-15400180",
            "author": "AM",
            "date": "2016-07-29T22:58:26+0000",
            "content": "Ok. "
        },
        {
            "id": "comment-15439002",
            "author": "Michael McCandless",
            "date": "2016-08-26T13:59:38+0000",
            "content": "Bulk close resolved issues after 6.2.0 release. "
        }
    ]
}