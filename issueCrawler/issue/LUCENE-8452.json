{
    "id": "LUCENE-8452",
    "title": "BKD-based shape indexing benchmarks",
    "details": {
        "components": [
            "modules/sandbox"
        ],
        "status": "Open",
        "resolution": "Unresolved",
        "fix_versions": [],
        "affect_versions": "None",
        "labels": "",
        "priority": "Major",
        "type": "Improvement"
    },
    "description": "Initial benchmarking of the new BKD-based shape indexing suggest that searches can be somewhat under-performing. \u00a0 I open this ticket to share the findings and to open a discussion how to speed up the solution.\n\n\u00a0\n\nThe first benchmark is done by using the current benchmark in luceneutils for indexing points and search by bounding box. We would expect LatLonShape\u00a0to be slower that LatLonPoint\u00a0but still having a good performance. The results of running such benchmark in my computer looks like:\n\n\u00a0\n\nLatLonPoint:\n\n89.717239531 sec to index\n\nINDEX SIZE: 0.5087761553004384 GB\n\nREADER MB: 0.6098232269287109\n\nmaxDoc=60844404\n\ntotHits=221118844\n\nBEST M hits/sec: 72.91056132596746\n\nBEST QPS: 74.19031323419311\u00a0\n\n\u00a0\n\nLatLonShape:\n\n89.388678805 sec to index\n\nINDEX SIZE: 1.3028179928660393 GB\n\nREADER MB: 0.8827085494995117\n\nmaxDoc=60844404\n\ntotHits=221118844\n\nBEST M hits/sec: 1.0053836784184809\n\nBEST QPS: 1.0230305276205143\n\n\u00a0\n\nA second benchmark has been performed indexing around 10 million 4-side polygons and around 3 million points. Searches are performed using bounding boxes. The results are compared with spatial trees alternatives. Spatial trees use a composite strategy, precision=0.001 degrees and distErrPct=0.25:\n\n\u00a0\n\ns2 (Geo3d):\n\n1191.732124301 sec to index part 0\n\nINDEX SIZE: 3.2086284114047885 GB\n\nREADER MB: 19.453557014465332\n\nmaxDoc=12949519\n\ntotHits=705758537\n\nBEST M hits/sec: 13.311369588840462\n\nBEST QPS: 4.243743434150063\n\n\u00a0\n\nquad (JTS):\n\n3252.62925159 sec to index part 0\n\nINDEX SIZE: 4.5238002222031355 GB\n\nREADER MB: 41.15725612640381\n\nmaxDoc=12949519\n\ntotHits=705758357\n\nBEST M hits/sec: 35.54591930673003\n\nBEST QPS: 11.332252412866938\n\n\u00a0\n\nLatLonShape:\n\n30.32712009 sec to index part 0\n\nINDEX SIZE: 0.5627057952806354 GB\n\nREADER MB: 0.29498958587646484\n\nmaxDoc=12949519\n\ntotHits=705758228\n\nBEST M hits/sec: 3.4130465326433357\n\nBEST QPS: 1.0880999177593018",
    "attachments": {
        "Park.png": "https://issues.apache.org/jira/secure/attachment/12935414/Park.png",
        "BKDperf.pdf": "https://issues.apache.org/jira/secure/attachment/12935007/BKDperf.pdf",
        "River.png": "https://issues.apache.org/jira/secure/attachment/12935416/River.png",
        "Lake.png": "https://issues.apache.org/jira/secure/attachment/12935415/Lake.png"
    },
    "issue_links": {},
    "comments": [
        {
            "id": "comment-16574539",
            "author": "Ignacio Vera",
            "content": "I think one of the keys to understand the performance of BKD-based shape indexing is to analyse\u00a0 how 6-d bounding boxes are transformed into 2-d bounding boxes.\u00a0 Our input is a 6d point representing the minimum value and 6d point representing the maximum value of\u00a0a\u00a0bounding box and we need to transform it into a 2d bounding box to check the relationship with the query shape. The logic to get the 2d bounding box goes as follow:\u00a0\n\nIn a 6-d points\u00a0we have three dimensions\u00a0corresponding to latitudes (0, 2, 4) and the other three for longitude (1,3,5). To build the 2d minimum point of the bounding box from the 6d minimum point, we compute the lat and lon using the minimum value\u00a0of the dimensions for the corresponding lat/lon entries.\u00a0 To build the 2d maximum point of the bounding box from the 6d maximum point, we compute the lat and lon using the maximum value of the dimensions for the corresponding lat/lon entries. \u00a0\n\nFor example: We have the following bounding box in 6d and the corresponding bounding box in 2d:\n\nMin: (0,0,0,0,0,0) -> (0,0)\n\nMax: (90,90,90,90,90,90)\u00a0 -> (90,90)\n\n\u00a0\n\nSplit first dimension in half:\n\n\u00a0\n\nLeft tree:\n\nMin: (0,0,0,0,0,0) -> (0,0)\n\nMax: (45,90,90,90,90,90)\u00a0 -> (90,90)\n\nRight tree:\n\nMin: (45,0,0,0,0,0) -> (0,0)\n\nMax: (90,90,90,90,90,90)\u00a0 -> (90,90)\n\n\u00a0\n\nUsing left tree, split\u00a0 third dimension in half :\n\n\u00a0\n\nLeft-Left tree:\n\nMin: (0,0,0,0,0,0) -> (0,0)\n\nMax: (45,90,45,90,90,90)\u00a0 -> (90,90)\n\nLeft-Right tree:\n\nMin: (45,0,45,0,0,0) -> (0,0)\n\nMax: (90,90,90,90,90,90)\u00a0 -> (90,90)\n\n\u00a0\n\nUsing left tree, split fifth\u00a0dimension in half :\n\n\u00a0\n\nLeft-Left-Left tree:\n\nMin: (0,0,0,0,0,0) -> (0,0)\n\nMax: (45,90,45,90,45,90)\u00a0 -> (45,90)\n\nLeft-Left-Right tree:\n\nMin: (45,0,45,0,45,0) -> (45,0)\n\nMax: (90,90,90,90,90,90)\u00a0 -> (90,90)\n\n\u00a0\n\n\u00a0We have to\u00a0split all three dimension for latitude to actually have an effect on the 2-d bounding box. Which means that we need to visit many nodes of the tree before we actually filter out some of the branches.\n\nNicholas Knize, does it make sense to you? ",
            "date": "2018-08-09T09:14:05+0000"
        },
        {
            "id": "comment-16574980",
            "author": "Nicholas Knize",
            "content": "Thanks for putting this together Ignacio Vera. Its a great start to benchmarking BKD with data higher than two dimensions. In fact, I don't think we've ever fully benchmarked past two dimensions, and the current POINTS implementation supports up to eight.  For this particular geo usecase it would be nice to put together some shape benchmarks with more representative real world data, along with different relation queries, and add to the nightly geo benchmarks. A good representative set I've been looking at for some time is the osm data which contain a fair number of linestrings, closed linestrings, and polygons with number of vertices much higher than 4.\n\nThis first benchmarking step certainly highlights the deficiency of the BKD split and merge algorithms for high dimension data. Its a side effect of their naivety; which was chosen simply for ease of implementation. And indexing LatLonShape with only point and bounding box data is going to highlight those deficiencies quite spectacularly - if only due to the dimensional expansion issue (especially with point shapes). There are a lot of optimizations in the literature that could (and should) be applied for well past two dimensions. For example x-tree has some nice heuristics for avoiding the sliver problem that occurs much more frequently in high dimension data. And we could also investigate different encoding methods for LatLonShape 's tessellated triangles. For now, it would be good to capture performance across various datasets and carefully note in the javadocs what tradeoffs should be considered for certain datasets (i.e., don't use LatLonShape if you're only indexing/searching points). In the meantime, we can investigate best approaches for strengthening the BKD split/merge algorithms for the general high dimension use-case (similar to what was done for the 1d usecase) and possibly revisit the idea of a new codec derived from BKD that is intended for the higher dimension usecase. ",
            "date": "2018-08-09T15:12:24+0000"
        },
        {
            "id": "comment-16575153",
            "author": "Ignacio Vera",
            "content": "What it actually concerns me is that the\u00a0dimensions are not independent. That has a big impact for the case of points only as the splitting only has effect when all the dependent dimensions have been splitted.\u00a0\n\nOut of curiosity, we have benchmarks for the 3d case for geo3d. I did run an experiment to see how the BKD tree behaves for different dimensions by running the geo benchmark for different number of points and dimensions. Attached are the resulting plots. The experiment was not run in a control environment so it needs to be interpreted with care.\n\nThe most interesting plot is the size of the reader which shows the different implementation in case of 1d and in the case of Nd (N>1). ",
            "date": "2018-08-09T17:14:39+0000"
        },
        {
            "id": "comment-16575338",
            "author": "Nicholas Knize",
            "content": "the dimensions are not independent.\n\nThat's what I mean by \"...due to the dimensional expansion issue (especially with point shapes).\" For point shapes, LatLonShape does the opposite of Principal Component Analysis. Instead of reducing dimensionality it expands it from two to six and subsequently perfectly correlates dimensions 1, 3, 5 and 2, 4, 6. It is not at all optimal and not at all expected to perform anywhere close to a structure optimized for true two dimension point space. In fact it goes against every concept of a optimal structure.\n\nto see how the BKD tree behaves for different dimensions\n\nAs I mentioned, the split/merge algorithms for BKD are naive for ease of implementation. Given the lack of heuristics along dimensions I'd expect QPS/HPS to drop as more dimensions are added.  Add a high level of correlation between dimensions and I'd expect it to get even worse. Certainly, for high dimension indexing, work will need to be done to optimize the BKD structure. Alternatively, we can work on a separate codec (possibly a R*/X/PR-tree hybrid) derived from the current BKD implementation that is designed for higher dimension space - since the kd structure itself was not designed for such applications. And subsequently restrict BKD to two dimensions only.  ",
            "date": "2018-08-09T20:06:00+0000"
        },
        {
            "id": "comment-16576334",
            "author": "Michael McCandless",
            "content": "Maybe we can fold these new shape benchmarks into luceneutil so it runs nightly? ",
            "date": "2018-08-10T14:21:02+0000"
        },
        {
            "id": "comment-16576386",
            "author": "Ignacio Vera",
            "content": "Before moving it into luceneutil I would like to agree in the format\u00a0for the benchmark datasets. I guess we have two options:\n\n1 )\u00a0\u00a0WKT:\u00a0\u00a0org.apache.lucene.geo.Polygon only supports GeoJSON, therefore we would have to add\u00a0 a SimpleWKTPolygonParser to org.apache.lucene.geo package similar to SimpleGeoJSONPolygonParser. WKT seems a more compact structure.\n\n2) \u00a0GeoJSON: Maybe the price of the verbosity of JSON is not too bad.\n\n\u00a0\n\n\u00a0\n\n\u00a0\n\n\u00a0\n\n\u00a0 ",
            "date": "2018-08-10T14:56:17+0000"
        },
        {
            "id": "comment-16576393",
            "author": "David Smiley",
            "content": "For WKT, there's already parsing in Spatial4J, a dependency of spatial-extras.... so the jar's should be there for the lucene-util benchmark to pick up.\n\nThis isn't to say Lucene itself should or shouldn't parse WKT but that's a new JIRA for sure and needn't delay the benchmarks. ",
            "date": "2018-08-10T15:06:42+0000"
        },
        {
            "id": "comment-16576408",
            "author": "Ignacio Vera",
            "content": "Thinking about this, we can make the format configurable with a flag.\u00a0 ",
            "date": "2018-08-10T15:13:38+0000"
        },
        {
            "id": "comment-16578650",
            "author": "Adrien Grand",
            "content": "What it actually concerns me is that the dimensions are not independent.\nwe could also investigate different encoding methods for LatLonShape 's tessellated triangles\n\nMaybe we could make them independent, eg. by indexing (x1, y1, x2 - x1, y2 - y1, x3 - x1, y3 - y1) instead of (x1, y1, x2, y2, x3, y3)? In addition to making dimensions independent, it would also have the nice property that an index that only has points should perform almost as well as LatLonPoint since it would partition the space exactly the same way.\n\nLUCENE-7862 is also a simple change that I would expect to help a lot with such high numbers of dimensions, especially when there is correlation. ",
            "date": "2018-08-13T17:23:07+0000"
        },
        {
            "id": "comment-16578730",
            "author": "Nicholas Knize",
            "content": "+1 Adrien Grand I'm toying around with that approach a bit and can post some benchmark numbers when I have them.\n\nAs a side note (that may be of interest) I went ahead and extracted all linestrings, multilinestrings, and multipolygons from the latest planet OSM snapshot to run some local scale benchmarks and general tests with real world shape data. I converted the data from .pbf to WKT for easy ingest in luceneutil (and already have a WKT parser for LatLonShape\u00a0- lines and polygons - that I can commit to luceneutil separately if interested). The data is quite large, and very good (real world w/ varying spatial extents, vertex counts, etc). If there is any interest I can extract a smaller set (e.g., 60M shapes to complement the 60M points in geobench) and make available for geo nightly benchmarks.\n\nHere are the numbers for the entire corpus of data:\n\n\n\nType\nCount\nFile Size\n\n\nLINESTRING\n157,075,680\n88GB\n\n\nMULTILINESTRING\n532,043\n7.1GB\n\n\nMULTIPOLYGON\n351,975,024\n164GB\n\n\n\n\n\nHere are\u00a0three simple examples of the type of shape data contained in the planet OSM corpus (river, lake, and park polygons):\n\n\n \n  ",
            "date": "2018-08-13T18:06:09+0000"
        },
        {
            "id": "comment-16579481",
            "author": "Adrien Grand",
            "content": "This looks like a nice dataset for benchmarking indeed! ",
            "date": "2018-08-14T09:04:33+0000"
        },
        {
            "id": "comment-16579547",
            "author": "Ignacio Vera",
            "content": "we could make them independent, eg. by indexing (x1, y1, x2 - x1, y2 - y1, x3 - x1, y3 - y1) instead of (x1, y1, x2, y2, x3, y3)\n+1,\u00a0it\u00a0looks promising...\n\n\u00a0\nalready have a WKT parser for LatLonShape\u00a0- lines and polygons - that I can commit to luceneutil separately if interested\nIs there any reason not to add this utility\u00a0to Lucene? It looks to me it would be very useful. (Note: We currently have the class SimpleGeoJSONPolygonParser which it seems to me it was added to support the GeoBenchmark for points).\n\n\u00a0\nI can extract a smaller set (e.g., 60M shapes to complement the 60M points in geobench)\n\u00a0\n\nAwesome, but note that with 60M shapes we might not be able to compare the performance with spatial trees because\u00a0it\u00a0probably takes too long to index the data.\u00a0\n\n\u00a0 ",
            "date": "2018-08-14T09:44:12+0000"
        }
    ]
}