{
    "id": "SOLR-1980",
    "title": "Implement boundary match support",
    "details": {
        "affect_versions": "None",
        "status": "Open",
        "fix_versions": [],
        "components": [
            "query parsers",
            "Schema and Analysis"
        ],
        "type": "New Feature",
        "priority": "Major",
        "labels": "",
        "resolution": "Unresolved"
    },
    "description": "Sometimes you need to specify that a query should match only at the start or end of a field, or be an exact match.\n\nWe should have a query syntax for boundary match, preferably on a lowest possible level such as the \"lucene\" query parser.",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "author": "Lance Norskog",
            "id": "comment-12884147",
            "date": "2010-07-01T03:38:33+0000",
            "content": "Another use case is with phrases, especially sloppy phrases.\n\"^hello kitty\" would find \"hello kitty\" at the beginning of the text.\n\"^hello\"~5 would find \"hello\" among the first 5 words, but the closer to the beginning, the better. This is especially interesting for consumer searches- people tend to type the first word of a movie title first. "
        },
        {
            "author": "Otis Gospodnetic",
            "id": "comment-12895937",
            "date": "2010-08-06T03:25:54+0000",
            "content": "What about Span queries - no use here? http://search-lucene.com/jd/lucene/org/apache/lucene/search/spans/SpanQuery.html "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-12896016",
            "date": "2010-08-06T10:53:07+0000",
            "content": "Phrase slop would work as before if the ^ and $ are encoded as simple special tokens in the index.\n\nFor multi-valued fields, each sub value need to be tagged.\n\nI think the \"^a b c$\" syntax is pretty easy to understand. But does it crash with any other feature or special char? Perhaps some existing regex stuff that I don't know about? "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-13000249",
            "date": "2011-02-28T11:58:25+0000",
            "content": "I have tried to implement this as a CharFilter and it works pretty well.\n\nThe problem I face is that inserting extra bytes at the beginning and end of the charstream does not play well with highlighting. I get an error:\n\norg.apache.solr.common.SolrException: org.apache.lucene.search.highlight.InvalidTokenOffsetsException: Token card exceeds length of provided text sized 43\n\tat org.apache.solr.highlight.DefaultSolrHighlighter.doHighlightingByHighlighter(DefaultSolrHighlighter.java:473)\n\tat org.apache.solr.highlight.DefaultSolrHighlighter.doHighlighting(DefaultSolrHighlighter.java:378)\n\tat org.apache.solr.handler.component.HighlightComponent.process(HighlightComponent.java:121) "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-13043248",
            "date": "2011-06-03T08:21:31+0000",
            "content": "Really, this is a type of feature that should be implemented on the Lucene level with proper query language support. Any suggestion on how this could be done, perhaps using the positions and #terms metadata from the index instead of inserting special tokens at begin and end? "
        },
        {
            "author": "Dawid Weiss",
            "id": "comment-13043252",
            "date": "2011-06-03T08:39:55+0000",
            "content": "Isn't it what regexp query (automaton-based) currently does (and does it efficiently)? "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-13043261",
            "date": "2011-06-03T09:09:00+0000",
            "content": "Is this backed by the Lucene Query parser? How would you query q=\"^quick fox$\" with the regex query? "
        },
        {
            "author": "Dawid Weiss",
            "id": "comment-13043290",
            "date": "2011-06-03T10:37:12+0000",
            "content": "Yep, it should be \u2013 qp.parse(\"/^quick fox$/\"). Peek at TestQueryParser#testRegexps "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13043332",
            "date": "2011-06-03T12:44:02+0000",
            "content": "you just don't need the anchors for this one (its implied).\n\nthe syntax is here: http://www.brics.dk/automaton/doc/dk/brics/automaton/RegExp.html\n\ni don't know if this really solves your problems, as you are talking about multiple tokens.\n\njust remember, users have trouble understanding how wildcards interact with stemming and such, so I don't see regexp queries spanning across multiple tokens (analyzed) anytime soon... "
        },
        {
            "author": "Dawid Weiss",
            "id": "comment-13043334",
            "date": "2011-06-03T12:46:42+0000",
            "content": "Right... multiple tokens will be an issue here, didn't think of that. "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13043338",
            "date": "2011-06-03T12:53:26+0000",
            "content": "well its fine if you are doing matching on something really short, you could index with keywordtokenizer and use this for some use cases. "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-13043399",
            "date": "2011-06-03T15:26:03+0000",
            "content": "I'm sure I can get it working the way I started, using CharFilter, however perhaps it's possible to implement in a more generic and Lucene-like query syntax utilizing position info from the index:\n\n\n title:\"quick fox\"@N:M\n\n\nThis would mean that the phrase must be anchored between N'th and M'th token position in the field. Negative values for N/M would mean relative to the end. Thus \"^quick fox$\" could be written\n\n title:\"quick fox\"@0:-0\n\n\nOr if you require the phrase to be within first 10 words OR last 10 words:\n\n title:(\"quick fox\"@0:10 OR \"quick fox\"@-10:-0)\n\n\nRequiring a term to be exactly @ position 3 would be:\n\n title:fox@3:3\n\n\n\nIf this syntax is feasible, we could use same syntax in eDisMax's pf param in order to tell it to add a position constraint when forming the pf part of the query:\n\n pf=title@0:-0\n\n\nThis would only generate a phrase match on title if the phrase is an exact match of the whole field.\n\nPotential issues with multi-valued fields? Is the field delimiter clearly marked or is it only an increment gap?\n\nWould it be easy to parse such a syntax and generate a Lucene query with the position constraints? "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-13251523",
            "date": "2012-04-11T13:05:05+0000",
            "content": "Tagging this for 4.0, hoping to revive some work on it...\n\nBtw. Any comments to my last syntax suggestion, utilizing term positions @N:M ? "
        },
        {
            "author": "Jan H\u00f8ydahl",
            "id": "comment-13251525",
            "date": "2012-04-11T13:08:08+0000",
            "content": "Shortening down the description field. I removed these paragraphs:\n\nProposed way of implmementation is through a new BoundaryMatchTokenFilter which behaves like this:\nOn the index side it inserts special unique tokens at beginning and end of field. These could be some weird unicode sequence.\nOn the query side, it looks for the first character matching \"^\" or the last character matching \"$\" and replaces them with the special tokens. "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13412211",
            "date": "2012-07-11T22:26:24+0000",
            "content": "bulk fixing the version info for 4.0-ALPHA and 4.0 all affected issues have \"hoss20120711-bulk-40-change\" in comment "
        },
        {
            "author": "Robert Muir",
            "id": "comment-13429787",
            "date": "2012-08-07T03:43:02+0000",
            "content": "rmuir20120906-bulk-40-change "
        },
        {
            "author": "Hoss Man",
            "id": "comment-13451043",
            "date": "2012-09-07T22:01:28+0000",
            "content": "removing fixVersion=4.0 since there is no evidence that anyone is currently working on this issue.  (this can certainly be revisited if volunteers step forward) "
        }
    ]
}