{
    "id": "LUCENE-2470",
    "title": "Add conditional braching/merging to Lucene's analysis pipeline",
    "details": {
        "labels": "",
        "priority": "Minor",
        "components": [
            "modules/analysis"
        ],
        "type": "New Feature",
        "fix_versions": [],
        "affect_versions": "4.0-ALPHA",
        "resolution": "Unresolved",
        "status": "Open"
    },
    "description": "Captured from a #lucene brainstorming session with Robert Muir:\n\nLucene's analysis pipeline would be more flexible if it were possible to apply filter(s) to only part of an input stream's tokens, under user-specifiable conditions (e.g. when a given token attribute has a particular value) in a way that did not place that responsibility on individual filters.\n\nTwo use cases:\n\n\n\tStandardAnalyzer could directly handle ideographic characters in the same way as CJKTokenizer, which generates bigrams, if it could call ShingleFilter only when the TypeAttribute=<CJK>, or if Robert's new ScriptAttribute=<Ideographic>.\n\tStemming might make sense for some stemmer/domain combinations only when token length exceeds some threshold.  For example, a user could configure an analyzer to stem only when CharTermAttribute length is greater than 4 characters.\n\n\n\nOne potential way to achieve this conditional branching facility is with a new kind of filter that can be configured with one or more following filters and condition(s) under which the filter should be engaged.  This could be called BranchingFilter.\n\nI think a MergingFilter, the inverse of BranchingFilter, is necessary in the current pipeline architecture, to have a single pipeline endpoint.  A MergingFilter might be useful in its own right, e.g. to collect document data from multiple sources.  Perhaps a conditional merging facility would be useful as well.",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "date": "2010-05-19T17:35:29+0000",
            "content": "One more thing from #lucene: if a conditionally-applied filter isn't given one or more input stream tokens, it could either be reset(), or it could detect position increment gaps.  Maybe both behaviors should be selectable via configuration? ",
            "author": "Steve Rowe",
            "id": "comment-12869217"
        },
        {
            "date": "2010-05-19T20:00:13+0000",
            "content": "This is a great idea!\n\nIt'd give us much more composability in the analysis pipeline, since\nindividual filters (Shingle, Stem) would be fully independent, ie not\naware that they are being invoked from the BranchingFilter.\n\nI think we should allow the conditional to switch between\nsub-pipelines?  EG I could make a stage that detects proper names\n(say)... and if the token is not a proper name, it'll run through a\nLowercaseFilter then StopFilter, else it passes through.  So the\nconditional would switch between full sub-pipelines.\n\nWe should also allow for 1 -> many sub-pipelines, eg you conditionally\ninvoke an ngram filter.  Or many -> may, eg you conditionally invoke a\nshingle filters.\n\nI think upgrading the analysis pipeline to write-once attr bindings\n(LUCENE-2450) would make this BranchingFilter easier to implement.\n\nWith write-once bindings, there's full visibility on which attrs a\nStage writes to (changes).  So this BranchingStage could easily\nintrospect to see which attrs its subs write to, invoke them as the\nconditions require, and if none of the conditions apply, copy over the\nnecessary attrs. ",
            "author": "Michael McCandless",
            "id": "comment-12869297"
        },
        {
            "date": "2010-05-19T20:09:04+0000",
            "content": "\nI think we should allow the conditional to switch between\nsub-pipelines? EG I could make a stage that detects proper names\n(say)... and if the token is not a proper name, it'll run through a\nLowercaseFilter then StopFilter, else it passes through. So the\nconditional would switch between full sub-pipelines.\n\nI really like this aspect of the idea. Besides the language issues that\nSteven brought up, we could start to look at the KeywordAttribute/KeywordMarker\nas a \"hack\", and this is a more generalized way to look at it.\n\nI think the real key is, if we can make it nice to do this declaratively,\nfor example in a Solr schema definition.\n\nThis way, someone with a multilanguage document/query could apply\nconditional pipelines to different parts, someone could do the 'keyword'\nstuff (but this might be based on length, their own custom attribute, POS,\nwhatever they want).\n\nIn truth I think there are a lot of hardcoded 'conditions/parameters' in the \nanalysis components right now. Something like this would allow pieces to\n be more general/reusable and flexible. ",
            "author": "Robert Muir",
            "id": "comment-12869302"
        },
        {
            "date": "2010-05-19T20:13:30+0000",
            "content": "I think we should allow the conditional to switch between sub-pipelines? EG I could make a stage that detects proper names (say)... and if the token is not a proper name, it'll run through a LowercaseFilter then StopFilter, else it passes through. So the conditional would switch between full sub-pipelines.\n\nI think one consequence of this design is that the BranchingFilter/Stage would have to do its own merging, so MergingFilter is not necessary, right?\n\nThe other uses for a MergingFilter should be put into another issue, if we go with this design and there is interest, switching this issue to cover only BranchingFilter/Stage.\n ",
            "author": "Steve Rowe",
            "id": "comment-12869307"
        },
        {
            "date": "2010-05-19T20:23:22+0000",
            "content": "We should also allow for 1 -> many sub-pipelines, eg you conditionally invoke an ngram filter.  Or many -> may, eg you conditionally invoke a shingle filters.\n\nDo you mean that it should be possible to configure multiple filters to process the same input token?  If so, then we could e.g. remove the \"outputUnigram\" option from ShingleFilter, and configure both a PassThroughFilter and a ShingleFilter to operate simultaneously over the same inputs.\n ",
            "author": "Steve Rowe",
            "id": "comment-12869317"
        },
        {
            "date": "2010-05-19T20:25:19+0000",
            "content": "Before I forget: It's always bugged me that analysis output can only be to a single field.  Could this be the place to fix that? ",
            "author": "Steve Rowe",
            "id": "comment-12869319"
        },
        {
            "date": "2010-05-19T20:36:44+0000",
            "content": "I think one consequence of this design is that the BranchingFilter/Stage would have to do its own merging, so MergingFilter is not necessary, right?\n\nRight.\n\nThe other uses for a MergingFilter should be put into another issue, if we go with this design and there is interest, switching this issue to cover only BranchingFilter/Stage.\n\nThese are interesting too!\n\nDo you mean that it should be possible to configure multiple filters to process the same input token?\n\nActually I didn't \u2013 I meant that we should allow a sub-pipeline to process 1 token and produce (say) 3.  But it is a neat idea to allow more than one sub to operate; I like the PassThroughFilter.\n\nBefore I forget: It's always bugged me that analysis output can only be to a single field. Could this be the place to fix that?\n\nThat's a biggish change   I think we should tackle it separately \u2013 we'd have to change indexer for this (right now it visits one field at a time, processing all of its tokens).\n\nBut, I do think this write-once attr approach could be used as a document pre-processing pipeline, eg to enhance the doc, pull out additional fields, etc. ",
            "author": "Michael McCandless",
            "id": "comment-12869322"
        },
        {
            "date": "2010-05-19T20:44:06+0000",
            "content": "I think the real key is, if we can make it nice to do this declaratively, for example in a Solr schema definition.\n\nI agree.\n\nWe could start with a BranchingStageFactory that takes in a structured conditional processing specification, but I have the feeling that it will seem like declarative specification of the entire analysis pipeline, ala Solr, is the way to go.\n ",
            "author": "Steve Rowe",
            "id": "comment-12869326"
        }
    ]
}