{
    "id": "SOLR-10215",
    "title": "Cannot use the namenode for HDFS HA as of Solr 6.4",
    "details": {
        "labels": "",
        "priority": "Blocker",
        "components": [
            "Hadoop Integration"
        ],
        "type": "Bug",
        "fix_versions": [
            "6.4.2"
        ],
        "affect_versions": "6.4,                                            6.4.1",
        "resolution": "Fixed",
        "status": "Resolved"
    },
    "description": "As of Solr 6.4, it seems it's no longer possible to use a namenode instead of a server address with the solr.hdfs.home parameter when configuring Solr with HDFS high availability (HA).\n\nStartup is fine, but when trying to create a collection, this error is in the logs:\n\n\n2017-02-27 22:22:57.359 ERROR (qtp401424608-21) [c:testing s:shard1  x:testing_shard1_replica1] o.a.s.c.CoreContainer Error creating core [testing_shard1_replica1]: Error Instantiating Update Handler, solr.DirectUpdateHandler2 failed to instantiate org.apache.solr.update.UpdateHandler\norg.apache.solr.common.SolrException: Error Instantiating Update Handler, solr.DirectUpdateHandler2 failed to instantiate org.apache.solr.update.UpdateHandler\n\n\n\nAnd after the full stack trace (which I will put in a comment), there is this:\n\n\nCaused by: java.lang.IllegalArgumentException: java.net.UnknownHostException: mycluster\n\n\n\nI started Solr with the params configured as system params instead of in solrconfig.xml, so my solr.in.sh has this:\n\n\nSOLR_OPTS=\"$SOLR_OPTS $SOLR_ZK_CREDS_AND_ACLS -Dsolr.directoryFactory=HdfsDirectoryFactory -Dsolr.lock.type=hdfs -Dsolr.hdfs.home=hdfs://mycluster:8020/solr-index -Dsolr.hdfs.confdir=/etc/hadoop/conf/\"\n\n\n\nSolr in this case is running on the same nodes as Hadoop (Hortonworks HDP 2.5).\n\nI tried with a couple variations of defining the Solr home parameter:\n\n\n\thdfs://mycluster:8020/solr-index\n\thdfs://mycluster/solr-index\n\tsolr-index\n\n\n\nNone of these variations worked with Solr 6.4.1 (the first 2 got the same error as above, the last was just wrong so it got a different error).\n\nI believe this problem is isolated to Solr 6.4.x. I tested the same setup (as in the solr.in.sh above) with 6.3.0 and it worked fine. Using the server address also works fine, but that negates the High Availability feature (which is like failover, for those who don't know).\n\nedit: the problem isn't just 6.4.1, I believe it's probably in 6.4.0 also",
    "attachments": {},
    "issue_links": {},
    "comments": [
        {
            "date": "2017-02-28T15:37:00+0000",
            "content": "Full stacktrace:\n\n\n2017-02-27 22:22:57.359 ERROR (qtp401424608-21) [c:testing s:shard1  x:testing_shard1_replica1] o.a.s.c.CoreContainer Error creating core [testing_shard1_replica1]: Error Instantiating Update Handler, solr.DirectUpdateHandler2 failed to instantiate org.apache.solr.update.UpdateHandler\norg.apache.solr.common.SolrException: Error Instantiating Update Handler, solr.DirectUpdateHandler2 failed to instantiate org.apache.solr.update.UpdateHandler\n        at org.apache.solr.core.SolrCore.<init>(SolrCore.java:959)\n        at org.apache.solr.core.SolrCore.<init>(SolrCore.java:823)\n        at org.apache.solr.core.CoreContainer.create(CoreContainer.java:890)\n        at org.apache.solr.core.CoreContainer.create(CoreContainer.java:827)\n        at org.apache.solr.handler.admin.CoreAdminOperation.lambda$static$0(CoreAdminOperation.java:88)\n        at org.apache.solr.handler.admin.CoreAdminOperation.execute(CoreAdminOperation.java:377)\n        at org.apache.solr.handler.admin.CoreAdminHandler$CallInfo.call(CoreAdminHandler.java:379)\n        at org.apache.solr.handler.admin.CoreAdminHandler.handleRequestBody(CoreAdminHandler.java:165)\n        at org.apache.solr.handler.RequestHandlerBase.handleRequest(RequestHandlerBase.java:166)\n        at org.apache.solr.servlet.HttpSolrCall.handleAdminRequest(HttpSolrCall.java:664)\n        at org.apache.solr.servlet.HttpSolrCall.call(HttpSolrCall.java:445)\n        at org.apache.solr.servlet.SolrDispatchFilter.doFilter(SolrDispatchFilter.java:345)\n        at org.apache.solr.servlet.SolrDispatchFilter.doFilter(SolrDispatchFilter.java:296)\n        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1691)\n        at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:582)\n        at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)\n        at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)\n        at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)\n        at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)\n        at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)\n        at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)\n        at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)\n        at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n        at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)\n        at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)\n        at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)\n        at org.eclipse.jetty.server.Server.handle(Server.java:534)\n        at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:320)\n        at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)\n        at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:273)\n        at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:95)\n        at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)\n        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)\n        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)\n        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)\n        at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)\n        at java.lang.Thread.run(Thread.java:745)\nCaused by: org.apache.solr.common.SolrException: Error Instantiating Update Handler, solr.DirectUpdateHandler2 failed to instantiate org.apache.solr.update.UpdateHandler\n        at org.apache.solr.core.SolrCore.createInstance(SolrCore.java:767)\n        at org.apache.solr.core.SolrCore.createUpdateHandler(SolrCore.java:815)\n        at org.apache.solr.core.SolrCore.initUpdateHandler(SolrCore.java:1065)\n        at org.apache.solr.core.SolrCore.<init>(SolrCore.java:930)\n        ... 37 more\nCaused by: java.lang.reflect.InvocationTargetException\n        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n        at java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n        at org.apache.solr.core.SolrCore.createInstance(SolrCore.java:753)\n        ... 40 more\nCaused by: java.lang.IllegalArgumentException: java.net.UnknownHostException: mycluster\n        at org.apache.hadoop.security.SecurityUtil.buildTokenService(SecurityUtil.java:378)\n        at org.apache.hadoop.hdfs.NameNodeProxies.createNonHAProxy(NameNodeProxies.java:310)\n        at org.apache.hadoop.hdfs.NameNodeProxies.createProxy(NameNodeProxies.java:176)\n        at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:678)\n        at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:619)\n        at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:149)\n        at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2653)\n        at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:368)\n        at org.apache.solr.update.HdfsUpdateLog.init(HdfsUpdateLog.java:145)\n        at org.apache.solr.update.UpdateHandler.<init>(UpdateHandler.java:137)\n        at org.apache.solr.update.UpdateHandler.<init>(UpdateHandler.java:94)\n        at org.apache.solr.update.DirectUpdateHandler2.<init>(DirectUpdateHandler2.java:102)\n        ... 45 more\nCaused by: java.net.UnknownHostException: mycluster\n        ... 57 more\n\n ",
            "author": "Cassandra Targett",
            "id": "comment-15888252"
        },
        {
            "date": "2017-02-28T16:53:35+0000",
            "content": "Seems to be a major regression, and should be part of 6.4.2. Marking this as a blocker, and holding off on the 6.4.2 RC for now, until someone can take a look. ",
            "author": "Ishan Chattopadhyaya",
            "id": "comment-15888429"
        },
        {
            "date": "2017-02-28T17:04:32+0000",
            "content": "The contents of /etc/hadoop/conf/ has the correct core-site.xml and hadoop-site.xml? ",
            "author": "Kevin Risden",
            "id": "comment-15888450"
        },
        {
            "date": "2017-02-28T17:07:17+0000",
            "content": "Usually I'll use the follow command to start Solr with HDFS so it pulls the right configs:\n\n\n-Dsolr.hdfs.home=$(hdfs getconf -confKey fs.defaultFS)/apps/solr -Dsolr.hdfs.confdir=/etc/hadoop/conf\n\n\n\nhdfs getconf -confKey fs.defaultFS will guarantee that the right HDFS home is used. It requires that /etc/hadoop/conf has the right config files. ",
            "author": "Kevin Risden",
            "id": "comment-15888458"
        },
        {
            "date": "2017-02-28T18:35:44+0000",
            "content": "The contents of /etc/hadoop/conf/ has the correct core-site.xml and hadoop-site.xml?\n\nYeah, I'm pretty sure it is. Solr 6.3 works with the same exact Hadoop cluster, and I copied/pasted the params from the 6.4.1 solr.in.sh to the 6.3.0 solr.in.sh. ",
            "author": "Cassandra Targett",
            "id": "comment-15888613"
        },
        {
            "date": "2017-02-28T22:45:17+0000",
            "content": "With Hoss' kind assistance, I did a git bisect on the commits between releases/solr/6.4.0 and releases/solr/6.3.0 and traced when this went bad to:\n\n\nc40cd2df49c80aee1ab2b6fea634191edc8b944f is the first bad commit\ncommit c40cd2df49c80aee1ab2b6fea634191edc8b944f\nAuthor: Andrzej Bialecki <ab@apache.org>\nDate:   Tue Jan 3 14:58:07 2017 +0100\n\n   SOLR-9854: Collect metrics for index merges and index store IO (squashed).\n\n:040000 040000 a3fd94768739f287b9afb9186cbf37f870080e86 23b7bba0a00be03b8a453d8fdd2fd586e8f36441 M    solr\nbisect run success\n\n\n\nHowever, the good news appears to be that this is already fixed already in branch_6_4; I'm going to assume SOLR-10182 fixes it.\n\nTomorrow morning I'll do a build of that branch locally and check it again, but am going to resolve this as fixed for now. ",
            "author": "Cassandra Targett",
            "id": "comment-15889012"
        },
        {
            "date": "2017-03-01T02:48:32+0000",
            "content": "I can confirm that 6.4.1 doesn't work with HDFS NameNode HA. 6.3.0 works just fine. The nightly build of 6.5.0 from https://builds.apache.org/job/Solr-Artifacts-6.x/lastSuccessfulBuild/artifact/solr/package/solr-6.5.0-254.tgz works as well.\n\nMy testing setup: https://github.com/risdenk/solr_hdfs_ha_docker\n\nThis works pretty well on 32GB of ram with AWS. I was using something similar to this:\n\ndocker-machine create --driver amazonec2 --amazonec2-region us-west-2 --amazonec2-request-spot-instance --amazonec2-spot-price 0.50 --amazonec2-root-size 50 --amazonec2-instance-type m4.2xlarge aws01\neval $(docker-machine env aws01)\n./run.sh\n\n ",
            "author": "Kevin Risden",
            "id": "comment-15889395"
        },
        {
            "date": "2017-03-01T12:58:36+0000",
            "content": "My testing setup: https://github.com/risdenk/solr_hdfs_ha_docker\n\nNice stuff! Thanks for confirming you are seeing that it's fixed also. ",
            "author": "Cassandra Targett",
            "id": "comment-15890108"
        },
        {
            "date": "2017-03-01T21:38:04+0000",
            "content": "I just checked this again with the 6.4.2 release candidate, and it's looking fixed to me. ",
            "author": "Cassandra Targett",
            "id": "comment-15891104"
        }
    ]
}