{
    "id": "LUCENE-5025",
    "title": "Allow more than 2.1B \"tail nodes\" when building FST",
    "details": {
        "components": [
            "core/FSTs"
        ],
        "fix_versions": [
            "4.4",
            "6.0"
        ],
        "affect_versions": "None",
        "priority": "Major",
        "labels": "",
        "type": "Improvement",
        "resolution": "Fixed",
        "status": "Closed"
    },
    "description": "We recently relaxed some of the limits for big FSTs, but there is\none more limit I think we should fix.  E.g. Aaron hit it in building\nthe world's biggest FST: http://aaron.blog.archive.org/2013/05/29/worlds-biggest-fst/\n\nThe issue is NodeHash, which currently uses a GrowableWriter (packed\nints impl that can grow both number of bits and number of values):\nit's indexed by int not long.\n\nThis is a hash table that's used to share suffixes, so we need random\nget/put on a long index of long values, i.e. this is logically a long[].\n\nI think one simple way to do this is to make a \"paged\"\nGrowableWriter...\n\nAlong with this we'd need to fix the hash codes to be long not\nint.",
    "attachments": {
        "LUCENE-5025.patch": "https://issues.apache.org/jira/secure/attachment/12585631/LUCENE-5025.patch"
    },
    "issue_links": {},
    "comments": [
        {
            "date": "2013-05-31T15:44:09+0000",
            "content": "Initial patch, also folding in Adrien's patch from LUCENE-5026.\n\nI had to make one change to that patch so that the last page (GrowableWriter) is sized down, ie if I use 1<<30 page size but only need 100 values then that single GrowableWriter should be size=100 I think.\n\nI'm running Test2BFSTs now ... ",
            "author": "Michael McCandless",
            "id": "comment-13671590"
        },
        {
            "date": "2013-05-31T23:46:16+0000",
            "content": "\nI had to make one change to that patch so that the last page (GrowableWriter) is sized down, ie if I use 1<<30 page size but only need 100 values then that single GrowableWriter should be size=100 I think.\n\nI played with this in the patch, seems to work fine!\nThere is a stray print left in rehash(), but precommit should find that  ",
            "author": "Robert Muir",
            "id": "comment-13671904"
        },
        {
            "date": "2013-06-01T16:59:34+0000",
            "content": "Thanks Rob.\n\nTest2BFSTs also passed, after 4.5 hours and 40 GB heap!\n\nI think it's ready ... I'll clean up that print and the nocommits and commit ... thanks Adrien for creating PagedGrowableWriter! ",
            "author": "Michael McCandless",
            "id": "comment-13672159"
        },
        {
            "date": "2013-06-01T17:07:23+0000",
            "content": "Hmm just hit a failure in the test case for PagedGrowableWriter:\n\nant test  -Dtestcase=TestPackedInts -Dtests.method=testPagedGrowableWriter -Dtests.seed=5F62E708DEB71329 -Dtests.slow=true -Dtests.locale=ar_BH -Dtests.timezone=America/Tijuana -Dtests.file.encoding=UTF-8\n\n\nI haven't looked into it yet ... ",
            "author": "Michael McCandless",
            "id": "comment-13672160"
        },
        {
            "date": "2013-06-01T19:52:37+0000",
            "content": "I think that bug is in PagedGrowableWriter.resize().\n\nCurrently, if you resize one where the last page isnt full, you try to access values that dont exist,\nbecause it just copies pagesize() values.\n\nI think instead it should be (something like):\n\nfor (int i = 0; i < numCommonPages; ++i) {\n      ...\n      final int valuesToCopy;\n      // if its the last page, it might be sized down\n      if (i == subWriters.length - 1) {\n        valuesToCopy = (int)(size() % pageSize());\n      } else {\n        valuesToCopy = pageSize();\n      }\n      PackedInts.copy(subWriters[i], 0, newWriter.subWriters[i], 0, valuesToCopy, copyBuffer);\n    }\n\n ",
            "author": "Robert Muir",
            "id": "comment-13672215"
        },
        {
            "date": "2013-06-02T18:03:59+0000",
            "content": "Thanks Rob!  That's it (due to a similar fix I made in the ctor ...).  I'll fix. ",
            "author": "Michael McCandless",
            "id": "comment-13672621"
        },
        {
            "date": "2013-07-23T18:37:09+0000",
            "content": "Bulk close resolved 4.4 issues ",
            "author": "Steve Rowe",
            "id": "comment-13716768"
        }
    ]
}